%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Cécile Issard at 2022-04-05 17:00:10 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{manybabies2020quantifying,
	author = {ManyBabies{ }Consortium},
	journal = {Advances in Methods and Practices in Psychological Science},
	number = {1},
	pages = {24--52},
	publisher = {SAGE Publications Sage CA: Los Angeles, CA},
	title = {Quantifying sources of variability in infancy research using the infant-directed-speech preference},
	volume = {3},
	year = {2020}}

@article{friedrich_n400-like_2004,
	abstract = {To understand mechanisms of early language acquisition, it is important to know whether the child's brain acts in an adult-like manner when processing words in meaningful contexts. The N400, a negative component in the event-related potential (ERP) of adults, is a sensitive index of semantic processing reflecting neural mechanisms of semantic integration into context. In the present study, we investigated whether the mechanisms indexed by the N400 are already working during early language acquisition. While 19-month-olds were looking at sequentially presented pictures, they were acoustically presented with words that were either congruous or incongruous to the picture content. The ERP averaged across the group of 55 children revealed an N400-like semantic incongruity effect in addition to an early phonological--lexical priming effect. The results suggest that both lexical expectations facilitating early phonological processing and mechanisms of semantic priming facilitating integration into semantic context are already present in 19-month-olds. The child's specific comprehension abilities are reflected in strength, latency, and hemispheric differences of the semantic incongruity effect. Spatio-temporal differences in that effect, thus, indicate changes in the organization of brain activity correlated with the child's behavioral development.},
	author = {Friedrich, Manuela and Friederici, Angela D.},
	doi = {10.1162/0898929042304705},
	file = {Snapshot:/Users/Cecile/Zotero/storage/2V4W9CXZ/0898929042304705.html:text/html},
	issn = {0898-929X},
	journal = {Journal of Cognitive Neuroscience},
	month = oct,
	number = {8},
	pages = {1465--1477},
	shorttitle = {N400-like {Semantic} {Incongruity} {Effect} in 19-{Month}-{Olds}},
	title = {N400-like {Semantic} {Incongruity} {Effect} in 19-{Month}-{Olds}: {Processing} {Known} {Words} in {Picture} {Contexts}},
	url = {http://www.mitpressjournals.org/doi/10.1162/0898929042304705},
	urldate = {2017-07-24},
	volume = {16},
	year = {2004},
	bdsk-url-1 = {http://www.mitpressjournals.org/doi/10.1162/0898929042304705},
	bdsk-url-2 = {https://doi.org/10.1162/0898929042304705}}

@article{shamir_representation_2009,
	abstract = {Author Summary
Sensory processing of time-varying stimuli, such as speech, is associated with high-frequency oscillatory cortical activity, the functional significance of which is still unknown. One possibility is that the oscillations are part of a stimulus-encoding mechanism. Here, we investigate a computational model of such a mechanism, a spiking neuronal network whose intrinsic oscillations interact with external input (waveforms simulating short speech segments in a single acoustic frequency band) to encode stimuli that extend over a time interval longer than the oscillation's period. The network implements a temporally sparse encoding, whose robustness to time warping and neuronal noise we quantify. To our knowledge, this study is the first to demonstrate that a biophysically plausible model of oscillations occurring in the processing of auditory input may generate a representation of signals that span multiple oscillation cycles.},
	author = {Shamir, Maoz and Ghitza, Oded and Epstein, Steven and Kopell, Nancy},
	doi = {10.1371/journal.pcbi.1000370},
	file = {PLoS Snapshot:/Users/Cecile/Zotero/storage/6J2AUV5C/infodoi10.1371journal.pcbi.html:text/html},
	journal = {PLoS Comput Biol},
	month = may,
	number = {5},
	pages = {e1000370},
	title = {Representation of {Time}-{Varying} {Stimuli} by a {Network} {Exhibiting} {Oscillations} on a {Faster} {Time} {Scale}},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1000370},
	urldate = {2014-10-21},
	volume = {5},
	year = {2009},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1000370}}

@article{vouloumanos_five-month-old_2009,
	abstract = {Humans speak, monkeys grunt, and ducks quack. How do we come to know which vocalizations animals produce? Here we explore this question by asking whether young infants expect humans, but not other animals, to produce speech, and further, whether infants have similarly restricted expectations about the sources of vocalizations produced by other species. Five-month-old infants matched speech, but not human nonspeech vocalizations, specifically to humans, looking longer at static human faces when human speech was played than when either rhesus monkey or duck calls were played. They also matched monkey calls to monkey faces, looking longer at static rhesus monkey faces when rhesus monkey calls were played than when either human speech or duck calls were played. However, infants failed to match duck vocalizations to duck faces, even though infants likely have more experience with ducks than monkeys. Results show that by 5 months of age, human infants generate expectations about the sources of some vocalizations, mapping human faces to speech and rhesus faces to rhesus calls. Infants' matching capacity does not appear to be based on a simple associative mechanism or restricted to their specific experiences. We discuss these findings in terms of how infants may achieve such competence, as well as its specificity and relevance to acquiring language.},
	annote = {*},
	author = {Vouloumanos, Athena and Druhen, Madelynn J and Hauser, Marc D and Huizink, Anouk T},
	date-modified = {2022-04-05 16:58:53 +0200},
	doi = {10.1073/pnas.0906049106},
	file = {Vouloumanos et al. - 2009 - Five-month-old infants' identification of the sour.pdf:/Users/Cecile/Zotero/storage/6NSJY8QV/Vouloumanos et al. - 2009 - Five-month-old infants' identification of the sour.pdf:application/pdf},
	issn = {1091-6490},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	keywords = {Acoustic Stimulation, Animals, Face, Humans, Infant, Macaca mulatta, Photic Stimulation, Speech, Time Factors, Vocalization, Animal},
	language = {eng},
	month = nov,
	number = {44},
	pages = {18867--18872},
	pmid = {19846770},
	title = {Five-month-old infants' identification of the sources of vocalizations},
	volume = {106},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.0906049106}}

@article{barlow_possible_1961,
	author = {Barlow, Horace B.},
	file = {Barlow - 1961 - Possible principles underlying the transformation .pdf:/Users/Cecile/Zotero/storage/Q7RF5ZPJ/Barlow - 1961 - Possible principles underlying the transformation .pdf:application/pdf},
	journal = {Sensory Communication},
	pages = {217--234},
	title = {Possible principles underlying the transformation of sensory messages},
	year = {1961}}

@article{ghitza_possible_2009,
	author = {Ghitza, Oded and Greenberg, Steven},
	doi = {10.1159/000208934},
	file = {Ghitzaetal2009.pdf:/Users/Cecile/Zotero/storage/K9FFKIBB/Ghitzaetal2009.pdf:application/pdf;Phonetica 2009, Vol. 66, No. 1-2 - On the Possible Role of Brain Rhythms in Speech Perception\: Intelligibility of Time-Compressed Speech with Periodic and Aperiodic Insertions of Silence - FullText - Karger Publishers:/Users/Cecile/Zotero/storage/M7WFNFKI/208934.html:text/html},
	issn = {1423-0321, 0031-8388},
	journal = {Phonetica},
	language = {en},
	number = {1-2},
	pages = {113--126},
	shorttitle = {On the {Possible} {Role} of {Brain} {Rhythms} in {Speech} {Perception}},
	title = {On the {Possible} {Role} of {Brain} {Rhythms} in {Speech} {Perception}: {Intelligibility} of {Time}-{Compressed} {Speech} with {Periodic} and {Aperiodic} {Insertions} of {Silence}},
	url = {http://www.karger.com/Article/FullText/208934},
	urldate = {2014-10-21},
	volume = {66},
	year = {2009},
	bdsk-url-1 = {http://www.karger.com/Article/FullText/208934},
	bdsk-url-2 = {https://doi.org/10.1159/000208934}}

@article{mahmoudzadeh_syllabic_2013,
	abstract = {The ontogeny of linguistic functions in the human brain remains elusive. Although some auditory capacities are described before term, whether and how such immature cortical circuits might process speech are unknown. Here we used functional optical imaging to evaluate the cerebral responses to syllables at the earliest age at which cortical responses to external stimuli can be recorded in humans (28- to 32-wk gestational age). At this age, the cortical organization in layers is not completed. Many neurons are still located in the subplate and in the process of migrating to their final location. Nevertheless, we observed several points of similarity with the adult linguistic network. First, whereas syllables elicited larger right than left responses, the posterior temporal region escaped this general pattern, showing faster and more sustained responses over the left than over the right hemisphere. Second, discrimination responses to a change of phoneme (ba vs. ga) and a change of human voice (male vs. female) were already present and involved inferior frontal areas, even in the youngest infants (29-wk gestational age). Third, whereas both types of changes elicited responses in the right frontal region, the left frontal region only reacted to a change of phoneme. These results demonstrate a sophisticated organization of perisylvian areas at the very onset of cortical circuitry, 3 mo before term. They emphasize the influence of innate factors on regions involved in linguistic processing and social communication in humans.},
	author = {Mahmoudzadeh, Mahdi and Dehaene-Lambertz, Ghislaine and Fournier, Marc and Kongolo, Guy and Goudjil, Sabrina and Dubois, Jessica and Grebe, Reinhard and Wallois, Fabrice},
	doi = {10.1073/pnas.1212220110},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BCBUMFCR/Mahmoudzadeh et al. - 2013 - Syllabic discrimination in premature human infants.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8N7FG7ZW/1212220110.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {hemispheric lateralization, hemodynamic response, near infrared spectroscopy, premature human brain, language},
	language = {en},
	month = feb,
	pages = {201212220},
	pmid = {23440196},
	title = {Syllabic discrimination in premature human infants prior to complete formation of cortical layers},
	url = {http://www.pnas.org/content/early/2013/02/19/1212220110},
	urldate = {2013-10-16},
	year = {2013},
	bdsk-url-1 = {http://www.pnas.org/content/early/2013/02/19/1212220110},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1212220110}}

@article{grossmann_developmental_2010,
	abstract = {In human adults, voices are processed in specialized brain regions in superior temporal cortices. We examined the development of this cortical organization during infancy by using near-infrared spectroscopy. In experiment 1, 7-month-olds but not 4-month-olds showed increased responses in left and right superior temporal cortex to the human voice when compared to nonvocal sounds, suggesting that voice-sensitive brain systems emerge between 4 and 7 months of age. In experiment 2, 7-month-old infants listened to words spoken with neutral, happy, or angry prosody. Hearing emotional prosody resulted in increased responses in a voice-sensitive region in the right hemisphere. Moreover, a region in right inferior frontal cortex taken to serve evaluative functions in the adult brain showed particular sensitivity to happy prosody. The pattern of findings suggests that temporal regions specialize in processing voices very early in development and that, already in infancy, emotions differentially modulate voice processing in the right hemisphere.},
	author = {Grossmann, Tobias and Oberecker, Regine and Koch, Stefan Paul and Friederici, Angela D.},
	doi = {10.1016/j.neuron.2010.03.001},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/S8PDXM32/Grossmann et al. - 2010 - The Developmental Origins of Voice Processing in t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WD8XHDSG/S0896-6273(10)00170-4.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {SYSNEURO},
	language = {English},
	month = mar,
	number = {6},
	pages = {852--858},
	pmid = {20346760},
	title = {The {Developmental} {Origins} of {Voice} {Processing} in the {Human} {Brain}},
	url = {http://www.cell.com/article/S0896627310001704/abstract},
	urldate = {2015-01-07},
	volume = {65},
	year = {2010},
	bdsk-url-1 = {http://www.cell.com/article/S0896627310001704/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2010.03.001}}

@article{futagi_theta_1998,
	abstract = {In order to specify the locations and to clarify the electrophysiological significance of the transitory rhythmic theta activities detected on scalp electrodes in infants, we performed simultaneous EEG and video recording with power spectral map analysis in 29 normal infants of less than 1 year of age. The rhythmic theta activities appeared in posterior temporal regions with sucking or crying, in the parietal region with gazing, and in the frontal region with handling. Each specific location of the theta rhythm seemed to correspond to the functional localization in the infant's brain. We thus concluded that these rhythmic theta activities might originate from direct cortical activation, or from the cortical activation driven by the neuronal impulses from the limbic system through the connection between that system and the cortex.},
	author = {Futagi, Yasuyuki and Ishihara, Tsutomu and Tsuda, Kumi and Suzuki, Yasuhiro and Goto, Megumi},
	doi = {10.1016/S0013-4694(98)00002-9},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/Z5WSCZ9K/Futagi et al. - 1998 - Theta rhythms associated with sucking, crying, gaz.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/6VQEWKQU/S0013469498000029.html:text/html},
	issn = {0013-4694},
	journal = {Electroencephalography and Clinical Neurophysiology},
	keywords = {Power spectral map analysis, EEG, Infants, Theta Rhythm},
	month = may,
	number = {5},
	pages = {392--399},
	title = {Theta rhythms associated with sucking, crying, gazing and handling in infants},
	url = {http://www.sciencedirect.com/science/article/pii/S0013469498000029},
	urldate = {2016-06-02},
	volume = {106},
	year = {1998},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0013469498000029},
	bdsk-url-2 = {https://doi.org/10.1016/S0013-4694(98)00002-9}}

@article{anne_fernald_four-month-old_1985,
	author = {{Anne Fernald}},
	file = {Four-month-old infants prefer to listen to motherese:/Users/Cecile/Zotero/storage/D8KIQMCK/S0163638385800059.html:text/html},
	journal = {Infant Behavior and Development},
	month = jun,
	number = {2},
	pages = {181--195},
	title = {Four-month-old infants prefer to listen to motherese},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059},
	urldate = {2014-09-06},
	volume = {8},
	year = {1985},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059}}

@article{spence_prenatal_1987,
	abstract = {By sucking on a nonnutritive nipple in the presence of one discriminative stimulus, newborns were reinforced with a low-pass filtered tape recording of their mothers' voices. Sucking in the presence of a different discriminative stimulus was reinforced with unfiltered maternal-voice recordings. Filtered versions simulated maternal-voice sounds that were available before birth and unfiltered versions simulated maternal-voice sounds available after birth. Newborns in the control group could be reinforced with the same stimuli in the same way, but the voices were unfamiliar to them. Infants hearing their mothers' voices had no preference for either version, but infants hearing the unfamiliar voices preferred the unfiltered version. The difference in the between-groups responsiveness to the low-pass voice samples is consistent with the hypothesis that prenatal experience with low-frequency characteristics of maternal voices influences early postnatal perception of maternal voices.},
	author = {Spence, Melanie J. and DeCasper, Anthony J.},
	doi = {10.1016/0163-6383(87)90028-2},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/WAHTJQC4/Spence et DeCasper - 1987 - Prenatal experience with low-frequency maternal-vo.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AIZIMENP/0163638387900282.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {auditory preception, auditory preference, maternal voice, newborn perception, prenatal sensory experience, voice perception},
	month = apr,
	number = {2},
	pages = {133--142},
	title = {Prenatal experience with low-frequency maternal-voice sounds influence neonatal perception of maternal voice samples},
	url = {http://www.sciencedirect.com/science/article/pii/0163638387900282},
	urldate = {2016-01-26},
	volume = {10},
	year = {1987},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0163638387900282},
	bdsk-url-2 = {https://doi.org/10.1016/0163-6383(87)90028-2}}

@article{nordt_use_2016,
	abstract = {Repetition suppression paradigms allow a more detailed look at brain functioning than classical paradigms and have been applied vigorously in adult cognitive neuroscience. These paradigms are well suited for studies in the field of developmental cognitive neuroscience as they can be applied without collecting a behavioral response and across all age groups. Furthermore, repetition suppression paradigms can be employed in various neuroscience techniques, such as functional magnetic resonance imaging (fMRI), functional near-infrared spectroscopy (fNIRS), electroencephalography (EEG) and magnetoencephalography (MEG). In the present article we review studies using repetition suppression paradigms in developmental cognitive neuroscience covering the age range from infancy to adolescence. Our first goal is to point out characteristics of developmental repetition suppression effects. In doing so, we discuss the relationship of the direction of repetition effects (suppression vs enhancement) with developmental factors, and address the question how the direction of repetition effects might be related to looking-time effects in behavioral infant paradigms, the most prominently used behavioral measure in infant research. To highlight the potential of repetition suppression paradigms, our second goal is to provide an overview on the insights recently obtained by applying repetition paradigms in neurodevelopmental studies, including research on children with autism spectrum disorders (ASDs). We conclude that repetition suppression paradigms are valuable tools for investigating neurodevelopmental processes, while at the same time we highlight the necessity for further studies that disentangle methodological and developmental factors.},
	author = {Nordt, Marisa and Hoehl, Stefanie and Weigelt, Sarah},
	doi = {10.1016/j.cortex.2016.04.002},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GST3AEDS/Nordt et al. - The use of repetition suppression paradigms in dev.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2Q9U2CP4/S0010945216300612.html:text/html},
	issn = {0010-9452},
	journal = {Cortex},
	keywords = {Adaptation, Brain development, Habituation, repetition suppression, Development},
	title = {The use of repetition suppression paradigms in developmental cognitive neuroscience},
	url = {http://www.sciencedirect.com/science/article/pii/S0010945216300612},
	urldate = {2016-05-23},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0010945216300612},
	bdsk-url-2 = {https://doi.org/10.1016/j.cortex.2016.04.002}}

@article{gervain_neonate_2008,
	abstract = {What are the origins of the efficient language learning abilities that allow humans to acquire their mother tongue in just a few years very early in life? Although previous studies have identified different mechanisms underlying the acquisition of auditory and speech patterns in older infants and adults, the earliest sensitivities remain unexplored. To address this issue, we investigated the ability of newborns to learn simple repetition-based structures in two optical brain-imaging experiments. In the first experiment, 22 neonates listened to syllable sequences containing immediate repetitions (ABB; e.g., ``mubaba,'' ``penana''), intermixed with random control sequences (ABC; e.g., ``mubage,'' ``penaku''). We found increased responses to the repetition sequences in the temporal and left frontal areas, indicating that the newborn brain differentiated the two patterns. The repetition sequences evoked greater activation than the random sequences during the first few trials, suggesting the presence of an automatic perceptual mechanism to detect repetitions. In addition, over the subsequent trials, activation increased further in response to the repetition sequences but not in response to the random sequences, indicating that recognition of the ABB pattern was enhanced by repeated exposure. In the second experiment, in which nonadjacent repetitions (ABA; e.g., ``bamuba,'' ``napena'') were contrasted with the same random controls, no discrimination was observed. These findings suggest that newborns are sensitive to certain input configurations in the auditory domain, a perceptual ability that might facilitate later language development.},
	author = {Gervain, Judit and Macagno, Francesco and Cogoi, Silvia and Pe{\~n}a, Marcela and Mehler, Jacques},
	doi = {10.1073/pnas.0806530105},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/96PUNDAW/Gervain et al. - 2008 - The neonate brain detects speech structure.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/D9TNZ9HQ/14222.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {language acquisition, newborns, optical imaging, perceptual primitives, speech perception, Speech Perception},
	language = {en},
	month = sep,
	number = {37},
	pages = {14222--14227},
	pmid = {18768785},
	title = {The neonate brain detects speech structure},
	url = {http://www.pnas.org/content/105/37/14222},
	urldate = {2014-01-20},
	volume = {105},
	year = {2008},
	bdsk-url-1 = {http://www.pnas.org/content/105/37/14222},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0806530105}}

@article{oherron_neural_2016,
	abstract = {Neural activation increases blood flow locally. This vascular signal is used by functional imaging techniques to infer the location and strength of neural activity. However, the precise spatial scale over which neural and vascular signals are correlated is unknown. Furthermore, the relative role of synaptic and spiking activity in driving haemodynamic signals is controversial. Previous studies recorded local field potentials as a measure of synaptic activity together with spiking activity and low-resolution haemodynamic imaging. Here we used two-photon microscopy to measure sensory-evoked responses of individual blood vessels (dilation, blood velocity) while imaging synaptic and spiking activity in the surrounding tissue using fluorescent glutamate and calcium sensors. In cat primary visual cortex, where neurons are clustered by their preference for stimulus orientation, we discovered new maps for excitatory synaptic activity, which were organized similarly to those for spiking activity but were less selective for stimulus orientation and direction. We generated tuning curves for individual vessel responses for the first time and found that parenchymal vessels in cortical layer 2/3 were orientation selective. Neighbouring penetrating arterioles had different orientation preferences. Pial surface arteries in cats, as well as surface arteries and penetrating arterioles in rat visual cortex (where orientation maps do not exist), responded to visual stimuli but had no orientation selectivity. We integrated synaptic or spiking responses around individual parenchymal vessels in cats and established that the vascular and neural responses had the same orientation preference. However, synaptic and spiking responses were more selective than vascular responses---vessels frequently responded robustly to stimuli that evoked little to no neural activity in the surrounding tissue. Thus, local neural and haemodynamic signals were partly decoupled. Together, these results indicate that intrinsic cortical properties, such as propagation of vascular dilation between neighbouring columns, need to be accounted for when decoding haemodynamic signals.},
	author = {O'Herron, Philip and Chhatbar, Pratik Y. and Levy, Manuel and Shen, Zhiming and Schramm, Adrien E. and Lu, Zhongyang and Kara, Prakash},
	copyright = {{\copyright} 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nature17965},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9S9CRFCP/O'Herron et al. - 2016 - Neural correlates of single-vessel haemodynamic re.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VA7VT957/nature17965.html:text/html},
	issn = {0028-0836},
	journal = {Nature},
	language = {en},
	month = may,
	title = {Neural correlates of single-vessel haemodynamic responses in vivo},
	url = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature17965.html},
	urldate = {2016-05-30},
	volume = {advance online publication},
	year = {2016},
	bdsk-url-1 = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature17965.html},
	bdsk-url-2 = {https://doi.org/10.1038/nature17965}}

@article{saby_utility_2012,
	abstract = {Research employing electroencephalographic (EEG) techniques with infants and young children has flourished in recent years due to increased interest in understanding the neural processes involved in early social and cognitive development. This review focuses on the functional characteristics of the alpha, theta, and gamma frequency bands in the developing EEG. Examples of how analyses of EEG band power have been applied to specific lines of developmental research are also discussed. These examples include recent work on the infant mu rhythm and action processing, frontal alpha asymmetry and approach-withdrawal tendencies, and EEG power measures in the study of early psychosocial adversity.},
	author = {Saby, Joni N. and Marshall, Peter J.},
	doi = {10.1080/87565641.2011.614663},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/IW5JS6EZ/Saby et Marshall - 2012 - The Utility of EEG Band Power Analysis in the Stud.pdf:application/pdf},
	issn = {8756-5641},
	journal = {Developmental Neuropsychology},
	month = apr,
	number = {3},
	pages = {253--273},
	pmcid = {PMC3347767},
	pmid = {22545661},
	title = {The {Utility} of {EEG} {Band} {Power} {Analysis} in the {Study} of {Infancy} and {Early} {Childhood}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3347767/},
	urldate = {2016-06-02},
	volume = {37},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3347767/},
	bdsk-url-2 = {https://doi.org/10.1080/87565641.2011.614663}}

@article{vouloumanos_tuning_2010,
	abstract = {Human neonates prefer listening to speech compared to many nonspeech sounds, suggesting that humans are born with a bias for speech. However, neonates' preference may derive from properties of speech that are not unique but instead are shared with the vocalizations of other species. To test this, thirty neonates and sixteen 3-month-olds were presented with nonsense speech and rhesus monkey vocalizations. Neonates showed no preference for speech over rhesus vocalizations but showed a preference for both these sounds over synthetic sounds. In contrast, 3-month-olds preferred speech to rhesus vocalizations. Neonates' initial biases minimally include speech and monkey vocalizations. These listening preferences are sharpened over 3 months, yielding a species-specific preference for speech, paralleling findings on infant face perception.},
	annote = {*},
	author = {Vouloumanos, Athena and Hauser, Marc D and Werker, Janet F and Martin, Alia},
	date-modified = {2022-04-05 16:59:11 +0200},
	doi = {10.1111/j.1467-8624.2009.01412.x},
	issn = {1467-8624},
	journal = {Child development},
	keywords = {Acoustic Stimulation, Animals, Arousal, Attention, Auditory Perception, Child Psychology, Choice Behavior, Female, Follow-Up Studies, Humans, Infant, Newborn, Language Development, Macaca mulatta, Male, Sound Spectrography, Vocalization, Animal, speech perception, Speech Perception},
	language = {eng},
	month = apr,
	number = {2},
	pages = {517--527},
	pmid = {20438457},
	title = {The tuning of human neonates' preference for speech},
	volume = {81},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1111/j.1467-8624.2009.01412.x}}

@article{poeppel_analysis_2003,
	abstract = {The `asymmetric sampling in time' (AST) hypothesis developed here provides a framework for understanding a range of psychophysical and neuropsychological data on speech perception in the context of a revised cortical functional anatomic model. The AST model is motivated by observations from psychophysics and cognitive neuroscience that speak to the fractionation of auditory processing, in general, and speech perception, in particular. Building on the observations (1) that the speech signal contains more than one time scale relevant to auditory cognition (e.g. time scales commensurate with processing formant transitions versus scales commensurate with syllabicity and intonation contours), and (2) that speech perception is mediated by both left and right auditory cortices, AST suggests a time-based perspective that maintains anatomic symmetry while permitting functional asymmetry. AST proposes that the input speech signal has a neural representation that is bilaterally symmetric at an early representational level. Beyond the initial representation, however, the signal is elaborated asymmetrically in the time domain: left auditory areas preferentially extract information from short (∼20--40 ms) temporal integration windows. The right hemisphere homologues preferentially extract information from long (∼150--250 ms) integration windows. It is suggested that temporal integration is reflected as oscillatory neuronal activity in different frequency bands (gamma, theta).},
	author = {Poeppel, David},
	doi = {10.1016/S0167-6393(02)00107-3},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/HNMHBJ8I/Poeppel - 2003 - The analysis of speech in different temporal integ.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZCWXHPRH/S0167639302001073.html:text/html},
	issn = {0167-6393},
	journal = {Speech Communication},
	keywords = {Gamma band, Hemispheric asymmetry, Neural basis of speech, Oscillations, Temporal integration, Theta band, Timing, Auditory cortex},
	month = aug,
	number = {1},
	pages = {245--255},
	series = {The {Nature} of {Speech} {Perception}},
	shorttitle = {The analysis of speech in different temporal integration windows},
	title = {The analysis of speech in different temporal integration windows: cerebral lateralization as `asymmetric sampling in time'},
	url = {http://www.sciencedirect.com/science/article/pii/S0167639302001073},
	urldate = {2014-10-21},
	volume = {41},
	year = {2003},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0167639302001073},
	bdsk-url-2 = {https://doi.org/10.1016/S0167-6393(02)00107-3}}

@article{ding_cortical_2014,
	abstract = {Auditory cortical activity is entrained to the temporal envelope of speech, which corresponds to the syllabic rhythm of speech. Such entrained cortical activity can be measured from subjects naturally listening to sentences or spoken passages, providing a reliable neural marker of online speech processing. A central question still remains to be answered about whether cortical entrained activity is more closely related to speech perception or non-speech-specific auditory encoding. Here, we review a few hypotheses about the functional roles of cortical entrainment to speech, e.g., encoding acoustic features, parsing syllabic boundaries, and selecting sensory information in complex listening environments. It is likely that speech entrainment is not a homogeneous response and these hypotheses apply separately for speech entrainment generated from different neural sources. The relationship between entrained activity and speech intelligibility is also discussed. A tentative conclusion is that theta-band entrainment (4--8 Hz) encodes speech features critical for intelligibility while delta-band entrainment (1--4 Hz) is related to the perceived, non-speech-specific acoustic rhythm. To further understand the functional properties of speech entrainment, a splitter's approach will be needed to investigate (1) not just the temporal envelope but what specific acoustic features are encoded and (2) not just speech intelligibility but what specific psycholinguistic processes are encoded by entrained cortical activity. Similarly, the anatomical and spectro-temporal details of entrained activity need to be taken into account when investigating its functional properties.},
	author = {Ding, Nai and Simon, Jonathan Z.},
	doi = {10.3389/fnhum.2014.00311},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/JBXMPBAS/Ding et Simon - 2014 - Cortical entrainment to continuous speech functio.pdf:application/pdf},
	journal = {Frontiers in Human Neuroscience},
	keywords = {Speech Intelligibility, cocktail party problem, entrainment of rhythms, speech envelope, speech perception in noise, Auditory cortex},
	pages = {311},
	shorttitle = {Cortical entrainment to continuous speech},
	title = {Cortical entrainment to continuous speech: functional roles and interpretations},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00311/abstract},
	urldate = {2015-10-22},
	volume = {8},
	year = {2014},
	bdsk-url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00311/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2014.00311}}

@article{voss_1/f_1978,
	abstract = {The spectral density of fluctuations in the audio power of many musical selections and of English speech varies approximately as 1/f (f is the frequency) down to a frequency of 5×10−4 Hz. This result implies that the audio‐power fluctuations are correlated over all times in the same manner as ''1/f noise'' in electronic components. The frequency fluctuations of music also have a 1/f spectral density at frequencies down to the inverse of the length of the piece of music. The frequency fluctuations of English speech have a quite different behavior, with a single characteristic time of about 0.1 s, the average length of a syllable. The observations on music suggest that 1/fnoise is a good choice for stochastic composition. Compositions in which the frequency and duration of each note were determined by 1/fnoise sources sounded pleasing. Those generated by white‐noise sources sounded too random, while those generated by 1/f 2noisesounded too correlated.},
	author = {Voss, Richard F. and Clarke, John},
	doi = {10.1121/1.381721},
	file = {Snapshot:/Users/Cecile/Zotero/storage/BB8SEDJE/1.html:text/html;voss-clarke.pdf:/Users/Cecile/Zotero/storage/R7J3BBIQ/voss-clarke.pdf:application/pdf},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {1/f noise, Acoustic noise, Acoustic source localization, Electronic devices, Speech},
	month = jan,
	number = {1},
	pages = {258--263},
	shorttitle = {''1/f noise'' in music},
	title = {''1/f noise'' in music: {Music} from 1/f noise},
	url = {http://scitation.aip.org/content/asa/journal/jasa/63/1/10.1121/1.381721},
	urldate = {2015-12-16},
	volume = {63},
	year = {1978},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/63/1/10.1121/1.381721},
	bdsk-url-2 = {https://doi.org/10.1121/1.381721}}

@article{remez_2_2008,
	author = {Remez, Robert E.},
	file = {RemezPercOrg2005.pdf:/Users/Cecile/Zotero/storage/WF3IT8EP/RemezPercOrg2005.pdf:application/pdf},
	journal = {The handbook of speech perception},
	pages = {28},
	title = {2 {Perceptual} {Organization} of {Speech}},
	url = {http://books.google.com/books?hl=en&lr=&id=EwY15naRiFgC&oi=fnd&pg=PA28&dq=%22perception+obliges+the+models+to+admit+severe+and+unintended+constraints%22+%22speech+alone,+there+has+been+a+plausible+and+convenient+way+to+persist%22+%22constituents+of+a+speech+signal,+the+perceptual+organization+of+speech%22+&ots=0NZ9A87_aO&sig=auGhQjQdfpaL6lJfH_ONOmQv0_s},
	urldate = {2015-10-02},
	year = {2008},
	bdsk-url-1 = {http://books.google.com/books?hl=en&lr=&id=EwY15naRiFgC&oi=fnd&pg=PA28&dq=%22perception+obliges+the+models+to+admit+severe+and+unintended+constraints%22+%22speech+alone,+there+has+been+a+plausible+and+convenient+way+to+persist%22+%22constituents+of+a+speech+signal,+the+perceptual+organization+of+speech%22+&ots=0NZ9A87_aO&sig=auGhQjQdfpaL6lJfH_ONOmQv0_s}}

@article{querleu_fetal_1988,
	abstract = {The fetus can hear during the last trimester of pregnancy. Consistent responses to acoustic stimuli have been observed from 28 weeks onwards. Animal experiments as well as investigations in the human lead to the conclusion that sounds from outside the mother are attenuated, but rarely by more than 30 decibels; external conversations are audible. Only 30\% of the phonetic information is available to the fetus, but intonation is almost perfectly transmitted to the amniotic sac. Evidence is accumulating that the mother's voice or different sound patterns from the same voice are learnt by the fetus. Thus there are indications that short-term auditory memory may be present by the end of pregnancy.},
	author = {Querleu, Denis and Renard, Xavier and Versyp, Fabienne and Paris-Delrue, Laurence and Cr{\`e}pin, Gilles},
	doi = {10.1016/0028-2243(88)90030-5},
	file = {1-s2.0-0028224388900305-main.pdf:/Users/Cecile/Zotero/storage/5ER53AI3/1-s2.0-0028224388900305-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4EVU6CKR/0028224388900305.html:text/html},
	issn = {0301-2115},
	journal = {European Journal of Obstetrics \& Gynecology and Reproductive Biology},
	keywords = {Attachment, Developmental neurology, Fetal hearing, Fetal reactivity},
	month = jul,
	number = {3},
	pages = {191--212},
	title = {Fetal hearing},
	url = {http://www.sciencedirect.com/science/article/pii/0028224388900305},
	urldate = {2016-01-26},
	volume = {28},
	year = {1988},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0028224388900305},
	bdsk-url-2 = {https://doi.org/10.1016/0028-2243(88)90030-5}}

@article{decasper_human_1980,
	abstract = {By sucking on a nonnutritive nipple in different ways, a newborn human could produce either its mother's voice or the voice of another female. Infants learned how to produce the mother's voice and produced it more often than the other voice. The neonate's preference for the maternal voice suggests that the period shortly after birth may be important for initiating infant bonding to the mother.},
	author = {DeCasper, A. J. and Fifer, W. P.},
	copyright = {{\copyright} 1980},
	doi = {10.1126/science.7375928},
	file = {Snapshot:/Users/Cecile/Zotero/storage/GTTGVNWM/1174.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jun,
	number = {4448},
	pages = {1174--1176},
	pmid = {7375928},
	shorttitle = {Of human bonding},
	title = {Of human bonding: newborns prefer their mothers' voices},
	url = {http://science.sciencemag.org/content/208/4448/1174},
	urldate = {2016-02-01},
	volume = {208},
	year = {1980},
	bdsk-url-1 = {http://science.sciencemag.org/content/208/4448/1174},
	bdsk-url-2 = {https://doi.org/10.1126/science.7375928}}

@article{kayser_rhythmic_2015,
	abstract = {The phase of low-frequency network activity in the auditory cortex captures changes in neural excitability, entrains to the temporal structure of natural sounds, and correlates with the perceptual performance in acoustic tasks. Although these observations suggest a causal link between network rhythms and perception, it remains unknown how precisely they affect the processes by which neural populations encode sounds. We addressed this question by analyzing neural responses in the auditory cortex of anesthetized rats using stimulus--response models. These models included a parametric dependence on the phase of local field potential rhythms in both stimulus-unrelated background activity and the stimulus--response transfer function. We found that phase-dependent models better reproduced the observed responses than static models, during both stimulation with a series of natural sounds and epochs of silence. This was attributable to two factors: (1) phase-dependent variations in background firing (most prominent for delta; 1--4 Hz); and (2) modulations of response gain that rhythmically amplify and attenuate the responses at specific phases of the rhythm (prominent for frequencies between 2 and 12 Hz). These results provide a quantitative characterization of how slow auditory cortical rhythms shape sound encoding and suggest a differential contribution of network activity at different timescales. In addition, they highlight a putative mechanism that may implement the selective amplification of appropriately timed sound tokens relative to the phase of rhythmic auditory cortex activity.},
	author = {Kayser, Christoph and Wilson, Caroline and Safaai, Houman and Sakata, Shuzo and Panzeri, Stefano},
	doi = {10.1523/JNEUROSCI.0268-15.2015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8G7V78MT/Kayser et al. - 2015 - Rhythmic Auditory Cortex Activity at Multiple Time.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4IUQPJ4M/7750.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	keywords = {LNP models, information coding, network state, neural coding, receptive fields, Delta Rhythm},
	language = {en},
	month = may,
	number = {20},
	pages = {7750--7762},
	title = {Rhythmic {Auditory} {Cortex} {Activity} at {Multiple} {Timescales} {Shapes} {Stimulus}--{Response} {Gain} and {Background} {Firing}},
	url = {http://www.jneurosci.org/content/35/20/7750},
	urldate = {2015-05-26},
	volume = {35},
	year = {2015},
	bdsk-url-1 = {http://www.jneurosci.org/content/35/20/7750},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.0268-15.2015}}

@article{atencio_hierarchical_2009,
	abstract = {Sensory cortical anatomy has identified a canonical microcircuit underlying computations between and within layers. This feed-forward circuit processes information serially from granular to supragranular and to infragranular layers. How this substrate correlates with an auditory cortical processing hierarchy is unclear. We recorded simultaneously from all layers in cat primary auditory cortex (AI) and estimated spectrotemporal receptive fields (STRFs) and associated nonlinearities. Spike-triggered averaged STRFs revealed that temporal precision, spectrotemporal separability, and feature selectivity varied with layer according to a hierarchical processing model. STRFs from maximally informative dimension (MID) analysis confirmed hierarchical processing. Of two cooperative MIDs identified for each neuron, the first comprised the majority of stimulus information in granular layers. Second MID contributions and nonlinear cooperativity increased in supragranular and infragranular layers. The AI microcircuit provides a valid template for three independent hierarchical computation principles. Increases in processing complexity, STRF cooperativity, and nonlinearity correlate with the synaptic distance from granular layers.},
	author = {Atencio, Craig A. and Sharpee, Tatyana O. and Schreiner, Christoph E.},
	doi = {10.1073/pnas.0908383106},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RK3R3QWV/Atencio et al. - 2009 - Hierarchical computation in the canonical auditory.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MBBEX89C/21894.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {cortical laminae, information, spectrotemporal receptive field, Auditory cortex},
	language = {en},
	month = dec,
	number = {51},
	pages = {21894--21899},
	pmid = {19918079},
	title = {Hierarchical computation in the canonical auditory cortical circuit},
	url = {http://www.pnas.org/content/106/51/21894},
	urldate = {2015-05-22},
	volume = {106},
	year = {2009},
	bdsk-url-1 = {http://www.pnas.org/content/106/51/21894},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0908383106}}

@article{hepper_development_1994,
	abstract = {Previous research has revealed that the human fetus responds to sound, but to date there has been little systematic investigation of the development of fetal hearing. The development of fetal behavioural responsiveness to pure tone auditory stimuli (100 Hz, 250 Hz, 500 Hz, 1000 Hz, and 3000 Hz) was examined from 19 to 35 weeks of gestational age. Stimuli were presented by a loudspeaker placed on the maternal abdomen and the fetus's response, a movement, recorded by ultrasound. The fetus responded first to the 500 Hz tone, where the first response was observed at 19 weeks of gestational age. The range of frequencies responded to expanded first downwards to lower frequencies, 100 Hz and 250 Hz, and then upwards to higher frequencies, 1000 Hz and 3000 Hz. At 27 weeks of gestational age, 96\% of fetuses responded to the 250 Hz and 500 Hz tones but none responded to the 1000 Hz and 3000 Hz tones. Responsiveness to 1000 Hz and 3000 Hz tones was observed in all fetuses at 33 and 35 weeks of gestational age, respectively. For all frequencies there was a large decrease (20-30 dB) in the intensity level required to elicit a response as the fetus matured. The observed pattern of behavioural responsiveness reflects underlying maturation of the auditory system. The sensitivity of the fetus to sounds in the low frequency range may promote language acquisition and result in increased susceptibility to auditory system damage arising from exposure to intense low frequency sounds.},
	author = {Hepper, Peter G and Shahidullah, B Sara},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/KAT78TV6/Hepper et Shahidullah - 1994 - Development of fetal hearing.pdf:application/pdf},
	issn = {1359-2998},
	journal = {Archives of Disease in Childhood Fetal and Neonatal edition},
	month = sep,
	number = {2},
	pages = {F81--F87},
	pmcid = {PMC1061088},
	pmid = {7979483},
	title = {Development of fetal hearing},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1061088/},
	urldate = {2015-04-01},
	volume = {71},
	year = {1994},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1061088/}}

@article{saoud_brainspeech_2012,
	abstract = {Asymmetry in auditory cortical oscillations could play a role in speech perception by fostering hemispheric triage of information across the two hemispheres. Due to this asymmetry, fast speech temporal modulations relevant for phonemic analysis could be best perceived by the left auditory cortex, while slower modulations conveying vocal and paralinguistic information would be better captured by the right one. It is unclear, however, whether and how early oscillation-based selection influences speech perception. Using a dichotic listening paradigm in human participants, where we provided different parts of the speech envelope to each ear, we show that word recognition is facilitated when the temporal properties of speech match the rhythmic properties of auditory cortices. We further show that the interaction between speech envelope and auditory cortices rhythms translates in their level of neural activity (as measured with fMRI). In the left auditory cortex, the neural activity level related to stimulus--brain rhythm interaction predicts speech perception facilitation. These data demonstrate that speech interacts with auditory cortical rhythms differently in right and left auditory cortex, and that in the latter, the interaction directly impacts speech perception performance.},
	author = {Saoud, Houda and Josse, Goulven and Bertasi, Eric and Truy, Eric and Chait, Maria and Giraud, Anne-Lise},
	doi = {10.1523/JNEUROSCI.3970-11.2012},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UMBIN5FF/Saoud et al. - 2012 - Brain--Speech Alignment Enhances Auditory Cortical .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DTZD2493/275.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = apr,
	number = {1},
	pages = {275--281},
	pmid = {22219289},
	title = {Brain--{Speech} {Alignment} {Enhances} {Auditory} {Cortical} {Responses} and {Speech} {Perception}},
	url = {http://www.jneurosci.org/content/32/1/275},
	urldate = {2015-01-07},
	volume = {32},
	year = {2012},
	bdsk-url-1 = {http://www.jneurosci.org/content/32/1/275},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3970-11.2012}}

@article{steinschneider_representation_2013,
	abstract = {Successful categorization of phonemes in speech requires that the brain analyze the acoustic signal along both spectral and temporal dimensions. Neural encoding of the stimulus amplitude envelope is critical for parsing the speech stream into syllabic units. Encoding of voice onset time (VOT) and place of articulation (POA), cues necessary for determining phonemic identity, occurs within shorter time frames. An unresolved question is whether the neural representation of speech is based on processing mechanisms that are unique to humans and shaped by learning and experience, or is based on rules governing general auditory processing that are also present in non-human animals. This question was examined by comparing the neural activity elicited by speech and other complex vocalizations in primary auditory cortex of macaques, who are limited vocal learners, with that in Heschl's gyrus, the putative location of primary auditory cortex in humans. Entrainment to the amplitude envelope is neither specific to humans nor to human speech. VOT is represented by responses time-locked to consonant release and voicing onset in both humans and monkeys. Temporal representation of VOT is observed both for isolated syllables and for syllables embedded in the more naturalistic context of running speech. The fundamental frequency of male speakers is represented by more rapid neural activity phase-locked to the glottal pulsation rate in both humans and monkeys. In both species, the differential representation of stop consonants varying in their POA can be predicted by the relationship between the frequency selectivity of neurons and the onset spectra of the speech sounds. These findings indicate that the neurophysiology of primary auditory cortex is similar in monkeys and humans despite their vastly different experience with human speech, and that Heschl's gyrus is engaged in general auditory, and not language-specific, processing.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	author = {Steinschneider, Mitchell and Nourski, Kirill V. and Fishman, Yonatan I.},
	doi = {10.1016/j.heares.2013.05.013},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SSE3WWW4/Steinschneider et al. - 2013 - Representation of speech in human auditory cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/FZGPASR2/S0378595513001433.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = nov,
	pages = {57--73},
	series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	shorttitle = {Representation of speech in human auditory cortex},
	title = {Representation of speech in human auditory cortex: {Is} it special?},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513001433},
	urldate = {2014-10-31},
	volume = {305},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001433},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.05.013}}

@article{benson_parametrically_2001,
	abstract = {Candidate brain regions constituting a neural network for preattentive phonetic perception were identified with fMRI and multivariate multiple regression of imaging data. Stimuli contrasted along speech/nonspeech, acoustic, or phonetic complexity (three levels each) and natural/synthetic dimensions. Seven distributed brain regions' activity correlated with speech and speech complexity dimensions, including five left-sided foci [posterior superior temporal gyrus (STG), angular gyrus, ventral occipitotemporal cortex, inferior/posterior supramarginal gyrus, and middle frontal gyrus (MFG)] and two right-sided foci (posterior STG and anterior insula). Only the left MFG discriminated natural and synthetic speech. The data also supported a parallel rather than serial model of auditory speech and nonspeech perception.},
	author = {Benson, Randall R. and Whalen, D. H. and Richardson, Matthew and Swainson, Brook and Clark, Vincent P. and Lai, Song and Liberman, Alvin M.},
	doi = {10.1006/brln.2001.2484},
	file = {Bensonetal2001.pdf:/Users/Cecile/Zotero/storage/2Q38P758/Bensonetal2001.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8B5A7NRR/S0093934X01924848.html:text/html},
	issn = {0093-934X},
	journal = {Brain and Language},
	keywords = {Imaging, Key Words: brain, Perception, Speech, Wernicke, auditory, fMRI, parametric, phonetic, language},
	month = sep,
	number = {3},
	pages = {364--396},
	title = {Parametrically {Dissociating} {Speech} and {Nonspeech} {Perception} in the {Brain} {Using} {fMRI}},
	url = {http://www.sciencedirect.com/science/article/pii/S0093934X01924848},
	urldate = {2014-10-21},
	volume = {78},
	year = {2001},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X01924848},
	bdsk-url-2 = {https://doi.org/10.1006/brln.2001.2484}}

@article{wild_adult-like_2017,
	abstract = {Functional neuroimaging has been used to show that the developing auditory cortex of very young human infants responds, in some way, to sound. However, impoverished stimuli and uncontrolled designs have made it difficult to attribute brain responses to specific auditory features, and thus made it difficult to assess the maturity of feature tuning in auditory cortex. To address this, we used functional magnetic resonance imaging (fMRI) to measure the brain activity evoked by naturalistic sounds (a series of sung lullabies) in two groups of infants (3 and 9 months) and adults. We developed a novel analysis method -- inter-subject regression (ISR) -- to quantify the similarity of cortical responses between infants and adults, and to decompose components of the response due to different auditory features. We found that the temporal pattern of activity in infant auditory cortex shared similarity with adults. Some of this shared response could be attributed to simple acoustic features, such as frequency, pitch, envelope, but other parts were not, suggesting that even more complex adult-like features are represented in auditory cortex in early infancy.},
	author = {Wild, Conor J. and Linke, Annika C. and Zubiaurre-Elorza, Leire and Herzmann, Charlotte and Duffy, Hester and Han, Victor K. and Lee, David S. C. and Cusack, Rhodri},
	doi = {10.1016/j.neuroimage.2017.06.038},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9HSDS4PK/S1053811917305062.html:text/html;Wild et al. - 2017 - Adult-like processing of naturalistic sounds in au.pdf:/Users/Cecile/Zotero/storage/DZ8UWJWA/Wild et al. - 2017 - Adult-like processing of naturalistic sounds in au.pdf:application/pdf},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = aug,
	number = {Supplement C},
	pages = {623--634},
	title = {Adult-like processing of naturalistic sounds in auditory cortex by 3- and 9-month old infants},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917305062},
	volume = {157},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811917305062},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2017.06.038}}

@article{aslin_methodological_2005,
	abstract = {Studies of cognitive development in human infants have relied almost entirely on descriptive data at the behavioral level -- the age at which a particular ability emerges. The underlying mechanisms of cognitive development remain largely unknown, despite attempts to correlate behavioral states with brain states. We argue that research on cognitive development must focus on theories of learning, and that these theories must reveal both the computational principles and the set of constraints that underlie developmental change. We discuss four specific issues in infant learning that gain renewed importance in light of this opinion.},
	author = {Aslin, Richard N. and Fiser, J{\'o}zsef},
	doi = {10.1016/j.tics.2005.01.003},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UN7M4VGI/Aslin et Fiser - 2005 - Methodological challenges for understanding cognit.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GCH78ZSX/S1364661305000227.html:text/html},
	issn = {1364-6613},
	journal = {Trends in Cognitive Sciences},
	month = mar,
	number = {3},
	pages = {92--98},
	series = {Special issue: {Developmental} cognitive neuroscience},
	title = {Methodological challenges for understanding cognitive development in infants},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661305000227},
	urldate = {2014-09-25},
	volume = {9},
	year = {2005},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661305000227},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2005.01.003}}

@article{liberman_specialization_1989,
	abstract = {The processes that underlie perception of consonants and vowels are specifically phonetic, distinct from those that localize sources and assign auditory qualities to the sound from each source. This specialization, or module, increases the rate of information flow, establishes the parity between sender and receiver that every communication system must have, and provides for the natural development of phonetic structures in the species and in the individual. The phonetic module has certain properties in common with modules that are "closed" (for example, sound localization or echo ranging in bats) and, like other members of this class, is so placed in the architecture of the auditory system as to preempt information that is relevant to its special function. Accordingly, this information is not available to such "open" modules as those for pitch, loudness, and timbre.},
	author = {Liberman, A. M. and Mattingly, I. G.},
	doi = {10.1126/science.2643163},
	file = {Liberman et Mattingly - 1989 - A specialization for speech perception.pdf:/Users/Cecile/Zotero/storage/SU3YFIP3/Liberman et Mattingly - 1989 - A specialization for speech perception.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PCRQBNDK/489.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jan,
	number = {4890},
	pages = {489--494},
	pmid = {2643163},
	title = {A specialization for speech perception},
	url = {http://www.sciencemag.org/content/243/4890/489},
	urldate = {2014-06-01},
	volume = {243},
	year = {1989},
	bdsk-url-1 = {http://www.sciencemag.org/content/243/4890/489},
	bdsk-url-2 = {https://doi.org/10.1126/science.2643163}}

@article{adank_perceptual_2009,
	abstract = {Speakers vary their speech rate considerably during a conversation, and listeners are able to quickly adapt to these variations in speech rate. Adaptation to fast speech rates is usually measured using artificially time-compressed speech. This study examined adaptation to two types of fast speech: artificially time-compressed speech and natural fast speech. Listeners performed a speeded sentence verification task on three series of sentences: normal-speed sentences, time-compressed sentences, and natural fast sentences. Listeners were divided into two groups to evaluate the possibility of transfer of learning between the time-compressed and natural fast conditions. The first group verified the natural fast before the time-compressed sentences, while the second verified the time-compressed before the natural fast sentences. The results showed transfer of learning when the time-compressed sentences preceded the natural fast sentences, but not when natural fast sentences preceded the time-compressed sentences. The results are discussed in the framework of theories on perceptual learning. Second, listeners show adaptation to the natural fast sentences, but performance for this type of fast speech does not improve to the level of time-compressed sentences.},
	author = {Adank, Patti and Janse, Esther},
	doi = {10.1121/1.3216914},
	file = {AdankJanse_JASA09.pdf:/Users/Cecile/Zotero/storage/823D88AS/AdankJanse_JASA09.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NQV5KZR5/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Acoustics, Spectral properties, Speech, Speech analysis, Time measurement},
	month = nov,
	number = {5},
	pages = {2649--2659},
	title = {Perceptual learning of time-compressed and natural fast speech},
	url = {http://scitation.aip.org/content/asa/journal/jasa/126/5/10.1121/1.3216914},
	urldate = {2014-10-21},
	volume = {126},
	year = {2009},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/126/5/10.1121/1.3216914},
	bdsk-url-2 = {https://doi.org/10.1121/1.3216914}}

@article{rankin_fractal_2014,
	abstract = {1/f serial correlations and statistical self-similarity (fractal structure) have been measured in various dimensions of musical compositions. Musical performances also display 1/f properties in expressive tempo fluctuations, and listeners predict tempo changes when synchronizing. Here the authors show that the 1/f structure is sufficient for listeners to predict the onset times of upcoming musical events. These results reveal what information listeners use to anticipate events in complex, non-isochronous acoustic rhythms, and this will entail innovative models of temporal synchronization. This finding could improve therapies for Parkinson\&apos;s and related disorders and inform deeper understanding of how endogenous neural rhythms anticipate events in complex, temporally structured communication signals.},
	author = {Rankin, Summer K. and Fink, Philip W. and Large, Edward W.},
	doi = {10.1121/1.4890198},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CM6ASTSW/Rankin et al. - 2014 - Fractal structure enables temporal prediction in m.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZM9APUJ5/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Acoustic modeling, Fractals, Musical analysis, Pitch, Time series analysis},
	month = oct,
	number = {4},
	pages = {EL256--EL262},
	title = {Fractal structure enables temporal prediction in music},
	url = {http://scitation.aip.org/content/asa/journal/jasa/136/4/10.1121/1.4890198},
	urldate = {2014-10-31},
	volume = {136},
	year = {2014},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/136/4/10.1121/1.4890198},
	bdsk-url-2 = {https://doi.org/10.1121/1.4890198}}

@article{carruthers_emergence_2015,
	author = {Carruthers, Isaac M. and Laplagne, Diego A. and Jaegle, Andrew and Briguglio, John and Mwilambwe-Tshilobo, Laetitia and Natan, Ryan G. and Geffen, Maria Neimark},
	doi = {10.1152/jn.00095.2015},
	file = {2726.full.pdf:/Users/Cecile/Zotero/storage/BRZ55V79/2726.full.pdf:application/pdf;Carruthers2015_Figures.pdf:/Users/Cecile/Zotero/storage/737CUTBZ/Carruthers2015_Figures.pdf:application/pdf},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = aug,
	pages = {jn.00095.2015},
	title = {Emergence of invariant representation of vocalizations in the auditory cortex.},
	url = {http://jn.physiology.org.gate1.inist.fr/lens/jn/114/5/2726},
	urldate = {2016-01-13},
	year = {2015},
	bdsk-url-1 = {http://jn.physiology.org.gate1.inist.fr/lens/jn/114/5/2726},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00095.2015}}

@article{leong_infant-directed_2014,
	author = {Leong, Victoria and Kalashnikova, Marina and Burnham, Denis and Goswami, Usha},
	file = {Leongetal2014.pdf:/Users/Cecile/Zotero/storage/JEI6SZIQ/Leongetal2014.pdf:application/pdf},
	journal = {Int Speech Commun Assoc},
	pages = {2563--7},
	title = {Infant-directed speech enhances temporal rhythmic structure in the envelope},
	url = {http://mazsola.iit.uni-miskolc.hu/~czap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140053.PDF},
	urldate = {2015-10-02},
	volume = {2014},
	year = {2014},
	bdsk-url-1 = {http://mazsola.iit.uni-miskolc.hu/~czap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140053.PDF}}

@article{homae_neural_2014,
	abstract = {Infants often pay special attention to speech sounds, and they appear to detect key features of these sounds. To investigate the neural foundation of speech perception in infants, we measured cortical activation using near-infrared spectroscopy. We presented the following three types of auditory stimuli while 3-month-old infants watched a silent movie: (1) normal speech sounds; (2) sine wave speech (SWS) sounds consisting of three sine waves that tracked the first, second, and third formants of speech sounds; and (3) synthesized tones composed of three pure tones. Statistical analyses of oxygenated hemoglobin (oxy-Hb) signals revealed significant activation in the left and right auditory areas in all conditions. Direct comparisons of oxy-Hb signal changes between SWS and synthesized tones showed significant differences in the left frontal and temporal regions. Furthermore, comparisons of oxy-Hb signal changes between speech sounds and SWS exhibited significant differences in a left posterior temporal region. These results demonstrated that functional differentiation occurs in the left temporal cortex while infants perceive different types of auditory information. Coactivation of the left temporal and frontal regions by speech sounds suggests the initial formation of a left fronto-temporal network related to infant speech processing. Clarification of the functional role of this left-lateralized network will help understand the speech code.},
	author = {Homae, Fumitaka and Watanabe, Hama and Taga, Gentaro},
	copyright = {{\copyright} 2014 Language Learning Research Club, University of Michigan},
	doi = {10.1111/lang.12076},
	file = {homae14.pdf:/Users/Cecile/Zotero/storage/CXMVXRSW/homae14.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2ATGI3NU/abstract.html:text/html},
	issn = {1467-9922},
	journal = {Language Learning},
	keywords = {Functional connectivity, NIRS, developing brain, formant, functional differentiation, language acquisition, language network, speech sounds},
	language = {en},
	month = sep,
	number = {s2},
	pages = {6--26},
	title = {The {Neural} {Substrates} of {Infant} {Speech} {Perception}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/lang.12076/abstract},
	urldate = {2014-09-06},
	volume = {64},
	year = {2014},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/lang.12076/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/lang.12076}}

@article{bennur_understanding_2013,
	abstract = {Acoustic communication between animals requires them to detect, discriminate, and categorize conspecific or heterospecific vocalizations in their natural environment. Laboratory studies of the auditory-processing abilities that facilitate these tasks have typically employed a broad range of acoustic stimuli, ranging from natural sounds like vocalizations to ``artificial'' sounds like pure tones and noise bursts. However, even when using vocalizations, laboratory studies often test abilities like categorization in relatively artificial contexts. Consequently, it is not clear whether neural and behavioral correlates of these tasks (1) reflect extensive operant training, which drives plastic changes in auditory pathways, or (2) the innate capacity of the animal and its auditory system. Here, we review a number of recent studies, which suggest that adopting more ethological paradigms utilizing natural communication contexts are scientifically important for elucidating how the auditory system normally processes and learns communication sounds. Additionally, since learning the meaning of communication sounds generally involves social interactions that engage neuromodulatory systems differently than laboratory-based conditioning paradigms, we argue that scientists need to pursue more ethological approaches to more fully inform our understanding of how the auditory system is engaged during acoustic communication.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	author = {Bennur, Sharath and Tsunada, Joji and Cohen, Yale E. and Liu, Robert C.},
	doi = {10.1016/j.heares.2013.08.008},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PWUI4ZPM/Bennur et al. - 2013 - Understanding the neurophysiological basis of audi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/39GTTUPF/S0378595513001998.html:text/html;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/39C47Z3N/S0378595513001998.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/ZMWBMEIC/Bennur et al. - 2013 - Understanding the neurophysiological basis of audi.pdf:application/pdf},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = nov,
	pages = {3--9},
	series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	shorttitle = {Understanding the neurophysiological basis of auditory abilities for social communication},
	title = {Understanding the neurophysiological basis of auditory abilities for social communication: {A} perspective on the value of ethological paradigms},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	urldate = {2014-10-31},
	volume = {305},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.08.008}}

@article{dupoux_perceptual_1997,
	abstract = {This study investigated the perceptual adjustments that occur when listeners recognize highly compressed speech. In Experiment 1, adjustment was examined as a function of the amount of exposure to compressed speech by use of 2 different speakers and compression rates. The results demonstrated that adjustment takes place over a number of sentences, depending on the compression rate. Lower compression rates required less experience before full adjustment occurred. In Experiment 2, the impact of an abrupt change in talker characteristics was investigated; in Experiment 3, the impact of an abrupt change in compression rate was studied. The results of these 2 experiments indicated that sudden changes in talker characteristics or compression rate had little impact on the adjustment process. The findings are discussed with respect to the level of speech processing at which such adjustment might occur.},
	author = {Dupoux, Emmanuel and Green, Kerry},
	copyright = {(c) 2012 APA, all rights reserved},
	doi = {10.1037/0096-1523.23.3.914},
	file = {Dupoux_Green_1997_adaptation_speech_compression.JEPHPP.pdf:/Users/Cecile/Zotero/storage/ZJ28JZWI/Dupoux_Green_1997_adaptation_speech_compression.JEPHPP.pdf:application/pdf},
	issn = {1939-1277(Electronic);0096-1523(Print)},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	keywords = {*Compressed Speech, *Speech Characteristics, *Speech Perception, Verbal Stimuli},
	number = {3},
	pages = {914--927},
	shorttitle = {Perceptual adjustment to highly compressed speech},
	title = {Perceptual adjustment to highly compressed speech: {Effects} of talker and rate changes},
	volume = {23},
	year = {1997},
	bdsk-url-1 = {https://doi.org/10.1037/0096-1523.23.3.914}}

@article{ghitza_linking_2011,
	abstract = {The premise of this study is that current models of speech perception, which are driven by acoustic features alone, are incomplete, and that the role of decoding time during memory access must be incorporated to account for the patterns of observed recognition phenomena. It is postulated that decoding time is governed by a cascade of neuronal oscillators, which guide template-matching operations at a hierarchy of temporal scales. Cascaded cortical oscillations in the theta, beta, and gamma frequency bands are argued to be crucial for speech intelligibility. Intelligibility is high so long as these oscillations remain phase locked to the auditory input rhythm. A model (Tempo) is presented which is capable of emulating recent psychophysical data on the intelligibility of speech sentences as a function of ``packaging'' rate (Ghitza and Greenberg, ). The data show that intelligibility of speech that is time-compressed by a factor of 3 (i.e., a high syllabic rate) is poor (above 50\% word error rate), but is substantially restored when the information stream is re-packaged by the insertion of silent gaps in between successive compressed-signal intervals -- a counterintuitive finding, difficult to explain using classical models of speech perception, but emerging naturally from the Tempo architecture.},
	author = {Ghitza, Oded},
	doi = {10.3389/fpsyg.2011.00130},
	file = {Ghitza_11.pdf:/Users/Cecile/Zotero/storage/NI8RNPK9/Ghitza_11.pdf:application/pdf;PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/HMSWWZMC/Ghitza - 2011 - Linking Speech Perception and Neurophysiology Spe.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	month = jun,
	pmcid = {PMC3127251},
	pmid = {21743809},
	shorttitle = {Linking {Speech} {Perception} and {Neurophysiology}},
	title = {Linking {Speech} {Perception} and {Neurophysiology}: {Speech} {Decoding} {Guided} by {Cascaded} {Oscillators} {Locked} to the {Input} {Rhythm}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3127251/},
	urldate = {2014-10-21},
	volume = {2},
	year = {2011},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3127251/},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2011.00130}}

@article{hutt_auditory_1968,
	author = {Hutt, S. J. and Hutt, Corinne and Lenard, H. G. and Bernuth, H. V. and Muntjewerff, W. J.},
	copyright = {{\copyright} 1968 Nature Publishing Group},
	doi = {10.1038/218888a0},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/J23JBV2M/Hutt et al. - 1968 - Auditory Responsivity in the Human Neonate.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K4TDPU33/218888a0.html:text/html},
	journal = {Nature},
	language = {en},
	month = jun,
	number = {5144},
	pages = {888--890},
	title = {Auditory {Responsivity} in the {Human} {Neonate}},
	url = {http://www.nature.com/nature/journal/v218/n5144/abs/218888a0.html},
	urldate = {2015-01-07},
	volume = {218},
	year = {1968},
	bdsk-url-1 = {http://www.nature.com/nature/journal/v218/n5144/abs/218888a0.html},
	bdsk-url-2 = {https://doi.org/10.1038/218888a0}}

@article{vagharchakian_temporal_2012,
	abstract = {Humans can understand spoken or written sentences presented at extremely fast rates of ∼400 wpm, far exceeding the normal speech rate (∼150 wpm). How does the brain cope with speeded language? And what processing bottlenecks eventually make language incomprehensible above a certain presentation rate? We used time-resolved fMRI to probe the brain responses to spoken and written sentences presented at five compression rates, ranging from intelligible (60--100\% of the natural duration) to challenging (40\%) and unintelligible (20\%). The results show that cortical areas differ sharply in their activation speed and amplitude. In modality-specific sensory areas, activation varies linearly with stimulus duration. However, a large modality-independent left-hemispheric language network, including the inferior frontal gyrus (pars orbitalis and triangularis) and the superior temporal sulcus, shows a remarkably time-invariant response, followed by a sudden collapse for unintelligible stimuli. Finally, linear and nonlinear responses, reflecting a greater effort as compression increases, are seen at various prefrontal and parietal sites. We show that these profiles fit with a simple model according to which the higher stages of language processing operate at a fixed speed and thus impose a temporal bottleneck on sentence comprehension. At presentation rates faster than this internal processing speed, incoming words must be buffered, and intelligibility vanishes when buffer storage and retrieval operations are saturated. Based on their temporal and amplitude profiles, buffer regions can be identified with the left inferior frontal/anterior insula, precentral cortex, and mesial frontal cortex.},
	author = {Vagharchakian, Laurianne and Dehaene-Lambertz, Ghislaine and Pallier, Christophe and Dehaene, Stanislas},
	doi = {10.1523/JNEUROSCI.5685-11.2012},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/TK6HHAF7/Vagharchakian et al. - 2012 - A Temporal Bottleneck in the Language Comprehensio.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HDG7TU3K/9089.html:text/html;Vagharchakianetal2012.pdf:/Users/Cecile/Zotero/storage/DB7T2W77/Vagharchakianetal2012.pdf:application/pdf},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = jun,
	number = {26},
	pages = {9089--9102},
	pmid = {22745508},
	title = {A {Temporal} {Bottleneck} in the {Language} {Comprehension} {Network}},
	url = {http://www.jneurosci.org/content/32/26/9089},
	urldate = {2015-07-13},
	volume = {32},
	year = {2012},
	bdsk-url-1 = {http://www.jneurosci.org/content/32/26/9089},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.5685-11.2012}}

@article{arnal_human_2015,
	abstract = {Screaming is arguably one of the most relevant communication signals for survival in humans. Despite their practical relevance and their theoretical significance as innate [ 1 ] and virtually universal [ 2, 3 ] vocalizations, what makes screams a unique signal and how they are processed is not known. Here, we use acoustic analyses, psychophysical experiments, and neuroimaging to isolate those features that confer to screams their alarming nature, and we track their processing in the human brain. Using the modulation power spectrum (MPS [ 4, 5 ]), a recently developed, neurally informed characterization of sounds, we demonstrate that human screams cluster within restricted portion of the acoustic space (between ∼30 and 150 Hz modulation rates) that corresponds to a well-known perceptual attribute, roughness. In contrast to the received view that roughness is irrelevant for communication [ 6 ], our data reveal that the acoustic space occupied by the rough vocal regime is segregated from other signals, including speech, a pre-requisite to avoid false alarms in normal vocal communication. We show that roughness is present in natural alarm signals as well as in artificial alarms and that the presence of roughness in sounds boosts their detection in various tasks. Using fMRI, we show that acoustic roughness engages subcortical structures critical to rapidly appraise danger. Altogether, these data demonstrate that screams occupy a privileged acoustic niche that, being separated from other communication signals, ensures their biological and ultimately social efficiency.},
	author = {Arnal, Luc H. and Flinker, Adeen and Kleinschmidt, Andreas and Giraud, Anne-Lise and Poeppel, David},
	doi = {10.1016/j.cub.2015.06.043},
	file = {Arnal et al. Current Biology 15+SM.pdf:/Users/Cecile/Zotero/storage/IEVCC2EJ/Arnal et al. Current Biology 15+SM.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/FEIB9UWN/S0960-9822(15)00737-X.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	language = {English},
	month = aug,
	number = {15},
	pages = {2051--2056},
	pmid = {26190070},
	title = {Human {Screams} {Occupy} a {Privileged} {Niche} in the {Communication} {Soundscape}},
	url = {http://www.cell.com/article/S096098221500737X/abstract},
	urldate = {2015-10-22},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {http://www.cell.com/article/S096098221500737X/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.06.043}}

@article{norman-haignere_distinct_2015,
	abstract = {The organization of human auditory cortex remains unresolved, due in part to the small stimulus sets common to fMRI studies and the overlap of neural populations within voxels. To address these challenges, we measured fMRI responses to 165 natural sounds and inferred canonical response profiles (``components'') whose weighted combinations explained voxel responses throughout auditory cortex. This analysis revealed six components, each with interpretable response characteristics despite being unconstrained by prior functional hypotheses. Four components embodied selectivity for particular acoustic features (frequency, spectrotemporal modulation, pitch). Two others exhibited pronounced selectivity for music and speech, respectively, and were not explainable by standard acoustic features. Anatomically, music and speech selectivity concentrated in distinct regions of non-primary auditory cortex. However, music selectivity was weak in raw voxel responses, and its detection required a decomposition method. Voxel decomposition identifies primary dimensions of response variation across natural sounds, revealing distinct cortical pathways for music and speech.},
	author = {Norman-Haignere, Sam V. and Kanwisher, Nancy G. and McDermott, Josh H.},
	doi = {10.1016/j.neuron.2015.11.035},
	file = {Norman-Haignere_Kanwisher_McDermott_2015.pdf:/Users/Cecile/Zotero/storage/IAARZS3M/Norman-Haignere_Kanwisher_McDermott_2015.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DJPAUPVV/S0896-6273(15)01071-5.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	language = {English},
	month = dec,
	number = {6},
	pages = {1281--1296},
	title = {Distinct {Cortical} {Pathways} for {Music} and {Speech} {Revealed} by {Hypothesis}-{Free} {Voxel} {Decomposition}},
	url = {http://www.cell.com/article/S0896627315010715/abstract},
	urldate = {2016-02-19},
	volume = {88},
	year = {2015},
	bdsk-url-1 = {http://www.cell.com/article/S0896627315010715/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2015.11.035}}

@misc{noauthor_four-month-old_nodate,
	file = {Four-month-old infants prefer to listen to motherese:/Users/Cecile/Zotero/storage/2WBEP55J/S0163638385800059.html:text/html},
	title = {Four-month-old infants prefer to listen to motherese},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059},
	urldate = {2014-09-06},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059}}

@article{scholkmann_general_2013,
	abstract = {Abstract. 
Continuous-wave near-infrared spectroscopy and near-infrared imaging enable the measurement of relative concentration changes in oxy- and deoxyhemoglobin and thus hemodynamics and oxygenation. The accuracy of determined changes depends mainly on the modeling of the light transport through the probed tissue. Due to the highly scattering nature of tissue, the light path is longer than the source--detector separation (d). This is incorporated in modeling by multiplying d by a differential pathlength factor (DPF) which depends on several factors such as wavelength, age of the subject, and type of tissue. In the present work, we derive a general DPF equation for the frontal human head, incorporating dependency on wavelength and age, based on published data. We validated the equation using different data sets of experimentally determined DPFs from six independent studies.},
	author = {Scholkmann, Felix and Wolf, Martin},
	doi = {10.1117/1.JBO.18.10.105004},
	issn = {1083-3668},
	journal = {Journal of Biomedical Optics},
	number = {10},
	pages = {105004--105004},
	title = {General equation for the differential pathlength factor of the frontal human head depending on wavelength and age},
	url = {http://dx.doi.org/10.1117/1.JBO.18.10.105004},
	urldate = {2017-02-27},
	volume = {18},
	year = {2013},
	bdsk-url-1 = {http://dx.doi.org/10.1117/1.JBO.18.10.105004}}

@article{remez_speech_1981,
	author = {Remez, R. E. and Rubin, P. E. and Pisoni, D. B. and Carrell, T. D.},
	doi = {10.1126/science.7233191},
	file = {Snapshot:/Users/Cecile/Zotero/storage/C6RPHZ3U/947.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = may,
	number = {4497},
	pages = {947--949},
	pmid = {7233191},
	title = {Speech perception without traditional speech cues},
	url = {http://www.sciencemag.org/content/212/4497/947},
	urldate = {2014-04-09},
	volume = {212},
	year = {1981},
	bdsk-url-1 = {http://www.sciencemag.org/content/212/4497/947},
	bdsk-url-2 = {https://doi.org/10.1126/science.7233191}}

@article{peelle_dissociable_2004,
	author = {Peelle, Jonathan E. and McMillan, Corey and Moore, Peachie and Grossman, Murray and Wingfield, Arthur},
	doi = {10.1016/j.bandl.2004.05.007},
	file = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech\: Evidence from fMRI:/Users/Cecile/Zotero/storage/DEJSBBPS/S0093934X04000781.html:text/html},
	issn = {0093934X},
	journal = {Brain and Language},
	month = dec,
	number = {3},
	pages = {315--325},
	shorttitle = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech},
	title = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech: {Evidence} from {fMRI}},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0093934X04000781},
	urldate = {2013-10-02},
	volume = {91},
	year = {2004},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0093934X04000781},
	bdsk-url-2 = {https://doi.org/10.1016/j.bandl.2004.05.007}}

@article{foulke_review_1969,
	abstract = {Time-compressed or accelerated speech is speech which has been reproduced in less than the original production time. Such speech may prove to be useful in a variety of situations in which people must rely upon listening to obtain the information specified by language. It may also prove to be a useful tool in studying the temporal requirements of the listener as he processes spoken language. Methods for the generation of time compressed speech are reviewed. Methods for the assessment of the effect of compression on word intelligibility and listening comprehension are discussed. Experiments dealing with the effect of time compression upon word intelligibility and upon the comprehensibility of connected discourse, and experiments concerned with the influence of stimulus variables, such as signal distortion, and organismic variables such as intelligence, are reviewed. The general finding that compression in time has a different effect upon the comprehensibility of connected discourse than upon word intelligibility is discussed, and a tentative explanation of this difference is offered. (63 ref.) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	author = {Foulke, Emerson and Sticht, Thomas G.},
	doi = {10.1037/h0027575},
	file = {EBSCO Full Text:/Users/Cecile/Zotero/storage/GEBIJV6G/Foulke et Sticht - 1969 - Review of research on the intelligibility and comp.pdf:application/pdf},
	issn = {0033-2909},
	journal = {Psychological Bulletin},
	keywords = {Auditory Discrimination, Experimentation, Literature Review, Thinking, intelligibility \& comprehension of accelerated speech, review of research, speech perception, Speech Perception},
	month = jul,
	number = {1},
	pages = {50--62},
	title = {Review of research on the intelligibility and comprehension of accelerated speech},
	url = {https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1969-12922-001&lang=fr&site=ehost-live},
	urldate = {2013-10-17},
	volume = {72},
	year = {1969},
	bdsk-url-1 = {https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1969-12922-001&lang=fr&site=ehost-live},
	bdsk-url-2 = {https://doi.org/10.1037/h0027575}}

@article{theunissen_neural_2014,
	abstract = {We might be forced to listen to a high-frequency tone at our audiologist's office or we might enjoy falling asleep with a white-noise machine, but the sounds that really matter to us are the voices of our companions or music from our favourite radio station. The auditory system has evolved to process behaviourally relevant natural sounds. Research has shown not only that our brain is optimized for natural hearing tasks but also that using natural sounds to probe the auditory system is the best way to understand the neural computations that enable us to comprehend speech or appreciate music.
View full text},
	author = {Theunissen, Fr{\'e}d{\'e}ric E. and Elie, Julie E.},
	copyright = {{\copyright} 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nrn3731},
	file = {Snapshot:/Users/Cecile/Zotero/storage/TCE3J5NV/nrn3731.html:text/html;Theunissen et Elie - 2014 - Neural processing of natural sounds.pdf:/Users/Cecile/Zotero/storage/4KBS7HRF/Theunissen et Elie - 2014 - Neural processing of natural sounds.pdf:application/pdf},
	issn = {1471-003X},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = jun,
	number = {6},
	pages = {355--366},
	title = {Neural processing of natural sounds},
	url = {http://www.nature.com/nrn/journal/v15/n6/abs/nrn3731.html},
	urldate = {2014-05-26},
	volume = {15},
	year = {2014},
	bdsk-url-1 = {http://www.nature.com/nrn/journal/v15/n6/abs/nrn3731.html},
	bdsk-url-2 = {https://doi.org/10.1038/nrn3731}}

@article{ghitza_neuronal_2013,
	abstract = {A recent opinion article (Neural oscillations in speech: do not be enslaved by the envelope. Obleser et al., ) questions the validity of a class of speech perception models inspired by the possible role of neuronal oscillations in decoding speech (e.g., Ghitza, ; Giraud and Poeppel, ). The authors criticize, in particular, what they see as an over-emphasis of the role of temporal speech envelope information, and an over-emphasis of entrainment to the input rhythm while neglecting the role of top-down processes in modulating the entrainment of neuronal oscillations. Here we respond to these arguments, referring to the phenomenological model of Ghitza (), taken as a representative of the criticized approach.},
	author = {Ghitza, Oded and Giraud, Anne-Lise and Poeppel, David},
	doi = {10.3389/fnhum.2012.00340},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Z7QI5S8V/Ghitza et al. - 2013 - Neuronal oscillations and speech perception criti.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = jan,
	pmcid = {PMC3539830},
	pmid = {23316150},
	shorttitle = {Neuronal oscillations and speech perception},
	title = {Neuronal oscillations and speech perception: critical-band temporal envelopes are the essence},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3539830/},
	urldate = {2014-10-31},
	volume = {6},
	year = {2013},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3539830/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2012.00340}}

@article{minagawa-kawai_optical_2011,
	abstract = {This study uses near-infrared spectroscopy in young infants in order to elucidate the nature of functional cerebral processing for speech. Previous imaging studies of infants' speech perception revealed left-lateralized responses to native language. However, it is unclear if these activations were due to language per se rather than to some low-level acoustic correlate of spoken language. Here we compare native (L1) and non-native (L2) languages with 3 different nonspeech conditions including emotional voices, monkey calls, and phase scrambled sounds that provide more stringent controls. Hemodynamic responses to these stimuli were measured in the temporal areas of Japanese 4 month-olds. The results show clear left-lateralized responses to speech, prominently to L1, as opposed to various activation patterns in the nonspeech conditions. Furthermore, implementing a new analysis method designed for infants, we discovered a slower hemodynamic time course in awake infants. Our results are largely explained by signal-driven auditory processing. However, stronger activations to L1 than to L2 indicate a language-specific neural factor that modulates these responses. This study is the first to discover a significantly higher sensitivity to L1 in 4 month-olds and reveals a neural precursor of the functional specialization for the higher cognitive network.},
	author = {Minagawa-Kawai, Yasuyo and van der Lely, Heather and Ramus, Franck and Sato, Yutaka and Mazuka, Reiko and Dupoux, Emmanuel},
	doi = {10.1093/cercor/bhq082},
	issn = {1460-2199},
	journal = {Cerebral cortex (New York, N.Y.: 1991)},
	keywords = {Acoustic Stimulation, Brain Mapping, Child Development, Emotions, Female, Functional Laterality, Hemoglobins, Humans, Infant, Male, Numerical Analysis, Computer-Assisted, Reaction Time, Spectroscopy, Near-Infrared, Temporal Lobe, Time Factors, language, speech perception, Speech Perception},
	language = {eng},
	month = feb,
	number = {2},
	pages = {254--261},
	pmid = {20497946},
	title = {Optical brain imaging reveals general auditory and language-specific processing in early infant development},
	volume = {21},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1093/cercor/bhq082}}

@article{winkler_newborn_2009,
	abstract = {To shed light on how humans can learn to understand music, we need to discover what the perceptual capabilities with which infants are born. Beat induction, the detection of a regular pulse in an auditory signal, is considered a fundamental human trait that, arguably, played a decisive role in the origin of music. Theorists are divided on the issue whether this ability is innate or learned. We show that newborn infants develop expectation for the onset of rhythmic cycles (the downbeat), even when it is not marked by stress or other distinguishing spectral features. Omitting the downbeat elicits brain activity associated with violating sensory expectations. Thus, our results strongly support the view that beat perception is innate.},
	author = {Winkler, Istv{\'a}n and H{\'a}den, G{\'a}bor P. and Ladinig, Olivia and Sziller, Istv{\'a}n and Honing, Henkjan},
	doi = {10.1073/pnas.0809035106},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Q7QEBGWQ/Winkler et al. - 2009 - Newborn infants detect the beat in music.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9MQ38THX/0809035106.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {Rhythm, event-related brain potentials (ERP), neonates},
	language = {en},
	month = jan,
	pages = {pnas.0809035106},
	pmid = {19171894},
	title = {Newborn infants detect the beat in music},
	url = {http://www.pnas.org/content/early/2009/01/26/0809035106},
	urldate = {2016-03-14},
	year = {2009},
	bdsk-url-1 = {http://www.pnas.org/content/early/2009/01/26/0809035106},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0809035106}}

@article{adank_-line_2010,
	abstract = {Listeners show remarkable flexibility in processing variation in speech signal. One striking example is the ease with which they adapt to novel speech distortions such as listening to someone with a foreign accent. Behavioural studies suggest that significant improvements in comprehension occur rapidly --- often within 10--20 sentences. In the present experiment, we investigate the neural changes underlying on-line adaptation to distorted speech using time-compressed speech. Listeners performed a sentence verification task on normal-speed and time-compressed sentences while their neural responses were recorded using fMRI. The results showed that rapid learning of the time-compressed speech occurred during presentation of the first block of 16 sentences and was associated with increased activation in left and right auditory association cortices and in left ventral premotor cortex. These findings suggest that the ability to adapt to a distorted speech signal may, in part, rely on mapping novel acoustic patterns onto existing articulatory motor plans, consistent with the idea that speech perception involves integrating multi-modal information including auditory and motoric cues.},
	author = {Adank, Patti and Devlin, Joseph T.},
	doi = {10.1016/j.neuroimage.2009.07.032},
	issn = {1053-8119},
	journal = {Neuroimage},
	month = jan,
	number = {1},
	pages = {1124--1132},
	pmcid = {PMC2775905},
	pmid = {19632341},
	shorttitle = {On-line plasticity in spoken sentence comprehension},
	title = {On-line plasticity in spoken sentence comprehension: {Adapting} to time-compressed speech},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775905/},
	urldate = {2014-01-20},
	volume = {49},
	year = {2010},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775905/},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2009.07.032}}

@article{ahissar_speech_2001,
	abstract = {Speech comprehension depends on the integrity of both the spectral content and temporal envelope of the speech signal. Although neural processing underlying spectral analysis has been intensively studied, less is known about the processing of temporal information. Most of speech information conveyed by the temporal envelope is confined to frequencies below 16 Hz, frequencies that roughly match spontaneous and evoked modulation rates of primary auditory cortex neurons. To test the importance of cortical modulation rates for speech processing, we manipulated the frequency of the temporal envelope of speech sentences and tested the effect on both speech comprehension and cortical activity. Magnetoencephalographic signals from the auditory cortices of human subjects were recorded while they were performing a speech comprehension task. The test sentences used in this task were compressed in time. Speech comprehension was degraded when sentence stimuli were presented in more rapid (more compressed) forms. We found that the average comprehension level, at each compression, correlated with (i) the similarity between the frequencies of the temporal envelopes of the stimulus and the subject's cortical activity (``stimulus-cortex frequency-matching'') and (ii) the phase-locking (PL) between the two temporal envelopes (``stimulus-cortex PL''). Of these two correlates, PL was significantly more indicative for single-trial success. Our results suggest that the match between the speech rate and the a priori modulation capacities of the auditory cortex is a prerequisite for comprehension. However, this is not sufficient: stimulus-cortex PL should be achieved during actual sentence presentation.},
	author = {Ahissar, Ehud and Nagarajan, Srikantan and Ahissar, Merav and Protopapas, Athanassios and Mahncke, Henry and Merzenich, Michael M.},
	doi = {10.1073/pnas.201400998},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/HUZW8ESF/pq013367.pdf:application/pdf},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	month = nov,
	number = {23},
	pages = {13367--13372},
	pmcid = {PMC60877},
	pmid = {11698688},
	title = {Speech comprehension is correlated with temporal response patterns recorded from auditory cortex},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC60877/},
	urldate = {2014-10-21},
	volume = {98},
	year = {2001},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC60877/},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.201400998}}

@article{matsui_referential_2014,
	abstract = {Functional near infrared spectroscopy (fNIRS), which is compact, portable, and tolerant of body movement, is suitable for monitoring infant brain functions. Nevertheless, fNIRS also poses a technical problem in that it cannot provide structural information. Supplementation with structural magnetic resonance images (MRI) is not always feasible for infants who undergo fNIRS measurement. Probabilistic registration methods using an MRI database instead of subjects' own MRIs are optimized for adult studies and offer only limited resources for infant studies. To overcome this, we used high-quality infant MRI data for a 12-month-old infant and manually delineated segmented gyri from among the highly visible macroanatomies on the lateral cortical surface. These macroanatomical regions are primarily linked to the spherical coordinate system based on external cranial landmarks, and further to traditional 10-20-based head-surface positioning systems. While macroanatomical structures were generally comparable between adult and infant atlases, differences were found in the parietal lobe, which was positioned posteriorly at the vertex in the infant brain. The present study provides a referential framework for macroanatomical analyses in infant fNIRS studies. With this resource, multichannel fNIRS functional data could be analyzed in reference to macroanatomical structures through virtual and probabilistic registrations without acquiring subject-specific MRIs.},
	author = {Matsui, Mie and Homae, Fumitaka and Tsuzuki, Daisuke and Watanabe, Hama and Katagiri, Masatoshi and Uda, Satoshi and Nakashima, Mitsuhiro and Dan, Ippeita and Taga, Gentaro},
	doi = {10.1016/j.neures.2014.01.003},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RFK66AEA/Matsui et al. - 2014 - Referential framework for transcranial anatomical .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2PSGZMXS/S0168010214000042.html:text/html},
	issn = {0168-0102},
	journal = {Neuroscience Research},
	keywords = {Baby, Manual tracing, Optical topography, Parcellation, Sulcus, Transcranial neuroimaging},
	month = mar,
	pages = {55--68},
	title = {Referential framework for transcranial anatomical correspondence for {fNIRS} based on manually traced sulci and gyri of an infant brain},
	url = {http://www.sciencedirect.com/science/article/pii/S0168010214000042},
	urldate = {2015-01-28},
	volume = {80},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010214000042},
	bdsk-url-2 = {https://doi.org/10.1016/j.neures.2014.01.003}}

@article{remez_perceptual_1994,
	abstract = {A general account of auditory perceptual organization has developed in the past 2 decades. It relies on primitive devices akin to the Gestalt principles of organization to assign sensory elements to probable groupings and invokes secondary schematic processes to confirm or to repair the possible organization. Although this conceptualization is intended to apply universally, the variety and arrangement of acoustic constituents of speech violate Gestalt principles at numerous junctures, cohering perceptually, nonetheless. The authors report 3 experiments on organization in phonetic perception, using sine wave synthesis to evade the Gestalt rules and the schematic processes alike. These findings falsify a general auditory account, showing that phonetic perceptual organization is achieved by specific sensitivity to the acoustic modulations characteristic of speech signals.},
	author = {Remez, R. E. and Rubin, P. E. and Berns, S. M. and Pardo, J. S. and Lang, J. M.},
	issn = {0033-295X},
	journal = {Psychological Review},
	keywords = {Adult, Attention, Female, Gestalt Theory, Humans, Male, Phonetics, Psychoacoustics, Sound Spectrography, speech perception, Speech Perception},
	language = {eng},
	month = jan,
	number = {1},
	pages = {129--156},
	pmid = {8121955},
	title = {On the perceptual organization of speech},
	volume = {101},
	year = {1994}}

@article{poldrack_relations_2001,
	abstract = {Functional magnetic resonance imaging (fMRI) was used to examine how the brain responds to temporal compression of speech and to determine whether the same regions are also involved in phonological processes associated with reading. Recorded speech was temporally compressed to varying degrees and presented in a sentence verification task. Regions involved in phonological processing were identified in a separate scan using a rhyming judgment task with pseudowords compared to a lettercase judgment task. The left inferior frontal and left superior temporal regions (Broca's and Wernicke's areas), along with the right inferior frontal cortex, demonstrated a convex response to speech compression; their activity increased as compression increased, but then decreased when speech became incomprehensible. Other regions exhibited linear increases in activity as compression increased, including the middle frontal gyri bilaterally. The auditory cortices exhibited compression-related decreases bilaterally, primarily reflecting a decrease in activity when speech became incomprehensible. Rhyme judgments engaged two left inferior frontal gyrus regions (pars triangularis and pars opercularis), of which only the pars triangularis region exhibited significant compression-related activity. These results directly demonstrate that a subset of the left inferior frontal regions involved in phonological processing is also sensitive to transient acoustic features within the range of comprehensible speech.},
	author = {Poldrack, R. A. and Temple, E. and Protopapas, A. and Nagarajan, S. and Tallal, P. and Merzenich, M. and Gabrieli, J. D.},
	doi = {10.1162/089892901750363235},
	issn = {0898-929X},
	journal = {Journal of Cognitive Neuroscience},
	keywords = {Adult, Auditory Perception, Mental Processes, Periodicity, Brain Mapping, Female, Humans, Male, Phonetics, Sound, Time Factors, Brain},
	language = {eng},
	month = jul,
	number = {5},
	pages = {687--697},
	pmid = {11506664},
	shorttitle = {Relations between the neural bases of dynamic auditory processing and phonological processing},
	title = {Relations between the neural bases of dynamic auditory processing and phonological processing: evidence from {fMRI}},
	volume = {13},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1162/089892901750363235}}

@article{schneider_sparse_2013,
	abstract = {Vocal communicators such as humans and songbirds readily recognize individual vocalizations, even in distracting auditory environments. This perceptual ability is likely subserved by auditory neurons whose spiking responses to individual vocalizations are minimally affected by background sounds. However, auditory neurons that produce background-invariant responses to vocalizations in auditory scenes have not been found. Here, we describe a population of neurons in the zebra finch auditory cortex that represent vocalizations with a sparse code and that maintain their vocalization-like firing patterns in levels of background sound that permit behavioral recognition. These same neurons decrease or stop spiking in levels of background sound that preclude behavioral recognition. In contrast, upstream neurons represent vocalizations with dense and background-corrupted responses. We provide experimental evidence suggesting that sparse coding is mediated by feedforward suppression. Finally, we show through simulations that feedforward inhibition can transform a dense representation of vocalizations into a sparse and background-invariant representation.},
	author = {Schneider, David M. and Woolley, Sarah M. N.},
	doi = {10.1016/j.neuron.2013.04.038},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EPQITPHS/Schneider et Woolley - 2013 - Sparse and Background-Invariant Coding of Vocaliza.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RNS3BIVG/S0896627313003693.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = jul,
	number = {1},
	pages = {141--152},
	title = {Sparse and {Background}-{Invariant} {Coding} of {Vocalizations} in {Auditory} {Scenes}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627313003693},
	urldate = {2015-09-30},
	volume = {79},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313003693},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2013.04.038}}

@article{wang_representation_1995,
	abstract = {1. The temporal and spectral characteristics of neural representations of a behaviorally important species-specific vocalization were studied in neuronal populations of the primary auditory cortex (A1) of barbiturate-anesthetized adult common marmosets (Callithrix jacchus), using both natural and synthetic vocalizations. The natural vocalizations used in electrophysiological experiments were recorded from the animals under study or from their conspecifics. These calls were frequently produced in vocal exchanges between members of our marmoset colony and are part of the well-defined and highly stereotyped vocal repertoire of this species. 2. The spectrotemporal discharge pattern of spatially distributed neuron populations in cortical field A1 was found to be correlated with the spectrotemporal acoustic pattern of a complex natural vocalization. However, the A1 discharge pattern was not a faithful replication of the acoustic parameters of a vocalization stimulus, but had been transformed into a more abstract representation than that in the auditory periphery. 3. Subpopulations of A1 neurons were found to respond selectively to natural vocalizations as compared with synthetic variations that had the same spectral but different temporal characteristics. A subpopulation responding selectively to a given monkey's call shared some but not all of its neuronal memberships with other individual-call-specific neuronal subpopulations. 4. In the time domain, responses of individual A1 units were phase-locked to the envelope of a portion of a complex vocalization, which was centered around a unit's characteristic frequency (CF). As a whole, discharges of A1 neuronal populations were phase-locked to discrete stimulus events but not to their rapidly changing spectral contents. The consequence was a reduction in temporal complexity and an increase in cross-population response synchronization. 5. In the frequency domain, major features of the stimulus spectrum were reflected in rate-CF profiles. The spectral features of a natural call were equally or more strongly represented by a subpopulation of A1 neurons that responded selectively to that call as compared with the entire responding A1 population. 6. Neuronal responses to a complex call were distributed very widely across cortical field A1. At the same time, the responses evoked by a vocalization scattered in discrete cortical patches were strongly synchronized to stimulus events and to each other. As a result, at any given time during the course of a vocalization, a coherent representation of the integrated spectrotemporal characteristics of a particular vocalization was present in a specific neuronal population. 7. These results suggest that the representation of behaviorally important and spectrotemporally complex species-specific vocalizations in A1 is 1) temporally integrated and 2) spectrally distributed in nature, and that the representation is carried by spatially dispersed and synchronized cortical cell assemblies that correspond to each individual's vocalizations in a specific and abstracted way.},
	author = {Wang, X. and Merzenich, M. M. and Beitel, R. and Schreiner, C. E.},
	copyright = {Copyright {\copyright} 1995 the American Physiological Society},
	file = {Snapshot:/Users/Cecile/Zotero/storage/5UE8KEGG/2685.html:text/html},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = dec,
	number = {6},
	pages = {2685--2706},
	pmid = {8747224},
	shorttitle = {Representation of a species-specific vocalization in the primary auditory cortex of the common marmoset},
	title = {Representation of a species-specific vocalization in the primary auditory cortex of the common marmoset: temporal and spectral characteristics},
	url = {http://jn.physiology.org/content/74/6/2685},
	urldate = {2015-05-22},
	volume = {74},
	year = {1995},
	bdsk-url-1 = {http://jn.physiology.org/content/74/6/2685}}

@article{saliba_functional_2016,
	abstract = {Functional neuroimaging can provide insight into the neurobiological factors that contribute to the variations in individual hearing outcomes following cochlear implantation. To date, measuring neural activity within the auditory cortex of cochlear implant (CI) recipients has been challenging, primarily because the use of traditional neuroimaging techniques is limited in people with CIs. Functional near-infrared spectroscopy (fNIRS) is an emerging technology that offers benefits in this population because it is non-invasive, compatible with CI devices, and not subject to electrical artifacts. However, there are important considerations to be made when using fNIRS to maximize the signal to noise ratio and to best identify meaningful cortical responses. This review considers these issues, the current data, and future directions for using fNIRS as a clinical application in individuals with CIs.

This article is part of a Special Issue entitled \&lt;Annual Reviews 2016\&gt;.},
	author = {Saliba, Joe and Bortfeld, Heather and Levitin, Daniel J. and Oghalai, John S.},
	doi = {10.1016/j.heares.2016.02.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BFG8TJHM/Saliba et al. - 2016 - Functional near-infrared spectroscopy for neuroima.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/CTBTIGQG/S0378595515301891.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	keywords = {Cochlear implant, Hearing loss, Speech, fNIRS, neuroimaging},
	month = aug,
	pages = {64--75},
	series = {Special {Issue}: {Annual} {Reviews} 2016},
	title = {Functional near-infrared spectroscopy for neuroimaging in cochlear implant recipients},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595515301891},
	urldate = {2016-11-14},
	volume = {338},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595515301891},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2016.02.005}}

@inproceedings{attias_temporal_1997,
	abstract = {The annual conference on Neural Information Processing Systems (NIPS) is the flagshipconference on neural computation. It draws preeminent academic researchers from around the world andis widely considered to be a showcase conference for new developments in network algorithms andarchitectures. The broad range of interdisciplinary research areas represented includes neuralnetworks and genetic algorithms, cognitive science, neuroscience and biology, computer science, AI,applied mathematics, physics, and many branches of engineering. Only about 30\% of the paperssubmitted are accepted for presentation at NIPS, so the quality is exceptionally high. All of thepapers presented appear in these proceedings.},
	author = {Attias, H. and Schreiner, Christoph E},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 9: {Proceedings} of the 1996 {Conference}},
	file = {AttiasSchneirer1997.pdf:/Users/Cecile/Zotero/storage/PU4CTUPW/AttiasSchneirer1997.pdf:application/pdf},
	isbn = {978-0-262-10065-6},
	keywords = {Computers / Neural Networks, Medical / Neuroscience},
	language = {en},
	publisher = {MIT Press},
	title = {Temporal {Low}-{Order} {Statistics} of {Natural} {Sounds}},
	year = {1997}}

@article{byrne_international_1994,
	abstract = {The long‐term average speech spectrum (LTASS) and some dynamic characteristics of speech were determined for 12 languages: English (several dialects), Swedish, Danish, German, French (Canadian), Japanese, Cantonese, Mandarin, Russian, Welsh, Singhalese, and Vietnamese. The LTASS only was also measured for Arabic. Speech samples (18) were recorded, using standardized equipment and procedures, in 15 localities for (usually) ten male and ten female talkers. All analyses were conducted at the National Acoustic Laboratories, Sydney. The LTASS was similar for all languages although there were many statistically significant differences. Such differences were small and not always consistent for male and female samples of the same language. For one‐third octave bands of speech, the maximum short‐term rms level was 10 dB above the maximum long‐term rms level, consistent across languages and frequency. A ``universal'' LTASS is suggested as being applicable, across languages, for many purposes including use in hearing aid prescription procedures and in the Articulation Index.},
	author = {Byrne, Denis and Dillon, Harvey and Tran, Khanh and Arlinger, Stig and Wilbraham, Keith and Cox, Robyn and Hagerman, Bjorn and Hetu, Raymond and Kei, Joseph and Lui, C. and Kiessling, Jurgen and Kotby, M. Nasser and Nasser, Nasser H. A. and Kholy, Wafaa A. H. El and Nakanishi, Yasuko and Oyer, Herbert and Powell, Richard and Stephens, Dafydd and Meredith, Rhys and Sirimanna, Tony and Tavartkiladze, George and Frolenkov, Gregory I. and Westerman, Soren and Ludvigsen, Carl},
	doi = {10.1121/1.410152},
	file = {Byrne et al. - 1994 - An international comparison of long‐term average s.pdf:/Users/Cecile/Zotero/storage/466ZTW8Z/Byrne et al. - 1994 - An international comparison of long‐term average s.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMKKCQ6C/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Acoustic analysis, Hearing, Spectral properties, Speech},
	month = oct,
	number = {4},
	pages = {2108--2120},
	title = {An international comparison of long‐term average speech spectra},
	url = {http://scitation.aip.org/content/asa/journal/jasa/96/4/10.1121/1.410152},
	urldate = {2015-02-13},
	volume = {96},
	year = {1994},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/96/4/10.1121/1.410152},
	bdsk-url-2 = {https://doi.org/10.1121/1.410152}}

@article{latinus_human_2011,
	abstract = {We are all voice experts. First and foremost, we can produce and understand speech, and this makes us a unique species. But in addition to speech perception, we routinely extract from voices a wealth of socially-relevant information in what constitutes a more primitive, and probably more universal, non-linguistic mode of communication. Consider the following example: you are sitting in a plane, and you can hear a conversation in a foreign language in the row behind you. You do not see the speakers' faces, and you cannot understand the speech content because you do not know the language. Yet, an amazing amount of information is available to you. You can evaluate the physical characteristics of the different protagonists, including their gender, approximate age and size, and associate an identity to the different voices. You can form a good idea of the different speaker's mood and affective state, as well as more subtle cues as the perceived attractiveness or dominance of the protagonists. In brief, you can form a fairly detailed picture of the type of social interaction unfolding, which a brief glance backwards can on the occasion help refine --- sometimes surprisingly so. What are the acoustical cues that carry these different types of vocal information? How does our brain process and analyse this information? Here we briefly review an emerging field and the main tools used in voice perception research.},
	author = {Latinus, Marianne and Belin, Pascal},
	doi = {10.1016/j.cub.2010.12.033},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/5XC8UWZ8/Latinus et Belin - 2011 - Human voice perception.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/84RXFEWK/S096098221001701X.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	month = feb,
	number = {4},
	pages = {R143--R145},
	title = {Human voice perception},
	url = {http://www.cell.com/current-biology/abstract/S0960-9822(10)01701-X},
	urldate = {2014-02-01},
	volume = {21},
	year = {2011},
	bdsk-url-1 = {http://www.cell.com/current-biology/abstract/S0960-9822(10)01701-X},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2010.12.033}}

@article{moon_what_2014,
	abstract = {Complex sound like speech can be characterized as the sum of number of amplitude-modulated signals representing the outputs of an array of narrow frequency bands. Temporal information at the output of each band can be separated into temporal fine structure (TFS), the rapid oscillations close to the center frequency and temporal envelope (ENV), slower amplitude modulations superimposed on the TFS. TFS information can be carried in the pattern of phase locking to the stimulus waveform, while ENV by the changes in firing rate over time. The relative importance of temporal ENV and TFS information in understanding speech has been studied using various sound-processing techniques. A number of studies demonstrated that ENV cues are associated with speech recognition in quiet, while TFS cues are possibly linked to melody/pitch perception and listening to speech in a competing background. However, there are evidences that recovered ENV from TFS as well as TFS itself may be partially responsible for speech recognition. Current technologies used in cochlear implants (CI) are not efficient in delivering the TFS cues, and new attempts have been made to deliver TFS information into sound-processing strategy in CI. We herein discuss the current updated findings of TFS with a literature review.},
	author = {Moon, Il Joon and Hong, Sung Hwa},
	doi = {10.7874/kja.2014.18.1.1},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/A8FUASN5/Moon et Hong - 2014 - What Is Temporal Fine Structure and Why Is It Impo.pdf:application/pdf},
	issn = {2092-9862},
	journal = {Korean Journal of Audiology},
	month = apr,
	number = {1},
	pages = {1--7},
	pmcid = {PMC4003734},
	pmid = {24782944},
	title = {What {Is} {Temporal} {Fine} {Structure} and {Why} {Is} {It} {Important}?},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4003734/},
	urldate = {2016-09-07},
	volume = {18},
	year = {2014},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4003734/},
	bdsk-url-2 = {https://doi.org/10.7874/kja.2014.18.1.1}}

@article{tang_sound_nodate,
	abstract = {Objective
This study investigated auditory cortical processing of linguistically-relevant temporal modulations in the developing brains of young children.
Methods
Auditory envelope following responses to white noise amplitude modulated at rates of 1--80 Hz in healthy children (aged 3--5 years) and adults were recorded using a paediatric magnetoencephalography (MEG) system and a conventional MEG system, respectively.
Results
For children, there were envelope following responses to slow modulations but no significant responses to rates higher than about 25 Hz, whereas adults showed significant envelope following responses to almost the entire range of stimulus rates.
Conclusion
Our results show that the auditory cortex of preschool-aged children has a sharply limited capacity to process rapid amplitude modulations in sounds, as compared to the auditory cortex of adults.
Significance
These neurophysiological results are consistent with previous psychophysical evidence for a protracted maturational time course for auditory temporal processing. The findings are also in good agreement with current linguistic theories that posit a perceptual bias for low frequency temporal information in speech during language acquisition. These insights also have clinical relevance for our understanding of language disorders that are associated with difficulties in processing temporal information in speech.},
	author = {Tang, Huizhen and Brock, Jon and Johnson, Blake W.},
	doi = {10.1016/j.clinph.2015.07.038},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TTBHF2IZ/Tang et al. - Sound envelope processing in the developing human .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TAKEUEK9/S1388245715007944.html:text/html},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology},
	keywords = {Auditory steady state response, Envelope following response, Temporal processing, language acquisition, Development, Auditory cortex},
	shorttitle = {Sound envelope processing in the developing human brain},
	title = {Sound envelope processing in the developing human brain: {A} {MEG} study},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245715007944},
	urldate = {2015-12-03},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245715007944},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2015.07.038}}

@article{moon_two-day-olds_1993,
	abstract = {Newborn infants whose mothers were monolingual speakers of Spanish or English were tested with audio recordings of female strangers speaking either Spanish or English. Infant sucking controlled the presentation of auditory stimuli. Infants activated recordings of their native language for longer periods than the foreign language.},
	author = {Moon, Christine and Cooper, Robin Panneton and Fifer, William P.},
	doi = {10.1016/0163-6383(93)80007-U},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/FR2F2X3B/016363839380007U.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {Perception, nonnutritive, preference, sucking, language, Newborn},
	month = oct,
	number = {4},
	pages = {495--500},
	title = {Two-day-olds prefer their native language},
	url = {http://www.sciencedirect.com/science/article/pii/016363839380007U},
	urldate = {2014-06-01},
	volume = {16},
	year = {1993},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/016363839380007U},
	bdsk-url-2 = {https://doi.org/10.1016/0163-6383(93)80007-U}}

@article{tremblay_processing_2013,
	abstract = {The supratemporal plane contains several functionally heterogeneous subregions that respond strongly to speech. Much of the prior work on the issue of speech processing in the supratemporal plane has focused on neural responses to single speech vs. non-speech sounds rather than focusing on higher-level computations that are required to process more complex auditory sequences. Here we examined how information is integrated over time for speech and non-speech sounds by quantifying the BOLD fMRI response to stochastic (non-deterministic) sequences of speech and non-speech naturalistic sounds that varied in their statistical structure (from random to highly structured sequences) during passive listening. Behaviorally, the participants were accurate in segmenting speech and non-speech sequences, though they were more accurate for speech. Several supratemporal regions showed increased activation magnitude for speech sequences (preference), but, importantly, this did not predict sensitivity to statistical structure: (i) several areas showing a speech preference were sensitive to statistical structure in both speech and non-speech sequences, and (ii) several regions that responded to both speech and non-speech sounds showed distinct responses to statistical structure in speech and non-speech sequences. While the behavioral findings highlight the tight relation between statistical structure and segmentation processes, the neuroimaging results suggest that the supratemporal plane mediates complex statistical processing for both speech and non-speech sequences and emphasize the importance of studying the neurocomputations associated with auditory sequence processing. These findings identify new partitions of functionally distinct areas in the supratemporal plane that cannot be evoked by single stimuli. The findings demonstrate the importance of going beyond input preference to examine the neural computations implemented in the superior temporal plane.},
	author = {Tremblay, P. and Baroni, M. and Hasson, U.},
	doi = {10.1016/j.neuroimage.2012.10.055},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BPFQH4XA/Tremblay et al. - 2013 - Processing of speech and non-speech sounds in the .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AQ4F5C4M/S1053811912010580.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Speech processing, Statistical regularities, Supratemporal plane, language},
	month = feb,
	pages = {318--332},
	shorttitle = {Processing of speech and non-speech sounds in the supratemporal plane},
	title = {Processing of speech and non-speech sounds in the supratemporal plane: {Auditory} input preference does not predict sensitivity to statistical structure},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912010580},
	urldate = {2014-10-21},
	volume = {66},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912010580},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2012.10.055}}

@article{vouloumanos_listening_2007,
	abstract = {The nature and origin of the human capacity for acquiring language is not yet fully understood. Here we uncover early roots of this capacity by demonstrating that humans are born with a preference for listening to speech. Human neonates adjusted their high amplitude sucking to preferentially listen to speech, compared with complex non-speech analogues that controlled for critical spectral and temporal parameters of speech. These results support the hypothesis that human infants begin language acquisition with a bias for listening to speech. The implications of these results for language and communication development are discussed. For a commentary on this article see Rosen and Iverson (2007).},
	annote = {*},
	author = {Vouloumanos, Athena and Werker, Janet F},
	date-modified = {2022-04-05 16:59:53 +0200},
	doi = {10.1111/j.1467-7687.2007.00549.x},
	file = {Vouloumanos_2007_series.pdf:/Users/Cecile/Zotero/storage/BDIA78F9/Vouloumanos_2007_series.pdf:application/pdf},
	issn = {1363-755X},
	journal = {Developmental science},
	keywords = {Acoustic Stimulation, Attention, Humans, Infant Behavior, Infant, Newborn, Sound Spectrography, Sucking Behavior, language, speech perception, Speech Perception},
	language = {eng},
	month = mar,
	number = {2},
	pages = {159--164},
	pmid = {17286838},
	shorttitle = {Listening to language at birth},
	title = {Listening to language at birth: evidence for a bias for speech in neonates},
	volume = {10},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1111/j.1467-7687.2007.00549.x}}

@article{henry_frequency_2012,
	abstract = {The human ability to continuously track dynamic environmental stimuli, in particular speech, is proposed to profit from ``entrainment'' of endogenous neural oscillations, which involves phase reorganization such that ``optimal'' phase comes into line with temporally expected critical events, resulting in improved processing. The current experiment goes beyond previous work in this domain by addressing two thus far unanswered questions. First, how general is neural entrainment to environmental rhythms: Can neural oscillations be entrained by temporal dynamics of ongoing rhythmic stimuli without abrupt onsets? Second, does neural entrainment optimize performance of the perceptual system: Does human auditory perception benefit from neural phase reorganization? In a human electroencephalography study, listeners detected short gaps distributed uniformly with respect to the phase angle of a 3-Hz frequency-modulated stimulus. Listeners' ability to detect gaps in the frequency-modulated sound was not uniformly distributed in time, but clustered in certain preferred phases of the modulation. Moreover, the optimal stimulus phase was individually determined by the neural delta oscillation entrained by the stimulus. Finally, delta phase predicted behavior better than stimulus phase or the event-related potential after the gap. This study demonstrates behavioral benefits of phase realignment in response to frequency-modulated auditory stimuli, overall suggesting that frequency fluctuations in natural environmental input provide a pacing signal for endogenous neural oscillations, thereby influencing perceptual processing.},
	author = {Henry, Molly J. and Obleser, Jonas},
	doi = {10.1073/pnas.1213390109},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Q6E87GZI/Henry et Obleser - 2012 - Frequency modulation entrains slow neural oscillat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JQSRBSF2/20095.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {EEG, FM, auditory processing, pre-stimulus phase},
	language = {en},
	month = apr,
	number = {49},
	pages = {20095--20100},
	pmid = {23151506},
	title = {Frequency modulation entrains slow neural oscillations and optimizes human listening behavior},
	url = {http://www.pnas.org/content/109/49/20095},
	urldate = {2014-10-31},
	volume = {109},
	year = {2012},
	bdsk-url-1 = {http://www.pnas.org/content/109/49/20095},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1213390109}}

@article{millman_role_2015,
	author = {Millman, Rebecca E. and Johnson, Sam R. and Prendergast, Garreth},
	doi = {10.1162/jocn_a_00719},
	file = {jocn_MillmanJohnsonPrendengast.pdf:/Users/Cecile/Zotero/storage/B2TR4AXD/jocn_MillmanJohnsonPrendengast.pdf:application/pdf},
	issn = {0898-929X, 1530-8898},
	journal = {Journal of Cognitive Neuroscience},
	language = {en},
	month = mar,
	number = {3},
	pages = {533--545},
	title = {The {Role} of {Phase}-locking to the {Temporal} {Envelope} of {Speech} in {Auditory} {Perception} and {Speech} {Intelligibility}},
	url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00719},
	urldate = {2015-07-30},
	volume = {27},
	year = {2015},
	bdsk-url-1 = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00719},
	bdsk-url-2 = {https://doi.org/10.1162/jocn_a_00719}}

@article{shannon_speech_1995,
	abstract = {Nearly perfect speech recognition was observed under conditions of greatly reduced spectral information. Temporal envelopes of speech were extracted from broad frequency bands and were used to modulate noises of the same bandwidths. This manipulation preserved temporal envelope cues in each band but restricted the listener to severely degraded information on the distribution of spectral energy. The identification of consonants, vowels, and words in simple sentences improved markedly as the number of bands increased; high speech recognition performance was obtained with only three bands of modulated noise. Thus, the presentation of a dynamic temporal pattern in only a few broad spectral regions is sufficient for the recognition of speech.},
	author = {Shannon, Robert V. and Zeng, Fan-Gang and Kamath, Vivek and Wygonski, John and Ekelid, Michael},
	doi = {10.1126/science.270.5234.303},
	file = {Snapshot:/Users/Cecile/Zotero/storage/3KKNMHWK/303.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = oct,
	number = {5234},
	pages = {303--304},
	pmid = {7569981},
	title = {Speech {Recognition} with {Primarily} {Temporal} {Cues}},
	url = {http://www.sciencemag.org/content/270/5234/303},
	urldate = {2013-10-17},
	volume = {270},
	year = {1995},
	bdsk-url-1 = {http://www.sciencemag.org/content/270/5234/303},
	bdsk-url-2 = {https://doi.org/10.1126/science.270.5234.303}}

@incollection{vaissiere_language-independent_1983,
	abstract = {The purpose of this contribution is to investigate the similarities in form and function of prosody among diverse languages. All speakers, regardless of their specific language, are equipped with the same production and perception apparatus, and consequently have the same capabilities and must face the same physiological constraints. Such similarities should be reflected in the acoustic production of any speaker. The first specific aim of this contribution is to review a number of striking acoustic similarities in the suprasegmental aspects of neutral sentences in different languages, together with possible physiological explanations for them.},
	author = {Vaissi{\`e}re, Jacqueline},
	booktitle = {Prosody: {Models} and {Measurements}},
	copyright = {{\copyright}1983 Springer-Verlag Berlin Heidelberg},
	editor = {Cutler, Anne and Ladd, Robert D.},
	file = {Snapshot:/Users/Cecile/Zotero/storage/RHZ8GS5K/978-3-642-69103-4_5.html:text/html},
	isbn = {978-3-642-69105-8 978-3-642-69103-4},
	keywords = {Acoustics},
	language = {en},
	month = jan,
	number = {14},
	pages = {53--66},
	publisher = {Springer Berlin Heidelberg},
	series = {Springer {Series} in {Language} and {Communication}},
	title = {Language-{Independent} {Prosodic} {Features}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-69103-4_5},
	urldate = {2013-12-15},
	year = {1983},
	bdsk-url-1 = {http://link.springer.com/chapter/10.1007/978-3-642-69103-4_5}}

@article{delivoria-papadopoulos_postnatal_1971,
	author = {Delivoria-Papadopoulos, Maria and Roncevic, Nevenka P and Oski, Franck A},
	file = {Pediatric Research - Abstract of article\: Postnatal Changes in Oxygen Transport of Term, Premature, and Sick Infants\: The Role of Red Cell 2,3-Diphosphoglycerate and Adult Hemoglobin:/Users/Cecile/Zotero/storage/QQCXF7KN/pr1971100a.html:text/html},
	journal = {Pediatric Research},
	number = {5},
	pages = {235--245},
	title = {Postnatal {Changes} in {Oxygen} {Transport} of {Term}, {Premature}, and {Sick} {Infants}: {The} {Role} of {Red} {Cell} 2,3-{Diphosphoglycerate} and {Adult} {Hemoglobin}},
	url = {http://www.nature.com/pr/journal/v5/n6/abs/pr1971100a.html},
	urldate = {2017-02-28},
	year = {1971},
	bdsk-url-1 = {http://www.nature.com/pr/journal/v5/n6/abs/pr1971100a.html}}

@article{r._wise_distribution_1991,
	author = {{R. Wise} and {F. Chollet,} and {U. Hadar} and {K. Friston} and {E. Hoffner} and {R. Frackowiak}},
	journal = {Brain},
	month = aug,
	number = {4},
	pages = {1803--1817},
	title = {Distribution of cortical neural networks involved in word comprehension and word retrieval},
	volume = {114},
	year = {1991}}

@article{vanrullen_how_2016,
	abstract = {A growing number of studies endeavor to reveal periodicities in sensory and cognitive functions, by comparing the distribution of ongoing (pre-stimulus) oscillatory phases between two (or more) trial groups reflecting distinct experimental outcomes. A systematic relation between the phase of spontaneous electrophysiological signals, before a stimulus is even presented, and the eventual result of sensory or cognitive processing for that stimulus, would be indicative of an intrinsic periodicity in the underlying neural process. Prior studies of phase-dependent perception have used a variety of analytical methods to measure and evaluate phase differences, and there is currently no established standard practice in this field. The present report intends to remediate this need, by systematically comparing the statistical power of various measures of ``phase opposition'' between two trial groups, in a number of real and simulated experimental situations. Seven measures were evaluated: one parametric test (circular Watson-Williams test), and three distinct measures of phase opposition (phase bifurcation index, phase opposition sum, and phase opposition product) combined with two procedures for non-parametric statistical testing (permutation, or a combination of z-score and permutation). While these are obviously not the only existing or conceivable measures, they have all been used in recent studies. All tested methods performed adequately on a previously published dataset (Busch et al., ). On a variety of artificially constructed datasets, no single measure was found to surpass all others, but instead the suitability of each measure was contingent on several experimental factors: the time, frequency, and depth of oscillatory phase modulation; the absolute and relative amplitudes of post-stimulus event-related potentials for the two trial groups; the absolute and relative trial numbers for the two groups; and the number of permutations used for non-parametric testing. The concurrent use of two phase opposition measures, the parametric Watson-Williams test and a non-parametric test based on summing inter-trial coherence values for the two trial groups, appears to provide the most satisfactory outcome in all situations tested. Matlab code is provided to automatically compute these phase opposition measures.},
	author = {VanRullen, Rufin},
	doi = {10.3389/fnins.2016.00426},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/E9KJ66W8/VanRullen - 2016 - How to Evaluate Phase Differences between Trial Gr.pdf:application/pdf},
	issn = {1662-4548},
	journal = {Frontiers in Neuroscience},
	month = sep,
	pmcid = {PMC5021700},
	pmid = {27683543},
	title = {How to {Evaluate} {Phase} {Differences} between {Trial} {Groups} in {Ongoing} {Electrophysiological} {Signals}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5021700/},
	urldate = {2017-10-12},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5021700/},
	bdsk-url-2 = {https://doi.org/10.3389/fnins.2016.00426}}

@article{saberi_cognitive_1999,
	abstract = {Speech is the most complex auditory signal and requires the most processing. The human brain devotes large cortical areas, to deciphering the information it contains, as well as parsing speech sounds produced simultaneously by several speakers. The brain can also invoke corrective measures to restore distortions in speech; for example, if a brief speech sound is replaced by an interfering sound that masks it, such as a cough, the listener perceives the missing speech as if the brain interpolates through the absent segment. We have studied the intelligibility of speech, and find it is resistant to time reversal of local segments of a spoken sentence, which has been described as "the most drastic form of time scale distortion".},
	author = {Saberi, Kourosh and Perrott, David R.},
	copyright = {{\copyright} 1999 Nature Publishing Group},
	doi = {10.1038/19652},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4BKPT5XU/Saberi et Perrott - 1999 - Cognitive restoration of reversed speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CHD2QI6N/398760a0.html:text/html},
	issn = {0028-0836},
	journal = {Nature},
	language = {en},
	month = apr,
	number = {6730},
	pages = {760--760},
	title = {Cognitive restoration of reversed speech},
	url = {http://www.nature.com/nature/journal/v398/n6730/full/398760a0.html},
	urldate = {2015-12-15},
	volume = {398},
	year = {1999},
	bdsk-url-1 = {http://www.nature.com/nature/journal/v398/n6730/full/398760a0.html},
	bdsk-url-2 = {https://doi.org/10.1038/19652}}

@article{carral_kind_2005,
	abstract = {`Primitive intelligence' in audition refers to the capacity of the auditory system to adaptatively model the acoustic regularity and react neurophysiologically to violations of such regularity, thus supporting the ability to predict future auditory events. In the present study, event-related brain potentials to pairs of tones were recorded in 11 human newborns to determine the infants' ability to extract an abstract acoustic rule, the direction of a frequency change. Most of the pairs (standard, P = 0.875) were of ascending frequency (i.e. the second tone higher than the first), while the remaining pairs (deviant, P = 0.125) were of descending frequency (the second tone being lower). Their frequencies varied among seven levels to prevent discrimination between standard and deviant pairs on the basis of absolute frequencies. We found that event-related brain potentials to deviant pairs differed in amplitude from those to standard pairs at 50--450 ms from the onset of the second tone of a pair, indicating the infants' ability to represent the abstract rule. This finding suggests the early ontogenetic origin of `primitive intelligence' in audition that eventually may form a prerequisite for later language acquisition.},
	author = {Carral, Vanessa and Huotilainen, Minna and Ruusuvirta, Timo and Fellman, Vineta and N{\"a}{\"a}t{\"a}nen, Risto and Escera, Carles},
	doi = {10.1111/j.1460-9568.2005.04144.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T6HNXWES/Carral et al. - 2005 - A kind of auditory `primitive intelligence' alread.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GWRPZ9WN/abstract\;jsessionid=35A2C645937DC92F340D9889BE2DA89F.html:text/html},
	issn = {1460-9568},
	journal = {European Journal of Neuroscience},
	keywords = {Auditory Perception, abstract regularities, change detection, human infant, Mismatch negativity},
	language = {en},
	month = jun,
	number = {11},
	pages = {3201--3204},
	title = {A kind of auditory `primitive intelligence' already present at birth},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1460-9568.2005.04144.x/abstract},
	urldate = {2016-03-14},
	volume = {21},
	year = {2005},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1460-9568.2005.04144.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1460-9568.2005.04144.x}}

@article{buzsaki_origin_2012,
	abstract = {Neuronal activity in the brain gives rise to transmembrane currents that can be measured in the extracellular medium. Although the major contributor of the extracellular signal is the synaptic transmembrane current, other sources --- including Na+ and Ca2+ spikes, ionic fluxes through voltage- and ligand-gated channels, and intrinsic membrane oscillations --- can substantially shape the extracellular field. High-density recordings of field activity in animals and subdural grid recordings in humans, combined with recently developed data processing tools and computational modelling, can provide insight into the cooperative behaviour of neurons, their average synaptic input and their spiking output, and can increase our understanding of how these processes contribute to the extracellular signal.},
	author = {Buzs{\'a}ki, Gy{\"o}rgy and Anastassiou, Costas A. and Koch, Christof},
	copyright = {{\copyright} 2012 Nature Publishing Group},
	doi = {10.1038/nrn3241},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/6CJM6MS4/Buzs{\'a}ki et al. - 2012 - The origin of extracellular fields and currents --- .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/V57BQ3SP/nrn3241.html:text/html},
	issn = {1471-003X},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = jun,
	number = {6},
	pages = {407--420},
	title = {The origin of extracellular fields and currents --- {EEG}, {ECoG}, {LFP} and spikes},
	url = {http://www.nature.com/nrn/journal/v13/n6/abs/nrn3241.html},
	urldate = {2015-07-13},
	volume = {13},
	year = {2012},
	bdsk-url-1 = {http://www.nature.com/nrn/journal/v13/n6/abs/nrn3241.html},
	bdsk-url-2 = {https://doi.org/10.1038/nrn3241}}

@article{averbeck_principal_2004,
	author = {Averbeck, B. B.},
	doi = {10.1152/jn.01103.2003},
	file = {Web of Knowledge [v.5.10] - All Databases:/Users/Cecile/Zotero/storage/7K9U5F82/full_record.html:text/html},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	month = jun,
	number = {6},
	pages = {2897--2909},
	shorttitle = {Principal and {Independent} {Components} of {Macaque} {Vocalizations}},
	title = {Principal and {Independent} {Components} of {Macaque} {Vocalizations}: {Constructing} {Stimuli} to {Probe} {High}-{Level} {Sensory} {Processing}},
	url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=11&SID=P2539gp3JpbfaaifH6k&page=8&doc=77&cacheurlFromRightClick=no},
	urldate = {2013-07-17},
	volume = {91},
	year = {2004},
	bdsk-url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=11&SID=P2539gp3JpbfaaifH6k&page=8&doc=77&cacheurlFromRightClick=no},
	bdsk-url-2 = {https://doi.org/10.1152/jn.01103.2003}}

@article{ramus_correlates_2000,
	abstract = {Spoken languages have been classified by linguists according to their rhythmic properties, and psycholinguists have relied on this classification to account for infants' capacity to discriminate languages. Although researchers have measured many speech signal properties, they have failed to identify reliable acoustic characteristics for language classes. This paper presents instrumental measurements based on a consonant/vowel segmentation for eight languages. The measurements suggest that intuitive rhythm types reflect specific phonological properties, which in turn are signaled by the acoustic/phonetic properties of speech. The data support the notion of rhythm classes and also allow the simulation of infant language discrimination, consistent with the hypothesis that newborns rely on a coarse segmentation of speech. A hypothesis is proposed regarding the role of rhythm perception in language acquisition.},
	author = {Ramus, Franck and Nespor, Marina and Mehler, Jacques},
	doi = {10.1016/S0010-0277(00)00101-3},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/G68EZW2I/Ramus et al. - 2000 - Correlates of linguistic rhythm in the speech sign.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PAGB43HS/S0010027700001013.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	keywords = {Language discrimination, Phonological bootstrapping, Speech rhythm, Syllable structure, language acquisition, prosody},
	month = apr,
	number = {1},
	pages = {AD3--AD30},
	title = {Correlates of linguistic rhythm in the speech signal},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027700001013},
	urldate = {2013-12-06},
	volume = {75},
	year = {2000},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0010027700001013},
	bdsk-url-2 = {https://doi.org/10.1016/S0010-0277(00)00101-3}}

@article{ming_efficient_2009,
	abstract = {Natural sounds possess characteristic statistical regularities. Recent research suggests that mammalian auditory processing maximizes information about these regularities in its internal representation while minimizing encoding cost [Smith, E. C. and Lewicki, M. S. (2006). Nature (London) 439, 978--982]. Evidence for this ``efficient coding hypothesis'' comes largely from neurophysiology and theoretical modeling [Olshausen, B. A., and Field, D. (2004). Curr. Opin. Neurobiol. 14, 481--487; DeWeese, M., et al. (2003). J. Neurosci. 23, 7940--7949; Klein, D. J., et al. (2003). EURASIP J. Appl. Signal Process. 7, 659--667]. The present research provides behavioral evidence for efficient coding in human auditory perception using six-channel noise-vocoded speech, which drastically limits spectral information and degrades recognition accuracy. Two experiments compared recognition accuracy of vocoder speech created using theoretically-motivated, efficient coding filterbanks derived from the statistical regularities of speech against recognition using standard cochleotopic (logarithmic) or linear filterbanks. Recognition of the speech created using efficient encoding filterbanks was significantly more accurate than either of the other classes. These findings suggest potential applications to cochlear implant design.},
	author = {Ming, Vivienne L. and Holt, Lori L.},
	doi = {10.1121/1.3158939},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/SHAC8PXC/Ming et Holt - 2009 - Efficient coding in human auditory perception.pdf:application/pdf},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = sep,
	number = {3},
	pages = {1312--1320},
	pmcid = {PMC2809690},
	pmid = {19739745},
	title = {Efficient coding in human auditory perception},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809690/},
	urldate = {2015-02-02},
	volume = {126},
	year = {2009},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809690/},
	bdsk-url-2 = {https://doi.org/10.1121/1.3158939}}

@article{kayser_analysis_2012,
	abstract = {Neurons in sensory cortices encode objects in our sensory environment by varying the timing and number of action potentials that they emit. Brain networks that `decode' this information need to partition those spike trains into their individual informative units. Experimenters achieve such partitioning by exploiting their knowledge about the millisecond precise timing of individual spikes relative to externally presented sensory stimuli. The brain, however, does not have access to this information and has to partition and decode spike trains using intrinsically available temporal reference frames. We show that slow (4--8 Hz) oscillatory network activity can provide such an intrinsic temporal reference. Specifically, we analyzed neural responses recorded in primary auditory and visual cortices. This revealed that the oscillatory reference frame performs nearly as well as the precise stimulus-locked reference frame and renders neural encoding robust to sensory noise and temporal uncertainty that naturally occurs during decoding. These findings provide a computational proof-of-concept that slow oscillatory network activity may serve the crucial function as temporal reference frame for sensory coding.},
	author = {Kayser, Christoph and Ince, Robin A. A. and Panzeri, Stefano},
	doi = {10.1371/journal.pcbi.1002717},
	file = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/W78DVIBJ/Kayser et al. - 2012 - Analysis of Slow (Theta) Oscillations as a Potenti.pdf:application/pdf;PLoS Snapshot:/Users/Cecile/Zotero/storage/WHAAVUMF/infodoi10.1371journal.pcbi.html:text/html;SinghTheunissen2003.pdf:/Users/Cecile/Zotero/storage/RA88M7IH/SinghTheunissen2003.pdf:application/pdf},
	journal = {PLoS Comput Biol},
	month = oct,
	number = {10},
	pages = {e1002717},
	title = {Analysis of {Slow} ({Theta}) {Oscillations} as a {Potential} {Temporal} {Reference} {Frame} for {Information} {Coding} in {Sensory} {Cortices}},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1002717},
	urldate = {2014-10-31},
	volume = {8},
	year = {2012},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1002717}}

@article{rossi_shedding_2012,
	abstract = {Investigating the neuronal network underlying language processing may contribute to a better understanding of how the brain masters this complex cognitive function with surprising ease and how language is acquired at a fast pace in infancy. Modern neuroimaging methods permit to visualize the evolvement and the function of the language network. The present paper focuses on a specific methodology, functional near-infrared spectroscopy (fNIRS), providing an overview over studies on auditory language processing and acquisition. The methodology detects oxygenation changes elicited by functional activation of the cerebral cortex. The main advantages for research on auditory language processing and its development during infancy are an undemanding application, the lack of instrumental noise, and its potential to simultaneously register electrophysiological responses. Also it constitutes an innovative approach for studying developmental issues in infants and children. The review will focus on studies on word and sentence processing including research in infants and adults.},
	author = {Rossi, Sonja and Telkemeyer, Silke and Wartenburger, Isabell and Obrig, Hellmuth},
	doi = {10.1016/j.bandl.2011.03.008},
	issn = {1090-2155},
	journal = {Brain and Language},
	keywords = {Adult, Brain Mapping, Child, Humans, Infant, Language Development, Spectroscopy, Near-Infrared, language, speech perception, Brain, Speech Perception},
	language = {eng},
	month = may,
	number = {2},
	pages = {152--163},
	pmid = {21546074},
	shorttitle = {Shedding light on words and sentences},
	title = {Shedding light on words and sentences: near-infrared spectroscopy in language research},
	volume = {121},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1016/j.bandl.2011.03.008}}

@article{nazzi_language_1998,
	abstract = {Three experiments investigated the ability of French newborns to discriminate between sets of sentences in different foreign languages. The sentences were low-pass filtered to reduce segmental information while sparing prosodic information. Infants discriminated between stress-timed English and mora-timed Japanese (Experiment 1) but failed to discriminate between stress-timed English and stress-timed Dutch (Experiment 2). In Experiment 3, infants heard different combinations of sentences from English, Dutch, Spanish, and Italian. Discrimination was observed only when English and Dutch sentences were contrasted with Spanish and Italian sentences. These results suggest that newborns use prosodic and, more specifically, rhythmic information to classify utterances into broad language classes defined according to global rhythmic properties. Implications of this for the acquisition of the rhythmic properties of the native language are discussed.},
	author = {Nazzi, Thierry and Bertoncini, Josiane and Mehler, Jacques},
	copyright = {(c) 2012 APA, all rights reserved},
	doi = {10.1037/0096-1523.24.3.756},
	file = {Nazzi et al. - 1998 - Language discrimination by newborns Toward an und.pdf:/Users/Cecile/Zotero/storage/97AP3SZI/Nazzi et al. - 1998 - Language discrimination by newborns Toward an und.pdf:application/pdf},
	issn = {1939-1277(Electronic);0096-1523(Print)},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	keywords = {*Auditory Discrimination, *Foreign Languages, *Neonatal Development, *Rhythm, Verbal Communication},
	number = {3},
	pages = {756--766},
	shorttitle = {Language discrimination by newborns},
	title = {Language discrimination by newborns: {Toward} an understanding of the role of rhythm},
	volume = {24},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1037/0096-1523.24.3.756}}

@article{elliott_modulation_2009,
	abstract = {Author Summary
The sound signal of speech is rich in temporal and frequency patterns. These fluctuations of power in time and frequency are called modulations. Despite their acoustic complexity, spoken words remain intelligible after drastic degradations in either time or frequency. To fully understand the perception of speech and to be able to reduce speech to its most essential components, we need to completely characterize how modulations in amplitude and frequency contribute together to the comprehensibility of speech. Hallmark research distorted speech in either time or frequency but described the arbitrary manipulations in terms limited to one domain or the other, without quantifying the remaining and missing portions of the signal. Here, we use a novel sound filtering technique to systematically investigate the joint features in time and frequency that are crucial for understanding speech. Both the modulation-filtering approach and the resulting characterization of speech have the potential to change the way that speech is compressed in audio engineering and how it is processed in medical applications such as cochlear implants.},
	author = {Elliott, Taffeta M. and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1371/journal.pcbi.1000302},
	file = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/IZKFACBS/Elliott et Theunissen - 2009 - The Modulation Transfer Function for Speech Intell.pdf:application/pdf},
	journal = {PLoS Comput Biol},
	month = mar,
	number = {3},
	pages = {e1000302},
	title = {The {Modulation} {Transfer} {Function} for {Speech} {Intelligibility}},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1000302},
	urldate = {2015-10-22},
	volume = {5},
	year = {2009},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1000302}}

@article{morais_does_1979,
	abstract = {It was found that illiterate adults could neither delete nor add a phone at the beginning of a non-word; but these tasks were rather easily performed by people with similar environment and childhood experiences, who learned to read rudimentarily as adults. Awareness of speech as a sequence of phones is thus not attained spontaneously in the course of general cognitive growth, but demands some specific training, which, for most persons, is probably provided by learning to read in the alphabetic system.},
	author = {Morais, Jos{\'e} and Cary, Luz and Alegria, J{\'e}sus and Bertelson, Paul},
	doi = {10.1016/0010-0277(79)90020-9},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EHMQGIUE/Morais et al. - 1979 - Does awareness of speech as a sequence of phones a.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2ATCCZBU/0010027779900209.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	number = {4},
	pages = {323--331},
	title = {Does awareness of speech as a sequence of phones arise spontaneously?},
	url = {http://www.sciencedirect.com/science/article/pii/0010027779900209},
	urldate = {2014-12-04},
	volume = {7},
	year = {1979},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0010027779900209},
	bdsk-url-2 = {https://doi.org/10.1016/0010-0277(79)90020-9}}

@article{peelle_hierarchical_2010,
	author = {Peelle, Jonathan E. and Johnsrude, Ingrid S. and Davis, Matthew H.},
	doi = {10.3389/fnhum.2010.00051},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/3FN2NCM2/Peelle et al. - 2010 - Hierarchical Processing for Speech in Human Audito.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = jun,
	pmcid = {PMC2907234},
	pmid = {20661456},
	title = {Hierarchical {Processing} for {Speech} in {Human} {Auditory} {Cortex} and {Beyond}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2907234/},
	urldate = {2015-05-22},
	volume = {4},
	year = {2010},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2907234/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2010.00051}}

@article{young_neural_2008,
	abstract = {Speech is the most interesting and one of the most complex sounds dealt with by the auditory system. The neural representation of speech needs to capture those features of the signal on which the brain depends in language communication. Here we describe the representation of speech in the auditory nerve and in a few sites in the central nervous system from the perspective of the neural coding of important aspects of the signal. The representation is tonotopic, meaning that the speech signal is decomposed by frequency and different frequency components are represented in different populations of neurons. Essential to the representation are the properties of frequency tuning and nonlinear suppression. Tuning creates the decomposition of the signal by frequency, and nonlinear suppression is essential for maintaining the representation across sound levels. The representation changes in central auditory neurons by becoming more robust against changes in stimulus intensity and more transient. However, it is probable that the form of the representation at the auditory cortex is fundamentally different from that at lower levels, in that stimulus features other than the distribution of energy across frequency are analysed.},
	author = {Young, Eric D.},
	doi = {10.1098/rstb.2007.2151},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Q6Z6VMR7/Young - 2008 - Neural representation of spectral and temporal inf.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/XAN866PQ/Young - 2008 - Neural representation of spectral and temporal inf.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/445FPFPN/923.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/GGCIQVMN/923.html:text/html},
	issn = {0962-8436, 1471-2970},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	keywords = {Speech, auditory nerve, discrimination, inferior colliculus, tonotopic, Auditory cortex},
	language = {en},
	month = dec,
	number = {1493},
	pages = {923--945},
	pmid = {17827107},
	title = {Neural representation of spectral and temporal information in speech},
	url = {http://rstb.royalsocietypublishing.org/content/363/1493/923},
	urldate = {2014-09-25},
	volume = {363},
	year = {2008},
	bdsk-url-1 = {http://rstb.royalsocietypublishing.org/content/363/1493/923},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2007.2151}}

@article{hyafil_speech_2015,
	author = {Hyafil, Alexandre and Fontolan, Lorenzo},
	doi = {10.7554/eLife.06213},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T7SFANC8/Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamm.pdf:application/pdf;Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamma oscillations.pdf:/Users/Cecile/Zotero/storage/WSZT5B57/Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamma oscillations.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ACX8HQZ3/eLife.06213.html:text/html;Speech encoding by coupled cortical theta and gamma oscillations (PDF Download Available):/Users/Cecile/Zotero/storage/VAD3BREB/277407075_Speech_encoding_by_coupled_cortical_theta_and_gamma_oscillations.html:text/html},
	issn = {2050-084X},
	journal = {eLife},
	title = {Speech encoding by coupled cortical theta and gamma oscillations},
	volume = {4},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.7554/eLife.06213}}

@article{segaert_suppression_2013,
	abstract = {Repetition suppression in fMRI studies is generally thought to underlie behavioural facilitation effects (i.e., priming) and it is often used to identify the neuronal representations associated with a stimulus. However, this pays little heed to the large number of repetition enhancement effects observed under similar conditions. In this review, we identify several cognitive variables biasing repetition effects in the BOLD response towards enhancement instead of suppression. These variables are stimulus recognition, learning, attention, expectation and explicit memory. We also evaluate which models can account for these repetition effects and come to the conclusion that there is no one single model that is able to embrace all repetition enhancement effects. Accumulation, novel network formation as well as predictive coding models can all explain subsets of repetition enhancement effects.},
	author = {Segaert, Katrien and Weber, Kirsten and de Lange, Floris P. and Petersson, Karl Magnus and Hagoort, Peter},
	doi = {10.1016/j.neuropsychologia.2012.11.006},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/5IC62V2R/Segaert et al. - 2013 - The suppression of repetition enhancement A revie.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7KDZE4IE/S0028393212004733.html:text/html},
	issn = {0028-3932},
	journal = {Neuropsychologia},
	keywords = {fMRI adaptation, priming, repetition enhancement, repetition suppression},
	month = jan,
	number = {1},
	pages = {59--66},
	shorttitle = {The suppression of repetition enhancement},
	title = {The suppression of repetition enhancement: {A} review of {fMRI} studies},
	url = {http://www.sciencedirect.com/science/article/pii/S0028393212004733},
	urldate = {2016-09-19},
	volume = {51},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0028393212004733},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuropsychologia.2012.11.006}}

@article{dicarlo_untangling_2007,
	abstract = {Despite tremendous variation in the appearance of visual objects, primates can recognize a multitude of objects, each in a fraction of a second, with no apparent effort. However, the brain mechanisms that enable this fundamental ability are not understood. Drawing on ideas from neurophysiology and computation, we present a graphical perspective on the key computational challenges of object recognition, and argue that the format of neuronal population representation and a property that we term `object tangling' are central. We use this perspective to show that the primate ventral visual processing stream achieves a particularly effective solution in which single-neuron invariance is not the goal. Finally, we speculate on the key neuronal mechanisms that could enable this solution, which, if understood, would have far-reaching implications for cognitive neuroscience.},
	author = {DiCarlo, James J. and Cox, David D.},
	doi = {10.1016/j.tics.2007.06.010},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EU788PCW/DiCarlo et Cox - 2007 - Untangling invariant object recognition.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/U5ZPX7WE/S1364661307001593.html:text/html},
	issn = {1364-6613},
	journal = {Trends in Cognitive Sciences},
	month = aug,
	number = {8},
	pages = {333--341},
	title = {Untangling invariant object recognition},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661307001593},
	urldate = {2015-05-22},
	volume = {11},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661307001593},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2007.06.010}}

@article{dehaene-lambertz_functional_2006,
	abstract = {We examined the functional organization of cerebral activity in 3-month-old infants when they were listening to their mother language. Short sentences were presented in a slow event-related functional MRI paradigm. We then parsed the infant's network of perisylvian responsive regions into functionally distinct regions based on their speed of activation and sensitivity to sentence repetition. An adult-like structure of functional MRI response delays was observed along the superior temporal regions, suggesting a hierarchical processing scheme. The fastest responses were recorded in the vicinity of Heschl's gyrus, whereas responses became increasingly slower toward the posterior part of the superior temporal gyrus and toward the temporal poles and inferior frontal regions (Broca's area). Activation in the latter region increased when the sentence was repeated after a 14-s delay, suggesting the early involvement of Broca's area in verbal memory. The fact that Broca's area is active in infants before the babbling stage implies that activity in this region is not the consequence of sophisticated motor learning but, on the contrary, that this region may drive, through interactions with the perceptual system, the learning of the complex motor sequences required for future speech production. Our results point to a complex, hierarchical organization of the human brain in the first months of life, which may play a crucial role in language acquisition in our species.},
	author = {Dehaene-Lambertz, Ghislaine and Hertz-Pannier, Lucie and Dubois, Jessica and M{\'e}riaux, S{\'e}bastien and Roche, Alexis and Sigman, Mariano and Dehaene, Stanislas},
	doi = {10.1073/pnas.0606302103},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	keywords = {Adult, Animals, Brain Mapping, Female, Frontal Lobe, Humans, Infant, Male, Temporal Lobe, language, speech perception, Magnetic resonance imaging, Speech Perception},
	language = {eng},
	month = sep,
	number = {38},
	pages = {14240--14245},
	pmcid = {PMC1599941},
	pmid = {16968771},
	title = {Functional organization of perisylvian activation during presentation of sentences in preverbal infants},
	volume = {103},
	year = {2006},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.0606302103}}

@article{muller_repetition_2013,
	abstract = {Upon repetition, certain stimuli induce reduced neural responses (i.e., repetition suppression), whereas others evoke stronger signals (i.e., repetition enhancement). It has been hypothesized that stimulus properties (e.g., visibility) determine the direction of the repetition effect. Here, we show that the very same stimuli can induce both repetition suppression and enhancement, whereby the only determining factor is the number of repetitions. Repeating the same, initially novel low-visible pictures of scenes for up to 5 times enhanced the blood oxygen level--dependent (BOLD) response in scene-selective areas, that is, the parahippocampal place area (PPA) and the transverse occipital sulcus (TOS), presumably reflecting the strengthening of the internal representation. Additional repetitions (6--9) resulted in progressively attenuated neural responses indicating a more efficient representation of the now familiar stimulus. Behaviorally, repetition led to increasingly faster responses and higher visibility ratings. Novel scenes induced the largest BOLD response in the PPA and also higher activity in yet another scene-selective region, the retrospenial cortex (RSC). We propose that 2 separable processes modulate activity in the PPA: one process optimizes the internal stimulus representation and involves TOS and the other differentiates between familiar and novel scenes and involves RSC.},
	author = {M{\"u}ller, Notger G. and Strumpf, H. and Scholz, M. and Baier, B. and Melloni, L.},
	doi = {10.1093/cercor/bhs009},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NJJJVVF7/M{\"u}ller et al. - 2013 - Repetition Suppression versus Enhancement---It's Qua.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M8563SI6/315.html:text/html},
	issn = {1047-3211, 1460-2199},
	journal = {Cerebral Cortex},
	keywords = {novelty detection, fMRI, priming, repetition suppression},
	language = {en},
	month = jan,
	number = {2},
	pages = {315--322},
	pmid = {22314047},
	title = {Repetition {Suppression} versus {Enhancement}---{It}'s {Quantity} {That} {Matters}},
	url = {http://cercor.oxfordjournals.org/content/23/2/315},
	urldate = {2016-09-19},
	volume = {23},
	year = {2013},
	bdsk-url-1 = {http://cercor.oxfordjournals.org/content/23/2/315},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhs009}}

@article{simoncelli_natural_2001,
	abstract = {It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954)Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons.},
	author = {Simoncelli, E P and Olshausen, B A},
	doi = {10.1146/annurev.neuro.24.1.1193},
	issn = {0147-006X},
	journal = {Annual review of neuroscience},
	keywords = {Animals, Brain Mapping, Environment, Humans, Image Processing, Computer-Assisted, Pattern Recognition, Visual, Visual Cortex, Visual Perception, Neurons},
	language = {eng},
	pages = {1193--1216},
	pmid = {11520932},
	title = {Natural image statistics and neural representation},
	volume = {24},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1146/annurev.neuro.24.1.1193}}

@article{raschle_pediatric_2012,
	abstract = {Structural and functional magnetic resonance imaging (fMRI) has been used increasingly to investigate typical and atypical brain development. However, in contrast to studies in school-aged children and adults, MRI research in young pediatric age groups is less common. Practical and technical challenges occur when imaging infants and children, which presents clinicians and research teams with a unique set of problems. These include procedural difficulties (e.g., participant anxiety or movement restrictions), technical obstacles (e.g., availability of child-appropriate equipment or pediatric MR head coils), and the challenge of choosing the most appropriate analysis methods for pediatric imaging data. Here, we summarize and review pediatric imaging and analysis tools and present neuroimaging protocols for young nonsedated children and infants, including guidelines and procedures that have been successfully implemented in research protocols across several research sites.},
	author = {Raschle, Nora and Zuk, Jennifer and Ortiz-Mantilla, Silvia and Sliva, Danielle D. and Franceschi, Angela and Grant, P. Ellen and Benasich, April A. and Gaab, Nadine},
	doi = {10.1111/j.1749-6632.2012.06457.x},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/WKF5DAFZ/Raschle et al. - 2012 - Pediatric neuroimaging in early childhood and infa.pdf:application/pdf},
	issn = {0077-8923},
	journal = {Annals of the New York Academy of Sciences},
	month = apr,
	pages = {43--50},
	pmcid = {PMC3499030},
	pmid = {22524338},
	shorttitle = {Pediatric neuroimaging in early childhood and infancy},
	title = {Pediatric neuroimaging in early childhood and infancy: challenges and practical guidelines},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3499030/},
	urldate = {2016-09-19},
	volume = {1252},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3499030/},
	bdsk-url-2 = {https://doi.org/10.1111/j.1749-6632.2012.06457.x}}

@article{scholkmann_review_2014,
	author = {Scholkmann, Felix and Kleiser, Stefan and Metz, Andreas Jaakko and Zimmermann, Raphael and Mata Pavia, Juan and Wolf, Ursula and Wolf, Martin},
	doi = {10.1016/j.neuroimage.2013.05.004},
	file = {A review on continuous wave functional near-infrared spectroscopy and imaging instrumentation and methodology:/Users/Cecile/Zotero/storage/4KFPVM4A/S1053811913004941.html:text/html;Scholkmannetal14.pdf:/Users/Cecile/Zotero/storage/J7WFB77F/Scholkmannetal14.pdf:application/pdf},
	issn = {10538119},
	journal = {NeuroImage},
	month = jan,
	pages = {6--27},
	title = {A review on continuous wave functional near-infrared spectroscopy and imaging instrumentation and methodology},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811913004941#},
	urldate = {2013-12-10},
	volume = {85},
	year = {2014},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811913004941#},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2013.05.004}}

@article{lee_acoustic_2016,
	author = {Lee, Yune-Sang and Min, Nam Eun and Wingfield, Arthur and Grossman, Murray and Peelle, Jonathan E.},
	doi = {10.1016/j.heares.2015.12.008},
	file = {Lee-2016-Acoustic_richness_modulates_the_neural_networks_supporting_intelligible_speech_processing.pdf:/Users/Cecile/Zotero/storage/Q5AU4DBJ/Lee-2016-Acoustic_richness_modulates_the_neural_networks_supporting_intelligible_speech_processing.pdf:application/pdf},
	issn = {03785955},
	journal = {Hearing Research},
	language = {en},
	month = mar,
	pages = {108--117},
	title = {Acoustic richness modulates the neural networks supporting intelligible speech processing},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595515301969},
	urldate = {2016-09-19},
	volume = {333},
	year = {2016},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378595515301969},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2015.12.008}}

@article{mehler_understanding_1993,
	author = {Mehler, Jacques and Sebastian, Nuria and Altmann, Gerry and Dupoux, Emmanuel and Christophe, Anne and Pallier, Christophe},
	doi = {10.1111/j.1749-6632.1993.tb22975.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BZVX2W6Q/Mehler et al. - 1993 - Understanding Compressed Sentences The Role of Rh.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2636T75N/abstract\;jsessionid=433CB7D845A881D1700FC231A486EC18.html:text/html},
	issn = {1749-6632},
	journal = {Annals of the New York Academy of Sciences},
	language = {en},
	month = jun,
	number = {1},
	pages = {272--282},
	shorttitle = {Understanding {Compressed} {Sentences}},
	title = {Understanding {Compressed} {Sentences}: {The} {Role} of {Rhythm} and {Meaning} a},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1993.tb22975.x/abstract},
	urldate = {2015-07-30},
	volume = {682},
	year = {1993},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1993.tb22975.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1749-6632.1993.tb22975.x}}

@incollection{van_santen_prosodic_2008,
	author = {van Santen, Jan and Mishra, Taniya and Klabbers, Esther},
	booktitle = {Springer {Handbook} of {Speech} {Processing}},
	file = {ProsodicProcessing.pdf:/Users/Cecile/Zotero/storage/9V422AH2/ProsodicProcessing.pdf:application/pdf},
	pages = {471--488},
	publisher = {Springer},
	title = {Prosodic processing},
	url = {http://link.springer.com/10.1007/978-3-540-49127-9_23},
	urldate = {2016-09-19},
	year = {2008},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-3-540-49127-9_23}}

@article{park_frontal_nodate,
	abstract = {Summary
Humans show a remarkable ability to understand continuous speech even under adverse listening conditions. This ability critically relies on dynamically updated predictions of incoming sensory information, but exactly how top-down predictions improve speech processing is still unclear. Brain oscillations are a likely mechanism for these top-down predictions [1, 2]. Quasi-rhythmic components in speech are known to entrain low-frequency oscillations in auditory areas [3, 4], and this entrainment increases with intelligibility [5]. We hypothesize that top-down signals from frontal brain areas causally modulate the phase of brain oscillations in auditory cortex. We use magnetoencephalography (MEG) to monitor brain oscillations in 22 participants during continuous speech perception. We characterize prominent spectral components of speech-brain coupling in auditory cortex and use causal connectivity analysis (transfer entropy) to identify the top-down signals driving this coupling more strongly during intelligible speech than during unintelligible speech. We report three main findings. First, frontal and motor cortices significantly modulate the phase of speech-coupled low-frequency oscillations in auditory cortex, and this effect depends on intelligibility of speech. Second, top-down signals are significantly stronger for left auditory cortex than for right auditory cortex. Third, speech-auditory cortex coupling is enhanced as a function of stronger top-down signals. Together, our results suggest that low-frequency brain oscillations play a role in implementing predictive top-down control during continuous speech perception and that top-down control is largely directed at left auditory cortex. This suggests a close relationship between (left-lateralized) speech production areas and the implementation of top-down control in continuous speech perception.},
	author = {Park, Hyojin and Ince, Robin A. A. and Schyns, Philippe G. and Thut, Gregor and Gross, Joachim},
	doi = {10.1016/j.cub.2015.04.049},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/R843RC5W/Park et al. - Frontal Top-Down Signals Increase Coupling of Audi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/CQJ6PXX2/S096098221500500X.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	title = {Frontal {Top}-{Down} {Signals} {Increase} {Coupling} of {Auditory} {Low}-{Frequency} {Oscillations} to {Continuous} {Speech} in {Human} {Listeners}},
	url = {http://www.sciencedirect.com/science/article/pii/S096098221500500X},
	urldate = {2015-06-02},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S096098221500500X},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.04.049}}

@misc{noauthor_analyzing_nodate,
	abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, and LFP recordings.},
	file = {Snapshot:/Users/Cecile/Zotero/storage/SMANU6F7/analyzing-neural-time-series-data.html:text/html},
	journal = {MIT Press},
	title = {Analyzing {Neural} {Time} {Series} {Data}},
	url = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data},
	urldate = {2015-12-11},
	bdsk-url-1 = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data}}

@article{poeppel_pure_2001,
	abstract = {The analysis of pure word deafness (PWD) suggests that speech perception, construed as the integration of acoustic information to yield representations that enter into the linguistic computational system, (i) is separable in a modular sense from other aspects of auditory cognition and (ii) is mediated by the posterior superior temporal cortex in both hemispheres. PWD data are consistent with neuropsychological and neuroimaging evidence in a manner that suggests that the speech code is analyzed bilaterally. The typical lateralization associated with language processing is a property of the computational system that acts beyond the analysis of the input signal. The hypothesis of the bilateral mediation of the speech code does not imply that both sides execute the same computation. It is proposed that the speech signal is asymmetrically analyzed in the time domain, with left-hemisphere mechanisms preferentially extracting information over shorter (25--50 ms) temporal integration windows and right mechanisms over longer (150--250 ms) windows.},
	author = {Poeppel, David},
	doi = {10.1016/S0364-0213(01)00050-7},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8G2R2CUS/S0364021301000507.html:text/html},
	issn = {0364-0213},
	journal = {Cognitive Science},
	keywords = {Auditory agnosia, Hemispheric asymmetry, Imaging, Lesions, Neural basis of speech, Temporal processing, speech perception, Speech Perception},
	month = sep,
	number = {5},
	pages = {679--693},
	title = {Pure word deafness and the bilateral processing of the speech code},
	url = {http://www.sciencedirect.com/science/article/pii/S0364021301000507},
	urldate = {2014-06-01},
	volume = {25},
	year = {2001},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0364021301000507},
	bdsk-url-2 = {https://doi.org/10.1016/S0364-0213(01)00050-7}}

@article{santoro_encoding_2014,
	abstract = {Author Summary  How does the human brain analyze natural sounds? Previous functional neuroimaging research could only describe the response patterns that sounds evoke in the human brain at the level of preferential regional activations. A comprehensive account of the neural basis of human hearing, however, requires deriving computational models that are able to provide quantitative predictions of brain responses to natural sounds. Here, we make a significant step in this direction by combining functional magnetic resonance imaging (fMRI) with computational modeling. We compare competing computational models of sound representations and select the model that most accurately predicts the measured fMRI response patterns. The computational models describe the processing of three relevant properties of natural sounds: frequency, temporal modulations and spectral modulations. We find that a model that represents spectral and temporal modulations jointly and in a frequency-dependent fashion provides the best account of fMRI responses and that the functional specialization of auditory cortical fields can be partially accounted for by their modulation tuning. Our results provide insights on how natural sounds are encoded in human auditory cortex and our methodological approach constitutes an advance in the way this question can be addressed in future studies.},
	author = {Santoro, Roberta and Moerel, Michelle and Martino, Federico De and Goebel, Rainer and Ugurbil, Kamil and Yacoub, Essa and Formisano, Elia},
	doi = {10.1371/journal.pcbi.1003412},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/2U4H9PVT/Santoro et al. - 2014 - Encoding of Natural Sounds at Multiple Spectral an.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DFWMWMMH/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Comput Biol},
	keywords = {Permutation, Topographic maps, auditory system, behavior, Modulation, Neuronal tuning, functional magnetic resonance imaging, Auditory cortex},
	month = jan,
	number = {1},
	pages = {e1003412},
	title = {Encoding of {Natural} {Sounds} at {Multiple} {Spectral} and {Temporal} {Resolutions} in the {Human} {Auditory} {Cortex}},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003412},
	urldate = {2016-03-17},
	volume = {10},
	year = {2014},
	bdsk-url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003412},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1003412}}

@article{may_language_2011,
	abstract = {Previous research has shown that by the time of birth, the neonate brain responds specially to the native language when compared to acoustically similar non-language stimuli. In the current study, we use near-infrared spectroscopy to ask how prenatal language experience might shape the brain response to language in newborn infants. To do so, we examine the neural response of neonates when listening to familiar versus unfamiliar language, as well as to non language stimuli. Twenty monolingual English-exposed neonates aged 0-3 days were tested. Each infant heard low-pass filtered sentences of forward English (familiar language), forward Tagalog (unfamiliar language), and backward English and Tagalog (non-language). During exposure, neural activation was measured across 12 channels on each hemisphere. Our results indicate a bilateral effect of language familiarity on neonates' brain response to language. Differential brain activation was seen when neonates listened to forward Tagalog (unfamiliar language) as compared to other types of language stimuli. We interpret these results as evidence that the prenatal experience with the native language gained in utero influences how the newborn brain responds to language across brain regions sensitive to speech processing.},
	author = {May, Lillian and Byers-Heinlein, Krista and Gervain, Judit and Werker, Janet F},
	doi = {10.3389/fpsyg.2011.00222},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/AN5FPDXG/May et al. - 2011 - Language and the Newborn Brain Does Prenatal Lang.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in psychology},
	keywords = {Near-infrared spectroscopy, language, neonates},
	language = {eng},
	pages = {222},
	pmid = {21960980},
	shorttitle = {Language and the newborn brain},
	title = {Language and the newborn brain: does prenatal language experience shape the neonate neural response to speech?},
	volume = {2},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.3389/fpsyg.2011.00222}}

@article{minagawa-kawai_cerebral_2011,
	author = {Minagawa-Kawai, Yasuyo and Cristi{\`a}, Alejandrina and Dupoux, Emmanuel},
	doi = {10.1016/j.dcn.2011.03.005},
	file = {MinagawaKawaietal11.pdf:/Users/Cecile/Zotero/storage/F6EDV992/MinagawaKawaietal11.pdf:application/pdf},
	issn = {18789293},
	journal = {Developmental Cognitive Neuroscience},
	language = {en},
	month = jul,
	number = {3},
	pages = {217--232},
	shorttitle = {Cerebral lateralization and early speech acquisition},
	title = {Cerebral lateralization and early speech acquisition: {A} developmental scenario},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1878929311000302},
	urldate = {2014-05-29},
	volume = {1},
	year = {2011},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1878929311000302},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2011.03.005}}

@incollection{werner_morphological_2012,
	address = {New York, NY},
	author = {Eggermont, Jos J. and Moore, Jean K.},
	booktitle = {Human {Auditory} {Development}},
	editor = {Werner, Lynne and Fay, Richard R. and Popper, Arthur N.},
	file = {Morphological and Functional Development of the Auditory Nervous System_chapter.pdf:/Users/Cecile/Zotero/storage/XJRHEM7S/Morphological and Functional Development of the Auditory Nervous System_chapter.pdf:application/pdf},
	isbn = {978-1-4614-1420-9 978-1-4614-1421-6},
	pages = {61--105},
	publisher = {Springer New York},
	title = {Morphological and {Functional} {Development} of the {Auditory} {Nervous} {System}},
	url = {http://link.springer.com/10.1007/978-1-4614-1421-6_3},
	urldate = {2015-07-30},
	volume = {42},
	year = {2012},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-1-4614-1421-6_3}}

@article{rosen_temporal_1992,
	abstract = {The temporal properties of speech appear to play a more important role in linguistic contrasts than has hitherto been appreciated. Therefore, a new framework for describing the acoustic structure of speech based purely on temporal aspects has been developed. From this point of view, speech can be said to be comprised of three main temporal features, based on dominant fluctuation rates: envelope, periodicity, and fine-structure. Each feature has distinct acoustic manifestations, auditory and perceptual correlates, and roles in linguistic contrasts. The applicability of this three-featured temporal system is discussed in relation to hearing-impaired and normal listeners.},
	author = {Rosen, Stuart},
	doi = {10.1098/rstb.1992.0070},
	file = {Rosen 1992 Temporal info in speech.pdf:/Users/Cecile/Zotero/storage/7VSWFWTZ/Rosen 1992 Temporal info in speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8KZE74RP/367.html:text/html},
	issn = {0962-8436, 1471-2970},
	journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
	language = {en},
	month = jun,
	number = {1278},
	pages = {367--373},
	pmid = {1354376},
	shorttitle = {Temporal {Information} in {Speech}},
	title = {Temporal {Information} in {Speech}: {Acoustic}, {Auditory} and {Linguistic} {Aspects}},
	url = {http://rstb.royalsocietypublishing.org/content/336/1278/367},
	urldate = {2016-01-30},
	volume = {336},
	year = {1992},
	bdsk-url-1 = {http://rstb.royalsocietypublishing.org/content/336/1278/367},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.1992.0070}}

@article{decasper_prenatal_1986,
	abstract = {Pregnant women recited a particular speech passage aloud each day during their last 6 weeks of pregnancy. Their newborns were tested with an operant-choice procedure to determine whether the sounds of the recited passage were more reinforcing than the sounds of a novel passage. The previously recited passage was more reinforcing. The reinforcing value of the two passages did not differ for a matched group of control subjects. Thus, third-trimester fetuses experience their mothers' speech sounds and that prenatal auditory experience can influence postnatal auditory preferences.},
	author = {DeCasper, Anthony J. and Spence, Melanie J.},
	doi = {10.1016/0163-6383(86)90025-1},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/34NZAJPI/0163638386900251.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {Auditory Perception, fetal experience, maternal voice, newborn perception, prenatal learning, prenatal sensory experience, speech perception, Speech Perception},
	month = apr,
	number = {2},
	pages = {133--150},
	title = {Prenatal maternal speech influences newborns' perception of speech sounds},
	url = {http://www.sciencedirect.com/science/article/pii/0163638386900251},
	urldate = {2014-06-01},
	volume = {9},
	year = {1986},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0163638386900251},
	bdsk-url-2 = {https://doi.org/10.1016/0163-6383(86)90025-1}}

@article{garcia-lazaro_emergence_2011,
	abstract = {We have previously shown that neurons in primary auditory cortex (A1) of anaesthetized (ketamine/medetomidine) ferrets respond more strongly and reliably to dynamic stimuli whose statistics follow "natural" 1/f dynamics than to stimuli exhibiting pitch and amplitude modulations that are faster (1/f(0.5)) or slower (1/f(2)) than 1/f. To investigate where along the central auditory pathway this 1/f-modulation tuning arises, we have now characterized responses of neurons in the central nucleus of the inferior colliculus (ICC) and the ventral division of the mediate geniculate nucleus of the thalamus (MGV) to 1/f(γ) distributed stimuli with γ varying between 0.5 and 2.8. We found that, while the great majority of neurons recorded from the ICC showed a strong preference for the most rapidly varying (1/f(0.5) distributed) stimuli, responses from MGV neurons did not exhibit marked or systematic preferences for any particular γ exponent. Only in A1 did a majority of neurons respond with higher firing rates to stimuli in which γ takes values near 1. These results indicate that 1/f tuning emerges at forebrain levels of the ascending auditory pathway.},
	author = {Garcia-Lazaro, Jose A and Ahmed, Bashir and Schnupp, Jan W H},
	doi = {10.1371/journal.pone.0022584},
	issn = {1932-6203},
	journal = {PloS one},
	keywords = {Acoustic Stimulation, Animals, Auditory Pathways, Electrophysiology, Ferrets, Inferior Colliculi, Thalamus, Neurons},
	language = {eng},
	number = {8},
	pages = {e22584},
	pmid = {21850231},
	title = {Emergence of tuning to natural stimulus statistics along the central auditory pathway},
	volume = {6},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1371/journal.pone.0022584}}

@article{beauchemin_mother_2011,
	abstract = {In the mature adult brain, there are voice selective regions that are especially tuned to familiar voices. Yet, little is known about how the infant's brain treats such information. Here, we investigated, using electrophysiology and source analyses, how newborns process their mother's voice compared with that of a stranger. Results suggest that, shortly after birth, newborns distinctly process their mother's voice at an early preattentional level and at a later presumably cognitive level. Activation sources revealed that exposure to the maternal voice elicited early language-relevant processing, whereas the stranger's voice elicited more voice-specific responses. A central probably motor response was also observed at a later time, which may reflect an innate auditory-articulatory loop. The singularity of left-dominant brain activation pattern together with its ensuing sustained greater central activation in response to the mother's voice may provide the first neurophysiologic index of the preferential mother's role in language acquisition.},
	author = {Beauchemin, Maude and Gonz{\'a}lez-Frankenberger, Berta and Tremblay, Julie and Vannasing, Phetsamone and Mart{\'\i}nez-Montes, Eduardo and Belin, Pascal and B{\'e}land, Ren{\'e}e and Francoeur, Diane and Carceller, Ana-Maria and Wallois, Fabrice and Lassonde, Maryse},
	doi = {10.1093/cercor/bhq242},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IITUAC7E/Beauchemin et al. - 2011 - Mother and Stranger An Electrophysiological Study.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/35QU3P8H/1705.html:text/html},
	issn = {1047-3211, 1460-2199},
	journal = {Cerebral Cortex},
	keywords = {newborns, source analyses, voice processing, Mismatch negativity},
	language = {en},
	month = jan,
	number = {8},
	pages = {1705--1711},
	pmid = {21149849},
	shorttitle = {Mother and {Stranger}},
	title = {Mother and {Stranger}: {An} {Electrophysiological} {Study} of {Voice} {Processing} in {Newborns}},
	url = {http://cercor.oxfordjournals.org/content/21/8/1705},
	urldate = {2015-04-01},
	volume = {21},
	year = {2011},
	bdsk-url-1 = {http://cercor.oxfordjournals.org/content/21/8/1705},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhq242}}

@article{moerel_processing_2013,
	author = {Moerel, M. and De Martino, F. and Santoro, R. and Ugurbil, K. and Goebel, R. and Yacoub, E. and Formisano, E.},
	doi = {10.1523/JNEUROSCI.5306-12.2013},
	file = {Web of Knowledge [v.5.12] - All Databases Full Record:/Users/Cecile/Zotero/storage/PE9H7RQB/full_record.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	month = jul,
	number = {29},
	pages = {11888--11898},
	shorttitle = {Processing of {Natural} {Sounds}},
	title = {Processing of {Natural} {Sounds}: {Characterization} of {Multipeak} {Spectral} {Tuning} in {Human} {Auditory} {Cortex}},
	url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=3&SID=Y1kaUFcp3zqegByBfKv&page=1&doc=3},
	urldate = {2013-12-09},
	volume = {33},
	year = {2013},
	bdsk-url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=3&SID=Y1kaUFcp3zqegByBfKv&page=1&doc=3},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.5306-12.2013}}

@article{peelle_neural_2012,
	abstract = {A key feature of speech is the quasi-regular rhythmic information contained in its slow amplitude modulations. In this article we review the information conveyed by speech rhythm, and the role of ongoing brain oscillations in listeners' processing of this content. Our starting point is the fact that speech is inherently temporal, and that rhythmic information conveyed by the amplitude envelope contains important markers for place and manner of articulation, segmental information, and speech rate. Behavioral studies demonstrate that amplitude envelope information is relied upon by listeners and plays a key role in speech intelligibility. Extending behavioral findings, data from neuroimaging -- particularly electroencephalography (EEG) and magnetoencephalography (MEG) -- point to phase locking by ongoing cortical oscillations to low-frequency information ({\textasciitilde}4--8 Hz) in the speech envelope. This phase modulation effectively encodes a prediction of when important events (such as stressed syllables) are likely to occur, and acts to increase sensitivity to these relevant acoustic cues. We suggest a framework through which such neural entrainment to speech rhythm can explain effects of speech rate on word and segment perception (i.e., that the perception of phonemes and words in connected speech is influenced by preceding speech rate). Neuroanatomically, acoustic amplitude modulations are processed largely bilaterally in auditory cortex, with intelligible speech resulting in differential recruitment of left-hemisphere regions. Notable among these is lateral anterior temporal cortex, which we propose functions in a domain-general fashion to support ongoing memory and integration of meaningful input. Together, the reviewed evidence suggests that low-frequency oscillations in the acoustic speech signal form the foundation of a rhythmic hierarchy supporting spoken language, mirrored by phase-locked oscillations in the human brain.},
	author = {Peelle, Jonathan E. and Davis, Matthew H.},
	doi = {10.3389/fpsyg.2012.00320},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/W4A3DM74/Peelle et Davis - 2012 - Neural Oscillations Carry Speech Rhythm through to.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	month = sep,
	pmcid = {PMC3434440},
	pmid = {22973251},
	title = {Neural {Oscillations} {Carry} {Speech} {Rhythm} through to {Comprehension}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434440/},
	urldate = {2014-10-31},
	volume = {3},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434440/},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2012.00320}}

@article{nir_regional_2011,
	abstract = {Summary
The most prominent EEG events in sleep are slow waves, reflecting a slow (\&lt;1 Hz) oscillation between up and down states in cortical neurons. It is unknown whether slow oscillations are synchronous across the majority or the minority of brain regions---are they a global or local phenomenon? To examine this, we recorded simultaneously scalp EEG, intracerebral EEG, and unit firing in multiple brain regions of neurosurgical patients. We find that most sleep slow waves and the underlying active and inactive neuronal states occur locally. Thus, especially in late sleep, some regions can be active while others are silent. We also find that slow waves can propagate, usually from medial prefrontal cortex to the medial temporal lobe and hippocampus. Sleep spindles, the other hallmark of NREM sleep EEG, are likewise predominantly local. Thus, intracerebral communication during sleep is constrained because slow and spindle oscillations often occur out-of-phase in different brain regions.
Video Abstract},
	author = {Nir, Yuval and Staba, Richard J. and Andrillon, Thomas and Vyazovskiy, Vladyslav V. and Cirelli, Chiara and Fried, Itzhak and Tononi, Giulio},
	doi = {10.1016/j.neuron.2011.02.043},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JCRFCSPI/Nir et al. - 2011 - Regional Slow Waves and Spindles in Human Sleep.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5A6MHIJN/S0896627311001668.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = apr,
	number = {1},
	pages = {153--169},
	title = {Regional {Slow} {Waves} and {Spindles} in {Human} {Sleep}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627311001668},
	urldate = {2013-12-18},
	volume = {70},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627311001668},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2011.02.043}}

@article{massaro_motor_2008,
	author = {Massaro, D. W. and Chen, T. H.},
	doi = {10.3758/PBR.15.2.453},
	file = {Web of Knowledge [v.5.11] - Web of Science Full Record:/Users/Cecile/Zotero/storage/6F5FAICI/full_record.html:text/html},
	issn = {1069-9384, 1531-5320},
	journal = {Psychonomic Bulletin \& Review},
	month = apr,
	number = {2},
	pages = {453--457},
	title = {The motor theory of speech perception revisited},
	url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=8&SID=W2jwcCJ3GJscqSTzLfG&page=1&doc=5},
	urldate = {2013-09-16},
	volume = {15},
	year = {2008},
	bdsk-url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=8&SID=W2jwcCJ3GJscqSTzLfG&page=1&doc=5},
	bdsk-url-2 = {https://doi.org/10.3758/PBR.15.2.453}}

@article{dehaene-lambertz_functional_2002,
	abstract = {Human infants begin to acquire their native language in the first months of life. To determine which brain regions support language processing at this young age, we measured with functional magnetic resonance imaging the brain activity evoked by normal and reversed speech in awake and sleeping 3-month-old infants. Left-lateralized brain regions similar to those of adults, including the superior temporal and angular gyri, were already active in infants. Additional activation in right prefrontal cortex was seen only in awake infants processing normal speech. Thus, precursors of adult cortical language areas are already active in infants, well before the onset of speech production.},
	author = {Dehaene-Lambertz, Ghislaine and Dehaene, Stanislas and Hertz-Pannier, Lucie},
	doi = {10.1126/science.1077066},
	file = {2013.full.pdf:/Users/Cecile/Zotero/storage/EXG5YBDI/2013.full.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/UFTBSK4D/Dehaene-Lambertz et al. - 2002 - Functional Neuroimaging of Speech Perception in In.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GE28SSTG/2013.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jun,
	number = {5600},
	pages = {2013--2015},
	pmid = {12471265},
	title = {Functional {Neuroimaging} of {Speech} {Perception} in {Infants}},
	url = {http://www.sciencemag.org/content/298/5600/2013},
	urldate = {2014-01-20},
	volume = {298},
	year = {2002},
	bdsk-url-1 = {http://www.sciencemag.org/content/298/5600/2013},
	bdsk-url-2 = {https://doi.org/10.1126/science.1077066}}

@article{licklider_process_1952,
	abstract = {The process of speech perception is analyzed into three main operations: (1) translation of the speech signal into form suitable for the nervous system, (2) identification of discrete speech elements, and (3) comprehension of meaning. The first operation appears to correspond roughly to the transformation made by the sound spectrograph. The second may be carried out by the neural equivalent of a set of matched filters. The third appears to involve a neural form of cross‐correlation that exhibits some of the properties of the analogous electronic process.},
	author = {Licklider, J. C. R.},
	doi = {10.1121/1.1906938},
	file = {Snapshot:/Users/Cecile/Zotero/storage/TG6TE735/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Nervous system, Speech, Speech analysis, speech perception, Speech Perception},
	month = nov,
	number = {6},
	pages = {590--594},
	title = {On the {Process} of {Speech} {Perception}},
	url = {http://scitation.aip.org/content/asa/journal/jasa/24/6/10.1121/1.1906938},
	urldate = {2014-07-26},
	volume = {24},
	year = {1952},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/24/6/10.1121/1.1906938},
	bdsk-url-2 = {https://doi.org/10.1121/1.1906938}}

@article{yovel_unified_2013,
	abstract = {Both faces and voices are rich in socially-relevant information, which humans are remarkably adept at extracting, including a person's identity, age, gender, affective state, personality, etc. Here, we review accumulating evidence from behavioral, neuropsychological, electrophysiological, and neuroimaging studies which suggest that the cognitive and neural processing mechanisms engaged by perceiving faces or voices are highly similar, despite the very different nature of their sensory input. The similarity between the two mechanisms likely facilitates the multi-modal integration of facial and vocal information during everyday social interactions. These findings emphasize a parsimonious principle of cerebral organization, where similar computational problems in different modalities are solved using similar solutions.},
	author = {Yovel, Galit and Belin, Pascal},
	doi = {10.1016/j.tics.2013.04.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/XKPDESMC/Yovel et Belin - 2013 - A unified coding strategy for processing faces and.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EH8GT2MT/S1364661313000776.html:text/html},
	issn = {1364-6613},
	journal = {Trends in Cognitive Sciences},
	keywords = {Visual Cortex, face recognition, neural selectivity, sensory coding, voice recognition, Auditory cortex},
	month = jun,
	number = {6},
	pages = {263--271},
	title = {A unified coding strategy for processing faces and voices},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661313000776},
	urldate = {2017-03-09},
	volume = {17},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661313000776},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2013.04.004}}

@inproceedings{guiraud_adaptation_2013,
	author = {Guiraud, H{\'e}l{\`e}ne and Ferragne, Emmanuel and Bedoin, Nathalie and Boulenger, V{\'e}ronique},
	booktitle = {{INTERSPEECH}},
	file = {Guiraudetal13.pdf:/Users/Cecile/Zotero/storage/S2E7HCF8/Guiraudetal13.pdf:application/pdf},
	pages = {1370--1374},
	publisher = {Citeseer},
	title = {Adaptation to natural fast speech and time-compressed speech in children.},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.3884&rep=rep1&type=pdf},
	urldate = {2015-10-02},
	year = {2013},
	bdsk-url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.3884&rep=rep1&type=pdf}}

@article{luo_phase_2007,
	abstract = {Summary
How natural speech is represented in the auditory cortex constitutes a major challenge for cognitive neuroscience. Although many single-unit and neuroimaging studies have yielded valuable insights about the processing of speech and matched complex sounds, the mechanisms underlying the analysis of speech dynamics in human auditory cortex remain largely unknown. Here, we show that the phase pattern of theta band (4--8 Hz) responses recorded from human auditory cortex with magnetoencephalography (MEG) reliably tracks and discriminates spoken sentences and that this discrimination ability is correlated with speech intelligibility. The findings suggest that an ∼200 ms temporal window (period of theta oscillation) segments the incoming speech signal, resetting and sliding to track speech dynamics. This hypothesized mechanism for cortical speech analysis is based on the stimulus-induced modulation of inherent cortical rhythms and provides further evidence implicating the syllable as a computational primitive for the representation of spoken language.},
	author = {Luo, Huan and Poeppel, David},
	doi = {10.1016/j.neuron.2007.06.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/3DBK6VTX/Luo et Poeppel - 2007 - Phase Patterns of Neuronal Responses Reliably Disc.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NM26FX4W/S0896627307004138.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {SYSNEURO},
	month = jun,
	number = {6},
	pages = {1001--1010},
	title = {Phase {Patterns} of {Neuronal} {Responses} {Reliably} {Discriminate} {Speech} in {Human} {Auditory} {Cortex}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627307004138},
	urldate = {2014-10-21},
	volume = {54},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627307004138},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2007.06.004}}

@article{ramus_language_2002,
	abstract = {Speech rhythm has long been claimed to be a useful bootstrapping cue in the very first steps of language acquisition. Previous studies have suggested that newborn infants do categorize varieties of speech rhythm, as demonstrated by their ability to discriminate between certain languages. However, the existing evidence is not unequivocal: in previous studies, stimuli discriminated by newborns always contained additional speech cues on top of rhythm. Here, we conducted a series of experiments assessing discrimination between Dutch and Japanese by newborn infants, using a speech resynthesis technique to progressively degrade non-rhythmical properties of the sentences. When the stimuli are resynthesized using identical phonemes and artificial intonation contours for the two languages, thereby preserving only their rhythmic and broad phonotactic structure, newborns still seem to be able to discriminate between the two languages, but the effect is weaker than when intonation is present. This leaves open the possibility that the temporal correlation between intonational and rhythmic cues might actually facilitate the processing of speech rhythm.},
	author = {Ramus, Franck},
	doi = {10.1075/arla.2.05ram},
	file = {Ramus - 2002 - Language discrimination by newborns Teasing apart.pdf:/Users/Cecile/Zotero/storage/2CBXYQPJ/Ramus - 2002 - Language discrimination by newborns Teasing apart.pdf:application/pdf},
	journal = {Annual Review of Language Acquisition},
	keywords = {Bootstrapping, Language discrimination, Newborn Speech Perception, Rhythm, Intonation, prosody},
	number = {1},
	pages = {85--115},
	shorttitle = {Language discrimination by newborns},
	title = {Language discrimination by newborns: {Teasing} apart phonotactic, rhythmic, and intonational cues},
	volume = {2},
	year = {2002},
	bdsk-url-1 = {https://doi.org/10.1075/arla.2.05ram}}

@article{atick_could_1991,
	abstract = {The sensory pathways of animals are well adapted to processing a special class of signals, namely stimuli from the animal's environment. An important fact about natural stimuli is that they are typically very redundant and hence the sampled representation of these signals formed by the array of sensory cells is inefficient. One could argue for some animals and pathways, as we do in this review, that efficiency of information representation in the nervous system has several evolutionary advantages. Consequently, one might expect that much of the processing in the early levels of these sensory pathways could be dedicated towards recoding incoming signals into a more efficient form. In this review, we explore the principle of efficiency of information representation as a design principle for sensory processing. We give a preliminary discussion on how this principle could be applied in general to predict neural processing and then discuss concretely some neural systems where it recently has been shown to be successful. In particular, we examine the fly's LMC coding strategy and the mammalian retinal coding in the spatial, temporal and chromatic domains.},
	author = {Atick, Joseph J},
	doi = {10.3109/0954898X.2011.638888},
	file = {Atick_1992.pdf:/Users/Cecile/Zotero/storage/GNEZX6JW/Atick_1992.pdf:application/pdf},
	issn = {1361-6536},
	journal = {Network (Bristol, England)},
	keywords = {Animals, Ecology, Humans, Information Theory, Neural Networks (Computer), Neural Pathways},
	language = {eng},
	number = {1-4},
	pages = {4--44},
	pmid = {22149669},
	title = {Could information theory provide an ecological theory of sensory processing?},
	volume = {22},
	year = {1991},
	bdsk-url-1 = {https://doi.org/10.3109/0954898X.2011.638888}}

@article{bieser_auditory_1996,
	abstract = {The neural response to amplitude-modulated sinus sounds (AM sound) was investigated in the auditory cortex and insula of the awake squirrel monkey. It was found that 78.1\% of all acoustically driven neurons encoded the envelope of the AM sound; the remaining 21.9\% displayed simple On, On/Off or Off responses at the beginning or the end of the stimulus sound. Those neurons with AM coding were able to encode the AM sound frequency in two different ways: (1) the spikes followed the amplitude modulation envelopes in a phase locked manner; (2) the spike rate changed significantly with changing modulation frequencies. As reported in other species, the modulation transfer functions for rate showed higher modulation frequencies than the phase-locked response. Both AM codings exhibited a filter characteristic for AM sound. Whereas 46.6\% of all neurons had the same filter characteristic for both the spike discharge and the phase-locked response, the remaining neurons displayed combinations of different filter types. The discharge pattern of a neuron to simple tone or noise bursts suggests the behaviour of this neuron when AM sound is used as the stimulus. Neurons with strong onset responses to tone/noise bursts tended to have higher phase-locked AM responses than neurons with weak onset responses. The spike rate maxima for AM sound showed no relation to the tone/noise burst discharge patterns. Varying modulation depth was encoded by the neuron's ability to follow the envelope cycles and not by the non-phase-locked spike rate frequency. The organization of the squirrel monkey's auditory cortex has previously been established by an anatomical study. We have added two new fields using physiological parameters. All fields investigated showed a clear functional separation for time-critical information processing. The best temporal resolution was shown by the primary auditory field (AI), the first-temporal field (T1) and the parainsular auditory field (Pi). The neural data in these fields and the amplitude modulation frequency range of squirrel monkey calls suggest a similar correlation between vocalization and perception as in human psychophysical data for speech and hearing sensation. The anterior fields in particular failed to follow the AM envelopes. For the first time in a primate, the insula was tested with different sound parameters ranging from simple tone bursts to AM sound. It is suggested that this cortical region plays a role in time-critical aspects of acoustic information processing. The observed best frequencies covered the same spectrum as AI. As in the auditory fields, most neurons in the insula encoded AM sound with different filter types. The high proportion of neurons unable to encode AM sound (40.6\%) and the low mean best modulation frequency (9.9 Hz) do not support a prominent role of the insula in temporal information processing.},
	author = {Bieser, A. and M{\"u}ller-Preuss, P.},
	issn = {0014-4819},
	journal = {Experimental Brain Research},
	keywords = {Acoustic Stimulation, Animals, Auditory Perception, Evoked Potentials, Auditory, Neurons, Afferent, Noise, Pitch Perception, Saimiri, Auditory cortex},
	language = {eng},
	month = mar,
	number = {2},
	pages = {273--284},
	pmid = {8815035},
	shorttitle = {Auditory responsive cortex in the squirrel monkey},
	title = {Auditory responsive cortex in the squirrel monkey: neural responses to amplitude-modulated sounds},
	volume = {108},
	year = {1996}}

@article{obleser_neural_2012,
	author = {Obleser, Jonas and Herrmann, Bjorn and Henry, Molly J.},
	doi = {10.3389/fnhum.2012.00250},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/K3V4W2AZ/Obleser et al. - 2012 - Neural Oscillations in Speech Don't be Enslaved b.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = aug,
	pmcid = {PMC3431501},
	pmid = {22969717},
	shorttitle = {Neural {Oscillations} in {Speech}},
	title = {Neural {Oscillations} in {Speech}: {Don}'t be {Enslaved} by the {Envelope}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431501/},
	urldate = {2014-10-31},
	volume = {6},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431501/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2012.00250}}

@phdthesis{turner_statistical_2010,
	abstract = {It is important to understand the rich structure of natural sounds in order to solve important
tasks, like automatic speech recognition, and to understand auditory processing
in the brain. This thesis takes a step in this direction by characterising the statistics of
simple natural sounds. We focus on the statistics because perception often appears to
depend on them, rather than on the raw waveform. For example the perception of auditory
textures, like running water, wind, fire and rain, depends on summary-statistics,
like the rate of falling rain droplets, rather than on the exact details of the physical
source.
In order to analyse the statistics of sounds accurately it is necessary to improve a
number of traditional signal processing methods, including those for amplitude demodulation,
time-frequency analysis, and sub-band demodulation. These estimation tasks
are ill-posed and therefore it is natural to treat them as Bayesian inference problems.
The new probabilistic versions of these methods have several advantages. For example,
they perform more accurately on natural signals and are more robust to noise,
they can also fill-in missing sections of data, and provide error-bars. Furthermore,
free-parameters can be learned from the signal. Using these new algorithms we demonstrate
that the energy, sparsity, modulation depth and modulation time-scale in each
sub-band of a signal are critical statistics, together with the dependencies between the
sub-band modulators. In order to validate this claim, a model containing co-modulated
coloured noise carriers is shown to be capable of generating a range of realistic sounding
auditory textures.
Finally, we explored the connection between the statistics of natural sounds and perception.
We demonstrate that inference in the model for auditory textures qualitatively
replicates the primitive grouping rules that listeners use to understand simple acoustic
scenes. This suggests that the auditory system is optimised for the statistics of natural
sounds.},
	author = {Turner, R. E.},
	copyright = {open},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ZDT7GCDI/Turner - 2010 - Statistical models for natural sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U8NV8BEP/19231.html:text/html},
	language = {eng},
	month = jan,
	school = {UCL (University College London)},
	title = {Statistical models for natural sounds},
	type = {Doctoral},
	url = {http://eprints.ucl.ac.uk/19231/},
	urldate = {2013-12-13},
	year = {2010},
	bdsk-url-1 = {http://eprints.ucl.ac.uk/19231/}}

@article{spierings_zebra_2014,
	abstract = {Variation in pitch, amplitude and rhythm adds crucial paralinguistic information to human speech. Such prosodic cues can reveal information about the meaning or emphasis of a sentence or the emotional state of the speaker. To examine the hypothesis that sensitivity to prosodic cues is language independent and not human specific, we tested prosody perception in a controlled experiment with zebra finches. Using a go/no-go procedure, subjects were trained to discriminate between speech syllables arranged in XYXY patterns with prosodic stress on the first syllable and XXYY patterns with prosodic stress on the final syllable. To systematically determine the salience of the various prosodic cues (pitch, duration and amplitude) to the zebra finches, they were subjected to five tests with different combinations of these cues. The zebra finches generalized the prosodic pattern to sequences that consisted of new syllables and used prosodic features over structural ones to discriminate between stimuli. This strong sensitivity to the prosodic pattern was maintained when only a single prosodic cue was available. The change in pitch was treated as more salient than changes in the other prosodic features. These results show that zebra finches are sensitive to the same prosodic cues known to affect human speech perception.},
	author = {Spierings, Michelle J. and ten Cate, Carel},
	copyright = {{\copyright} 2014 The Author(s) Published by the Royal Society. All rights reserved.},
	doi = {10.1098/rspb.2014.0480},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/3GC3W45F/Spierings et Cate - 2014 - Zebra finches are sensitive to prosodic features o.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9FHVNZ5T/20140480.html:text/html},
	issn = {0962-8452, 1471-2954},
	journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	language = {en},
	month = jul,
	number = {1787},
	pages = {20140480},
	pmid = {24870039},
	title = {Zebra finches are sensitive to prosodic features of human speech},
	url = {http://rspb.royalsocietypublishing.org/content/281/1787/20140480},
	urldate = {2015-12-07},
	volume = {281},
	year = {2014},
	bdsk-url-1 = {http://rspb.royalsocietypublishing.org/content/281/1787/20140480},
	bdsk-url-2 = {https://doi.org/10.1098/rspb.2014.0480}}

@article{gerhardt_cochlear_1992,
	abstract = {Purpose: Sounds present within the uterus stimulate the fetal inner ear and central auditory pathway. This study was undertaken to determine the efficiency of transmission of exogenous airborne stimuli to the fetal inner ear. In this way, we may quantify the extent to which the fetal auditory system is isolated from sounds produced outside the mother.

Materials and Methods: Cochlear microphonics were recorded from fetal and newborn sheep to evaluate the extent to which the fetus is isolated from sounds exogenous to the ewe. Electrodes were surgically placed in contact with the round window membrane in nine near-term fetal sheep. Cochlear microphonics were recorded in response to 13 octave-band noises (0.125 to 2.0 kHz) delivered through a loudspeaker 1.8 m from one side of the pregnant ewe. Sound pressure levels generated by the noises were simultaneously recorded ex utero with a microphone and in utero with a hydrophone previously sutured to the fetal neck. After cochlear microphonic amplitudes were recorded, the fetus was delivered through an abdominal incision. Recordings were repeated from the newborn lamb. Fetal sound isolation was calculated as the difference between the sound pressure levels that were necessary to evoke equal cochlear microphonic amplitudes from the fetus and from the newborn lamb.

Results: The sound attenuation observed was variable for all frequencies. The fetus was isolated from external sounds by 11.1 dB for 0.125 kHz, 19.8 dB for 0.25 kHz, 35.3 dB for 0.5 kHz, 38.2 dB for 1.0 kHz, and 45.0 dB for 2.0 kHz.

Conclusions: Other investigators have demonstrated that the immature auditory system is more susceptible to damage produced by noise exposure than is the mature auditory system. Low-frequency noise produces damaged cells that later in life code higher frequencies. A possibility of fetal hearing loss produced by intense noise exposure needs more careful evaluation.},
	author = {Gerhardt, Kenneth J and Otto, Randal and Abrams, Robert M and Colle, Joy J and Burchfield, David J and Peters, Aemil J. M},
	doi = {10.1016/0196-0709(92)90026-P},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IJKBZ79T/Gerhardt et al. - 1992 - Cochlear microphonics recorded from fetal and newb.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7PN66QQ4/019607099290026P.html:text/html},
	issn = {0196-0709},
	journal = {American Journal of Otolaryngology},
	month = jul,
	number = {4},
	pages = {226--233},
	title = {Cochlear microphonics recorded from fetal and newborn sheep},
	url = {http://www.sciencedirect.com/science/article/pii/019607099290026P},
	urldate = {2016-01-30},
	volume = {13},
	year = {1992},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/019607099290026P},
	bdsk-url-2 = {https://doi.org/10.1016/0196-0709(92)90026-P}}

@article{minagawa-kawai_insights_2013,
	abstract = {Each language has a unique set of phonemic categories and phonotactic rules which determine permissible sound sequences in that language. Behavioral research demonstrates that one's native language shapes the perception of both sound categories and sound sequences in adults, and neuroimaging results further indicate that the processing of native phonemes and phonotactics involves a left-dominant perisylvian brain network. Recent work using a novel technique, functional Near InfraRed Spectroscopy (NIRS), has suggested that a left-dominant network becomes evident toward the end of the first year of life as infants process phonemic contrasts. The present research project attempted to assess whether the same pattern would be seen for native phonotactics. We measured brain responses in Japanese- and French-learning infants to two contrasts: Abuna vs. Abna (a phonotactic contrast that is native in French, but not in Japanese) and Abuna vs. Abuuna (a vowel length contrast that is native in Japanese, but not in French). Results did not show a significant response to either contrast in either group, unlike both previous behavioral research on phonotactic processing and NIRS work on phonemic processing. To understand these null results, we performed similar NIRS experiments with Japanese adult participants. These data suggest that the infant null results arise from an interaction of multiple factors, involving the suitability of the experimental paradigm for NIRS measurements and stimulus perceptibility. We discuss the challenges facing this novel technique, particularly focusing on the optimal stimulus presentation which could yield strong enough hemodynamic responses when using the change detection paradigm.},
	author = {Minagawa-Kawai, Yasuyo and Cristia, Alejandrina and Long, Bria and Vendelin, Inga and Hakuno, Yoko and Dutat, Michel and Filippin, Luca and Cabrol, Dominique and Dupoux, Emmanuel},
	doi = {10.3389/fpsyg.2013.00170},
	journal = {Language Sciences},
	keywords = {Infant, near infrared spectroscopy, phoneme perception, phonotactics, speech perception, Speech Perception},
	pages = {170},
	title = {Insights on {NIRS} sensitivity from a cross-linguistic study on the emergence of phonological grammar},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00170/abstract},
	urldate = {2016-03-28},
	volume = {4},
	year = {2013},
	bdsk-url-1 = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00170/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2013.00170}}

@article{pena_sounds_2003,
	abstract = {Does the neonate's brain have left hemisphere (LH) dominance for speech? Twelve full-term neonates participated in an optical topography study designed to assess whether the neonate brain responds specifically to linguistic stimuli. Participants were tested with normal infant-directed speech, with the same utterances played in reverse and without auditory stimulation. We used a 24-channel optical topography device to assess changes in the concentration of total hemoglobin in response to auditory stimulation in 12 areas of the right hemisphere and 12 areas of the LH. We found that LH temporal areas showed significantly more activation when infants were exposed to normal speech than to backward speech or silence. We conclude that neonates are born with an LH superiority to process specific properties of speech.},
	author = {Pe{\~n}a, Marcela and Maki, Atsushi and Kovacic, Damir and Dehaene-Lambertz, Ghislaine and Koizumi, Hideaki and Bouquet, Furio and Mehler, Jacques},
	doi = {10.1073/pnas.1934290100},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/F673HJHG/Pena et al. - 2003 - Sounds and silence An optical topography study of.pdf:application/pdf},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	month = sep,
	number = {20},
	pages = {11702--11705},
	pmcid = {PMC208821},
	pmid = {14500906},
	shorttitle = {Sounds and silence},
	title = {Sounds and silence: {An} optical topography study of language recognition at birth},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC208821/},
	urldate = {2013-06-18},
	volume = {100},
	year = {2003},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC208821/},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1934290100}}

@article{telkemeyer_sensitivity_2009,
	abstract = {Understanding the rapidly developing building blocks of speech perception in infancy requires a close look at the auditory prerequisites for speech sound processing. Pioneering studies have demonstrated that hemispheric specializations for language processing are already present in early infancy. However, whether these computational asymmetries can be considered a function of linguistic attributes or a consequence of basic temporal signal properties is under debate. Several studies in adults link hemispheric specialization for certain aspects of speech perception to an asymmetry in cortical tuning and reveal that the auditory cortices are differentially sensitive to spectrotemporal features of speech. Applying concurrent electrophysiological (EEG) and hemodynamic (near-infrared spectroscopy) recording to newborn infants listening to temporally structured nonspeech signals, we provide evidence that newborns process nonlinguistic acoustic stimuli that share critical temporal features with language in a differential manner. The newborn brain preferentially processes temporal modulations especially relevant for phoneme perception. In line with multi-time-resolution conceptions, modulations on the time scale of phonemes elicit strong bilateral cortical responses. Our data furthermore suggest that responses to slow acoustic modulations are lateralized to the right hemisphere. That is, the newborn auditory cortex is sensitive to the temporal structure of the auditory input and shows an emerging tendency for functional asymmetry. Hence, our findings support the hypothesis that development of speech perception is linked to basic capacities in auditory processing. From birth, the brain is tuned to critical temporal properties of linguistic signals to facilitate one of the major needs of humans: to communicate.},
	author = {Telkemeyer, Silke and Rossi, Sonja and Koch, Stefan P. and Nierhaus, Till and Steinbrink, Jens and Poeppel, David and Obrig, Hellmuth and Wartenburger, Isabell},
	doi = {10.1523/JNEUROSCI.1246-09.2009},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/EMWR48U6/Telkemeyer et al. - 2009 - Sensitivity of Newborn Auditory Cortex to the Temp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JUNBPS7R/14726.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = nov,
	number = {47},
	pages = {14726--14733},
	pmid = {19940167},
	title = {Sensitivity of {Newborn} {Auditory} {Cortex} to the {Temporal} {Structure} of {Sounds}},
	url = {http://www.jneurosci.org/content/29/47/14726},
	urldate = {2015-02-06},
	volume = {29},
	year = {2009},
	bdsk-url-1 = {http://www.jneurosci.org/content/29/47/14726},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1246-09.2009}}

@article{friederici_brain_2007,
	author = {Friederici, Angela D. and Friedrich, Manuela and Christophe, Anne},
	doi = {10.1016/j.cub.2007.06.011},
	file = {Friedericietal07.pdf:/Users/Cecile/Zotero/storage/EWQRG8J4/Friedericietal07.pdf:application/pdf},
	issn = {09609822},
	journal = {Current Biology},
	language = {en},
	month = jul,
	number = {14},
	pages = {1208--1211},
	title = {Brain {Responses} in 4-{Month}-{Old} {Infants} {Are} {Already} {Language} {Specific}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982207015114},
	urldate = {2015-07-30},
	volume = {17},
	year = {2007},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0960982207015114},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2007.06.011}}

@article{dehaene-lambertz_language_2010,
	abstract = {Understanding how language emerged in our species calls for a detailed investigation of the initial specialization of the human brain for speech processing. Our earlier research demonstrated that an adult-like left-lateralized network of perisylvian areas is already active when infants listen to sentences in their native language, but did not address the issue of the specialization of this network for speech processing. Here we used fMRI to study the organization of brain activity in two-month-old infants when listening to speech or to music. We also explored how infants react to their mother's voice relative to an unknown voice. The results indicate that the well-known structural asymmetry already present in the infants' posterior temporal areas has a functional counterpart: there is a left-hemisphere advantage for speech relative to music at the level of the planum temporale. The posterior temporal regions are thus differently sensitive to the auditory environment very early on, channelling speech inputs preferentially to the left side. Furthermore, when listening to the mother's voice, activation was modulated in several areas, including areas involved in emotional processing (amygdala, orbito-frontal cortex), but also, crucially, a large extent of the left posterior temporal lobe, suggesting that the mother's voice plays a special role in the early shaping of posterior language areas. Both results underscore the joint contributions of genetic constraints and environmental inputs in the fast emergence of an efficient cortical network for language processing in humans.},
	author = {Dehaene-Lambertz, G and Montavont, A and Jobert, A and Allirol, L and Dubois, J and Hertz-Pannier, L and Dehaene, S},
	doi = {10.1016/j.bandl.2009.09.003},
	issn = {1090-2155},
	journal = {Brain and language},
	keywords = {Acoustic Stimulation, Amygdala, Auditory Pathways, Female, Frontal Lobe, Humans, Infant, Language Development, Male, Mothers, Music, Phonetics, Temporal Lobe, Voice, speech perception, Auditory cortex, Magnetic resonance imaging, Speech Perception},
	language = {eng},
	month = aug,
	number = {2},
	pages = {53--65},
	pmid = {19864015},
	shorttitle = {Language or music, mother or {Mozart}?},
	title = {Language or music, mother or {Mozart}? {Structural} and environmental influences on infants' language networks},
	volume = {114},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1016/j.bandl.2009.09.003}}

@article{schnupp_plasticity_2006,
	abstract = {It has been suggested that ``call-selective'' neurons may play an important role in the encoding of vocalizations in primary auditory cortex (A1). For example, marmoset A1 neurons often respond more vigorously to natural than to time-reversed twitter calls, although the spectral energy distribution in the natural and time-reversed signals is the same. Neurons recorded in cat A1, in contrast, showed no such selectivity for natural marmoset calls. To investigate whether call selectivity in A1 can arise purely as a result of auditory experience, we recorded responses to marmoset calls in A1 of naive ferrets, as well as in ferrets that had been trained to recognize these natural marmoset calls. We found that training did not induce call selectivity for the trained vocalizations in A1. However, although ferret A1 neurons were not call selective, they efficiently represented the vocalizations through temporal pattern codes, and trained animals recognized marmoset twitters with a high degree of accuracy. These temporal patterns needed to be analyzed at timescales of 10--50 ms to ensure efficient decoding. Training led to a substantial increase in the amount of information transmitted by these temporal discharge patterns, but the fundamental nature of the temporal pattern code remained unaltered. These results emphasize the importance of temporal discharge patterns and cast doubt on the functional significance of call-selective neurons in the processing of animal communication sounds at the level of A1.},
	author = {Schnupp, Jan W. H. and Hall, Thomas M. and Kokelaar, Rory F. and Ahmed, Bashir},
	doi = {10.1523/JNEUROSCI.4330-05.2006},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UR3V7GVA/Schnupp et al. - 2006 - Plasticity of Temporal Pattern Codes for Vocalizat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QQIXQDAT/4785.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	keywords = {Sound, behavior, temporal coding, training, vocalization, Auditory cortex},
	language = {en},
	month = mar,
	number = {18},
	pages = {4785--4795},
	pmid = {16672651},
	title = {Plasticity of {Temporal} {Pattern} {Codes} for {Vocalization} {Stimuli} in {Primary} {Auditory} {Cortex}},
	url = {http://www.jneurosci.org/content/26/18/4785},
	urldate = {2015-07-15},
	volume = {26},
	year = {2006},
	bdsk-url-1 = {http://www.jneurosci.org/content/26/18/4785},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.4330-05.2006}}

@article{abboub_prosodic_2016,
	abstract = {Experience with spoken language starts prenatally, as hearing becomes operational during the second half of gestation. While maternal tissues filter out many aspects of speech, they readily transmit speech prosody and rhythm. These properties of the speech signal then play a central role in early language acquisition. In this study, we ask how the newborn brain uses variation in duration, pitch and intensity (the three acoustic cues that carry prosodic information in speech) to group sounds. In four near-infrared spectroscopy studies (NIRS), we demonstrate that perceptual biases governing how sound sequences are perceived and organized are present in newborns from monolingual and bilingual language backgrounds. Importantly, however, these prosodic biases are present only for acoustic patterns found in the prosody of their native languages. These findings advance our understanding of how prenatal language experience lays the foundations for language development.},
	author = {Abboub, Nawal and Nazzi, Thierry and Gervain, Judit},
	doi = {10.1016/j.bandl.2016.08.002},
	issn = {1090-2155},
	journal = {Brain and Language},
	keywords = {Newborn infants, Perceptual biases, Prenatal exposure, Prosodic grouping, bilingualism, Near-infrared spectroscopy},
	language = {ENG},
	month = aug,
	pages = {46--59},
	pmid = {27567401},
	title = {Prosodic grouping at birth},
	volume = {162},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1016/j.bandl.2016.08.002}}

@article{friederici_lateralization_2004,
	abstract = {Spoken language comprehension requires the coordination of different subprocesses in time. After the initial acoustic analysis the system has to extract segmental information such as phonemes, syntactic elements and lexical-semantic elements as well as suprasegmental information such as accentuation and intonational phrases, i.e., prosody. According to the dynamic dual pathway model of auditory language comprehension syntactic and semantic information are primarily processed in a left hemispheric temporo-frontal pathway including separate circuits for syntactic and semantic information whereas sentence level prosody is processed in a right hemispheric temporo-frontal pathway. The relative lateralization of these functions occurs as a result of stimulus properties and processing demands. The observed interaction between syntactic and prosodic information during auditory sentence comprehension is attributed to dynamic interactions between the two hemispheres.},
	author = {Friederici, Angela D and Alter, Kai},
	doi = {10.1016/S0093-934X(03)00351-1},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RTBN92UT/Friederici et Alter - 2004 - Lateralization of auditory language functions A d.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TIBKV57Q/S0093934X03003511.html:text/html},
	issn = {0093-934X},
	journal = {Brain and Language},
	month = may,
	number = {2},
	pages = {267--276},
	series = {Language and {MotorIntegration}},
	shorttitle = {Lateralization of auditory language functions},
	title = {Lateralization of auditory language functions: {A} dynamic dual pathway model},
	url = {http://www.sciencedirect.com/science/article/pii/S0093934X03003511},
	urldate = {2016-01-30},
	volume = {89},
	year = {2004},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X03003511},
	bdsk-url-2 = {https://doi.org/10.1016/S0093-934X(03)00351-1}}

@article{shi_infant_2011,
	abstract = {Background
Studies for infants are usually hindered by the insufficient image contrast, especially for neonates. Prior knowledge, in the form of atlas, can provide additional guidance for the data processing such as spatial normalization, label propagation, and tissue segmentation. Although it is highly desired, there is currently no such infant atlas which caters for all these applications. The reason may be largely due to the dramatic early brain development, image processing difficulties, and the need of a large sample size. 
         
         
           Methodology 
           To this end, after several years of subject recruitment and data acquisition, we have collected a unique longitudinal dataset, involving 95 normal infants (56 males and 39 females) with MRI scanned at 3 ages, i.e., neonate, 1-year-old, and 2-year-old. State-of-the-art MR image segmentation and registration techniques were employed, to construct which include the templates (grayscale average images), tissue probability maps (TPMs), and brain parcellation maps (i.e., meaningful anatomical regions of interest) for each age group. In addition, the longitudinal correspondences between age-specific atlases were also obtained. Experiments of typical infant applications validated that the proposed atlas outperformed other atlases and is hence very useful for infant-related studies. 
         
         
           Conclusions 
           We expect that the proposed infant 0--1--2 brain atlases would be significantly conducive to structural and functional studies of the infant brains. These atlases are publicly available in our website,  http://bric.unc.edu/ideagroup/free-softwares/ .},
	author = {Shi, Feng and Yap, Pew-Thian and Wu, Guorong and Jia, Hongjun and Gilmore, John H. and Lin, Weili and Shen, Dinggang},
	doi = {10.1371/journal.pone.0018746},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/N42XSPWJ/Shi et al. - 2011 - Infant Brain Atlases from Neonates to 1- and 2-Yea.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZGUNHVQG/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Age groups, Deformation, Imaging techniques, neuroimaging, Infants, neonates, Brain, Magnetic resonance imaging},
	month = apr,
	number = {4},
	pages = {e18746},
	title = {Infant {Brain} {Atlases} from {Neonates} to 1- and 2-{Year}-{Olds}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018746},
	urldate = {2016-09-28},
	volume = {6},
	year = {2011},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018746},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0018746}}

@article{price_review_2012,
	author = {Price, Cathy J.},
	doi = {https://dx-doi-org.frodon.univ-paris5.fr/10.1016/j.neuroimage.2012.04.062},
	file = {A review and synthesis of the first 20years of PET and fMRI studies of heard speech, spoken language and reading:/Users/Cecile/Zotero/storage/9XNWIMTP/S1053811912004703.html:text/html;Price12.pdf:/Users/Cecile/Zotero/storage/ZEH7XXBG/Price12.pdf:application/pdf},
	journal = {NeuroImage},
	month = aug,
	number = {2},
	pages = {816--847},
	title = {A review and synthesis of the first 20years of {PET} and {fMRI} studies of heard speech, spoken language and reading},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811912004703},
	urldate = {2014-06-01},
	volume = {62},
	year = {2012},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811912004703},
	bdsk-url-2 = {https://dx-doi-org.frodon.univ-paris5.fr/10.1016/j.neuroimage.2012.04.062}}

@article{lewicki_information_2010,
	abstract = {Approaches that abandon traditional speech categories offer promise for developing statistical descriptions that encapsulate how speech conveys information. Grandparents would be among the beneficiaries.},
	author = {Lewicki, Michael S.},
	copyright = {{\copyright} 2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/466821a},
	file = {A Signal Take On Speech:/Users/Cecile/Zotero/storage/NHHVZGCB/Lewicki10ASignalTakeOnSpeech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XZ4ZCZ8J/466821a.html:text/html},
	issn = {0028-0836},
	journal = {Nature},
	language = {en},
	month = aug,
	number = {7308},
	pages = {821--822},
	shorttitle = {Information theory},
	title = {Information theory: {A} signal take on speech},
	url = {http://www.nature.com/nature/journal/v466/n7308/full/466821a.html?message-global=remove},
	urldate = {2015-02-04},
	volume = {466},
	year = {2010},
	bdsk-url-1 = {http://www.nature.com/nature/journal/v466/n7308/full/466821a.html?message-global=remove},
	bdsk-url-2 = {https://doi.org/10.1038/466821a}}

@article{sharpee_hierarchical_2011,
	abstract = {Understanding the neural mechanisms of invariant object recognition remains one of the major unsolved problems in neuroscience. A common solution that is thought to be employed by diverse sensory systems is to create hierarchical representations of increasing complexity and tolerance. However, in the mammalian auditory system many aspects of this hierarchical organization remain undiscovered, including the prominent classes of high-level representations (that would be analogous to face selectivity in the visual system or selectivity to bird's own song in the bird) and the dominant types of invariant transformations. Here we review the recent progress that begins to probe the hierarchy of auditory representations, and the computational approaches that can be helpful in achieving this feat.},
	author = {Sharpee, Tatyana O. and Atencio, Craig A. and Schreiner, Christoph E.},
	doi = {10.1016/j.conb.2011.05.027},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NWS9KRXF/S095943881100095X.html:text/html},
	issn = {1873-6882},
	journal = {Current Opinion in Neurobiology},
	keywords = {Acoustic Stimulation, Animals, Auditory Pathways, Computer Simulation, Humans, Models, Biological, Auditory cortex},
	language = {eng},
	month = oct,
	number = {5},
	pages = {761--767},
	pmcid = {PMC3223290},
	pmid = {21704508},
	title = {Hierarchical representations in the auditory cortex},
	volume = {21},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1016/j.conb.2011.05.027}}

@article{toga_mapping_2006,
	abstract = {Human brain maturation is a complex, lifelong process that can now be examined in detail using neuroimaging techniques. Ongoing projects scan subjects longitudinally with structural magnetic resonance imaging (MRI), enabling the time-course and anatomical sequence of development to be reconstructed. Here, we review recent progress on imaging studies of development. We focus on cortical and subcortical changes observed in healthy children, and contrast them with abnormal developmental changes in early-onset schizophrenia, fetal alcohol syndrome, attention-deficit--hyperactivity disorder (ADHD) and Williams syndrome. We relate these structural changes to the cellular processes that underlie them, and to cognitive and behavioral changes occurring throughout childhood and adolescence.},
	author = {Toga, Arthur W. and Thompson, Paul M. and Sowell, Elizabeth R.},
	doi = {10.1016/j.tins.2006.01.007},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/M84B7UKC/Toga et al. - 2006 - Mapping brain maturation.pdf:application/pdf},
	issn = {0166-2236},
	journal = {Trends in neurosciences},
	month = mar,
	number = {3},
	pages = {148--159},
	pmcid = {PMC3113697},
	pmid = {16472876},
	title = {Mapping brain maturation},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3113697/},
	urldate = {2017-02-09},
	volume = {29},
	year = {2006},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3113697/},
	bdsk-url-2 = {https://doi.org/10.1016/j.tins.2006.01.007}}

@article{binder_human_2000,
	abstract = {Functional organization of the lateral temporal cortex in humans is not well understood. We recorded blood oxygenation signals from the temporal lobes of normal volunteers using functional magnetic resonance imaging during stimulation with unstructured noise, frequency-modulated (FM) tones, reversed speech, pseudowords and words. For all conditions, subjects performed a material- nonspecific detection response when a train of stimuli began or ceased. Dorsal areas surrounding Heschl's gyrus bilaterally, particularly the planum temporale and dorsolateral superior temporal gyrus, were more strongly activated by FM tones than by noise, suggesting a role in processing simple temporally encoded auditory information. Distinct from these dorsolateral areas, regions centered in the superior temporal sulcus bilaterally were more activated by speech stimuli than by FM tones. Identical results were obtained in this region using words, pseudowords and reversed speech, suggesting that the speech--tones activation difference is due to acoustic rather than linguistic factors. In contrast, previous comparisons between word and nonword speech sounds showed left-lateralized activation differences in more ventral temporal and temporoparietal regions that are likely involved in processing lexical--semantic or syntactic information associated with words. The results indicate functional subdivision of the human lateral temporal cortex and provide a preliminary framework for understanding the cortical processing of speech sounds.},
	author = {Binder, J. R. and Frost, J. A. and Hammeke, T. A. and Bellgowan, P. S. F. and Springer, J. A. and Kaufman, J. N. and Possing, E. T.},
	doi = {10.1093/cercor/10.5.512},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KNRFNDHU/Binder et al. - 2000 - Human Temporal Lobe Activation by Speech and Nonsp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H5QAGS44/512.html:text/html},
	issn = {1047-3211, 1460-2199},
	journal = {Cerebral Cortex},
	language = {en},
	month = jan,
	number = {5},
	pages = {512--528},
	pmid = {10847601},
	title = {Human {Temporal} {Lobe} {Activation} by {Speech} and {Nonspeech} {Sounds}},
	url = {http://cercor.oxfordjournals.org/content/10/5/512},
	urldate = {2013-12-15},
	volume = {10},
	year = {2000},
	bdsk-url-1 = {http://cercor.oxfordjournals.org/content/10/5/512},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/10.5.512}}

@article{attneave_informational_1954,
	author = {Attneave, Fred},
	doi = {10.1037/h0054663},
	file = {Web of Knowledge [v.5.11] - Web of Science Full Record:/Users/Cecile/Zotero/storage/C9ZXMBX9/full_record.html:text/html},
	issn = {0033-295X},
	journal = {Psychological Review},
	number = {3},
	pages = {183--193},
	title = {Some informational aspects of visual perception.},
	url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=1&SID=P2ojBCV1Rdt1XniwInN&page=1&doc=1},
	urldate = {2013-10-23},
	volume = {61},
	year = {1954},
	bdsk-url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=1&SID=P2ojBCV1Rdt1XniwInN&page=1&doc=1},
	bdsk-url-2 = {https://doi.org/10.1037/h0054663}}

@article{gratton_toward_2000,
	abstract = {The event-related optical signal (EROS) has been recently proposed as a method for studying noninvasively the time course of activity in localized cortical areas (G. Gratton and M. Fabiani, 1998, Psychonomic Bull. Rev. 5: 535--563). Previous data have shown that EROS has very good temporal resolution and can provide detailed surface activity maps. In the present study we investigated whether the depth of the active area can also be estimated. Nine subjects were run in a study in which the eccentricity of the visual stimuli was varied, and EROS was recorded from medial occipital areas using multiple source--detector distances. Seven of the same subjects were also run through a functional magnetic resonance imaging (fMRI) study using the same protocol. The fMRI data indicated that the depth from the head surface to the cortical area activated increased systematically with the eccentricity of the visual stimuli. The EROS recording indicated a response with a latency of 60--80 ms from stimulation. This response varied systematically with eccentricity, so that the greater the eccentricity of the stimuli, the longer the source--detector distance (and thus the depth) at which the EROS effect was observed. The depth of the brain area generating the EROS effect was estimated using a simple algorithm derived from phantom studies on homogeneous media. The average depth estimates for each eccentricity condition obtained with EROS corresponded with those obtained with fMRI, with discrepancies of less than 1 mm. These data demonstrate that multiple source--detector distances can be used to estimate the depth of the cortical areas responsible for the EROS effects.},
	author = {Gratton, Gabriele and Sarno, Anita and Maclin, Ed and Corballis, Paul M. and Fabiani, Monica},
	doi = {10.1006/nimg.2000.0565},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GHNUQWZF/S1053811900905652.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {event-related optical signal (EROS), functional magnetic resonance imaging (fMRI), tridimensional reconstruction, functional brain imaging},
	month = may,
	number = {5},
	pages = {491--504},
	shorttitle = {Toward {Noninvasive} 3-{D} {Imaging} of the {Time} {Course} of {Cortical} {Activity}},
	title = {Toward {Noninvasive} 3-{D} {Imaging} of the {Time} {Course} of {Cortical} {Activity}: {Investigation} of the {Depth} of the {Event}-{Related} {Optical} {Signal}},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811900905652},
	urldate = {2016-11-26},
	volume = {11},
	year = {2000},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811900905652},
	bdsk-url-2 = {https://doi.org/10.1006/nimg.2000.0565}}

@article{sato_development_2010,
	abstract = {Infants' speech perception abilities change through the first year of life, from broad sensitivity to a wide range of speech contrasts to becoming more finely attuned to their native language. What remains unclear, however, is how this perceptual change relates to brain responses to native language contrasts in terms of the functional specialization of the left and right hemispheres. Here, to elucidate the developmental changes in functional lateralization accompanying this perceptual change, we conducted two experiments on Japanese infants using Japanese lexical pitch-accent, which changes word meanings with the pitch pattern within words. In the first behavioral experiment, using visual habituation, we confirmed that infants at both 4 and 10 months have sensitivities to the lexical pitch- accent pattern change embedded in disyllabic words. In the second experiment, near-infrared spectroscopy was used to measure cortical hemodynamic responses in the left and right hemispheres to the same lexical pitch-accent pattern changes and their pure tone counterparts. We found that brain responses to the pitch change within words differed between 4- and 10-month-old infants in terms of functional lateralization: Left hemisphere dominance for the perception of the pitch change embedded in words was seen only in the 10-month-olds. These results suggest that the perceptual change in Japanese lexical pitch-accent may be related to a shift in functional lateralization from bilateral to left hemisphere dominance.},
	author = {Sato, Yutaka and Sogabe, Yuko and Mazuka, Reiko},
	file = {Satoetal2010.pdf:/Users/Cecile/Zotero/storage/IUTX9JB2/Satoetal2010.pdf:application/pdf},
	issn = {0898929X},
	journal = {Journal of Cognitive Neuroscience},
	keywords = {COGNITIVE development, KNOWLEDGE acquisition (Expert systems), CEREBRAL dominance, NEWBORN infants -- Development, JAPAN, Lexical access},
	month = nov,
	number = {11},
	pages = {2503--2513},
	title = {Development of {Hemispheric} {Specialization} for {Lexical} {Pitch}-{Accent} in {Japanese} {Infants}},
	url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=52409177&lang=fr&site=eds-live&scope=site},
	urldate = {2016-09-28},
	volume = {22},
	year = {2010},
	bdsk-url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=52409177&lang=fr&site=eds-live&scope=site}}

@article{giraud_cortical_2012,
	abstract = {Neuronal oscillations are ubiquitous in the brain and may contribute to cognition in several ways: for example, by segregating information and organizing spike timing. Recent data show that delta, theta and gamma oscillations are specifically engaged by the multi-timescale, quasi-rhythmic properties of speech and can track its dynamics. We argue that they are foundational in speech and language processing, 'packaging' incoming information into units of the appropriate temporal granularity. Such stimulus-brain alignment arguably results from auditory and motor tuning throughout the evolution of speech and language and constitutes a natural model system allowing auditory research to make a unique contribution to the issue of how neural oscillatory activity affects human cognition.},
	author = {Giraud, Anne-Lise and Poeppel, David},
	doi = {10.1038/nn.3063},
	file = {GiraudPoeppel12.pdf:/Users/Cecile/Zotero/storage/QPVWAZ46/GiraudPoeppel12.pdf:application/pdf;GiraudPoeppel2012.pdf:/Users/Cecile/Zotero/storage/GQ8V52UZ/GiraudPoeppel2012.pdf:application/pdf},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	keywords = {Acoustic Stimulation, Brain Mapping, Brain Waves, Computational Biology, Cortical Synchronization, Humans, Nerve Net, Speech, speech perception, Auditory cortex, Speech Perception, Action potentials},
	language = {eng},
	month = apr,
	number = {4},
	pages = {511--517},
	pmid = {22426255},
	shorttitle = {Cortical oscillations and speech processing},
	title = {Cortical oscillations and speech processing: emerging computational principles and operations},
	volume = {15},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1038/nn.3063}}

@article{kobayashi_processing_2014,
	abstract = {Using near-infrared spectroscopy (NIRS), our previous neural adaptation studies found that infants' bilateral temporal regions process facial identity (FiHN 5:153, 2011). In addition, we revealed that size-invariant processing of facial identity develops by 5 months of age (NR 23:984-988, 2012), while view-invariant processing develops around 7 months of age (FiHN 5:153, 2011). The aim in the current study was to examine whether infants' brains process facial identity across the non-rigid transformation of facial features by using the neural adaptation paradigm. We used NIRS to compare hemodynamic changes in the bilateral temporal areas of 5- to 6-month-olds and 7- to 8-month-olds during presentations of an identical face and of different faces.},
	author = {Kobayashi, Megumi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	doi = {10.1186/1471-2202-15-81},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DAJEXRSC/art%3A10.1186%2F1471-2202-15-81.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JFZK942J/1471-2202-15-81.html:text/html},
	issn = {1471-2202},
	journal = {BMC Neuroscience},
	pages = {81},
	shorttitle = {The processing of faces across non-rigid facial transformation develops at 7 month of age},
	title = {The processing of faces across non-rigid facial transformation develops at 7 month of age: a {fNIRS}-adaptation study},
	url = {http://dx.doi.org/10.1186/1471-2202-15-81},
	urldate = {2016-09-28},
	volume = {15},
	year = {2014},
	bdsk-url-1 = {http://dx.doi.org/10.1186/1471-2202-15-81}}

@article{carruthers_encoding_2013,
	abstract = {One of the central tasks of the mammalian auditory system is to represent information about acoustic communicative signals, such as vocalizations. However, the neuronal computations underlying vocalization encoding in the central auditory system are poorly understood. To learn how the rat auditory cortex encodes information about conspecific vocalizations, we presented a library of natural and temporally transformed ultrasonic vocalizations (USVs) to awake rats while recording neural activity in the primary auditory cortex (A1) with chronically implanted multielectrode probes. Many neurons reliably and selectively responded to USVs. The response strength to USVs correlated strongly with the response strength to frequency-modulated (FM) sweeps and the FM rate tuning index, suggesting that related mechanisms generate responses to USVs as to FM sweeps. The response strength further correlated with the neuron's best frequency, with the strongest responses produced by neurons whose best frequency was in the ultrasonic frequency range. For responses of each neuron to each stimulus group, we fitted a novel predictive model: a reduced generalized linear-nonlinear model (GLNM) that takes the frequency modulation and single-tone amplitude as the only two input parameters. The GLNM accurately predicted neuronal responses to previously unheard USVs, and its prediction accuracy was higher than that of an analogous spectrogram-based linear-nonlinear model. The response strength of neurons and the model prediction accuracy were higher for original, rather than temporally transformed, vocalizations. These results indicate that A1 processes original USVs differentially than transformed USVs, indicating preference for temporal statistics of the original vocalizations.},
	author = {Carruthers, Isaac M. and Natan, Ryan G. and Geffen, Maria N.},
	copyright = {Copyright {\copyright} 2013 the American Physiological Society. Licensed under Creative Commons Attribution CC-BY 3.0: the American Physiological Society.},
	doi = {10.1152/jn.00483.2012},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4WR3MD7S/Carruthers et al. - 2013 - Encoding of ultrasonic vocalizations in the audito.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4JQA2274/1912.html:text/html},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = apr,
	number = {7},
	pages = {1912--1927},
	pmid = {23324323},
	title = {Encoding of ultrasonic vocalizations in the auditory cortex},
	url = {http://jn.physiology.org.gate1.inist.fr/content/109/7/1912},
	urldate = {2016-01-15},
	volume = {109},
	year = {2013},
	bdsk-url-1 = {http://jn.physiology.org.gate1.inist.fr/content/109/7/1912},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00483.2012}}

@article{vouloumanos_why_2007,
	author = {Vouloumanos, Athena and Werker, Janet F.},
	copyright = {{\copyright} 2007 The Authors. Journal compilation {\copyright} 2007 Blackwell Publishing Ltd},
	doi = {10.1111/j.1467-7687.2007.00551.x},
	file = {Snapshot:/Users/Cecile/Zotero/storage/X36EAV6Q/abstract.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	number = {2},
	pages = {169--171},
	title = {Why voice melody alone cannot explain neonates' preference for speech},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00551.x/abstract},
	urldate = {2013-06-17},
	volume = {10},
	year = {2007},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00551.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00551.x}}

@article{malach_targeting_2012,
	author = {Malach, Rafael},
	doi = {10.1016/j.neuroimage.2012.01.002},
	issn = {10538119},
	journal = {NeuroImage},
	language = {en},
	month = aug,
	number = {2},
	pages = {1163--1169},
	title = {Targeting the functional properties of cortical neurons using {fMR}-adaptation},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811912000055},
	urldate = {2016-09-28},
	volume = {62},
	year = {2012},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1053811912000055},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.002}}

@article{poremba_processing_2013,
	abstract = {Abundant evidence from both field and lab studies has established that conspecific vocalizations (CVs) are of critical ecological significance for a wide variety of species, including humans, non-human primates, rodents, and other mammals and birds. Correspondingly, a number of experiments have demonstrated behavioral processing advantages for CVs, such as in discrimination and memory tasks. Further, a wide range of experiments have described brain regions in many species that appear to be specialized for processing CVs. For example, several neural regions have been described in both mammals and birds wherein greater neural responses are elicited by CVs than by comparison stimuli such as heterospecific vocalizations, nonvocal complex sounds, and artificial stimuli. These observations raise the question of whether these regions reflect domain-specific neural mechanisms dedicated to processing CVs, or alternatively, if these regions reflect domain-general neural mechanisms for representing complex sounds of learned significance. Inasmuch as CVs can be viewed as complex combinations of basic spectrotemporal features, the plausibility of the latter position is supported by a large body of literature describing modulated cortical and subcortical representation of a variety of acoustic features that have been experimentally associated with stimuli of natural behavioral significance (such as food rewards). Herein, we review a relatively small body of existing literature describing the roles of experience, learning, and memory in the emergence of species-typical neural representations of CVs and auditory system plasticity. In both songbirds and mammals, manipulations of auditory experience as well as specific learning paradigms are shown to modulate neural responses evoked by CVs, either in terms of overall firing rate or temporal firing patterns. In some cases, CV-sensitive neural regions gradually acquire representation of non-CV stimuli with which subjects have training and experience. These results parallel literature in humans describing modulation of responses in face-sensitive neural regions through learning and experience. Thus, although many questions remain, the available evidence is consistent with the notion that CVs may acquire distinct neural representation through domain-general mechanisms for representing complex auditory objects that are of learned importance to the animal.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	author = {Poremba, Amy and Bigelow, James and Rossi, Breein},
	doi = {10.1016/j.heares.2013.06.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ED4CGVB9/Poremba et al. - 2013 - Processing of communication sounds Contributions .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9RXRMVM3/S0378595513001482.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	keywords = {oiseau},
	month = nov,
	pages = {31--44},
	series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	shorttitle = {Processing of communication sounds},
	title = {Processing of communication sounds: {Contributions} of learning, memory, and experience},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513001482},
	urldate = {2014-11-03},
	volume = {305},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001482},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.06.005}}

@article{nourski_auditory_2017,
	abstract = {Objective

Direct electrophysiological recordings in epilepsy patients offer an opportunity to study human auditory cortical processing with unprecedented spatiotemporal resolution. This review highlights recent intracranial studies of human auditory cortex and focuses on its basic response properties as well as modulation of cortical activity during the performance of active behavioral tasks.
Data Sources: Literature review.
Review Methods: A review of the literature was conducted to summarize the functional organization of human auditory and auditory-related cortex as revealed using intracranial recordings.


Results

The tonotopically organized core auditory cortex within the posteromedial portion of Heschl's gyrus represents spectrotemporal features of sounds with high temporal precision and short response latencies. At this level of processing, high gamma (70--150 Hz) activity is minimally modulated by task demands. Non-core cortex on the lateral surface of the superior temporal gyrus also maintains representation of stimulus acoustic features and, for speech, subserves transformation of acoustic inputs into phonemic representations. High gamma responses in this region are modulated by task requirements. Prefrontal cortex exhibits complex response patterns, related to stimulus intelligibility and task relevance. At this level of auditory processing, activity is strongly modulated by task requirements and reflects behavioral performance.


Conclusions

Direct recordings from the human brain reveal hierarchical organization of sound processing within auditory and auditory-related cortex.


Level of Evidence

Level V},
	author = {Nourski, Kirill V.},
	doi = {10.1002/lio2.73},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/B8X6MH5G/Nourski - 2017 - Auditory processing in the human cortex An intrac.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q2UBD7JZ/abstract.html:text/html},
	issn = {2378-8038},
	journal = {Laryngoscope Investigative Otolaryngology},
	keywords = {Superior temporal gyrus, Electrocorticography, Heschl's gyrus, high gamma},
	language = {en},
	month = apr,
	pages = {n/a--n/a},
	shorttitle = {Auditory processing in the human cortex},
	title = {Auditory processing in the human cortex: {An} intracranial electrophysiology perspective},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/lio2.73/abstract},
	urldate = {2017-05-21},
	year = {2017},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/lio2.73/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/lio2.73}}

@article{bank_regulation_2006,
	abstract = {The human globin genes are among the most extensively characterized in the human genome, yet the details of the molecular events regulating normal human hemoglobin switching and the potential reactivation of fetal hemoglobin in adult hematopoietic cells remain elusive. Recent discoveries demonstrate physical interactions between the β locus control region and the downstream structural γ- and β-globin genes, and with transcription factors and chromatin remodeling complexes. These interactions all play roles in globin gene expression and globin switching at the human β-globin locus. If the molecular events in hemoglobin switching were better understood and fetal hemoglobin could be more fully reactivated in adult cells, the insights obtained might lead to new approaches to the therapy of sickle cell disease and β thalassemia by identifying specific new targets for molecular therapies.},
	author = {Bank, Arthur},
	doi = {10.1182/blood-2005-05-2113},
	issn = {0006-4971},
	journal = {Blood},
	month = jan,
	number = {2},
	pages = {435--443},
	pmcid = {PMC1895603},
	pmid = {16109777},
	shorttitle = {Regulation of human fetal hemoglobin},
	title = {Regulation of human fetal hemoglobin: new players, new complexities},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1895603/},
	urldate = {2017-02-27},
	volume = {107},
	year = {2006},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1895603/},
	bdsk-url-2 = {https://doi.org/10.1182/blood-2005-05-2113}}

@article{mehler_precursor_1988,
	abstract = {Four-day-old French and 2-month-old American infants distinguish utterances in their native languages from those of another language. In contrast, neither group gave evidence of distinguishing utterances from two foreign languages. A series of control experiments confirmed that the ability to distinguish utterances from two different languages appears to depend upon some familiarity with at least one of the two languages. Finally, two experiments with low-pass-filtered versions of the samples replicated the main findings of discrimination of the native language utterances. These latter results suggest that the basis for classifying utterances from the native language may be provided by prosodic cues.},
	author = {Mehler, Jacques and Jusczyk, Peter and Lambertz, Ghislaine and Halsted, Nilofar and Bertoncini, Josiane and Amiel-Tison, Claudine},
	doi = {10.1016/0010-0277(88)90035-2},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/3G4GNBQ9/Mehler et al. - 1988 - A precursor of language acquisition in young infan.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/M5N548DS/0010027788900352.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	month = jul,
	number = {2},
	pages = {143--178},
	title = {A precursor of language acquisition in young infants},
	url = {http://www.sciencedirect.com/science/article/pii/0010027788900352},
	urldate = {2016-01-26},
	volume = {29},
	year = {1988},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0010027788900352},
	bdsk-url-2 = {https://doi.org/10.1016/0010-0277(88)90035-2}}

@article{sebastian-galles_adaptation_2000,
	abstract = {Perceptual adaptation to time-compressed speech was analyzed in two experiments. Previous research has suggested that this adaptation phenomenon is language specific and takes place at the phonological level. Moreover, it has been proposed that adaptation should only be observed for languages that are rhythmically similar. This assumption was explored by studying adaptation to different time-compressed languages in Spanish speakers. In Experiment 1, the performances of Spanish-speaking subjects who adapted to Spanish, Italian, French, English, and Japanese were compared. In Experiment 2, subjects from the same population were tested with Greek sentences compressed to two different rates. The results showed adaptation for Spanish, Italian, and Greek and no adaptation for English and Japanese, with French being an intermediate case. To account for the data, we propose that variables other than just the rhythmic properties of the languages, such as the vowel system and/or the lexical stress pattern, must be considered. The Greek data also support the view that phonological, rather than lexical, information is a determining factor in adaptation to compressed speech.},
	author = {Sebasti{\'a}n-Gall{\'e}s, N{\'u}ria and Dupoux, Emmanuel and Costa, Albert and Mehler, Jacques},
	doi = {10.3758/BF03206926},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/B3SS5G8V/Sebasti{\'a}n-Gall{\'e}s et al. - 2000 - Adaptation to time-compressed speech Phonological.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4QNFTNZQ/BF03206926.html:text/html},
	issn = {0031-5117, 1532-5962},
	journal = {Perception \& Psychophysics},
	keywords = {Cognitive Psychology},
	language = {en},
	month = jan,
	number = {4},
	pages = {834--842},
	shorttitle = {Adaptation to time-compressed speech},
	title = {Adaptation to time-compressed speech: {Phonological} determinants},
	url = {http://link.springer.com/article/10.3758/BF03206926},
	urldate = {2015-07-15},
	volume = {62},
	year = {2000},
	bdsk-url-1 = {http://link.springer.com/article/10.3758/BF03206926},
	bdsk-url-2 = {https://doi.org/10.3758/BF03206926}}

@article{beasley_childrens_1976,
	abstract = {Time-compressed versions of the Word Intelligibility by Picture Identification (WIPI) and H. A. Haskins's PB-K 50 speech discrimination measures were presented at 2 sensation levels to 60 children divided into 3 age-groups (3.5-4.5, 5.5-6.5, and 7.5-8.5 yrs) of 20 each. Results show that average intelligibility scores increased as a function of age and sensation level and decreased with increasing amounts of time compression. The PB-K 50 measure was more difficult than the WIPI for each age group under each condition of time compression and sensation level. Several interactions were also found. Results are discussed in terms of open- vs closed-message set response tasks and the implications for audiological diagnoses of children with central auditory processing problems. (22 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	author = {Beasley, Daniel S. and Maki, Jean E. and Orchik, Daniel J.},
	issn = {0022-4677},
	journal = {Journal of Speech \& Hearing Disorders},
	keywords = {Age Differences, Auditory Discrimination, Diagnosis, Speech and Hearing Measures, time compression \& sensation level \& age, speech discrimination measure \& intelligibility scores, 3-8 yr olds with normal speech \& language, implications for audiological diagnosis of central auditory processing problems, speech perception, Speech Perception},
	month = may,
	number = {2},
	pages = {216--225},
	title = {Children's perception of time-compressed speech on two measures of speech discrimination},
	volume = {41},
	year = {1976}}

@article{vouloumanos_detection_2001,
	author = {Vouloumanos, Athena and Kiehl, Kent A. and Werker, Janet F. and Liddle, Peter F.},
	doi = {10.1162/089892901753165890},
	file = {Web of Knowledge [v.5.10] - Web of Science Full Record:/Users/Cecile/Zotero/storage/NP5AIE2Q/full_record.html:text/html},
	issn = {0898-929X, 1530-8898},
	journal = {Journal of Cognitive Neuroscience},
	month = oct,
	number = {7},
	pages = {994--1005},
	shorttitle = {Detection of {Sounds} in the {Auditory} {Stream}},
	title = {Detection of {Sounds} in the {Auditory} {Stream}: {Event}-{Related} {fMRI} {Evidence} for {Differential} {Activation} to {Speech} and {Nonspeech}},
	url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=9&SID=P2539gp3JpbfaaifH6k&page=1&doc=1},
	urldate = {2013-07-17},
	volume = {13},
	year = {2001},
	bdsk-url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=9&SID=P2539gp3JpbfaaifH6k&page=1&doc=1},
	bdsk-url-2 = {https://doi.org/10.1162/089892901753165890}}

@book{winer_auditory_2010,
	abstract = {There has been substantial progress in understanding the contributions of the auditory forebrain to hearing, sound localization, communication, emotive behavior, and cognition.  The Auditory Cortex covers the latest knowledge about the auditory forebrain, including the auditory cortex as well as the medial geniculate body in the thalamus.  This book will cover all important aspects of the auditory forebrain organization and function, integrating the auditory thalamus and cortex into a smooth, coherent whole.  Volume One covers basic auditory neuroscience.  It complements The Auditory Cortex, Volume 2: Integrative Neuroscience, which takes a more applied/clinical perspective.},
	author = {Winer, Jeffery A. and Schreiner, Christoph E.},
	isbn = {978-1-4419-0074-6},
	keywords = {Medical / Neurology, Medical / Neuroscience, Medical / Otorhinolaryngology, Science / Life Sciences / Neuroscience, Science / Life Sciences / Zoology / General},
	language = {en},
	month = dec,
	publisher = {Springer Science \& Business Media},
	title = {The {Auditory} {Cortex}},
	year = {2010}}

@article{pallier_perceptual_1998,
	abstract = {Previous research has shown that, when hearers listen to artificially speeded speech, their performance improves over the course of 10--15 sentences, as if their perceptual system was ``adapting'' to these fast rates of speech. In this paper, we further investigate the mechanisms that are responsible for such effects. In Experiment 1, we report that, for bilingual speakers of Catalan and Spanish, exposure to compressed sentences in either language improves performance on sentences in the other language. Experiment 2 reports that Catalan/Spanish transfer of performance occurs even in monolingual speakers of Spanish who do not understand Catalan. In Experiment 3, we study another pair of languages--- namely, English and French---and report no transfer of adaptation between these two languages for English---French bilinguals. Experiment 4, with monolingual English speakers, assesses transfer of adaptation from French, Dutch, and English toward English. Here we find that there is no adaptation from French and intermediate adaptation from Dutch. We discuss the locus of the adaptation to compressed speech and relate our findings to other cross-linguistic studies in speech perception.},
	author = {Pallier, Christophe and Sebastian-Gall{\'e}s, Nuria and Dupoux, Emmanuel and Christophe, Anne and Mehler, Jacques},
	doi = {10.3758/BF03211403},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KZT7BKSC/Pallier et al. - 1998 - Perceptual adjustment to time-compressed speech A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J2HXN82W/BF03211403.html:text/html},
	issn = {0090-502X, 1532-5946},
	journal = {Memory \& Cognition},
	keywords = {Cognitive Psychology},
	language = {en},
	month = jul,
	number = {4},
	pages = {844--851},
	shorttitle = {Perceptual adjustment to time-compressed speech},
	title = {Perceptual adjustment to time-compressed speech: {A} cross-linguistic study},
	url = {http://link.springer.com/article/10.3758/BF03211403},
	urldate = {2014-01-20},
	volume = {26},
	year = {1998},
	bdsk-url-1 = {http://link.springer.com/article/10.3758/BF03211403},
	bdsk-url-2 = {https://doi.org/10.3758/BF03211403}}

@article{rieke_naturalistic_1995,
	abstract = {Natural sounds, especially communication sounds, have highly structured amplitude and phase spectra. We have quantified how structure in the amplitude spectrum of natural sounds affects coding in primary auditory afferents. Auditory afferents encode stimuli with naturalistic amplitude spectra dramatically better than broad-band stimuli (approximating white noise); the rate at which the spike train carries information about the stimulus is 2-6 times higher for naturalistic sounds. Furthermore, the information rates can reach 90\% of the fundamental limit to information transmission set by the statistics of the spike response. These results indicate that the coding strategy of the auditory nerve is matched to the structure of natural sounds; this `tuning' allows afferent spike trains to provide higher processing centres with a more complete description of the sensory world.},
	author = {Rieke, F. and Bodnar, D. A. and Bialek, W.},
	doi = {10.1098/rspb.1995.0204},
	file = {Snapshot:/Users/Cecile/Zotero/storage/TU54VMWS/259.html:text/html},
	issn = {0962-8452, 1471-2954},
	journal = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
	language = {en},
	month = dec,
	number = {1365},
	pages = {259--265},
	pmid = {8587884},
	title = {Naturalistic {Stimuli} {Increase} the {Rate} and {Efficiency} of {Information} {Transmission} by {Primary} {Auditory} {Afferents}},
	url = {http://rspb.royalsocietypublishing.org/content/262/1365/259},
	urldate = {2014-05-24},
	volume = {262},
	year = {1995},
	bdsk-url-1 = {http://rspb.royalsocietypublishing.org/content/262/1365/259},
	bdsk-url-2 = {https://doi.org/10.1098/rspb.1995.0204}}

@article{bortfeld_identifying_2009,
	abstract = {We investigate the utility of near-infrared spectroscopy (NIRS) as an alternative technique for studying infant speech processing. NIRS is an optical imaging technology that uses relative changes in total hemoglobin concentration and oxygenation as an indicator of neural activation. Procedurally, NIRS has the advantage over more common methods (e.g., fMRI) in that it can be used to study the neural responses of behaviorally active infants. Older infants (aged 6--9 months) were allowed to sit on their caretakers' laps during stimulus presentation to determine relative differences in focal activity in the temporal region of the brain during speech processing. Results revealed a dissociation of sensory-specific processing in two cortical regions, the left and right temporal lobes. These findings are consistent with those obtained using other neurophysiological methods and point to the utility of NIRS as a means of establishing neural correlates of language development in older (and more active) infants.},
	author = {Bortfeld, Heather and Fava, Eswen and Boas, David A.},
	doi = {10.1080/87565640802564481},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FEHMUI7Z/Bortfeld et al. - 2009 - Identifying Cortical Lateralization of Speech Proc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AH97PBRP/87565640802564481.html:text/html},
	issn = {8756-5641},
	journal = {Developmental Neuropsychology},
	month = jan,
	number = {1},
	pages = {52--65},
	pmid = {19142766},
	title = {Identifying {Cortical} {Lateralization} of {Speech} {Processing} in {Infants} {Using} {Near}-{Infrared} {Spectroscopy}},
	url = {http://dx.doi.org/10.1080/87565640802564481},
	urldate = {2016-10-10},
	volume = {34},
	year = {2009},
	bdsk-url-1 = {http://dx.doi.org/10.1080/87565640802564481}}

@book{poeppel_human_2012,
	abstract = {We live in a complex and dynamically changing acoustic environment. To this end, the auditory cortex of humans has developed the ability to process a remarkable amount of diverse acoustic information with apparent ease. In fact, a phylogenetic comparison of auditory systems reveals that human auditory association cortex in particular has undergone extensive changes relative to that of other species, although our knowledge of this remains incomplete. In contrast to other senses, human auditory cortex receives input that is highly pre-processed in a number of sub-cortical structures; this suggests that even primary auditory cortex already performs quite complex analyses. At the same time, much of the functional role of the various sub-areas in human auditory cortex is still relatively unknown, and a more sophisticated understanding is only now emerging through the use of contemporary electrophysiological and neuroimaging techniques. The integration of results across the various techniques signify a new era in our knowledge of how human auditory cortex forms basis for auditory experience. This volume on human auditory cortex will have two major parts. In Part A, the principal methodologies currently used to investigate human auditory cortex will be discussed. Each chapter will first outline how the methodology is used in auditory neuroscience, highlighting the challenges of obtaining data from human auditory cortex; second, each methods chapter will provide two or (at most) three brief examples of how it has been used to generate a major result about auditory processing. In Part B, the central questions for auditory processing in human auditory cortex are covered. Each chapter can draw on all the methods introduced in Part A but will focus on a major computational challenge the system has to solve. This volume will constitute an important contemporary reference work on human auditory cortex. Arguably, this will be the first and most focused book on this critical neurological structure. The combination of different methodological and experimental approaches as well as a diverse range of aspects of human auditory perception ensures that this volume will inspire novel insights and spurn future research.},
	author = {Poeppel, David and Overath, Tobias and Popper, Arthur N. and Fay, Richard R.},
	isbn = {978-1-4614-2313-3},
	keywords = {Medical / Neuroscience, Medical / Otorhinolaryngology, Science / Life Sciences / Ecology, Science / Life Sciences / Neuroscience, Science / Life Sciences / Zoology / General},
	language = {en},
	month = apr,
	publisher = {Springer Science \& Business Media},
	title = {The {Human} {Auditory} {Cortex}},
	year = {2012}}

@article{bench_sound_1968,
	author = {Bench, J.},
	doi = {10.1080/00221325.1968.10533811},
	issn = {0022-1325},
	journal = {The Journal of Genetic Psychology},
	keywords = {Abdominal Muscles, Female, Fetus, Humans, Pregnancy, Sound},
	language = {eng},
	month = sep,
	number = {1st Half},
	pages = {85--87},
	pmid = {4236927},
	title = {Sound transmission to the human foetus through the maternal abdominal wall},
	volume = {113},
	year = {1968},
	bdsk-url-1 = {https://doi.org/10.1080/00221325.1968.10533811}}

@article{lakatos_oscillatory_2005,
	abstract = {EEG oscillations are hypothesized to reflect cyclical variations in the neuronal excitability, with particular frequency bands reflecting differing spatial scales of brain operation. However, despite decades of clinical and scientific investigation, there is no unifying theory of EEG organization, and the role of ongoing activity in sensory processing remains controversial. This study analyzed laminar profiles of synaptic activity [current source density CSD] and multiunit activity (MUA), both spontaneous and stimulus-driven, in primary auditory cortex of awake macaque monkeys. Our results reveal that the EEG is hierarchically organized; delta (1--4 Hz) phase modulates theta (4--10 Hz) amplitude, and theta phase modulates gamma (30--50 Hz) amplitude. This oscillatory hierarchy controls baseline excitability and thus stimulus-related responses in a neuronal ensemble. We propose that the hierarchical organization of ambient oscillatory activity allows auditory cortex to structure its temporal activity pattern so as to optimize the processing of rhythmic inputs.},
	author = {Lakatos, Peter and Shah, Ankoor S. and Knuth, Kevin H. and Ulbert, Istvan and Karmos, George and Schroeder, Charles E.},
	copyright = {Copyright {\copyright} 2005 by the American Physiological Society},
	doi = {10.1152/jn.00263.2005},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/SXF2Z93Z/Lakatos et al. - 2005 - An Oscillatory Hierarchy Controlling Neuronal Exci.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6CJ3326Q/1904.html:text/html},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = sep,
	number = {3},
	pages = {1904--1911},
	title = {An {Oscillatory} {Hierarchy} {Controlling} {Neuronal} {Excitability} and {Stimulus} {Processing} in the {Auditory} {Cortex}},
	url = {http://jn.physiology.org/content/94/3/1904},
	urldate = {2014-11-03},
	volume = {94},
	year = {2005},
	bdsk-url-1 = {http://jn.physiology.org/content/94/3/1904},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00263.2005}}

@article{liberman_motor_1985,
	author = {Liberman, Alvin M. and Mattingly, Ignatius G.},
	doi = {10.1016/0010-0277(85)90021-6},
	file = {The motor theory of speech perception revised:/Users/Cecile/Zotero/storage/AXX9JMTD/0010027785900216.html:text/html},
	issn = {00100277},
	journal = {Cognition},
	month = oct,
	number = {1},
	pages = {1--36},
	title = {The motor theory of speech perception revised},
	url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/0010027785900216},
	urldate = {2013-09-16},
	volume = {21},
	year = {1985},
	bdsk-url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/0010027785900216},
	bdsk-url-2 = {https://doi.org/10.1016/0010-0277(85)90021-6}}

@article{gross_speech_2013,
	abstract = {{\textless}p{\textgreater}A neuroimaging study reveals how coupled brain oscillations at different frequencies align with quasi-rhythmic features of continuous speech such as prosody, syllables, and phonemes.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}},
	author = {Gross, Joachim and Hoogenboom, Nienke and Thut, Gregor and Schyns, Philippe and Panzeri, Stefano and Belin, Pascal and Garrod, Simon},
	doi = {10.1371/journal.pbio.1001752},
	file = {PLoS Snapshot:/Users/Cecile/Zotero/storage/WMRNWNPI/infodoi10.1371journal.pbio.html:text/html},
	journal = {PLoS Biol},
	month = dec,
	number = {12},
	pages = {e1001752},
	title = {Speech {Rhythms} and {Multiplexed} {Oscillatory} {Sensory} {Coding} in the {Human} {Brain}},
	url = {http://dx.doi.org/10.1371/journal.pbio.1001752},
	urldate = {2014-10-31},
	volume = {11},
	year = {2013},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pbio.1001752}}

@article{best_stimulus-alternation_1998,
	author = {Best, CatherineT. and Jones, Cathleen},
	doi = {10.1016/S0163-6383(98)91508-9},
	issn = {01636383},
	journal = {Infant Behavior and Development},
	language = {en},
	month = apr,
	pages = {295},
	title = {Stimulus-alternation preference procedure to test infant speech discrimination},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0163638398915089},
	urldate = {2016-10-11},
	volume = {21},
	year = {1998},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0163638398915089},
	bdsk-url-2 = {https://doi.org/10.1016/S0163-6383(98)91508-9}}

@article{lerner_temporal_2014,
	abstract = {Different brain areas integrate information over different timescales, and this capacity to accumulate information increases from early sensory areas to higher order perceptual and cognitive areas. It is currently unknown whether the timescale capacity of each brain area is fixed or whether it adaptively rescales depending on the rate at which information arrives from the world. Here, using functional MRI, we measured brain responses to an auditory narrative presented at different rates. We asked whether neural responses to slowed (speeded) versions of the narrative could be compressed (stretched) to match neural responses to the original narrative. Temporal rescaling was observed in early auditory regions (which accumulate information over short timescales) as well as linguistic and extra-linguistic brain areas (which can accumulate information over long timescales). The temporal rescaling phenomenon started to break down for stimuli presented at double speed, and intelligibility was also impaired for these stimuli. These data suggest that 1) the rate of neural information processing can be rescaled according to the rate of incoming information, both in early sensory regions as well as in higher order cortexes, and 2) the rescaling of neural dynamics is confined to a range of rates that match the range of behavioral performance.},
	author = {Lerner, Y. and Honey, C. J. and Katkov, M. and Hasson, U.},
	copyright = {Copyright {\copyright} 2014 the American Physiological Society},
	doi = {10.1152/jn.00497.2013},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/77AAN6D4/Lerner et al. - 2014 - Temporal scaling of neural responses to compressed.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M2VFVHBH/2433.html:text/html},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = jun,
	number = {12},
	pages = {2433--2444},
	pmid = {24647432},
	title = {Temporal scaling of neural responses to compressed and dilated natural speech},
	url = {http://jn.physiology.org.gate1.inist.fr/content/111/12/2433},
	urldate = {2015-08-24},
	volume = {111},
	year = {2014},
	bdsk-url-1 = {http://jn.physiology.org.gate1.inist.fr/content/111/12/2433},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00497.2013}}

@article{ding_robust_2014,
	abstract = {Speech recognition is robust to background noise. One underlying neural mechanism is that the auditory system segregates speech from the listening background and encodes it reliably. Such robust internal representation has been demonstrated in auditory cortex by neural activity entrained to the temporal envelope of speech. A paradox, however, then arises, as the spectro-temporal fine structure rather than the temporal envelope is known to be the major cue to segregate target speech from background noise. Does the reliable cortical entrainment in fact reflect a robust internal ``synthesis'' of the attended speech stream rather than direct tracking of the acoustic envelope? Here, we test this hypothesis by degrading the spectro-temporal fine structure while preserving the temporal envelope using vocoders. Magnetoencephalography (MEG) recordings reveal that cortical entrainment to vocoded speech is severely degraded by background noise, in contrast to the robust entrainment to natural speech. Furthermore, cortical entrainment in the delta-band (1--4 Hz) predicts the speech recognition score at the level of individual listeners. These results demonstrate that reliable cortical entrainment to speech relies on the spectro-temporal fine structure, and suggest that cortical entrainment to the speech envelope is not merely a representation of the speech envelope but a coherent representation of multiscale spectro-temporal features that are synchronized to the syllabic and phrasal rhythms of speech.},
	author = {Ding, Nai and Chatterjee, Monita and Simon, Jonathan Z.},
	doi = {10.1016/j.neuroimage.2013.10.054},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ZBGZ7WX3/Ding et al. - 2014 - Robust cortical entrainment to the speech envelope.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VUJTSVGD/S105381191301077X.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Auditory scene analysis, Envelope entrainment, MEG, Auditory cortex},
	month = mar,
	pages = {41--46},
	title = {Robust cortical entrainment to the speech envelope relies on the spectro-temporal fine structure},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191301077X},
	urldate = {2014-10-31},
	volume = {88},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191301077X},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2013.10.054}}

@article{lin_regional_2013,
	abstract = {Understanding the evolution of regional and hemispheric asymmetries in the early stages of life is essential to the advancement of developmental neuroscience. By using 2 noninvasive optical methods, frequency-domain near-infrared spectroscopy and diffuse correlation spectroscopy, we measured cerebral hemoglobin oxygenation (SO(2)), blood volume (CBV), an index of cerebral blood flow (CBF(i)), and the metabolic rate of oxygen (CMRO(2i)) in the frontal, temporal, and parietal regions of 70 premature and term newborns. In concordance with results obtained using more invasive imaging modalities, we verified both hemodynamic (CBV, CBF(i), and SO(2)) and metabolic (CMRO(2i)) parameters were greater in the temporal and parietal regions than in the frontal region and that these differences increased with age. In addition, we found that most parameters were significantly greater in the right hemisphere than in the left. Finally, in comparing age-matched males and females, we found that males had higher CBF(i) in most cortical regions, higher CMRO(2i) in the frontal region, and more prominent right-left CBF(i) asymmetry. These results reveal, for the first time, that we can detect regional and hemispheric asymmetries in newborns using noninvasive optical techniques. Such a bedside screening tool may facilitate early detection of abnormalities and delays in maturation of specific cortical areas.},
	author = {Lin, Pei-Yi and Roche-Labarbe, Nad{\`e}ge and Dehaes, Mathieu and Fenoglio, Angela and Grant, P. Ellen and Franceschini, Maria Angela},
	doi = {10.1093/cercor/bhs023},
	issn = {1460-2199},
	journal = {Cerebral Cortex (New York, N.Y.: 1991)},
	keywords = {Female, Hemodynamics, Humans, Infant, Newborn, Male, Cerebrovascular Circulation, Infant, Premature, Spectrum Analysis, Oxygen, Brain},
	language = {eng},
	month = feb,
	number = {2},
	pages = {339--348},
	pmcid = {PMC3584954},
	pmid = {22328446},
	title = {Regional and hemispheric asymmetries of cerebral hemodynamic and oxygen metabolism in newborns},
	volume = {23},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1093/cercor/bhs023}}

@article{griffiths_planum_nodate,
	author = {Griffiths, Timothy D. and Warren, Jason D.},
	journal = {Trends in Cognitive Neurosciences},
	number = {7},
	pages = {348--353},
	title = {The planum temporale as a computational hub},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223602021914},
	volume = {25},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223602021914}}

@article{kobayashi_infants_2011,
	abstract = {Recent adult functional magnetic resonance imaging (fMRI) studies reported that face-sensitive cortical areas showed attenuated responses to the repeated presentation of an identical facial image compared to the presentation of different facial images (fMRI-adaptation effects: e.g., Andrews and Ewbank, 2004). Building upon this finding, the current study, employing the adaptation paradigm, used near-infrared spectroscopy (NIRS) to explore the neural basis of face processing in infants. In Experiment 1, we compared hemodynamic responses in the bilateral temporal regions during the repeated presentation of the same face (the same-face condition) and the sequential presentation of different faces (the different-face condition). We found that (1) hemodynamic responses in the channels around the T5 and T6 regions increased during the presentation of different faces compared to those during the presentation of different objects; and that (2) these channels showed significantly lower response in the same-face condition than in the different-face condition, demonstrating the neural adaptation effect in 5- to 8-month-olds as measured by NIRS. In Experiment 2, when faces in both the same-face and different-face conditions were changed in viewpoint, lower hemodynamic responses in the same-face condition were found in 7- to 8-month-olds but not in 5- to 6-month-olds. Our results suggest that faces are represented in a viewpoint-invariant manner in 7- and 8-month-old infants.},
	author = {Kobayashi, Megumi and Otsuka, Yumiko and Nakato, Emi and Kanazawa, So and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	doi = {10.3389/fnhum.2011.00153},
	file = {fnhum-05-00153.pdf:/Users/Cecile/Zotero/storage/YZ3TUAVV/fnhum-05-00153.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/8TBV7P5W/Kobayashi et al. - 2011 - Do infants represent the face in a viewpoint-invar.pdf:application/pdf},
	journal = {Frontiers in Human Neuroscience},
	keywords = {adaptation effect, viewpoint-invariant, Face, NIRS, Infants, Near-infrared spectroscopy},
	pages = {153},
	shorttitle = {Do infants represent the face in a viewpoint-invariant manner?},
	title = {Do infants represent the face in a viewpoint-invariant manner? {Neural} adaptation study as measured by near-infrared spectroscopy},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2011.00153/full},
	urldate = {2016-10-11},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2011.00153/full},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2011.00153}}

@article{orchik_time-compressed_1977,
	abstract = {The Word Intelligibility by Picture Identification (WIPI) Test of Speech Discrimination was time compressed at 0, 30, and 60\% and administered to 48 normal-hearing children. The children, all between the ages of 5 years, 6 months and six years, 7 months of age, were equally divided into three groups on the basis of articulation ability. Significant effects were found for test groups and levels of time compression, with differences increasing as time compression increased. The implication is that children with multiple articulation errors demonstrate a developmental lag in the ability to process time-compressed speech. Time-compressed speech may be a useful tool in the study of auditory perception in children.},
	author = {Orchik, D J and Oelschlaeger, M L},
	issn = {0360-9294},
	journal = {Journal of the American Audiology Society},
	keywords = {Audiometry, Auditory Perception, Child, Child, Preschool, Hearing Disorders, Humans, Speech},
	language = {eng},
	month = aug,
	number = {1},
	pages = {37--41},
	pmid = {893199},
	title = {Time-compressed speech discrimination in children and its relationship to articulation},
	volume = {3},
	year = {1977}}

@article{nakato_i_2011,
	abstract = {Previously, we used near-infrared spectroscopy (NIRS) to measure infant's brain activity during face processing by detecting changes in hemodynamic responses, oxy-Hb, deoxy-Hb, and total-Hb concentrations [1,2]. We found that the right temporal cortex of the brain was activated when infants looked at upright frontal faces rather than inverted faces, and at the frontal view as well as the profile view on 8-month-olds. In the present study, we investigated 7- and 8-month-olds' brain activity related to the perception of mother's and stranger's faces by NIRS. The finding was that oxy-Hb and total-Hb concentrations in the right temporal cortex increased against the baseline during presentation of the mother's face. For strangers' faces, the total-Hb concentration in the right temporal cortex was greater than the baseline. By contrast, oxy- and total-Hb concentrations in the left temporal cortex increased only in the presentation of mother's face. The great activity in the right temporal region for faces irrespective of familiarity was consistent with a predominance of the right temporal cortex found previously in infants [1,2] as well as functional magnetic resonance imaging (fMRI) studies in adults [3,4]. In contrast to the activity in the right temporal cortex, the greater hemodynamic response in the left temporal cortex was observed only in the mother's face condition. These findings suggest that the processing of the mother's face enhances activity in bilateral temporal cortex. This is the first study to clarify the location of brain activity in infants related to the perception of their mother's face.},
	author = {Nakato, Emi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Honda, Yukiko and Kakigi, Ryusuke},
	doi = {10.1016/j.earlhumdev.2010.08.030},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/25KHI5JD/Nakato et al. - 2011 - I know this face Neural activity during mother' f.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4TPWUKW3/S0378378210006638.html:text/html},
	issn = {0378-3782},
	journal = {Early Human Development},
	keywords = {Familiarity, Mother's face processing, Infants, Near-infrared spectroscopy},
	month = jan,
	number = {1},
	pages = {1--7},
	shorttitle = {I know this face},
	title = {I know this face: {Neural} activity during mother' face perception in 7- to 8-month-old infants as investigated by near-infrared spectroscopy},
	url = {http://www.sciencedirect.com/science/article/pii/S0378378210006638},
	urldate = {2017-12-07},
	volume = {87},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378378210006638},
	bdsk-url-2 = {https://doi.org/10.1016/j.earlhumdev.2010.08.030}}

@article{quaresima_brief_2012,
	abstract = {Upon stimulation, real time maps of cortical hemodynamic responses can be obtained by non-invasive functional near-infrared spectroscopy (fNIRS) which measures changes in oxygenated and deoxygenated hemoglobin after positioning multiple sources and detectors over the human scalp. The current commercially available transportable fNIRS systems have a time resolution of 1-10 Hz, a depth sensitivity of about 1.5 cm, and a spatial resolution of about 1cm. The goal of this brief review is to report infants, children and adults fNIRS language studies. Since 1998, 60 studies have been published on cortical activation in the brain's classic language areas in children/adults as well as newborns using fNIRS instrumentations of different complexity. In addition, the basic principles of fNIRS including features, strengths, advantages, and limitations are summarized in terms that can be understood even by non specialists. Future prospects of fNIRS in the field of language processing imaging are highlighted.},
	author = {Quaresima, Valentina and Bisconti, Silvia and Ferrari, Marco},
	doi = {10.1016/j.bandl.2011.03.009},
	issn = {1090-2155},
	journal = {Brain and Language},
	keywords = {Adult, Brain Mapping, Child, Humans, Infant, Newborn, Spectroscopy, Near-Infrared, language, Brain},
	language = {eng},
	month = may,
	number = {2},
	pages = {79--89},
	pmid = {21507474},
	title = {A brief review on the use of functional near-infrared spectroscopy ({fNIRS}) for language imaging studies in human newborns and adults},
	volume = {121},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1016/j.bandl.2011.03.009}}

@article{aslin_hemodynamic_2015,
	abstract = {Over the past 20 years, the field of cognitive neuroscience has relied heavily on hemodynamic measures of blood oxygenation in local regions of the brain to make inferences about underlying cognitive processes. These same functional magnetic resonance imaging (fMRI) and functional near-infrared spectroscopy (fNIRS) techniques have recently been adapted for use with human infants. We review the advantages and disadvantages of these two neuroimaging methods for studies of infant cognition, with a particular emphasis on their technical limitations and the linking hypotheses that are used to draw conclusions from correlational data. In addition to summarizing key findings in several domains of infant cognition, we highlight the prospects of improving the quality of fNIRS data from infants to address in a more sophisticated way how cognitive development is mediated by changes in underlying neural mechanisms.},
	author = {Aslin, Richard N. and Shukla, Mohinish and Emberson, Lauren L.},
	doi = {10.1146/annurev-psych-010213-115108},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/I525QRDE/Aslin et al. - 2015 - Hemodynamic Correlates of Cognition in Human Infan.pdf:application/pdf},
	issn = {0066-4308},
	journal = {Annual review of psychology},
	month = jan,
	pages = {349--379},
	pmcid = {PMC4429889},
	pmid = {25251480},
	title = {Hemodynamic {Correlates} of {Cognition} in {Human} {Infants}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4429889/},
	urldate = {2016-11-02},
	volume = {66},
	year = {2015},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4429889/},
	bdsk-url-2 = {https://doi.org/10.1146/annurev-psych-010213-115108}}

@article{dehaene-lambertz_infancy_2015,
	author = {Dehaene-Lambertz, G. and Spelke, E.S.},
	doi = {10.1016/j.neuron.2015.09.026},
	file = {DehaeneLambertz-Spelke_TheinfancyoftheHumanBrain_Neuron2015.pdf:/Users/Cecile/Zotero/storage/DWZEX2JN/DehaeneLambertz-Spelke_TheinfancyoftheHumanBrain_Neuron2015.pdf:application/pdf},
	issn = {08966273},
	journal = {Neuron},
	language = {en},
	month = oct,
	number = {1},
	pages = {93--109},
	title = {The {Infancy} of the {Human} {Brain}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008156},
	urldate = {2015-10-12},
	volume = {88},
	year = {2015},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008156},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2015.09.026}}

@article{banai_perceptual_2012,
	abstract = {BackgroundTime-compressed speech, a form of rapidly presented speech, is harder to comprehend than natural speech, especially for non-native speakers. Although it is possible to adapt to time-compressed speech after a brief exposure, it is not known whether additional perceptual learning occurs with further practice. Here, we ask whether multiday training on time-compressed speech yields more learning than that observed during the initial adaptation phase and whether the pattern of generalization following successful learning is different than that observed with initial adaptation only.Methodology/Principal FindingsTwo groups of non-native Hebrew speakers were tested on five different conditions of time-compressed speech identification in two assessments conducted 10--14 days apart. Between those assessments, one group of listeners received five practice sessions on one of the time-compressed conditions. Between the two assessments, trained listeners improved significantly more than untrained listeners on the trained condition. Furthermore, the trained group generalized its learning to two untrained conditions in which different talkers presented the trained speech materials. In addition, when the performance of the non-native speakers was compared to that of a group of na{\"\i}ve native Hebrew speakers, performance of the trained group was equivalent to that of the native speakers on all conditions on which learning occurred, whereas performance of the untrained non-native listeners was substantially poorer.Conclusions/SignificanceMultiday training on time-compressed speech results in significantly more perceptual learning than brief adaptation. Compared to previous studies of adaptation, the training induced learning is more stimulus specific. Taken together, the perceptual learning of time-compressed speech appears to progress from an initial, rapid adaptation phase to a subsequent prolonged and more stimulus specific phase. These findings are consistent with the predictions of the Reverse Hierarchy Theory of perceptual learning and suggest constraints on the use of perceptual-learning regimens during second language acquisition.},
	author = {Banai, Karen and Lavner, Yizhar},
	doi = {10.1371/journal.pone.0047099},
	file = {BanaiLavner12.pdf:/Users/Cecile/Zotero/storage/6H64DJVB/BanaiLavner12.pdf:application/pdf;PLoS Full Text PDF:/Users/Cecile/Zotero/storage/JT67DSA2/Banai et Lavner - 2012 - Perceptual Learning of Time-Compressed Speech Mor.pdf:application/pdf;PLoS Snapshot:/Users/Cecile/Zotero/storage/W74N79WQ/infodoi10.1371journal.pone.html:text/html},
	journal = {PLoS ONE},
	month = oct,
	number = {10},
	pages = {e47099},
	shorttitle = {Perceptual {Learning} of {Time}-{Compressed} {Speech}},
	title = {Perceptual {Learning} of {Time}-{Compressed} {Speech}: {More} than {Rapid} {Adaptation}},
	url = {http://dx.doi.org/10.1371/journal.pone.0047099},
	urldate = {2014-04-02},
	volume = {7},
	year = {2012},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pone.0047099}}

@article{remez_bistability_2001,
	abstract = {Our studies revealed two stable modes of perceptual organization, one based on attributes of auditory sensory elements and another based on attributes of patterned sensory variation composed by the aggregation of sensory elements. In a dual-task method, listeners attended concurrently to both aspects, component and pattern, of a sine wave analogue of a word. Organization of elements was indexed by several single-mode tests of auditory form perception to verify the perceptual segregation of either an individual formant of a synthetic word or a tonal component of a sinusoidal word analogue. Organization of patterned variation was indexed by a test of lexical identification. The results show the independence of the perception of auditory and phonetic form, which appear to be differently organized concurrent effects of the same acoustic cause.},
	author = {Remez, Robert E. and Pardo, Jennifer S. and Piorkowski, Rebecca L. and Rubin, Philip E.},
	doi = {10.1111/1467-9280.00305},
	file = {Snapshot:/Users/Cecile/Zotero/storage/NUSTFC2Z/24.html:text/html},
	issn = {0956-7976, 1467-9280},
	journal = {Psychological Science},
	language = {en},
	month = jan,
	number = {1},
	pages = {24--29},
	pmid = {11294224},
	title = {On the {Bistability} of {Sine} {Wave} {Analogues} of {Speech}},
	url = {http://pss.sagepub.com/content/12/1/24},
	urldate = {2014-05-28},
	volume = {12},
	year = {2001},
	bdsk-url-1 = {http://pss.sagepub.com/content/12/1/24},
	bdsk-url-2 = {https://doi.org/10.1111/1467-9280.00305}}

@article{wang_neurophysiological_2010,
	abstract = {Synchronous rhythms represent a core mechanism for sculpting temporal coordination of neural activity in the brain-wide network. This review focuses on oscillations in the cerebral cortex that occur during cognition, in alert behaving conditions. Over the last two decades, experimental and modeling work has made great strides in elucidating the detailed cellular and circuit basis of these rhythms, particularly gamma and theta rhythms. The underlying physiological mechanisms are diverse (ranging from resonance and pacemaker properties of single cells to multiple scenarios for population synchronization and wave propagation), but also exhibit unifying principles. A major conceptual advance was the realization that synaptic inhibition plays a fundamental role in rhythmogenesis, either in an interneuronal network or in a reciprocal excitatory-inhibitory loop. Computational functions of synchronous oscillations in cognition are still a matter of debate among systems neuroscientists, in part because the notion of regular oscillation seems to contradict the common observation that spiking discharges of individual neurons in the cortex are highly stochastic and far from being clocklike. However, recent findings have led to a framework that goes beyond the conventional theory of coupled oscillators and reconciles the apparent dichotomy between irregular single neuron activity and field potential oscillations. From this perspective, a plethora of studies will be reviewed on the involvement of long-distance neuronal coherence in cognitive functions such as multisensory integration, working memory, and selective attention. Finally, implications of abnormal neural synchronization are discussed as they relate to mental disorders like schizophrenia and autism.},
	author = {Wang, Xiao-Jing},
	copyright = {Copyright {\copyright} 2010 the American Physiological Society},
	doi = {10.1152/physrev.00035.2008},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NV2D4RDB/Wang - 2010 - Neurophysiological and Computational Principles of.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/996TUASI/1195.html:text/html},
	issn = {0031-9333, 1522-1210},
	journal = {Physiological Reviews},
	language = {en},
	month = jul,
	number = {3},
	pages = {1195--1268},
	title = {Neurophysiological and {Computational} {Principles} of {Cortical} {Rhythms} in {Cognition}},
	url = {http://physrev.physiology.org/content/90/3/1195},
	urldate = {2014-10-21},
	volume = {90},
	year = {2010},
	bdsk-url-1 = {http://physrev.physiology.org/content/90/3/1195},
	bdsk-url-2 = {https://doi.org/10.1152/physrev.00035.2008}}

@article{bertoncini_morae_1995,
	abstract = {Are neonates sensitive to the different rhythmical units that are used in different spoken languages? And do they use these units to represent and discriminate multisyllabic words? In the present study, we used the High-Amplitude Sucking procedure to test whether 3-day-old French infants discriminate lists of Japanese words. The lists of words differed either in the number of syllabic units or in the number of sub-syllabic units such as morae. In Experiment 1, infants heard bisyllabic versus trisyllabic words (e.g.: iga vs. hekiga); in Experiment 2, they were presented with bimoraic versus trimoraic bisyllabic words (e.g.: iga vs. iNga). The results corroborate those obtained by Bijeljac-Babic, Bertoncini, and Mehler (1993), providing further evidence that neonates discriminate bisyllabic from trisyllabic words. In contrast, neonates do not appear to discriminate bisyllabic words that vary in number of sub-syllabic units. It is proposed that syllables are particularly salient units during the initial stage of speech processing, irrespective of which language and rhythmical structure is heard.},
	author = {Bertoncini, Josiane and Floccia, Caroline and Nazzi, Thierry and Mehler, Jacques},
	doi = {10.1177/002383099503800401},
	file = {Snapshot:/Users/Cecile/Zotero/storage/38GN29CQ/311.html:text/html},
	issn = {0023-8309, 1756-6053},
	journal = {Language and Speech},
	keywords = {Rhythm, cue transparency, infant speech perception, speech units},
	language = {en},
	month = jan,
	number = {4},
	pages = {311--329},
	shorttitle = {Morae and {Syllables}},
	title = {Morae and {Syllables}: {Rhythmical} {Basis} of {Speech} {Representations} in {Neonates}},
	url = {http://las.sagepub.com/content/38/4/311},
	urldate = {2014-06-01},
	volume = {38},
	year = {1995},
	bdsk-url-1 = {http://las.sagepub.com/content/38/4/311},
	bdsk-url-2 = {https://doi.org/10.1177/002383099503800401}}

@article{dehaene-lambertz_cerebral_2000,
	abstract = {Early cerebral specialization and lateralization for auditory processing in 4-month-old infants was studied by recording high-density evoked potentials to acoustical and phonetic changes in a series of repeated stimuli (either tones or syllables). Mismatch responses to these stimuli exhibit a distinct topography suggesting that different neural networks within the temporal lobe are involved in the perception and representation of the different features of an auditory stimulus. These data confirm that specialized modules are present within the auditory cortex very early in development. However, both for syllables and continuous tones, higher voltages were recorded over the left hemisphere than over the right with no significant interaction of hemisphere by type of stimuli. This suggests that there is no greater left hemisphere involvement in phonetic processing than in acoustic processing during the first months of life.},
	author = {Dehaene-Lambertz, G.},
	doi = {10.1162/089892900562264},
	file = {Citeseer - Full Text PDF:/Users/Cecile/Zotero/storage/RKPVLGLJ/In et al. - 2000 - Cerebral Specialization for Speech and.pdf:application/pdf;Journal of Cognitive Neuroscience Snapshot:/Users/Cecile/Zotero/storage/AAUBA23W/089892900562264.html:text/html},
	issn = {0898-929X},
	journal = {Journal of Cognitive Neuroscience},
	month = may,
	number = {3},
	pages = {449--460},
	title = {Cerebral {Specialization} for {Speech} and {Non}-{Speech} {Stimuli} in {Infants}},
	url = {http://dx.doi.org/10.1162/089892900562264},
	urldate = {2014-05-29},
	volume = {12},
	year = {2000},
	bdsk-url-1 = {http://dx.doi.org/10.1162/089892900562264}}

@article{lloyd-fox_cortical_2015,
	abstract = {The extent to which perception and action share common neural processes is much debated in cognitive neuroscience. Taking a developmental approach to this issue allows us to assess whether perceptual processing develops in close association with the emergence of related action skills within the same individual. The current study used functional near-infrared spectroscopy (fNIRS) to investigate the perception of human action in 4- to 6-month-old human infants. In addition, the infants' manual dexterity was assessed using the fine motor component of The Mullen Scales of Early Learning and an in-house developed Manual Dexterity task. Results show that the degree of cortical activation, within the posterior superior temporal sulcus---temporoparietal junction (pSTS-TPJ) region, to the perception of manual actions in individual infants correlates with their own level of fine motor skills. This association was not fully explained by either measures of global attention (i.e., looking time) or general developmental stage. This striking concordance between the emergence of motor skills and related perceptual processing within individuals is consistent with experience-related cortical specialization in the developing brain.},
	author = {Lloyd-Fox, Sarah and Wu, Rachel and Richards, John E. and Elwell, Clare E. and Johnson, Mark H.},
	doi = {10.1093/cercor/bht207},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/44UQQ83D/Lloyd-Fox et al. - 2015 - Cortical Activation to Action Perception is Associ.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EPVQP96C/296958.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = feb,
	number = {2},
	pages = {289--297},
	title = {Cortical {Activation} to {Action} {Perception} is {Associated} with {Action} {Production} {Abilities} in {Young} {Infants}},
	url = {https://academic.oup.com/cercor/article/25/2/289/296958},
	urldate = {2017-12-08},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/25/2/289/296958},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bht207}}

@article{ferry_nonhuman_2013,
	abstract = {Language is a signature of our species and our primary conduit for conveying the contents of our minds. The power of language derives not only from the exquisite detail of the signal itself but also from its intricate link to human cognition. To acquire a language, infants must identify which signals are part of their language and discover how these signals are linked to meaning. At birth, infants prefer listening to vocalizations of human and nonhuman primates; within 3 mo, this initially broad listening preference is tuned specifically to human vocalizations. Moreover, even at this early developmental point, human vocalizations evoke more than listening preferences alone: they engender in infants a heightened focus on the objects in their visual environment and promote the formation of object categories, a fundamental cognitive capacity. Here, we illuminate the developmental origin of this early link between human vocalizations and cognition. We document that this link emerges from a broad biological template that initially encompasses vocalizations of human and nonhuman primates (but not backward speech) and that within 6 mo this link to cognition is tuned specifically to human vocalizations. At 3 and 4 mo, nonhuman primate vocalizations promote object categorization, mirroring precisely the advantages conferred by human vocalizations, but by 6 mo, nonhuman primate vocalizations no longer exert this advantageous effect. This striking developmental shift illuminates a path of specialization that supports infants as they forge the foundational links between human language and the core cognitive processes that will serve as the foundations of meaning.},
	author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	doi = {10.1073/pnas.1221166110},
	issn = {1091-6490},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	keywords = {Age Factors, Animals, Attention, Child Development, Cognition, Humans, Infant, Language Development, Lemur, Species Specificity, Speech, Vocalization, Animal},
	language = {eng},
	month = sep,
	number = {38},
	pages = {15231--15235},
	pmcid = {PMC3780887},
	pmid = {24003164},
	title = {Nonhuman primate vocalizations support categorization in very young human infants},
	volume = {110},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.1221166110}}

@article{partanen_learning-induced_2013,
	abstract = {Learning, the foundation of adaptive and intelligent behavior, is based on plastic changes in neural assemblies, reflected by the modulation of electric brain responses. In infancy, auditory learning implicates the formation and strengthening of neural long-term memory traces, improving discrimination skills, in particular those forming the prerequisites for speech perception and understanding. Although previous behavioral observations show that newborns react differentially to unfamiliar sounds vs. familiar sound material that they were exposed to as fetuses, the neural basis of fetal learning has not thus far been investigated. Here we demonstrate direct neural correlates of human fetal learning of speech-like auditory stimuli. We presented variants of words to fetuses; unlike infants with no exposure to these stimuli, the exposed fetuses showed enhanced brain activity (mismatch responses) in response to pitch changes for the trained variants after birth. Furthermore, a significant correlation existed between the amount of prenatal exposure and brain activity, with greater activity being associated with a higher amount of prenatal speech exposure. Moreover, the learning effect was generalized to other types of similar speech sounds not included in the training material. Consequently, our results indicate neural commitment specifically tuned to the speech features heard before birth and their memory representations.},
	author = {Partanen, Eino and Kujala, Teija and N{\"a}{\"a}t{\"a}nen, Risto and Liitola, Auli and Sambeth, Anke and Huotilainen, Minna},
	doi = {10.1073/pnas.1302159110},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CINW4T3X/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/MKQW4IT9/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/Q8EB2FMA/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BG833BUU/15145.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/V7NZKAB5/15145.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/333E9JB9/15145.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {event-related potentials, Mismatch negativity, mismatch negativity},
	language = {en},
	month = oct,
	number = {37},
	pages = {15145--15150},
	pmid = {23980148},
	title = {Learning-induced neural plasticity of speech processing before birth},
	url = {http://www.pnas.org/content/110/37/15145},
	urldate = {2015-04-01},
	volume = {110},
	year = {2013},
	bdsk-url-1 = {http://www.pnas.org/content/110/37/15145},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1302159110}}

@article{shultz_neural_2014,
	abstract = {How does the brain's response to speech change over the first months of life? Although behavioral findings indicate that neonates' listening biases are sharpened over the first months of life, with a species-specific preference for speech emerging by 3 months, the neural substrates underlying this developmental change are unknown. We examined neural responses to speech compared with biological non-speech sounds in 1- to 4-month-old infants using fMRI. Infants heard speech and biological non-speech sounds, including heterospecific vocalizations and human non-speech. We observed a left-lateralized response in temporal cortex for speech compared to biological non-speech sounds, indicating that this region is highly selective for speech by the first month of life. Specifically, this brain region becomes increasingly selective for speech over the next 3 months as neural substrates become less responsive to non-speech sounds. These results reveal specific changes in neural responses during a developmental period characterized by rapid behavioral changes.},
	author = {Shultz, Sarah and Vouloumanos, Athena and Bennett, Randi H. and Pelphrey, Kevin},
	copyright = {{\copyright} 2014 The Authors. Developmental Science Published by John Wiley \& Sons Ltd., This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.},
	doi = {10.1111/desc.12151},
	file = {Snapshot:/Users/Cecile/Zotero/storage/MIQH32U4/abstract.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = feb,
	pages = {n/a--n/a},
	title = {Neural specialization for speech in the first months of life},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12151/abstract},
	urldate = {2014-05-22},
	year = {2014},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12151/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12151}}

@article{geffen_auditory_2011,
	abstract = {Many natural signals, including environmental sounds, exhibit scale-invariant statistics: their structure is repeated at multiple scales. Such scale-invariance has been identified separately across spectral and temporal correlations of natural sounds (Clarke and Voss, 1975; Attias and Schreiner, 1997; Escabi et al., 2003; Singh and Theunissen, 2003). Yet the role of scale-invariance across overall spectro-temporal structure of the sound has not been explored directly in auditory perception. Here, we identify that the acoustic waveform from the recording of running water is a self-similar fractal, exhibiting scale-invariance not only within spectral channels, but also across the full spectral bandwidth. The auditory perception of the water sound did not change with its scale. We tested the role of scale-invariance in perception by using an artificial sound, which could be rendered scale-invariant. We generated a random chirp stimulus: an auditory signal controlled by two parameters, Q, controlling the relative, and r, controlling the absolute, temporal structure of the sound. Imposing scale-invariant statistics on the artificial sound was required for its perception as natural and water-like. Further, Q had to be restricted to a specific range for the sound to be perceived as natural. To detect self-similarity in the water sound, and identify Q, the auditory system needs to process the temporal dynamics of the waveform across spectral bands in terms of the number of cycles, rather than absolute timing. We propose a two-stage neural model implementing this computation. This computation may be carried out by circuits of neurons in the auditory cortex. The set of auditory stimuli developed in this study are particularly suitable for measurements of response properties of neurons in the auditory pathway, allowing for quantification of the effects of varying the statistics of the spectro-temporal statistical structure of the stimulus.},
	author = {Geffen, Maria N. and Gervain, Judit and Werker, Janet F. and Magnasco, Marcelo O.},
	doi = {10.3389/fnint.2011.00015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7RVX7JAK/Geffen et al. - 2011 - Auditory perception of self-similarity in water so.pdf:application/pdf},
	journal = {Frontiers in Integrative Neuroscience},
	keywords = {Perception, Psychophysics, auditory, coherence, receptive field, scale-invariance, temporal adaptation},
	pages = {15},
	title = {Auditory perception of self-similarity in water sounds},
	url = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2011.00015/abstract},
	urldate = {2013-06-17},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2011.00015/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/fnint.2011.00015}}

@article{kida_gentle_2013,
	abstract = {Previous studies have demonstrated that pleasant touch activates reward-related cortical regions including the anterior prefrontal cortex (APFC) in adults, but the developmental change is still unknown in infancy. The present study used near infrared spectroscopy (NIRS) to investigate activation of the APFC by gentle touching of the hand of infants 2--16 months after birth, who were classified into three groups (3, 6 and 10 months old). Results showed that 10-month-olds, but not 3- and 6-month-olds, showed bilateral activation of the APFC by gentle touching of the palm with a sensuous velvet fabric compared to touch with rounded wood. The present finding suggests that developmental changes in the tactile affective system are associated with the activation of the APFC and that the critical point is between 6 and 10 months after birth.},
	author = {Kida, Tetsuo and Shinohara, Kazuyuki},
	doi = {10.1016/j.neulet.2013.01.048},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GSQH3T77/Kida et Shinohara - 2013 - Gentle touch activates the prefrontal cortex in in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/384TPWAD/S0304394013001055.html:text/html},
	issn = {0304-3940},
	journal = {Neuroscience Letters},
	keywords = {Hemodynamics, Plasticity, Pleasant touch, Development},
	month = apr,
	pages = {63--66},
	shorttitle = {Gentle touch activates the prefrontal cortex in infancy},
	title = {Gentle touch activates the prefrontal cortex in infancy: {An} {NIRS} study},
	url = {http://www.sciencedirect.com/science/article/pii/S0304394013001055},
	urldate = {2016-10-24},
	volume = {541},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394013001055},
	bdsk-url-2 = {https://doi.org/10.1016/j.neulet.2013.01.048}}

@article{dubois_assessment_2006,
	abstract = {The human infant is particularly immature at birth and brain maturation, with the myelination of white matter fibers, is protracted until adulthood. Diffusion tensor imaging offers the possibility to describe non invasively the fascicles spatial organization at an early stage and to follow the cerebral maturation with quantitative parameters that might be correlated with behavioral development. Here, we assessed the feasibility to study the organization and maturation of major white matter bundles in eighteen 1- to 4-month-old healthy infants, using a specific acquisition protocol customized to the immature brain (with 15 orientations of the diffusion gradients and a 700 s mm−2 b factor). We were able to track most of the main fascicles described at later ages despite the low anisotropy of the infant white matter, using the FACT algorithm. This mapping allows us to propose a new method of quantification based on reconstructed tracts, split between specific regions, which should be more sensitive to specific changes in a bundle than the conventional approach, based on regions-of-interest. We observed variations in fractional anisotropy and mean diffusivity over the considered developmental period in most bundles (corpus callosum, cerebellar peduncles, cortico-spinal tract, spino-thalamic tract, capsules, radiations, longitudinal and uncinate fascicles, cingulum). The results are in good agreement with the known stages of white matter maturation and myelination, and the proposed approach might provide important insights on brain development.},
	author = {Dubois, J. and Hertz-Pannier, L. and Dehaene-Lambertz, G. and Cointepas, Y. and Le Bihan, D.},
	doi = {10.1016/j.neuroimage.2005.11.022},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IUP4MTMA/Dubois et al. - 2006 - Assessment of the early organization and maturatio.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/G7PAGU5F/S1053811905024535.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Diffusion tensor imaging, Myelination, Tractography, Infant, Development, Brain},
	month = may,
	number = {4},
	pages = {1121--1132},
	shorttitle = {Assessment of the early organization and maturation of infants' cerebral white matter fiber bundles},
	title = {Assessment of the early organization and maturation of infants' cerebral white matter fiber bundles: {A} feasibility study using quantitative diffusion tensor imaging and tractography},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905024535},
	urldate = {2016-10-24},
	volume = {30},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811905024535},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2005.11.022}}

@article{beasley_intelligibility_1980,
	abstract = {Time-compressed monosyllables have been studied relative to the assessment of central auditory disorders. In certain instances, sentential stimuli may be more useful than word lists in central auditory testing, particularly when results may be contaminated by concomitant peripheral hearing losses. Central Institute for the Deaf (CID) and Revised CID sentence lists and a contrived sentential approximation task were presented to 96 normal hearing young adults at time-compression ratios of 0\%, 40\%, 60\%, and 70\%, under sensation levels of 24 and 40 dB. The CID and RCID stimuli were more intelligible than the sentential approximations. The results are presented and discussed as they pertain to central auditory testing and are compared to earlier data using consonant-nucleus-consonant monosyllabic stimuli.},
	author = {Beasley, D. S. and Bratt, G. W. and Rintelmann, W. F.},
	issn = {0022-4685},
	journal = {Journal of Speech and Hearing Research},
	keywords = {Adult, Hearing Loss, Central, Humans, Reference Values, Speech Discrimination Tests, Speech Intelligibility},
	language = {eng},
	month = dec,
	number = {4},
	pages = {722--731},
	pmid = {7442207},
	title = {Intelligibility of time-compressed sentential stimuli},
	volume = {23},
	year = {1980}}

@article{nasi_spontaneous_2011,
	abstract = {Understanding the interaction between the nervous system and cerebral vasculature is fundamental to forming a complete picture of the neurophysiology of sleep and its role in maintaining physiological homeostasis. However, the intrinsic hemodynamics of slow-wave sleep (SWS) are still poorly known. We carried out 30 all-night sleep measurements with combined near-infrared spectroscopy (NIRS) and polysomnography to investigate spontaneous hemodynamic behavior in SWS compared to light (LS) and rapid-eye-movement sleep (REM). In particular, we concentrated on slow oscillations (3--150 mHz) in oxy- and deoxyhemoglobin concentrations, heart rate, arterial oxygen saturation, and the pulsation amplitude of the photoplethysmographic signal. We also analyzed the behavior of these variables during sleep stage transitions. The results indicate that slow spontaneous cortical and systemic hemodynamic activity is reduced in SWS compared to LS, REM, and wakefulness. This behavior may be explained by neuronal synchronization observed in electrophysiological studies of SWS and a reduction in autonomic nervous system activity. Also, sleep stage transitions are asymmetric, so that the SWS-to-LS and LS-to-REM transitions, which are associated with an increase in the complexity of cortical electrophysiological activity, are characterized by more dramatic hemodynamic changes than the opposite transitions. Thus, it appears that while the onset of SWS and termination of REM occur only as gradual processes over time, the termination of SWS and onset of REM may be triggered more abruptly by a particular physiological event or condition. The results suggest that scalp hemodynamic changes should be considered alongside cortical hemodynamic changes in NIRS sleep studies to assess the interaction between the autonomic and central nervous systems.},
	author = {N{\"a}si, Tiina and Virtanen, Jaakko and Noponen, Tommi and Toppila, Jussi and Salmi, Tapani and Ilmoniemi, Risto J.},
	doi = {10.1371/journal.pone.0025415},
	file = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/GRRE7MAE/N{\"a}si et al. - 2011 - Spontaneous Hemodynamic Oscillations during Human .pdf:application/pdf},
	journal = {PLoS ONE},
	month = oct,
	number = {10},
	pages = {e25415},
	title = {Spontaneous {Hemodynamic} {Oscillations} during {Human} {Sleep} and {Sleep} {Stage} {Transitions} {Characterized} with {Near}-{Infrared} {Spectroscopy}},
	url = {http://dx.doi.org/10.1371/journal.pone.0025415},
	urldate = {2015-02-13},
	volume = {6},
	year = {2011},
	bdsk-url-1 = {http://dx.doi.org/10.1371/journal.pone.0025415}}

@article{holmstrom_efficient_2010,
	abstract = {An important question in sensory neuroscience is what coding strategies and mechanisms are used by the brain to detect and discriminate among behaviorally relevant stimuli. There is evidence that sensory systems migrate from a distributed and redundant encoding strategy at the periphery to a more heterogeneous encoding in cortical structures. It has been hypothesized that heterogeneity is an efficient encoding strategy that minimizes the redundancy of the neural code and maximizes information throughput. Evidence of this mechanism has been documented in cortical structures. In this study, we examined whether heterogeneous encoding of complex sounds contributes to efficient encoding in the auditory midbrain by characterizing neural responses to behaviorally relevant vocalizations in the mouse inferior colliculus (IC). We independently manipulated the frequency, amplitude, duration, and harmonic structure of the vocalizations to create a suite of modified vocalizations. Based on measures of both spike rate and timing, we characterized the heterogeneity of neural responses to the natural vocalizations and their perturbed variants. Using information theoretic measures, we found that heterogeneous response properties of IC neurons contribute to efficient encoding of behaviorally relevant vocalizations.},
	author = {Holmstrom, Lars A. and Eeuwes, Lonneke B. M. and Roberts, Patrick D. and Portfors, Christine V.},
	doi = {10.1523/JNEUROSCI.1964-09.2010},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/MM8B7RCH/Holmstrom et al. - 2010 - Efficient Encoding of Vocalizations in the Auditor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EETQZ3DX/802.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = jan,
	number = {3},
	pages = {802--819},
	pmid = {20089889},
	title = {Efficient {Encoding} of {Vocalizations} in the {Auditory} {Midbrain}},
	url = {http://www.jneurosci.org/content/30/3/802},
	urldate = {2016-03-21},
	volume = {30},
	year = {2010},
	bdsk-url-1 = {http://www.jneurosci.org/content/30/3/802},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1964-09.2010}}

@article{perani_neural_2011,
	abstract = {The ability to learn language is a human trait. In adults and children, brain imaging studies have shown that auditory language activates a bilateral frontotemporal network with a left hemispheric dominance. It is an open question whether these activations represent the complete neural basis for language present at birth. Here we demonstrate that in 2-d-old infants, the language-related neural substrate is fully active in both hemispheres with a preponderance in the right auditory cortex. Functional and structural connectivities within this neural network, however, are immature, with strong connectivities only between the two hemispheres, contrasting with the adult pattern of prevalent intrahemispheric connectivities. Thus, although the brain responds to spoken language already at birth, thereby providing a strong biological basis to acquire language, progressive maturation of intrahemispheric functional connectivity is yet to be established with language exposure as the brain develops.},
	author = {Perani, Daniela and Saccuman, Maria C. and Scifo, Paola and Anwander, Alfred and Spada, Danilo and Baldoli, Cristina and Poloniato, Antonella and Lohmann, Gabriele and Friederici, Angela D.},
	doi = {10.1073/pnas.1102991108},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T8S43T3A/Perani et al. - 2011 - Neural language networks at birth.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/N7CD9C7K/16056.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {brain activity, dorsal pathway, newborns, ventral pathway},
	language = {en},
	month = sep,
	number = {38},
	pages = {16056--16061},
	pmid = {21896765},
	title = {Neural language networks at birth},
	url = {http://www.pnas.org/content/108/38/16056},
	urldate = {2014-05-28},
	volume = {108},
	year = {2011},
	bdsk-url-1 = {http://www.pnas.org/content/108/38/16056},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1102991108}}

@article{lloyd-fox_are_2015,
	abstract = {Human interactions are guided by continuous communication among the parties involved, in which verbal communication plays a primary role. However, speech does not necessarily reveal to whom it is addressed, especially for young infants who are unable to decode its semantic content. To overcome such difficulty, adults often explicitly mark their communication as infant-directed. In the present study we investigated whether ostensive signals, which would disambiguate the infant as the addressee of a communicative act, would modulate the brain responses of 6-month-old infants to speech and gestures in an ecologically valid setting. In Experiment 1, we tested whether the gaze direction of the speaker modulates cortical responses to infant-direct speech. To provide a naturalistic environment, two infants and their parents participated at the same time. In Experiment 2, we tested whether a similar modulation of the cortical response would be obtained by varying the intonation (infant versus adult directed speech) of the speech during face-to-face communication, one on one. The results of both experiments indicated that only the combination of ostensive signals (infant directed speech and direct gaze) led to enhanced brain activation. This effect was indicated by responses localized in regions known to be involved in processing auditory and visual aspects of social communication. This study also demonstrated the potential of fNIRS as a tool for studying neural responses in naturalistic scenarios, and for simultaneous measurement of brain function in multiple participants.},
	author = {Lloyd-Fox, Sarah and Sz{\'e}plaki-K{\"o}ll{\H o}d, Borb{\'a}la and Yin, Jun and Csibra, Gergely},
	doi = {10.1016/j.cortex.2015.02.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F2FGEJ3X/Lloyd-Fox et al. - 2015 - Are you talking to me Neural activations in 6-mon.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VZ38G8EE/S0010945215000623.html:text/html},
	issn = {0010-9452},
	journal = {Cortex},
	keywords = {Communication, Infant-directed speech, Ostensive signals, Social interactions, fNIRS},
	month = sep,
	number = {Supplement C},
	pages = {35--48},
	series = {Special issue: {Neuro}-cognitive mechanisms of social interaction},
	shorttitle = {Are you talking to me?},
	title = {Are you talking to me? {Neural} activations in 6-month-old infants in response to being addressed during natural interactions},
	url = {http://www.sciencedirect.com/science/article/pii/S0010945215000623},
	urldate = {2017-12-08},
	volume = {70},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0010945215000623},
	bdsk-url-2 = {https://doi.org/10.1016/j.cortex.2015.02.005}}

@article{leaver_cortical_2010,
	abstract = {How the brain processes complex sounds, like voices or musical instrument sounds, is currently not well understood. The features comprising the acoustic profiles of such sounds are thought to be represented by neurons responding to increasing degrees of complexity throughout auditory cortex, with complete auditory ``objects'' encoded by neurons (or small networks of neurons) in anterior superior temporal regions. Although specialized voice and speech--sound regions have been proposed, it is unclear how other types of complex natural sounds are processed within this object-processing pathway. Using functional magnetic resonance imaging, we sought to demonstrate spatially distinct patterns of category-selective activity in human auditory cortex, independent of semantic content and low-level acoustic features. Category-selective responses were identified in anterior superior temporal regions, consisting of clusters selective for musical instrument sounds and for human speech. An additional subregion was identified that was particularly selective for the acoustic--phonetic content of speech. In contrast, regions along the superior temporal plane closer to primary auditory cortex were not selective for stimulus category, responding instead to specific acoustic features embedded in natural sounds, such as spectral structure and temporal modulation. Our results support a hierarchical organization of the anteroventral auditory-processing stream, with the most anterior regions representing the complete acoustic signature of auditory objects.},
	author = {Leaver, Amber M. and Rauschecker, Josef P.},
	doi = {10.1523/JNEUROSCI.0296-10.2010},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UJFX5IZW/Leaver et Rauschecker - 2010 - Cortical Representation of Natural Complex Sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TX6HCE4I/7604.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = feb,
	number = {22},
	pages = {7604--7612},
	pmid = {20519535},
	shorttitle = {Cortical {Representation} of {Natural} {Complex} {Sounds}},
	title = {Cortical {Representation} of {Natural} {Complex} {Sounds}: {Effects} of {Acoustic} {Features} and {Auditory} {Object} {Category}},
	url = {http://www.jneurosci.org/content/30/22/7604},
	urldate = {2016-03-17},
	volume = {30},
	year = {2010},
	bdsk-url-1 = {http://www.jneurosci.org/content/30/22/7604},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.0296-10.2010}}

@article{engineer_cortical_2008,
	abstract = {Neural activity in the cerebral cortex can explain many aspects of sensory perception. Extensive psychophysical and neurophysiological studies of visual motion and vibrotactile processing show that the firing rate of cortical neurons averaged across 50--500 ms is well correlated with discrimination ability. In this study, we tested the hypothesis that primary auditory cortex (A1) neurons use temporal precision on the order of 1--10 ms to represent speech sounds shifted into the rat hearing range. Neural discrimination was highly correlated with behavioral performance on 11 consonant-discrimination tasks when spike timing was preserved and was not correlated when spike timing was eliminated. This result suggests that spike timing contributes to the auditory cortex representation of consonant sounds.},
	author = {Engineer, Crystal T. and Perez, Claudia A. and Chen, YeTing H. and Carraway, Ryan S. and Reed, Amanda C. and Shetake, Jai A. and Jakkamsetti, Vikram and Chang, Kevin Q. and Kilgard, Michael P.},
	copyright = {{\copyright} 2008 Nature Publishing Group},
	doi = {10.1038/nn.2109},
	file = {Snapshot:/Users/Cecile/Zotero/storage/4BAS8JMD/nn.2109.html:text/html},
	issn = {1097-6256},
	journal = {Nature Neuroscience},
	language = {en},
	month = may,
	number = {5},
	pages = {603--608},
	title = {Cortical activity patterns predict speech discrimination ability},
	url = {http://www.nature.com/neuro/journal/v11/n5/full/nn.2109.html},
	urldate = {2015-05-22},
	volume = {11},
	year = {2008},
	bdsk-url-1 = {http://www.nature.com/neuro/journal/v11/n5/full/nn.2109.html},
	bdsk-url-2 = {https://doi.org/10.1038/nn.2109}}

@incollection{werner_morphological_2012-1,
	address = {New York, NY},
	author = {Abdala, Carolina and Keefe, Douglas H.},
	booktitle = {Human {Auditory} {Development}},
	editor = {Werner, Lynne and Fay, Richard R. and Popper, Arthur N.},
	file = {Chapter 2.pdf:/Users/Cecile/Zotero/storage/HUV3P9V2/Chapter 2.pdf:application/pdf},
	isbn = {978-1-4614-1420-9 978-1-4614-1421-6},
	pages = {19--59},
	publisher = {Springer New York},
	title = {Morphological and {Functional} {Ear} {Development}},
	url = {http://link.springer.com/10.1007/978-1-4614-1421-6_2},
	urldate = {2015-07-30},
	volume = {42},
	year = {2012},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-1-4614-1421-6_2}}

@article{versfeld_relationship_2002,
	abstract = {A conventional measure to determine the ability to understand speech in noisy backgrounds is the so-called speech reception threshold (SRT) for sentences. It yields the signal-to-noise ratio (in dB) for which half of the sentences are correctly perceived. The SRT defines to what degree speech must be audible to a listener in order to become just intelligible. There are indications that elderly listeners have greater difficulty in understanding speech in adverse listening conditions than young listeners. This may be partly due to the differences in hearing sensitivity (presbycusis), hence audibility, but other factors, such as temporal acuity, may also play a significant role. A potential measure for the temporal acuity may be the threshold to which speech can be accelerated, or compressed in time. A new test is introduced where the speech rate is varied adaptively. In analogy to the SRT, the time-compression threshold (or TCT) then is defined as the speech rate (expressed in syllables per second) for which half of the sentences are correctly perceived. In experiment I, the TCT test is introduced and normative data are provided. In experiment II, four groups of subjects (young and elderly normal-hearing and hearing-impaired subjects) participated, and the SRT's in stationary and fluctuating speech-shaped noise were determined, as well as the TCT. The results show that the SRT in fluctuating noise and the TCT are highly correlated. All tests indicate that, even after correction for the hearing loss, elderly normal-hearing subjects perform worse than young normal-hearing subjects. The results indicate that the use of the TCT test or the SRT test in fluctuating noise is preferred over the SRT test in stationary noise.},
	author = {Versfeld, Niek J and Dreschler, Wouter A},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Adult, Age Factors, Aged, Aging, Audiometry, Pure-Tone, Cochlea, Female, Hearing Loss, Sensorineural, Humans, Male, Middle Aged, Noise, Speech, Time Factors, speech perception, Speech Perception},
	language = {eng},
	month = jan,
	number = {1 Pt 1},
	pages = {401--408},
	pmid = {11831813},
	title = {The relationship between the intelligibility of time-compressed speech and speech in noise in young and elderly listeners},
	volume = {111},
	year = {2002}}

@article{obleser_what_2017,
	author = {Obleser, Jonas and Henry, Molly J. and Lakatos, Peter},
	doi = {10.1371/journal.pbio.2002794},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DDUKP3PB/Obleser et al. - 2017 - What do we talk about when we talk about rhythm.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5IVCBK97/article.html:text/html},
	issn = {1545-7885},
	journal = {PLOS Biology},
	keywords = {Biophysical simulations, Phase determination, Sensory perception, Sequence alignment, Sequence analysis, behavior, event-related potentials, Cognitive Science},
	month = sep,
	number = {9},
	pages = {e2002794},
	title = {What do we talk about when we talk about rhythm?},
	url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002794},
	urldate = {2017-10-17},
	volume = {15},
	year = {2017},
	bdsk-url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002794},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pbio.2002794}}

@article{sevy_neuroimaging_2010,
	abstract = {Cochlear implants (CI) are commonly used to treat deafness in young children. While many factors influence the ability of a deaf child who is hearing through a CI to develop speech and language skills, an important factor is that the CI has to stimulate the auditory cortex. Obtaining behavioral measurements from young children with CIs can often be unreliable. While a variety of noninvasive techniques can be used for detecting cortical activity in response to auditory stimuli, many have critical limitations when applied to the pediatric CI population. We tested the ability of near-infrared spectroscopy (NIRS) to detect cortical responses to speech stimuli in pediatric CI users. Neuronal activity leads to changes in blood oxy- and deoxy-hemoglobin concentrations that can be detected by measuring the transmission of near-infrared light through the tissue. To verify the efficacy of NIRS, we first compared auditory cortex responses measured with NIRS and fMRI in normal-hearing adults. We then examined four different participant cohorts with NIRS alone. Speech-evoked cortical activity was observed in 100\% of normal-hearing adults (11 of 11), 82\% of normal-hearing children (9 of 11), 78\% of deaf children who have used a CI \&gt; 4 months (28 of 36), and 78\% of deaf children who completed NIRS testing on the day of CI initial activation (7 of 9). Therefore, NIRS can measure cortical responses in pediatric CI users, and has the potential to be a powerful adjunct to current CI assessment tools.},
	author = {Sevy, Alexander B. G. and Bortfeld, Heather and Huppert, Theodore J. and Beauchamp, Michael S. and Tonini, Ross E. and Oghalai, John S.},
	doi = {10.1016/j.heares.2010.09.010},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T49PMQCH/S0378595510003904.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = dec,
	number = {1--2},
	pages = {39--47},
	title = {Neuroimaging with near-infrared spectroscopy demonstrates speech-evoked activity in the auditory cortex of deaf children following cochlear implantation},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595510003904},
	urldate = {2016-11-01},
	volume = {270},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595510003904},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2010.09.010}}

@article{pollonini_auditory_2014,
	abstract = {The primary goal of most cochlear implant procedures is to improve a patient's ability to discriminate speech. To accomplish this, cochlear implants are programmed so as to maximize speech understanding. However, programming a cochlear implant can be an iterative, labor-intensive process that takes place over months. In this study, we sought to determine whether functional near-infrared spectroscopy (fNIRS), a non-invasive neuroimaging method which is safe to use repeatedly and for extended periods of time, can provide an objective measure of whether a subject is hearing normal speech or distorted speech. We used a 140 channel fNIRS system to measure activation within the auditory cortex in 19 normal hearing subjects while they listed to speech with different levels of intelligibility. Custom software was developed to analyze the data and compute topographic maps from the measured changes in oxyhemoglobin and deoxyhemoglobin concentration. Normal speech reliably evoked the strongest responses within the auditory cortex. Distorted speech produced less region-specific cortical activation. Environmental sounds were used as a control, and they produced the least cortical activation. These data collected using fNIRS are consistent with the fMRI literature and thus demonstrate the feasibility of using this technique to objectively detect differences in cortical responses to speech of different intelligibility.},
	author = {Pollonini, Luca and Olds, Cristen and Abaya, Homer and Bortfeld, Heather and Beauchamp, Michael S. and Oghalai, John S.},
	doi = {10.1016/j.heares.2013.11.007},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9RMEBB8T/S0378595513002803.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = mar,
	pages = {84--93},
	title = {Auditory cortex activation to natural speech and simulated cochlear implant speech measured with functional near-infrared spectroscopy},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513002803},
	urldate = {2016-11-01},
	volume = {309},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513002803},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.11.007}}

@article{tanner_how_2015,
	abstract = {Although it is widely known that high-pass filters can reduce the amplitude of slow ERP components, these filters can also introduce artifactual peaks that lead to incorrect conclusions. To demonstrate this and provide evidence about optimal filter settings, we recorded ERPs in a typical language processing paradigm involving syntactic and semantic violations. Unfiltered results showed standard N400 and P600 effects in the semantic and syntactic violation conditions, respectively. However, high-pass filters with cutoffs at 0.3 Hz and above produced artifactual effects of opposite polarity before the true effect. That is, excessive high-pass filtering introduced a significant N400 effect preceding the P600 in the syntactic condition, and a significant P2 effect preceding the N400 in the semantic condition. Thus, inappropriate use of high-pass filters can lead to false conclusions about which components are influenced by a given manipulation. The present results also lead to practical recommendations for high-pass filter settings that maximize statistical power while minimizing filtering artifacts.},
	author = {Tanner, Darren and Morgan-Short, Kara and Luck, Steven J.},
	doi = {10.1111/psyp.12437},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/23X7U5IT/Tanner et al. - 2015 - How inappropriate high-pass filters can produce ar.pdf:application/pdf},
	issn = {0048-5772},
	journal = {Psychophysiology},
	month = aug,
	number = {8},
	pages = {997--1009},
	pmcid = {PMC4506207},
	pmid = {25903295},
	title = {How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in {ERP} studies of language and cognition},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4506207/},
	urldate = {2016-12-13},
	volume = {52},
	year = {2015},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4506207/},
	bdsk-url-2 = {https://doi.org/10.1111/psyp.12437}}

@article{osullivan_evidence_2015,
	abstract = {The human brain has evolved to operate effectively in highly complex acoustic environments, segregating multiple sound sources into perceptually distinct auditory objects. A recent theory seeks to explain this ability by arguing that stream segregation occurs primarily due to the temporal coherence of the neural populations that encode the various features of an individual acoustic source. This theory has received support from both psychoacoustic and functional magnetic resonance imaging (fMRI) studies that use stimuli which model complex acoustic environments. Termed stochastic figure--ground (SFG) stimuli, they are composed of a ``figure'' and background that overlap in spectrotemporal space, such that the only way to segregate the figure is by computing the coherence of its frequency components over time. Here, we extend these psychoacoustic and fMRI findings by using the greater temporal resolution of electroencephalography to investigate the neural computation of temporal coherence. We present subjects with modified SFG stimuli wherein the temporal coherence of the figure is modulated stochastically over time, which allows us to use linear regression methods to extract a signature of the neural processing of this temporal coherence. We do this under both active and passive listening conditions. Our findings show an early effect of coherence during passive listening, lasting from ∼115 to 185 ms post-stimulus. When subjects are actively listening to the stimuli, these responses are larger and last longer, up to ∼265 ms. These findings provide evidence for early and preattentive neural computations of temporal coherence that are enhanced by active analysis of an auditory scene.},
	author = {O'Sullivan, James A. and Shamma, Shihab A. and Lalor, Edmund C.},
	doi = {10.1523/JNEUROSCI.4973-14.2015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/MF5364HA/O'Sullivan et al. - 2015 - Evidence for Neural Computations of Temporal Coher.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GK6DXHT3/7256.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	keywords = {Auditory scene analysis, denoising source separation (DSS), electroencephalography (EEG), stream segregation, temporal coherence, temporal response function (TRF)},
	language = {en},
	month = jun,
	number = {18},
	pages = {7256--7263},
	pmid = {25948273},
	title = {Evidence for {Neural} {Computations} of {Temporal} {Coherence} in an {Auditory} {Scene} and {Their} {Enhancement} during {Active} {Listening}},
	url = {http://www.jneurosci.org/content/35/18/7256},
	urldate = {2016-05-11},
	volume = {35},
	year = {2015},
	bdsk-url-1 = {http://www.jneurosci.org/content/35/18/7256},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.4973-14.2015}}

@article{molavi_analyzing_2014,
	abstract = {We have evaluated the use of phase synchronization to identify resting state functional connectivity (RSFC) in the language system in infants using functional near infrared spectroscopy (fNIRS). We used joint probability distribution of phase between fNIRS channels with a seed channel in the language area to estimate phase relations and to identify the language system network. Our results indicate the feasibility of this method in identifying the language system. The connectivity maps are consistent with anatomical cortical connections and are also comparable to those obtained from functional magnetic resonance imaging (fMRI) functional connectivity studies. The results also indicate left hemisphere lateralization of the language network.},
	author = {Molavi, Behnam and May, Lillian and Gervain, Judit and Carreiras, Manuel and Werker, Janet F. and Dumont, Guy A.},
	doi = {10.3389/fnhum.2013.00921},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/87Z2CE4B/Molavi et al. - 2014 - Analyzing the resting state functional connectivit.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = jan,
	pmcid = {PMC3905209},
	pmid = {24523685},
	title = {Analyzing the resting state functional connectivity in the human language system using near infrared spectroscopy},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3905209/},
	urldate = {2016-12-12},
	volume = {7},
	year = {2014},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3905209/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2013.00921}}

@article{husain_review_2005,
	abstract = {Neonatal electroencephalography (EEG) presents some of the most difficult challenges in EEG interpretation. It differs significantly in many ways from EEG of older children and adults. Technologically, acquisition of a neonatal EEG is significantly more difficult and different than an adult EEG. There are numerous features that are age-specific and change almost week-to-week in the preterm infant. Some features may be normal at one age and abnormal if they persist for several weeks. Many of these features also have different implications in neonates as compared to older individuals. These issues mandate a different approach to neonatal EEG interpretation. In this article an overview of neonatal EEG is presented. After a brief discussion of relevant technical issues, various normal EEG features encountered in neonates are discussed. This is followed by a discussion of the ontogeny of EEG, starting from the age of viability to the first few months of life. A description of various abnormalities follows. Finally, an approach to analysis of a neonatal EEG is presented.},
	author = {Husain, Aatif M.},
	file = {Review_of_Neonatal_EEG.pdf:/Users/Cecile/Zotero/storage/5DP4GWZ7/Review_of_Neonatal_EEG.pdf:application/pdf},
	issn = {1086-508X},
	journal = {American Journal of Electroneurodiagnostic Technology},
	keywords = {Brain Mapping, Electroencephalography, Humans, Infant, Newborn, Infant, Newborn, Diseases, Brain Diseases, Diagnosis, Computer-Assisted, Practice Guidelines as Topic, Practice Patterns, Physicians', Sleep, Sleep Wake Disorders},
	language = {eng},
	month = mar,
	number = {1},
	pages = {12--35},
	pmid = {15832672},
	title = {Review of neonatal {EEG}},
	volume = {45},
	year = {2005}}

@article{pefkou_theta-_2017,
	abstract = {Recent psychophysics data suggest that speech perception is not limited by the capacity of the auditory system to encode fast acoustic variations through neural gamma activity, but rather by the time given to the brain to decode them. Whether the decoding process is bounded by the capacity of theta rhythm to follow speech syllabic rhythm, or constrained by a more endogenous top-down mechanism, e.g. involving beta activity, is unknown. We addressed the dynamics of auditory decoding in speech comprehension by challenging syllable tracking and speech decoding using comprehensible and incomprehensible time-compressed auditory sentences. We measured EEG in human participants and found that neural activity in both theta and gamma ranges was sensitive to syllabic rate. Phase patterns of slow neural activity consistently followed the syllabic rate (4---14 Hz), even when this rate went beyond the classical theta range (4---8 Hz). The power of theta activity increased linearly with syllabic rate but showed no sensitivity to comprehension. Conversely, the power of beta (14---21 Hz) activity was insensitive to syllabic rate, yet reflected comprehension on a single trial basis. Consistent with their role in stimulus driven versus endogenous mechanisms, we found different long-range dynamics for theta and beta activity, with beta activity building up in time while more contextual information becomes available. These data show that speech comprehension is constrained by concurrent stimulus-driven theta and low-gamma activity, and by endogenous beta activity, but not primarily by the capacity of theta activity to track the syllabic rhythm.
SIGNIFICANCE STATEMENT
Speech comprehension partly depends on the ability of the auditory cortex to track syllable boundaries with theta-range neural oscillations. The reason comprehension drops when speech is accelerated could hence be because theta oscillations can no longer follow the syllabic rate. Here, we presented subjects with comprehensible and incomprehensible accelerated speech, and show that neural phase patterns in the theta band consistently reflect the syllabic rate, even when speech becomes too fast to be intelligible. The drop in comprehension, however, is signaled by a significant decrease in the power of low-beta oscillations (14---21 Hz). These data suggest that speech comprehension is not limited by the capacity of theta oscillations to adapt to syllabic rate, but by an endogenous decoding process.},
	author = {Pefkou, Maria and Arnal, Luc H. and Fontolan, Lorenzo and Giraud, Anne-Lise},
	copyright = {Copyright {\copyright} 2017 the authors},
	doi = {10.1523/JNEUROSCI.2882-16.2017},
	file = {pefkou2017.pdf:/Users/Cecile/Zotero/storage/BGQZXB8K/pefkou2017.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/F94TET3S/JNEUROSCI.2882-16.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = jul,
	pages = {2882--16},
	pmid = {28729443},
	title = {Theta- and beta-band neural activity reflect independent syllable tracking and comprehension of time-compressed speech},
	url = {http://www.jneurosci.org/content/early/2017/07/20/JNEUROSCI.2882-16.2017},
	urldate = {2017-10-24},
	year = {2017},
	bdsk-url-1 = {http://www.jneurosci.org/content/early/2017/07/20/JNEUROSCI.2882-16.2017},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2882-16.2017}}

@article{gliga_development_2007,
	abstract = {Do infants perceive visual cues as diverse as frontal-view faces, profiles or bodies as being different aspects of the same object, a fellow human? If that is the case, visual exposure to one such cue should facilitate the subsequent processing of the others. To verify this hypothesis, we recorded event-related responses in 4-month-old infants and in adults. Pictures of eyes were interleaved amongst images belonging to three human contexts (frontal-view faces, profiles or bodies) or non-human contexts (houses, cars or pliers). In adults, both profile and frontal-face contexts elicited suppression of the N170 response to eye pictures, indicating an access to a view-invariant representation of faces. In infants, a response suppression of the N290 component was recorded only in the context of frontal faces, while profile context induces a different effect (i.e., a P400 enhancement) on eye processing. This dissociation suggests that the view-invariant representation of faces is learned, as it is for other 3-D objects and needs more than 4 months of exposure to be established. In a follow-up study, where infants were exposed to a short movie showing people rotating their heads, the profile-induced P400 effect was speeded up, indicating that exposure to successive views of the same object is probably a way to build up adult-like face representations.},
	author = {Gliga, Teodora and Dehaene-Lambertz, Ghislaine},
	doi = {10.1016/j.cognition.2006.01.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/P55DTJ6W/Gliga et Dehaene-Lambertz - 2007 - Development of a view-invariant representation of .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UNM2ERKD/S0010027706000187.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	keywords = {ERPs, Infant face perception, N170, Response suppression, View invariance},
	month = feb,
	number = {2},
	pages = {261--288},
	title = {Development of a view-invariant representation of the human head},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027706000187},
	urldate = {2017-02-17},
	volume = {102},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0010027706000187},
	bdsk-url-2 = {https://doi.org/10.1016/j.cognition.2006.01.004}}

@article{naatanen_mismatch_1995,
	abstract = {Physically deviant auditory stimuli occurring among frequent ("standard") stimuli (e.g., tones or phonetic stimuli) elicit the mismatch negativity (MMN) of the auditory event-related potential (ERP). The MMN is presumably generated by a mismatch process between the sensory input from a deviant stimulus and a neural sensory-memory trace representing the physical features of the standard stimulus. This process, as well as sensory analysis of auditory input and its encoding into the memory trace, appear to be automatic since the MMN is elicited even by changes in unattended auditory stimuli. Therefore the MMN indirectly provides a unique, objective measure of the central representation of a sound. This opens new possibilities for basic research as well as clinical and other applications.},
	author = {N{\"a}{\"a}t{\"a}nen, R. and Alho, K.},
	issn = {0020-7454},
	journal = {The International Journal of Neuroscience},
	keywords = {Adolescent, Adult, Age Factors, Aged, Aging, Auditory Perception, Evoked Potentials, Auditory, Humans, Learning, Automatism, Blindness, Memory, Middle Aged, Neural Pathways, Neuronal Plasticity, Brain},
	language = {eng},
	number = {1-4},
	pages = {317--337},
	pmid = {7775056},
	title = {Mismatch negativity--a unique measure of sensory processing in audition},
	volume = {80},
	year = {1995}}

@article{arichi_development_2012,
	abstract = {In the rodent brain the hemodynamic response to a brief external stimulus changes significantly during development. Analogous changes in human infants would complicate the determination and use of the hemodynamic response function (HRF) for functional magnetic resonance imaging (fMRI) in developing populations. We aimed to characterize HRF in human infants before and after the normal time of birth using rapid sampling of the Blood Oxygen Level Dependent (BOLD) signal. A somatosensory stimulus and an event related experimental design were used to collect data from 10 healthy adults, 15 sedated infants at term corrected post menstrual age (PMA) (median 41 + 1 weeks), and 10 preterm infants (median PMA 34 + 4 weeks). A positive amplitude HRF waveform was identified across all subject groups, with a systematic maturational trend in terms of decreasing time-to-peak and increasing positive peak amplitude associated with increasing age. Application of the age-appropriate HRF models to fMRI data significantly improved the precision of the fMRI analysis. These findings support the notion of a structured development in the brain's response to stimuli across the last trimester of gestation and beyond., ► First systematic characterization of the BOLD signal HRF in human neonates. ► A maturational trend in HRF morphology was identified. ► Application of empirical HRF models significantly improved neonatal fMRI analysis.},
	author = {Arichi, Tomoki and Fagiolo, Gianlorenzo and Varela, Marta and Melendez-Calderon, Alejandro and Allievi, Alessandro and Merchant, Nazakat and Tusor, Nora and Counsell, Serena J. and Burdet, Etienne and Beckmann, Christian F. and Edwards, A. David},
	doi = {10.1016/j.neuroimage.2012.06.054},
	issn = {1053-8119},
	journal = {Neuroimage},
	month = nov,
	number = {2},
	pages = {663--673},
	pmcid = {PMC3459097},
	pmid = {22776460},
	title = {Development of {BOLD} signal hemodynamic responses in the human brain},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459097/},
	urldate = {2016-12-19},
	volume = {63},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459097/},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2012.06.054}}

@article{lin_non-invasive_2013,
	abstract = {Perinatal brain injury remains a significant cause of infant mortality and morbidity, but there is not yet an effective bedside tool that can accurately screen for brain injury, monitor injury evolution, or assess response to therapy. The energy used by neurons is derived largely from tissue oxidative metabolism, and neural hyperactivity and cell death are reflected by corresponding changes in cerebral oxygen metabolism (CMRO₂). Thus, measures of CMRO₂ are reflective of neuronal viability and provide critical diagnostic information, making CMRO₂ an ideal target for bedside measurement of brain health. Brain-imaging techniques such as positron emission tomography (PET) and single-photon emission computed tomography (SPECT) yield measures of cerebral glucose and oxygen metabolism, but these techniques require the administration of radionucleotides, so they are used in only the most acute cases. Continuous-wave near-infrared spectroscopy (CWNIRS) provides non-invasive and non-ionizing radiation measures of hemoglobin oxygen saturation (SO₂) as a surrogate for cerebral oxygen consumption. However, SO₂ is less than ideal as a surrogate for cerebral oxygen metabolism as it is influenced by both oxygen delivery and consumption. Furthermore, measurements of SO₂ are not sensitive enough to detect brain injury hours after the insult, because oxygen consumption and delivery reach equilibrium after acute transients. We investigated the possibility of using more sophisticated NIRS optical methods to quantify cerebral oxygen metabolism at the bedside in healthy and brain-injured newborns. More specifically, we combined the frequency-domain NIRS (FDNIRS) measure of SO2 with the diffuse correlation spectroscopy (DCS) measure of blood flow index (CBFi) to yield an index of CMRO₂ (CMRO₂i). With the combined FDNIRS/DCS system we are able to quantify cerebral metabolism and hemodynamics. This represents an improvement over CWNIRS for detecting brain health, brain development, and response to therapy in neonates. Moreover, this method adheres to all neonatal intensive care unit (NICU) policies on infection control and institutional policies on laser safety. Future work will seek to integrate the two instruments to reduce acquisition time at the bedside and to implement real-time feedback on data quality to reduce the rate of data rejection.},
	author = {Lin, Pei-Yi and Roche-Labarbe, Nadege and Dehaes, Mathieu and Carp, Stefan and Fenoglio, Angela and Barbieri, Beniamino and Hagan, Katherine and Grant, P. Ellen and Franceschini, Maria Angela},
	doi = {10.3791/4379},
	issn = {1940-087X},
	journal = {Journal of Visualized Experiments: JoVE},
	keywords = {Hemodynamics, Humans, Infant, Cerebrovascular Circulation, Oxygen Consumption, Spectrum Analysis, Oxygen, Sulfur Dioxide, Spectroscopy, Near-Infrared, optical imaging, Brain},
	language = {eng},
	month = mar,
	number = {73},
	pages = {e4379},
	pmcid = {PMC3639513},
	pmid = {23524854},
	title = {Non-invasive optical measurement of cerebral metabolism and hemodynamics in infants},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.3791/4379}}

@article{seghier_functional_2006,
	abstract = {Summary
In order to provide accurate prognosis and developmental intervention to newborns, new methods of assessing cerebral functions are needed. The non-invasive technique of functional magnetic resonance imaging (fMRI) can be considered as the leading technique for functional exploration of the infant's brain. Several studies have previously applied fMRI in both healthy and diseased newborns with different sensory and cognitive tasks. In this chapter, the methodological issues that are proper to the use of fMRI in the newborn are detailed. In addition, an overview of the major findings of previous fMRI studies is provided, with a focus on notable differences from those in adult subjects. More specifically, the functional responses and the localization of cortical activations in healthy and diseased newborns are discussed. We expect a rapid expansion of this field and the establishment of fMRI as a valid clinical diagnostic tool in the newborn.},
	author = {Seghier, Mohamed L. and Lazeyras, Francois and Huppi, Petra S.},
	doi = {10.1016/j.siny.2006.07.007},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/U3VHGM8T/Seghier et al. - 2006 - Functional MRI of the newborn.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7KA9Z55Q/S1744165X06000734.html:text/html},
	issn = {1744-165X},
	journal = {Seminars in Fetal and Neonatal Medicine},
	keywords = {BOLD response, Brain activation, Brain plasticity, Functional MRI, Maturation, Newborn},
	month = dec,
	number = {6},
	pages = {479--488},
	series = {Assessing {Brain} {Function} in the {Perinatal} {Period}},
	title = {Functional {MRI} of the newborn},
	url = {http://www.sciencedirect.com/science/article/pii/S1744165X06000734},
	urldate = {2016-12-19},
	volume = {11},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1744165X06000734},
	bdsk-url-2 = {https://doi.org/10.1016/j.siny.2006.07.007}}

@article{marin-padilla_human_2012,
	abstract = {The capillary from the meningeal inner pial lamella play a crucial role in the development and structural organization of the cerebral cortex extrinsic and intrinsic microvascular compartments. Only pial capillaries are capable of perforating through the cortex external glial limiting membrane (EGLM) to enter into the nervous tissue, although incapable of perforating the membrane to exit the brain. Circulatory dynamics and functional demands determine which capillaries become arterial and which capillaries become venous. The perforation of the cortex EGLM by pial capillaries is a complex process characterized by three fundamental stages: (1) pial capillary contact with the EGLM with fusion of vascular and glial basal laminae at the contact site, (2) endothelial cell filopodium penetration through the fussed laminae with the formation of a funnel between them that accompanies it into the nervous tissue while remaining open to the meningeal interstitium and, (3) penetration of the whole capillary carrying the open funnel with it and establishing an extravascular Virchow-Robin Compartment (V-RC) that maintains the perforating vessel extrinsic (outside) the nervous tissue through its entire length. The V-RC is walled internally by the vascular basal lamina and externally by the basal lamina of joined glial cells endfeet. The VRC outer glial wall appear as an extension of the cortex superficial EGLM. All the perforating vessels within the V-RCs constitute the cerebral cortex extrinsic microvascular compartment. These perforating vessels are the only one capable of responding to inflammatory insults. The V-RC remains open (for life) to the meningeal interstitium permitting the exchanges of fluid and of cells between brain and meninges. The V-RC function as the brain sole drainage (prelymphatic) system in both physiological as well as pathological situations. During cortical development, capillaries emerge from the perforating vessels, by endothelial cells growing sprouts analogous to their angiogenesis, entering into their corresponding V-RCs. These new capillaries to enter into the nervous tissue must perforate through the V-RC outer glial wall, a process analogous to the original perforation of the cortex EGLM by pial capillaries. These emerging capillaries are incapable of reentering the V-RCs and/or perforating vessels. As the new capillary enters into the nervous tissue, it becomes surrounded by glial endfeet and carries a single basal lamina (possibly glial). Capillaries emerging from contiguous perforators establish an anastomotic plexus between them, by mechanisms still poorly understood. The capillaries of this anastomotic plexus constitute the cerebral cortex intrinsic microvascular compartment and together constitute the so-called blood-brain-barrier. The intrinsic capillaries are changing and readapting continuously, by both active angiogenesis and reabsorption, to the gray matter neurons developmental and functional needs. The brain intrinsic capillaries are among the most active microvessels of the human body. Unresolved developmental and functional aspects concerning the cerebral cortex intrinsic capillary plexus need to be further investigated.},
	author = {Mar{\'\i}n-Padilla, Miguel},
	doi = {10.3389/fnana.2012.00038},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/FZKXGCPX/Mar{\'\i}n-Padilla - 2012 - The human brain intracerebral microvascular system.pdf:application/pdf},
	issn = {1662-5129},
	journal = {Frontiers in Neuroanatomy},
	month = sep,
	pmcid = {PMC3440694},
	pmid = {22993505},
	shorttitle = {The human brain intracerebral microvascular system},
	title = {The human brain intracerebral microvascular system: development and structure},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3440694/},
	urldate = {2016-12-19},
	volume = {6},
	year = {2012},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3440694/},
	bdsk-url-2 = {https://doi.org/10.3389/fnana.2012.00038}}

@article{lloyd-fox_cortical_2017,
	abstract = {Brain and nervous system development in human infants during the first 1000 days (conception to two years of age) is critical, and compromised development during this time (such as from under nutrition or poverty) can have life-long effects on physical growth and cognitive function. Cortical mapping of cognitive function during infancy is poorly understood in resource-poor settings due to the lack of transportable and low-cost neuroimaging methods. Having established a signature cortical response to social versus non-social visual and auditory stimuli in infants from 4 to 6 months of age in the UK, here we apply this functional Near Infrared Spectroscopy (fNIRS) paradigm to investigate social responses in infants from the first postnatal days to the second year of life in two contrasting environments: rural Gambian and urban UK. Results reveal robust, localized, socially selective brain responses from 9--24 months of life to both the visual and auditory stimuli. In contrast at 0--2 months of age infants exhibit non-social auditory selectivity, an effect that persists until 4--8 months when we observe a transition to greater social stimulus selectivity. These findings reveal a robust developmental curve of cortical specialization over the first two years of life.},
	author = {Lloyd-Fox, S. and Begus, K. and Halliday, D. and Pirazzoli, L. and Blasi, A. and Papademetriou, M. and Darboe, M. K. and Prentice, A. M. and Johnson, M. H. and Moore, S. E. and Elwell, C. E.},
	doi = {10.1016/j.dcn.2016.11.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SPQ4RW59/Lloyd-Fox et al. - Cortical specialisation to social stimuli from the.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H5CVHHBF/S1878929316301840.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {low- and middle-income countries, nutrition, poverty, social cognition, fNIRS, infancy},
	month = jun,
	pages = {92--104},
	shorttitle = {Cortical specialisation to social stimuli from the first days to the second year of life},
	title = {Cortical specialisation to social stimuli from the first days to the second year of life: {A} rural {Gambian} cohort.},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929316301840},
	urldate = {2016-12-21},
	volume = {25},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316301840},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2016.11.005}}

@article{lloyd-fox_fnirs_2016,
	abstract = {The goal of our work is to establish assessments to evaluate the impact of early risk on cognitive development in infancy and childhood in global health settings. Prior work using functional near-infrared spectroscopy (fNIRS) has shown differential brain responses in infants to social vs. nonsocial stimuli in urban European (Lloyd-Fox et al., 2009; 2013) cohorts. This experimental paradigm has been proposed as an objective measure of social cognition that can be used in many different cohorts with minimal adaptation.
Cortical mapping of the brain during infancy is rarely undertaken in low-income countries due to the lack of transportable neuroimaging methods. Functional near infrared spectroscopy (fNIRS) - which uses the absorption of near infrared light to non-invasively measure changes in oxygen in the blood - is an elegant method for assessing cognitive function in such settings. Participants, ranging in age from 4 -- 8 months (UK: N = 64; The Gambia: N = 24; Bangladesh: N = 23), were tested with a multi-channel NIRS system that recorded brain activity over the frontal and temporal cortices. The experimental stimuli presented were videos of people moving their eyes or hands (i.e. a ``Peek-a-boo'' game), accompanied by vocal sounds (i.e. yawn, laughter), non-vocal sounds (i.e. water running, bell), or silence. Social videos were alternated with control blocks of pictures of local modes of transportation presented with no sounds.
Here we present a comparison of data collected in urban European, rural African and urban Asian cohorts. Participants in The Gambia lived in a rural community of subsistence farmers and participants in Bangladesh lived in an urban slum. Both cohorts were exposed to a broad range of adversity early in life including poverty, under-nourishment, recurrent infections, and lack of maternal education.
Our results indicate specialised social {\textgreater} non-social activation in the superior and middle temporal cortex across all three cohorts and across 4 -- 36 months of life. These results confirm the suitability of fNIRS in this age group in a resource poor setting. Changes in cortical haemoglobin may afford early biomarkers that are more sensitive to nutritional insults and early adversity affecting cognition than current standardised behavioural measures.
Support or Funding Information
Bill and Melinda Gates Foundation, Medical Research Council UK,},
	author = {Lloyd-Fox, Sarah and Moore, Sophie and Darboe, Momodou and Prentice, Andrew and Papademetriou, Maria and Blasi, Anna and Kumar, Swapna and Westerlund, Alissa and Perdue, Katherine L. and Johnson, Mark H. and Nelson, Charles A. and Elwell, Clare E.},
	file = {Snapshot:/Users/Cecile/Zotero/storage/PIHKKW97/1149.18.html:text/html},
	issn = {0892-6638, 1530-6860},
	journal = {The FASEB Journal},
	language = {en},
	month = jan,
	number = {1 Supplement},
	pages = {1149.18--1149.18},
	shorttitle = {{fNIRS} in {Africa} \& {Asia}},
	title = {{fNIRS} in {Africa} \& {Asia}: an {Objective} {Measure} of {Cognitive} {Development} for {Global} {Health} {Settings}},
	url = {http://www.fasebj.org/content/30/1_Supplement/1149.18},
	urldate = {2016-12-21},
	volume = {30},
	year = {2016},
	bdsk-url-1 = {http://www.fasebj.org/content/30/1_Supplement/1149.18}}

@article{homae_large-scale_2011,
	abstract = {A critical issue in human development is that of whether the language-related areas in the left frontal and temporal regions work as a functional network in preverbal infants. Here, we used 94-channel near-infrared spectroscopy to reveal the functional networks in the brains of sleeping 3-month-old infants with and without presenting speech sounds. During the first 3 min, we measured spontaneous brain activation (period 1). After period 1, we provided stimuli by playing Japanese sentences for 3 min (period 2). Finally, we measured brain activation for 3 min without providing the stimulus (period 3), as in period 1. We found that not only the bilateral temporal and temporoparietal regions but also the prefrontal and occipital regions showed oxygenated hemoglobin signal increases and deoxygenated hemoglobin signal decreases when speech sounds were presented to infants. By calculating time-lagged cross-correlations and coherences of oxy-Hb signals between channels, we tested the functional connectivity for the three periods. The oxy-Hb signals in neighboring channels, as well as their homologous channels in the contralateral hemisphere, showed high correlation coefficients in period 1. Similar correlations were observed in period 2; however, the number of channels showing high correlations was higher in the ipsilateral hemisphere, especially in the anterior--posterior direction. The functional connectivity in period 3 showed a close relationship between the frontal and temporal regions, which was less prominent in period 1, indicating that these regions form the functional networks and work as a hysteresis system that has memory of the previous inputs. We propose a hypothesis that the spatiotemporally large-scale brain networks, including the frontal and temporal regions, underlie speech processing in infants and they might play important roles in language acquisition during infancy.},
	author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Taga, Gentaro},
	doi = {10.3389/fpsyg.2011.00093},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/5MTSW9SJ/Homae et al. - 2011 - Large-Scale Brain Networks Underlying Language Acq.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	month = may,
	pmcid = {PMC3110337},
	pmid = {21687461},
	title = {Large-{Scale} {Brain} {Networks} {Underlying} {Language} {Acquisition} in {Early} {Infancy}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110337/},
	urldate = {2016-12-21},
	volume = {2},
	year = {2011},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110337/},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2011.00093}}

@article{khakh_diversity_2015,
	abstract = {Astrocytes tile the entire CNS. They are vital for neural circuit function, but have traditionally been viewed as simple, homogenous cells that serve the same essential supportive roles everywhere. Here, we summarize breakthroughs that instead indicate that astrocytes represent a population of complex and functionally diverse cells. Physiological diversity of astrocytes is apparent between different brain circuits and microcircuits, and individual astrocytes display diverse signaling in subcellular compartments. With respect to injury and disease, astrocytes undergo diverse phenotypic changes that may be protective or causative with regard to pathology in a context-dependent manner. These new insights herald the concept that astrocytes represent a diverse population of genetically tractable cells that mediate neural circuit-specific roles in health and disease.},
	author = {Khakh, Baljit S and Sofroniew, Michael V},
	doi = {10.1038/nn.4043},
	file = {KhakhSofroniew15.pdf:/Users/Cecile/Zotero/storage/W9Q965FF/ContentServer.asp.pdf:application/pdf},
	issn = {10976256},
	journal = {Nature Neuroscience},
	keywords = {NEURAL circuitry, BRAIN -- Research, ASTROCYTES, CELLS, CENTRAL NERVOUS SYSTEM},
	month = jul,
	number = {7},
	pages = {942--952},
	title = {Diversity of astrocyte functions and phenotypes in neural circuits},
	url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=103427935&lang=fr&site=eds-live&scope=site},
	urldate = {2016-12-22},
	volume = {18},
	year = {2015},
	bdsk-url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=103427935&lang=fr&site=eds-live&scope=site},
	bdsk-url-2 = {https://doi.org/10.1038/nn.4043}}

@article{bouchon_hemispheric_2015,
	abstract = {Background The repeated presentation of stimuli typically attenuates neural responses (repetition suppression) or, less commonly, increases them (repetition enhancement) when stimuli are highly complex, degraded or presented under noisy conditions. In adult functional neuroimaging research, these repetition effects are considered as neural correlates of habituation. The development and respective functional significance of these effects in infancy remain largely unknown.   Objective This study investigates repetition effects in newborns using functional near-infrared spectroscopy, and specifically the role of stimulus complexity in evoking a repetition enhancement vs. a repetition suppression response, following up on Gervain et al. (2008). In that study, abstract rule-learning was found at birth in cortical areas specific to speech processing, as evidenced by a left-lateralized repetition enhancement of the hemodynamic response to highly variable speech sequences conforming to a repetition-based ABB artificial grammar, but not to a random ABC grammar.   Methods Here, the same paradigm was used to investigate how simpler stimuli (12 different sequences per condition as opposed to 140), and simpler presentation conditions (blocked rather than interleaved) would influence repetition effects at birth.   Results Results revealed that the two grammars elicited different dynamics in the two hemispheres. In left fronto-temporal areas, we reproduce the early perceptual discrimination of the two grammars, with ABB giving rise to a greater response at the beginning of the experiment than ABC. In addition, the ABC grammar evoked a repetition enhancement effect over time, whereas a stable response was found for the ABB grammar. Right fronto-temporal areas showed neither initial discrimination, nor change over time to either pattern.   Conclusion Taken together with Gervain et al. (2008), this is the first evidence that manipulating methodological factors influences the presence or absence of neural repetition enhancement effects in newborns and stimulus variability appears a particularly important factor. Further, this temporal modulation is restricted to the left hemisphere, confirming its specialization for learning linguistic regularities from birth.},
	author = {Bouchon, Camillia and Nazzi, Thierry and {Judit Gervain}},
	doi = {10.1371/journal.pone.0140160},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/S9BQ24HP/Bouchon et al. - 2015 - Hemispheric Asymmetries in Repetition Enhancement .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DUCZ4RSA/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Hemodynamics, Learning, Grammar, Left hemisphere, Syllables, neuroimaging, Near-infrared spectroscopy, functional magnetic resonance imaging},
	month = oct,
	number = {10},
	pages = {e0140160},
	title = {Hemispheric {Asymmetries} in {Repetition} {Enhancement} and {Suppression} {Effects} in the {Newborn} {Brain}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140160},
	urldate = {2016-12-23},
	volume = {10},
	year = {2015},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140160},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0140160}}

@article{clarke_emerging_2013,
	abstract = {Astrocytes are now emerging as key participants in many aspects of brain development, function and disease. In particular, new evidence shows that astrocytes powerfully control the formation, maturation, function and elimination of synapses through various secreted and contact-mediated signals. Astrocytes are also increasingly being implicated in the pathophysiology of many psychiatric and neurological disorders that result from synaptic defects. A better understanding of how astrocytes regulate neural circuit development and function in the healthy and diseased brain might lead to the development of therapeutic agents to treat these diseases.},
	author = {Clarke, Laura E. and Barres, Ben A.},
	doi = {10.1038/nrn3484},
	file = {ClarkeBarres13.pdf:/Users/Cecile/Zotero/storage/ZCWRJQJR/ClarkeBarres13.pdf:application/pdf},
	issn = {1471003X},
	journal = {Nature Reviews Neuroscience},
	keywords = {NEURAL circuitry, ASTROCYTES, Neural development, Pathological physiology, Nervous system -- Abnormalities, Synapses},
	month = may,
	number = {5},
	pages = {311--321},
	title = {Emerging roles of astrocytes in neural circuit development},
	url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=87027738&lang=fr&site=eds-live&scope=site},
	urldate = {2016-12-22},
	volume = {14},
	year = {2013},
	bdsk-url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=87027738&lang=fr&site=eds-live&scope=site},
	bdsk-url-2 = {https://doi.org/10.1038/nrn3484}}

@article{homae_right_2006,
	abstract = {Behavioral studies proposed that prosodic information in speech sounds plays important roles for human infants to acquire their native languages. Here, we examined the neural basis of prosodic processing in 3-month-old infants. In order to obtain hemodynamic responses with high signal-to-noise ratio, we used near-infrared optical topography in the infants while they were in quiet sleep. First, we observed bilateral activation under each of the normal and flattened speech conditions. The flattened speech sound was created by eliminating changes in the pitch contours of the original utterance. In a direct comparison between the two conditions, the right temporoparietal region showed more prominent activation to normal speech sounds than to flattened speech sounds. This result demonstrates that the localized region of the right hemisphere in 3-month-old infant is involved in the processing of pitch contours. Our findings suggest that prosodic processing in the right hemisphere may facilitate the acquisition of lexical or syntactic knowledge in the early stages of language development.},
	author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Asakawa, Kayo and Taga, Gentaro},
	doi = {10.1016/j.neures.2005.12.006},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GHHRAW4W/Homae et al. - 2006 - The right hemisphere of sleeping infant perceives .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VTZZFQNM/S0168010205003287.html:text/html},
	issn = {0168-0102},
	journal = {Neuroscience Research},
	keywords = {Infant, Near-infrared optical topography, language acquisition, speech perception, Intonation, prosody, Speech Perception},
	month = apr,
	number = {4},
	pages = {276--280},
	title = {The right hemisphere of sleeping infant perceives sentential prosody},
	url = {http://www.sciencedirect.com/science/article/pii/S0168010205003287},
	urldate = {2016-12-23},
	volume = {54},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010205003287},
	bdsk-url-2 = {https://doi.org/10.1016/j.neures.2005.12.006}}

@article{reemst_indispensable_2016,
	abstract = {Glia are essential for brain functioning during development and in the adult brain. Here, we discuss the various roles of both microglia and astrocytes, and their interactions during brain development. Although both cells are fundamentally different in origin and function, they often affect the same developmental processes such as neuro-/gliogenesis, angiogenesis, axonal outgrowth, synaptogenesis and synaptic pruning. Due to their important instructive roles in these processes, dysfunction of microglia or astrocytes during brain development could contribute to neurodevelopmental disorders and potentially even late-onset neuropathology. A better understanding of the origin, differentiation process and developmental functions of microglia and astrocytes will help to fully appreciate their role both in the developing as well as in the adult brain, in health and disease.},
	author = {Reemst, Kitty and Noctor, Stephen C. and Lucassen, Paul J. and Hol, Elly M.},
	doi = {10.3389/fnhum.2016.00566},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DWN9UGPQ/Reemst et al. - 2016 - The Indispensable Roles of Microglia and Astrocyte.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	keywords = {Brain development, ASTROCYTES, Microglia, glial cells, Neurodevelopmental disorders},
	language = {English},
	title = {The {Indispensable} {Roles} of {Microglia} and {Astrocytes} during {Brain} {Development}},
	url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00566/abstract},
	urldate = {2016-12-22},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00566/abstract},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2016.00566}}

@article{grossmann_early_2008,
	abstract = {This study examined the brain bases of early human social cognitive abilities. Specifically, we investigated whether cortical regions implicated in adults' perception of facial communication signals are functionally active in early human development. Four-month-old infants watched two kinds of dynamic scenarios in which a face either established mutual gaze or averted its gaze, both of which were followed by an eyebrow raise with accompanying smile. Haemodynamic responses were measured by near-infrared spectroscopy, permitting spatial localization of brain activation (experiment 1), and gamma-band oscillatory brain activity was analysed from electroencephalography to provide temporal information about the underlying cortical processes (experiment 2). The results revealed that perceiving facial communication signals activates areas in the infant temporal and prefrontal cortex that correspond to the brain regions implicated in these processes in adults. In addition, mutual gaze itself, and the eyebrow raise with accompanying smile in the context of mutual gaze, produce similar cortical activations. This pattern of results suggests an early specialization of the cortical network involved in the perception of facial communication cues, which is essential for infants' interactions with, and learning from, others.},
	author = {Grossmann, Tobias and Johnson, Mark H. and Lloyd-Fox, Sarah and Blasi, Anna and Deligianni, Fani and Elwell, Clare and Csibra, Gergely},
	copyright = {Copyright {\copyright} 2008 The Royal Society. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	doi = {10.1098/rspb.2008.0986},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/HZHE5NZR/Grossmann et al. - 2008 - Early cortical specialization for face-to-face com.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NBARQ28K/2803.html:text/html},
	issn = {0962-8452, 1471-2954},
	journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	language = {en},
	month = dec,
	number = {1653},
	pages = {2803--2811},
	pmid = {18755668},
	title = {Early cortical specialization for face-to-face communication in human infants},
	url = {http://rspb.royalsocietypublishing.org/content/275/1653/2803},
	urldate = {2016-12-23},
	volume = {275},
	year = {2008},
	bdsk-url-1 = {http://rspb.royalsocietypublishing.org/content/275/1653/2803},
	bdsk-url-2 = {https://doi.org/10.1098/rspb.2008.0986}}

@article{harris_physiology_2011,
	abstract = {BOLD fMRI (blood oxygenation level dependent functional magnetic resonance imaging) is increasingly used to detect developmental changes of human brain function that are hypothesized to underlie the maturation of cognitive processes. BOLD signals depend on neuronal activity increasing cerebral blood flow, and are reduced by neural oxygen consumption. Thus, developmental changes of BOLD signals may not reflect altered information processing if there are concomitant changes in neurovascular coupling (the mechanism by which neuronal activity increases blood flow) or neural energy use (and hence oxygen consumption). We review how BOLD signals are generated, and explain the signalling pathways which convert neuronal activity into increased blood flow. We then summarize in broad terms the developmental changes that the brain's neural circuitry undergoes during growth from childhood through adolescence to adulthood, and present the changes in neurovascular coupling mechanisms and energy use which occur over the same period. This information provides a framework for assessing whether the BOLD changes observed during human development reflect altered cognitive processing or changes in neurovascular coupling and energy use.},
	author = {Harris, Julia J. and Reynell, Clare and Attwell, David},
	doi = {10.1016/j.dcn.2011.04.001},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TT9RVVZH/Harris et al. - 2011 - The physiology of developmental changes in BOLD fu.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RJC63V8H/S1878929311000314.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {BOLD fMRI, Blood flow, Energy, Glutamate, Neurovascular coupling, Development},
	month = jul,
	number = {3},
	pages = {199--216},
	title = {The physiology of developmental changes in {BOLD} functional imaging signals},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929311000314},
	urldate = {2016-12-26},
	volume = {1},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929311000314},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2011.04.001}}

@article{maki_optical_1999,
	author = {Maki, Atsushi and Yamashita, Yuichi and Watanabe, Eijyu and Yamamoto, Tsuyoshi and Kogure, Kyuya and Kawaguchi, Fumio and Koizumi, Hideaki},
	file = {Snapshot:/Users/Cecile/Zotero/storage/2DMRZGA5/cat.inist.fr.html:text/html},
	issn = {0277-786X},
	journal = {Proceedings of SPIE, the International Society for Optical Engineering},
	language = {eng},
	pages = {202--212},
	title = {Optical topography},
	url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=17451877},
	urldate = {2017-08-14},
	volume = {3597},
	year = {1999},
	bdsk-url-1 = {http://cat.inist.fr/?aModele=afficheN&cpsidt=17451877}}

@article{hall_interpreting_2016,
	abstract = {Cognitive neuroscience depends on the use of blood oxygenation level-dependent (BOLD) functional magnetic resonance imaging (fMRI) to probe brain function. Although commonly used as a surrogate measure of neuronal activity, BOLD signals actually reflect changes in brain blood oxygenation. Understanding the mechanisms linking neuronal activity to vascular perfusion is, therefore, critical in interpreting BOLD. Advances in cellular neuroscience demonstrating differences in this neurovascular relationship in different brain regions, conditions or pathologies are often not accounted for when interpreting BOLD. Meanwhile, within cognitive neuroscience, the increasing use of high magnetic field strengths and the development of model-based tasks and analyses have broadened the capability of BOLD signals to inform us about the underlying neuronal activity, but these methods are less well understood by cellular neuroscientists. In 2016, a Royal Society Theo Murphy Meeting brought scientists from the two communities together to discuss these issues. Here, we consolidate the main conclusions arising from that meeting. We discuss areas of consensus about what BOLD fMRI can tell us about underlying neuronal activity, and how advanced modelling techniques have improved our ability to use and interpret BOLD. We also highlight areas of controversy in understanding BOLD and suggest research directions required to resolve these issues.
This article is part of the themed issue `Interpreting BOLD: a dialogue between cognitive and cellular neuroscience'.},
	author = {Hall, Catherine N. and Howarth, Clare and Kurth-Nelson, Zebulun and Mishra, Anusha},
	copyright = {{\copyright} 2016 The Author(s). http://royalsocietypublishing.org/licencePublished by the Royal Society. All rights reserved.},
	doi = {10.1098/rstb.2015.0348},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/JXK89STX/Hall et al. - 2016 - Interpreting BOLD towards a dialogue between cogn.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2QE76GI7/20150348.html:text/html},
	issn = {0962-8436, 1471-2970},
	journal = {Phil. Trans. R. Soc. B},
	language = {en},
	month = oct,
	number = {1705},
	pages = {20150348},
	pmid = {27574302},
	shorttitle = {Interpreting {BOLD}},
	title = {Interpreting {BOLD}: towards a dialogue between cognitive and cellular neuroscience},
	url = {http://rstb.royalsocietypublishing.org/content/371/1705/20150348},
	urldate = {2016-12-26},
	volume = {371},
	year = {2016},
	bdsk-url-1 = {http://rstb.royalsocietypublishing.org/content/371/1705/20150348},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2015.0348}}

@article{cheour_auditory_2002,
	abstract = {The present study investigated the temporal dynamics of auditory sensory memory in newborns as reflected by the mismatch negativity (MMN), a preattentive electric change-detection response. MMN was obtained from 24 full-term healthy newborns who were either awake or asleep (quiet or active sleep) during the experiments. Stimuli were 1,000 Hz tones (standards) that were occasionally replaced by 1,100 Hz tones (deviants). The constant stimulus onset asynchrony (SOA) was, in separate blocks, either 450, 800, or 1,500 ms. A prominent MMN was obtained at the 800 ms SOA in all three sleep or waking states, whereas no MMN occurred at 450 and 1,500 ms SOAs. In view of the fact that in adults MMN is elicited even with a 10s SOA, these results imply that the time span of auditory memory is considerably shorter in neonates than in adults and 8-12-year-old children.},
	author = {Cheour, Marie and {\v C}{\.e}ponien{\'e}, Rita and Lepp{\"a}nen, Paavo and Alho, Kimmo and Kujala, Teija and Renlund, Martin and Fellman, Vineta and N{\"a}{\"a}t{\"a}nen, Risto},
	doi = {10.1111/1467-9450.00266},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/TJBE7A8E/Cheour et al. - 2002 - The auditory sensory memory trace decays rapidlyin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5EN33MHG/abstract.html:text/html},
	issn = {1467-9450},
	journal = {Scandinavian Journal of Psychology},
	language = {en},
	month = feb,
	number = {1},
	pages = {33--39},
	title = {The auditory sensory memory trace decays rapidlyin newborns},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00266/abstract},
	urldate = {2016-12-26},
	volume = {43},
	year = {2002},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00266/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/1467-9450.00266}}

@article{haartsen_human_2016,
	abstract = {Recent studies of the structural and functional development of the human brain over the early years have highlighted the rapid development of brain structures and their interconnectivity. Some regional functional specializations emerge within the first months after birth, while others have a more protracted course of development spanning over the first decade or longer. While some anatomical changes enable the emergence of new functions, evidence also points to the importance of resting state oscillations in sculpting neural architecture during development. In atypical development differences in brain structure, function and task-related activity in infancy often precede the emergence of later diagnostic behavioural symptoms.},
	author = {Haartsen, Rianne and Jones, Emily JH and Johnson, Mark H},
	doi = {10.1016/j.cobeha.2016.05.015},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IWI4J3MM/Haartsen et al. - 2016 - Human brain development over the early years.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T3H3JWC5/S2352154616301164.html:text/html},
	issn = {2352-1546},
	journal = {Current Opinion in Behavioral Sciences},
	month = aug,
	pages = {149--154},
	series = {Neuroscience of education},
	title = {Human brain development over the early years},
	url = {http://www.sciencedirect.com/science/article/pii/S2352154616301164},
	urldate = {2016-12-26},
	volume = {10},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S2352154616301164},
	bdsk-url-2 = {https://doi.org/10.1016/j.cobeha.2016.05.015}}

@incollection{kozberg_chapter_2016,
	abstract = {In the adult brain, increases in local neural activity are almost always accompanied by increases in local blood flow. However, many functional imaging studies of the newborn and developing human brain have observed patterns of hemodynamic responses that differ from adult responses. Among the proposed mechanisms for the observed variations is that neurovascular coupling itself is still developing in the perinatal brain. Many of the components thought to be involved in actuating and propagating this hemodynamic response are known to still be developing postnatally, including perivascular cells such as astrocytes and pericytes. Both neural and vascular networks expand and are then selectively pruned over the first year of human life. Additionally, the metabolic demands of the newborn brain are still evolving. These changes are highly likely to affect early postnatal neurovascular coupling, and thus may affect functional imaging signals in this age group. This chapter will discuss the literature relating to neurovascular development. Potential effects of normal and aberrant development of neurovascular coupling on the newborn brain will also be explored, as well as ways to effectively utilize imaging techniques that rely on hemodynamic modulation such as fMRI and NIRS in younger populations.},
	author = {Kozberg, M. and Hillman, E.},
	booktitle = {Progress in {Brain} {Research}},
	editor = {Kazuto Masamoto, Hajime Hirase {and} Katsuya Yamada},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UB2XJEXD/S0079612316000376.html:text/html},
	keywords = {Brain development, Brain metabolism, Neurovascular coupling, fMRI, optical imaging},
	pages = {213--242},
	publisher = {Elsevier},
	series = {New {Horizons} in {Neurovascular} {Coupling}: {A} {Bridge} {Between} {Brain} {Circulation} and {Neural} {Plasticity}},
	title = {Chapter 10 - {Neurovascular} coupling and energy metabolism in the developing brain},
	url = {http://www.sciencedirect.com/science/article/pii/S0079612316000376},
	urldate = {2016-12-26},
	volume = {225},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0079612316000376}}

@article{dukart_cerebral_2017,
	abstract = {Application of metabolic magnetic resonance imaging measures such as cerebral blood flow in translational medicine is limited by the unknown link of observed alterations to specific neurophysiological processes. Here we address this question by probing cerebral blood flow in healthy volunteers using seven established drugs with known dopaminergic, serotonergic, glutamatergic and GABAergic mechanisms of action in a novel framework aimed at disentangling the observed effects to underlying neurotransmitter systems. We find for all evaluated compounds a reliable spatial link of respective cerebral blood flow changes with underlying activity and/or neurotransmitter receptor densities corresponding to their primary mechanisms of action. The strength of these associations with receptor density is mediated by respective drug affinities. These findings validate cerebral blood flow as a sensitive brain-wide in-vivo assay of metabolic demands across a variety of neurotransmitter systems in humans, with widespread implications for translational medicine and drug discovery alike.},
	author = {Dukart, Juergen and Holiga, Stefan and Chatham, Christopher and Hawkins, Peter and Forsyth, Anna and McMillan, Rebecca and Myers, Jim and Lingford-Hughes, Anne and Nutt, David and Merlo-Pich, Emilio and Risterucci, Celine and Umbricht, Daniel and Boak, Lauren and Schobel, Scott and Liu, Thomas and Mehta, Mitul and Zelaya, Fernando and Williams, Steve and Brown, Gregory and Paulus, Martin and Honey, Garry and Muthukumaraswamy, Suresh and Hipp, Joerg and Bertolino, Alessandro and Sambataro, Fabio},
	copyright = {{\copyright} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	doi = {10.1101/207407},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/M5M4PMAA/Dukart et al. - 2017 - Cerebral blood flow predicts differential neurotra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4Q97CAFV/207407.html:text/html},
	journal = {bioRxiv},
	language = {en},
	month = oct,
	pages = {207407},
	title = {Cerebral blood flow predicts differential neurotransmitter activity},
	url = {https://www.biorxiv.org/content/early/2017/10/24/207407},
	urldate = {2017-10-25},
	year = {2017},
	bdsk-url-1 = {https://www.biorxiv.org/content/early/2017/10/24/207407},
	bdsk-url-2 = {https://doi.org/10.1101/207407}}

@article{ma_resting-state_2016,
	abstract = {Brain hemodynamics serve as a proxy for neural activity in a range of noninvasive neuroimaging techniques including functional magnetic resonance imaging (fMRI). In resting-state fMRI, hemodynamic fluctuations have been found to exhibit patterns of bilateral synchrony, with correlated regions inferred to have functional connectivity. However, the relationship between resting-state hemodynamics and underlying neural activity has not been well established, making the neural underpinnings of functional connectivity networks unclear. In this study, neural activity and hemodynamics were recorded simultaneously over the bilateral cortex of awake and anesthetized Thy1-GCaMP mice using wide-field optical mapping. Neural activity was visualized via selective expression of the calcium-sensitive fluorophore GCaMP in layer 2/3 and 5 excitatory neurons. Characteristic patterns of resting-state hemodynamics were accompanied by more rapidly changing bilateral patterns of resting-state neural activity. Spatiotemporal hemodynamics could be modeled by convolving this neural activity with hemodynamic response functions derived through both deconvolution and gamma-variate fitting. Simultaneous imaging and electrophysiology confirmed that Thy1-GCaMP signals are well-predicted by multiunit activity. Neurovascular coupling between resting-state neural activity and hemodynamics was robust and fast in awake animals, whereas coupling in urethane-anesthetized animals was slower, and in some cases included lower-frequency ({\textless}0.04 Hz) hemodynamic fluctuations that were not well-predicted by local Thy1-GCaMP recordings. These results support that resting-state hemodynamics in the awake and anesthetized brain are coupled to underlying patterns of excitatory neural activity. The patterns of bilaterally-symmetric spontaneous neural activity revealed by wide-field Thy1-GCaMP imaging may depict the neural foundation of functional connectivity networks detected in resting-state fMRI.},
	author = {Ma, Ying and Shaik, Mohammed A. and Kozberg, Mariel G. and Kim, Sharon H. and Portes, Jacob P. and Timerman, Dmitriy and Hillman, Elizabeth M. C.},
	doi = {10.1073/pnas.1525369113},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IK48TQP8/Ma et al. - 2016 - Resting-state hemodynamics are spatiotemporally co.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NXXFUHB8/E8463.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {Neurovascular coupling, resting state, GCaMP, neural network activity, optical imaging},
	language = {en},
	month = dec,
	number = {52},
	pages = {E8463--E8471},
	pmid = {27974609},
	title = {Resting-state hemodynamics are spatiotemporally coupled to synchronized and symmetric neural activity in excitatory neurons},
	url = {http://www.pnas.org/content/113/52/E8463},
	urldate = {2016-12-27},
	volume = {113},
	year = {2016},
	bdsk-url-1 = {http://www.pnas.org/content/113/52/E8463},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1525369113}}

@article{homae_prosodic_2007,
	abstract = {Speech prosody is considered to be one of the most important sources of information for infants in acquiring their native language. Using multi-channel near-infrared spectroscopy in 10-month-old infants, we examined cortical activation when normal and flattened speech sounds were presented to the infants. The flattened speech sound was generated by eliminating changes in the pitch contours of the original utterance. We found bilateral activation under both speech conditions. In a direct comparison between the two conditions, the right temporal and temporoparietal regions, and bilateral prefrontal regions showed more prominent activation in response to flattened speech than to normal speech. These results demonstrate that the unfamiliar pitch contours of flattened speech induce additional processing in the cortical regions of 10-month-old infants, suggesting that 10-month-old infants already have neural mechanisms for the processing of at least a part of the prosodic structures in their native language. To investigate developmental changes in cortical activation patterns, we compared the present results with those of our previous study using the same paradigm with 3-month-old infants. We propose that speech processing in the infant brain develops from analyzing pitch information per se, to comparing and integrating information in input speech sounds with acquired prosodic structures.},
	author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Taga, Gentaro},
	doi = {10.1016/j.neures.2007.05.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PCID57AM/Homae et al. - 2007 - Prosodic processing in the developing brain.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C57R83K5/S0168010207001812.html:text/html},
	issn = {0168-0102},
	journal = {Neuroscience Research},
	keywords = {Infant, NIRS, Pitch, language acquisition, speech perception, prosody, Speech Perception},
	month = sep,
	number = {1},
	pages = {29--39},
	title = {Prosodic processing in the developing brain},
	url = {http://www.sciencedirect.com/science/article/pii/S0168010207001812},
	urldate = {2017-12-11},
	volume = {59},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010207001812},
	bdsk-url-2 = {https://doi.org/10.1016/j.neures.2007.05.005}}

@article{kidd_goldilocks_2012,
	abstract = {Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants' visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants' probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.},
	author = {Kidd, Celeste and Piantadosi, Steven T. and Aslin, Richard N.},
	doi = {10.1371/journal.pone.0036399},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BNUJW34K/Kidd et al. - 2012 - The Goldilocks Effect Human Infants Allocate Atte.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VZDQ8KZM/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Attention, Learning, Human learning, Curve fitting, Eyes, Sequence analysis, Vision, Infants},
	month = may,
	number = {5},
	pages = {e36399},
	shorttitle = {The {Goldilocks} {Effect}},
	title = {The {Goldilocks} {Effect}: {Human} {Infants} {Allocate} {Attention} to {Visual} {Sequences} {That} {Are} {Neither} {Too} {Simple} {Nor} {Too} {Complex}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036399},
	urldate = {2017-01-05},
	volume = {7},
	year = {2012},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036399},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0036399}}

@article{minagawa-kawai_neural_2007,
	abstract = {To elucidate the developmental neural attunement process in the language-specific phonemic repertoire, cerebral hemodynamic responses to a Japanese durational vowel contrast were measured in Japanese infants using near-infrared spectroscopy. Because only relative durational information distinguishes this particular vowel contrast, both first and second language learners have difficulties in acquiring this phonemically crucial durational difference. Previous cross-linguistic studies conducted on adults showed that phoneme-specific, left-dominant neural responses were observed only for native Japanese listeners. Using the same stimuli, we show that a larger response to the across-category changes than to the within-category changes occurred transiently in the 6- to 7-month-old group before stabilizing in the groups older than 12 months. However, the left dominance of the phoneme-specific response in the auditory area was observed only in the groups of 13 months and above. Thus, the durational phonemic contrast is most likely processed first by a generic auditory circuit at 6--7 months as a result of early auditory experience. The neural processing of the contrast is then switched over to a more linguistic circuit after 12 months, this time with a left dominance similar to native adult listeners.},
	author = {Minagawa-Kawai, Yasuyo and Mori, Koichi and Naoi, Nozomi and Kojima, Shozo},
	copyright = {Copyright {\copyright} 2007 Society for Neuroscience 0270-6474/07/270315-07\$15.00/0},
	doi = {10.1523/JNEUROSCI.1984-06.2007},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/EW779KTX/Minagawa-Kawai et al. - 2007 - Neural Attunement Processes in Infants during the .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5BC9QHM2/315.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {NIRS, auditory area, cerebral lateralization, phonemic acquisition, speech perception, Development, Speech Perception},
	language = {en},
	month = jan,
	number = {2},
	pages = {315--321},
	pmid = {17215392},
	title = {Neural {Attunement} {Processes} in {Infants} during the {Acquisition} of a {Language}-{Specific} {Phonemic} {Contrast}},
	url = {http://www.jneurosci.org/content/27/2/315},
	urldate = {2017-02-20},
	volume = {27},
	year = {2007},
	bdsk-url-1 = {http://www.jneurosci.org/content/27/2/315},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1984-06.2007}}

@article{kozberg_resolving_2013,
	abstract = {The adult brain exhibits a local increase in cortical blood flow in response to external stimulus. However, broadly varying hemodynamic responses in the brains of newborn and young infants have been reported. Particular controversy exists over whether the ``true'' neonatal response to stimulation consists of a decrease or an increase in local deoxyhemoglobin, corresponding to a positive (adult-like) or negative blood oxygen level-dependent (BOLD) signal in functional magnetic resonance imaging (fMRI), respectively. A major difficulty with previous studies has been the variability in human subjects and measurement paradigms. Here, we present a systematic study in neonatal rats that charts the evolution of the cortical blood flow response during postnatal development using exposed-cortex multispectral optical imaging. We demonstrate that postnatal-day-12--13 rats (equivalent to human newborns) exhibit an ``inverted'' hemodynamic response (increasing deoxyhemoglobin, negative BOLD) with early signs of oxygen consumption followed by delayed, active constriction of pial arteries. We observed that the hemodynamic response then matures via development of an initial hyperemic (positive BOLD) phase that eventually masks oxygen consumption and balances vasoconstriction toward adulthood. We also observed that neonatal responses are particularly susceptible to stimulus-evoked systemic blood pressure increases, leading to cortical hyperemia that resembles adult positive BOLD responses. We propose that this confound may account for much of the variability in prior studies of neonatal cortical hemodynamics. Our results suggest that functional magnetic resonance imaging studies of infant and child development may be profoundly influenced by the maturing neurovascular and autoregulatory systems of the neonatal brain.},
	author = {Kozberg, Mariel G. and Chen, Brenda R. and DeLeo, Sarah E. and Bouchard, Matthew B. and Hillman, Elizabeth M. C.},
	doi = {10.1073/pnas.1212785110},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IESKGP4Z/Kozberg et al. - 2013 - Resolving the transition from negative to positive.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3RDKN3CB/4380.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {Brain development, Neurovascular coupling, autoregulation, somatosensory stimulation, vascular compartments},
	language = {en},
	month = dec,
	number = {11},
	pages = {4380--4385},
	pmid = {23426630},
	title = {Resolving the transition from negative to positive blood oxygen level-dependent responses in the developing brain},
	url = {http://www.pnas.org/content/110/11/4380},
	urldate = {2017-02-24},
	volume = {110},
	year = {2013},
	bdsk-url-1 = {http://www.pnas.org/content/110/11/4380},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1212785110}}

@article{wood_cortical_2017,
	abstract = {Inhibitory and excitatory neurons form intricate interconnected circuits in the mammalian sensory cortex. Whereas the function of excitatory neurons is largely to integrate and transmit information within and between brain areas, inhibitory neurons are thought to shape the way excitatory neurons integrate information, and they exhibit context-specific and behavior-specific responses. Over the last few years, work across sensory modalities has begun unraveling the function of distinct types of cortical inhibitory neurons in sensory processing, identifying their contribution to controlling stimulus selectivity of excitatory neurons and modulating information processing based on the behavioral state of the subject. Here, we review results from recent studies and discuss the implications for the contribution of inhibition to cortical circuit activity and information processing.},
	author = {Wood, Katherine C and Blackwell, Jennifer M and Geffen, Maria Neimark},
	doi = {10.1016/j.conb.2017.08.018},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/5JHJGSBN/Wood et al. - 2017 - Cortical inhibitory interneurons control sensory p.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TA67XGKE/S0959438817300788.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = oct,
	number = {Supplement C},
	pages = {200--207},
	series = {{SI}: 46 : {Computational} {Neuroscience} (2017)},
	title = {Cortical inhibitory interneurons control sensory processing},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438817300788},
	urldate = {2017-11-13},
	volume = {46},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438817300788},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2017.08.018}}

@article{roche-labarbe_somatosensory_2014,
	abstract = {The hemodynamic functional response is used as a reliable marker of neuronal activity in countless studies of brain function and cognition. In newborns and infants, however, conflicting results have appeared in the literature concerning the typical response, and there is little information on brain metabolism and functional activation. Measurement of all hemodynamic components and oxygen metabolism is critical for understanding neurovascular coupling in the developing brain., To this end, we combined multiple near infrared spectroscopy techniques to measure oxy- and deoxy-hemoglobin concentrations, cerebral blood volume (CBV), and relative cerebral blood flow (CBF) in the somatosensory cortex of 6 preterm neonates during passive tactile stimulation of the hand. By combining these measures we estimated relative changes in the cerebral metabolic rate of oxygen consumption (rCMRO2)., CBF starts increasing immediately after stimulus onset, and returns to baseline before blood volume. This is consistent with the model of pre-capillary arteriole active dilation driving the CBF response, with a subsequent CBV increase influenced by capillaries and veins dilating passively to accommodate the extra blood. rCMRO2 estimated using the steady-state formulation shows a biphasic pattern: an increase immediately after stimulus onset, followed by a post-stimulus undershoot due to blood flow returning faster to baseline than oxygenation. However, assuming a longer mean transit time from the arterial to the venous compartment, due to the immature vascular system of premature infants, reduces the post-stimulus undershoot and increases the flow/consumption ratio to values closer to adult values reported in the literature., We are the first to report changes in local rCBF and rCMRO2 during functional activation in preterm infants. The ability to measure these variables in addition to hemoglobin concentration changes is critical for understanding neurovascular coupling in the developing brain, and for using this coupling as a reliable functional imaging marker in neonates.},
	author = {Roche-Labarbe, Nadege and Fenoglio, Angela and Radakrishnan, Harsha and Kocienski-Filip, Marcia and Carp, Stefan A. and Dubb, Jay and Boas, David A. and Grant, P. Ellen and Franceschini, Maria Angela},
	doi = {10.1016/j.neuroimage.2013.01.035},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/H7G45VNF/Roche-Labarbe et al. - 2014 - Somatosensory evoked changes in cerebral oxygen co.pdf:application/pdf},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = jan,
	number = {0 1},
	pmcid = {PMC3686986},
	pmid = {23370052},
	title = {Somatosensory evoked changes in cerebral oxygen consumption measured non-invasively in premature neonates},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3686986/},
	urldate = {2016-12-29},
	volume = {85},
	year = {2014},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3686986/},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2013.01.035}}

@article{chi_spectro-temporal_1999,
	abstract = {Detection thresholds for spectral and temporal modulations are measured using broadband spectra with sinusoidally rippled profiles that drift up or down the log-frequency axis at constant velocities. Spectro-temporal modulation transfer functions (MTFs) are derived as a function of ripple peak density (Ω cycles/octave) and drifting velocity (ω Hz). The MTFs exhibit a low-pass function with respect to both dimensions, with 50\% bandwidths of about 16 Hz and 2 cycles/octave. The data replicate (as special cases) previously measured purely temporal MTFs (Ω=0) [Viemeister, J. Acoust. Soc. Am. 66, 1364--1380 (1979)] and purely spectral MTFs (ω=0) [Green, in Auditory Frequency Selectivity (Plenum, Cambridge, 1986), pp. 351--359]. A computational auditory model is presented that exhibits spectro-temporal MTFs consistent with the salient trends in the data. The model is used to demonstrate the potential relevance of these MTFs to the assessment of speech intelligibility in noise and reverberant conditions.},
	author = {Chi, Taishih and Gao, Yujie and Guyton, Matthew C. and Ru, Powen and Shamma, Shihab},
	doi = {10.1121/1.428100},
	file = {Snapshot:/Users/Cecile/Zotero/storage/3HGHKRJK/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Speech Intelligibility, Time measurement, Acoustical measurements, Auditory system models, Modulation transfer functions},
	month = nov,
	number = {5},
	pages = {2719--2732},
	title = {Spectro-temporal modulation transfer functions and speech intelligibility},
	url = {http://scitation.aip.org/content/asa/journal/jasa/106/5/10.1121/1.428100},
	urldate = {2016-04-08},
	volume = {106},
	year = {1999},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/106/5/10.1121/1.428100},
	bdsk-url-2 = {https://doi.org/10.1121/1.428100}}

@article{shamma_role_2001,
	abstract = {Unlike visual and tactile stimuli, auditory signals that allow perception of timbre, pitch and localization are temporal. To process these, the auditory nervous system must either possess specialized neural machinery for analyzing temporal input, or transform the initial responses into patterns that are spatially distributed across its sensory epithelium. The former hypothesis, which postulates the existence of structures that facilitate temporal processing, is most popular. However, I argue that the cochlea transforms sound into spatiotemporal response patterns on the auditory nerve and central auditory stages; and that a unified computational framework exists for central auditory, visual and other sensory processing. Specifically, I explain how four fundamental concepts in visual processing play analogous roles in auditory processing.},
	author = {Shamma, Shihab},
	doi = {10.1016/S1364-6613(00)01704-6},
	file = {Snapshot:/Users/Cecile/Zotero/storage/M82PRKVN/S1364-6613(00)01704-6.html:text/html},
	issn = {1364-6613, 1879-307X},
	journal = {Trends in Cognitive Sciences},
	keywords = {Cognitive Science},
	language = {English},
	month = aug,
	number = {8},
	pages = {340--348},
	pmid = {11477003, 11477003},
	title = {On the role of space and time in auditory processing},
	url = {http://www.cell.com/article/S1364661300017046/abstract},
	urldate = {2016-04-08},
	volume = {5},
	year = {2001},
	bdsk-url-1 = {http://www.cell.com/article/S1364661300017046/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/S1364-6613(00)01704-6}}

@article{krekelberg_adaptation:_2006,
	abstract = {Functional magnetic resonance imaging adaptation (fMRIa) is an increasingly popular method that aims to provide insight into the functional properties of subpopulations of neurons within an imaging voxel. The technique relies on the assumption that neural adaptation reduces activity when two successive stimuli activate the same subpopulation but not when they stimulate different subpopulations. Here, we assess the validity of fMRIa by comparing single-cell recordings with functional imaging of orientation, motion and face processing. We find that fMRIa provides novel insight into neural representations in the human brain. However, network responses in general and adaptation in particular are more complex than is often assumed, and an unequivocal interpretation of fMRIa results can be achieved only with great care.},
	author = {Krekelberg, Bart and Boynton, Geoffrey M. and van Wezel, Richard J. A.},
	doi = {10.1016/j.tins.2006.02.008},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MZVT8FZM/Krekelberg et al. - 2006 - Adaptation from single cells to BOLD signals.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5DDSMA52/S0166223606000488.html:text/html},
	issn = {0166-2236},
	journal = {Trends in Neurosciences},
	month = may,
	number = {5},
	pages = {250--256},
	shorttitle = {Adaptation},
	title = {Adaptation: from single cells to {BOLD} signals},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223606000488},
	urldate = {2016-12-28},
	volume = {29},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223606000488},
	bdsk-url-2 = {https://doi.org/10.1016/j.tins.2006.02.008}}

@article{singh_modulation_2003,
	author = {Singh, Nandini C. and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1121/1.1624067},
	file = {SinghTheunissen2003.pdf:/Users/Cecile/Zotero/storage/KKKPI84S/SinghTheunissen2003.pdf:application/pdf},
	issn = {00014966},
	journal = {The Journal of the Acoustical Society of America},
	language = {en},
	number = {6},
	pages = {3394},
	title = {Modulation spectra of natural sounds and ethological theories of auditory processing},
	url = {http://scitation.aip.org/content/asa/journal/jasa/114/6/10.1121/1.1624067},
	urldate = {2016-04-12},
	volume = {114},
	year = {2003},
	bdsk-url-1 = {http://scitation.aip.org/content/asa/journal/jasa/114/6/10.1121/1.1624067},
	bdsk-url-2 = {https://doi.org/10.1121/1.1624067}}

@article{konopka_insights_2016,
	abstract = {The use of vocalizations to communicate information and elaborate social bonds is an adaptation seen in many vertebrate species. Human speech is an extreme version of this pervasive form of communication. Unlike the vocalizations exhibited by the majority of land vertebrates, speech is a learned behavior requiring early sensory exposure and auditory feedback for its development and maintenance. Studies in humans and a small number of other species have provided insights into the neural and genetic basis for learned vocal communication and are helping to delineate the roles of brain circuits across the cortex, basal ganglia, and cerebellum in generating vocal behaviors. This Review provides an outline of the current knowledge about these circuits and the genes implicated in vocal communication, as well as a perspective on future research directions in this field.},
	author = {Konopka, Genevieve and Roberts, Todd F.},
	doi = {10.1016/j.cell.2016.02.039},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/33KNT544/Konopka et Roberts - 2016 - Insights into the Neural and Genetic Basis of Voca.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C9JMDVJ4/S0092867416301891.html:text/html},
	issn = {0092-8674},
	journal = {Cell},
	keywords = {Speech, sensorimotor circuits, human brain, songbird, FOXP2, language},
	month = mar,
	number = {6},
	pages = {1269--1276},
	title = {Insights into the {Neural} and {Genetic} {Basis} of {Vocal} {Communication}},
	url = {http://www.sciencedirect.com/science/article/pii/S0092867416301891},
	urldate = {2016-04-19},
	volume = {164},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0092867416301891},
	bdsk-url-2 = {https://doi.org/10.1016/j.cell.2016.02.039}}

@article{blackwell_stable_2016,
	abstract = {Natural auditory scenes possess highly structured statistical regularities, which are dictated by the physics of sound production in nature, such as scale-invariance. We recently identified that natural water sounds exhibit a particular type of scale invariance, in which the temporal modulation within spectral bands scales with the centre frequency of the band. Here, we tested how neurons in the mammalian primary auditory cortex encode sounds that exhibit this property, but differ in their statistical parameters. The stimuli varied in spectro-temporal density and cyclo-temporal statistics over several orders of magnitude, corresponding to a range of water-like percepts, from pattering of rain to a slow stream. We recorded neuronal activity in the primary auditory cortex of awake rats presented with these stimuli. The responses of the majority of individual neurons were selective for a subset of stimuli with specific statistics. However, as a neuronal population, the responses were remarkably stable over large changes in stimulus statistics, exhibiting a similar range in firing rate, response strength, variability and information rate, and only minor variation in receptive field parameters. This pattern of neuronal responses suggests a potentially general principle for cortical encoding of complex acoustic scenes: while individual cortical neurons exhibit selectivity for specific statistical features, a neuronal population preserves a constant response structure across a broad range of statistical parameters.},
	author = {Blackwell, Jennifer M. and Taillefumier, Thibaud O. and Natan, Ryan G. and Carruthers, Isaac M. and Magnasco, Marcelo O. and Geffen, Maria N.},
	doi = {10.1111/ejn.13144},
	issn = {1460-9568},
	journal = {The European Journal of Neuroscience},
	keywords = {Electrophysiology, receptive field, computational neuroscience, natural scene analysis, rat, Auditory cortex},
	language = {eng},
	month = mar,
	number = {6},
	pages = {751--764},
	pmid = {26663571},
	title = {Stable encoding of sounds over a broad range of statistical parameters in the auditory cortex},
	volume = {43},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1111/ejn.13144}}

@article{oswald_synaptic_2006,
	abstract = {In vivo voltage clamp recordings have provided new insights into the synaptic mechanisms that underlie processing in the primary auditory cortex. Of particular importance are the discoveries that excitatory and inhibitory inputs have similar frequency and intensity tuning, that excitation is followed by inhibition with a short delay, and that the duration of inhibition is briefer than expected. These findings challenge existing models of auditory processing in which broadly tuned lateral inhibition is used to limit excitatory receptive fields and suggest new mechanisms by which inhibition and short term plasticity shape neural responses.},
	author = {Oswald, Anne-Marie M. and Schiff, Max L. and Reyes, Alex D.},
	doi = {10.1016/j.conb.2006.06.015},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TAMR8GQ6/Oswald et al. - 2006 - Synaptic mechanisms underlying auditory processing.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9ZXQ2IIN/S0959438806000882.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = aug,
	number = {4},
	pages = {371--376},
	series = {Sensory systems},
	title = {Synaptic mechanisms underlying auditory processing},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438806000882},
	urldate = {2016-04-25},
	volume = {16},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438806000882},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2006.06.015}}

@article{isaacson_how_2011,
	abstract = {Cortical processing reflects the interplay of synaptic excitation and synaptic inhibition. Rapidly accumulating evidence is highlighting the crucial role of inhibition in shaping spontaneous and sensory-evoked cortical activity and thus underscores how a better knowledge of inhibitory circuits is necessary for our understanding of cortical function. We discuss current views of how inhibition regulates the function of cortical neurons and point to a number of important open questions.},
	author = {Isaacson, Jeffry S. and Scanziani, Massimo},
	doi = {10.1016/j.neuron.2011.09.027},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IPGQVAHD/Isaacson et Scanziani - 2011 - How Inhibition Shapes Cortical Activity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZR7HMJFK/S0896-6273(11)00879-8.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	language = {English},
	month = oct,
	number = {2},
	pages = {231--243},
	pmid = {22017986, 22017986},
	title = {How {Inhibition} {Shapes} {Cortical} {Activity}},
	url = {http://www.cell.com/article/S0896627311008798/abstract},
	urldate = {2016-04-25},
	volume = {72},
	year = {2011},
	bdsk-url-1 = {http://www.cell.com/article/S0896627311008798/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2011.09.027}}

@article{lloyd-fox_social_2009,
	author = {Lloyd-Fox, Sarah and Blasi, Anna and Volein, Agnes and Everdell, Nick and Elwell, Claire E. and Johnson, Mark H.},
	doi = {10.1111/j.1467-8624.2009.01312.x},
	file = {Lloyd-Fox_et_al-2009-Child_Development.pdf:/Users/Cecile/Zotero/storage/FER4JXCN/Lloyd-Fox_et_al-2009-Child_Development.pdf:application/pdf},
	issn = {00093920, 14678624},
	journal = {Child Development},
	language = {en},
	month = jul,
	number = {4},
	pages = {986--999},
	shorttitle = {Social {Perception} in {Infancy}},
	title = {Social {Perception} in {Infancy}: {A} {Near} {Infrared} {Spectroscopy} {Study}},
	url = {http://doi.wiley.com/10.1111/j.1467-8624.2009.01312.x},
	urldate = {2016-04-26},
	volume = {80},
	year = {2009},
	bdsk-url-1 = {http://doi.wiley.com/10.1111/j.1467-8624.2009.01312.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01312.x}}

@article{lerner_topographic_2011,
	abstract = {Real-life activities, such as watching a movie or engaging in conversation, unfold over many minutes. In the course of such activities, the brain has to integrate information over multiple time scales. We recently proposed that the brain uses similar strategies for integrating information across space and over time. Drawing a parallel with spatial receptive fields, we defined the temporal receptive window (TRW) of a cortical microcircuit as the length of time before a response during which sensory information may affect that response. Our previous findings in the visual system are consistent with the hypothesis that TRWs become larger when moving from low-level sensory to high-level perceptual and cognitive areas. In this study, we mapped TRWs in auditory and language areas by measuring fMRI activity in subjects listening to a real-life story scrambled at the time scales of words, sentences, and paragraphs. Our results revealed a hierarchical topography of TRWs. In early auditory cortices (A1+), brain responses were driven mainly by the momentary incoming input and were similarly reliable across all scrambling conditions. In areas with an intermediate TRW, coherent information at the sentence time scale or longer was necessary to evoke reliable responses. At the apex of the TRW hierarchy, we found parietal and frontal areas that responded reliably only when intact paragraphs were heard in a meaningful sequence. These results suggest that the time scale of processing is a functional property that may provide a general organizing principle for the human cerebral cortex.},
	author = {Lerner, Yulia and Honey, Christopher J. and Silbert, Lauren J. and Hasson, Uri},
	doi = {10.1523/JNEUROSCI.3684-10.2011},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DM4FGEFM/Lerner et al. - 2011 - Topographic Mapping of a Hierarchy of Temporal Rec.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UI7E3FAT/2906.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = feb,
	number = {8},
	pages = {2906--2915},
	pmid = {21414912},
	title = {Topographic {Mapping} of a {Hierarchy} of {Temporal} {Receptive} {Windows} {Using} a {Narrated} {Story}},
	url = {http://www.jneurosci.org/content/31/8/2906},
	urldate = {2016-05-03},
	volume = {31},
	year = {2011},
	bdsk-url-1 = {http://www.jneurosci.org/content/31/8/2906},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3684-10.2011}}

@article{anderson_neonatal_2001,
	abstract = {The objective of this study was to detect auditory cortical activation in non-sedated neonates employing functional magnetic resonance imaging (fMRI). Using echo-planar functional brain imaging, subjects were presented with a frequency-modulated pure tone; the BOLD signal response was mapped in 5 mm-thick slices running parallel to the superior temporal gyrus. Twenty healthy neonates (13 term, 7 preterm) at term and 4 adult control subjects. Blood oxygen level-dependent (BOLD) signal in response to auditory stimulus was detected in all 4 adults and in 14 of the 20 neonates. FMRI studies of adult subjects demonstrated increased signal in the superior temporal regions during auditory stimulation. In contrast, signal decreases were detected during auditory stimulation in 9 of 14 newborns with BOLD response. fMRI can be used to detect brain activation with auditory stimulation in human infants.},
	author = {Anderson, Adam W. and Marois, Rene and Colson, Eve R. and Peterson, Bradley S. and Duncan, Charles C. and Ehrenkranz, Richard A. and Schneider, Karen C. and Gore, John C. and Ment, Laura R.},
	doi = {10.1016/S0730-725X(00)00231-9},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/XNP788XH/Anderson et al. - 2001 - Neonatal auditory activation detected by functiona.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/Q7HVZIIM/S0730725X00002319.html:text/html},
	issn = {0730-725X},
	journal = {Magnetic Resonance Imaging},
	keywords = {Neonate, Term, functional magnetic resonance imaging, Auditory cortex},
	month = jan,
	number = {1},
	pages = {1--5},
	title = {Neonatal auditory activation detected by functional magnetic resonance imaging},
	url = {http://www.sciencedirect.com/science/article/pii/S0730725X00002319},
	urldate = {2017-01-07},
	volume = {19},
	year = {2001},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0730725X00002319},
	bdsk-url-2 = {https://doi.org/10.1016/S0730-725X(00)00231-9}}

@article{kidd_goldilocks_2014,
	abstract = {Infants must learn about many cognitive domains (e.g., language, music) from auditory statistics, yet capacity limits on their cognitive resources restrict the quantity that they can encode. Previous research has established that infants can attend to only a subset of available acoustic input. Yet few previous studies have directly examined infant auditory attention, and none have directly tested theorized mechanisms of attentional selection based on stimulus complexity. This work utilizes model-based behavioral methods that were recently developed to examine visual attention in infants (e.g., Kidd, Piantadosi, \& Aslin, 2012). The present results demonstrate that 7- to 8-month-old infants selectively attend to nonsocial auditory stimuli that are intermediately predictable/complex with respect to their current implicit beliefs and expectations. These findings provide evidence of a broad principle of infant attention across modalities and suggest that sound-to-sound transitional statistics heavily influence the allocation of auditory attention in human infants.},
	author = {Kidd, Celeste and Piantadosi, Steven T. and Aslin, Richard N.},
	doi = {10.1111/cdev.12263},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ARSU9STC/Kidd et al. - 2014 - The Goldilocks Effect in Infant Auditory Attention.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WGCAR2DF/abstract\;jsessionid=F56328E1510356CCB1F8C3719A745321.html:text/html},
	issn = {1467-8624},
	journal = {Child Development},
	language = {en},
	month = sep,
	number = {5},
	pages = {1795--1804},
	title = {The {Goldilocks} {Effect} in {Infant} {Auditory} {Attention}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/cdev.12263/abstract},
	urldate = {2017-01-06},
	volume = {85},
	year = {2014},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/cdev.12263/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/cdev.12263}}

@article{born_visual_1998,
	abstract = {The purpose of this study was to determine whether visual stimulation in sleeping infants and young children can be examined by functional magnetic resonance imaging. We studied 17 children, aged 3 d to 48 mo, and three healthy adults. Visual stimulation was performed with 8-Hz flickering light through the sleeping childs' closed eyelids. Functional magnetic resonance imaging was performed with a gradient echoplanar sequence in a 1.5-T magnetic resonance scanner. Six subjects were excluded because of movement artifacts; the youngest infant showed no response. In 10 children, we could demonstrate areas of signal decrease during visual stimulation in the occipital cortex (mean decrease 2.21\%), contrary to the signal increase observed in the adult controls (mean increase 2.82\%). This decrease may be due to a higher proportional increase in oxygen extraction compared with increase in cerebral blood flow during activation. The different response patterns in young children and adults can reflect developmental or behavioral differences. Localization of the activation seemed to be age-dependent. In the older children and the adults, it encompassed the whole length of the calcarine sulcus, whereas it was restricted to the anterior and medial part of the calcarine sulcus in the younger infants. This may reflect a different functional organization of the young child's visual cortex or the on-going retinal development.},
	author = {Born, Peter and Leth, Helle and Miranda, Maria J. and Rostrup, Egill and Stensgaard, Anders and Peitersen, Birgit and Larsson, Henrik B. W. and Lou, Hans C.},
	copyright = {{\copyright} 1998 Nature Publishing Group},
	doi = {10.1203/00006450-199810000-00018},
	file = {Snapshot:/Users/Cecile/Zotero/storage/C7V6CFSD/pr1998504a.html:text/html},
	issn = {0031-3998},
	journal = {Pediatric Research},
	language = {en},
	month = oct,
	number = {4},
	pages = {578--583},
	title = {Visual {Activation} in {Infants} and {Young} {Children} {Studied} by {Functional} {Magnetic} {Resonance} {Imaging}},
	url = {http://www.nature.com/pr/journal/v44/n4/full/pr1998504a.html},
	urldate = {2017-01-07},
	volume = {44},
	year = {1998},
	bdsk-url-1 = {http://www.nature.com/pr/journal/v44/n4/full/pr1998504a.html},
	bdsk-url-2 = {https://doi.org/10.1203/00006450-199810000-00018}}

@article{pernet_human_2015,
	abstract = {fMRI studies increasingly examine functions and properties of non-primary areas of human auditory cortex. However there is currently no standardized localization procedure to reliably identify specific areas across individuals such as the standard `localizers' available in the visual domain. Here we present an fMRI `voice localizer' scan allowing rapid and reliable localization of the voice-sensitive `temporal voice areas' (TVA) of human auditory cortex. We describe results obtained using this standardized localizer scan in a large cohort of normal adult subjects. Most participants (94\%) showed bilateral patches of significantly greater response to vocal than non-vocal sounds along the superior temporal sulcus/gyrus (STS/STG). Individual activation patterns, although reproducible, showed high inter-individual variability in precise anatomical location. Cluster analysis of individual peaks from the large cohort highlighted three bilateral clusters of voice-sensitivity, or ``voice patches'' along posterior (TVAp), mid (TVAm) and anterior (TVAa) STS/STG, respectively. A series of extra-temporal areas including bilateral inferior prefrontal cortex and amygdalae showed small, but reliable voice-sensitivity as part of a large-scale cerebral voice network. Stimuli for the voice localizer scan and probabilistic maps in MNI space are available for download.},
	author = {Pernet, Cyril R. and McAleer, Phil and Latinus, Marianne and Gorgolewski, Krzysztof J. and Charest, Ian and Bestelmeyer, Patricia E. G. and Watson, Rebecca H. and Fleming, David and Crabbe, Frances and Valdes-Sosa, Mitchell and Belin, Pascal},
	doi = {10.1016/j.neuroimage.2015.06.050},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RH9NGGGW/Pernet et al. - 2015 - The human voice areas Spatial organization and in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3ZGEQC3S/S1053811915005558.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Amygdala, Voice, Inferior prefrontal cortex, Superior temporal gyrus, Superior temporal sulcus, functional magnetic resonance imaging, Auditory cortex},
	month = oct,
	pages = {164--174},
	shorttitle = {The human voice areas},
	title = {The human voice areas: {Spatial} organization and inter-individual variability in temporal and extra-temporal cortices},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811915005558},
	urldate = {2017-03-09},
	volume = {119},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811915005558},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2015.06.050}}

@article{meek_regional_1998,
	abstract = {This study presents the first measurements using near infrared spectroscopy of changes in regional hemodynamics as a response to a visual stimulus in awake infants. Ten infants aged 3 d to 14 wk viewed a checkerboard with a 5-Hz pattern reversal. The emitter and detector (optodes) of a near infrared spectrophotometer were placed over the occipital region of the head. Changes in concentration of oxy- and deoxyhemoglobin (Hbo2 and Hb) were measured and compared during 10-s epochs of stimulus on and off. A control group of 10 infants aged 18 d to 13 wk were examined with the same setup, but with the optodes over the frontoparietal region. In the test group the total hemoglobin concentration (Hbo2 + Hb) increased while the stimulus was on by a mean (+/-SD) of 2.51 (+/-1.48) micromol x L(-1). Nine out of 10 infants showed an Hbo2 increase, and 9 out of 10 an Hb increase related to the stimulus. There was no significant change in any of these parameters in the control group. The results imply that there is increased cerebral blood flow due to stimulation that is specific to the visual cortex and that infants, unlike adults, show increased cerebral oxygen utilization during activation that outstrips this hemodynamic effect. The study demonstrates that near infrared spectroscopy can be used as a practical and noninvasive method of measuring visual functional activation and its hemodynamic correlates in the awake infant.},
	author = {Meek, J. H. and Firbank, M. and Elwell, C. E. and Atkinson, J. and Braddick, O. and Wyatt, J. S.},
	doi = {10.1203/00006450-199806000-00019},
	issn = {0031-3998},
	journal = {Pediatric Research},
	keywords = {Adult, Aging, Frontal Lobe, Hemodynamics, Hemoglobins, Humans, Infant, Infant, Newborn, Kinetics, Cerebrovascular Circulation, Photic Stimulation, Time Factors, Occipital Lobe, Oxyhemoglobins},
	language = {eng},
	month = jun,
	number = {6},
	pages = {840--843},
	pmid = {9621996},
	title = {Regional hemodynamic responses to visual stimulation in awake infants},
	volume = {43},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1203/00006450-199806000-00019}}

@article{norman_growth_1986,
	abstract = {Sections of the occipital cortex from 31 fetuses, infants and children, ranging in age from 15 weeks gestation to ten years postnatal, were stained to demonstrate alkaline phosphatase activity in intracortical vessels. At 15 weeks gestation intracortical positively staining vessels, assumed to be arterial precursors, were radially oriented, originating from leptomeningeal arteries. Most radial vessels coursed through the cerebral cortex without branching to vascularize the subcortical tissue. By 20 weeks gestation horizontal branches arose from radial vessels, most frequently in the lower half of the cortex. Occasionally, recurrent collaterals ascended from these horizontal branches to more superficial cortex. From 20--27 weeks gestation, the number of horizontal branches and recurrent collaterals increased in the lower half of the cortex, horizontal branches appeared in the upper half. From 27 weeks to term, shorter radial vessels, terminating in the more superficial cortical laminae increased in number. After birth a network of fine vessels, presumably precursors of capillaries, increased, particularly vascular layer 3 (neuronal lamina IV and Va). The number of radially oriented vessels per mm2 of pial surface (NA) decreased throughout development, with the most dramatic decrease occurring prenatally. In five cases of trisomy values of NA decreased less rapidly than in the normal},
	author = {Norman, Margaret G. and O'Kusky, John R.},
	copyright = {Copyright {\copyright} 1986, by the American Association of Neuropathologists},
	doi = {10.1097/00005072-198605000-00003},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/VP5BAPEQ/Norman et O'Kusky - 1986 - The Growth and Development of Microvasculature in .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AUIQNCJT/222.html:text/html},
	issn = {0022-3069, 1554-6578},
	journal = {Journal of Neuropathology \& Experimental Neurology},
	language = {en},
	month = may,
	number = {3},
	pages = {222--232},
	pmid = {3958756},
	title = {The {Growth} and {Development} of {Microvasculature} in {Human} {Cerebral} {Cortex}},
	url = {http://jnen.oxfordjournals.org/content/45/3/222},
	urldate = {2017-01-10},
	volume = {45},
	year = {1986},
	bdsk-url-1 = {http://jnen.oxfordjournals.org/content/45/3/222},
	bdsk-url-2 = {https://doi.org/10.1097/00005072-198605000-00003}}

@article{benes_myelination_1994,
	abstract = {BACKGROUND: A previous study demonstrated that myelination of the superior medullary lamina along the surface of the parahippocampal gyrus is occurring in human brain during adolescence. To further investigate whether postnatal increases of myelination may continue during the second decade and possibly even longer, the extent of myelination in this region has been analyzed in 164 psychiatrically normal individuals aged newborn to 76 years.
METHODS: Cross sections of the hippocampal formation with adjoining hippocampal gyrus were analyzed on a blinded basis using either a global rating scale or measurements of the area of myelin staining.
RESULTS: A curvilinear increase in the extent of myelination between the first and sixth decades of life (r = .71 and r = .67, respectively) was observed. When the area of myelination was expressed relative to brain weight, there was a twofold increase between the first and second decades and an additional increase of 60\% between the fourth and sixth decades. Female subjects showed a significantly greater degree of myelin staining than did male subjects during the interval of ages 6 to 29 years; however, after the third decade, there were no gender differences in the area of myelin staining.
CONCLUSIONS: The increased staining of myelin during the first and second decades principally occurred in the subicular region and adjacent portions of the presubiculum. During the fourth through sixth decades, however, it extended to progressively more lateral locations along the surface of the presubiculum. The precise origin(s) of the axons showing progressive myelination is unknown; however, the axons in the subiculum may include some perforant path fibers, while those found in the presubiculum may include cingulum bundle projections. Overall, our data are consistent with the idea that both early and late postnatal increases of myelination occur in a key corticolimbic relay area of the human brain and underscore the importance of applying a neurodevelopmental perspective to the study of psychopathology during childhood, adolescence, and even adulthood.},
	author = {Benes, F. M. and Turtle, M. and Khan, Y. and Farol, P.},
	issn = {0003-990X},
	journal = {Archives of General Psychiatry},
	keywords = {Adolescent, Adult, Age Factors, Aged, Aging, Animals, Child, Child Development, Child, Preschool, Female, Humans, Infant, Infant, Newborn, Male, Middle Aged, Neural Pathways, Hippocampus, Myelin Sheath, Organ Size, Sex Factors, Brain},
	language = {eng},
	month = jun,
	number = {6},
	pages = {477--484},
	pmid = {8192550},
	title = {Myelination of a key relay zone in the hippocampal formation occurs in the human brain during childhood, adolescence, and adulthood},
	volume = {51},
	year = {1994}}

@article{mishra_astrocytes_2016,
	abstract = {Active neurons increase their energy supply by dilating nearby arterioles and capillaries. This neurovascular coupling underlies blood oxygen level-dependent functional imaging signals, but its mechanism is controversial. Canonically, neurons release glutamate to activate metabotropic glutamate receptor 5 (mGluR5) on astrocytes, evoking Ca(2+) release from internal stores, activating phospholipase A2 and generating vasodilatory arachidonic acid derivatives. However, adult astrocytes lack mGluR5, and knockout of the inositol 1,4,5-trisphosphate receptors that release Ca(2+) from stores does not affect neurovascular coupling. We now show that buffering astrocyte Ca(2+) inhibits neuronally evoked capillary dilation, that astrocyte [Ca(2+)]i is raised not by release from stores but by entry through ATP-gated channels, and that Ca(2+) generates arachidonic acid via phospholipase D2 and diacylglycerol kinase rather than phospholipase A2. In contrast, dilation of arterioles depends on NMDA receptor activation and Ca(2+)-dependent NO generation by interneurons. These results reveal that different signaling cascades regulate cerebral blood flow at the capillary and arteriole levels.},
	author = {Mishra, Anusha and Reynolds, James P. and Chen, Yang and Gourine, Alexander V. and Rusakov, Dmitri A. and Attwell, David},
	doi = {10.1038/nn.4428},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {eng},
	month = dec,
	number = {12},
	pages = {1619--1627},
	pmcid = {PMC5131849},
	pmid = {27775719},
	title = {Astrocytes mediate neurovascular signaling to capillary pericytes but not to arterioles},
	volume = {19},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1038/nn.4428}}

@article{dubois_exploring_2016,
	abstract = {Linguistic processing is based on a close collaboration between temporal and frontal regions connected by two pathways: the ``dorsal'' and ``ventral pathways'' (assumed to support phonological and semantic processing, respectively, in adults). We investigated here the development of these pathways at the onset of language acquisition, during the first post-natal weeks, using cross-sectional diffusion imaging in 21 healthy infants (6--22 weeks of age) and 17 young adults. We compared the bundle organization and microstructure at these two ages using tractography and original clustering analyses of diffusion tensor imaging parameters. We observed structural similarities between both groups, especially concerning the dorsal/ventral pathway segregation and the arcuate fasciculus asymmetry. We further highlighted the developmental tempos of the linguistic bundles: The ventral pathway maturation was more advanced than the dorsal pathway maturation, but the latter catches up during the first post-natal months. Its fast development during this period might relate to the learning of speech cross-modal representations and to the first combinatorial analyses of the speech input.},
	author = {Dubois, Jessica and Poupon, Cyril and Thirion, Bertrand and Simonnet, Hina and Kulikova, Sofya and Leroy, Fran{\c c}ois and Hertz-Pannier, Lucie and Dehaene-Lambertz, Ghislaine},
	doi = {10.1093/cercor/bhv082},
	file = {Snapshot:/Users/Cecile/Zotero/storage/F3RPNUHF/2283.html:text/html},
	issn = {1047-3211, 1460-2199},
	journal = {Cerebral Cortex},
	keywords = {Brain development, language network, diffusion imaging, interhemispheric asymmetry, white matter maturation and myelination},
	language = {en},
	month = jan,
	number = {5},
	pages = {2283--2298},
	pmid = {25924951},
	title = {Exploring the {Early} {Organization} and {Maturation} of {Linguistic} {Pathways} in the {Human} {Infant} {Brain}},
	url = {http://cercor.oxfordjournals.org/content/26/5/2283},
	urldate = {2017-01-10},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {http://cercor.oxfordjournals.org/content/26/5/2283},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhv082}}

@article{kusaka_noninvasive_2004,
	abstract = {During the developmental stage, the brain undergoes anatomic, functional, and metabolic changes necessary to support the complex adaptive behavior of a mature individual. Estimation of developmental changes occurring in different regions of the brain would provide a means of relating various behavioral phenomena to maturation-specific brain structures, thereby providing useful information on structure-function relationships in both normal and disease states. We used multichannel near-infrared spectroscopy (MNIRS), a new noninvasive imaging technique for revealing the course of neural activity in selected brain regions, to monitor the activities of the visual cortex as mirrored by hemodynamic responses in infants subjected to photostimulation during natural sleep. In the infants, oxyhemoglobin and total hemoglobin decreased and deoxyhemoglobin increased in the visual cortex with photostimulation. This pattern of responses was different from the response pattern in adults reported previously. The different patterns of responses to photostimulation in the visual cortices of infants and adults might reflect developmental and behavioral differences. It may reflect a different functional organization of the visual cortex in infants or ongoing retinal development. Our results demonstrated that regional hemodynamic change could be detected in a small area around the visual cortex. MNIRS offers considerable potential for research and noninvasive clinical applications.},
	author = {Kusaka, Takashi and Kawada, Kou and Okubo, Kensuke and Nagano, Keiko and Namba, Masanori and Okada, Hitoshi and Imai, Tadashi and Isobe, Kenichi and Itoh, Susumu},
	doi = {10.1002/hbm.20020},
	issn = {1065-9471},
	journal = {Human Brain Mapping},
	keywords = {Adult, Brain Mapping, Hemoglobins, Humans, Infant, Infant, Newborn, Sleep, Photic Stimulation, Spectroscopy, Near-Infrared, Visual Cortex, Oxyhemoglobins},
	language = {eng},
	month = jun,
	number = {2},
	pages = {122--132},
	pmid = {15108300},
	title = {Noninvasive optical imaging in the visual cortex in young infants},
	volume = {22},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1002/hbm.20020}}

@article{mahmoudzadeh_functional_2017,
	author = {Mahmoudzadeh, Mahdi and Wallois, Fabrice and Kongolo, Guy and Goudjil, Sabrina and Dehaene-Lambertz, Ghislaine},
	doi = {10.1093/cercor/bhw103},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CQKEF2JR/Mahmoudzadeh et al. - 2017 - Functional Maps at the Onset of Auditory Inputs in.pdf:application/pdf;SI_Submit_final.pdf:/Users/Cecile/Zotero/storage/2HMJSJBZ/SI_Submit_final.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4QAPAJ6Q/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = apr,
	number = {4},
	pages = {2500--2512},
	title = {Functional {Maps} at the {Onset} of {Auditory} {Inputs} in {Very} {Early} {Preterm} {Human} {Neonates}},
	url = {https://academic.oup.com/cercor/article/27/4/2500/3056357/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in},
	urldate = {2017-05-15},
	volume = {27},
	year = {2017},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/27/4/2500/3056357/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhw103}}

@article{maggioni_investigation_2015,
	abstract = {Despite negative blood oxygenation level dependent (BOLD) responses to visual stimuli have recently gained considerable interest, the explanation for their underlying neuronal and vascular mechanisms is still controversial. In the present study, a multimodal experimental approach is presented to shed light on the negative BOLD phenomenon in the human brain. In particular, information from functional magnetic resonance imaging (fMRI) and near infrared spectroscopy (NIRS) was integrated to confirm and gain insight into the phenomenon of negative BOLD responses (NBRs) to unpatterned intermittent photic stimulation (IPS) in healthy subjects. Eight healthy subjects participated in the study. Consistent findings emerged from the activation analysis of fMRI and NIRS data and the comparison of BOLD and hemoglobin responses at the single channel level showed that NBRs are related to a decrease in oxyhemoglobin (HbO) combined with a lower increase in deoxyhemoglobin (HHb), corresponding to a decrease in total hemoglobin (THb) and estimated cerebral blood volume (CBV). The HbO and HHb variations were significant in at least one channel in six subjects out of eight (p \&lt; 0.05). The NIRS technique allowed obtaining valuable information on the vascular determinants of the NBRs, since the discrimination between HbO, HHb and THb information provided a more comprehensive view of the negative BOLD phenomenon. The within and between subject heterogeneous BOLD-Hb temporal relations pave the way to further investigations into the neurovascular properties of NBRs.},
	author = {Maggioni, Eleonora and Molteni, Erika and Zucca, Claudio and Reni, Gianluigi and Cerutti, Sergio and Triulzi, Fabio M. and Arrigoni, Filippo and Bianchi, Anna M.},
	doi = {10.1016/j.neuroimage.2014.12.074},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BH5I7UAN/Maggioni et al. - 2015 - Investigation of negative BOLD responses in human .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KVJK95HR/S1053811914010805.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = mar,
	pages = {410--422},
	title = {Investigation of negative {BOLD} responses in human brain through {NIRS} technique. {A} visual stimulation study},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811914010805},
	urldate = {2017-06-13},
	volume = {108},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914010805},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2014.12.074}}

@article{zhu_mouth_2017,
	abstract = {Cortex in and around the human posterior superior temporal sulcus (pSTS) is known to be critical for speech perception. The pSTS responds to both the visual modality (especially biological motion) and the auditory modality (especially human voices). Using fMRI in single subjects with no spatial smoothing, we show that visual and auditory selectivity are linked. Regions of the pSTS were identified that preferred visually presented moving mouths (presented in isolation or as part of a whole face) or moving eyes. Mouth-preferring regions responded strongly to voices and showed a significant preference for vocal compared with nonvocal sounds. In contrast, eye-preferring regions did not respond to either vocal or nonvocal sounds. The converse was also true: regions of the pSTS that showed a significant response to speech or preferred vocal to nonvocal sounds responded more strongly to visually presented mouths than eyes. These findings can be explained by environmental statistics. In natural environments, humans see visual mouth movements at the same time as they hear voices, while there is no auditory accompaniment to visual eye movements. The strength of a voxel's preference for visual mouth movements was strongly correlated with the magnitude of its auditory speech response and its preference for vocal sounds, suggesting that visual and auditory speech features are coded together in small populations of neurons within the pSTS.
SIGNIFICANCE STATEMENT Humans interacting face to face make use of auditory cues from the talker's voice and visual cues from the talker's mouth to understand speech. The human posterior superior temporal sulcus (pSTS), a brain region known to be important for speech perception, is complex, with some regions responding to specific visual stimuli and others to specific auditory stimuli. Using BOLD fMRI, we show that the natural statistics of human speech, in which voices co-occur with mouth movements, are reflected in the neural architecture of the pSTS. Different pSTS regions prefer visually presented faces containing either a moving mouth or moving eyes, but only mouth-preferring regions respond strongly to voices.},
	author = {Zhu, Lin L. and Beauchamp, Michael S.},
	copyright = {Copyright {\copyright} 2017 the authors 0270-6474/17/372697-12\$15.00/0},
	doi = {10.1523/JNEUROSCI.2914-16.2017},
	file = {Snapshot:/Users/Cecile/Zotero/storage/4R9DWEQ4/2697.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {Face, audiovisual, multisensory, speech perception, Speech Perception},
	language = {en},
	month = mar,
	number = {10},
	pages = {2697--2708},
	pmid = {28179553},
	shorttitle = {Mouth and {Voice}},
	title = {Mouth and {Voice}: {A} {Relationship} between {Visual} and {Auditory} {Preference} in the {Human} {Superior} {Temporal} {Sulcus}},
	url = {http://www.jneurosci.org/content/37/10/2697},
	urldate = {2017-03-14},
	volume = {37},
	year = {2017},
	bdsk-url-1 = {http://www.jneurosci.org/content/37/10/2697},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2914-16.2017}}

@article{hall_spectral_2002,
	author = {Hall, Deborah A. and Johnsrude, Ingrid S. and Haggard, Mark P. and Palmer, Alan R. and Akeroyd, Michael A. and Summerfield, A. Quentin},
	doi = {10.1093/cercor/12.2.140},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/J4ZB92C3/Hall et al. - 2002 - Spectral and Temporal Processing in Human Auditory.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5FT4TD8S/Spectral-and-Temporal-Processing-in-Human-Auditory.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = feb,
	number = {2},
	pages = {140--149},
	title = {Spectral and {Temporal} {Processing} in {Human} {Auditory} {Cortex}},
	url = {https://academic.oup.com/cercor/article/12/2/140/301066/Spectral-and-Temporal-Processing-in-Human-Auditory},
	urldate = {2017-03-10},
	volume = {12},
	year = {2002},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/12/2/140/301066/Spectral-and-Temporal-Processing-in-Human-Auditory},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/12.2.140}}

@article{hunter_multifactor_1988,
	abstract = {Presents a multifactor model for predicting when infants will prefer novel stimuli, when they will prefer familiar stimuli, and when they will show no preference for either is derived. According to this model, preferences for novelty and familiarity are not tied to particular ages, but instead can be found at any age, depending on the duration of previous familiarization and on task difficulty relative to the age and experience of the infant. A selective review is performed to show how the model can be used to provide an alternative explanation for research results supporting the age dependent view of preferences and to review that studies that have directly tested the model. An attempt is made to expand and furbish the model by pointing out additional factors that might be incorporated into it and by interfacing it with several related areas of infant development.},
	author = {Hunter, Michael A. and Ames, Elinor W.},
	copyright = {(c) 2016 APA, all rights reserved},
	file = {APA PsycNET Snapshot:/Users/Cecile/Zotero/storage/5PR92QPT/1997-72976-001.html:text/html;Hunter Ames 1988 - A multifactor model of infant preferences for novel.pdf:/Users/Cecile/Zotero/storage/57DP8AF2/Hunter Ames 1988 - A multifactor model of infant preferences for novel.pdf:application/pdf},
	issn = {0732-9598},
	journal = {Advances in Infancy Research},
	keywords = {*Models, *Preferences, Stimulus Novelty},
	language = {English},
	pages = {69--95},
	title = {A multifactor model of infant preferences for novel and familiar stimuli},
	volume = {5},
	year = {1988}}

@article{blasi_investigation_2007,
	abstract = {Near-infrared spectroscopy has been used to record oxygenation changes in the visual cortex of 4 month old infants. Our in-house topography system, with 30 channels and 3 different source--detector separations, recorded changes in the concentration of oxy-, deoxy- and total haemoglobin (HbO 2 , HHb and HbT) in response to visual stimuli (face, scrambled visual noise and cartoons as rest). The aim of this work was to demonstrate the capability of the system to spatially localize functional activation and study the possibility of depth discrimination in the haemodynamic response. The group data show both face stimulation and visual noise stimulation induced significant increases in HbO 2 from rest, but the increase in HbO 2 with face stimulation was not significantly different from that seen with visual noise stimulation. The face stimuli induced increases in HbO 2 were spread across a greater area across all depths than visual noise induced changes. In results from a single subject there was a significant increase of HbO 2 in the inferior area of the visual cortex in response to both types of stimuli, and a larger number of channels (source--detector pairs) showed HbO 2 increase to face stimuli, especially at the greatest depth. Activation maps were obtained using 3D reconstruction methods on multi source--detector separation optical topography data.},
	author = {Blasi, A. and Fox, S. and Everdell, N. and Volein, A. and Tucker, L. and Csibra, G. and Gibson, A. P. and Hebden, J. C. and Johnson, M. H. and Elwell, C. E.},
	doi = {10.1088/0031-9155/52/23/005},
	issn = {0031-9155},
	journal = {Physics in Medicine \& Biology},
	language = {en},
	number = {23},
	pages = {6849},
	title = {Investigation of depth dependent changes in cerebral haemodynamics during face perception in infants},
	url = {http://stacks.iop.org/0031-9155/52/i=23/a=005},
	urldate = {2017-08-03},
	volume = {52},
	year = {2007},
	bdsk-url-1 = {http://stacks.iop.org/0031-9155/52/i=23/a=005},
	bdsk-url-2 = {https://doi.org/10.1088/0031-9155/52/23/005}}

@article{peelle_phase-locked_2013,
	abstract = {A growing body of evidence shows that ongoing oscillations in auditory cortex modulate their phase to match the rhythm of temporally regular acoustic stimuli, increasing sensitivity to relevant environmental cues and improving detection accuracy. In the current study, we test the hypothesis that nonsensory information provided by linguistic content enhances phase-locked responses to intelligible speech in the human brain. Sixteen adults listened to meaningful sentences while we recorded neural activity using magnetoencephalography. Stimuli were processed using a noise-vocoding technique to vary intelligibility while keeping the temporal acoustic envelope consistent. We show that the acoustic envelopes of sentences contain most power between 4 and 7 Hz and that it is in this frequency band that phase locking between neural activity and envelopes is strongest. Bilateral oscillatory neural activity phase-locked to unintelligible speech, but this cerebro-acoustic phase locking was enhanced when speech was intelligible. This enhanced phase locking was left lateralized and localized to left temporal cortex. Together, our results demonstrate that entrainment to connected speech does not only depend on acoustic characteristics, but is also affected by listeners' ability to extract linguistic information. This suggests a biological framework for speech comprehension in which acoustic and linguistic cues reciprocally aid in stimulus prediction.},
	author = {Peelle, Jonathan E. and Gross, Joachim and Davis, Matthew H.},
	doi = {10.1093/cercor/bhs118},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/GDCVEHHG/Peelle et al. - 2013 - Phase-Locked Responses to Speech in Human Auditory.pdf:application/pdf},
	issn = {1047-3211},
	journal = {Cerebral Cortex (New York, NY)},
	month = jun,
	number = {6},
	pages = {1378--1387},
	pmcid = {PMC3643716},
	pmid = {22610394},
	title = {Phase-{Locked} {Responses} to {Speech} in {Human} {Auditory} {Cortex} are {Enhanced} {During} {Comprehension}},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3643716/},
	urldate = {2017-05-31},
	volume = {23},
	year = {2013},
	bdsk-url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3643716/},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhs118}}

@article{prieto_phonotactic_2012,
	abstract = {The goal of this study is twofold: first, to examine in greater depth the claimed contribution of differences in syllable structure to measures of speech rhythm for three languages that are reported to belong to different rhythmic classes, namely, English, Spanish, and Catalan; and second, to investigate differences in the durational marking of prosodic heads and final edges of prosodic constituents between the three languages and test whether this distinction correlates in any way with the rhythmic distinctions. Data from a total of 24 speakers reading 720 utterances from these three languages show that differences in the rhythm metrics emerge even when syllable structure is controlled for in the experimental materials, at least between English on the one hand and Spanish/Catalan on the other, suggesting that important differences in durational patterns exist between these languages that cannot simply be attributed to differences in phonotactic properties. In particular, the vocalic variability measures nPVI-V, ΔV, and VarcoV are shown to be robust tools for discrimination above and beyond such phonotactic properties. Further analyses of the data indicate that the rhythmic class distinctions under consideration finely correlate with differences in the way these languages instantiate two prosodic timing processes, namely, the durational marking of prosodic heads, and pre-final lengthening at prosodic boundaries.},
	author = {Prieto, Pilar and Vanrell, Maria del Mar and Astruc, Llu{\"\i}sa and Payne, Elinor and Post, Brechtje},
	doi = {10.1016/j.specom.2011.12.001},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EMK6C5TM/Prieto et al. - 2012 - Phonotactic and phrasal properties of speech rhyth.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/82TZ8VQD/S0167639311001646.html:text/html},
	issn = {0167-6393},
	journal = {Speech Communication},
	keywords = {Rhythm, Accentual lengthening, Catalan language, English language, Final lengthening, Rhythm index measures, Spanish language},
	month = jul,
	number = {6},
	pages = {681--702},
	title = {Phonotactic and phrasal properties of speech rhythm. {Evidence} from {Catalan}, {English}, and {Spanish}},
	url = {http://www.sciencedirect.com/science/article/pii/S0167639311001646},
	urldate = {2017-04-18},
	volume = {54},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0167639311001646},
	bdsk-url-2 = {https://doi.org/10.1016/j.specom.2011.12.001}}

@inproceedings{ramus_psychological_2003,
	abstract = {Linguists have traditionally classified languages into three
rhythm classes, namely stress-timed, syllable-timed and mora-timed languages. However, this classification has remained controversial for various reasons: the search for reliable acoustic cues to the different rhythm types has long remained elusive; some languages are claimed to belong to none of the three classes; and few perceptual studies has bolstered the notion. We have previously proposed an acoustic/phonetic model of the different types of linguistic rhythm, and of their categorisation as such by
listeners. Here, we present perceptual experiments that directly test the notion of rhythm classes, our model's predictions, and the question of intermediate languages. Language discrimination experiments were run using a speech resynthesis technique to ensure that only rhythmic cues were available to the subjects. Languages investigated were English, Dutch, Spanish, Catalan and Polish. Our results are consistent with the idea that English and Dutch are stress-timed, Spanish and Catalan are syllable-timed,
but Polish seems to be different from any other language studied and thus may constitute a new rhythm class. We propose that perceptual studies tapping the ability to discriminate languages' rhythm are the proper way to generate more empirical data relevant to rhythm typology.},
	author = {Ramus, Franck and Dupoux, Emmanuel and Mehler, Jacques},
	file = {ICPhS03.pdf:/Users/Cecile/Zotero/storage/BCFTZMLG/ICPhS03.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M4UFZPJ6/3079.html:text/html},
	publisher = {Universitat Aut{\`o}noma de Barcelona},
	shorttitle = {The psychological reality of rhythm classes},
	title = {The psychological reality of rhythm classes: {Perceptual} studies},
	url = {http://cogprints.org/3079/},
	urldate = {2017-04-18},
	year = {2003},
	bdsk-url-1 = {http://cogprints.org/3079/}}

@article{arvaniti_usefulness_2012,
	abstract = {The performance of the rhythm metrics ΔC, \%V, PVIs and Varcos, said to quantify rhythm class distinctions, was tested using English, German, Greek, Italian, Korean and Spanish. Eight participants per language produced speech using three elicitation methods, spontaneous speech, story reading and reading a set of sentences divided into ``uncontrolled'' sentences from original works of each language, and sentences devised to maximize or minimize syllable structure complexity (``stress-timed'' and ``syllable-timed'' sets respectively). Rhythm classifications based on pooled data were inconsistent across metrics, while cross-linguistic differences in scores were often statistically non-significant even for comparisons between prototypical languages like English and Spanish. Metrics showed substantial inter-speaker variation and proved very sensitive to elicitation method and syllable complexity, so that the size of both effects was large and often comparable to that of language. These results suggest that any cross-linguistic differences captured by metrics are not robust; metric scores range substantially within a language and are readily affected by a variety of methodological decisions, making cross-linguistic comparisons and rhythmic classifications based on metrics unsafe at best.},
	author = {Arvaniti, Amalia},
	doi = {10.1016/j.wocn.2012.02.003},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/6DM3HWNS/Arvaniti - 2012 - The usefulness of metrics in the quantification of.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/49EEG99U/S0095447012000137.html:text/html},
	issn = {0095-4470},
	journal = {Journal of Phonetics},
	month = may,
	number = {3},
	pages = {351--373},
	title = {The usefulness of metrics in the quantification of speech rhythm},
	url = {http://www.sciencedirect.com/science/article/pii/S0095447012000137},
	urldate = {2017-04-18},
	volume = {40},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0095447012000137},
	bdsk-url-2 = {https://doi.org/10.1016/j.wocn.2012.02.003}}

@article{moore_noise-invariant_2013,
	abstract = {Author Summary Birds and humans excel at the task of detecting important sounds, such as song and speech, in difficult listening environments such as in a large bird colony or in a crowded bar. How our brains achieve such a feat remains a mystery to both neuroscientists and audio engineers. In our research, we found a population of neurons in the brain of songbirds that are able to extract a song signal from a background of noise. We explain how the neurons are able to perform this task and show how a biologically inspired algorithm could outperform the best noise-reduction methods proposed by engineers.},
	author = {Moore, R. Channing and Lee, Tyler and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1371/journal.pcbi.1002942},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4N4TQTIQ/Moore et al. - 2013 - Noise-invariant Neurons in the Avian Auditory Cort.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/GX8F7CNW/Moore et al. - 2013 - Noise-invariant Neurons in the Avian Auditory Cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/I2PFS8FQ/article.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/T46GS26Z/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Algorithms, Audio signal processing, Modulation, Neuronal tuning, Neurons, Signal filtering, Signal processing, Speech signal processing},
	month = mar,
	number = {3},
	pages = {e1002942},
	shorttitle = {Noise-invariant {Neurons} in the {Avian} {Auditory} {Cortex}},
	title = {Noise-invariant {Neurons} in the {Avian} {Auditory} {Cortex}: {Hearing} the {Song} in {Noise}},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002942},
	urldate = {2017-04-05},
	volume = {9},
	year = {2013},
	bdsk-url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002942},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1002942}}

@article{ng_eeg_2013,
	author = {Ng, Benedict Shien Wei and Logothetis, Nikos K. and Kayser, Christoph},
	doi = {10.1093/cercor/bhs031},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UW5ACM5M/Ng et al. - 2013 - EEG Phase Patterns Reflect the Selectivity of Neur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GDIP4PZA/bhs031.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = feb,
	number = {2},
	pages = {389--398},
	title = {{EEG} {Phase} {Patterns} {Reflect} the {Selectivity} of {Neural} {Firing}},
	url = {https://academic.oup.com/cercor/article/23/2/389/286373/EEG-Phase-Patterns-Reflect-the-Selectivity-of},
	urldate = {2017-06-01},
	volume = {23},
	year = {2013},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/23/2/389/286373/EEG-Phase-Patterns-Reflect-the-Selectivity-of},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhs031}}

@article{fukui_monte_2003,
	abstract = {In near-infrared spectroscopy and imaging, the sensitivity of the detected signal to brain activation and the volume of interrogated tissue are clinically important. Light propagation in adult and neonatal heads is strongly affected by the presence of a low-scattering cerebrospinal fluid layer. The effect of the heterogeneous structure of the head on light propagation in the adult brain is likely to be different from that in the neonatal brain because the thickness of the superficial tissues and the optical properties of the brain of the neonatal head are quite different from those of the adult head. In this study, light propagation in the two-dimensional realistic adult and neonatal head models, whose geometries are generated from a magnetic resonance imaging scan of the human heads, is predicted by Monte Carlo simulation. The sandwich structure, which is a low-scattering cerebrospinal fluid layer held between the high-scattering skull and gray matter, strongly affects light propagation in the brain of the adult head. The sensitivity of the absorption change in the gray matter is improved; however, the intensely sensitive region is confined to the shallow region of the gray matter. The high absorption of the neonatal brain causes a similar effect on light propagation in the head. The intensely sensitive region in the neonatal brain is confined to the gray matter; however, the spatial sensitivity profile penetrates into the deeper region of the white matter.},
	author = {Fukui, Yuich and Ajichi, Yusaku and Okada, Eiji},
	copyright = {{\copyright} 2003 Optical Society of America},
	doi = {10.1364/AO.42.002881},
	file = {fukui2003.pdf:/Users/Cecile/Zotero/storage/U6AG9G29/fukui2003.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ICUCZTM2/abstract.html:text/html},
	issn = {1539-4522},
	journal = {Applied Optics},
	keywords = {Light propagation in tissues, Medical optics and biotechnology, Medical optics instrumentation},
	language = {EN},
	month = jun,
	number = {16},
	pages = {2881--2887},
	title = {Monte {Carlo} prediction of near-infrared light propagation in realistic adult and neonatal head models},
	url = {https://www.osapublishing.org/abstract.cfm?uri=ao-42-16-2881},
	urldate = {2017-06-13},
	volume = {42},
	year = {2003},
	bdsk-url-1 = {https://www.osapublishing.org/abstract.cfm?uri=ao-42-16-2881},
	bdsk-url-2 = {https://doi.org/10.1364/AO.42.002881}}

@article{minagawa-kawai_assessing_2011,
	abstract = {Past studies have found that in adults that acoustic properties of sound signals (such as fast vs. slow temporal features) differentially activate the left and right hemispheres, and some have hypothesized that left-lateralization for speech processing may follow from left-lateralization to rapidly changing signals. Here, we tested whether newborns' brains show some evidence of signal-specific lateralization responses using near-infrared spectroscopy (NIRS) and auditory stimuli that elicits lateralized responses in adults, composed of segments that vary in duration and spectral diversity. We found significantly greater bilateral responses of oxygenated hemoglobin (oxy-Hb) in the temporal areas for stimuli with a minimum segment duration of 21 ms, than stimuli with a minimum segment duration of 667 ms. However, we found no evidence for hemispheric asymmetries dependent on the stimulus characteristics. We hypothesize that acoustic-based functional brain asymmetries may develop throughout early infancy, and discuss their possible relationship with brain asymmetries for language.},
	author = {Minagawa-Kawai, Yasuyo and Cristi{\`a}, Alejandrina and Vendelin, Inga and Cabrol, Dominique and Dupoux, Emmanuel},
	doi = {10.3389/fpsyg.2011.00135},
	file = {Minagawa-Kawai et al. - 2011 - Assessing Signal-Driven Mechanisms in Neonates Br.pdf:/Users/Cecile/Zotero/storage/Y4PM6S9J/Minagawa-Kawai et al. - 2011 - Assessing Signal-Driven Mechanisms in Neonates Br.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	keywords = {near-infrared spectroscopy (NIRS), functional lateralization, hemispheric specialization, signal-driven system, neonates, Development, Auditory cortex},
	language = {English},
	shorttitle = {Assessing {Signal}-{Driven} {Mechanisms} in {Neonates}},
	title = {Assessing {Signal}-{Driven} {Mechanisms} in {Neonates}: {Brain} {Responses} to {Temporally} and {Spectrally} {Different} {Sounds}},
	url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00135/full},
	urldate = {2017-06-13},
	volume = {2},
	year = {2011},
	bdsk-url-1 = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00135/full},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2011.00135}}

@article{strangman_non-invasive_2002,
	abstract = {This article reviews diffuse optical brain imaging, a technique that employs near-infrared light to non-invasively probe the brain for changes in parameters relating to brain function. We describe the general methodology, including types of measurements and instrumentation (including the tradeoffs inherent in the various instrument components), and the basic theory required to interpret the recorded data. A brief review of diffuse optical applications is included, with an emphasis on research that has been done with psychiatric populations. Finally, we discuss some practical issues and limitations that are relevant when conducting diffuse optical experiments. We find that, while diffuse optics can provide substantial advantages to the psychiatric researcher relative to the alternative brain imaging methods, the method remains substantially underutilized in this field.},
	author = {Strangman, Gary and Boas, David A and Sutton, Jeffrey P},
	doi = {10.1016/S0006-3223(02)01550-0},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/6RIK47NK/Strangman et al. - 2002 - Non-invasive neuroimaging using near-infrared ligh.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/HKUJ7XCG/S0006322302015500.html:text/html},
	issn = {0006-3223},
	journal = {Biological Psychiatry},
	keywords = {NIRS, optical imaging, Diffuse optical tomography, functional brain activity, non-invasive},
	month = oct,
	number = {7},
	pages = {679--693},
	title = {Non-invasive neuroimaging using near-infrared light},
	url = {http://www.sciencedirect.com/science/article/pii/S0006322302015500},
	urldate = {2017-06-13},
	volume = {52},
	year = {2002},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0006322302015500},
	bdsk-url-2 = {https://doi.org/10.1016/S0006-3223(02)01550-0}}

@article{blasi_early_2011,
	abstract = {Human voices play a fundamental role in social communication, and areas of the adult ``social brain'' show specialization for processing voices and their emotional content (superior temporal sulcus, inferior prefrontal cortex, premotor cortical regions, amygdala, and insula) [1--8]. However, it is unclear when this specialization develops. Functional magnetic resonance (fMRI) studies suggest that the infant temporal cortex does not differentiate speech from music or backward speech [9, 10], but a prior study with functional near-infrared spectroscopy revealed preferential activation for human voices in 7-month-olds, in a more posterior location of the temporal cortex than in adults [11]. However, the brain networks involved in processing nonspeech human vocalizations in early development are still unknown. To address this issue, in the present fMRI study, 3- to 7-month-olds were presented with adult nonspeech vocalizations (emotionally neutral, emotionally positive, and emotionally negative) and nonvocal environmental sounds. Infants displayed significant differential activation in the anterior portion of the temporal cortex, similarly to adults [1]. Moreover, sad vocalizations modulated the activity of brain regions involved in processing affective stimuli such as the orbitofrontal cortex [12] and insula [7, 8]. These results suggest remarkably early functional specialization for processing human voice and negative emotions.},
	author = {Blasi, Anna and Mercure, Evelyne and Lloyd-Fox, Sarah and Thomson, Alex and Brammer, Michael and Sauter, Disa and Deeley, Quinton and Barker, Gareth J. and Renvall, Ville and Deoni, Sean and Gasston, David and Williams, Steven C. R. and Johnson, Mark H. and Simmons, Andrew and Murphy, Declan G. M.},
	doi = {10.1016/j.cub.2011.06.009},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AQMGDNJ8/S0960982211006543.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	month = jul,
	number = {14},
	pages = {1220--1224},
	title = {Early {Specialization} for {Voice} and {Emotion} {Processing} in the {Infant} {Brain}},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982211006543},
	urldate = {2017-06-16},
	volume = {21},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982211006543},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2011.06.009}}

@article{lloyd-fox_illuminating_2010,
	abstract = {A decade has passed since near infrared spectroscopy (NIRS) was first applied to functional brain imaging in infants. As part of the team that published the first functional near infrared spectroscopy (fNIRS) infant study in 1998, we have continued to develop and refine both the technology and methods associated with these measurements. The increasing international interest that this technology is generating among neurodevelopmental researchers and the recent technical developments in biomedical optics have prompted us to compile this review of the challenges that have been overcome in this field, and the practicalities of performing fNIRS in infants. We highlight the increasingly diverse and ambitious studies that have been undertaken and review the technological and methodological advances that have been made in the study design, optical probe development, and interpretation and analyses of the haemodynamic response. A strong emphasis is placed on the potential of the technology and future prospects of fNIRS in the field of developmental neuroscience.},
	author = {Lloyd-Fox, S. and Blasi, A. and Elwell, C. E.},
	doi = {10.1016/j.neubiorev.2009.07.008},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QEXN9J5R/Lloyd-Fox et al. - 2010 - Illuminating the developing brain The past, prese.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PPM2HB2P/S0149763409001043.html:text/html},
	issn = {0149-7634},
	journal = {Neuroscience \& Biobehavioral Reviews},
	keywords = {Infant, functional brain imaging, optical imaging, Developmental neuroscience, Near infrared spectroscopy (NIRS)},
	month = feb,
	number = {3},
	pages = {269--284},
	shorttitle = {Illuminating the developing brain},
	title = {Illuminating the developing brain: {The} past, present and future of functional near infrared spectroscopy},
	url = {http://www.sciencedirect.com/science/article/pii/S0149763409001043},
	urldate = {2017-06-13},
	volume = {34},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0149763409001043},
	bdsk-url-2 = {https://doi.org/10.1016/j.neubiorev.2009.07.008}}

@article{plichta_event-related_2006,
	abstract = {The purpose of the present study was to investigate the retest reliability of event-related functional near-infrared spectroscopy (fNIRS). Therefore, isolated functional activation was evoked in the occipital cortex by a periodic checkerboard stimulation. During a 52-channel fNIRS recording, 12 subjects underwent 60 trials of visual stimulation in two sessions. The retest interval was set to 3 weeks. Linear correlations of the contrast t values supplemented by scatter plots, channel-wise intraclass correlation coefficients (ICC) as well as reproducibility indices for the quantity of activated channels (RQUANTITY) and the location (ROVERLAP) of the detected activation were calculated. The results at the group level showed good reliability in terms of the single measure ICCs (up to 0.84) and excellent reproducibility quantified by RQUANTITY and ROVERLAP (up to 96\% of the quantity and the location were reproducible), whereas the results at the single subjects' level were mediocre. Furthermore, the reliability assessed by single measurement ICCs improved if regarded at a cluster level.},
	author = {Plichta, M. M. and Herrmann, M. J. and Baehne, C. G. and Ehlis, A. -C. and Richter, M. M. and Pauli, P. and Fallgatter, A. J.},
	doi = {10.1016/j.neuroimage.2005.12.008},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ASQUF43T/Plichta et al. - 2006 - Event-related functional near-infrared spectroscop.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7BIJ22RQ/S1053811905025425.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {NIRS, Time series analysis, Deoxygenated haemoglobin, Event-related, Functional near-infrared spectroscopy, Oxygenated haemoglobin, Reproducibility, Test--retest reliability, Total haemoglobin},
	month = may,
	number = {1},
	pages = {116--124},
	shorttitle = {Event-related functional near-infrared spectroscopy ({fNIRS})},
	title = {Event-related functional near-infrared spectroscopy ({fNIRS}): {Are} the measurements reliable?},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905025425},
	urldate = {2017-06-13},
	volume = {31},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811905025425},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2005.12.008}}

@article{taga_brain_2003,
	abstract = {Studies of young infants are critical to understand perceptual, motor, and cognitive processing in humans. However, brain mechanisms involved are poorly understood, because the use of brain-imaging methods such as functional magnetic resonance imaging in awake infants is difficult. In the present study we show functional brain imaging of awake infants viewing visual stimuli by means of multichannel near-infrared spectroscopy, a technique that permits a measurement of cerebral hemoglobin oxygenation in response to brain activation through the intact skull without subject constraint. We found that event-related increases in oxyhemoglobin were evident in localized areas of the occipital cortex of infants aged 2--4 months in response to a brief presentation of a checkerboard pattern reversal while they maintained fixation to attention-grabbing stimuli. The dynamic change in cerebral blood oxygenation was qualitatively similar to that observed in the adult brain. This result introduces near-infrared optical topography as a method for investigating the functional development of the brain in early infancy.},
	author = {Taga, Gentaro and Asakawa, Kayo and Maki, Atsushi and Konishi, Yukuo and Koizumi, Hideaki},
	doi = {10.1073/pnas.1932552100},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KTFIZDDT/Taga et al. - 2003 - Brain imaging in awake infants by near-infrared op.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KMIXH65V/10722.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = sep,
	number = {19},
	pages = {10722--10727},
	pmid = {12960368},
	title = {Brain imaging in awake infants by near-infrared optical topography},
	url = {http://www.pnas.org/content/100/19/10722},
	urldate = {2017-06-14},
	volume = {100},
	year = {2003},
	bdsk-url-1 = {http://www.pnas.org/content/100/19/10722},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1932552100}}

@article{brigadoi_how_2015,
	abstract = {In recent years, it has been demonstrated that using functional near-infrared spectroscopy (fNIRS) channels with short separations to explicitly sample extra-cerebral tissues can provide a significant improvement in the accuracy and reliability of fNIRS measurements. The aim of these short-separation channels is to measure the same superficial hemodynamics observed by standard fNIRS channels while also being insensitive to the brain. We use Monte Carlo simulations of photon transport in anatomically informed multilayer models to determine the optimum source-detector distance for short-separation channels in adult and newborn populations. We present a look-up plot that provides (for an acceptable value of short-separation channel brain sensitivity relative to standard channel brain sensitivity) the optimum short-separation distance. Though values vary across the scalp, when the acceptable ratio of the short-separation channel brain sensitivity to standard channel brain sensitivity is set at 5\%, the optimum short-separation distance is 8.4 mm in the typical adult and 2.15 mm in the term-age infant.},
	author = {Brigadoi, Sabrina and Cooper, Robert J.},
	doi = {10.1117/1.NPh.2.2.025005},
	issn = {2329-423X},
	journal = {Neurophotonics},
	keywords = {Functional near-infrared spectroscopy, Monte Carlo simulations, short-separation channel, source--detector distance},
	language = {eng},
	month = apr,
	number = {2},
	pages = {025005},
	pmcid = {PMC4478880},
	pmid = {26158009},
	shorttitle = {How short is short?},
	title = {How short is short? {Optimum} source-detector distance for short-separation channels in functional near-infrared spectroscopy},
	volume = {2},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1117/1.NPh.2.2.025005}}

@article{taga_effects_2007,
	abstract = {One of the practical problems in neuroimaging using near infrared spectroscopy (NIRS) is to choose an appropriate source-detector distance to maximize the sensitivity to cerebral blood oxygenation and to improve the spatial resolution for mapping cortical activation. While NIRS has attracted increasing attention in neuroimaging in infants, there has been no report of comparative data regarding source-detector distance for the infant brain. In the present study, 9 quietly sleeping 3-month-old infants were exposed to 3-s speech sounds, and hemodynamic responses over the bilateral temporal cortices were assessed by using multiple pairs of source and detector of NIR light with varying distances (1, 2, 3 and 4 cm) and varying intensities (0.6 and 1.2 mW). The statistical analyses of the group-averaged hemodynamic responses and the frequency analyses of the signal-to-noise ratios revealed that a 2-cm source-detector distance with 0.6-mW NIR light provided the highest sensitivity to cortical responses. This indicates that NIRS can be used to detect the activation of the cortical regions, in the infant brain, by using the source-detector distance scaled to the smaller head size of infants and a relatively low intensity of NIR light compared to the ones that have been routinely used in adult studies.},
	author = {Taga, Gentaro and Homae, Fumitaka and Watanabe, Hama},
	doi = {10.1016/j.neuroimage.2007.07.050},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4K7U2K3C/Taga et al. - 2007 - Effects of source-detector distance of near infrar.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/U5JU4GV6/S105381190700660X.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = nov,
	number = {3},
	pages = {452--460},
	title = {Effects of source-detector distance of near infrared spectroscopy on the measurement of the cortical hemodynamic response in infants},
	url = {http://www.sciencedirect.com/science/article/pii/S105381190700660X},
	urldate = {2017-06-13},
	volume = {38},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S105381190700660X},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2007.07.050}}

@article{brigadoi_4d_2014,
	abstract = {Diffuse optical tomography is most accurate when an individual's MRI data can be used as a spatial prior for image reconstruction and for visualization of the resulting images of changes in oxy- and deoxy-hemoglobin concentration. As this necessitates an MRI scan to be performed for each study, which undermines many of the advantages of diffuse optical methods, the use of registered atlases to model the individual's anatomy is becoming commonplace. Infant studies require carefully age-matched atlases because of the rapid growth and maturation of the infant brain. In this paper, we present a 4D neonatal head model which, for each week from 29 to 44 weeks post-menstrual age, includes: 1) a multi-layered tissue mask which identifies extra-cerebral layers, cerebrospinal fluid, gray matter, white matter, cerebellum and brainstem, 2) a high-density tetrahedral head mesh, 3) surface meshes for the scalp, gray-matter and white matter layers and 4) cranial landmarks and 10-5 locations on the scalp surface. This package, freely available online at www.ucl.ac.uk/medphys/research/4dneonatalmodel can be applied by users of near-infrared spectroscopy and diffuse optical tomography to optimize probe locations, optimize image reconstruction, register data to cortical locations and ultimately improve the accuracy and interpretation of diffuse optical techniques in newborn populations.},
	author = {Brigadoi, Sabrina and Aljabar, Paul and Kuklisova-Murgasova, Maria and Arridge, Simon R. and Cooper, Robert J.},
	doi = {10.1016/j.neuroimage.2014.06.028},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/9DQK95W9/Brigadoi et al. - 2014 - A 4D neonatal head model for diffuse optical imagi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JNPJB8GG/S1053811914005059.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {NIRS, Diffuse optical imaging, Diffuse optical tomography, Mesh, Neonatal head models, Preterm infants},
	month = oct,
	pages = {385--394},
	title = {A {4D} neonatal head model for diffuse optical imaging of pre-term to term infants},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811914005059},
	urldate = {2017-06-13},
	volume = {100},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914005059},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2014.06.028}}

@article{cristia_online_2013,
	abstract = {Until recently, imaging the infant brain was very challenging. Functional Near InfraRed Spectroscopy (fNIRS) is a promising, relatively novel technique, whose use is rapidly expanding. As an emergent field, it is particularly important to share methodological knowledge to ensure replicable and robust results. In this paper, we present a community-augmented database which will facilitate precisely this exchange. We tabulated articles and theses reporting empirical fNIRS research carried out on infants below three years of age along several methodological variables. The resulting spreadsheet has been uploaded in a format allowing individuals to continue adding new results, and download the most recent version of the table. Thus, this database is ideal to carry out systematic reviews. We illustrate its academic utility by focusing on the factors affecting three key variables: infant attrition, the reliability of oxygenated and deoxygenated responses, and signal-to-noise ratios. We then discuss strengths and weaknesses of the DBIfNIRS, and conclude by suggesting a set of simple guidelines aimed to facilitate methodological convergence through the standardization of reports.},
	author = {Cristia, Alejandrina and Dupoux, Emmanuel and Hakuno, Yoko and Lloyd-Fox, Sarah and Schuetze, Manuela and Kivits, Jos{\'e} and Bergvelt, Tomas and Gelder, Marjolijn van and Filippin, Luca and Charron, Sylvain and Minagawa-Kawai, Yasuyo},
	doi = {10.1371/journal.pone.0058906},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KWHKW8ZJ/Cristia et al. - 2013 - An Online Database of Infant Functional Near Infra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VHXTII3Z/article.pdf:application/pdf},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Age groups, Hemodynamics, neuroimaging, Signal to noise ratio, Supervisors, Infants, Near-infrared spectroscopy, HEMOGLOBIN},
	month = mar,
	number = {3},
	pages = {e58906},
	shorttitle = {An {Online} {Database} of {Infant} {Functional} {Near} {InfraRed} {Spectroscopy} {Studies}},
	title = {An {Online} {Database} of {Infant} {Functional} {Near} {InfraRed} {Spectroscopy} {Studies}: {A} {Community}-{Augmented} {Systematic} {Review}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0058906},
	urldate = {2017-06-13},
	volume = {8},
	year = {2013},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0058906},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0058906}}

@article{lloyd-fox_coregistering_2014,
	abstract = {Abstract. 
Functional near-infrared spectroscopy (fNIRS) is becoming a popular tool in developmental neuroscience for mapping functional localized brain responses. However, as it cannot provide information about underlying anatomy, researchers have begun to conduct spatial registration of fNIRS channels to cortical anatomy in adults. The current work investigated this issue with infants by coregistering fNIRS and magnetic resonance imaging (MRI) data from 55 individuals. Our findings suggest that fNIRS channels can be reliably registered with regions in the frontal and temporal cortex of infants from 4 to 7 months of age. Although some macro-anatomical regions are difficult to consistently define, others are more stable and fNIRS channels on an age-appropriate MRI template are often consistent with individual infant MRIs. We have generated a standardized scalp surface map of fNIRS channel locators to reliably locate cortical regions for fNIRS developmental researchers. This new map can be used to identify the inferior frontal gyrus, superior temporal sulcus (STS) region [which includes the superior and middle temporal gyri (MTG) nearest to the STS], and MTG and temporal-parietal regions in 4- to 7-month-old infants. Future work will model data for the whole head, taking into account the properties of light transport in tissue, and expanding to different ages across development.},
	author = {Lloyd-Fox, Sarah and Richards, John E. and Blasi, Anna and Murphy, Declan G. M. and Elwell, Clare E. and Johnson, Mark H.},
	doi = {10.1117/1.NPh.1.2.025006},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ITPUKZ7U/Lloyd-Fox et al. - 2014 - Coregistering functional near-infrared spectroscop.pdf:application/pdf},
	issn = {2329-423X},
	journal = {Neurophotonics},
	number = {2},
	pages = {025006--025006},
	title = {Coregistering functional near-infrared spectroscopy with underlying cortical areas in infants},
	url = {http://dx.doi.org/10.1117/1.NPh.1.2.025006},
	urldate = {2017-06-16},
	volume = {1},
	year = {2014},
	bdsk-url-1 = {http://dx.doi.org/10.1117/1.NPh.1.2.025006}}

@article{singh_mapping_2014,
	abstract = {Seizures in the newborn brain represent a major challenge to neonatal medicine. Neonatal seizures are poorly classified, under-diagnosed, difficult to treat and are associated with poor neurodevelopmental outcome. Video-EEG is the current gold-standard approach for seizure detection and monitoring. Interpreting neonatal EEG requires expertise and the impact of seizures on the developing brain remains poorly understood. In this case study we present the first ever images of the haemodynamic impact of seizures on the human infant brain, obtained using simultaneous diffuse optical tomography (DOT) and video-EEG with whole-scalp coverage. Seven discrete periods of ictal electrographic activity were observed during a 60 minute recording of an infant with hypoxic--ischaemic encephalopathy. The resulting DOT images show a remarkably consistent, high-amplitude, biphasic pattern of changes in cortical blood volume and oxygenation in response to each electrographic event. While there is spatial variation across the cortex, the dominant haemodynamic response to seizure activity consists of an initial increase in cortical blood volume prior to a large and extended decrease typically lasting several minutes. This case study demonstrates the wealth of physiologically and clinically relevant information that DOT--EEG techniques can yield. The consistency and scale of the haemodynamic responses observed here also suggest that DOT--EEG has the potential to provide improved detection of neonatal seizures.},
	author = {Singh, Harsimrat and Cooper, Robert J. and Wai Lee, Chuen and Dempsey, Laura and Edwards, Andrea and Brigadoi, Sabrina and Airantzis, Dimitrios and Everdell, Nick and Michell, Andrew and Holder, David and Hebden, Jeremy C. and Austin, Topun},
	doi = {10.1016/j.nicl.2014.06.012},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EGIPUAEH/Singh et al. - 2014 - Mapping cortical haemodynamics during neonatal sei.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/J6FC2KUT/S2213158214000886.html:text/html},
	issn = {2213-1582},
	journal = {NeuroImage: Clinical},
	keywords = {Diffuse optical tomography (DOT), Functional near infrared spectroscopy (fNIRS), Hypoxic--ischaemic encephalopathy (HIE), Neonatal seizures},
	pages = {256--265},
	shorttitle = {Mapping cortical haemodynamics during neonatal seizures using diffuse optical tomography},
	title = {Mapping cortical haemodynamics during neonatal seizures using diffuse optical tomography: {A} case study},
	url = {http://www.sciencedirect.com/science/article/pii/S2213158214000886},
	urldate = {2017-06-13},
	volume = {5},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S2213158214000886},
	bdsk-url-2 = {https://doi.org/10.1016/j.nicl.2014.06.012}}

@article{plichta_model-based_2007,
	abstract = {To validate the usefulness of a model-based analysis approach according to the general linear model (GLM) for functional near-infrared spectroscopy (fNIRS) data, a rapid event-related paradigm with an unpredictable stimulus sequence was applied to 15 healthy subjects. A parametric design was chosen wherein four differently graded contrasts of a flickering checkerboard were presented, allowing directed hypotheses about the rank order of the evoked hemodynamic response amplitudes. The results indicate the validity of amplitude estimation by three main findings (a) the GLM approach for fNIRS data is capable to identify human brain activation in the visual cortex with inter-stimulus intervals of 4--9 s (6.5 s average) whereas in non-visual areas no systematic activation was detectable; (b) the different contrast level intensities lead to the hypothesized rank order of the GLM amplitude parameters: visual cortex activation evoked by highest contrast \&gt; moderate contrast \&gt; lowest contrast \&gt; no stimulation; (c) analysis of null-events (no stimulation) did not produce any significant activation in the visual cortex or in other brain areas.
We conclude that a model-based GLM approach delivers valid fNIRS amplitude estimations and enables the analysis of rapid event-related fNIRS data series, which is highly relevant in particular for cognitive fNIRS studies.},
	author = {Plichta, M. M. and Heinzel, S. and Ehlis, A. -C. and Pauli, P. and Fallgatter, A. J.},
	doi = {10.1016/j.neuroimage.2006.11.028},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/G8BZMHTJ/Plichta et al. - 2007 - Model-based analysis of rapid event-related functi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/47CCUQ29/S1053811906011657.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {GLM, Methods, NIRS, Event-related, Functional near-infrared spectroscopy, Model-based approach, OLS, Parametric design, Two-stage ordinary least square},
	month = apr,
	number = {2},
	pages = {625--634},
	shorttitle = {Model-based analysis of rapid event-related functional near-infrared spectroscopy ({NIRS}) data},
	title = {Model-based analysis of rapid event-related functional near-infrared spectroscopy ({NIRS}) data: {A} parametric validation study},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811906011657},
	urldate = {2017-06-13},
	volume = {35},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811906011657},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2006.11.028}}

@article{perdue_effects_2013,
	abstract = {The objective of this work is to quantify how patterns of cortical activity at different spatial scales are measured by noninvasive functional neuroimaging sensors. We simulated cortical activation patterns at nine different spatial scales in a realistic head model and propagated this activity to magnetoencephalography (MEG), electroencephalography (EEG), diffuse optical tomography (DOT), and functional magnetic resonance imaging (fMRI) sensors in arrangements that are typically used in functional neuroimaging studies. We estimated contrast transfer functions (CTF), correlation distances in sensor space, and the minimum resolvable spatial scale of cortical activity for each modality. We found that CTF decreases as the spatial extent of cortical activity decreases, and that correlations between nearby sensors depend on the spatial extent of cortical activity. For cortical activity on the intermediate spatial scale of 6.7 cm2, the correlation distances (r{\textgreater}0.5) were 1.0 cm for fMRI, 2.0 cm for DOT, 12.8 for EEG, 9.5 cm for MEG magnetometers and 9.7 cm for MEG gradiometers. The resolvable spatial pattern scale was found to be 1.43 cm2 for MEG magnetometers, 0.88 cm2 for MEG gradiometers, 376 cm2 for EEG, 0.75 cm2 for DOT, and 0.072 cm2 for fMRI. These findings show that sensitivity to cortical activity varies substantially as a function of spatial scale within and between the different imaging modalities. This information should be taken into account when interpreting neuroimaging data and when choosing the number of nodes for network analyses in sensor space.},
	author = {Perdue, Katherine L. and Diamond, Solomon Gilbert},
	doi = {10.1371/journal.pone.0083299},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CV8FJ99M/Perdue et Diamond - 2013 - Effects of Spatial Pattern Scale of Brain Activity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DZXRUZQX/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Imaging techniques, Electroencephalography, Head, neuroimaging, Magnetometers, Network analysis, functional magnetic resonance imaging, magnetoencephalography},
	month = dec,
	number = {12},
	pages = {e83299},
	title = {Effects of {Spatial} {Pattern} {Scale} of {Brain} {Activity} on the {Sensitivity} of {DOT}, {fMRI}, {EEG} and {MEG}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083299},
	urldate = {2017-06-15},
	volume = {8},
	year = {2013},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083299},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0083299}}

@article{duncan_measurement_1996,
	abstract = {Near infrared spectroscopy (NIRS) has been used to measure concentration changes of cerebral hemoglobin and cytochrome in neonates, children, and adults, to study cerebral oxygenation and hemodynamics. To derive quantitative concentration changes from measurements of light attenuation, the optical path length must be known. This is obtained by multiplying the source/detector separation by a laboratory measured differential path length factor (DPF) which accounts for the increased distance traveled by light due to scattering. DPF has been measured by time of flight techniques on small populations of adults and postmortem infants. The values for adults are greater than those for newborns, and it is not clear how to interpolate the present data for studies on children. Recent developments in instrumentation using phase resolved spectroscopy techniques have produced a bedside unit which can measure optical path length on any subject. We have developed an intensity modulated optical spectrometer which measures path length at four wavelengths. Two hundred and eighty three subjects from 1 d of age to 50 y were studied. Measurements were made at a fixed frequency of 200 MHz and a source detector separation of 4.5 cm. Results suggest a slowly varying age dependence of DPF, following the relation DPF690 = 5.38 + 0.049A0.877, DPF744 = 5.11 + 0.106A0.723, DPF807 = 4.99 + 0.067A0.814, and DPF832 = 4.67 + 0.062A0.819, where DPF690 is the DPF measured at 690 nm and A is age is expressed in years from full term. There was a wide scatter of values, however, implying that ideally DPF should be measured at the time of each study.},
	author = {Duncan, Arlene and Meek, Judith H. and Clemence, Matthew and Elwell, Clare E. and Fallon, Penny and Tyszczuk, Lidia and Cope, Mark and Delpy, David T.},
	copyright = {{\copyright} 1996 Nature Publishing Group},
	doi = {10.1203/00006450-199605000-00025},
	file = {Snapshot:/Users/Cecile/Zotero/storage/HGHQR7R2/pr19962544a.html:text/html},
	issn = {0031-3998},
	journal = {Pediatric Research},
	language = {en},
	month = may,
	number = {5},
	pages = {889--894},
	title = {Measurement of {Cranial} {Optical} {Path} {Length} as a {Function} of {Age} {Using} {Phase} {Resolved} {Near} {Infrared} {Spectroscopy}},
	url = {https://www.nature.com/pr/journal/v39/n5/full/pr19962544a.html},
	urldate = {2017-06-16},
	volume = {39},
	year = {1996},
	bdsk-url-1 = {https://www.nature.com/pr/journal/v39/n5/full/pr19962544a.html},
	bdsk-url-2 = {https://doi.org/10.1203/00006450-199605000-00025}}

@article{plichta_event-related_2006-1,
	abstract = {The purpose of this study was to investigate the regional specificity of multi-channel functional near-infrared spectroscopy (fNIRS) in the detection of cortical activation in humans. Therefore, brain},
	author = {Plichta, M. M. and Herrmann, M. J. and Ehlis, A.-C. and Baehne, C. G. and Richter, M. M. and Fallgatter, A. J.},
	doi = {10.1159/000091723},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/C9BEFBAE/Plichta et al. - 2006 - Event-Related Visual versus Blocked Motor Task De.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/423VVGHJ/91723.html:text/html},
	issn = {0302-282X, 1423-0224},
	journal = {Neuropsychobiology},
	language = {english},
	number = {2},
	pages = {77--82},
	pmid = {16511338},
	shorttitle = {Event-{Related} {Visual} versus {Blocked} {Motor} {Task}},
	title = {Event-{Related} {Visual} versus {Blocked} {Motor} {Task}: {Detection} of {Specific} {Cortical} {Activation} {Patterns} with {Functional} {Near}-{Infrared} {Spectroscopy}},
	url = {http://www.karger.com/Article/Abstract/91723},
	urldate = {2017-06-15},
	volume = {53},
	year = {2006},
	bdsk-url-1 = {http://www.karger.com/Article/Abstract/91723},
	bdsk-url-2 = {https://doi.org/10.1159/000091723}}

@article{watanabe_general_2010,
	abstract = {A critical issue in the functional development of the cerebral cortex is whether cortical regions are functionally differentiated in early infancy. Although a growing number of neuroimaging studies have revealed that functional differentiation between early sensory and association regions of the cortex is already present at 3 months of age, it is unclear how functional regions per se emerge in the earlier developmental period. Here, we present 3 possible hypotheses regarding the functional development of the cerebral cortex as follows: (1) functionally differentiated regions are prespecified in the early developmental period; (2) functional activations appear in a hierarchical order from early sensory regions to the association regions; and (3) functional activation patterns change in a general-to-specific manner, thereby increasing the localization of regions activated by a particular stimulus and increasing the exclusivity of the response to specific stimuli within a particular cortical region. In the present study, we used multichannel near-infrared spectroscopy (NIRS) to measure cortical hemodynamic responses to 2 different video images of colorful mobile objects and black-and-white checkerboard pattern reversals over the occipital and prefrontal regions in awake 2-month-old infants. Both visual stimuli produced comparative activations over broad regions of the cortex including the early sensory and association regions, supporting the general-to-specific development (Hypothesis 3). This result suggests that functional cortical regions emerge between 2 and 3 months of age for visual perception.},
	author = {Watanabe, Hama and Homae, Fumitaka and Taga, Gentaro},
	doi = {10.1016/j.neuroimage.2010.01.068},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UH33P3VI/Watanabe et al. - 2010 - General to specific development of functional acti.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/I2ABAPP6/S105381191000090X.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Infant, functional differentiation, near-infrared spectroscopy (NIRS), Cortical development, Visual object processing},
	month = may,
	number = {4},
	pages = {1536--1544},
	title = {General to specific development of functional activation in the cerebral cortexes of 2- to 3-month-old infants},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191000090X},
	urldate = {2017-06-20},
	volume = {50},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191000090X},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2010.01.068}}

@article{karen_hemodynamic_2008,
	abstract = {Brain activity is associated with physiological changes, which alter the optical properties of tissue. These changes can be detected by near-infrared spectroscopy (NIRS). Aim of the study was to determine changes in cerebral oxygenation in response to stimulation in the visual cortex in newborn infants during spontaneous sleep in the first days of life. We used an in-house developed multichannel NIRS imaging instrument, the MCP-II, to measure changes in concentration of oxyhemoglobin (O2Hb) and deoxyhemoglobin (HHb) in specific brain areas. In 10 out of 15 subjects, a significant increase in O2Hb and/or a significant decrease in HHb were found in one or more channels over the occipital cortex. During stimulation, O2Hb increased by a mean of 0.98 μmol/l, HHb decreased by a mean 0.17 μmol/l, and total-Hb increased by a mean of 0.81 μmol/l. The hemodynamic response to visual stimulation in the occipital cortex in newborn infants is similar to adults. The increase in O2Hb and the simultaneous decrease in HHb during stimulation suggest an increase in cerebral blood flow (CBF) that overcompensates for the increased oxygen consumption (CMRO2) in the activated cortical area. Hum Brain Mapp, 2008. {\copyright} 2007 Wiley-Liss, Inc.},
	author = {Karen, Tanja and Morren, Geert and Haensse, Daniel and Bauschatz, Andrea S. and Bucher, Hans Ulrich and Wolf, Martin},
	doi = {10.1002/hbm.20411},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8SI4NIBB/Karen et al. - 2008 - Hemodynamic response to visual stimulation in newb.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZTT3J92I/abstract.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {Functional near-infrared spectroscopy, age dependence, behavioral state, visual stimulation, hemodynamic response, Infants},
	language = {en},
	month = apr,
	number = {4},
	pages = {453--460},
	title = {Hemodynamic response to visual stimulation in newborn infants using functional near-infrared spectroscopy},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20411/abstract},
	urldate = {2017-06-20},
	volume = {29},
	year = {2008},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20411/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.20411}}

@article{nakano_prefrontal_2009,
	author = {Nakano, Tamami and Watanabe, Hama and Homae, Fumitaka and Taga, Gentaro},
	doi = {10.1093/cercor/bhn096},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RVCT9FBI/Nakano et al. - 2009 - Prefrontal Cortical Involvement in Young Infants' .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S9Q7PJ7V/bhn096.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = feb,
	number = {2},
	pages = {455--463},
	title = {Prefrontal {Cortical} {Involvement} in {Young} {Infants}' {Analysis} of {Novelty}},
	url = {https://academic.oup.com/cercor/article/19/2/455/345396/Prefrontal-Cortical-Involvement-in-Young-Infants},
	urldate = {2017-07-04},
	volume = {19},
	year = {2009},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/19/2/455/345396/Prefrontal-Cortical-Involvement-in-Young-Infants},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhn096}}

@article{issard_adult-like_2017,
	abstract = {Humans can adapt to a wide range of variations in the speech signal, maintaining an invariant representation of the linguistic information it contains. Among them, adaptation to rapid or time-compressed speech has been well studied in adults, but the developmental origin of this capacity remains unknown. Does this ability depend on experience with speech (if yes, as heard in utero or as heard postnatally), with sounds in general or is it experience-independent? Using near-infrared spectroscopy, we show that the newborn brain can discriminate between three different compression rates: normal, i.e. 100\% of the original duration, moderately compressed, i.e. 60\% of original duration and highly compressed, i.e. 30\% of original duration. Even more interestingly, responses to normal and moderately compressed speech are similar, showing a canonical hemodynamic response in the left temporoparietal, right frontal and right temporal cortex, while responses to highly compressed speech are inverted, showing a decrease in oxyhemoglobin concentration. These results mirror those found in adults, who readily adapt to moderately compressed, but not to highly compressed speech, showing that adaptation to time-compressed speech requires little or no experience with speech, and happens at an auditory, and not at a more abstract linguistic level.},
	author = {Issard, C{\'e}cile and Gervain, Judit},
	copyright = {All rights reserved},
	doi = {10.1016/j.dcn.2016.10.006},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GH273QGZ/IssardGervain16.pdf:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Newborn infants, Temporal envelope, Time-compressed speech, near-infrared spectroscopy (NIRS), prosody},
	month = jun,
	pages = {176--184},
	series = {Sensitive periods across development},
	shorttitle = {Adult-like processing of time-compressed speech by newborns},
	title = {Adult-like processing of time-compressed speech by newborns: {A} {NIRS} study},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929316300469},
	urldate = {2017-07-04},
	volume = {25},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316300469},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2016.10.006}}

@article{kozberg_rapid_2016,
	abstract = {In the adult brain, increases in neural activity lead to increases in local blood flow. However, many prior measurements of functional hemodynamics in the neonatal brain, including functional magnetic resonance imaging (fMRI) in human infants, have noted altered and even inverted hemodynamic responses to stimuli. Here, we demonstrate that localized neural activity in early postnatal mice does not evoke blood flow increases as in the adult brain, and elucidate the neural and metabolic correlates of these altered functional hemodynamics as a function of developmental age. Using wide-field GCaMP imaging, the development of neural responses to somatosensory stimulus is visualized over the entire bilaterally exposed cortex. Neural responses are observed to progress from tightly localized, unilateral maps to bilateral responses as interhemispheric connectivity becomes established. Simultaneous hemodynamic imaging confirms that spatiotemporally coupled functional hyperemia is not present during these early stages of postnatal brain development, and develops gradually as cortical connectivity is established. Exploring the consequences of this lack of functional hyperemia, measurements of oxidative metabolism via flavoprotein fluorescence suggest that neural activity depletes local oxygen to below baseline levels at early developmental stages. Analysis of hemoglobin oxygenation dynamics at the same age confirms oxygen depletion for both stimulus-evoked and resting-state neural activity. This state of unmet metabolic demand during neural network development poses new questions about the mechanisms of neurovascular development and its role in both normal and abnormal brain development. These results also provide important insights for the interpretation of fMRI studies of the developing brain.
SIGNIFICANCE STATEMENT This work demonstrates that the postnatal development of neuronal connectivity is accompanied by development of the mechanisms that regulate local blood flow in response to neural activity. Novel in vivo imaging reveals that, in the developing mouse brain, strong and localized GCaMP neural responses to stimulus fail to evoke local blood flow increases, leading to a state in which oxygen levels become locally depleted. These results demonstrate that the development of cortical connectivity occurs in an environment of altered energy availability that itself may play a role in shaping normal brain development. These findings have important implications for understanding the pathophysiology of abnormal developmental trajectories, and for the interpretation of functional magnetic resonance imaging data acquired in the developing brain.},
	author = {Kozberg, Mariel G. and Ma, Ying and Shaik, Mohammed A. and Kim, Sharon H. and Hillman, Elizabeth M. C.},
	copyright = {Copyright {\copyright} 2016 the authors 0270-6474/16/366704-14\$15.00/0},
	doi = {10.1523/JNEUROSCI.2363-15.2016},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/U2VV839R/Kozberg et al. - 2016 - Rapid Postnatal Expansion of Neural Networks Occur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MW8K2PUE/6704.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {Oxygen Consumption, Neurovascular coupling, fMRI, GCaMP imaging, flavoprotein fluorescence, functional hyperemia, postnatal neural development},
	language = {en},
	month = jun,
	number = {25},
	pages = {6704--6717},
	pmid = {27335402},
	title = {Rapid {Postnatal} {Expansion} of {Neural} {Networks} {Occurs} in an {Environment} of {Altered} {Neurovascular} and {Neurometabolic} {Coupling}},
	url = {http://www.jneurosci.org/content/36/25/6704},
	urldate = {2017-06-30},
	volume = {36},
	year = {2016},
	bdsk-url-1 = {http://www.jneurosci.org/content/36/25/6704},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2363-15.2016}}

@article{schacter_reductions_2007,
	abstract = {Priming is a nonconscious form of memory in which an encounter with a stimulus influences the subsequent identification, production or classification of the same or a related stimulus. Neuroimaging studies have revealed that behavioral priming is typically accompanied by reduced activity in several cortical regions. We review recent studies that have concerned two key issues. First, specificity effects produced by changes between study and test in either the physical features of stimuli or the behavioral response reveal cortical sensitivity to the perceptual, conceptual and stimulus-to-decision mapping properties of primed items. Second, correlations between behavioral priming and activity reductions are robust across a range of tasks and procedures in prefrontal regions but not in posterior regions. On the basis of these recent studies, we suggest that the reduction in cortical activity during priming involves at least two different mechanisms.},
	author = {Schacter, Daniel L and Wig, Gagan S and Stevens, W Dale},
	doi = {10.1016/j.conb.2007.02.001},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3WP5RX4C/S0959438807000256.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = apr,
	number = {2},
	pages = {171--176},
	series = {Cognitive neuroscience},
	title = {Reductions in cortical activity during priming},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438807000256},
	urldate = {2017-07-04},
	volume = {17},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438807000256},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2007.02.001}}

@article{liao_neonatal_2010,
	abstract = {The neurodevelopmental outcome of neonatal intensive care unit (NICU) infants is a major clinical concern with many infants displaying neurobehavioral deficits in childhood. Functional neuroimaging may provide early recognition of neural deficits in high-risk infants. Near-infrared spectroscopy (NIRS) has the advantage of providing functional neuroimaging in infants at the bedside. However, limitations in traditional NIRS have included contamination from superficial vascular dynamics in the scalp. Furthermore, controversy exists over the nature of normal vascular, responses in infants. To address these issues, we extend the use of novel high-density NIRS arrays with multiple source-detector distances and a superficial signal regression technique to infants. Evaluations of healthy term-born infants within the first three days of life are performed without sedation using a visual stimulus. We find that the regression technique significantly improves brain activation signal quality. Furthermore, in six out of eight infants, both oxy- and total hemoglobin increases while deoxyhemoglobin decreases, suggesting that, at term, the neurovascular coupling in the visual cortex is similar to that found in healthy adults. These results demonstrate the feasibility of using high-density NIRS arrays in infants to improve signal quality through superficial signal regression, and provide a foundation for further development of high-density NIRS as a clinical tool.},
	author = {Liao, Steve M. and Gregg, Nick M. and White, Brian R. and Zeff, Benjamin W. and Bjerkaas, Katelin A. and Inder, Terrie E. and Culver, Joseph P.},
	doi = {10.1117/1.3369809},
	issn = {1083-3668},
	journal = {Journal of Biomedical Optics},
	number = {2},
	pages = {026010--026010--9},
	shorttitle = {Neonatal hemodynamic response to visual cortex activity},
	title = {Neonatal hemodynamic response to visual cortex activity: high-density near-infrared spectroscopy study},
	url = {http://dx.doi.org/10.1117/1.3369809},
	urldate = {2017-06-20},
	volume = {15},
	year = {2010},
	bdsk-url-1 = {http://dx.doi.org/10.1117/1.3369809}}

@article{taga_hemodynamic_2003,
	abstract = {A near-infrared optical topography (OT) was used to reveal spatio-temporal changes in the cerebral oxygenation of newborn infants in response to brief visual stimulation. Newborn infants were presented 3-s stroboscopic light flashing at 14 Hz during spontaneous sleep. Event-related changes in oxy- and deoxyhemoglobin ([oxy-Hb] and [deoxy-Hb]) were observed over the occipital and frontal cortex. The visual stimulus produced statistically significant increases in oxyhemoglobin not only in the occipital cortex but also in the prefrontal cortex. These results suggest that the cerebrovascular coupling is already functioning in newborn's brain. The prefrontal activation implies that it may contribute to early processing of sensory signals.},
	author = {Taga, Gentaro and Asakawa, Kayo and Hirasawa, Kyoko and Konishi, Yukuo},
	doi = {10.1016/j.earlhumdev.2003.08.023},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KX8C47BM/S0378378203001324.html:text/html},
	issn = {0378-3782},
	journal = {Early Human Development},
	keywords = {Hemodynamics, brain imaging, Optical topography, Near-infrared spectroscopy, Newborn},
	month = dec,
	pages = {203--210},
	shorttitle = {Hemodynamic responses to visual stimulation in occipital and frontal cortex of newborn infants},
	title = {Hemodynamic responses to visual stimulation in occipital and frontal cortex of newborn infants: a near-infrared optical topography study},
	url = {http://www.sciencedirect.com/science/article/pii/S0378378203001324},
	urldate = {2017-06-20},
	volume = {75},
	year = {2003},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378378203001324},
	bdsk-url-2 = {https://doi.org/10.1016/j.earlhumdev.2003.08.023}}

@article{novitski_neonatal_2007,
	abstract = {The precision of sound frequency discrimination in newborn infants in the 250--4000-Hz frequency range was determined using the neonatal electrophysiological mismatch response (MMR), the infant equivalent of adult mismatch negativity (MMN). The electroencephalogram (EEG) was recorded in 11 full-term sleeping newborn infants mostly in active sleep (67\% of the time). Pure tones were presented through loudspeakers in an oddball paradigm with a 800-ms stimulus onset asynchrony (SOA). Each stimulus block contained a standard (p=0.76) of 250, 1000, or 4000Hz in frequency (in separate blocks) and deviants with a frequency change of either 5\% or 20\% of the standard (p=0.12 of each). A positive ERP deflection was found at 200--300ms from stimulus onset in response to the 20\% deviation from the 250, 1000, and 4000Hz standard frequencies. The amplitude of the response in the 200--300ms time window was significantly larger for the 20\% than 5\% deviation. We observed in newborn infants automatic frequency discrimination as reflected by a positive MMR. The newborns were able to discriminate frequency change of 20\% in the 250--4000-Hz frequency range, whereas the discrimination of the 5\% frequency change was not statistically confirmed. The present data hence suggest that the neonatal frequency discrimination has lower resolution than that in adult and older children data.},
	author = {Novitski, Nikolai and Huotilainen, Minna and Tervaniemi, Mari and N{\"a}{\"a}t{\"a}nen, Risto and Fellman, Vineta},
	doi = {10.1016/j.clinph.2006.10.008},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EAWBIRKC/S1388245706014787.html:text/html},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology},
	keywords = {Newborn infants, Frequency discrimination, MMN},
	month = feb,
	number = {2},
	pages = {412--419},
	shorttitle = {Neonatal frequency discrimination in 250--4000-{Hz} range},
	title = {Neonatal frequency discrimination in 250--4000-{Hz} range: {Electrophysiological} evidence},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245706014787},
	urldate = {2017-06-27},
	volume = {118},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245706014787},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2006.10.008}}

@article{nakato_when_2009,
	abstract = {The objective of the present study was to determine whether a developmental difference occurs in brain activity when infants look at frontal and profile views using near-infrared spectroscopy (NIRS), which is an optical imaging technique used to measure changes in the concentrations of oxyhemoglobin (oxy-Hb), deoxyhemoglobin (deoxy-Hb), and total hemoglobin (total-Hb). For this objective, we compared NIRS results in two age groups, 5- and 8-month-old infants, while they were looking at frontal views, profile views, and objects. We found that the concentration of oxy-Hb and total-Hb in the 5-month-old group increased for only frontal views in the right temporal regions. In contrast, the concentration of oxy-Hb and total-Hb in the 8-month-old group increased for both frontal and profile views in the right temporal regions. Therefore, the present study indicated that the right hemisphere was dominant for the perception of profile views as well as frontal views. In addition, the most important and interesting finding was that the infants' brain activity of the face area would become view-invariant at the age of 8 months but not at 5 months. The developmental period for view-invariant face recognition has been discussed in previous psychological studies, but this is the first objective study to confirm that the period is between 5- and 8-months by measuring the blood flow in the brain using NIRS. Hum Brain Mapp, 2009. {\copyright} 2007 Wiley-Liss, Inc.},
	author = {Nakato, Emi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Watanabe, Shoko and Kakigi, Ryusuke},
	doi = {10.1002/hbm.20516},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KV8ITRPD/Nakato et al. - 2009 - When do infants differentiate profile face from fr.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DR4WVQBD/abstract.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {near infrared spectroscopy, developmental changes, face perception, right hemisphere, Infants},
	language = {en},
	month = feb,
	number = {2},
	pages = {462--472},
	shorttitle = {When do infants differentiate profile face from frontal face?},
	title = {When do infants differentiate profile face from frontal face? {A} near-infrared spectroscopic study},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20516/abstract},
	urldate = {2017-06-20},
	volume = {30},
	year = {2009},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20516/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.20516}}

@article{taga_selectivity_2007,
	abstract = {To better understand the development of multimodal perception, we examined selectivity and localization of cortical responses to auditory and visual stimuli in young infants. Near-infrared optical topography with 24 channels was used to measure event-related cerebral oxygenation changes of the bilateral temporal cortex in 15 infants aged 2 to 4 months, when they were exposed to speech sounds lasting 3 s and checkerboard pattern reversals lasting 3 s, which were asynchronously presented with different alternating intervals. Group analysis revealed focal increases in oxy-hemoglobin and decreases in deoxy-hemoglobin in both hemispheres in response to auditory, but not to visual, stimulation. These results indicate that localized areas of the primary auditory cortex and the auditory association cortex are involved in auditory perception in infants as young as 2 months of age. In contrast to the hypothesis that perception of distinct sensory modalities may not be separated due to cross talk over the immature cortex in young infants, the present study suggests that unrelated visual events do not influence on the auditory perception of awake infants.},
	author = {Taga, Gentaro and Asakawa, Kayo},
	doi = {10.1016/j.neuroimage.2007.04.037},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JK7Z68FP/S1053811907002832.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = jul,
	number = {4},
	pages = {1246--1252},
	title = {Selectivity and localization of cortical response to auditory and visual stimulation in awake infants aged 2 to 4 months},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811907002832},
	urldate = {2017-06-23},
	volume = {36},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811907002832},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2007.04.037}}

@article{allievi_maturation_2016,
	author = {Allievi, Alessandro G. and Arichi, Tomoki and Tusor, Nora and Kimpton, Jessica and Arulkumaran, Sophie and Counsell, Serena J. and Edwards, A. David and Burdet, Etienne},
	doi = {10.1093/cercor/bhv203},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9SDFXH77/Allievi et al. - 2016 - Maturation of Sensori-Motor Functional Responses i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M5R3EUKW/Maturation-of-Sensori-Motor-Functional-Responses.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = jan,
	number = {1},
	pages = {402--413},
	title = {Maturation of {Sensori}-{Motor} {Functional} {Responses} in the {Preterm} {Brain}},
	url = {https://academic.oup.com/cercor/article/26/1/402/2367359/Maturation-of-Sensori-Motor-Functional-Responses},
	urldate = {2017-06-27},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/26/1/402/2367359/Maturation-of-Sensori-Motor-Functional-Responses},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhv203}}

@article{eggebrecht_quantitative_2012,
	abstract = {Functional neuroimaging commands a dominant role in current neuroscience research. However its use in bedside clinical and certain neuro-scientific studies has been limited because the current tools lack the combination of being non-invasive, non-ionizing and portable while maintaining moderate resolution and localization accuracy. Optical neuroimaging satisfies many of these requirements, but, until recent advances in high-density diffuse optical tomography (HD-DOT), has been hampered by limited resolution. While early results of HD-DOT have been promising, a quantitative voxel-wise comparison and validation of HD-DOT against the gold standard of functional magnetic resonance imaging (fMRI) has been lacking. Herein, we provide such an analysis within the visual cortex using matched visual stimulation protocols in a single group of subjects (n = 5) during separate HD-DOT and fMRI scanning sessions. To attain the needed voxel-to-voxel co-registration between HD-DOT and fMRI image spaces, we implemented subject-specific head modeling that incorporated MRI anatomy, detailed segmentation, and alignment of source and detector positions. Comparisons of the visual responses found an average localization error between HD-DOT and fMRI of 4.4 +/− 1 mm, significantly less than the average distance between cortical gyri. This specificity demonstrates that HD-DOT has sufficient image quality to be useful as a surrogate for fMRI.},
	author = {Eggebrecht, Adam T. and White, Brian R. and Ferradal, Silvina L. and Chen, Chunxiao and Zhan, Yuxuan and Snyder, Abraham Z. and Dehghani, Hamid and Culver, Joseph P.},
	doi = {10.1016/j.neuroimage.2012.01.124},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/K8GXGZHE/Eggebrecht et al. - 2012 - A quantitative spatial comparison of high-density .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3E6CW7FI/S1053811912001516.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Functional Neuroimaging, Cortex, Human, Mapping, Optical tomography},
	month = jul,
	number = {4},
	pages = {1120--1128},
	title = {A quantitative spatial comparison of high-density diffuse optical tomography and {fMRI} cortical mapping},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912001516},
	urldate = {2017-06-20},
	volume = {61},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912001516},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.124}}

@article{okubo_hemodynamic_2002,
	abstract = {This is the first report on the use of near-infrared topography (NIRT) for functional imaging of the visual cortex of newborn infants during photic stimulation (PS) under the condition of natural sleep. Measurements were conducted in four healthy term neonates within 1 week after birth. NIRT was performed on the occipital region of the head using a device consisting of 16 optical fibers, 8 for transmission and 8 for detection, and 24-measuring points were determined. Baseline data were collected over a period of 10 s. PS was produced by flashing lights (laser-emitting diodes) at 8 Hz and lasting for 15 s, followed by a 45-s rest period. Data were collected every 0.1 s, averaged over 10 cycles, and smoothed. As control data, hemodynamic changes in all neonates without stimulation were measured by the same method. PS caused marked increases from the baseline values in oxyhemoglobin ([HbO2]) and total hemoglobin ([T-Hb]) and a decrease in deoxyhemoglobin ([Hb]) in the primary visual areas of all neonates. We conclude that our method is useful for imaging and evaluating the primary visual area function in response to PS even in newborn infants during natural sleep.},
	author = {Okubo, Kensuke and Kusaka, Takashi and Isobe, Kenichi and Nagano, Keiko and Kawada, Kou and Namba, Masanori and Imai, Tadashi and Itoh, Susumu and Onishi, Shoju},
	doi = {10.1016/S0531-5131(01)00813-5},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/K85GIEPM/S0531513101008135.html:text/html},
	issn = {0531-5131},
	journal = {International Congress Series},
	keywords = {Newborn infants, Photic Stimulation, Multichannel near-infrared spectroscopy, Primary visual cortex},
	month = apr,
	pages = {593--597},
	series = {Recent advances in human brain mapping},
	title = {Hemodynamic changes in the neonatal visual cortex by using near-infrared topography},
	url = {http://www.sciencedirect.com/science/article/pii/S0531513101008135},
	urldate = {2017-06-20},
	volume = {1232},
	year = {2002},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0531513101008135},
	bdsk-url-2 = {https://doi.org/10.1016/S0531-5131(01)00813-5}}

@article{boas_improving_2004,
	abstract = {We compare two geometries of sources and detectors for optimizing the diffuse optical imaging resolution of brain activation in humans. Because of limitations in the instruments' dynamic range, most diffuse optical brain activation images have used only nonoverlapping measurements. We demonstrate theoretically and with a human experiment that a simple geometry of sources and detectors can provide overlapping measurements within the limitation of instrumentation dynamic range and produce an image resolution and localization accuracy that is twofold better.},
	author = {Boas, D. A. and Chen, K. and Grebert, D. and Franceschini, M. A.},
	copyright = {{\copyright} 2004 Optical Society of America},
	doi = {10.1364/OL.29.001506},
	file = {Boas_OptLett_29_1506_2004.pdf:/Users/Cecile/Zotero/storage/97NXQK4V/Boas_OptLett_29_1506_2004.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TWG78HXV/abstract.html:text/html},
	issn = {1539-4794},
	journal = {Optics Letters},
	keywords = {Image reconstruction techniques, Photon migration, Tomography},
	language = {EN},
	month = jul,
	number = {13},
	pages = {1506--1508},
	title = {Improving the diffuse optical imaging spatial resolution of the cerebral hemodynamic response to brain activation in humans},
	url = {https://www.osapublishing.org/abstract.cfm?uri=ol-29-13-1506},
	urldate = {2017-06-20},
	volume = {29},
	year = {2004},
	bdsk-url-1 = {https://www.osapublishing.org/abstract.cfm?uri=ol-29-13-1506},
	bdsk-url-2 = {https://doi.org/10.1364/OL.29.001506}}

@article{sato_cerebral_2012,
	abstract = {Considerable knowledge on neural development related to speech perception has been obtained by functional imaging studies using near-infrared spectroscopy (optical topography). In particular, a pioneering study showed stronger left-dominant activation in the temporal lobe for (normal) forward speech (FW) than for (reversed) backward speech (BW) in neonates. However, it is unclear whether this stronger left-dominant activation for FW is equally observed for any language or is clearer for the mother tongue. We hypothesized that the maternal language elicits clearer activation than a foreign language in newborns because of their prenatal and/or few-day postnatal exposure to the maternal language. To test this hypothesis, we developed a whole-head optode cap for 72-channel optical topography and visualized the spatiotemporal hemodynamics in the brains of 17 Japanese newborns when they were exposed to FW and BW in their maternal language (Japanese) and in a foreign language (English). Statistical analysis showed that all sound stimuli together induced significant activation in the bilateral temporal regions and the frontal region. They also showed that the left temporal-parietal region was significantly more active for Japanese FW than Japanese BW or English FW, while no significant difference between FW and BW was shown for English. This supports our hypothesis and suggests that the few-day-old brain begins to become attuned to the maternal language. Together with a finding of equivalent activation for all sound stimuli in the adjacent measurement positions in the temporal region, these findings further clarify the functional organization of the neonatal brain. Hum Brain Mapp 33:2092--2103, 2012. {\copyright} 2011 Wiley Periodicals, Inc.},
	author = {Sato, Hiroki and Hirabayashi, Yukiko and Tsubokura, Hifumi and Kanai, Makoto and Ashida, Takashi and Konishi, Ikuo and Uchida-Ota, Mariko and Konishi, Yukuo and Maki, Atsushi},
	doi = {10.1002/hbm.21350},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ZQQC2H2S/Sato et al. - 2012 - Cerebral hemodynamics in newborn infants exposed t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CJVRI8Q8/abstract.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {language acquisition, near-infrared spectroscopy (NIRS), neonates, speech perception, Auditory cortex, Speech Perception},
	language = {en},
	month = sep,
	number = {9},
	pages = {2092--2103},
	shorttitle = {Cerebral hemodynamics in newborn infants exposed to speech sounds},
	title = {Cerebral hemodynamics in newborn infants exposed to speech sounds: {A} whole-head optical topography study},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21350/abstract},
	urldate = {2017-07-18},
	volume = {33},
	year = {2012},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21350/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.21350}}

@article{cristia_neural_2014,
	abstract = {The present study investigated the neural correlates of infant discrimination of very similar linguistic varieties (Quebecois and Parisian French) using functional Near InfraRed Spectroscopy. In line with previous behavioral and electrophysiological data, there was no evidence that 3-month-olds discriminated the two regional accents, whereas 5-month-olds did, with the locus of discrimination in left anterior perisylvian regions. These neuroimaging results suggest that a developing language network relying crucially on left perisylvian cortices sustains infants' discrimination of similar linguistic varieties within this early period of infancy.},
	author = {Cristia, Alejandrina and Minagawa-Kawai, Yasuyo and Egorova, Natalia and Gervain, Judit and Filippin, Luca and Cabrol, Dominique and Dupoux, Emmanuel},
	doi = {10.1111/desc.12160},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PWTUQCGG/Cristia et al. - 2014 - Neural correlates of infant accent discrimination.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/97UZ5WCD/abstract.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = jul,
	number = {4},
	pages = {628--635},
	shorttitle = {Neural correlates of infant accent discrimination},
	title = {Neural correlates of infant accent discrimination: an {fNIRS} study},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12160/abstract},
	urldate = {2017-07-24},
	volume = {17},
	year = {2014},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12160/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12160}}

@article{naccache_priming_2001,
	abstract = {Most of the current brain imaging methods are limited by the low spatial resolution of neuroimaging techniques and remain unable to measure activity at the scale of single neurons or small columns of neurons, which are the coding elements of the nervous system. In this work we have adapted the priming method, an emerging research strategy that can overcome some of these spatial limitations, to investigate the coding of numerical quantities in the human brain. This approach combines the logic of psychological priming experiments with the recently discovered neurophysiological phenomenon called repetition suppression (RS). In each trial, while subjects perform a constant task, a subliminal prime is presented prior to each target. By varying the relationship between prime and target, one can detect which brain areas present RS specifically for any given level of prime--target repetition. We first expose the general logic, potential and limitations of the priming method and then illustrate it by demonstrating that a region of parietal cortex is coding for numbers at the quantity level, independently of other stimulus attributes, and that this region processes both consciously and unconsciously perceived stimuli.},
	author = {Naccache, Lionel and Dehaene, Stanislas},
	doi = {10.1093/cercor/11.10.966},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UPC2WFQ6/Naccache et Dehaene - 2001 - The Priming Method Imaging Unconscious Repetition.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DDSEDPSM/The-Priming-Method-Imaging-Unconscious-Repetition.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	month = oct,
	number = {10},
	pages = {966--974},
	shorttitle = {The {Priming} {Method}},
	title = {The {Priming} {Method}: {Imaging} {Unconscious} {Repetition} {Priming} {Reveals} an {Abstract} {Representation} of {Number} in the {Parietal} {Lobes}},
	url = {https://academic.oup.com/cercor/article/11/10/966/280031/The-Priming-Method-Imaging-Unconscious-Repetition},
	urldate = {2017-07-19},
	volume = {11},
	year = {2001},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/11/10/966/280031/The-Priming-Method-Imaging-Unconscious-Repetition},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/11.10.966}}

@article{kotilahti_hemodynamic_2010,
	abstract = {We used near-infrared spectroscopy (NIRS) to study responses to speech and music on the auditory cortices of 13 healthy full-term newborn infants during natural sleep. The purpose of the study was to investigate the lateralization of speech and music responses at this stage of development. NIRS data was recorded from eight positions on both hemispheres simultaneously with electroencephalography, electrooculography, electrocardiography, pulse oximetry, and inclinometry. In 11 subjects, statistically significant (P {\textless} 0.02) oxygenated (HbO2) and total hemoglobin (HbT) responses were recorded. Both stimulus types elicited significant HbO2 and HbT responses on both hemispheres in five subjects. Six of the 11 subjects had positive HbO2 and HbT responses to both stimulus types, whereas one subject had negative responses. Mixed positive and negative responses were observed in four neonates. On both hemispheres, speech and music responses were significantly correlated (r = 0.64; P = 0.018 on the left hemisphere (LH) and r = 0.60; P = 0.029 on the right hemisphere (RH)). On the group level, the average response to the speech stimuli was statistically significantly greater than zero in the LH, whereas responses on the RH or to the music stimuli did not differ significantly from zero. This suggests a more coherent response to speech on the LH. However, significant differences in lateralization of the responses or mean response amplitudes of the two stimulus types were not observed on the group level. Hum Brain Mapp, 2010. {\copyright} 2009 Wiley-Liss, Inc.},
	author = {Kotilahti, Kalle and Nissil{\"a}, Ilkka and N{\"a}si, Tiina and Lipi{\"a}inen, Lauri and Noponen, Tommi and Meril{\"a}inen, Pekka and Huotilainen, Minna and Fellman, Vineta},
	doi = {10.1002/hbm.20890},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PSAF5ZZG/Kotilahti et al. - 2010 - Hemodynamic responses to speech and music in newbo.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/C56763FG/abstract.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {Functional Laterality, brain imaging, Neonate, auditory responses, Near-infrared spectroscopy},
	language = {en},
	month = apr,
	number = {4},
	pages = {595--603},
	title = {Hemodynamic responses to speech and music in newborn infants},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20890/abstract},
	urldate = {2017-07-24},
	volume = {31},
	year = {2010},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20890/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.20890}}

@article{okada_near-infrared_2003,
	abstract = {It is important for near-infrared spectroscopy (NIRS) and imaging to estimate the sensitivity of the detected signal to the change in hemoglobin that results from brain activation and the volume of tissue interrogated for a specific source-detector fiber spacing. In this study light propagation in adult head models is predicted by Monte Carlo simulation to investigate the effect of the superficial tissue thickness on the partial optical path length in the brain and on the spatial sensitivity profile. In the case of source-detector spacing of 30 mm, the partial optical path length depends mainly on the depth of the inner skull surface whereas the spatial sensitivity profile is significantly affected by the thickness of the cerebrospinal fluid layer. The mean optical path length that can be measured by time-resolved experiments increases when the skull thickness increases whereas the partial mean optical path length in the brain decreases when the skull thickness increases. These results indicate that it is not appropriate to use the mean optical path length as an alternative to the partial optical path length to compensate the NIRS signal for the difference in sensitivity caused by variation of the superficial tissue thickness.},
	author = {Okada, Eiji and Delpy, David T.},
	issn = {0003-6935},
	journal = {Applied Optics},
	keywords = {Adult, Head, Humans, Spectroscopy, Near-Infrared, Cerebrospinal Fluid, Models, Anatomic, Monte Carlo Method, Sensitivity and Specificity, Skull},
	language = {eng},
	month = jun,
	number = {16},
	pages = {2915--2922},
	pmid = {12790440},
	title = {Near-infrared light propagation in an adult head model. {II}. {Effect} of superficial tissue thickness on the sensitivity of the near-infrared spectroscopy signal},
	volume = {42},
	year = {2003}}

@article{okada_near-infrared_2003-1,
	abstract = {Adequate modeling of light propagation in a human head is important for quantitative near-infrared spectroscopy and optical imaging. The presence of a nonscattering cerebrospinal fluid (CSF) that surrounds the brain has been previously shown to have a strong effect on light propagation in the head. However, in reality, a small amount of scattering is caused by the arachnoid trabeculae in the CSF layer. In this study, light propagation in an adult head model with discrete scatterers distributed within the CSF layer has been predicted by Monte Carlo simulation to investigate the effect of the small amount of scattering caused by the arachnoid trabeculae in the CSF layer. This low scattering in the CSF layer is found to have little effect on the mean optical path length, a parameter that can be directly measured by a time-resolved experiment. However, the partial optical path length in brain tissue that relates the sensitivity of the detected signal to absorption changes in the brain is strongly affected by the presence of scattering within the CSF layer. The sensitivity of the near-infrared signal to hemoglobin changes induced by brain activation is improved by the effect of a low-scattering CSF layer.},
	author = {Okada, Eiji and Delpy, David T.},
	issn = {0003-6935},
	journal = {Applied Optics},
	keywords = {Adult, Head, Humans, Spectroscopy, Near-Infrared, Cerebrospinal Fluid, Models, Anatomic, Monte Carlo Method, Models, Theoretical, Scattering, Radiation, Brain},
	language = {eng},
	month = jun,
	number = {16},
	pages = {2906--2914},
	pmid = {12790439},
	title = {Near-infrared light propagation in an adult head model. {I}. {Modeling} of low-level scattering in the cerebrospinal fluid layer},
	volume = {42},
	year = {2003}}

@article{benavides-varela_brain_2017,
	abstract = {Perception and cognition in infants have been traditionally investigated using habituation paradigms, assuming that babies' memories in laboratory contexts are best constructed after numerous repetitions of the very same stimulus in the absence of interference. A crucial, yet open, question regards how babies deal with stimuli experienced in a fashion similar to everyday learning situations-namely, in the presence of interfering stimuli. To address this question, we used functional near-infrared spectroscopy to test 40 healthy newborns on their ability to encode words presented in concomitance with other words. The results evidenced a habituation-like hemodynamic response during encoding in the left-frontal region, which was associated with a progressive decrement of the functional connections between this region and the left-temporal, right-temporal, and right-parietal regions. In a recognition test phase, a characteristic neural signature of recognition recruited first the right-frontal region and subsequently the right-parietal ones. Connections originating from the right-temporal regions to these areas emerged when newborns listened to the familiar word in the test phase. These findings suggest a neural specialization at birth characterized by the lateralization of memory functions: the interplay between temporal and left-frontal regions during encoding and between temporo-parietal and right-frontal regions during recognition of speech sounds. Most critically, the results show that newborns are capable of retaining the sound of specific words despite hearing other stimuli during encoding. Thus, habituation designs that include various items may be as effective for studying early memory as repeated presentation of a single word.},
	author = {Benavides-Varela, Silvia and Siugzdaite, Roma and G{\'o}mez, David Maximiliano and Macagno, Francesco and Cattarossi, Luigi and Mehler, Jacques},
	doi = {10.1073/pnas.1617589114},
	issn = {1091-6490},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	keywords = {Habituation, Memory, newborns, fNIRS effective connectivity, language},
	language = {eng},
	month = jul,
	number = {29},
	pages = {7588--7593},
	pmcid = {PMC5530644},
	pmid = {28674020},
	title = {Brain regions and functional interactions supporting early word recognition in the face of input variability},
	volume = {114},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1073/pnas.1617589114}}

@article{sakatani_cerebral_1999,
	abstract = {Recent neuronal activation studies on newborns using functional MRI or near infrared spectroscopy (NIRS) have suggested that the increase in O2 consumption accompanying neuronal activation exceeds the increase in O2 delivery in the visual cortex during photic stimulation. In the present study, we evaluated the cerebral blood oxygenation (CBO) changes induced by auditory stimulation in the frontal lobe of newborns using NIRS. We studied 28 newborns; the postnatal age at CBO measurements was 3.1+/-0.3 days (mean+/-S.E.M.). We measured concentration changes of deoxyhemoglobin (Deoxy-Hb), oxyhemoglobin (Oxy-Hb), and total hemoglobin (Total-Hb) induced by auditory (music) stimulation in the bilateral frontal lobes of the newborns. Twenty-six (92.9\%) out of 28 subjects showed increases of Oxy-Hb and Total-Hb during the stimulation. In these subjects, 17 (60.7\%) subjects showed an increase of Deoxy-Hb associated with increases of Oxy-Hb and Total-Hb, while nine (32.1\%) subjects showed a decrease of Deoxy-Hb. Although the direction of the Deoxy-Hb differed, these two groups did not differ for Oxy-Hb and Total-Hb (P {\textgreater} 0.05). Two (7.1\%) subjects showed other changes. The frontal lobe of newborns shows CBO responses similar to those observed in the visual cortex, specifically neuronal activation causes an increase of Deoxy-Hb associated with increases of Oxy-Hb and Total-Hb. These results support the hypothesis that increments in O2 consumption exceed increments in O2 delivery during neuronal activity in newborns.},
	author = {Sakatani, K. and Chen, S. and Lichty, W. and Zuo, H. and Wang, Y. P.},
	issn = {0378-3782},
	journal = {Early Human Development},
	keywords = {Acoustic Stimulation, Female, Frontal Lobe, Hemoglobins, Humans, Infant, Newborn, Male, Oxygen, Spectroscopy, Near-Infrared, Oxyhemoglobins, Brain},
	language = {eng},
	month = jul,
	number = {3},
	pages = {229--236},
	pmid = {10463787},
	title = {Cerebral blood oxygenation changes induced by auditory stimulation in newborn infants measured by near infrared spectroscopy},
	volume = {55},
	year = {1999}}

@article{spelke_core_2000,
	abstract = {Complex cognitive skills such as reading and calculation and complex cognitive achievements such as formal science and mathematics may depend on a set of building block systems that emerge early in human ontogeny and phylogeny. These core knowledge systems show characteristic limits of domain and task specificity: Each serves to represent a particular class of entities for a particular set of purposes. By combining representations from these systems, however human cognition may achieve extraordinary flexibility. Studies of cognition in human infants and in nonhuman primates therefore may contribute to understanding unique features of human knowledge. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Spelke, Elizabeth S.},
	doi = {10.1037/0003-066X.55.11.1233},
	file = {EBSCO Full Text:/Users/Cecile/Zotero/storage/USRT79TN/Spelke - 2000 - Core knowledge.pdf:application/pdf},
	issn = {0003-066X},
	journal = {American Psychologist},
	keywords = {Animals, Cognition, COGNITIVE development, Humans, Primates, Human Development, Mathematical Ability, Phylogeny, Problem Solving, Psychology, Child, Reading, Science Achievement, development of cognitive skills such as reading \& calculation \& cognitive achievements such as formal science \& mathematics},
	month = nov,
	number = {11},
	pages = {1233--1243},
	title = {Core knowledge},
	url = {http://frodon.univ-paris5.fr/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2000-14050-006&lang=fr&site=ehost-live},
	urldate = {2017-09-14},
	volume = {55},
	year = {2000},
	bdsk-url-1 = {http://frodon.univ-paris5.fr/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2000-14050-006&lang=fr&site=ehost-live},
	bdsk-url-2 = {https://doi.org/10.1037/0003-066X.55.11.1233}}

@phdthesis{cabrera_developpement_2013,
	author = {Cabrera, Laurianne},
	file = {Doctorale et al. - 2013 - spectro-te mporal modulation processing Behavioral studies in infants Th{\`e}se de Doctorat Laurianne Cabrera-annotated.pdf:/Users/Cecile/Zotero/storage/U6B4IM5N/Doctorale et al. - 2013 - spectro-te mporal modulation processing Behavioral studies in infants Th{\`e}se de Doctorat Laurianne Cabrera-annota.pdf:application/pdf},
	school = {Paris 5},
	shorttitle = {D{\'e}veloppement de la perception de la parole et du traitement auditif des modulations spectro-temporelles},
	title = {D{\'e}veloppement de la perception de la parole et du traitement auditif des modulations spectro-temporelles: {\'e}tudes comportementales chez le nourrisson},
	url = {http://www.theses.fr/2013PA05H112},
	urldate = {2017-09-25},
	year = {2013},
	bdsk-url-1 = {http://www.theses.fr/2013PA05H112}}

@incollection{saffran_infants_2007,
	abstract = {The focus of this chapter is on how infants perceive, process, and learn from their auditory environments. We focus on mechanism of hearing, speech perception, and early language learning, with the goal of elucidating recent progress in this field and its historical context. The literature reviewed includes studies of hearing development in young infants, the beginnings of speech perception and tuning to the native language, word segmentation, word learning, phonological acquisition, and the early stages of language acquisition. Throughout, we focus on current controversies along with theoretical and methodological innovations.},
	author = {Saffran, Jenny R. and Werker, Janet F. and Werner, Lynne A.},
	booktitle = {Handbook of {Child} {Psychology}},
	copyright = {Copyright {\copyright} 2006 John Wiley \& Sons, Inc. All rights reserved.},
	doi = {10.1002/9780470147658.chpsy0202},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/N2E3R49C/Saffran et al. - 2007 - The Infant's Auditory World Hearing, Speech, and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CWFUDADS/abstract.html:text/html},
	isbn = {978-0-470-14765-8},
	keywords = {Hearing, Speech, Words, Infants, language},
	language = {en},
	publisher = {John Wiley \& Sons, Inc.},
	shorttitle = {The {Infant}'s {Auditory} {World}},
	title = {The {Infant}'s {Auditory} {World}: {Hearing}, {Speech}, and the {Beginnings} of {Language}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470147658.chpsy0202/abstract},
	urldate = {2017-09-25},
	year = {2007},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/9780470147658.chpsy0202/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/9780470147658.chpsy0202}}

@article{spelke_initial_1994,
	abstract = {Although debates continue, studies of cognition in infancy suggest that knowledge begins to emerge early in life and constitutes part of humans' innate endowment. Early-developing knowledge appears to be both domain-specific and task-specific, it appears to capture fundamental constraints on ecologically important classes of entities in the child's environment, and it appears to remain central to the commonsense knowledge systems of adults.},
	author = {Spelke, Elizabeth S.},
	doi = {10.1016/0010-0277(94)90039-6},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/K2VCZBGA/0010027794900396.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	month = apr,
	number = {1},
	pages = {431--445},
	shorttitle = {Initial knowledge},
	title = {Initial knowledge: six suggestions},
	url = {http://www.sciencedirect.com/science/article/pii/0010027794900396},
	volume = {50},
	year = {1994},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0010027794900396},
	bdsk-url-2 = {https://doi.org/10.1016/0010-0277(94)90039-6}}

@article{birnholz_development_1983,
	abstract = {Blink-startle responses to vibroacoustic stimulation were monitored ultrasonically in human fetuses of known gestational age. Responses were first elicited between 24 and 25 weeks of gestational age and were present consistently after 28 weeks. Defining the developmental sequence for audition provides a foundation for diagnosing deafness and recognizing aberrant responses antenatally.},
	author = {Birnholz, J. C. and Benacerraf, B. R.},
	copyright = {{\copyright} 1983},
	doi = {10.1126/science.6623091},
	file = {Snapshot:/Users/Cecile/Zotero/storage/R3UNFG9R/516.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = nov,
	number = {4623},
	pages = {516--518},
	pmid = {6623091},
	title = {The development of human fetal hearing},
	url = {http://science.sciencemag.org/content/222/4623/516},
	urldate = {2017-10-06},
	volume = {222},
	year = {1983},
	bdsk-url-1 = {http://science.sciencemag.org/content/222/4623/516},
	bdsk-url-2 = {https://doi.org/10.1126/science.6623091}}

@article{lecanuet_fetal_1988,
	abstract = {Accelerative and decelerative cardiac responses and motor responses (leg movements) of 37--40 weeks (G.A.) fetuses are analyzed as a function of the frequency of three octave-band noises (respectively centered at 500 Hz, 2000 Hz and 5000 Hz) and of their intensity level (100, 105, 110 dB SPL, ex utero), during high (HV) and low (LV) heart rate (HR) variability pattern states. In both states, increasing the frequency and/or the intensity of the acoustic stimulation: (i) increases the ratios and amplitudes of accelerations, and the motor response ratios, (ii) reduces deceleration ratios and motor response latencies. Cardiac and motor reactiveness are higher in HV than in LV with acceleration ratios always greater than motor ones. However, when a high intensity and/or frequency is used, the reactiveness differences between states disappears. Low intensity and/or frequency stimulation levels induce a majority of decelerations.},
	author = {Lecanuet, J-P. and Granier-Deferre, C. and Busnel, M-C.},
	doi = {10.1016/0378-3782(88)90045-X},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/WS35G56Z/Lecanuet et al. - 1988 - Fetal cardiac and motor responses to octave-band n.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/N2R394A2/037837828890045X.html:text/html},
	issn = {0378-3782},
	journal = {Early Human Development},
	keywords = {Fetus, acoustical stimulation, cardiac acceleration, cardiac deceleration, frequency, heart rate variability pattern, intensity, motor response},
	month = dec,
	number = {2},
	pages = {81--93},
	title = {Fetal cardiac and motor responses to octave-band noises as a function of central frequency, intensity and heart rate variability},
	url = {http://www.sciencedirect.com/science/article/pii/037837828890045X},
	urldate = {2017-10-06},
	volume = {18},
	year = {1988},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/037837828890045X},
	bdsk-url-2 = {https://doi.org/10.1016/0378-3782(88)90045-X}}

@article{marler_innate_1990,
	abstract = {Research on the ways in which different species of birds learn to sing is used to illustrate the necessity of taking innate factors into account in studies of behavioral development. Experiments on two species of songbirds are described that reveal innate species differences in responsiveness to taperecorded songs. Conspecific songs are favored over those of other species. These patterns of innately varying responsiveness provide a basis for the development, not of stereotyped behavior, but of variable, individually learned behavior. The viewpoint is presented that mechanisms that differ innately from species to species, some with general functions, others specialized for particular ontogenetic assignments, provide the necessary substrates with which experience interacts.},
	author = {Marler, Peter},
	doi = {10.1002/dev.420230703},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KIWNEMWA/Marler - 1990 - Innate learning preferences Signals for communica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XUIWVDDZ/abstract.html:text/html},
	issn = {1098-2302},
	journal = {Developmental Psychobiology},
	keywords = {oiseau},
	language = {en},
	month = nov,
	number = {7},
	pages = {557--568},
	shorttitle = {Innate learning preferences},
	title = {Innate learning preferences: {Signals} for communication},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/dev.420230703/abstract},
	urldate = {2017-10-05},
	volume = {23},
	year = {1990},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/dev.420230703/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/dev.420230703}}

@article{spelke_core_2007,
	abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a fifth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
	author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
	doi = {10.1111/j.1467-7687.2007.00569.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9G7E6DZW/Spelke et Kinzler - 2007 - Core knowledge.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QBWB9XFX/abstract.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = jan,
	number = {1},
	pages = {89--96},
	title = {Core knowledge},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x/abstract},
	urldate = {2017-10-03},
	volume = {10},
	year = {2007},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00569.x}}

@article{moore_human_2007,
	abstract = {This review traces the structural maturation of the human auditory system, and compares the timeline of anatomical development with cotemporaneous physiological and behavioral events. During the embryonic period, there is formation of basic structure at all levels of the system, i.e. the inner ear, the brainstem pathway, and the cortex. The second trimester is a time of rapid growth and development, and by the end of this period, the cochlea has acquired a very adult-like configuration. During the perinatal period, the brainstem reaches a mature state, and brainstem activity is reflected in behavioral responses to sound, including phonetic discrimination, and in evoked brainstem and early middle latency responses. The perinatal period is also the time of peak development of brainstem input to the cortex through the marginal layer, and of the long latency cortical potentials, the N2 and mismatch negativity. In early childhood, from the sixth post-natal month to age five, there is progressive maturation of the thalamic projections to the cortex and of the longer latency Pa and P1 evoked potentials. Later childhood, from six to twelve years, is the time of maturation of the superficial cortical layers and their intracortical connections, accompanied by appearance of the N1 potential and improved linguistic discriminative abilities. Some consideration is given to the potential negative effects of deafness-induced sound deprivation during the perinatal period and childhood.},
	author = {Moore, Jean K. and Linthicum, Fred H. Jr},
	doi = {10.1080/14992020701383019},
	file = {moore2007.pdf:/Users/Cecile/Zotero/storage/Q7JBM2TK/moore2007.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/894VP7I5/14992020701383019.html:text/html},
	issn = {1499-2027},
	journal = {International Journal of Audiology},
	keywords = {Cochlea, MMN, ABR, Brainstem, MLR, Auditory cortex},
	month = jan,
	number = {9},
	pages = {460--478},
	shorttitle = {The human auditory system},
	title = {The human auditory system: {A} timeline of development},
	url = {http://dx.doi.org/10.1080/14992020701383019},
	urldate = {2017-10-06},
	volume = {46},
	year = {2007},
	bdsk-url-1 = {http://dx.doi.org/10.1080/14992020701383019}}

@article{granier-deferre_near-term_2011,
	abstract = {The perception of speech and music requires processing of variations in spectra and amplitude over different time intervals. Near-term fetuses can discriminate acoustic features, such as frequencies and spectra, but whether they can process complex auditory streams, such as speech sequences and more specifically their temporal variations, fast or relatively slow acoustic variations, is unclear. We recorded the cardiac activity of 82 near-term fetuses (38 weeks GA) in quiet sleep during a silent control condition and four 15 s streams presented at 90 dB SPL Leq: two piano melodies with opposite contours, a natural Icelandic sentence and a chimera of the sentence -- all its spectral information was replaced with broadband noise, leaving its specific temporal variations in amplitude intact without any phonological information. All stimuli elicited a heart rate deceleration. The response patterns to the melodies were the same and differed significantly from those observed with the Icelandic sentence and its chimera, which did not differ. The melodies elicited a monophasic heart rate deceleration, indicating a stimulus orienting reflex while the Icelandic and its chimera evoked a sustained lower magnitude response, indicating a sustained attentional response or more focused information processing. A conservative interpretation of the data is that near-term fetuses can perceive sound streams and the rapid temporal variations in amplitude that are specific to speech sounds with no spectral variations at all.},
	author = {Granier-Deferre, Carolyn and Ribeiro, Aur{\'e}lie and Jacquet, Anne-Yvonne and Bassereau, Sophie},
	doi = {10.1111/j.1467-7687.2010.00978.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T8C2BTE7/Granier-Deferre et al. - 2011 - Near-term fetuses process temporal features of spe.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ETF8276M/abstract\;jsessionid=65A2DA716F95867A8D20547AF93BBECD.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = mar,
	number = {2},
	pages = {336--352},
	title = {Near-term fetuses process temporal features of speech},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2010.00978.x/abstract},
	urldate = {2017-10-06},
	volume = {14},
	year = {2011},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2010.00978.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2010.00978.x}}

@article{magnuson_acoustic_2007,
	abstract = {Two talkers' productions of the same phoneme may be quite different acoustically, whereas their productions of different speech sounds may be virtually identical. Despite this lack of invariance in the relationship between the speech signal and linguistic categories, listeners experience phonetic constancy across a wide range of talkers, speaking styles, linguistic contexts, and acoustic environments. The authors present evidence that perceptual sensitivity to talker variability involves an active cognitive mechanism: Listeners expecting to hear 2 different talkers differing only slightly in average pitch showed performance costs typical of adjusting to talker variability, whereas listeners hearing the same materials but expecting a single talker or given no special instructions did not show these performance costs. The authors discuss the implications for understanding phonetic constancy despite variability between talkers (and other sources of variability) and for theories of speech perception. The results provide further evidence for active, controlled processing in real-time speech perception and are consistent with a model of talker normalization that involves contextual tuning.},
	author = {Magnuson, James S. and Nusbaum, Howard C.},
	doi = {10.1037/0096-1523.33.2.391},
	file = {magnuson_nusbaum_JEPHPP2007.pdf:/Users/Cecile/Zotero/storage/THRKQ284/magnuson_nusbaum_JEPHPP2007.pdf:application/pdf},
	issn = {0096-1523},
	journal = {Journal of Experimental Psychology. Human Perception and Performance},
	keywords = {Acoustics, Female, Humans, Male, Phonetics, Verbal Behavior, speech perception, Speech Perception},
	language = {eng},
	month = apr,
	number = {2},
	pages = {391--409},
	pmid = {17469975},
	title = {Acoustic differences, listener expectations, and the perceptual accommodation of talker variability},
	volume = {33},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1037/0096-1523.33.2.391}}

@article{anderson_information-processing_2003,
	abstract = {Two imaging experiments were performed--one involving an algebraic transformation task studied by Anderson, Reder, and Lebiere (1996) and the other an abstraction symbol manipulation task studied by Blessing and Anderson (1996). ACT-R models exist that predict the latency patterns in these tasks. These models require activity in an imaginal buffer to represent changes to the problem representation, in a retrieval buffer to hold information from declarative memory, and in a manual buffer to hold information about motor behavior. A general theory is described about how to map activity in these buffers onto the fMRI blood oxygen level dependent (BOLD) response. This theory claims that the BOLD response is integrated over the duration that a buffer is active and can be used to predict the observed BOLD function. Activity in the imaginal buffer is shown to predict the BOLD response in a left posterior parietal region; activity in the retrieval buffer is shown to predict the BOLD response in a left prefrontal region; and activity in the manual buffer is shown to predict activity in a motor region. More generally, this article shows how to map a large class of information-processing theories (not just ACT-R) onto the BOLD response and provides a precise interpretation of the cognitive significance of the BOLD response.},
	author = {Anderson, John R. and Qin, Yulin and Sohn, Myeong-Ho and Stenger, V. Andrew and Carter, Cameron S.},
	file = {Anderson2003.pdf:/Users/Cecile/Zotero/storage/RUB47XRV/Anderson2003.pdf:application/pdf},
	issn = {1069-9384},
	journal = {Psychonomic Bulletin \& Review},
	keywords = {Cognition, Humans, Memory, Models, Biological, Oxygen, Parietal Lobe, Symbolism, Brain, Magnetic resonance imaging},
	language = {eng},
	month = jun,
	number = {2},
	pages = {241--261},
	pmid = {12921408},
	title = {An information-processing model of the {BOLD} response in symbol manipulation tasks},
	volume = {10},
	year = {2003}}

@article{mayhew_global_2016,
	abstract = {In functional magnetic resonance imaging (fMRI), the relationship between positive BOLD responses (PBRs) and negative BOLD responses (NBRs) to stimulation is potentially informative about the balance of excitatory and inhibitory brain responses in sensory cortex. In this study, we performed three separate experiments delivering visual, motor or somatosensory stimulation unilaterally, to one side of the sensory field, to induce PBR and NBR in opposite brain hemispheres. We then assessed the relationship between the evoked amplitudes of contralateral PBR and ipsilateral NBR at the level of both single-trial and average responses. We measure single-trial PBR and NBR peak amplitudes from individual time-courses, and show that they were positively correlated in all experiments. In contrast, in the average response across trials the absolute magnitudes of both PBR and NBR increased with increasing stimulus intensity, resulting in a negative correlation between mean response amplitudes. Subsequent analysis showed that the amplitude of single-trial PBR was positively correlated with the BOLD response across all grey-matter voxels and was not specifically related to the ipsilateral sensory cortical response. We demonstrate that the global component of this single-trial response modulation could be fully explained by voxel-wise vascular reactivity, the BOLD signal standard deviation measured in a separate resting-state scan (resting state fluctuation amplitude, RSFA). However, bilateral positive correlation between PBR and NBR regions remained. We further report that modulations in the global brain fMRI signal cannot fully account for this positive PBR--NBR coupling and conclude that the local sensory network response reflects a combination of superimposed vascular and neuronal signals. More detailed quantification of physiological and noise contributions to the BOLD signal is required to fully understand the trial-by-trial PBR and NBR relationship compared with that of average responses.},
	author = {Mayhew, S. D. and Mullinger, K. J. and Ostwald, D. and Porcaro, C. and Bowtell, R. and Bagshaw, A. P. and Francis, S. T.},
	doi = {10.1016/j.neuroimage.2016.02.077},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/FZPHIVHW/Mayhew et al. - 2016 - Global signal modulation of single-trial fMRI resp.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/D3J9Q6VE/S1053811916001956.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Global signal, Negative BOLD response, deactivation, RSFA},
	month = jun,
	number = {Supplement C},
	pages = {62--74},
	shorttitle = {Global signal modulation of single-trial {fMRI} response variability},
	title = {Global signal modulation of single-trial {fMRI} response variability: {Effect} on positive vs negative {BOLD} response relationship},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811916001956},
	urldate = {2017-12-12},
	volume = {133},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811916001956},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2016.02.077}}

@article{mullinger_evidence_2014,
	abstract = {Unambiguous interpretation of changes in the BOLD signal is challenging because of the complex neurovascular coupling that translates changes in neuronal activity into the subsequent haemodynamic response. In particular, the neurophysiological origin of the negative BOLD response (NBR) remains incompletely understood. Here, we simultaneously recorded BOLD, EEG and cerebral blood flow (CBF) responses to 10s blocks of unilateral median nerve stimulation (MNS) in order to interrogate the NBR. Both negative BOLD and negative CBF responses to MNS were observed in the same region of the ipsilateral primary sensorimotor cortex (S1/M1) and calculations showed that MNS induced a decrease in the cerebral metabolic rate of oxygen consumption (CMRO2) in this NBR region. The ∆CMRO2/∆CBF coupling ratio (n) was found to be significantly larger in this ipsilateral S1/M1 region (n=0.91$\pm$0.04, M=10.45\%) than in the contralateral S1/M1 (n=0.65$\pm$0.03, M=10.45\%) region that exhibited a positive BOLD response (PBR) and positive CBF response, and a consequent increase in CMRO2 during MNS. The fMRI response amplitude in ipsilateral S1/M1 was negatively correlated with both the power of the 8--13Hz EEG mu oscillation and somatosensory evoked potential amplitude. Blocks in which the largest magnitude of negative BOLD and CBF responses occurred therefore showed greatest mu power, an electrophysiological index of cortical inhibition, and largest somatosensory evoked potentials. Taken together, our results suggest that a neuronal mechanism underlies the NBR, but that the NBR may originate from a different neurovascular coupling mechanism to the PBR, suggesting that caution should be taken in assuming the NBR simply represents the neurophysiological inverse of the PBR.},
	author = {Mullinger, K. J. and Mayhew, S. D. and Bagshaw, A. P. and Bowtell, R. and Francis, S. T.},
	doi = {10.1016/j.neuroimage.2014.02.029},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RCANGMJW/Mullinger et al. - 2014 - Evidence that the negative BOLD response is neuron.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KIUJT7CC/Mullinger et al. - 2014 - Evidence that the negative BOLD response is neuron.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9GUIE4CH/S1053811914001426.html:text/html;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WP2MNJM9/S1053811914001426.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = jul,
	number = {Supplement C},
	pages = {263--274},
	shorttitle = {Evidence that the negative {BOLD} response is neuronal in origin},
	title = {Evidence that the negative {BOLD} response is neuronal in origin: {A} simultaneous {EEG}--{BOLD}--{CBF} study in humans},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811914001426},
	urldate = {2017-12-12},
	volume = {94},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914001426},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2014.02.029}}

@article{obrig_impact_2017,
	abstract = {During early language development native phonotactics are acquired in a `bottom-up' fashion, relying on exquisite auditory differentiation skills operational from birth. Since basic lexico-semantic abilities have been demonstrated from 6 months onwards, `top-down' influences on phonotactic learning may complement the extraction of transitional probabilities in phonotactic learning. Such a bidirectional acquisition strategy predicts, that familiarization with (proto)words should affect processing of untrained word-forms of similar phonological structure. We investigated 6-month-old infants undergoing an associative training to establish a pseudoword-pseudoobject link. Comparison between pre- and post-training responses to trained and untrained items allowed investigating training effects. Additionally phonotactic status (50\% legal, 50\% illegal with regard to German) allowed investigating influences of previous language experience. EEG and functional near-infrared spectroscopy (fNIRS) provided measures of electrophysiological and hemodynamic responses. We find evidence for a robust effect of associative training on pseudoword processing when presented in isolation. This transferred to untrained items. Previous linguistic experience showed a much weaker effect. Taken together the results suggest that sensitivity to phonotactic contrasts is present at 6 months, but that acceptance as lexical candidates is rapidly modulated when word forms following non-native phonotactics become potentially meaningful due to repeated exposure in a semantic context.},
	author = {Obrig, Hellmuth and Mock, Julia and Stephan, Franziska and Richter, Maria and Vignotto, Micol and Rossi, Sonja},
	doi = {10.1016/j.dcn.2016.09.001},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UGUCKWJ3/Obrig et al. - 2017 - Impact of associative word learning on phonotactic.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8XW9SV6D/S1878929316300603.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Language Development, Associative training, fNIRS, phonotactics},
	month = jun,
	number = {Supplement C},
	pages = {185--197},
	series = {Sensitive periods across development},
	shorttitle = {Impact of associative word learning on phonotactic processing in 6-month-old infants},
	title = {Impact of associative word learning on phonotactic processing in 6-month-old infants: {A} combined {EEG} and {fNIRS} study},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929316300603},
	urldate = {2017-12-12},
	volume = {25},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316300603},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2016.09.001}}

@article{buxton_dynamics_1998,
	abstract = {A biomechanical model is presented for the dynamic changes in deoxyhemoglobin content during brain activation. The model incorporates the conflicting effects of dynamic changes in both blood oxygenation and blood volume. Calculations based on the model show pronounced transients in the deoxyhemoglobin content and the blood oxygenation level dependent (BOLD) signal measured with functional MRI, including initial dips and overshoots and a prolonged post-stimulus undershoot of the BOLD signal. Furthermore, these transient effects can occur in the presence of tight coupling of cerebral blood flow and oxygen metabolism throughout the activation period. An initial test of the model against experimental measurements of flow and BOLD changes during a finger-tapping task showed good agreement.},
	author = {Buxton, Richard B. and Wong, Eric C. and Frank, Lawrence R.},
	doi = {10.1002/mrm.1910390602},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FEPHMQ5D/Buxton et al. - 1998 - Dynamics of blood flow and oxygenation changes dur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMCBUTCM/abstract\;jsessionid=574B21C633AFB659AF923D355EC813B9.html:text/html},
	issn = {1522-2594},
	journal = {Magnetic Resonance in Medicine},
	keywords = {cerebral blood flow, cerebral blood volume, cerebral oxygen metabolism, functional magnetic resonance imaging},
	language = {en},
	month = jun,
	number = {6},
	pages = {855--864},
	shorttitle = {Dynamics of blood flow and oxygenation changes during brain activation},
	title = {Dynamics of blood flow and oxygenation changes during brain activation: {The} balloon model},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1910390602/abstract},
	urldate = {2017-12-18},
	volume = {39},
	year = {1998},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1910390602/abstract},
	bdsk-url-2 = {https://doi.org/10.1002/mrm.1910390602}}

@book{macwhinney_childes_2000,
	author = {MacWhinney, B.},
	publisher = {Mahwah, NJ: Lawrence Erlbaum Associates.},
	title = {The {CHILDES} {Project}: {Tools} for analyzing talk. {Third} {Edition}.},
	year = {2000}}

@article{telkemeyer_acoustic_2011,
	abstract = {Speech perception requires rapid extraction of the linguistic content from the acoustic signal. The ability to efficiently process rapid changes in auditory information is important for decoding speech and thereby crucial during language acquisition. Investigating functional networks of speech perception in infancy might elucidate neuronal ensembles supporting perceptual abilities that gate language acquisition. Interhemispheric specializations for language have been demonstrated in infants. How these asymmetries are shaped by basic temporal acoustic properties is under debate. We recently provided evidence that newborns process non-linguistic sounds sharing temporal features with language in a differential and lateralized fashion. The present study used the same material while measuring brain responses of 6 and 3 month old infants using simultaneous recordings of electroencephalography (EEG) and near-infrared spectroscopy (NIRS). NIRS reveals that the lateralization observed in newborns remains constant over the first months of life. While fast acoustic modulations elicit bilateral neuronal activations, slow modulations lead to right-lateralized responses. Additionally, auditory-evoked potentials and oscillatory EEG responses show differential responses for fast and slow modulations indicating a sensitivity for temporal acoustic variations. Oscillatory responses reveal an effect of development, that is, 6 but not 3 month old infants show stronger theta-band desynchronization for slowly modulated sounds. Whether this developmental effect is due to increasing fine-grained perception for spectrotemporal sounds in general remains speculative. Our findings support the notion that a more general specialization for acoustic properties can be considered the basis for lateralization of speech perception. The results show that concurrent assessment of vascular based imaging and electrophysiological responses have great potential in the research on language acquisition.},
	author = {Telkemeyer, Silke and Rossi, Sonja and Nierhaus, Till and Steinbrink, Jens and Obrig, Hellmuth and Wartenburger, Isabell},
	doi = {10.3389/fpsyg.2011.00062},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/BIE3D8SB/Telkemeyer et al. - 2011 - Acoustic Processing of Temporally Modulated Sounds.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	month = apr,
	pmcid = {PMC3110620},
	pmid = {21716574},
	shorttitle = {Acoustic {Processing} of {Temporally} {Modulated} {Sounds} in {Infants}},
	title = {Acoustic {Processing} of {Temporally} {Modulated} {Sounds} in {Infants}: {Evidence} from a {Combined} {Near}-{Infrared} {Spectroscopy} and {EEG} {Study}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110620/},
	volume = {2},
	year = {2011},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110620/},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2011.00062}}

@article{rosen_constructing_2007,
	abstract = {Vouloumanos and Werker (2007) claim that human neonates have a (possibly innate) bias to listen to speech based on a preference for natural speech utterances over sine-wave analogues. We argue that this bias more likely arises from the strikingly different saliency of voice melody in the two kinds of sounds, a bias that has already been shown to be learned pre-natally. Possible avenues of research to address this crucial issue are proposed, based on a consideration of the distinctive acoustic properties of speech.},
	author = {Rosen, Stuart and Iverson, Paul},
	doi = {10.1111/j.1467-7687.2007.00550.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/87GQ9ITT/Rosen et Iverson - 2007 - Constructing adequate non-speech analogues what i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PCKI4EUH/abstract.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = mar,
	number = {2},
	pages = {165--168},
	shorttitle = {Constructing adequate non-speech analogues},
	title = {Constructing adequate non-speech analogues: what is special about speech anyway?},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00550.x/abstract},
	urldate = {2017-12-30},
	volume = {10},
	year = {2007},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00550.x/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00550.x}}

@book{lloyd_james_speech_1940,
	address = {London},
	author = {Lloyd James, Arthur},
	keywords = {Signals and signaling., Speech., Telephone.},
	language = {eng},
	note = {Open Library ID: OL6442817M},
	publisher = {Sir I. Pitman \& sons, ltd.},
	title = {Speech signals in telephony},
	year = {1940}}

@article{borges_scale-free_2018,
	abstract = {Speech comprehension is preserved up to a threefold acceleration, but deteriorates rapidly at higher speeds. Current models posit that perceptual resilience to accelerated speech is limited by the brain's ability to parse speech into syllabic units using δ/θ oscillations. Here, we investigated whether the involvement of neuronal oscillations in processing accelerated speech also relates to their scale-free amplitude modulation as indexed by the strength of long-range temporal correlations (LRTC). We recorded MEG while 24 human subjects (12 females) listened to radio news uttered at different comprehensible rates, at a mostly unintelligible rate and at this same speed interleaved with silence gaps. δ, θ, and low-γ oscillations followed the nonlinear variation of comprehension, with LRTC rising only at the highest speed. In contrast, increasing the rate was associated with a monotonic increase in LRTC in high-γ activity. When intelligibility was restored with the insertion of silence gaps, LRTC in the δ, θ, and low-γ oscillations resumed the low levels observed for intelligible speech. Remarkably, the lower the individual subject scaling exponents of δ/θ oscillations, the greater the comprehension of the fastest speech rate. Moreover, the strength of LRTC of the speech envelope decreased at the maximal rate, suggesting an inverse relationship with the LRTC of brain dynamics when comprehension halts. Our findings show that scale-free amplitude modulation of cortical oscillations and speech signals are tightly coupled to speech uptake capacity.
SIGNIFICANCE STATEMENT One may read this statement in 20--30 s, but reading it in less than five leaves us clueless. Our minds limit how much information we grasp in an instant. Understanding the neural constraints on our capacity for sensory uptake is a fundamental question in neuroscience. Here, MEG was used to investigate neuronal activity while subjects listened to radio news played faster and faster until becoming unintelligible. We found that speech comprehension is related to the scale-free dynamics of δ and θ bands, whereas this property in high-γ fluctuations mirrors speech rate. We propose that successful speech processing imposes constraints on the self-organization of synchronous cell assemblies and their scale-free dynamics adjusts to the temporal properties of spoken language.},
	author = {Borges, Ana Filipa Teixeira and Giraud, Anne-Lise and Mansvelder, Huibert D. and Linkenkaer-Hansen, Klaus},
	copyright = {Copyright {\copyright} 2018 the authors 0270-6474/18/380710-13\$15.00/0},
	doi = {10.1523/JNEUROSCI.1515-17.2017},
	file = {Snapshot:/Users/Cecile/Zotero/storage/NKZV2JBD/710.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {accelerated speech, language comprehension, long-range temporal correlations, magnetoencephalography (MEG), principle of complexity management (PCM), scale-free dynamics},
	language = {en},
	month = jan,
	number = {3},
	pages = {710--722},
	pmid = {29217685},
	title = {Scale-{Free} {Amplitude} {Modulation} of {Neuronal} {Oscillations} {Tracks} {Comprehension} of {Accelerated} {Speech}},
	url = {http://www.jneurosci.org/content/38/3/710},
	urldate = {2018-01-23},
	volume = {38},
	year = {2018},
	bdsk-url-1 = {http://www.jneurosci.org/content/38/3/710},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1515-17.2017}}

@article{wade_negative_2002,
	abstract = {Many fMRI experiments show regions of cortex that seem to respond in antiphase with the primary stimulus. In this issue of Neuron, Shmuel et al. show that this ``negative BOLD response'' is spatially and temporally linked to reductions in blood flow. By combining BOLD and blood flow data to model the energy consumption in cortex, they conclude that the NBR is primarily due to active neuronal inhibition.},
	author = {Wade, Alex R.},
	doi = {10.1016/S0896-6273(02)01138-8},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SHX27LC5/Wade - 2002 - The Negative BOLD Signal Unmasked.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/B4CQ22FW/S0896627302011388.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = dec,
	number = {6},
	pages = {993--995},
	title = {The {Negative} {BOLD} {Signal} {Unmasked}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627302011388},
	urldate = {2018-01-08},
	volume = {36},
	year = {2002},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627302011388},
	bdsk-url-2 = {https://doi.org/10.1016/S0896-6273(02)01138-8}}

@phdthesis{diallo_probleme_2017,
	author = {Diallo, Mohamadou Malal},
	file = {theseDiallo.pdf:/Users/Cecile/Zotero/storage/TC3IZX7F/theseDiallo.pdf:application/pdf},
	school = {Universit{\'e} de Picardie-Jules Verne},
	title = {Probl{\`e}me inverse de sources en {Electro}-{Enc{\'e}phalo}-{Graphie} chez le nouveau-n{\'e}},
	type = {{PhD} {Thesis}},
	year = {2017}}

@article{alho_stimulus-dependent_2014,
	author = {Alho, Kimmo and Rinne, Teemu and Herron, Timothy J. and Woods, David L.},
	doi = {10.1016/j.heares.2013.08.001},
	file = {Alho_et_al_2014_Hear_Res_Auditory_fMRI_meta-analysis.pdf:/Users/Cecile/Zotero/storage/7ZI7355U/Alho_et_al_2014_Hear_Res_Auditory_fMRI_meta-analysis.pdf:application/pdf},
	issn = {03785955},
	journal = {Hearing Research},
	language = {en},
	month = jan,
	pages = {29--41},
	shorttitle = {Stimulus-dependent activations and attention-related modulations in the auditory cortex},
	title = {Stimulus-dependent activations and attention-related modulations in the auditory cortex: {A} meta-analysis of {fMRI} studies},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595513001913},
	urldate = {2018-02-01},
	volume = {307},
	year = {2014},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378595513001913},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.08.001}}

@article{alho_attention-related_2012,
	author = {Alho, Kimmo and Salonen, Johanna and Rinne, Teemu and Medvedev, Svyatoslav V. and Hugdahl, Kenneth and H{\"a}m{\"a}l{\"a}inen, Heikki},
	doi = {10.1016/j.brainres.2012.01.007},
	file = {Alho_et_al_2012_Brain_Res_dichotic_listening_aud_attn_MEG.pdf:/Users/Cecile/Zotero/storage/HPENSBIC/Alho_et_al_2012_Brain_Res_dichotic_listening_aud_attn_MEG.pdf:application/pdf},
	issn = {00068993},
	journal = {Brain Research},
	language = {en},
	month = mar,
	pages = {47--54},
	title = {Attention-related modulation of auditory-cortex responses to speech sounds during dichotic listening},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0006899312000455},
	urldate = {2018-02-01},
	volume = {1442},
	year = {2012},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0006899312000455},
	bdsk-url-2 = {https://doi.org/10.1016/j.brainres.2012.01.007}}

@article{flemming_evaluation_2005,
	author = {Flemming, Lars and Wang, Yaozhi and Caprihan, Arvind and Eiselt, Michael and Haueisen, Jens and Okada, Yoshio},
	doi = {10.1016/j.clinph.2005.01.007},
	file = {Flemming 2005.pdf:/Users/Cecile/Zotero/storage/JQPPZTAF/Flemming 2005.pdf:application/pdf},
	issn = {13882457},
	journal = {Clinical Neurophysiology},
	language = {en},
	month = may,
	number = {5},
	pages = {1141--1152},
	title = {Evaluation of the distortion of {EEG} signals caused by a hole in the skull mimicking the fontanel in the skull of human neonates},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1388245705000295},
	urldate = {2018-02-01},
	volume = {116},
	year = {2005},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1388245705000295},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2005.01.007}}

@article{moerel_processing_2012,
	abstract = {Auditory cortical processing of complex meaningful sounds entails the transformation of sensory (tonotopic) representations of incoming acoustic waveforms into higher-level sound representations (e.g., their category). However, the precise neural mechanisms enabling such transformations remain largely unknown. In the present study, we use functional magnetic resonance imaging (fMRI) and natural sounds stimulation to examine these two levels of sound representation (and their relation) in the human auditory cortex. In a first experiment, we derive cortical maps of frequency preference (tonotopy) and selectivity (tuning width) by mathematical modeling of fMRI responses to natural sounds. The tuning width maps highlight a region of narrow tuning that follows the main axis of Heschl's gyrus and is flanked by regions of broader tuning. The narrowly tuned portion on Heschl's gyrus contains two mirror-symmetric frequency gradients, presumably defining two distinct primary auditory areas. In addition, our analysis indicates that spectral preference and selectivity (and their topographical organization) extend well beyond the primary regions and also cover higher-order and category-selective auditory regions. In particular, regions with preferential responses to human voice and speech occupy the low-frequency portions of the tonotopic map. We confirm this observation in a second experiment, where we find that speech/voice selective regions exhibit a response bias toward the low frequencies characteristic of human voice and speech, even when responding to simple tones. We propose that this frequency bias reflects the selective amplification of relevant and category-characteristic spectral bands, a useful processing step for transforming a sensory (tonotopic) sound image into higher level neural representations.},
	author = {Moerel, Michelle and Martino, Federico De and Formisano, Elia},
	copyright = {Copyright {\copyright} 2012 the authors 0270-6474/12/3214205-12\$15.00/0},
	doi = {10.1523/JNEUROSCI.1388-12.2012},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FQA7XPVX/Moerel et al. - 2012 - Processing of Natural Sounds in Human Auditory Cor.pdf:application/pdf},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = oct,
	number = {41},
	pages = {14205--14216},
	pmid = {23055490},
	shorttitle = {Processing of {Natural} {Sounds} in {Human} {Auditory} {Cortex}},
	title = {Processing of {Natural} {Sounds} in {Human} {Auditory} {Cortex}: {Tonotopy}, {Spectral} {Tuning}, and {Relation} to {Voice} {Sensitivity}},
	url = {http://www.jneurosci.org/content/32/41/14205},
	urldate = {2018-02-04},
	volume = {32},
	year = {2012},
	bdsk-url-1 = {http://www.jneurosci.org/content/32/41/14205},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1388-12.2012}}

@article{schridde_negative_2008,
	abstract = {Blood oxygen level--dependent (BOLD) functional magnetic resonance imaging (fMRI) is widely used in neuroscience to study brain activity. However, BOLD fMRI does not measure neuronal activity directly but depends on cerebral blood flow (CBF), cerebral blood volume (CBV), and cerebral metabolic rate of oxygen (CMRO2) consumption. Using fMRI, CBV, CBF, neuronal recordings, and CMRO2 modeling, we investigated how the signals are related during seizures in rats. We found that increases in hemodynamic, neuronal, and metabolic activity were associated with positive BOLD signals in the cortex, but with negative BOLD signals in hippocampus. Our data show that negative BOLD signals do not necessarily imply decreased neuronal activity or CBF, but can result from increased neuronal activity, depending on the interplay between hemodynamics and metabolism. Caution should be used in interpreting fMRI signals because the relationship between neuronal activity and BOLD signals may depend on brain region and state and can be different during normal and pathological conditions.},
	author = {Schridde, Ulrich and Khubchandani, Manjula and Motelow, Joshua E. and Sanganahalli, Basavaraju G. and Hyder, Fahmeed and Blumenfeld, Hal},
	doi = {10.1093/cercor/bhm208},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/B3836W7J/Schridde et al. - 2008 - Negative BOLD with Large Increases in Neuronal Act.pdf:application/pdf},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	language = {en},
	month = aug,
	number = {8},
	pages = {1814--1827},
	title = {Negative {BOLD} with {Large} {Increases} in {Neuronal} {Activity}},
	url = {https://academic.oup.com/cercor/article/18/8/1814/284529},
	urldate = {2018-01-25},
	volume = {18},
	year = {2008},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/18/8/1814/284529},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhm208}}

@article{shmuel_sustained_2002,
	abstract = {Most fMRI studies are based on the detection of a positive BOLD response (PBR). Here, we demonstrate and characterize a robust sustained negative BOLD response (NBR) in the human occipital cortex, triggered by stimulating part of the visual field. The NBR was spatially adjacent to but segregated from the PBR. It depended on the stimulus and thus on the pattern of neuronal activity. The time courses of the NBR and PBR were similar, and their amplitudes covaried both with increasing stimulus duration and increasing stimulus contrast. The NBR was associated with reductions in blood flow and with decreases in oxygen consumption. Our findings support the contribution to the NBR of (1) a significant component of reduction in neuronal activity and (2) possibly a component of hemodynamic changes independent of the local changes in neuronal activity.},
	author = {Shmuel, Amir and Yacoub, Essa and Pfeuffer, Josef and Van de Moortele, Pierre-Francois and Adriany, Gregor and Hu, Xiaoping and Ugurbil, Kamil},
	doi = {10.1016/S0896-6273(02)01061-9},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/M3C7GTB5/Shmuel et al. - 2002 - Sustained Negative BOLD, Blood Flow and Oxygen Con.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WK37DMSQ/S0896627302010619.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = dec,
	number = {6},
	pages = {1195--1210},
	title = {Sustained {Negative} {BOLD}, {Blood} {Flow} and {Oxygen} {Consumption} {Response} and {Its} {Coupling} to the {Positive} {Response} in the {Human} {Brain}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627302010619},
	urldate = {2018-01-25},
	volume = {36},
	year = {2002},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627302010619},
	bdsk-url-2 = {https://doi.org/10.1016/S0896-6273(02)01061-9}}

@article{issard_variability_2018,
	abstract = {Measuring brain activity in developmental populations remains a major challenge despite great technological advances. Among the numerous available methods, functional near-infrared spectroscopy (fNIRS), an imaging modality that probes the hemodynamic response, is a powerful tool for recording brain activity in a great variety of situations and populations. Neurocognitive studies with infants have often reported inverted hemodynamic responses, i.e. a decrease instead of an increase in regional blood oxygenation, but the exact physiological explanation and cognitive interpretation of this response remain unclear. Here, we first provide an overview of the basic principles of NIRS and its use in cognitive developmental neuroscience. We then review the infant fNIRS literature to show that the hemodynamic response is modulated by experimental design and stimulus complexity, sometimes leading to hemodynamic responses with non-canonical shapes. We also argue that this effect is further modulated by the age of participants, the cortical regions involved, and the developmental stage of the tested cognitive process. We argue that this variability needs to be taken into account when designing and interpreting developmental studies measuring the hemodynamic response.},
	author = {Issard, C{\'e}cile and Gervain, Judit},
	doi = {10.1016/j.dcn.2018.01.009},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/URT4QVTJ/Issard et Gervain - 2018 - Variability of the hemodynamic response in infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EVPQC8ZG/S187892931730049X.html:text/html;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/R4K2R9EV/S187892931730049X.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {fNIRS, Infants, Development, Experimental complexity, Inverted Hemodynamic Response},
	shorttitle = {Variability of the hemodynamic response in infants},
	title = {Variability of the hemodynamic response in infants: {Influence} of experimental design and stimulus complexity},
	url = {https://www.sciencedirect.com/science/article/pii/S187892931730049X},
	urldate = {2018-02-05},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S187892931730049X},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2018.01.009}}

@article{may_specificity_2018,
	abstract = {In this work we ask whether at birth, the human brain responds uniquely to speech, or if similar activation also occurs to a non-speech surrogate `language'. We compare neural activation in newborn infants to the language heard in utero (English), to an unfamiliar language (Spanish), and to a whistled surrogate language (Silbo Gomero) that, while used by humans to communicate, is not speech. Anterior temporal areas of the neonate cortex are activated in response to both familiar and unfamiliar spoken language, but these classic language areas are not activated to the whistled surrogate form. These results suggest that at the time human infants emerge from the womb, the neural preparation for language is specialized to speech.},
	author = {May, Lillian and Gervain, Judit and Carreiras, Manuel and Werker, Janet F.},
	doi = {10.1111/desc.12564},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/K3L3Y9BB/May et al. - The specificity of the neural response to speech a.pdf:application/pdf;may2017.pdf:/Users/Cecile/Zotero/storage/ISW8AKFJ/may2017.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6S3I6S8J/abstract\;jsessionid=467B234A42F2B0A6454F7393E93C39B2.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	number = {3},
	pages = {n/a--n/a},
	title = {The specificity of the neural response to speech at birth},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12564/abstract},
	urldate = {2018-01-30},
	volume = {21},
	year = {2018},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12564/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12564}}

@article{lew_effects_2013,
	author = {Lew, Seok and Sliva, Danielle D. and Choe, Myong-sun and Grant, P. Ellen and Okada, Yoshio and Wolters, Carsten H. and H{\"a}m{\"a}l{\"a}inen, Matti S.},
	doi = {10.1016/j.neuroimage.2013.03.017},
	file = {Lew 2013.pdf:/Users/Cecile/Zotero/storage/96MBK8GV/Lew 2013.pdf:application/pdf},
	issn = {10538119},
	journal = {NeuroImage},
	language = {en},
	month = aug,
	pages = {282--293},
	title = {Effects of sutures and fontanels on {MEG} and {EEG} source analysis in a realistic infant head model},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913002590},
	urldate = {2018-02-01},
	volume = {76},
	year = {2013},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913002590},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2013.03.017}}

@article{alho_event-related_1990,
	abstract = {We report here event-related potentials (ERPs) of human newborns to occasional pitch changes in a repetitive sequence of tone pips. These pitch changes elicited a large slow negative ERP component which resembles the mismatch negativity (MMN) generated by the adult brain under similar conditions. This MMN-type of negativity in newborns suggests that already at this early ontogenetic stage the brain monitors the acoustic environment for a possible change in any of its repetitive aspects. Apart from its theoretical interest, this finding might provide a new way to test the development of the central nervous system and to diagnose cerebral dysfunction at a very early stage.},
	author = {Alho, K. and Sainio, K. and Sajaniemi, N. and Reinikainen, K. and N{\"a}{\"a}t{\"a}nen, R.},
	doi = {10.1016/0168-5597(90)90031-8},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BEGX3HKY/Alho et al. - 1990 - Event-related brain potential of human newborns to.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GWY8L6XT/0168559790900318.html:text/html},
	issn = {0168-5597},
	journal = {Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section},
	keywords = {Audition, Event-related brain potential, Mismatch negativity, Newborn},
	month = mar,
	number = {2},
	pages = {151--155},
	title = {Event-related brain potential of human newborns to pitch change of an acoustic stimulus},
	url = {http://www.sciencedirect.com/science/article/pii/0168559790900318},
	urldate = {2018-02-01},
	volume = {77},
	year = {1990},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0168559790900318},
	bdsk-url-2 = {https://doi.org/10.1016/0168-5597(90)90031-8}}

@article{moore_maturation_2002,
	abstract = {This project traced the maturation of the human auditory cortex from midgestation to young adulthood, using immunostaining of axonal neurofilaments to determine the time of onset of rapid conduction. The study identified 3 developmental periods, each characterized by maturation of a different axonal system. During the perinatal period (3rd trimester to 4th postnatal month), neurofilament expression occurs only in axons of the marginal layer. These axons drive the structural and functional development of cells in the deeper cortical layers, but do not relay external stimuli. In early childhood (6 months to 5 years), maturing thalamocortical afferents to the deeper cortical layers are the first source of input to the auditory cortex from lower levels of the auditory system. During later childhood (5 to 12 years), maturation of commissural and association axons in the superficial cortical layers allows communication between different subdivisions of the auditory cortex, thus forming a basis for more complex cortical processing of auditory stimuli.},
	author = {Moore, Jean K.},
	doi = {10.1177/00034894021110S502},
	issn = {0003-4894},
	journal = {Annals of Otology, Rhinology \& Laryngology},
	language = {en},
	month = may,
	number = {5\_suppl},
	pages = {7--10},
	shorttitle = {Maturation of {Human} {Auditory} {Cortex}},
	title = {Maturation of {Human} {Auditory} {Cortex}: {Implications} for {Speech} {Perception}},
	url = {https://doi.org/10.1177/00034894021110S502},
	urldate = {2018-02-02},
	volume = {111},
	year = {2002},
	bdsk-url-1 = {https://doi.org/10.1177/00034894021110S502}}

@article{may_auditory_2004,
	author = {May, P. J. and Tiitinen, H.},
	file = {May_Tiitinen_2004_Neurol_Clin_Neurophysiol_Auditory_scene_analysis_and_sensory_memory_Sustained_transient_MEG.pdf:/Users/Cecile/Zotero/storage/SRGSSRK4/May_Tiitinen_2004_Neurol_Clin_Neurophysiol_Auditory_scene_analysis_and_sensory_memory_Sustained_transient_MEG.pdf:application/pdf},
	journal = {Neurology and Clinical Neurophysiology},
	shorttitle = {Auditory scene analysis and sensory memory},
	title = {Auditory scene analysis and sensory memory: the role of the auditory {N100m}},
	volume = {19},
	year = {2004}}

@article{edwards_functional_2016,
	abstract = {Humans are born with the ability to mentally represent the approximate numerosity of a set of objects, but little is known about the brain systems that sub-serve this ability early in life and their relation to the brain systems underlying symbolic number and mathematics later in development. Here we investigate processing of numerical magnitudes before the acquisition of a symbolic numerical system or even spoken language, by measuring the brain response to numerosity changes in pre-verbal infants using functional near-infrared spectroscopy (fNIRS). To do this, we presented infants with two types of numerical stimulus blocks: number change blocks that presented dot arrays alternating in numerosity and no change blocks that presented dot arrays all with the same number. Images were carefully constructed to rule out the possibility that responses to number changes could be due to non-numerical stimulus properties that tend to co-vary with number. Interleaved with the two types of numerical blocks were audio-visual animations designed to increase attention. We observed that number change blocks evoked an increase in oxygenated hemoglobin over a focal right parietal region that was greater than that observed during no change blocks and during audio-visual attention blocks. The location of this effect was consistent with intra-parietal activity seen in older children and adults for both symbolic and non-symbolic numerical tasks. A distinct set of bilateral occipital and middle parietal channels responded more to the attention-grabbing animations than to either of the types of numerical stimuli, further dissociating the specific right parietal response to number from a more general bilateral visual or attentional response. These results provide the strongest evidence to date that the right parietal cortex is specialized for numerical processing in infancy, as the response to number is dissociated from visual change processing and general attentional processing.},
	author = {Edwards, Laura A. and Wagner, Jennifer B. and Simon, Charline E. and Hyde, Daniel C.},
	doi = {10.1111/desc.12333},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PUQ9SHN2/Edwards et al. - 2016 - Functional brain organization for number processin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T5W6P89L/abstract\;jsessionid=EB934C5ED2D842EE09A96E2D53D47898.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = sep,
	number = {5},
	pages = {757--769},
	title = {Functional brain organization for number processing in pre-verbal infants},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12333/abstract},
	urldate = {2018-01-30},
	volume = {19},
	year = {2016},
	bdsk-url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12333/abstract},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12333}}

@article{vasile_human_2017,
	abstract = {Data collected on astrocytes' physiology in the rodent have placed them as key regulators of synaptic, neuronal, network, and cognitive functions. While these findings proved highly valuable for our awareness and appreciation of non-neuronal cell significance in brain physiology, early structural and phylogenic investigations of human astrocytes hinted at potentially different astrocytic properties. This idea sparked interest to replicate rodent-based studies on human samples, which have revealed an analogous but enhanced involvement of astrocytes in neuronal function of the human brain. Such evidence pointed to a central role of human astrocytes in sustaining more complex information processing. Here, we review the current state of our knowledge of human astrocytes regarding their structure, gene profile, and functions, highlighting the differences with rodent astrocytes. This recent insight is essential for assessment of the relevance of findings using animal models and for comprehending the functional significance of species-specific properties of astrocytes. Moreover, since dysfunctional astrocytes have been described in many brain disorders, a more thorough understanding of human-specific astrocytic properties is crucial for better-adapted translational applications.},
	author = {Vasile, Flora and Dossi, Elena and Rouach, Nathalie},
	doi = {10.1007/s00429-017-1383-5},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/K8UFUF4H/Vasile et al. - 2017 - Human astrocytes structure and functions in the h.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/N8QZU4VF/s00429-017-1383-5.html:text/html},
	issn = {1863-2653, 1863-2661},
	journal = {Brain Structure and Function},
	language = {en},
	month = jul,
	number = {5},
	pages = {2017--2029},
	shorttitle = {Human astrocytes},
	title = {Human astrocytes: structure and functions in the healthy brain},
	url = {https://link.springer.com/article/10.1007/s00429-017-1383-5},
	urldate = {2018-02-07},
	volume = {222},
	year = {2017},
	bdsk-url-1 = {https://link.springer.com/article/10.1007/s00429-017-1383-5},
	bdsk-url-2 = {https://doi.org/10.1007/s00429-017-1383-5}}

@article{aizenberg_bidirectional_2015,
	abstract = {Modulating the activity of a specific type of cortical neuron can either improve or impair the ability to discriminate between tones of different frequencies and to associate danger with specific sounds.},
	author = {Aizenberg, Mark and Mwilambwe-Tshilobo, Laetitia and Briguglio, John J. and Natan, Ryan G. and Geffen, Maria N.},
	doi = {10.1371/journal.pbio.1002308},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BZGH5TPF/Aizenberg et al. - 2015 - Bidirectional Regulation of Innate and Learned Beh.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DDPGRWGQ/article.html:text/html},
	issn = {1545-7885},
	journal = {PLOS Biology},
	keywords = {Cognition, Learning, Neuronal tuning, Neurons, Conditioned response, Interneurons, Lasers, Mice},
	language = {en},
	month = dec,
	number = {12},
	pages = {e1002308},
	title = {Bidirectional {Regulation} of {Innate} and {Learned} {Behaviors} {That} {Rely} on {Frequency} {Discrimination} by {Cortical} {Inhibitory} {Neurons}},
	url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002308},
	urldate = {2018-02-14},
	volume = {13},
	year = {2015},
	bdsk-url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002308},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pbio.1002308}}

@article{aizenberg_bidirectional_2013,
	abstract = {Although emotional learning affects sensory acuity, little is known about how these changes are facilitated in the brain. We found that auditory fear conditioning in mice elicited either an increase or a decrease in frequency discrimination acuity depending on how specific the learned response was to the conditioned tone. Using reversible pharmacological inactivation, we found that the auditory cortex mediated learning-evoked changes in acuity in both directions.},
	author = {Aizenberg, Mark and Geffen, Maria Neimark},
	copyright = {2013 Nature Publishing Group},
	doi = {10.1038/nn.3443},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BU9LQ5BQ/Aizenberg et Geffen - 2013 - Bidirectional effects of aversive learning on perc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WBDBLE6U/nn.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = aug,
	number = {8},
	pages = {994--996},
	title = {Bidirectional effects of aversive learning on perceptual acuity are mediated by the sensory cortex},
	url = {https://www.nature.com/articles/nn.3443},
	urldate = {2018-02-14},
	volume = {16},
	year = {2013},
	bdsk-url-1 = {https://www.nature.com/articles/nn.3443},
	bdsk-url-2 = {https://doi.org/10.1038/nn.3443}}

@article{blackwell_progress_2017,
	abstract = {Advances in multi-neuron recordings and optogenetic manipulation have resulted in an interrogation of the function of specific cortical cell types in auditory cortex during sound processing. Here, the authors review this literature and discuss the merits of integrating computational approaches from dynamic network science.},
	author = {Blackwell, Jennifer M. and Geffen, Maria N.},
	copyright = {2017 The Author(s)},
	doi = {10.1038/s41467-017-01755-2},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Z99HWLX6/Blackwell et Geffen - 2017 - Progress and challenges for understanding the func.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XJFIEKCP/s41467-017-01755-2.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = dec,
	number = {1},
	pages = {2165},
	title = {Progress and challenges for understanding the function of cortical microcircuits in auditory processing},
	url = {https://www.nature.com/articles/s41467-017-01755-2},
	urldate = {2018-02-12},
	volume = {8},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-017-01755-2},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-017-01755-2}}

@article{kang_astrocyte-mediated_1998,
	abstract = {We investigated the role of astrocytes in activity-dependent modulation of inhibitory synaptic transmission in hippocampal slices. Repetitive firing of an interneuron decreased the probability of synaptic failures in spike-evoked inhibitory postsynaptic currents (unitary IPSCs) in CA1 pyramidal neurons. The GABAB-receptor antagonist CGP55845A abolished this effect. Direct stimulation of astrocytes, or application of the GABAB-receptor agonist baclofen, potentiated miniature inhibitory postsynaptic currents (mIPSCs) in pyramidal neurons. These effects were blocked by inhibition of astrocytic calcium signaling with the calcium chelator BAPTA or by antagonists of the ionotropic glutamate receptors. These observations suggest that interneuronal firing elicits a GABAB-receptor-mediated elevation of calcium in surrounding astrocytes, which in turn potentiates inhibitory transmission. Astrocytes may therefore be a necessary intermediary in activity-dependent modulation of inhibitory synapses in the hippocampus.},
	author = {Kang, J. and Jiang, L. and Goldman, S. A. and Nedergaard, M.},
	doi = {10.1038/3684},
	issn = {1097-6256},
	journal = {Nature Neuroscience},
	keywords = {Animals, Female, Male, ASTROCYTES, Synapses, Hippocampus, Neurons, Calcium Signaling, In Vitro Techniques, Neural Inhibition, Neuroglia, Rats, Rats, Sprague-Dawley, Receptors, AMPA, Receptors, N-Methyl-D-Aspartate, Synaptic Transmission},
	language = {eng},
	month = dec,
	number = {8},
	pages = {683--692},
	pmid = {10196584},
	title = {Astrocyte-mediated potentiation of inhibitory synaptic transmission},
	volume = {1},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1038/3684}}

@article{bazargani_astrocyte_2016,
	abstract = {The discovery that transient elevations of calcium concentration occur in astrocytes, and release 'gliotransmitters' which act on neurons and vascular smooth muscle, led to the idea that astrocytes are powerful regulators of neuronal spiking, synaptic plasticity and brain blood flow. These findings were challenged by a second wave of reports that astrocyte calcium transients did not mediate functions attributed to gliotransmitters and were too slow to generate blood flow increases. Remarkably, the tide has now turned again: the most important calcium transients occur in fine astrocyte processes not resolved in earlier studies, and new mechanisms have been discovered by which astrocyte [Ca2+]i is raised and exerts its effects. Here we review how this third wave of discoveries has changed our understanding of astrocyte calcium signaling and its consequences for neuronal function.},
	author = {Bazargani, Narges and Attwell, David},
	copyright = {2016 Nature Publishing Group},
	doi = {10.1038/nn.4201},
	file = {Snapshot:/Users/Cecile/Zotero/storage/26F3QRBS/nn.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = feb,
	number = {2},
	pages = {182--189},
	shorttitle = {Astrocyte calcium signaling},
	title = {Astrocyte calcium signaling: the third wave},
	url = {https://www.nature.com/articles/nn.4201},
	urldate = {2018-02-22},
	volume = {19},
	year = {2016},
	bdsk-url-1 = {https://www.nature.com/articles/nn.4201},
	bdsk-url-2 = {https://doi.org/10.1038/nn.4201}}

@article{lenard_acoustic_1969,
	author = {Lenard, H. G. and Bernuth, H. von and Hutt, S. J.},
	doi = {10.1016/0013-4694(69)90164-3},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/V4P4XLIJ/Lenard et al. - 1969 - Acoustic evoked responses in newborn infants the .pdf:application/pdf},
	issn = {0013-4694},
	journal = {Electroencephalography and Clinical Neurophysiology},
	language = {English},
	month = aug,
	number = {2},
	pages = {121--127},
	shorttitle = {Acoustic evoked responses in newborn infants},
	title = {Acoustic evoked responses in newborn infants: the influence of pitch and complexity of the stimulus},
	url = {http://www.clinph-journal.com/article/0013-4694(69)90164-3/fulltext},
	urldate = {2018-03-09},
	volume = {27},
	year = {1969},
	bdsk-url-1 = {http://www.clinph-journal.com/article/0013-4694(69)90164-3/fulltext},
	bdsk-url-2 = {https://doi.org/10.1016/0013-4694(69)90164-3}}

@article{klatt_analysis_1990,
	author = {Klatt, Dennis H. and Klatt, Laura C.},
	doi = {10.1121/1.398894},
	file = {Snapshot:/Users/Cecile/Zotero/storage/525HH6FL/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = feb,
	number = {2},
	pages = {820--857},
	title = {Analysis, synthesis, and perception of voice quality variations among female and male talkers},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.398894},
	urldate = {2018-03-08},
	volume = {87},
	year = {1990},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.398894},
	bdsk-url-2 = {https://doi.org/10.1121/1.398894}}

@incollection{lindblom_explaining_1990,
	abstract = {The H\&H theory is developed from evidence showing that speaking and listening are shaped by biologically general processes. Speech production is adaptive. Speakers can, and typically do, tune their performance according to communicative and situational demands, controlling the interplay between production-oriented factors on the one hand, and output-oriented constraints on the other. For the ideal speaker, H\&H claims that such adaptations reflect his tacit awareness of the listener's access to sources of information independent of the signal and his judgement of the short-term demands for explicit signal information. Hence speakers are expected to vary their output along a continuum of hyper- and hypospeech. The theory suggests that the lack of invariance that speech signals commonly exhibit (Perkell and Klatt 1986) is a direct consequence of this adaptive organization (cf MacNeilage 1970). Accordingly, in the H\&H program the quest for phonetic invariance is replaced by another research task: Explicating the notion of sufficient discriminability and defining the class of speech signals that meet that criterion.},
	author = {Lindblom, B.},
	booktitle = {Speech {Production} and {Speech} {Modelling}},
	doi = {10.1007/978-94-009-2037-8_16},
	file = {Snapshot:/Users/Cecile/Zotero/storage/SC6FQI8W/978-94-009-2037-8_16.html:text/html},
	isbn = {978-94-010-7414-8 978-94-009-2037-8},
	language = {en},
	pages = {403--439},
	publisher = {Springer, Dordrecht},
	series = {{NATO} {ASI} {Series}},
	shorttitle = {Explaining {Phonetic} {Variation}},
	title = {Explaining {Phonetic} {Variation}: {A} {Sketch} of the {H}\&amp;{H} {Theory}},
	url = {https://link.springer.com/chapter/10.1007/978-94-009-2037-8_16},
	urldate = {2018-03-12},
	year = {1990},
	bdsk-url-1 = {https://link.springer.com/chapter/10.1007/978-94-009-2037-8_16},
	bdsk-url-2 = {https://doi.org/10.1007/978-94-009-2037-8_16}}

@book{perkell_invariance_2014,
	abstract = {First published in 1986. Routledge is an imprint of Taylor \& Francis, an informa company.},
	author = {Perkell, J. S. and Klatt, D. H.},
	isbn = {978-1-317-76829-6},
	keywords = {Medical / Audiology \& Speech Pathology, Psychology / General, Psychology / Cognitive Psychology \& Cognition, Psychology / Experimental Psychology},
	language = {en},
	month = jan,
	note = {Google-Books-ID: HsmYAgAAQBAJ},
	publisher = {Psychology Press},
	title = {Invariance and {Variability} in {Speech} {Processes}},
	year = {2014}}

@article{gervain_role_2018,
	abstract = {Human infants are born linguistic citizens of the world, possessing broad-based, universal perceptual and learning abilities that allow them to start {\ldots}},
	author = {Gervain, Judit},
	doi = {10.1016/j.cobeha.2018.02.004},
	file = {Snapshot:/Users/Cecile/Zotero/storage/JKJHVBX4/S2352154617301365.html:text/html},
	issn = {2352-1546},
	journal = {Current Opinion in Behavioral Sciences},
	language = {en},
	month = jun,
	pages = {62--67},
	title = {The role of prenatal experience in language development},
	url = {https://www.sciencedirect.com/science/article/pii/S2352154617301365},
	urldate = {2018-03-18},
	volume = {21},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S2352154617301365},
	bdsk-url-2 = {https://doi.org/10.1016/j.cobeha.2018.02.004}}

@article{perani_bilingual_1998,
	abstract = {Functional imaging methods show differences in the pattern of cerebral activation associated with the subject's native language (L1) compared with a second language (L2). In a recent PET investigation on bilingualism we showed that auditory processing of stories in L1 (Italian) engages the temporal lobes and temporoparietal cortex more extensively than L2 (English). However, in that study the Italian subjects learned L2 late and attained a fair, but not an excellent command of this language (low proficiency, late acquisition bilinguals). Thus, the different patterns of activation could be ascribed either to age of acquisition or to proficiency level. In the current study we use a similar paradigm to evaluate the effect of early and late acquisition of L2 in highly proficient bilinguals. We studied a group of Italian-English bilinguals who acquired L2 after the age of 10 years (high proficiency, late acquisition bilinguals) and a group of Spanish-Catalan bilinguals who acquired L2 before the age of 4 years (high proficiency, early acquisition bilinguals). The differing cortical responses we had observed when low proficiency volunteers listened to stories in L1 and L2 were not found in either of the high proficiency groups in this study. Several brain areas, similar to those observed for L1 in low proficiency bilinguals, were activated by L2. These findings suggest that, at least for pairs of L1 and L2 languages that are fairly close, attained proficiency is more important than age of acquisition as a determinant of the cortical representation of L2.},
	author = {Perani, D. and Paulesu, E. and Galles, N. S. and Dupoux, E. and Dehaene, S. and Bettinardi, V. and Cappa, S. F. and Fazio, F. and Mehler, J.},
	doi = {10.1093/brain/121.10.1841},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9CDR2SII/Perani et al. - 1998 - The bilingual brain. Proficiency and age of acquis.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/6ZDUQDDE/Perani et al. - 1998 - The bilingual brain. Proficiency and age of acquis.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMX2UAPP/265619.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/MM8HECCI/265619.html:text/html},
	issn = {0006-8950},
	journal = {Brain},
	language = {en},
	month = oct,
	number = {10},
	pages = {1841--1852},
	title = {The bilingual brain. {Proficiency} and age of acquisition of the second language.},
	url = {https://academic.oup.com/brain/article/121/10/1841/265619},
	urldate = {2018-03-20},
	volume = {121},
	year = {1998},
	bdsk-url-1 = {https://academic.oup.com/brain/article/121/10/1841/265619},
	bdsk-url-2 = {https://doi.org/10.1093/brain/121.10.1841}}

@article{maryn_acoustic_2009,
	author = {Maryn, Youri and Roy, Nelson and De Bodt, Marc and Van Cauwenberge, Paul and Corthals, Paul},
	doi = {10.1121/1.3224706},
	file = {Snapshot:/Users/Cecile/Zotero/storage/VNC3FDFX/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = nov,
	number = {5},
	pages = {2619--2634},
	shorttitle = {Acoustic measurement of overall voice quality},
	title = {Acoustic measurement of overall voice quality: {A} meta-analysis},
	url = {https://asa.scitation.org/doi/10.1121/1.3224706},
	volume = {126},
	year = {2009},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.3224706},
	bdsk-url-2 = {https://doi.org/10.1121/1.3224706}}

@article{mcgettigan_social_2015,
	abstract = {The social life of voices: studying the neural bases for the expression and perception of the self and others during spoken communication},
	author = {McGettigan, Carolyn},
	doi = {10.3389/fnhum.2015.00129},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CVH6C4JS/McGettigan - 2015 - The social life of voices studying the neural bas.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	keywords = {Functional Neuroimaging, Voice, speech perception, social neuroscience, speech production, Identity, Speech Perception},
	language = {English},
	shorttitle = {The social life of voices},
	title = {The social life of voices: studying the neural bases for the expression and perception of the self and others during spoken communication},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00129/full#B22},
	urldate = {2018-03-29},
	volume = {9},
	year = {2015},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00129/full#B22},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2015.00129}}

@article{rosen_adaptation_1999,
	author = {Rosen, Stuart and Faulkner, Andrew and Wilkinson, Lucy},
	doi = {10.1121/1.428215},
	file = {Snapshot:/Users/Cecile/Zotero/storage/AX4TZX9X/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = nov,
	number = {6},
	pages = {3629--3636},
	shorttitle = {Adaptation by normal listeners to upward spectral shifts of speech},
	title = {Adaptation by normal listeners to upward spectral shifts of speech: {Implications} for cochlear implants},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.428215},
	volume = {106},
	year = {1999},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.428215},
	bdsk-url-2 = {https://doi.org/10.1121/1.428215}}

@article{belin_voice-selective_2000,
	abstract = {The human voice contains in its acoustic structure a wealth of information on the speaker's identity and emotional state which we perceive with remarkable ease and accuracy1,2,3. Although the perception of speaker-related features of voice plays a major role in human communication, little is known about its neural basis4,5,6,7. Here we show, using functional magnetic resonance imaging in human volunteers, that voice-selective regions can be found bilaterally along the upper bank of the superior temporal sulcus (STS). These regions showed greater neuronal activity when subjects listened passively to vocal sounds, whether speech or non-speech, than to non-vocal environmental sounds. Central STS regions also displayed a high degree of selectivity by responding significantly more to vocal sounds than to matched control stimuli, including scrambled voices and amplitude-modulated noise. Moreover, their response to stimuli degraded by frequency filtering paralleled the subjects' behavioural performance in voice-perception tasks that used these stimuli. The voice-selective areas in the STS may represent the counterpart of the face-selective areas in human visual cortex8,9; their existence sheds new light on the functional architecture of the human auditory cortex.},
	author = {Belin, Pascal and Zatorre, Robert J. and Lafaille, Philippe and Ahad, Pierre and Pike, Bruce},
	copyright = {2000 Nature Publishing Group},
	doi = {10.1038/35002078},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/YJBYBB34/Belin et al. - 2000 - Voice-selective areas in human auditory cortex.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/FXWXUKTB/35002078.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = jan,
	number = {6767},
	pages = {309--312},
	title = {Voice-selective areas in human auditory cortex},
	url = {https://www.nature.com/articles/35002078},
	urldate = {2018-03-30},
	volume = {403},
	year = {2000},
	bdsk-url-1 = {https://www.nature.com/articles/35002078},
	bdsk-url-2 = {https://doi.org/10.1038/35002078}}

@article{keitel_perceptually_2018,
	abstract = {During online speech processing, our brain tracks the acoustic fluctuations in speech at different timescales. Previous research has focused on generic timescales (for example, delta or theta bands) that are assumed to map onto linguistic features such as prosody or syllables. However, given the high intersubject variability in speaking patterns, such a generic association between the timescales of brain activity and speech properties can be ambiguous. Here, we analyse speech tracking in source-localised magnetoencephalographic data by directly focusing on timescales extracted from statistical regularities in our speech material. This revealed widespread significant tracking at the timescales of phrases (0.6--1.3 Hz), words (1.8--3 Hz), syllables (2.8--4.8 Hz), and phonemes (8--12.4 Hz). Importantly, when examining its perceptual relevance, we found stronger tracking for correctly comprehended trials in the left premotor (PM) cortex at the phrasal scale as well as in left middle temporal cortex at the word scale. Control analyses using generic bands confirmed that these effects were specific to the speech regularities in our stimuli. Furthermore, we found that the phase at the phrasal timescale coupled to power at beta frequency (13--30 Hz) in motor areas. This cross-frequency coupling presumably reflects top-down temporal prediction in ongoing speech perception. Together, our results reveal specific functional and perceptually relevant roles of distinct tracking and cross-frequency processes along the auditory--motor pathway.},
	author = {Keitel, Anne and Gross, Joachim and Kayser, Christoph},
	doi = {10.1371/journal.pbio.2004473},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/GY7JVKUV/Keitel et al. - 2018 - Perceptually relevant speech tracking in auditory .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/F43YRDUX/article.html:text/html},
	issn = {1545-7885},
	journal = {PLOS Biology},
	keywords = {Syllables, Speech, Speech signal processing, Linguistics, Motor system, Phonemes, Syntax, magnetoencephalography},
	language = {en},
	month = mar,
	number = {3},
	pages = {e2004473},
	title = {Perceptually relevant speech tracking in auditory and motor cortex reflects distinct linguistic features},
	url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2004473},
	urldate = {2018-04-03},
	volume = {16},
	year = {2018},
	bdsk-url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2004473},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pbio.2004473}}

@article{kello_hierarchical_2017,
	abstract = {Humans talk, sing and play music. Some species of birds and whales sing long and complex songs. All these behaviours and sounds exhibit hierarchical structure---syllables and notes are positioned within words and musical phrases, words and motives in sentences and musical phrases, and so on. We developed a new method to measure and compare hierarchical temporal structures in speech, song and music. The method identifies temporal events as peaks in the sound amplitude envelope, and quantifies event clustering across a range of timescales using Allan factor (AF) variance. AF variances were analysed and compared for over 200 different recordings from more than 16 different categories of signals, including recordings of speech in different contexts and languages, musical compositions and performances from different genres. Non-human vocalizations from two bird species and two types of marine mammals were also analysed for comparison. The resulting patterns of AF variance across timescales were distinct to each of four natural categories of complex sound: speech, popular music, classical music and complex animal vocalizations. Comparisons within and across categories indicated that nested clustering in longer timescales was more prominent when prosodic variation was greater, and when sounds came from interactions among individuals, including interactions between speakers, musicians, and even killer whales. Nested clustering also was more prominent for music compared with speech, and reflected beat structure for popular music and self-similarity across timescales for classical music. In summary, hierarchical temporal structures reflect the behavioural and social processes underlying complex vocalizations and musical performances.},
	author = {Kello, Christopher T. and Bella, Simone Dalla and M{\'e}d{\'e}, Butovens and Balasubramaniam, Ramesh},
	copyright = {{\copyright} 2017 The Author(s). http://royalsocietypublishing.org/licencePublished by the Royal Society. All rights reserved.},
	doi = {10.1098/rsif.2017.0231},
	file = {Kello et al. - 2017 - Hierarchical temporal structure in music, speech a.pdf:/Users/Cecile/Zotero/storage/U8ZLEEX8/Kello et al. - 2017 - Hierarchical temporal structure in music, speech a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3EF9K9DQ/20170231.html:text/html},
	issn = {1742-5689, 1742-5662},
	journal = {Journal of The Royal Society Interface},
	language = {en},
	month = oct,
	number = {135},
	pages = {20170231},
	pmid = {29021158},
	shorttitle = {Hierarchical temporal structure in music, speech and animal vocalizations},
	title = {Hierarchical temporal structure in music, speech and animal vocalizations: jazz is like a conversation, humpbacks sing like hermit thrushes},
	url = {http://rsif.royalsocietypublishing.org/content/14/135/20170231},
	urldate = {2018-04-03},
	volume = {14},
	year = {2017},
	bdsk-url-1 = {http://rsif.royalsocietypublishing.org/content/14/135/20170231},
	bdsk-url-2 = {https://doi.org/10.1098/rsif.2017.0231}}

@book{mehler_neonate_1985,
	author = {Mehler, Jacques A. and Fox, Robin},
	isbn = {978-0-89859-345-7},
	keywords = {Psychology / General},
	language = {en},
	publisher = {L. Erlbaum Associates},
	shorttitle = {Neonate {Cognition}},
	title = {Neonate {Cognition}: {Beyond} the {Blooming} {Buzzing} {Confusion}},
	year = {1985}}

@article{dehaene-lambertz_electrophysiological_2001,
	abstract = {At least two fundamental properties should be present in a network computing a phonetic representation: categorical perception and normalization across different utterances. Normalization processes were studied at birth by recording high density evoked potentials to strings of syllables in sleeping neonates. We compared the response to a change of phoneme when irrelevant speaker variation was present or absent. A mismatch response was recorded at the same latency in both cases, suggesting that relevant phonetic information was extracted from the irrelevant variation. Combined with our previous work showing that the mismatch response is sensitive to categorical perception in infants, this result suggests that a phonetic network like that of adults, is already present in the infant brain. Furthermore, efficient phonetic processing does not require attention.},
	author = {Dehaene-Lambertz, G. and Pena, M.},
	file = {Dehaene-Lambertz et Pena - 2001 - Electrophysiological evidence for automatic phonet.pdf:/Users/Cecile/Zotero/storage/XMI8JNLP/Dehaene-Lambertz et Pena - 2001 - Electrophysiological evidence for automatic phonet.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/R74MVQJM/articleviewer.html:text/html},
	issn = {0959-4965},
	journal = {NeuroReport},
	language = {en-US},
	month = oct,
	number = {14},
	pages = {3155},
	title = {Electrophysiological evidence for automatic phonetic processing in neonates},
	url = {https://journals.lww.com/neuroreport/pages/articleviewer.aspx?year=2001&issue=10080&article=00034&type=abstract},
	urldate = {2018-04-23},
	volume = {12},
	year = {2001},
	bdsk-url-1 = {https://journals.lww.com/neuroreport/pages/articleviewer.aspx?year=2001&issue=10080&article=00034&type=abstract}}

@article{ecklund-flores_asymmetric_1996,
	abstract = {Functional asymmetries were examined in 59 newborns by recording headturns from midline to bin-aurally equivalent sounds. Results showed that robust, asymmetric pattern of headturning occurred in most newborns' responses to binaurally presented unfiltered female speech sounds, with increased rightward orientation demonstrated in five replications. Female speech that was modified by attenuation of frequencies above 500 Hz, as well as speech attenuated below 1500 Hz and above 3000 Hz, resulted in a significant rightward bias in headturning. In contrast, female speech attenuated below 3500 Hz, and continuous, repetitive stimuli such as heartbeat sounds and phrases of speech repeated at the rate of heartbeat (termed heartspeech), failed to generate the rightward orientation bias. These results suggest that female speech sounds, particularly low-frequency sounds related to the naturally occurring prosodic characteristics of speech, are a salient class of stimuli for the organization of lateral biases in orienting in newborns. {\copyright} 1996 John Wiley \& Sons, Inc.},
	annote = {*},
	author = {Ecklund-Flores, Lisa and Turkewitz, Gerald},
	copyright = {Copyright {\copyright} 1996 John Wiley \& Sons, Inc.},
	date-modified = {2022-04-05 16:54:17 +0200},
	doi = {10.1002/(SICI)1098-2302(199604)29:3<205::AID-DEV2>3.0.CO;2-V},
	file = {Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:/Users/Cecile/Zotero/storage/ME9WP2MY/Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:application/pdf;Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:/Users/Cecile/Zotero/storage/KS3CEAUV/Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UPCVM56Y/(SICI)1098-2302(199604)293205AID-DEV23.0.html:text/html},
	issn = {1098-2302},
	journal = {Developmental Psychobiology},
	language = {en},
	month = apr,
	number = {3},
	pages = {205--217},
	title = {Asymmetric headturning to speech and nonspeech in human newborns},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2302%28199604%2929%3A3%3C205%3A%3AAID-DEV2%3E3.0.CO%3B2-V},
	urldate = {2018-04-24},
	volume = {29},
	year = {1996},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2302%28199604%2929%3A3%3C205%3A%3AAID-DEV2%3E3.0.CO%3B2-V},
	bdsk-url-2 = {https://doi.org/10.1002/(SICI)1098-2302(199604)29:3%3C205::AID-DEV2%3E3.0.CO;2-V}}

@article{liberman_perception_1967,
	author = {Liberman, A. M. and Cooper, F. S. and Shankweiler, D. P. and Studdert-Kennedy, M.},
	doi = {10.1037/h0020279},
	file = {Liberman et al. - 1967 - Perception of the speech code..pdf:/Users/Cecile/Zotero/storage/UYB9ULJZ/Liberman et al. - 1967 - Perception of the speech code..pdf:application/pdf},
	issn = {1939-1471, 0033-295X},
	journal = {Psychological Review},
	language = {en},
	number = {6},
	pages = {431--461},
	title = {Perception of the speech code.},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0020279},
	urldate = {2018-04-21},
	volume = {74},
	year = {1967},
	bdsk-url-1 = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0020279},
	bdsk-url-2 = {https://doi.org/10.1037/h0020279}}

@incollection{silva_eeg:_2009,
	abstract = {The existence of the electrical activity of the brain (i.e. the electroencephalogram or EEG) was discovered more than a century ago by Caton. After the demonstration that the EEG could be recorded from the human scalp by Berger in the 1920s, it made a slow start before it became accepted as a method of analysis of brain functions in health and disease. It is interesting to note that this acceptance came only after the demonstration by Adrian and Mathews (1934) that the EEG, namely the alpha rhythm, was likely generated in the occipital lobes in man, and was not artefactual. However, the neuronal sources of the alpha rhythm remained undefined until the 1970s, when we demonstrated, in dog, that the alpha rhythm is generated by a dipole layer cantered at layers IV and V of the visual cortex (Lopes da Silva and Storm van Leeuwen 1977). It may be not surprising that the mechanisms of generation and the functional significance of the EEG remained controversial for a relatively long time considering the complexity of the underlying systems of neuronal generators on the one hand and the rather involved transfer of signals from the cortical surface to the scalp due to the topological and electrical properties of the volume conductor (brain, cerebrospinal fluid, skull, scalp) on the other. The EEG consists of the summed electrical activities of populations of neurons, with a modest contribution from glial cells. The neurons are excitable cells with characteristic intrinsic electrical properties, and their activity produces electrical and magnetic fields. These fields may be recorded by means of electrodes at a short distance from the sources (the local EEG or local field potentials, LFPs), or from the cortical surface (the electrocorticogram or ECoG), or at longer distances, even from the scalp (i.e. the EEG, in the most common sense). The associated MEG is usually recorded via sensors that are highly sensitive to changes in the very weak neuronal magnetic fields, which are placed at short distances around the scalp.},
	author = {Silva, Fernando Lopes da},
	booktitle = {{EEG} - {fMRI}},
	doi = {10.1007/978-3-540-87919-0_2},
	file = {Snapshot:/Users/Cecile/Zotero/storage/I4QFN232/10.html:text/html},
	isbn = {978-3-540-87918-3 978-3-540-87919-0},
	language = {en},
	pages = {19--38},
	publisher = {Springer, Berlin, Heidelberg},
	shorttitle = {{EEG}},
	title = {{EEG}: {Origin} and {Measurement}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-87919-0_2},
	urldate = {2018-05-06},
	year = {2009},
	bdsk-url-1 = {https://link.springer.com/chapter/10.1007/978-3-540-87919-0_2},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-540-87919-0_2}}

@article{leong_acoustic-emergent_2015,
	abstract = {When acquiring language, young children may use acoustic spectro-temporal patterns in speech to derive phonological units in spoken language (e.g., prosodic stress patterns, syllables, phonemes). Children appear to learn acoustic-phonological mappings rapidly, without direct instruction, yet the underlying developmental mechanisms remain unclear. Across different languages, a relationship between amplitude envelope sensitivity and phonological development has been found, suggesting that children may make use of amplitude modulation (AM) patterns within the envelope to develop a phonological system. Here we present the Spectral Amplitude Modulation Phase Hierarchy (S-AMPH) model, a set of algorithms for deriving the dominant AM patterns in child-directed speech (CDS). Using Principal Components Analysis, we show that rhythmic CDS contains an AM hierarchy comprising 3 core modulation timescales. These timescales correspond to key phonological units: prosodic stress (Stress AM, {\textasciitilde}2 Hz), syllables (Syllable AM, {\textasciitilde}5 Hz) and onset-rime units (Phoneme AM, {\textasciitilde}20 Hz). We argue that these AM patterns could in principle be used by na{\"\i}ve listeners to compute acoustic-phonological mappings without lexical knowledge. We then demonstrate that the modulation statistics within this AM hierarchy indeed parse the speech signal into a primitive hierarchically-organised phonological system comprising stress feet (proto-words), syllables and onset-rime units. We apply the S-AMPH model to two other CDS corpora, one spontaneous and one deliberately-timed. The model accurately identified 72--82\% (freely-read CDS) and 90--98\% (rhythmically-regular CDS) stress patterns, syllables and onset-rime units. This in-principle demonstration that primitive phonology can be extracted from speech AMs is termed Acoustic-Emergent Phonology (AEP) theory. AEP theory provides a set of methods for examining how early phonological development is shaped by the temporal modulation structure of speech across languages. The S-AMPH model reveals a crucial developmental role for stress feet (AMs {\textasciitilde}2 Hz). Stress feet underpin different linguistic rhythm typologies, and speech rhythm underpins language acquisition by infants in all languages.},
	author = {Leong, Victoria and Goswami, Usha},
	doi = {10.1371/journal.pone.0144411},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/6Y236JXW/Leong et Goswami - 2015 - Acoustic-Emergent Phonology in the Amplitude Envel.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P7GTPNPX/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Acoustics, Phonology, Syllables, Speech, Speech signal processing, Linguistics, Principal component analysis, Vowels},
	language = {en},
	month = dec,
	number = {12},
	pages = {e0144411},
	title = {Acoustic-{Emergent} {Phonology} in the {Amplitude} {Envelope} of {Child}-{Directed} {Speech}},
	url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144411},
	urldate = {2018-06-05},
	volume = {10},
	year = {2015},
	bdsk-url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144411},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0144411}}

@inproceedings{guiraud_perception_2018,
	abstract = {According to the "prosodic phrasing" hypothesis (Cumming et al., 2015), children with Developmental Language Disorder (DLD) show difficulty extracting low-frequency rhythmic information from the speech signal, hindering syllabic segmentation and leading to phonological and morpho-syntactic impairments. We tested this hypothesis by measuring, using magnetoencephalography, the synchronization between cortical oscillations and speech amplitude envelope in children with DLD paired to typically-developing children when listening to sentences naturally produced at a normal or rapid rate. Our results in the theta frequency band (4-7 Hz) show reduced brain-to-speech coupling in children with DLD, as compared with typically-developing children, 1) in the right auditory cortex at normal rate and 2) left (pre)motor regions at fast rate. To our knowledge, this study brings the first piece of evidence for atypical cortical alignment to speech syllabic rhythm in children with DLD.},
	address = {Aix-en-Provence, France},
	author = {Guiraud, H{\'e}l{\`e}ne and Hincapi{\'e}, Ana-Sofia and Jerbi, Karim and Boulenger, V{\'e}ronique},
	booktitle = {Proc. {XXXIIe} {Journ{\'e}es} d'{\'E}tudes sur la {Parole}},
	doi = {10.21437/JEP.2018-26},
	file = {H{\'e}l{\`e}ne et al. - 2018 - Perception de la parole et oscillations c{\'e}r{\'e}brales.pdf:/Users/Cecile/Zotero/storage/HJHYQMBR/H{\'e}l{\`e}ne et al. - 2018 - Perception de la parole et oscillations c{\'e}r{\'e}brales.pdf:application/pdf},
	language = {fr},
	month = jun,
	pages = {222--230},
	publisher = {ISCA},
	title = {Perception de la parole et oscillations c{\'e}r{\'e}brales chez les enfants neurotypiques et dysphasiques.},
	url = {http://www.isca-speech.org/archive/JEP_2018/abstracts/189775.html},
	urldate = {2018-06-14},
	year = {2018},
	bdsk-url-1 = {http://www.isca-speech.org/archive/JEP_2018/abstracts/189775.html},
	bdsk-url-2 = {https://doi.org/10.21437/JEP.2018-26}}

@article{dudley_carrier_1940,
	abstract = {Speech synthesizing is here discussed in the terminology of carrier circuits. The speaker is pictured as a sort of radio broadcast transmitter with the message to be sent out originating in the studio of the talker's brain and manifesting itself in muscular wave motions in the vocal tract. Although these motions contain the message, they are inaudible because they occur at syllabic rates. An audible sound is needed to pass the message into the listener's ear. This is provided by the carrier in the form of a group of higher frequency waves in the audible range set up by oscillatory action at the vocal cords or elsewhere in the vocal tract. These carrier waves either in their generation or their transmission are modulated by the message waves to form the speech waves. As the speech waves contain the message information on an audible carrier they are adapted to broadcast reception by receiving sets in the form of listeners' ears. The message is then recovered by the listeners' minds.},
	author = {Dudley, Homer},
	copyright = {{\copyright} 1940 The Bell System Technical Journal},
	doi = {10.1002/j.1538-7305.1940.tb00843.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UX5VHRT6/Dudley - The Carrier Nature of Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J8BTZCAA/j.1538-7305.1940.tb00843.html:text/html},
	issn = {1538-7305},
	journal = {Bell System Technical Journal},
	language = {en},
	number = {4},
	pages = {495--515},
	title = {The {Carrier} {Nature} of {Speech}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1940.tb00843.x},
	urldate = {2018-06-05},
	volume = {19},
	year = {1940},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1940.tb00843.x},
	bdsk-url-2 = {https://doi.org/10.1002/j.1538-7305.1940.tb00843.x}}

@article{rendall_pitch_2005,
	abstract = {Key voice features--fundamental frequency (F0) and formant frequencies--can vary extensively between individuals. Much of the variation can be traced to differences in the size of the larynx and vocal-tract cavities, but whether these differences in turn simply reflect differences in speaker body size (i.e., neutral vocal allometry) remains unclear. Quantitative analyses were therefore undertaken to test the relationship between speaker body size and voice F0 and formant frequencies for human vowels. To test the taxonomic generality of the relationships, the same analyses were conducted on the vowel-like grunts of baboons, whose phylogenetic proximity to humans and similar vocal production biology and voice acoustic patterns recommend them for such comparative research. For adults of both species, males were larger than females and had lower mean voice F0 and formant frequencies. However, beyond this, F0 variation did not track body-size variation between the sexes in either species, nor within sexes in humans. In humans, formant variation correlated significantly with speaker height but only in males and not in females. Implications for general vocal allometry are discussed as are implications for speech origins theories, and challenges to them, related to laryngeal position and vocal tract length.},
	author = {Rendall, Drew and Kollias, Sophie and Ney, Christina and Lloyd, Peter},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	keywords = {Adolescent, Adult, Animals, Female, Humans, Male, Phonetics, Sound Spectrography, Species Specificity, Speech Acoustics, Vocalization, Animal, Biometry, Body Size, Papio, Phonation, Voice Quality},
	language = {eng},
	month = feb,
	number = {2},
	pages = {944--955},
	pmid = {15759713},
	shorttitle = {Pitch ({F0}) and formant profiles of human vowels and vowel-like baboon grunts},
	title = {Pitch ({F0}) and formant profiles of human vowels and vowel-like baboon grunts: the role of vocalizer body size and voice-acoustic allometry},
	volume = {117},
	year = {2005}}

@article{chandrasekaran_natural_2009,
	abstract = {Humans, like other animals, are exposed to a continuous stream of signals, which are dynamic, multimodal, extended, and time varying in nature. This complex input space must be transduced and sampled by our sensory systems and transmitted to the brain where it can guide the selection of appropriate actions. To simplify this process, it's been suggested that the brain exploits statistical regularities in the stimulus space. Tests of this idea have largely been confined to unimodal signals and natural scenes. One important class of multisensory signals for which a quantitative input space characterization is unavailable is human speech. We do not understand what signals our brain has to actively piece together from an audiovisual speech stream to arrive at a percept versus what is already embedded in the signal structure of the stream itself. In essence, we do not have a clear understanding of the natural statistics of audiovisual speech. In the present study, we identified the following major statistical features of audiovisual speech. First, we observed robust correlations and close temporal correspondence between the area of the mouth opening and the acoustic envelope. Second, we found the strongest correlation between the area of the mouth opening and vocal tract resonances. Third, we observed that both area of the mouth opening and the voice envelope are temporally modulated in the 2--7 Hz frequency range. Finally, we show that the timing of mouth movements relative to the onset of the voice is consistently between 100 and 300 ms. We interpret these data in the context of recent neural theories of speech which suggest that speech communication is a reciprocally coupled, multisensory event, whereby the outputs of the signaler are matched to the neural processes of the receiver.},
	author = {Chandrasekaran, Chandramouli and Trubanova, Andrea and Stillittano, S{\'e}bastien and Caplier, Alice and Ghazanfar, Asif A.},
	doi = {10.1371/journal.pcbi.1000436},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BJ6TKW33/Chandrasekaran et al. - 2009 - The Natural Statistics of Audiovisual Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5VUYW84J/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Speech, Vision, Audio signal processing, Speech signal processing, Acoustic signals, Lips, Mouth, Visual signals},
	language = {en},
	month = jul,
	number = {7},
	pages = {e1000436},
	title = {The {Natural} {Statistics} of {Audiovisual} {Speech}},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000436},
	urldate = {2018-05-10},
	volume = {5},
	year = {2009},
	bdsk-url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000436},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1000436}}

@article{lee_speaker_2009,
	author = {Lee, Tchao-Yang and Tao, Liang and Bond, Z. S.},
	doi = {10.1016/j.wocn.2008.08.001},
	journal = {Journal of Phonetics},
	month = jan,
	number = {1},
	title = {Speaker variability and context in the identification of fragmented {Mandarin} tones by native and non-native listeners},
	url = {https://www.sciencedirect.com/science/article/pii/S0095447008000405},
	volume = {37},
	year = {2009},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0095447008000405},
	bdsk-url-2 = {https://doi.org/10.1016/j.wocn.2008.08.001}}

@article{varnet_cross-linguistic_2017,
	author = {Varnet, L{\'e}o and Ortiz-Barajas, Maria Clemencia and Erra, Ram{\'o}n Guevara and Gervain, Judit and Lorenzi, Christian},
	doi = {10.1121/1.5006179},
	file = {Snapshot:/Users/Cecile/Zotero/storage/QG9M7HUR/1.html:text/html;Varnet et al. - 2017 - A cross-linguistic study of speech modulation spec.pdf:/Users/Cecile/Zotero/storage/I3ZV6LYS/Varnet et al. - 2017 - A cross-linguistic study of speech modulation spec.pdf:application/pdf},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = oct,
	number = {4},
	pages = {1976--1989},
	title = {A cross-linguistic study of speech modulation spectra},
	url = {https://asa.scitation.org/doi/10.1121/1.5006179},
	urldate = {2018-05-08},
	volume = {142},
	year = {2017},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.5006179},
	bdsk-url-2 = {https://doi.org/10.1121/1.5006179}}

@article{kreitewolf_neural_2014,
	abstract = {Understanding speech from different speakers is a sophisticated process, particularly because the same acoustic parameters convey important information about both the speech message and the person speaking. How the human brain accomplishes speech recognition under such conditions is unknown.
One view is that speaker information is discarded at early processing stages and not used for understanding the speech message. An alternative view is that speaker information is exploited to improve speech recognition. Consistent with the latter view, previous research identified functional interactions between the left- and the right-hemispheric superior temporal sulcus/gyrus, which process speech- and speaker-specific vocal tract parameters, respectively. Vocal tract parameters are one of the two major acoustic features that determine both speaker identity and speech message (phonemes). Here, using functional magnetic resonance imaging (fMRI), we show that a similar interaction exists for glottal fold parameters between the left and right Heschl's gyri. Glottal fold parameters are the other main acoustic feature that determines speaker identity and speech message (linguistic prosody).
The findings suggest that interactions between left- and right-hemispheric areas are specific to the processing of different acoustic features of speech and speaker, and that they represent a general neural mechanism when understanding speech from different speakers.},
	author = {Kreitewolf, Jens and Gaudrain, Etienne and von Kriegstein, Katharina},
	doi = {10.1016/j.neuroimage.2014.01.005},
	journal = {NeuroImage},
	language = {English},
	month = may,
	pages = {375--385},
	title = {A neural mechanism for recognizing speech spoken by different speakers},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811914000160?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_recommender_email},
	volume = {91},
	year = {2014},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811914000160?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_recommender_email},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2014.01.005}}

@article{vaissiere_language-independent_1983-1,
	abstract = {The purpose of this paper is to investigate the similarities in form and function of prosody among diverse languages: - the pause - Fo declinaison tendency and its control - natural Fo range and its control - Resetting of the baseline - the alternance between Fo rise and fall - Fo continuation rise and final fall - intensity fall - final lengthening the differences between the languages seem to be due to - a different timing of the same gestures - a different order of priorities - a different relationship betwen Fo, duration and intensity},
	author = {Vaissi{\`e}re, Jacqueline},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/C96H2ZMP/Vaissi{\`e}re - 1983 - Language-independent prosodic features.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YBXHYQNK/halshs-00703571.html:text/html},
	language = {en},
	pages = {53--65},
	title = {Language-independent prosodic features},
	url = {https://halshs.archives-ouvertes.fr/halshs-00703571/document},
	urldate = {2018-06-07},
	year = {1983},
	bdsk-url-1 = {https://halshs.archives-ouvertes.fr/halshs-00703571/document}}

@article{nourski_temporal_2009,
	abstract = {Speech comprehension relies on temporal cues contained in the speech envelope, and the auditory cortex has been implicated as playing a critical role in encoding this temporal information. We investigated auditory cortical responses to speech stimuli in subjects undergoing invasive electrophysiological monitoring for pharmacologically refractory epilepsy. Recordings were made from multi-contact electrodes implanted in Heschl's gyrus (HG). Speech sentences, time-compressed from 0.75 to 0.20 of natural speaking rate, elicited average evoked potentials (AEPs) and increases in event-related band power (ERBP) of cortical high frequency (70--250 Hz) activity. Cortex of posteromedial HG, the presumed core of human auditory cortex, represented the envelope of speech stimuli in the AEP and ERBP. Envelope-following in ERBP, but not in AEP, was evident in both language dominant and non-dominant hemispheres for relatively high degrees of compression where speech was not comprehensible. Compared to posteromedial HG, responses from anterolateral HG --- an auditory belt field --- exhibited longer latencies, lower amplitudes and little or no time locking to the speech envelope. The ability of the core auditory cortex to follow the temporal speech envelope over a wide range of speaking rates leads us to conclude that such capacity in itself is not a limiting factor for speech comprehension.},
	author = {Nourski, Kirill V. and Reale, Richard A. and Oya, Hiroyuki and Kawasaki, Hiroto and Kovach, Christopher K. and Chen, Haiming and Howard, Matthew A. and Brugge, John F.},
	doi = {10.1523/JNEUROSCI.3065-09.2009},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/P2858G3T/Nourski et al. - 2009 - Temporal envelope of time-compressed speech repres.pdf:application/pdf},
	issn = {0270-6474},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	month = dec,
	number = {49},
	pages = {15564--15574},
	pmcid = {PMC2851231},
	pmid = {20007480},
	title = {Temporal envelope of time-compressed speech represented in the human auditory cortex},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2851231/},
	urldate = {2018-06-14},
	volume = {29},
	year = {2009},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2851231/},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3065-09.2009}}

@article{moore_role_2008,
	abstract = {Complex broadband sounds are decomposed by the auditory filters into a series of relatively narrowband signals, each of which can be considered as a slowly varying envelope (E) superimposed on a more rapid temporal fine structure (TFS). Both E and TFS information are represented in the timing of neural discharges, although TFS information as defined here depends on phase locking to individual cycles of the stimulus waveform. This paper reviews the role played by TFS in masking, pitch perception, and speech perception and concludes that cues derived from TFS play an important role for all three. TFS may be especially important for the ability to ``listen in the dips'' of fluctuating background sounds when detecting nonspeech and speech signals. Evidence is reviewed suggesting that cochlear hearing loss reduces the ability to use TFS cues. The perceptual consequences of this, and reasons why it may happen, are discussed.},
	author = {Moore, Brian C. J.},
	doi = {10.1007/s10162-008-0143-x},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/C6DW8V85/Moore - 2008 - The Role of Temporal Fine Structure Processing in .pdf:application/pdf},
	issn = {1525-3961},
	journal = {JARO: Journal of the Association for Research in Otolaryngology},
	month = dec,
	number = {4},
	pages = {399--406},
	pmcid = {PMC2580810},
	pmid = {18855069},
	title = {The {Role} of {Temporal} {Fine} {Structure} {Processing} in {Pitch} {Perception}, {Masking}, and {Speech} {Perception} for {Normal}-{Hearing} and {Hearing}-{Impaired} {People}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2580810/},
	urldate = {2018-05-10},
	volume = {9},
	year = {2008},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2580810/},
	bdsk-url-2 = {https://doi.org/10.1007/s10162-008-0143-x}}

@article{maki_spatial_1995,
	abstract = {The effect of motor activity on the left fronto?central region of the human brain was analyzed spatially and temporally by using noninvasive near?infrared light (NIR) topography. The changes in oxygenation states caused by motor activity were measured using intensity?modulated NIR spectroscopy at ten measurement positions on the head surface. The subject randomly performed unilateral finger opposition for 30 s as motor stimulation. When the subject performed contralateral (right) finger movement, significant increases in both oxygenated hemoglobin (oxy?Hb) and total hemoglobin (total?Hb) and decreases in deoxygenated hemoglobin (deoxy?Hb) were observed in a particular area. By mapping the static topograms of the changes of each Hb and comparing them with an anatomical image of MRI, it was found that the particular area was located on the motor cortex along the central sulcus. By mapping the dynamic topograms of the changes of total?Hb, which reflect the cerebral blood volume, and analyzing the spatiotemporal hemodynamic changes associated with the brain activity, it was found that the regional change in cerebral blood volume in the primary motor area overlaps the global change around the motor cortex. These results demonstrate that NIR topography can be used to effectively observe the human brain activity.},
	author = {Maki, Atsushi and Yamashita, Yuichi and Ito, Yoshitoshi and Watanabe, Eiju and Mayanagi, Yoshiaki and Koizumi, Hideaki},
	doi = {10.1118/1.597496},
	file = {Makietal95.pdf:/Users/Cecile/Zotero/storage/KDH8RRTQ/Makietal95.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S667WT8Y/1.html:text/html},
	issn = {0094-2405},
	journal = {Medical Physics},
	keywords = {Hemodynamics, 87.56.09, 87.59.05, Brain, CENTRAL NERVOUS SYSTEM, Global change, HEMOGLOBIN, HUMAN POPULATIONS, Haemodynamics, MRI anatomic imaging, Magnetic resonance imaging, Medical imaging, NEAR INFRARED RADIATION, OPTICAL SPECTROMETERS, Pneumodyamics, respiration, SPATIAL RESOLUTION, Spatial analysis, Surface spectroscopy, Surface states, TOPOGRAPHY, Thermography, Topography},
	month = dec,
	number = {12},
	pages = {1997--2005},
	title = {Spatial and temporal analysis of human motor activity using noninvasive {NIR} topography},
	url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.597496},
	urldate = {2018-05-07},
	volume = {22},
	year = {1995},
	bdsk-url-1 = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.597496},
	bdsk-url-2 = {https://doi.org/10.1118/1.597496}}

@article{andermann_neuromagnetic_2017,
	abstract = {Vowel recognition is largely immune to differences in speaker size despite the waveform differences associated with variation in speaker size. This has led to the suggestion that voice pitch and mean formant frequency (MFF) are extracted early in the hierarchy of hearing/speech processing and used to normalize the internal representation of vowel sounds. This paper presents a magnetoencephalographic (MEG) experiment designed to locate and compare neuromagnetic activity associated with voice pitch, MFF and vowel type in human auditory cortex. Sequences of six sustained vowels were used to contrast changes in the three components of vowel perception, and MEG responses to the changes were recorded from 25 participants. A staged procedure was employed to fit the MEG data with a source model having one bilateral pair of dipoles for each component of vowel perception. This dipole model showed that the activity associated with the three perceptual changes was functionally separable; the pitch source was located in Heschl's gyrus (bilaterally), while the vowel-type and formant-frequency sources were located (bilaterally) just behind Heschl's gyrus in planum temporale. The results confirm that vowel normalization begins in auditory cortex at an early point in the hierarchy of speech processing.},
	author = {Andermann, Martin and Patterson, Roy D. and Vogt, Caroline and Winterstetter, Lisa and Rupp, Andr{\'e}},
	doi = {10.1016/j.neuroimage.2017.06.065},
	journal = {NeuroImage},
	month = sep,
	pages = {79--89},
	title = {Neuromagnetic correlates of voice pitch, vowel type, and speaker size in auditory cortex},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811917305360},
	volume = {158},
	year = {2017},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811917305360},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2017.06.065}}

@article{obleser_pre-lexical_2009,
	author = {Obleser, Jonas and Eisner, Franck},
	doi = {10.1016/j.tics.2008.09.005},
	journal = {Trends in Cognitive Sciences},
	month = jan,
	number = {1},
	pages = {14--19},
	title = {Pre-lexical abstraction of speech in the auditory cortex},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661308002477},
	volume = {13},
	year = {2009},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1364661308002477},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2008.09.005}}

@article{doelling_acoustic_2014,
	abstract = {A growing body of research suggests that intrinsic neuronal slow ({\textless}10 Hz) oscillations in auditory cortex appear to track incoming speech and other spectro-temporally complex auditory signals. Within this framework, several recent studies have identified critical-band temporal envelopes as the specific acoustic feature being reflected by the phase of these oscillations. However, how this alignment between speech acoustics and neural oscillations might underpin intelligibility is unclear. Here we test the hypothesis that the 'sharpness' of temporal fluctuations in the critical band envelope acts as a temporal cue to speech syllabic rate, driving delta-theta rhythms to track the stimulus and facilitate intelligibility. We interpret our findings as evidence that sharp events in the stimulus cause cortical rhythms to re-align and parse the stimulus into syllable-sized chunks for further decoding. Using magnetoencephalographic recordings, we show that by removing temporal fluctuations that occur at the syllabic rate, envelope-tracking activity is reduced. By artificially reinstating these temporal fluctuations, envelope-tracking activity is regained. These changes in tracking correlate with intelligibility of the stimulus. Together, the results suggest that the sharpness of fluctuations in the stimulus, as reflected in the cochlear output, drive oscillatory activity to track and entrain to the stimulus, at its syllabic rate. This process likely facilitates parsing of the stimulus into meaningful chunks appropriate for subsequent decoding, enhancing perception and intelligibility.},
	author = {Doelling, Keith B. and Arnal, Luc H. and Ghitza, Oded and Poeppel, David},
	doi = {10.1016/j.neuroimage.2013.06.035},
	issn = {1095-9572},
	journal = {NeuroImage},
	keywords = {Acoustic Stimulation, Adolescent, Adult, Comprehension, Cues, Female, Humans, MEG, Male, Speech, Young Adult, Acoustic edge, Auditory cortex, CACoh, CALM, Delta Rhythm, Neural oscillation, Perceptual parsing, Speech Perception, Theta Rhythm, categorization and learning module, cerebro-acoustic coherence, magnetoencephalography},
	language = {eng},
	month = jan,
	pages = {761--768},
	pmcid = {PMC3839250},
	pmid = {23791839},
	title = {Acoustic landmarks drive delta-theta oscillations to enable speech comprehension by facilitating perceptual parsing},
	volume = {85 Pt 2},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1016/j.neuroimage.2013.06.035}}

@article{rohrmeier_principles_2015,
	abstract = {Human language, music and a variety of animal vocalizations constitute ways of sonic communication that exhibit remarkable structural complexity. While the complexities of language and possible parallels in animal communication have been discussed intensively, reflections on the complexity of music and animal song, and their comparisons, are underrepresented. In some ways, music and animal songs are more comparable to each other than to language as propositional semantics cannot be used as indicator of communicative success or wellformedness, and notions of grammaticality are less easily defined. This review brings together accounts of the principles of structure building in music and animal song. It relates them to corresponding models in formal language theory, the extended Chomsky hierarchy (CH), and their probabilistic counterparts. We further discuss common misunderstandings and shortcomings concerning the CH and suggest ways to move beyond. We discuss language, music and animal song in the context of their function and motivation and further integrate problems and issues that are less commonly addressed in the context of language, including continuous event spaces, features of sound and timbre, representation of temporality and interactions of multiple parallel feature streams. We discuss these aspects in the light of recent theoretical, cognitive, neuroscientific and modelling research in the domains of music, language and animal song.},
	author = {Rohrmeier, Martin and Zuidema, Willem and Wiggins, Geraint A. and Scharff, Constance},
	doi = {10.1098/rstb.2014.0097},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/D9XCQPWR/Rohrmeier et al. - 2015 - Principles of structure building in music, languag.pdf:application/pdf},
	issn = {0962-8436},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	month = mar,
	number = {1664},
	pmcid = {PMC4321138},
	pmid = {25646520},
	title = {Principles of structure building in music, language and animal song},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321138/},
	urldate = {2018-05-10},
	volume = {370},
	year = {2015},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321138/},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2014.0097}}

@article{schweinberger_neural_2011,
	abstract = {Apart from speech content, the human voice also carries paralinguistic information about speaker identity. Voice identification and its neural correlates have received little scientific attention up to now. Here we use event-related potentials (ERPs) in an adaptation paradigm, in order to investigate the neural representation and the time course of vocal identity processing. Participants adapted to repeated utterances of vowel--consonant--vowel (VCV) of one personally familiar speaker (either A or B), before classifying a subsequent test voice varying on an identity continuum between these two speakers. Following adaptation to speaker A, test voices were more likely perceived as speaker B and vice versa, and these contrastive voice identity aftereffects (VIAEs) were much more pronounced when the same syllable, rather than a different syllable, was used as adaptor. Adaptation induced amplitude reductions of the frontocentral N1--P2 complex and a prominent reduction of the parietal P3 component, for test voices preceded by identity-corresponding adaptors. Importantly, only the P3 modulation remained clear for across-syllable combinations of adaptor and test stimuli. Our results suggest that voice identity is contrastively processed by specialized neurons in auditory cortex within ∼250 ms after stimulus onset, with identity processing becoming less dependent on speech content after ∼300 ms.},
	author = {Schweinberger, Stefan R. and Walther, Christian and Z{\"a}ske, Romi and Kov{\'a}cs, Gyula},
	copyright = {{\copyright} 2011 The British Psychological Society},
	doi = {10.1111/j.2044-8295.2011.02048.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/E2UBXNKG/Schweinberger et al. - 2011 - Neural correlates of adaptation to voice identity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BRP9JDFM/j.2044-8295.2011.02048.html:text/html},
	issn = {2044-8295},
	journal = {British Journal of Psychology},
	language = {en},
	month = nov,
	number = {4},
	pages = {748--764},
	title = {Neural correlates of adaptation to voice identity},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.2011.02048.x},
	urldate = {2018-05-12},
	volume = {102},
	year = {2011},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.2011.02048.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.2044-8295.2011.02048.x}}

@article{mullennix_stimulus_1990,
	abstract = {Processing dependencies in speech perception between voice and phoneme were investigated using the Garner (1974) speeded classification procedure. Variability in the voice of the talker and in the cues to word-initial consonants were manipulated. The results showed that the processing of a talker's voice and the perception of voicing are asymmetrically dependent. In addition, when stimulus variability was increased in each dimension, the amount of orthogonal interference obtained for each dimension became significantly larger. The processing asymmetry between voice and phoneme was interpreted in terms of a parallel-contingent relationship of talker normalization processes to auditory-to-phonetic coding processes. The processing of voice information appears to be qualitatively different from the encoding of segmental phonetic information, although they are not independent. Implications of these results for current theories of speech perception are discussed.},
	author = {Mullennix, John W. and Pisoni, David B.},
	doi = {10.3758/BF03210878},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/TJY4ZCXX/Mullennix et Pisoni - 1990 - Stimulus variability and processing dependencies i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9BT9PDEK/BF03210878.html:text/html},
	issn = {0031-5117, 1532-5962},
	journal = {Perception \& Psychophysics},
	language = {en},
	month = jul,
	number = {4},
	pages = {379--390},
	title = {Stimulus variability and processing dependencies in speech perception},
	url = {https://link.springer.com/article/10.3758/BF03210878},
	urldate = {2018-05-14},
	volume = {47},
	year = {1990},
	bdsk-url-1 = {https://link.springer.com/article/10.3758/BF03210878},
	bdsk-url-2 = {https://doi.org/10.3758/BF03210878}}

@article{schwartz_identification_1968,
	author = {Schwartz, Martin F.},
	doi = {10.1121/1.1910954},
	file = {Snapshot:/Users/Cecile/Zotero/storage/EPT8YEXU/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = may,
	number = {5},
	pages = {1178--1179},
	title = {Identification of {Speaker} {Sex} from {Isolated}, {Voiceless} {Fricatives}},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1910954},
	urldate = {2018-05-14},
	volume = {43},
	year = {1968},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1910954},
	bdsk-url-2 = {https://doi.org/10.1121/1.1910954}}

@article{bladon_towards_1984,
	author = {Bladon, R.A.W. and Henton, C.G. and Pickering, J.B.},
	doi = {10.1016/0271-5309(84)90019-3},
	file = {Bladon et al. - 1984 - Towards an auditory theory of speaker normalizatio.pdf:/Users/Cecile/Zotero/storage/JXE8F26R/Bladon et al. - 1984 - Towards an auditory theory of speaker normalizatio.pdf:application/pdf},
	issn = {02715309},
	journal = {Language \& Communication},
	language = {en},
	month = jan,
	number = {1},
	pages = {59--69},
	title = {Towards an auditory theory of speaker normalization},
	url = {http://linkinghub.elsevier.com/retrieve/pii/0271530984900193},
	urldate = {2018-05-14},
	volume = {4},
	year = {1984},
	bdsk-url-1 = {http://linkinghub.elsevier.com/retrieve/pii/0271530984900193},
	bdsk-url-2 = {https://doi.org/10.1016/0271-5309(84)90019-3}}

@article{giordano_contributions_2017,
	abstract = {Seeing a speaker's face enhances speech intelligibility in adverse environments. We investigated the underlying network mechanisms by quantifying local speech representations and directed connectivity in MEG data obtained while human participants listened to speech of varying acoustic SNR and visual context. During high acoustic SNR speech encoding by temporally entrained brain activity was strong in temporal and inferior frontal cortex, while during low SNR strong entrainment emerged in premotor and superior frontal cortex. These changes in local encoding were accompanied by changes in directed connectivity along the ventral stream and the auditory-premotor axis. Importantly, the behavioral benefit arising from seeing the speaker's face was not predicted by changes in local encoding but rather by enhanced functional connectivity between temporal and inferior frontal cortex. Our results demonstrate a role of auditory-frontal interactions in visual speech representations and suggest that functional connectivity along the ventral pathway facilitates speech comprehension in multisensory environments., DOI:
http://dx.doi.org/10.7554/eLife.24763.001, When listening to someone in a noisy environment, such as a cocktail party, we can understand the speaker more easily if we can also see his or her face. Movements of the lips and tongue convey additional information that helps the listener's brain separate out syllables, words and sentences. However, exactly where in the brain this effect occurs and how it works remain unclear., To find out, Giordano et al. scanned the brains of healthy volunteers as they watched clips of people speaking. The clarity of the speech varied between clips. Furthermore, in some of the clips the lip movements of the speaker corresponded to the speech in question, whereas in others the lip movements were nonsense babble. As expected, the volunteers performed better on a word recognition task when the speech was clear and when the lips movements agreed with the spoken dialogue., Watching the video clips stimulated rhythmic activity in multiple regions of the volunteers' brains, including areas that process sound and areas that plan movements. Speech is itself rhythmic, and the volunteers' brain activity synchronized with the rhythms of the speech they were listening to. Seeing the speaker's face increased this degree of synchrony. However, it also made it easier for sound-processing regions within the listeners' brains to transfer information to one other. Notably, only the latter effect predicted improved performance on the word recognition task. This suggests that seeing a person's face makes it easier to understand his or her speech by boosting communication between brain regions, rather than through effects on individual areas., Further work is required to determine where and how the brain encodes lip movements and speech sounds. The next challenge will be to identify where these two sets of information interact, and how the brain merges them together to generate the impression of specific words., DOI:
http://dx.doi.org/10.7554/eLife.24763.002},
	author = {Giordano, Bruno L and Ince, Robin A A and Gross, Joachim and Schyns, Philippe G and Panzeri, Stefano and Kayser, Christoph},
	doi = {10.7554/eLife.24763},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/PBYLRZN5/Giordano et al. - Contributions of local speech encoding and functio.pdf:application/pdf},
	issn = {2050-084X},
	journal = {eLife},
	pmcid = {PMC5462535},
	pmid = {28590903},
	title = {Contributions of local speech encoding and functional connectivity to audio-visual speech perception},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5462535/},
	urldate = {2018-05-08},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5462535/},
	bdsk-url-2 = {https://doi.org/10.7554/eLife.24763}}

@phdthesis{guiraud_symphonie_2017,
	author = {Guiraud, H{\'e}l{\`e}ne},
	file = {Guiraud - Symphonie des oscillations c{\'e}r{\'e}brales lors de la p.pdf:/Users/Cecile/Zotero/storage/ZCIK775B/Guiraud - Symphonie des oscillations c{\'e}r{\'e}brales lors de la p.pdf:application/pdf},
	language = {fr},
	month = nov,
	school = {Universit{\'e} lumi{\`e}re Lyon 2},
	title = {Symphonie des oscillations c{\'e}r{\'e}brales lors de la perception de parole: {\'E}tudes comportementale et en magn{\'e}toenc{\'e}phalographie chez les enfants neurotypiques et dysphasiques.},
	year = {2017}}

@article{chandrasekaran_neural_2011,
	abstract = {Human speech is composed of two types of information, related to content (lexical information, i.e., ``what'' is being said [e.g., words]) and to the speaker (indexical information, i.e., ``who'' is talking [e.g., voices]). The extent to which lexical versus indexical information is represented separately or integrally in the brain is unresolved. In the current experiment, we use short-term fMRI adaptation to address this issue. Participants performed a loudness judgment task during which single or multiple sets of words/pseudowords were repeated with single (repeat) or multiple talkers (speaker-change) conditions while BOLD responses were collected. As reflected by adaptation fMRI, the left posterior middle temporal gyrus, a crucial component of the ventral auditory stream performing sound-to-meaning computations (``what'' pathway), showed sensitivity to lexical as well as indexical information. Previous studies have suggested that speaker information is abstracted during this stage of auditory word processing. Here, we demonstrate that indexical information is strongly coupled with word information. These findings are consistent with a plethora of behavioral results that have demonstrated that changes to speaker-related information can influence lexical processing.},
	author = {Chandrasekaran, Bharath and Chan, Alice H. D. and Wong, Patrick C. M.},
	doi = {10.1162/jocn.2011.21631},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LSU3B6W9/Chandrasekaran et al. - 2011 - Neural Processing of What and Who Information in S.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6CKKH647/jocn.2011.html:text/html},
	issn = {0898-929X},
	journal = {Journal of Cognitive Neuroscience},
	month = jan,
	number = {10},
	pages = {2690--2700},
	title = {Neural {Processing} of {What} and {Who} {Information} in {Speech}},
	url = {https://doi.org/10.1162/jocn.2011.21631},
	urldate = {2018-05-12},
	volume = {23},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1162/jocn.2011.21631}}

@article{picheny_speaking_1986,
	author = {Picheny, M. A. and Durlach, N. I. and Braida, L. D.},
	doi = {10.1044/jshr.2904.434},
	file = {Snapshot:/Users/Cecile/Zotero/storage/32SGME5G/article.html:text/html},
	issn = {1092-4388},
	journal = {Journal of Speech, Language, and Hearing Research},
	language = {en},
	month = dec,
	number = {4},
	pages = {434--446},
	shorttitle = {Speaking {Clearly} for the {Hard} of {Hearing} {II}},
	title = {Speaking {Clearly} for the {Hard} of {Hearing} {II}: {Acoustic} {Characteristics} of {Clear} and {Conversational} {Speech}},
	url = {https://jslhr.pubs.asha.org/article.aspx?articleid=1778250},
	urldate = {2018-05-10},
	volume = {29},
	year = {1986},
	bdsk-url-1 = {https://jslhr.pubs.asha.org/article.aspx?articleid=1778250},
	bdsk-url-2 = {https://doi.org/10.1044/jshr.2904.434}}

@article{krause_acoustic_2003,
	author = {Krause, Jean C. and Braida, Louis D.},
	doi = {10.1121/1.1635842},
	file = {Snapshot:/Users/Cecile/Zotero/storage/PW4LVCXW/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = dec,
	number = {1},
	pages = {362--378},
	title = {Acoustic properties of naturally produced clear speech at normal speaking rates},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1635842},
	urldate = {2018-05-10},
	volume = {115},
	year = {2003},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1635842},
	bdsk-url-2 = {https://doi.org/10.1121/1.1635842}}

@article{peterson_control_1952,
	author = {Peterson, Gordon E. and Barney, Harold L.},
	doi = {10.1121/1.1906875},
	file = {Peterson et Barney - 1952 - Control Methods Used in a Study of the Vowels.pdf:/Users/Cecile/Zotero/storage/PSGZ4PI4/Peterson et Barney - 1952 - Control Methods Used in a Study of the Vowels.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/A85WRRNJ/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = mar,
	number = {2},
	pages = {175--184},
	title = {Control {Methods} {Used} in a {Study} of the {Vowels}},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1906875},
	urldate = {2018-05-12},
	volume = {24},
	year = {1952},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1906875},
	bdsk-url-2 = {https://doi.org/10.1121/1.1906875}}

@article{csibra_gamma_2000,
	abstract = {An enduring controversy in neuroscience concerns how the brain ``binds'' together separately coded stimulus features to form unitary representations of objects. Recent evidence has indicated a close link between this binding process and 40-hertz (gamma-band) oscillations generated by localized neural circuits. In a separate line of research, the ability of young infants to perceive objects as unitary and bounded has become a central focus for debates about the mechanisms of perceptual development. Here we demonstrate that binding-related 40-hertz oscillations are evident in the infant brain around 8 months of age, which is the same age at which behavioral and event-related potential evidence indicates the onset of perceptual binding of spatially separated static visual features.},
	author = {Csibra, G. and Davis, G. and Spratling, M. W. and Johnson, M. H.},
	doi = {10.1126/science.290.5496.1582},
	file = {Csibra et al. - 2000 - Gamma Oscillations and Object Processing in the In.pdf:/Users/Cecile/Zotero/storage/NWNE8GZI/Csibra et al. - 2000 - Gamma Oscillations and Object Processing in the In.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ILSPKTBD/1582.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = nov,
	number = {5496},
	pages = {1582--1585},
	pmid = {11090357},
	title = {Gamma {Oscillations} and {Object} {Processing} in the {Infant} {Brain}},
	url = {http://science.sciencemag.org/content/290/5496/1582},
	urldate = {2018-06-18},
	volume = {290},
	year = {2000},
	bdsk-url-1 = {http://science.sciencemag.org/content/290/5496/1582},
	bdsk-url-2 = {https://doi.org/10.1126/science.290.5496.1582}}

@article{marshall_development_2002,
	abstract = {OBJECTIVES: This report provides a systematic longitudinal analysis of the EEG from infancy into early childhood. Particular emphasis is placed on the empirical confirmation of a 6-9 Hz alpha-range frequency band that has previously been used in the infant EEG literature.
METHODS: EEG data in 1-Hz bins from 3 to 12 Hz were analyzed from a longitudinal sample of 29 participants at 5, 10, 14, 24, and 51 months of age.
RESULTS: Inspection of power spectra averaged across the whole sample indicated the emergence of a peak in the 6-9 Hz range across multiple scalp regions. Coding of peaks in the power spectra of individual infants showed a clear developmental increase in the frequency of this peak. A rhythm in the 6-9 Hz emerged at central sites that was independent of the classical alpha rhythm at posterior sites. The relative amplitude of this central rhythm peaked in the second year of life, when major changes are occurring in locomotor behavior.
CONCLUSIONS: The 6-9 Hz band is a useful alpha-range band from the end of the first year of life into early childhood. The findings also complement other research relating the infant central rhythm with the adult sensorimotor mu rhythm.},
	author = {Marshall, Peter J. and Bar-Haim, Yair and Fox, Nathan A.},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	keywords = {Aging, Child, Preschool, Electrodes, Electroencephalography, Female, Frontal Lobe, Humans, Infant, Male, Occipital Lobe, Parietal Lobe, Brain, Alpha Rhythm, Longitudinal Studies, Motor Activity},
	language = {eng},
	month = aug,
	number = {8},
	pages = {1199--1208},
	pmid = {12139998},
	title = {Development of the {EEG} from 5 months to 4 years of age},
	volume = {113},
	year = {2002}}

@article{stroganova_eeg_1999,
	abstract = {The 'functional topography' approach has been applied to study alpha rhythms in infant twins during the second half-year of life. The experimental sample included 154 normal infants born at 32-41 weeks of gestational age. Their chronological age varied from 7.4 to 12.4 months. EEG was registered during wakefulness under two experimental conditions: sustained visual attention and dark homogenous visual field. During darkness as compared with visual attention the sharp increase of spectral amplitudes within 5.2-9.6 Hz band was observed over the occipital-parietal cortex. The properties of the 5.2-9.6 Hz occipital rhythmic activity comply with the classical properties of alpha rhythm. The distinct spectral peak in 6.0-8.8 Hz band at precentral recording sites was observed during sustained visual attention. This rhythmic component was suppressed under the condition of total darkness. Arguments in favour of homology between the infant central rhythm and adult sensorimotor mu rhythm are advanced. The group mean of alpha peak frequency increased from 6.24 +/- 0.45 Hz at 8 months to 6.78 +/- 0.38 Hz at 11 months of chronological age. The frequency of infant alpha rhythm depended only on the period of extrauterine experience, regardless of gestational age at birth. This result points to the critical role of early visual experience in alpha rhythm development. The group mean of the peak frequency of mu rhythm also increased during the second half-year of life, from 7.03 +/- 0.47 Hz at 8 months to 7.42 +/- 0.46 Hz at 11 months. Unlike alpha rhythm, the peak frequency of mu rhythm depended on duration of both intra- and extrauterine development. We speculate that the development of sensorimotor mu rhythm is influenced by somatosensory stimulation, which, in sharp contrast to the visual input, is present in the uterus.},
	author = {Stroganova, T. A. and Orekhova, E. V. and Posikera, I. N.},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	keywords = {Electroencephalography, Female, Humans, Infant, Newborn, Male, Brain, Age Distribution, Analysis of Variance},
	language = {eng},
	month = jun,
	number = {6},
	pages = {997--1012},
	pmid = {10402087},
	title = {{EEG} alpha rhythm in infants},
	volume = {110},
	year = {1999}}

@article{marshall_neural_2011,
	abstract = {How do human children come to understand the actions of other people? What neural systems are associated with the processing of others' actions and how do these systems develop, starting in infancy? These questions span cognitive psychology and developmental cognitive neuroscience, and addressing them has important implications for the study of social cognition. A large amount of research has used behavioral measures to investigate infants' imitation of the actions of other people; a related but smaller literature has begun to use neurobiological measures to study of infants' action representation. Here we focus on experiments employing electroencephalographic (EEG) techniques for assessing mu rhythm desynchronization in infancy, and analyze how this work illuminates the links between action perception and production prior to the onset of language.},
	author = {Marshall, Peter J. and Meltzoff, Andrew N.},
	doi = {10.1016/j.dcn.2010.09.001},
	issn = {1878-9307},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Brain Waves, Electroencephalography, Humans, Infant, Infant Behavior, Photic Stimulation, Psychomotor Performance, Reaction Time, Imitative Behavior, Mirror Neurons},
	language = {eng},
	month = apr,
	number = {2},
	pages = {110--123},
	pmcid = {PMC3081582},
	pmid = {21528008},
	shorttitle = {Neural mirroring systems},
	title = {Neural mirroring systems: exploring the {EEG} μ rhythm in human infancy},
	volume = {1},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1016/j.dcn.2010.09.001}}

@article{maguire_what_2013,
	abstract = {EEG is a primary method for studying temporally precise neuronal processes across the lifespan. Most of this work focuses on Event Related Potentials (ERPs); however, using time-locked time frequency analysis to decompose the EEG signal can identify and distinguish multiple changes in brain oscillations underlying cognition (). Further this measure is thought to reflect changes in inter-neuronal communication more directly than ERPs (). Although time frequency has elucidated cognitive processes in adults, applying it to cognitive development is still rare. Here, we review the basics of neuronal oscillations, some of what they reveal about adult cognitive function, and what little is known relating to children. We focus on language because it develops early and engages complex cortical networks. Additionally, because time frequency analysis of the EEG related to adult language comprehension has been incredibly informative, using similar methods with children will shed new light on current theories of language development and increase our understanding of how neural processes change over the lifespan. Our goal is to emphasize the power of this methodology and encourage its use throughout developmental cognitive neuroscience.},
	author = {Maguire, Mandy J. and Abel, Alyson D.},
	doi = {10.1016/j.dcn.2013.08.002},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/VR3VR9V5/Maguire et Abel - 2013 - What changes in neural oscillations can reveal abo.pdf:application/pdf},
	issn = {1878-9293},
	journal = {Developmental cognitive neuroscience},
	month = oct,
	pmcid = {PMC3875138},
	pmid = {24060670},
	shorttitle = {What changes in neural oscillations can reveal about developmental cognitive neuroscience},
	title = {What changes in neural oscillations can reveal about developmental cognitive neuroscience: {Language} development as a case in point},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875138/},
	urldate = {2018-06-18},
	volume = {6},
	year = {2013},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875138/},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2013.08.002}}

@article{nacar_garcia_evoked_2018,
	abstract = {Language discrimination is one of the core differences between bilingual and monolingual language acquisition. Here, we investigate the earliest brain specialization induced by it. Following previous research, we hypothesize that bilingual native language discrimination is a complex process involving specific processing of the prosodic properties of the speech signal. We recorded the brain activity of monolingual and bilingual 4.5-month-old infants using EEG, while listening to their native/dominant language and two foreign languages. We defined two different windows of analysis to separate discrimination and identification effects. In the early window of analysis (150-280 ms) we measured the P200 component, and in the later window of analysis we measured Theta (400-1800 ms) and Gamma (300-2800 ms) oscillations. The results point in the direction of different language discrimination strategies for bilingual and monolingual infants. While only monolingual infants show early discrimination of their native language based on familiarity, bilinguals perform a later processing which is compatible with an increase in attention to the speech signal. This is the earliest evidence found for brain specialization induced by bilingualism.},
	author = {Nacar Garcia, Loreto and Guerrero-Mosquera, Carlos and Colomer, Marc and Sebastian-Galles, Nuria},
	doi = {10.1038/s41598-018-20824-0},
	issn = {2045-2322},
	journal = {Scientific Reports},
	language = {eng},
	month = feb,
	number = {1},
	pages = {2770},
	pmcid = {PMC5807452},
	pmid = {29426859},
	title = {Evoked and oscillatory {EEG} activity differentiates language discrimination in young monolingual and bilingual infants},
	volume = {8},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1038/s41598-018-20824-0}}

@article{cheour_maturation_1998,
	abstract = {The mismatch negativity (MMN) is a pre-attentive change-specific component of the event-related brain potentials (ERPs). During the last decade this response has been intensively studied in adults, but investigations in children and especially in infants are still rare. Recent studies, however, have shown that MMN is also elicited in infants in response to changes in pure tones as well as in phonemes. The present study compared MMN in pre-term infants (conceptional age at the time of recording, 30--35 weeks), full-term newborns and full-term 3-month-old infants. Stimuli were Klatt-synthesized Finnish vowels /y/ and /i/. Previous studies have reported larger MMN amplitudes in school-age children compared with those obtained in adults. According to the results, however, the infant MMN amplitude seems to resemble that of adults. No significant differences in MMN amplitudes were found between the three age groups either. The mean MMN latency, however, decreased significantly with age, although in 3-month-old infants it was not much longer than in a previous study conducted in adults with the same stimuli.},
	author = {Cheour, M. and Alho, K. and {\v C}eponien{\'e}, R. and Reinikainen, K. and Sainio, K. and Pohjavuori, M. and Aaltonen, O. and N{\"a}{\"a}t{\"a}nen, R.},
	doi = {10.1016/S0167-8760(98)00017-8},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4UUW8QPB/Cheour et al. - 1998 - Maturation of mismatch negativity in infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XINF3C22/S0167876098000178.html:text/html},
	issn = {0167-8760},
	journal = {International Journal of Psychophysiology},
	keywords = {Event-related brain potential, Mismatch negativity, Pre-term infants},
	month = jul,
	number = {2},
	pages = {217--226},
	title = {Maturation of mismatch negativity in infants},
	url = {http://www.sciencedirect.com/science/article/pii/S0167876098000178},
	volume = {29},
	year = {1998},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0167876098000178},
	bdsk-url-2 = {https://doi.org/10.1016/S0167-8760(98)00017-8}}

@article{mcclelland_trace_1986,
	abstract = {We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic processing structure called ``the Trace,'' which serves at once as the perceptual processing mechanism and as the system's working memory. The model is instantiated in two simulation programs. TRACE I, described in detail elsewhere, deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be embodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difficulty with the COHORT model: it can recover from underspecification or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception.},
	author = {McClelland, James L and Elman, Jeffrey L},
	doi = {10.1016/0010-0285(86)90015-0},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/38RIP3KL/McClelland et Elman - 1986 - The TRACE model of speech perception.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EA42JI78/0010028586900150.html:text/html},
	issn = {0010-0285},
	journal = {Cognitive Psychology},
	month = jan,
	number = {1},
	pages = {1--86},
	title = {The {TRACE} model of speech perception},
	url = {http://www.sciencedirect.com/science/article/pii/0010028586900150},
	urldate = {2018-06-21},
	volume = {18},
	year = {1986},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0010028586900150},
	bdsk-url-2 = {https://doi.org/10.1016/0010-0285(86)90015-0}}

@article{rao_predictive_1999,
	abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
	author = {Rao, R. P. and Ballard, D. H.},
	doi = {10.1038/4580},
	issn = {1097-6256},
	journal = {Nature Neuroscience},
	keywords = {Models, Neurological, Neural Networks (Computer), Visual Cortex, Feedback, Forecasting, Visual Pathways},
	language = {eng},
	month = jan,
	number = {1},
	pages = {79--87},
	pmid = {10195184},
	shorttitle = {Predictive coding in the visual cortex},
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
	volume = {2},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1038/4580}}

@article{murakami_contributions_2006,
	abstract = {A realistically shaped three-dimensional single-neuron model was constructed for each of four principal cell types in the neocortex in order to infer their contributions to magnetoencephalography (MEG) and electroencephalography (EEG) signals. For each cell, the soma was stimulated and the resulting intracellular current was used to compute the current dipole Q for the whole cell or separately for the apical and basal dendrites. The magnitude of Q is proportional to the magnetic field and electrical potential far from the neuron. A train of spikes and depolarization shift in an intracellular burst discharge were seen as spikes and an envelope in Q for the layer V and layer II/III pyramidal cells. The stellate cells lacked the envelope. As expected, the pyramidal cells produced a stronger Q than the stellate cells. The spikes produced by the layer V pyramidal cells (n = 4) varied between −0.78 and 2.97 pA m with the majority of the cells showing a current toward the pia (defined as positive). The basal dendrites, however, produced considerable spike currents. The magnitude and direction of dipole moment are in agreement with the distribution of the dendrites. The spikes in Q for the layer V pyramidal cells were produced by the transient sodium conductance and potassium conductance of delayed rectifier type; the conductances distributed along the dendrites were capable of generating spike propagation, which was seen in Q as the tail of a triphasic wave lasting several milliseconds. The envelope was similar in magnitude (−0.41 to −0.90 pA m) across the four layer V pyramidal cells. The spike and envelope for the layer II/III pyramidal cell were 0.47 and −0.29 pA m, respectively; these values agreed well with empirical and theoretical estimates for guinea pig CA3 pyramidal cells. Spikes were stronger for the layer IV spiny stellate (0.27 pA m) than the layer III aspiny stellate cell (0.06 pA m) along their best orientations. The spikes may thus be stronger than has been previously thought. The Q for a population of stellate cells may be weaker than a linear sum of their individual Q values due to their variable dendritic geometry. The burst discharge by pyramidal cells may be detectable with MEG and EEG when 10 000--50 000 cells are synchronously active.},
	author = {Murakami, Shingo and Okada, Yoshio},
	doi = {10.1113/jphysiol.2006.105379},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/A6TDK7JL/Murakami et Okada - 2006 - Contributions of principal neocortical neurons to .pdf:application/pdf},
	issn = {0022-3751},
	journal = {The Journal of Physiology},
	month = sep,
	number = {Pt 3},
	pages = {925--936},
	pmcid = {PMC1995687},
	pmid = {16613883},
	title = {Contributions of principal neocortical neurons to magnetoencephalography and electroencephalography signals},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1995687/},
	urldate = {2018-06-22},
	volume = {575},
	year = {2006},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1995687/},
	bdsk-url-2 = {https://doi.org/10.1113/jphysiol.2006.105379}}

@article{singh_which_2012,
	abstract = {Over the last 20years, BOLD-FMRI has proved itself to be a powerful and versatile tool for the study of the neural substrate underpinning many of our cognitive and perceptual functions. However, exactly how it is coupled to the underlying neurophysiology, and how this coupling varies across the brain, across tasks and across individuals is still unclear. The story is further complicated by the fact that within the same cortical region, multiple evoked and induced oscillatory effects may be modulated during task execution, supporting different cognitive roles, and any or all of these may have metabolic demands that then drive the BOLD response. In this paper I shall concentrate on one experimental approach to shedding light on this problem i.e. the execution of the same experimental tasks using MEG and fMRI in order to reveal which electrophysiological responses best match the BOLD response spatially, temporally and functionally. The results demonstrate a rich and complex story that does not fit with a simplistic view of BOLD reflecting ``neural activity'' and suggests that we could consider the coupling between BOLD and the various parameters of neural function as an ill-posed inverse problem. Finally, I describe recent work linking individual variability in both cortical oscillations and the BOLD-fMRI response to variability in endogenous GABA concentration.},
	author = {Singh, Krish D.},
	doi = {10.1016/j.neuroimage.2012.01.028},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TE97SHVH/Singh - 2012 - Which ``neural activity'' do you mean fMRI, MEG, os.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VPQBNUMF/S1053811912000456.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {MEG, Oscillations, BOLD, Vision, fMRI, Behaviour, GABA, Variability},
	month = aug,
	number = {2},
	pages = {1121--1130},
	series = {20 {YEARS} {OF} {fMRI}},
	shorttitle = {Which ``neural activity'' do you mean?},
	title = {Which ``neural activity'' do you mean? {fMRI}, {MEG}, oscillations and neurotransmitters},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811912000456},
	urldate = {2018-06-22},
	volume = {62},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912000456},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.028}}

@article{deco_dynamic_2008,
	abstract = {The cortex is a complex system, characterized by its dynamics and architecture, which underlie many functions such as action, perception, learning, language, and cognition. Its structural architecture has been studied for more than a hundred years; however, its dynamics have been addressed much less thoroughly. In this paper, we review and integrate, in a unifying framework, a variety of computational approaches that have been used to characterize the dynamics of the cortex, as evidenced at different levels of measurement. Computational models at different space--time scales help us understand the fundamental mechanisms that underpin neural processes and relate these processes to neuroscience data. Modeling at the single neuron level is necessary because this is the level at which information is exchanged between the computing elements of the brain; the neurons. Mesoscopic models tell us how neural elements interact to yield emergent behavior at the level of microcolumns and cortical columns. Macroscopic models can inform us about whole brain dynamics and interactions between large-scale neural systems such as cortical regions, the thalamus, and brain stem. Each level of description relates uniquely to neuroscience data, from single-unit recordings, through local field potentials to functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), and magnetoencephalogram (MEG). Models of the cortex can establish which types of large-scale neuronal networks can perform computations and characterize their emergent properties. Mean-field and related formulations of dynamics also play an essential and complementary role as forward models that can be inverted given empirical data. This makes dynamic models critical in integrating theory and experiments. We argue that elaborating principled and informed models is a prerequisite for grounding empirical neuroscience in a cogent theoretical framework, commensurate with the achievements in the physical sciences.},
	author = {Deco, Gustavo and Jirsa, Viktor K. and Robinson, Peter A. and Breakspear, Michael and Friston, Karl},
	doi = {10.1371/journal.pcbi.1000092},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FT5K8EVT/Deco et al. - 2008 - The Dynamic Brain From Spiking Neurons to Neural .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CVTY7BYE/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Neurons, Action potentials, Membrane potential, Mesoscopic physics, Neural networks, Nonlinear dynamics, Population density, Single neuron function},
	language = {en},
	month = aug,
	number = {8},
	pages = {e1000092},
	shorttitle = {The {Dynamic} {Brain}},
	title = {The {Dynamic} {Brain}: {From} {Spiking} {Neurons} to {Neural} {Masses} and {Cortical} {Fields}},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092},
	urldate = {2018-06-22},
	volume = {4},
	year = {2008},
	bdsk-url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1000092}}

@article{coombes_large-scale_2010,
	abstract = {We review the use of neural field models for modelling the brain at the large scales necessary for interpreting EEG, fMRI, MEG and optical imaging data. Albeit a framework that is limited to coarse-grained or mean-field activity, neural field models provide a framework for unifying data from different imaging modalities. Starting with a description of neural mass models, we build to spatially extend cortical models of layered two-dimensional sheets with long range axonal connections mediating synaptic interactions. Reformulations of the fundamental non-local mathematical model in terms of more familiar local differential (brain wave) equations are described. Techniques for the analysis of such models, including how to determine the onset of spatio-temporal pattern forming instabilities, are reviewed. Extensions of the basic formalism to treat refractoriness, adaptive feedback and inhomogeneous connectivity are described along with open challenges for the development of multi-scale models that can integrate macroscopic models at large spatial scales with models at the microscopic scale.},
	author = {Coombes, S.},
	doi = {10.1016/j.neuroimage.2010.01.045},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SKJLXYDZ/Coombes - 2010 - Large-scale neural dynamics Simple and complex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5MH4KHWD/S1053811910000674.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {EEG, fMRI, Brain wave equation, Neural field theory},
	month = sep,
	number = {3},
	pages = {731--739},
	series = {Computational {Models} of the {Brain}},
	shorttitle = {Large-scale neural dynamics},
	title = {Large-scale neural dynamics: {Simple} and complex},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910000674},
	urldate = {2018-06-22},
	volume = {52},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811910000674},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2010.01.045}}

@article{alexandrou_cortical_nodate,
	author = {Alexandrou, Anna Maria and Saarinen, Timo and Kujala, Jan and Salmelin, Riitta},
	doi = {https://doi.org/10.1162/jocn_a_01295},
	journal = {Journal of Cognitive Neuroscience},
	title = {Cortical tracking of global and local variation of speech rhythm during connected natural speech perception},
	bdsk-url-1 = {https://doi.org/10.1162/jocn_a_01295}}

@article{scherer_vocal_1991,
	abstract = {This research examines the correspondence between theoretical predictions on vocal expression patterns in naturally occurring emotions (as based on the component process theory of emotion; Scherer, 1986) and empirical data on the acoustic characteristics of actors' portrayals. Two male and two female professional radio actors portrayed anger, sadness, joy, fear, and disgust based on realistic scenarios of emotion-eliciting events. A series of judgment studies was conducted to assess the degree to which judges are able to recognize the intended emotion expressions. Disgust was relatively poorly recognized; average recognition accuracy for the other emotions attained 62.8\% across studies. A set of portrayals reaching a satisfactory level of recognition accuracy underwent digital acoustic analysis. The results for the acoustic parameters extracted from the speech signal show a number of significant differences between emotions, generally confirming the theoretical predictions.},
	author = {Scherer, Klaus R. and Banse, Rainer and Wallbott, Harald G. and Goldbeck, Thomas},
	doi = {10.1007/BF00995674},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T2PF7EK5/Scherer et al. - 1991 - Vocal cues in emotion encoding and decoding.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BLVD5RCY/BF00995674.html:text/html},
	issn = {0146-7239, 1573-6644},
	journal = {Motivation and Emotion},
	language = {en},
	month = jun,
	number = {2},
	pages = {123--148},
	title = {Vocal cues in emotion encoding and decoding},
	url = {https://link.springer.com/article/10.1007/BF00995674},
	urldate = {2018-08-05},
	volume = {15},
	year = {1991},
	bdsk-url-1 = {https://link.springer.com/article/10.1007/BF00995674},
	bdsk-url-2 = {https://doi.org/10.1007/BF00995674}}

@article{sheft_effects_2012,
	abstract = {Objective
The frequency modulation (FM) of speech can convey linguistic information and also enhance speech-stream coherence and segmentation. Using a clinically oriented approach, the purpose of the present study was to examine the effects of age and hearing loss on the ability to discriminate between stochastic patterns of low-rate FM and determine whether difficulties in speech perception experienced by older listeners relate to a deficit in this ability.

Design
Data were collected from 18 normal-hearing young adults, and 18 participants who were at least 60 years old, nine normal-hearing and nine with a mild-to-moderate sensorineural hearing loss. Using stochastic frequency modulators derived from 5-Hz lowpass noise applied to a 1-kHz carrier, discrimination thresholds were measured in terms of frequency excursion (ΔF) both in quiet and with a speech-babble masker present, stimulus duration, and signal-to-noise ratio (SNRFM) in the presence of a speech-babble masker. Speech perception ability was evaluated using Quick Speech-in-Noise (QuickSIN) sentences in four-talker babble.

Results
Results showed a significant effect of age, but not of hearing loss among the older listeners, for FM discrimination conditions with masking present (ΔF and SNRFM). The effect of age was not significant for the FM measures based on stimulus duration. ΔF and SNRFM were also the two conditions for which performance was significantly correlated with listener age when controlling for effect of hearing loss as measured by pure-tone average. With respect to speech-in-noise ability, results from the SNRFM condition were significantly correlated with QuickSIN performance.

Conclusions
Results indicate that aging is associated with reduced ability to discriminate moderate-duration patterns of low-rate stochastic FM. Furthermore, the relationship between QuickSIN performance and the SNRFM thresholds suggests that the difficulty experienced by older listeners with speech-in-noise processing may in part relate to diminished ability to process slower fine-structure modulation at low sensation levels. Results thus suggest that clinical consideration of stochastic FM discrimination measures may offer a fuller picture of auditory processing abilities.},
	author = {Sheft, Stanley and Shafiro, Valeriy and Lorenzi, Christian and McMullen, Rachel and Farrell, Caitlin},
	doi = {10.1097/AUD.0b013e31825aab15},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/MDWECQIH/Sheft et al. - 2012 - Effects of Age and Hearing Loss on the Relationshi.pdf:application/pdf},
	issn = {0196-0202},
	journal = {Ear and hearing},
	month = nov,
	number = {6},
	pages = {709--720},
	pmcid = {PMC3480978},
	pmid = {22790319},
	title = {Effects of {Age} and {Hearing} {Loss} on the {Relationship} between {Discrimination} of {Stochastic} {Frequency} {Modulation} and {Speech} {Perception}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480978/},
	urldate = {2018-08-04},
	volume = {33},
	year = {2012},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480978/},
	bdsk-url-2 = {https://doi.org/10.1097/AUD.0b013e31825aab15}}

@article{silva_intrinsic_1991,
	abstract = {Rhythmic activity in the neocortex varies with different behavioral and pathological states and in some cases may encode sensory information. However, the neural mechanisms of these oscillations are largely unknown. Many pyramidal neurons in layer 5 of the neocortex showed prolonged, 5- to 12-hertz rhythmic firing patterns at threshold. Rhythmic firing was due to intrinsic membrane properties, sodium conductances were essential for rhythmicity, and calcium-dependent conductances strongly modified rhythmicity. Isolated slices of neocortex generated epochs of 4- to 10-hertz synchronized activity when N-methyl-D-aspartate receptor-mediated channels were facilitated. Layer 5 was both necessary and sufficient to produce these synchronized oscillations. Thus, synaptic networks of intrinsically rhythmic neurons in layer 5 may generate or promote certain synchronized oscillations of the neocortex.},
	author = {Silva, L. R. and Amitai, Y. and Connors, B. W.},
	copyright = {{\copyright} 1991},
	doi = {10.1126/science.1824881},
	file = {Snapshot:/Users/Cecile/Zotero/storage/WTNU8YV6/432.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jan,
	number = {4992},
	pages = {432--435},
	pmid = {1824881},
	title = {Intrinsic oscillations of neocortex generated by layer 5 pyramidal neurons},
	url = {http://science.sciencemag.org/content/251/4992/432},
	urldate = {2018-08-03},
	volume = {251},
	year = {1991},
	bdsk-url-1 = {http://science.sciencemag.org/content/251/4992/432},
	bdsk-url-2 = {https://doi.org/10.1126/science.1824881}}

@article{odabaee_neonatal_2014,
	abstract = {The potential improvements in spatial resolution of neonatal EEG used in source localization have been challenged by the insufficiencies in realistic neonatal head models. Our present study aimed at using empirical methods to indirectly estimate skull conductivity; the model parameter that is known to significantly affect the behavior of newborn scalp EEG and cause it to be markedly different from that of an adult. To this end, we used 64 channel EEG recordings to study the spatial specificity of scalp EEG by assessing the spatial decays in focal transients using both amplitudes and between-c'hannels linear correlations. The findings showed that these amplitudes and correlations decay within few centimeters from the reference channel/electrode, and that the nature of the decay is independent of the scalp area. This decay in newborn infants was found to be approximately three times faster than the corresponding decay in adult EEG analyzed from a set of 256 channel recordings. We then generated realistic head models using both finite and boundary element methods along with a manually segmented magnetic resonance images to study the spatial decays of scalp potentials produced by single dipole in the cortex. By comparing the spatial decays due to real and simulated EEG for different skull conductivities (from 0.003 to 0.3S/m), we showed that a close match between the empirical and simulated decays was obtained when the selected skull conductivity for newborn was around 0.06--0.2S/m. This is over an order of magnitude higher than the currently used values in adult head modeling. The results also showed that the neonatal scalp EEG is less smeared than that of an adult and this characteristic is the same across the entire scalp, including the fontanel region. These results indicate that a focal cortical activity is generally only registered by electrodes within few centimeters from the source. Hence, the conventional 10 to 20 channel neonatal EEG acquisition systems give a significantly spatially under sampled scalp EEG and may, consequently, give distorted pictures of focal brain activities. Such spatial specificity can only be reconciled by appreciating the anatomy of the neonatal head, especially the still unossified skull structure that needs to be modeled with higher conductivities than conventionally used in the adults.},
	author = {Odabaee, Maryam and Tokariev, Anton and Layeghy, Siamak and Mesbah, Mostefa and Colditz, Paul B. and Ramon, Ceon and Vanhatalo, Sampsa},
	doi = {10.1016/j.neuroimage.2014.04.007},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/L7LM6BE4/Odabaee et al. - 2014 - Neonatal EEG at scalp is focal and implies high sk.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/524UIQZX/S1053811914002626.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Head model, High density EEG, Neonatal EEG, Source localization},
	month = aug,
	pages = {73--80},
	title = {Neonatal {EEG} at scalp is focal and implies high skull conductivity in realistic neonatal head models},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811914002626},
	urldate = {2018-08-01},
	volume = {96},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914002626},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2014.04.007}}

@article{luo_concurrent_2006,
	abstract = {A natural sound can be described by dynamic changes in envelope (amplitude) and carrier (frequency), corresponding to amplitude modulation (AM) and frequency modulation (FM), respectively. Although the neural responses to both AM and FM sounds are extensively studied in both animals and humans, it is uncertain how they are corepresented when changed simultaneously but independently, as is typical for ecologically natural signals. This study elucidates the neural coding of such sounds in human auditory cortex using magnetoencephalography (MEG). Using stimuli with both sinusoidal modulated envelope (ƒAM, 37 Hz) and carrier frequency (ƒFM, 0.3--8 Hz), it is demonstrated that AM and FM stimulus dynamics are corepresented in the neural code of human auditory cortex. The stimulus AM dynamics are represented neurally with AM encoding, by the auditory steady-state response (aSSR) at ƒAM. For sounds with slowly changing carrier frequency (ƒFM {\textless}5 Hz), it is shown that the stimulus FM dynamics are tracked by the phase of the aSSR, demonstrating neural phase modulation (PM) encoding of the stimulus carrier frequency. For sounds with faster carrier frequency change (ƒFM ≥ 5 Hz), it is shown that modulation encoding of stimulus FM dynamics persists, but the neural encoding is no longer purely PM. This result is consistent with the recruitment of additional neural AM encoding over and above the original neural PM encoding, indicating that both the amplitude and phase of the aSSR at ƒAM track the stimulus FM dynamics. A neural model is suggested to account for these observations.},
	author = {Luo, Huan and Wang, Yadong and Poeppel, David and Simon, Jonathan Z.},
	doi = {10.1152/jn.01256.2005},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LJZ88J9D/Luo et al. - 2006 - Concurrent Encoding of Frequency and Amplitude Mod.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8XZFNT38/jn.01256.html:text/html},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	month = nov,
	number = {5},
	pages = {2712--2723},
	shorttitle = {Concurrent {Encoding} of {Frequency} and {Amplitude} {Modulation} in {Human} {Auditory} {Cortex}},
	title = {Concurrent {Encoding} of {Frequency} and {Amplitude} {Modulation} in {Human} {Auditory} {Cortex}: {MEG} {Evidence}},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.01256.2005},
	urldate = {2018-07-17},
	volume = {96},
	year = {2006},
	bdsk-url-1 = {https://www.physiology.org/doi/abs/10.1152/jn.01256.2005},
	bdsk-url-2 = {https://doi.org/10.1152/jn.01256.2005}}

@article{obleser_bilateral_2008,
	abstract = {{\textless}p{\textgreater}Speech comprehension has been shown to be a strikingly bilateral process, but the differential contributions of the subfields of left and right auditory cortices have remained elusive. The hypothesis that left auditory areas engage predominantly in decoding fast temporal perturbations of a signal whereas the right areas are relatively more driven by changes of the frequency spectrum has not been directly tested in speech or music. This brain-imaging study independently manipulated the speech signal itself along the spectral and the temporal domain using noise-band vocoding. In a parametric design with five temporal and five spectral degradation levels in word comprehension, a functional distinction of the left and right auditory association cortices emerged: increases in the temporal detail of the signal were most effective in driving brain activation of the left anterolateral superior temporal sulcus (STS), whereas the right homolog areas exhibited stronger sensitivity to the variations in spectral detail. In accordance with behavioral measures of speech comprehension acquired in parallel, change of spectral detail exhibited a stronger coupling with the STS BOLD signal. The relative pattern of lateralization (quantified using lateralization quotients) proved reliable in a jack-knifed iterative reanalysis of the group functional magnetic resonance imaging model. This study supplies direct evidence to the often implied functional distinction of the two cerebral hemispheres in speech processing. Applying direct manipulations to the speech signal rather than to low-level surrogates, the results lend plausibility to the notion of complementary roles for the left and right superior temporal sulci in comprehending the speech signal.{\textless}/p{\textgreater}},
	author = {Obleser, Jonas and Eisner, Frank and Kotz, Sonja A.},
	copyright = {Copyright {\copyright} 2008 Society for Neuroscience 0270-6474/08/288116-08\$15.00/0},
	doi = {10.1523/JNEUROSCI.1290-08.2008},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/J5MD42MX/Obleser et al. - 2008 - Bilateral Speech Comprehension Reflects Differenti.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/C3I47BS2/tab-article-info.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = aug,
	number = {32},
	pages = {8116--8123},
	pmid = {18685036},
	title = {Bilateral {Speech} {Comprehension} {Reflects} {Differential} {Sensitivity} to {Spectral} and {Temporal} {Features}},
	url = {http://www.jneurosci.org/content/28/32/8116},
	urldate = {2018-07-17},
	volume = {28},
	year = {2008},
	bdsk-url-1 = {http://www.jneurosci.org/content/28/32/8116},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1290-08.2008}}

@inproceedings{kawahara_tandem-straight:_2008,
	abstract = {A simple new method for estimating temporally stable power spectra is introduced to provide a unified basis for computing an interference-free spectrum, the fundamental frequency (F0), as well as aperiodicity estimation. F0 adaptive spectral smoothing and cepstral liftering based on consistent sampling theory are employed for interference-free spectral estimation. A perturbation spectrum, calculated from temporally stable power and interference-free spectra, provides the basis for both F0 and aperiodicity estimation. The proposed approach eliminates ad-hoc parameter tuning and the heavy demand on computational power, from which STRAIGHT has suffered in the past.},
	author = {Kawahara, H. and Morise, M. and Takahashi, T. and Nisimura, R. and Irino, T. and Banno, H.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	doi = {10.1109/ICASSP.2008.4518514},
	file = {IEEE Xplore Abstract Record:/Users/Cecile/Zotero/storage/97ZI4NMJ/4518514.html:text/html},
	keywords = {Speech analysis, adaptive estimation, adaptive signal processing, adaptive spectral smoothing, aperiodicity estimation, cepstral analysis, cepstral liftering, consistent sampling, consistent sampling theory, Filters, Fourier transforms, Frequency estimation, Interference, interference (signal), interference-free spectral estimation, periodic signal, periodic signal power spectral representation, periodicity, perturbation spectrum, power spectrum, Sampling methods, signal sampling, Signal sampling, smoothing methods, speech processing, speech synthesis, Speech synthesis, TANDEM-STRAIGHT, Testing, Transfer functions},
	month = mar,
	pages = {3933--3936},
	shorttitle = {Tandem-{STRAIGHT}},
	title = {Tandem-{STRAIGHT}: {A} temporally stable power spectral representation for periodic signals and applications to interference-free spectrum, {F0}, and aperiodicity estimation},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP.2008.4518514}}

@article{manju_association_2014,
	abstract = {Amplitude modulations in the speech convey important acoustic information for speech perception. Auditory steady state response (ASSR) is thought to be physiological correlate of amplitude modulation perception. Limited research is available exploring association between ASSR and modulation detection ability as well as speech perception. Correlation of modulation detection thresholds (MDT) and speech perception in noise with ASSR was investigated in twofold experiments. 30 normal hearing individuals and 11 normal hearing individuals within age range of 18-24 years participated in experiments 1 and 2, respectively. MDTs were measured using ASSR and behavioral method at 60 Hz, 80 Hz, and 120 Hz modulation frequencies in the first experiment. ASSR threshold was obtained by estimating the minimum modulation depth required to elicit ASSR (ASSR-MDT). There was a positive correlation between behavioral MDT and ASSR-MDT at all modulation frequencies. In the second experiment, ASSR for amplitude modulation (AM) sweeps at four different frequency ranges (30-40 Hz, 40-50 Hz, 50-60 Hz, and 60-70 Hz) was recorded. Speech recognition threshold in noise (SRTn) was estimated using staircase procedure. There was a positive correlation between amplitude of ASSR for AM sweep with frequency range of 30-40 Hz and SRTn. Results of the current study suggest that ASSR provides substantial information about temporal modulation and speech perception.},
	author = {Manju, Venugopal and Gopika, Kizhakke Kodiyath and Arivudai Nambi, Pitchai Muthu},
	doi = {10.1155/2014/374035},
	issn = {2090-5742},
	journal = {ISRN otolaryngology},
	language = {eng},
	pages = {374035},
	pmcid = {PMC4009337},
	pmid = {25006511},
	title = {Association of auditory steady state responses with perception of temporal modulations and speech in noise},
	volume = {2014},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1155/2014/374035}}

@article{millman_spatiotemporal_2010,
	abstract = {The aim of this study was to investigate the mechanisms involved in the perception of perceptually salient frequency modulation (FM) using auditory steady-state responses (ASSRs) measured with magnetoencephalography (MEG). Previous MEG studies using frequency-modulated amplitude modulation as stimuli (Luo et al., 2006, 2007) suggested that a phase modulation encoding mechanism exists for low ({\textless}5 Hz) FM modulation frequencies but additional amplitude modulation encoding is required for faster FM modulation frequencies. In this study single-cycle sinusoidal FM stimuli were used to generate the ASSR. The stimulus was either an unmodulated 1-kHz sinusoid or a 1-kHz sinusoid that was frequency-modulated with a repetition rate of 4, 8, or 12 Hz. The fast Fourier transform (FFT) of each MEG channel was calculated to obtain the phase and magnitude of the ASSR in sensor-space and multivariate Hotelling's T2 statistics were used to determine the statistical significance of ASSRs. MEG beamformer analyses were used to localise the ASSR sources. Virtual electrode analyses were used to reconstruct the time series at each source. FFTs of the virtual electrode time series were calculated to obtain the amplitude and phase characteristics of each source identified in the beamforming analyses. Multivariate Hotelling's T2 statistics were used to determine the statistical significance of these reconstructed ASSRs. The results suggest that the ability of auditory cortex to phase-lock to FM is dependent on the FM pulse rate and that the ASSR to FM is lateralised to the right hemisphere.},
	author = {Millman, Rebecca E. and Prendergast, Garreth and Kitterick, P{\'a}draig T. and Woods, Will P. and Green, Gary G. R.},
	doi = {10.1016/j.neuroimage.2009.08.029},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ATLYEQEL/Millman et al. - 2010 - Spatiotemporal reconstruction of the auditory stea.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KTMBGAYJ/S1053811909009410.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Auditory steady-state response, Beamforming, Frequency modulation, Magnetoencephalography, Phase-locking, Virtual electrodes},
	month = jan,
	number = {1},
	pages = {745--758},
	title = {Spatiotemporal reconstruction of the auditory steady-state response to frequency modulation using magnetoencephalography},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811909009410},
	urldate = {2018-09-05},
	volume = {49},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811909009410},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2009.08.029}}

@article{lewicki_efficient_2002,
	abstract = {The auditory system encodes sound by decomposing the amplitude signal arriving at the ear into multiple frequency bands whose center frequencies and bandwidths are approximately exponential functions of the distance from the stapes. This organization is thought to result from the adaptation of cochlear mechanisms to the animal's auditory environment. Here we report that several basic auditory nerve fiber tuning properties can be accounted for by adapting a population of filter shapes to encode natural sounds efficiently. The form of the code depends on sound class, resembling a Fourier transformation when optimized for animal vocalizations and a wavelet transformation when optimized for non-biological environmental sounds. Only for the combined set does the optimal code follow scaling characteristics of physiological data. These results suggest that auditory nerve fibers encode a broad set of natural sounds in a manner consistent with information theoretic principles.},
	author = {Lewicki, Michael S.},
	copyright = {2002 Nature Publishing Group},
	doi = {10.1038/nn831},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8P4PM49B/Lewicki - 2002 - Efficient coding of natural sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZRKRECDG/nn831.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = apr,
	number = {4},
	pages = {356--363},
	title = {Efficient coding of natural sounds},
	url = {https://www.nature.com/articles/nn831},
	urldate = {2018-09-02},
	volume = {5},
	year = {2002},
	bdsk-url-1 = {https://www.nature.com/articles/nn831},
	bdsk-url-2 = {https://doi.org/10.1038/nn831}}

@article{stilp_statistical_2013,
	author = {Stilp, Christian E. and Lewicki, Michael S.},
	doi = {10.1121/1.4865250},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/6MLHRRM9/Stilp et Lewicki - 2013 - Statistical structure of speech sound classes is c.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NGJRX7SV/1.html:text/html},
	journal = {Proceedings of Meetings on Acoustics},
	month = dec,
	number = {1},
	pages = {050001},
	title = {Statistical structure of speech sound classes is congruent with cochlear nucleus response properties},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.4865250},
	urldate = {2018-09-02},
	volume = {20},
	year = {2013},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.4865250},
	bdsk-url-2 = {https://doi.org/10.1121/1.4865250}}

@article{nelken_processing_2008,
	abstract = {The coding of complex sounds in the early auditory system has a `standard model' based on the known physiology of the cochlea and main brainstem pathways. This model accounts for a wide range of perceptual capabilities. It is generally accepted that high cortical areas encode abstract qualities such as spatial location or speech sound identity. Between the early and late auditory system, the role of primary auditory cortex (A1) is still debated. A1 is clearly much more than a `whiteboard' of acoustic information---neurons in A1 have complex response properties, showing sensitivity to both low-level and high-level features of sounds.},
	author = {Nelken, Israel},
	doi = {10.1016/j.conb.2008.08.014},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QTB396WK/Nelken - 2008 - Processing of complex sounds in the auditory syste.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WJYFQZ35/S0959438808000895.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = aug,
	number = {4},
	pages = {413--417},
	series = {Sensory systems},
	title = {Processing of complex sounds in the auditory system},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438808000895},
	urldate = {2018-09-02},
	volume = {18},
	year = {2008},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438808000895},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2008.08.014}}

@article{nelken_processing_2004,
	abstract = {Neuronal responses in auditory cortex show a fascinating mixture of characteristics that span the range from almost perfect copies of physical aspects of the stimuli to extremely complex context-dependent responses. Fast, highly stimulus-specific adaptation and slower plastic mechanisms work together to constantly adjust neuronal response properties to the statistics of the auditory scene. Evidence with converging implications suggests that the neuronal activity in primary auditory cortex represents sounds in terms of auditory objects rather than in terms of invariant acoustic features.},
	author = {Nelken, Israel},
	doi = {10.1016/j.conb.2004.06.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YFUGFF23/Nelken - 2004 - Processing of complex stimuli and natural scenes i.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JGPY5RRQ/S0959438804000947.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = aug,
	number = {4},
	pages = {474--480},
	title = {Processing of complex stimuli and natural scenes in the auditory cortex},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438804000947},
	urldate = {2018-09-02},
	volume = {14},
	year = {2004},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438804000947},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2004.06.005}}

@article{walker_multiplexed_2011,
	abstract = {We can recognize the melody of a familiar song when it is played on different musical instruments. Similarly, an animal must be able to recognize a warning call whether the caller has a high-pitched female or a lower-pitched male voice, and whether they are sitting in a tree to the left or right. This type of perceptual invariance to ``nuisance'' parameters comes easily to listeners, but it is unknown whether or how such robust representations of sounds are formed at the level of sensory cortex. In this study, we investigate whether neurons in both core and belt areas of ferret auditory cortex can robustly represent the pitch, formant frequencies, or azimuthal location of artificial vowel sounds while the other two attributes vary. We found that the spike rates of the majority of cortical neurons that are driven by artificial vowels carry robust representations of these features, but the most informative temporal response windows differ from neuron to neuron and across five auditory cortical fields. Furthermore, individual neurons can represent multiple features of sounds unambiguously by independently modulating their spike rates within distinct time windows. Such multiplexing may be critical to identifying sounds that vary along more than one perceptual dimension. Finally, we observed that formant information is encoded in cortex earlier than pitch information, and we show that this time course matches ferrets' behavioral reaction time differences on a change detection task.},
	author = {Walker, Kerry M. M. and Bizley, Jennifer K. and King, Andrew J. and Schnupp, Jan W. H.},
	copyright = {Copyright {\copyright} 2011 the authors 0270-6474/11/3114565-12\$15.00/0},
	doi = {10.1523/JNEUROSCI.2074-11.2011},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UYK6ZZTY/Walker et al. - 2011 - Multiplexed and Robust Representations of Sound Fe.pdf:application/pdf},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = oct,
	number = {41},
	pages = {14565--14576},
	pmid = {21994373},
	title = {Multiplexed and {Robust} {Representations} of {Sound} {Features} in {Auditory} {Cortex}},
	url = {http://www.jneurosci.org/content/31/41/14565},
	urldate = {2018-09-02},
	volume = {31},
	year = {2011},
	bdsk-url-1 = {http://www.jneurosci.org/content/31/41/14565},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2074-11.2011}}

@article{delorme_eeglab:_2004,
	abstract = {We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive `pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A `plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.},
	author = {Delorme, Arnaud and Makeig, Scott},
	doi = {10.1016/j.jneumeth.2003.10.009},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/78SGQRG6/Delorme et Makeig - 2004 - EEGLAB an open source toolbox for analysis of sin.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9GSLXCTP/S0165027003003479.html:text/html},
	issn = {0165-0270},
	journal = {Journal of Neuroscience Methods},
	keywords = {EEG, Software, ERP, ICA, Matlab, Single-trial, Spectral decomposition},
	month = mar,
	number = {1},
	pages = {9--21},
	shorttitle = {{EEGLAB}},
	title = {{EEGLAB}: an open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
	url = {http://www.sciencedirect.com/science/article/pii/S0165027003003479},
	urldate = {2018-08-29},
	volume = {134},
	year = {2004},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0165027003003479},
	bdsk-url-2 = {https://doi.org/10.1016/j.jneumeth.2003.10.009}}

@article{cohen_where_2017,
	abstract = {Electroencephalography (EEG) has been instrumental in making discoveries about cognition, brain function, and dysfunction. However, where do EEG signals come from and what do they mean? The purpose of this paper is to argue that we know shockingly little about the answer to this question, to highlight what we do know, how important the answers are, and how modern neuroscience technologies that allow us to measure and manipulate neural circuits with high spatiotemporal accuracy might finally bring us some answers. Neural oscillations are perhaps the best feature of EEG to use as anchors because oscillations are observed and are studied at multiple spatiotemporal scales of the brain, in multiple species, and are widely implicated in cognition and in neural computations.},
	author = {Cohen, Michael X},
	doi = {10.1016/j.tins.2017.02.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/VRCVKT2Y/Cohen - 2017 - Where Does EEG Come From and What Does It Mean.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ILF44DKQ/S0166223617300243.html:text/html},
	issn = {0166-2236},
	journal = {Trends in Neurosciences},
	keywords = {EEG, computation, electrophysiology, neural microcircuit, oscillations},
	month = apr,
	number = {4},
	pages = {208--218},
	title = {Where {Does} {EEG} {Come} {From} and {What} {Does} {It} {Mean}?},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223617300243},
	urldate = {2018-08-28},
	volume = {40},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223617300243},
	bdsk-url-2 = {https://doi.org/10.1016/j.tins.2017.02.004}}

@article{cohen_its_2011,
	author = {Cohen, Michael X},
	doi = {10.3389/fnhum.2011.00002},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/IDACVXDE/Cohen - 2011 - It's about Time.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = jan,
	pmcid = {PMC3025647},
	pmid = {21267395},
	title = {It's about {Time}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025647/},
	urldate = {2018-08-28},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025647/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2011.00002}}

@article{grossmann_detection_2010,
	abstract = {A precondition for successful communication between people is the detection of signals indicating the intention to communicate, such as eye contact or calling a person's name. In adults, establishing communication by eye contact or calling a person's name results in overlapping activity in right prefrontal cortex, suggesting that, regardless of modality, the intention to communicate is detected by the same brain region. We measured prefrontal cortex responses in 5-month-olds using near-infrared spectroscopy (NIRS) to examine the neural basis of detecting communicative signals across modalities in early development. Infants watched human faces that either signaled eye contact or directed their gaze away from the infant, and they also listened to voices that addressed them with their own name or another name. The results revealed that infants recruit adjacent but non-overlapping regions in the left dorsal prefrontal cortex when they process eye contact and own name. Moreover, infants that responded sensitively to eye contact in the one prefrontal region were also more likely to respond sensitively to their own name in the adjacent prefrontal region as revealed in a correlation analysis, suggesting that responding to communicative signals in these two regions might be functionally related. These NIRS results suggest that infants selectively process and attend to communicative signals directed at them. However, unlike adults, infants do not seem to recruit a common prefrontal region when processing communicative signals of different modalities. The implications of these findings for our understanding of infants' developing communicative abilities are discussed.},
	author = {Grossmann, Tobias and Parise, Eugenio and Friederici, Angela D.},
	doi = {10.3389/fnhum.2010.00201},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/64VG8I67/Grossmann et al. - 2010 - The Detection of Communicative Signals Directed at.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	month = oct,
	pmcid = {PMC2981376},
	pmid = {21088694},
	title = {The {Detection} of {Communicative} {Signals} {Directed} at the {Self} in {Infant} {Prefrontal} {Cortex}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2981376/},
	urldate = {2017-12-14},
	volume = {4},
	year = {2010},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2981376/},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2010.00201}}

@article{taga_spatiotemporal_2011,
	abstract = {Multi-channel near-infrared spectroscopy (NIRS) has been used as a neuroimaging tool to study functional activation of the developing brain in infants. In this paper, we focus on spatiotemporal dynamics of cortical oxygenation changes during sensory processing in young infants. We use a 94-channel NIRS system to assess the activity of wide regions of the cortex in quietly sleeping three-month-old infants. Auditory stimuli composed of a random sequence of pure tones induced haemodynamic changes not only in the temporal auditory regions, but also in the occipital and frontal regions. Analyses of phase synchronization showed that mutual synchronizations of signal changes among the cortical regions were much stronger than the stimulus-induced synchronizations of signal changes. Furthermore, analyses of phase differences among cortical regions revealed phase advancement of the bilateral temporal auditory regions, and phase gradient in a posterior direction from the temporal auditory regions to the occipital regions and in an anterior direction within the frontal regions. We argue that multi-channel NIRS is capable of detecting the precise timing of cortical activation and its flow in the global network of the developing brain.},
	author = {Taga, Gentaro and Watanabe, Hama and Homae, Fumitaka},
	copyright = {This journal is {\copyright} 2011 The Royal Society},
	doi = {10.1098/rsta.2011.0238},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/XDK3GG9E/Taga et al. - 2011 - Spatiotemporal properties of cortical haemodynamic.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3NG7QYSH/4495.html:text/html},
	issn = {1364-503X, 1471-2962},
	journal = {Phil. Trans. R. Soc. A},
	language = {en},
	month = nov,
	number = {1955},
	pages = {4495--4511},
	pmid = {22006903},
	title = {Spatiotemporal properties of cortical haemodynamic response to auditory stimuli in sleeping infants revealed by multi-channel near-infrared spectroscopy},
	url = {http://rsta.royalsocietypublishing.org/content/369/1955/4495},
	urldate = {2017-08-15},
	volume = {369},
	year = {2011},
	bdsk-url-1 = {http://rsta.royalsocietypublishing.org/content/369/1955/4495},
	bdsk-url-2 = {https://doi.org/10.1098/rsta.2011.0238}}

@book{pike_intonation_1945,
	author = {Pike, Kenneth Lee},
	language = {en},
	note = {Google-Books-ID: Jz3iAAAAMAAJ},
	publisher = {University of Michigan Press},
	title = {The {Intonation} of {American} {English}},
	year = {1945}}

@article{anders_standardized_1971,
	author = {Anders, T.F. and {Emde, R.} and {Parmelee, A. A.}},
	journal = {UCLA Brain Information Service},
	title = {A standardized terminology, techniques and criteria for scoring states of sleep and wakefulness},
	year = {1971}}

@article{martynova_mismatch_2003,
	abstract = {Event-related potentials were recorded from sleeping newborns to compare amplitudes and latencies of mismatch negativity (MMN) and late discriminative negativity (LDN) in active and quiet sleep stages. MMN and LDN were obtained in response to changes in semi-synthesized vowels from 20 healthy newborn infants. MMN and LDN responses were significant for both active and quiet sleep. The amplitude and latency of MMN or LDN did not differ between the sleep stages. Thus, in contrast to adult studies that show a significant drop in the MMN amplitude and an increase in the MMN latency as the sleep gets deeper, arousal stages do not seem to effect either MMN or LDN characteristics in newborns. These results suggest functional differences between infant and adult sleep.},
	author = {Martynova, Olga and Kirjavainen, Jarkko and Cheour, Marie},
	doi = {10.1016/S0304-3940(02)01401-5},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SQX549J4/Martynova et al. - 2003 - Mismatch negativity and late discriminative negati.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZA6MH2I7/S0304394002014015.html:text/html},
	issn = {0304-3940},
	journal = {Neuroscience Letters},
	keywords = {Sleep, Mismatch negativity, Event-related potential, Late discriminative negativity, Newborns},
	month = apr,
	number = {2},
	pages = {75--78},
	title = {Mismatch negativity and late discriminative negativity in sleeping human newborns},
	url = {http://www.sciencedirect.com/science/article/pii/S0304394002014015},
	urldate = {2018-08-25},
	volume = {340},
	year = {2003},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394002014015},
	bdsk-url-2 = {https://doi.org/10.1016/S0304-3940(02)01401-5}}

@article{plonsey_considerations_1967,
	abstract = {Conditions under which a time varying electromagnetic field problem (such as arises in electrophysiology, electrocardiography, etc.) can be reduced to the conventional quasistatic problem are summarized. These conditions are discussed for typical physiological parameters.},
	author = {Plonsey, Robert and Heppner, Dennis B.},
	doi = {10.1007/BF02476917},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/Y9XDD3LV/Plonsey et Heppner - 1967 - Considerations of quasi-stationarity in electrophy.pdf:application/pdf},
	issn = {1522-9602},
	journal = {The bulletin of mathematical biophysics},
	keywords = {Effect Neglect, Electrophysiological System, Normal Electric Field, Scalar Helmholtz Equation, Secondary Field},
	language = {en},
	month = dec,
	number = {4},
	pages = {657--664},
	title = {Considerations of quasi-stationarity in electrophysiological systems},
	url = {https://doi.org/10.1007/BF02476917},
	urldate = {2018-08-25},
	volume = {29},
	year = {1967},
	bdsk-url-1 = {https://doi.org/10.1007/BF02476917}}

@book{nunez_electric_2006,
	abstract = {Electroencephalography (EEG) is practiced by neurologists, cognitive neuroscientists, and others interested in functional brain imaging. Whether for clinical or experimental purposes, all studies share a common purpose-to relate scalp potentials to the underlying neurophysiology. Electrical potentials on the scalp exhibit spatial and temporal patterns that depend on the nature and location of the sources and the way that currents and fields spread through tissue. Because these dynamic patterns are correlated with behavior and cognition, EEG provides a "window on the mind," correlating physiology and psychology. This classic and widely acclaimed text, originally published in 1981, filled the large gap between EEG and the physical sciences. It has now been brought completely up to date and will again serve as an invaluable resource for understanding the principles of electric fields in living tissue and for using hard science to study human consciousness and cognition. No comparable volume exists for it is no easy task to explain the problems of EEG in clear language, with mathematics presented mainly in appendices. Among the many topics covered by the Second Edition are micro and meso (intermediate scale) synaptic sources, electrode placement, choice of reference, volume conduction, power and coherence measures, projection of scalp potentials to dura surface, dynamic signatures of conscious experience, neural networks immersed in global fields of synaptic action, and physiological bases for brain source dynamics. The Second Edition is an invaluable resource for neurologists, neuroscientists (especially cognitive neuroscientists), biomedical engineers, and their students and trainees. It will also appeal to physicists, mathematicians, computer scientists, psychiatrists, and industrial engineers interested in EEG.},
	author = {Nunez, Paul L. and Nunez, Emeritus Professor of Biomedical Engineering Paul L. and Srinivasan, Ramesh and Srinivasan, Assistant Professor of Cognitive Science Ramesh},
	isbn = {978-0-19-505038-7},
	keywords = {Medical / Neurology, Medical / Neuroscience},
	language = {en},
	note = {Google-Books-ID: fUv54as56\_8C},
	publisher = {Oxford University Press},
	shorttitle = {Electric {Fields} of the {Brain}},
	title = {Electric {Fields} of the {Brain}: {The} {Neurophysics} of {EEG}},
	year = {2006}}

@article{munck_how_2010,
	author = {Munck, Jan C. de and Bijma, Fetsje},
	doi = {10.1016/j.clinph.2009.10.002},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/H6SDK7T4/Munck et Bijma - 2010 - How are evoked responses generated The need for a.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XQNLHMRL/S1388245709005811.html:text/html},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology},
	month = feb,
	number = {2},
	pages = {127--129},
	shorttitle = {How are evoked responses generated?},
	title = {How are evoked responses generated? {The} need for a unified mathematical framework},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245709005811},
	urldate = {2018-08-25},
	volume = {121},
	year = {2010},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245709005811},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2009.10.002}}

@book{cohen_analyzing_2014,
	abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, and LFP recordings.
                This book offers a comprehensive guide to the theory and practice of analyzing electrical brain signals. It explains the conceptual, mathematical, and implementational (via Matlab programming) aspects of time-, time-frequency- and synchronization-based analyses of magnetoencephalography (MEG), electroencephalography (EEG), and local field potential (LFP) recordings from humans and nonhuman animals. It is the only book on the topic that covers both the theoretical background and the implementation in language that can be understood by readers without extensive formal training in mathematics, including cognitive scientists, neuroscientists, and psychologists.Readers who go through the book chapter by chapter and implement the examples in Matlab will develop an understanding of why and how analyses are performed, how to interpret results, what the methodological issues are, and how to perform single-subject-level and group-level analyses. Researchers who are familiar with using automated programs to perform advanced analyses will learn what happens when they click the ``analyze now'' button.The book provides sample data and downloadable Matlab code. Each of the 38 chapters covers one analysis topic, and these topics progress from simple to advanced. Most chapters conclude with exercises that further develop the material covered in the chapter. Many of the methods presented (including convolution, the Fourier transform, and Euler's formula) are fundamental and form the groundwork for other advanced data analysis methods. Readers who master the methods in the book will be well prepared to learn other approaches.},
	address = {Cambridge, Mass.},
	author = {Cohen, Mike X},
	file = {Snapshot:/Users/Cecile/Zotero/storage/BWT4W7V4/analyzing-neural-time-series-data.html:text/html},
	isbn = {978-0-262-01987-3},
	language = {en},
	month = jan,
	publisher = {MIT Press},
	series = {Issues in {Clinical} and {Cognitive} {Neuropsychology}},
	shorttitle = {Analyzing {Neural} {Time} {Series} {Data}},
	title = {Analyzing {Neural} {Time} {Series} {Data}: {Theory} and {Practice}},
	url = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data},
	urldate = {2018-08-25},
	year = {2014},
	bdsk-url-1 = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data}}

@book{luck_introduction_2014,
	abstract = {An essential guide to designing, conducting, and analyzing event-related potential (ERP) experiments, completely updated for this edition.
                The event-related potential (ERP) technique, in which neural responses to specific events are extracted from the EEG, provides a powerful noninvasive tool for exploring the human brain. This volume describes practical methods for ERP research along with the underlying theoretical rationale. It offers researchers and students an essential guide to designing, conducting, and analyzing ERP experiments. This second edition has been completely updated, with additional material, new chapters, and more accessible explanations. Freely available supplementary material, including several online-only chapters, offer expanded or advanced treatment of selected topics.The first half of the book presents essential background information, describing the origins of ERPs, the nature of ERP components, and the design of ERP experiments. The second half of the book offers a detailed treatment of the main steps involved in conducting ERP experiments, covering such topics as recording the EEG, filtering the EEG and ERP waveforms, and quantifying amplitudes and latencies. Throughout, the emphasis is on rigorous experimental design and relatively simple analyses. New material in the second edition includes entire chapters devoted to components, artifacts, measuring amplitudes and latencies, and statistical analysis; updated coverage of recording technologies; concrete examples of experimental design; and many more figures. Online chapters cover such topics as overlap, localization, writing and reviewing ERP papers, and setting up and running an ERP lab.},
	address = {Cambridge, Mass.},
	author = {Luck, Steven J.},
	edition = {2nd edition},
	file = {Snapshot:/Users/Cecile/Zotero/storage/6K96Z5CT/introduction-event-related-potential-technique-second-edition.html:text/html},
	isbn = {978-0-262-52585-5},
	language = {en},
	publisher = {MIT press},
	title = {An {Introduction} to the {Event}-{Related} {Potential} {Technique}, {Second} {Edition}},
	url = {https://mitpress.mit.edu/books/introduction-event-related-potential-technique-second-edition},
	urldate = {2018-08-25},
	year = {2014},
	bdsk-url-1 = {https://mitpress.mit.edu/books/introduction-event-related-potential-technique-second-edition}}

@article{buzsaki_nucleus_1988,
	abstract = {EEG and single-unit techniques have been used to study the EEG correlates of cellular firing in the neocortex, n. reticularis (RT) and ``specific'' thalamic nuclei, and the cholinergic forebrain area (nucleus basalis, NB). Neuronal firing was related to the ongoing behavior of the rat. In addition, using a 16-channel neocortical recording/mapping system, we studied the effects of ibotenic acid lesion of NB, RT, and other thalamic nuclei on the patterns and spatial distribution of neocortical electrical activity. The majority of neurons in neocortex, NB, and RT increased their firing rates during walking, as compared to during immobility, with concurrent decrease of delta power in the neocortical EEG. During immobility, high-voltage spindles (HVS; greater than 1 mV) were occasionally recorded from the neocortex. Depth profiles of HVS and slow delta waves were different in the neocortex. Neocortical cells decreased their discharge frequency during the positive portion of delta waves recorded in layers V and VI. All cells in the neocortex and specific thalamic nuclei fired rhythmically and phase-locked to the spike component of HVS. RT neurons showed an opposite phase relationship and fired mainly during the wave component of HVS. Half of the NB neurons also showed phasic modulation with HVS. Circumscribed lesion of RT and extensive damage of other thalamic regions, including the intralaminar nuclei, suppressed HVS but had no effect on the neocortical EEG correlates of behavior. In sharp contrast, damage to the NB resulted in a dramatic increase of slow delta waves on the side of the lesion, mimicking the effect of scopolamine administration. We suggest that the NB plays a key role in neocortical arousal by directly activating the neocortex and by suppressing the rhythm generation in the RT-thalamocortical circuitry. We further suggest that the NB system may serve as a structural basis for the concept of the generalized ascending activation of Moruzzi and Magoun (1949).},
	author = {Buzsaki, G. and Bickford, R. G. and Ponomareff, G. and Thal, L. J. and Mandel, R. and Gage, F. H.},
	copyright = {{\copyright} 1988 by Society for Neuroscience},
	doi = {10.1523/JNEUROSCI.08-11-04007.1988},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UYCRPH99/Buzsaki et al. - 1988 - Nucleus basalis and thalamic control of neocortica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K7MGNEL6/4007.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = nov,
	number = {11},
	pages = {4007--4026},
	pmid = {3183710},
	title = {Nucleus basalis and thalamic control of neocortical activity in the freely moving rat},
	url = {http://www.jneurosci.org/content/8/11/4007},
	urldate = {2018-08-25},
	volume = {8},
	year = {1988},
	bdsk-url-1 = {http://www.jneurosci.org/content/8/11/4007},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.08-11-04007.1988}}

@article{gervain_speech_2010,
	abstract = {During the first year of life, infants pass important milestones in language development. We review some of the experimental evidence concerning these milestones in the domains of speech perception, phonological development, word learning, morphosyntactic acquisition, and bilingualism, emphasizing their interactions. We discuss them in the context of their biological underpinnings, introducing the most recent advances not only in language development, but also in neighboring areas such as genetics and the comparative research on animal communication systems. We argue for a theory of language acquisition that integrates behavioral, cognitive, neural, and evolutionary considerations and proposes to unify previously opposing theoretical stances, such as statistical learning, rule-based nativist accounts, and perceptual learning theories.},
	author = {Gervain, Judit and Mehler, Jacques},
	doi = {10.1146/annurev.psych.093008.100408},
	journal = {Annual Review of Psychology},
	number = {1},
	pages = {191--218},
	pmid = {19575623},
	title = {Speech {Perception} and {Language} {Acquisition} in the {First} {Year} of {Life}},
	url = {https://doi.org/10.1146/annurev.psych.093008.100408},
	urldate = {2018-08-25},
	volume = {61},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1146/annurev.psych.093008.100408}}

@article{davidesco_electrocorticographic_2018,
	abstract = {Human listeners understand spoken language across a variety of rates, but when speech is presented three times or more faster than its usual rate, it becomes unintelligible. How the brain achieves such tolerance and why speech becomes unintelligible above certain rates is still unclear. We addressed these questions using electrocorticography (ECoG) recordings in 7 epileptic patients (two female). Patients rated the intelligibility of sentences presented at the original rate (100\%), speeded rates (33\% or 66\% of the original sentence duration) and a slowed rate (150\%). We then examined which parameters of the neural response covary with the transition from intelligible to unintelligible speech. Specifically, we asked whether neural responses: 1) track the acoustic envelope of the incoming speech; 2) scale with speech rate, i.e. whether neural responses elicited by slowed and speeded sentences can be linearly scaled to match the responses to the original sentence. Behaviorally, intelligibility was at ceiling for speech rates of 66\% and above, but dropped significantly for the 33\% rate. At the neural level, Superior Temporal Gyrus regions (STG) in close proximity to A1 (low-level) tracked the acoustic envelope and linearly scaled with the input across all speech rates, irrespective of intelligibility. In contrast, secondary auditory areas in the STG as well as the inferior frontal gyrus and angular gyrus (high-level) tracked the acoustic envelope and linearly scaled with input only for intelligible speech. These results help reconcile seemingly contradictory previous findings and provide better understanding of how information processing unfolds along the cortical auditory hierarchy.},
	author = {Davidesco, Ido and Thesen, Thomas and Honey, Christopher J. and Melloni, Lucia and Doyle, Werner and Devinsky, Orrin and Ghitza, Oded and Schroeder, Charles and Poeppel, David and Hasson, Uri},
	copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	doi = {10.1101/354464},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/V56YX6D5/Davidesco et al. - 2018 - Electrocorticographic responses to time-compressed.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JXW2P7HC/354464.html:text/html},
	issn = {10.1101/354464},
	journal = {bioRxiv},
	language = {en},
	month = jun,
	pages = {354464},
	title = {Electrocorticographic responses to time-compressed speech vary across the cortical auditory hierarchy},
	url = {https://www.biorxiv.org/content/early/2018/06/22/354464},
	urldate = {2018-08-25},
	year = {2018},
	bdsk-url-1 = {https://www.biorxiv.org/content/early/2018/06/22/354464},
	bdsk-url-2 = {https://doi.org/10.1101/354464}}

@article{diliberto_low-frequency_2015,
	abstract = {Summary
The human ability to understand speech is underpinned by a hierarchical auditory system whose successive stages process increasingly complex attributes of the acoustic input. It has been suggested that to produce categorical speech perception, this system must elicit consistent neural responses to speech tokens (e.g., phonemes) despite variations in their acoustics. Here, using electroencephalography (EEG), we provide evidence for this categorical phoneme-level speech processing by showing that the relationship between continuous speech and neural activity is best described when that speech is represented using both low-level spectrotemporal information and categorical labeling of phonetic features. Furthermore, the mapping between phonemes and EEG becomes more discriminative for phonetic features at longer latencies, in line with what one might expect from a hierarchical system. Importantly, these effects are not seen for time-reversed speech. These findings may form the basis for future research on natural language processing in specific cohorts of interest and for broader insights into how brains transform acoustic input into meaning.},
	author = {Di Liberto, Giovanni M. and O'Sullivan, James A. and Lalor, Edmund C.},
	doi = {10.1016/j.cub.2015.08.030},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4P5T6T39/Di Liberto et al. - 2015 - Low-Frequency Cortical Entrainment to Speech Refle.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/I8TIBFS5/S0960982215010015.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	month = oct,
	number = {19},
	pages = {2457--2465},
	title = {Low-{Frequency} {Cortical} {Entrainment} to {Speech} {Reflects} {Phoneme}-{Level} {Processing}},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982215010015},
	urldate = {2018-08-25},
	volume = {25},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982215010015},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.08.030}}

@article{potter_toward_1950,
	author = {Potter, R. K. and Steinberg, J. C.},
	doi = {10.1121/1.1906694},
	file = {Potter et Steinberg - 1950 - Toward the Specification of Speech.pdf:/Users/Cecile/Zotero/storage/MHJ7B29F/Potter et Steinberg - 1950 - Toward the Specification of Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MZZPQVRJ/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = nov,
	number = {6},
	pages = {807--820},
	title = {Toward the {Specification} of {Speech}},
	url = {https://asa.scitation.org/doi/10.1121/1.1906694},
	urldate = {2018-08-25},
	volume = {22},
	year = {1950},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.1906694},
	bdsk-url-2 = {https://doi.org/10.1121/1.1906694}}

@article{ding_temporal_2017,
	abstract = {Speech and music have structured rhythms. Here we discuss a major acoustic correlate of spoken and musical rhythms, the slow (0.25--32Hz) temporal modulations in sound intensity and compare the modulation properties of speech and music. We analyze these modulations using over 25h of speech and over 39h of recordings of Western music. We show that the speech modulation spectrum is highly consistent across 9 languages (including languages with typologically different rhythmic characteristics). A different, but similarly consistent modulation spectrum is observed for music, including classical music played by single instruments of different types, symphonic, jazz, and rock. The temporal modulations of speech and music show broad but well-separated peaks around 5 and 2Hz, respectively. These acoustically dominant time scales may be intrinsic features of speech and music, a possibility which should be investigated using more culturally diverse samples in each domain. Distinct modulation timescales for speech and music could facilitate their perceptual analysis and its neural processing.},
	author = {Ding, Nai and Patel, Aniruddh D. and Chen, Lin and Butler, Henry and Luo, Cheng and Poeppel, David},
	doi = {10.1016/j.neubiorev.2017.02.011},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4YQCEE88/Ding et al. - 2017 - Temporal modulations in speech and music.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4ZD2FV9A/S0149763416305668.html:text/html},
	issn = {0149-7634},
	journal = {Neuroscience \& Biobehavioral Reviews},
	keywords = {Music, Rhythm, Speech, Modulation spectrum, Temporal modulations},
	month = oct,
	pages = {181--187},
	series = {The {Biology} of {Language}},
	title = {Temporal modulations in speech and music},
	url = {http://www.sciencedirect.com/science/article/pii/S0149763416305668},
	urldate = {2018-08-25},
	volume = {81},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0149763416305668},
	bdsk-url-2 = {https://doi.org/10.1016/j.neubiorev.2017.02.011}}

@book{chiba_vowel:_1941,
	author = {Chiba, Tsutomu and Kajiyama, Masato},
	language = {en},
	note = {Google-Books-ID: tpkKAAAAMAAJ},
	publisher = {Tokyo-Kaiseikan},
	shorttitle = {The vowel},
	title = {The vowel: its nature and structure},
	year = {1941}}

@book{moore_introduction_2012,
	abstract = {Now available in a sixth edition, An Introduction to the Psychology of Hearing is the leading textbook in the field of auditory perception, also known as psychoacoustics.The textbooks longevity and loyal readership can be attributed to the accessible manner in which it describes the relationships between the characteristics of the sounds that enter the ear and the sensations that they produce. Wherever possible, the author has specified these relationships in terms of the underlying mechanisms. The intention is to impart an understanding of what the auditory system does and how it works: research results are not just described, but are interpreted and evaluated; knowledge is not assumed, but deduced from basic principles. Topics covered include the physics of sound, the physiology of the auditory system, frequency selectivity and masking, loudness perception, temporal analysis, pitch perception, sound localization, timbre perception, the perceptual organization of complex auditory scenes, speech perception, and practical applications such as hearing aids, cochlear implants, and high-fidelity sound reproduction. The book also includes extensive references to recent research so that those interested in a specific area can readily obtain more detailed information.},
	author = {Moore, Brian C. J.},
	isbn = {978-1-78052-038-4},
	keywords = {Science / Life Sciences / Neuroscience, Psychology / Cognitive Psychology \& Cognition, Science / Acoustics \& Sound},
	language = {en},
	note = {Google-Books-ID: LM9U8e28pLMC},
	publisher = {BRILL},
	title = {An {Introduction} to the {Psychology} of {Hearing}},
	year = {2012}}

@article{ramus_language_1999,
	author = {Ramus, Franck and Mehler, Jacques},
	doi = {10.1121/1.424522},
	file = {Ramus et Mehler - 1999 - Language identification with suprasegmental cues .pdf:/Users/Cecile/Zotero/storage/9EPZARCC/Ramus et Mehler - 1999 - Language identification with suprasegmental cues .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/SX7EYB7K/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = jan,
	number = {1},
	pages = {512--521},
	shorttitle = {Language identification with suprasegmental cues},
	title = {Language identification with suprasegmental cues: {A} study based on speech resynthesis},
	url = {https://asa.scitation.org/doi/10.1121/1.424522},
	urldate = {2018-08-22},
	volume = {105},
	year = {1999},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.424522},
	bdsk-url-2 = {https://doi.org/10.1121/1.424522}}

@article{nichols_nonparametric_2002,
	abstract = {Requiring only minimal assumptions for validity, nonparametric permutation testing provides a flexible and intuitive methodology for the statistical analysis of data from functional neuroimaging experiments, at some computational expense. Introduced into the functional neuroimaging literature by Holmes et al. ([1996]: J Cereb Blood Flow Metab 16:7--22), the permutation approach readily accounts for the multiple comparisons problem implicit in the standard voxel-by-voxel hypothesis testing framework. When the appropriate assumptions hold, the nonparametric permutation approach gives results similar to those obtained from a comparable Statistical Parametric Mapping approach using a general linear model with multiple comparisons corrections derived from random field theory. For analyses with low degrees of freedom, such as single subject PET/SPECT experiments or multi-subject PET/SPECT or fMRI designs assessed for population effects, the nonparametric approach employing a locally pooled (smoothed) variance estimate can outperform the comparable Statistical Parametric Mapping approach. Thus, these nonparametric techniques can be used to verify the validity of less computationally expensive parametric approaches. Although the theory and relative advantages of permutation approaches have been discussed by various authors, there has been no accessible explication of the method, and no freely distributed software implementing it. Consequently, there have been few practical applications of the technique. This article, and the accompanying MATLAB software, attempts to address these issues. The standard nonparametric randomization and permutation testing ideas are developed at an accessible level, using practical examples from functional neuroimaging, and the extensions for multiple comparisons described. Three worked examples from PET and fMRI are presented, with discussion, and comparisons with standard parametric approaches made where appropriate. Practical considerations are given throughout, and relevant statistical concepts are expounded in appendices. Hum. Brain Mapping 15:1--25, 2001. {\copyright} 2001 Wiley-Liss, Inc.},
	author = {Nichols, Thomas E. and Holmes, Andrew P.},
	copyright = {Copyright {\copyright} 2001 Wiley‐Liss, Inc.},
	doi = {10.1002/hbm.1058},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PPSRGNR4/Nichols et Holmes - 2002 - Nonparametric permutation tests for functional neu.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZV2WKCWF/hbm.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {nonparametric, general linear model, hypothesis test, multiple comparisons, permutation test, randomization test, SPM, statistic image},
	language = {fr},
	month = jan,
	number = {1},
	pages = {1--25},
	shorttitle = {Nonparametric permutation tests for functional neuroimaging},
	title = {Nonparametric permutation tests for functional neuroimaging: {A} primer with examples},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.1058},
	urldate = {2018-08-22},
	volume = {15},
	year = {2002},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.1058},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.1058}}

@article{maris_nonparametric_2007,
	abstract = {In this paper, we show how ElectroEncephaloGraphic (EEG) and MagnetoEncephaloGraphic (MEG) data can be analyzed statistically using nonparametric techniques. Nonparametric statistical tests offer complete freedom to the user with respect to the test statistic by means of which the experimental conditions are compared. This freedom provides a straightforward way to solve the multiple comparisons problem (MCP) and it allows to incorporate biophysically motivated constraints in the test statistic, which may drastically increase the sensitivity of the statistical test. The paper is written for two audiences: (1) empirical neuroscientists looking for the most appropriate data analysis method, and (2) methodologists interested in the theoretical concepts behind nonparametric statistical tests. For the empirical neuroscientist, a large part of the paper is written in a tutorial-like fashion, enabling neuroscientists to construct their own statistical test, maximizing the sensitivity to the expected effect. And for the methodologist, it is explained why the nonparametric test is formally correct. This means that we formulate a null hypothesis (identical probability distribution in the different experimental conditions) and show that the nonparametric test controls the false alarm rate under this null hypothesis.},
	author = {Maris, Eric and Oostenveld, Robert},
	doi = {10.1016/j.jneumeth.2007.03.024},
	issn = {0165-0270},
	journal = {Journal of Neuroscience Methods},
	keywords = {Brain Mapping, Evoked Potentials, Data Interpretation, Statistical, Electroencephalography, Humans, Signal Processing, Computer-Assisted, Brain, Magnetoencephalography, Statistics, Nonparametric},
	language = {eng},
	month = aug,
	number = {1},
	pages = {177--190},
	pmid = {17517438},
	title = {Nonparametric statistical testing of {EEG}- and {MEG}-data},
	volume = {164},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1016/j.jneumeth.2007.03.024}}

@article{meng_discovering_2018,
	abstract = {The folding of the human cerebral cortex is highly complex and variable across individuals, but certain common major patterns of cortical folding do exist. Mining such common patterns of cortical folding is of great importance in understanding the inter-individual variability of cortical folding and their relationship with cognitive functions and brain disorders. As primary cortical folds are mainly genetically influenced and are well established at term birth, neonates with minimal exposure to the complicated postnatal environmental influences are ideal candidates for mining the major patterns of cortical folding. In this paper, we propose a sulcal-pit-based method to discover the major sulcal patterns of cortical folding. In our method, first, the sulcal pattern is characterized by the spatial distribution of sulcal pits, which are the locally deepest points in cortical sulci. Since deep sulcal pits are genetically related, relatively consistent across individuals, and also stable during brain development, they are well suited for representing and characterizing the sulcal patterns. Then, the similarity between the distributions of sulcal pits is measured from the spatial, geometrical, and topological points of view. Next, a comprehensive similarity matrix is constructed for the whole dataset by adaptively fusing these measurements together, thus capturing both their common and complementary information. Finally, leveraging the similarity matrix, a hierarchical affinity propagation algorithm is used to group similar sulcal folding patterns together. The proposed method has been applied to 677 neonatal brains, and revealed multiple distinct and meaningful sulcal patterns in the central sulcus, superior temporal sulcus, and cingulate sulcus.},
	author = {Meng, Yu and Li, Gang and Wang, Li and Lin, Weili and Gilmore, John H. and Shen, Dinggang},
	copyright = {{\copyright} 2018 Wiley Periodicals, Inc.},
	doi = {10.1002/hbm.24199},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/AL8LWGM5/Meng et al. - 2018 - Discovering cortical sulcal folding patterns in ne.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HRP5SIXF/hbm.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {cortical surface, neonatal brain, sulcal folding pattern, sulcal pit},
	language = {en},
	month = sep,
	number = {9},
	pages = {3625--3635},
	title = {Discovering cortical sulcal folding patterns in neonates using large-scale dataset},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24199},
	urldate = {2018-08-21},
	volume = {39},
	year = {2018},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24199},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.24199}}

@article{isler_toward_2012,
	abstract = {The event-related potential (ERP) effect of mismatch negativity (MMN) was the first electrophysiological probe to evaluate cognitive processing (change detection) in newborn infants. Initial studies of MMN predicted clinical utility for this measure in identification of infants at risk for developmental cognitive deficits. These predictions have not been realized. We hypothesized that in sleeping newborn infants, measures derived from wavelet assessment of power in the MMN paradigm would be more robust markers of the brain's response to stimulus change than the ERP-derived MMN. Consistent with this premise, we found increased power in response to unpredictable and infrequent tones compared to frequent tones. These increases were present at multiple locations on the scalp over a range of latencies and frequencies and occurred even in the absence of an ERP-derived MMN. There were two predominant effects. First, theta band power was elevated at middle and late latencies (200 to 600 ms), suggesting that neocortical theta rhythms that subserve working memory in adults are present at birth. Second, late latency (500 ms) increased power to the unpredictable and infrequent tones was observed in the beta and gamma bands, suggesting that oscillations involved in adult cognition are also present in the neonate. These findings support the expectation that frequency dependent measures, such as wavelet power, will improve the prospects for a clinically useful test of cortical function early in the postnatal period.},
	author = {Isler, Joseph R. and Tarullo, Amanda R. and Grieve, Philip G. and Housman, Elizabeth and Kaku, Michelle and Stark, Raymond I. and Fifer, William P.},
	copyright = {{\copyright} 2011 Blackwell Publishing Ltd},
	doi = {10.1111/j.1467-7687.2011.01122.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9HLEBCSJ/Isler et al. - 2012 - Toward an electrocortical biomarker of cognition f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H7I8VPW4/j.1467-7687.2011.01122.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	month = mar,
	number = {2},
	pages = {260--271},
	title = {Toward an electrocortical biomarker of cognition for newborn infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2011.01122.x},
	urldate = {2018-08-07},
	volume = {15},
	year = {2012},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2011.01122.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2011.01122.x}}

@article{stefanics_auditory_2007,
	abstract = {Adults normally perceive auditory scenes in terms of sound patterns emitted by concurrently active sources. Thus pattern formation is an important process of auditory object perception. The aim of the present study was to determine whether neonates group sounds by repeating pitch patterns. Standard (``S''; p=80\%) and deviant tones (``D'', p=20\%) differing only in pitch were delivered either in a randomized order (random condition) or in a repeating SSSSD pattern (grouped condition). Both event-related brain potentials and gamma-band activity differed between the S and D tones in the random condition but not in the grouped condition. These results suggest that in the grouped condition, the S and D tones were processed as part of the same higher order regularity by the neonate auditory system. Also, for the first time, we observed oscillatory gamma-band activity in neonates, which was sensitive to infrequent pitch changes.},
	author = {Stefanics, G{\'a}bor and H{\'a}den, G{\'a}bor and Huotilainen, Minna and Bal{\'a}zs, L{\'a}szl{\'o} and Sziller, Istv{\'a}n and Beke, Anna and Fellman, Vineta and Winkler, Istv{\'a}n},
	doi = {10.1111/j.1469-8986.2007.00540.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/YFQ3HR6S/Stefanics et al. - 2007 - Auditory temporal grouping in newborn infants.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T5AWPQ5B/j.1469-8986.2007.00540.html:text/html},
	issn = {1469-8986},
	journal = {Psychophysiology},
	keywords = {Neonate, Auditory event-related potential, Gamma synchronization, Mismatch negativity (MMN), Perceptual development},
	language = {en},
	month = sep,
	number = {5},
	pages = {697--702},
	title = {Auditory temporal grouping in newborn infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2007.00540.x},
	urldate = {2018-08-07},
	volume = {44},
	year = {2007},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2007.00540.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1469-8986.2007.00540.x}}

@article{haden_timbre-independent_2009,
	abstract = {The ability to separate pitch from other spectral sound features, such as timbre, is an important prerequisite of veridical auditory perception underlying speech acquisition and music cognition. The current study investigated whether or not newborn infants generalize pitch across different timbres. Perceived resonator size is an aspect of timbre that informs the listener about the size of the sound source, a cue that may be important already at birth. Therefore, detection of infrequent pitch changes was tested by recording event-related brain potentials in healthy newborn infants to frequent standard and infrequent pitch-deviant sounds while the perceived resonator size of all sounds was randomly varied. The elicitation of an early negative and a later positive discriminative response by deviant sounds demonstrated that the neonate auditory system represents pitch separately from timbre, thus showing advanced pitch processing capabilities.},
	author = {H{\'a}den, G{\'a}bor P. and Stefanics, G{\'a}bor and Vestergaard, Martin D. and Denham, Susan L. and Sziller, Istv{\'a}n and Winkler, Istv{\'a}n},
	copyright = {Copyright {\copyright} 2008 Society for Psychophysiological Research},
	doi = {10.1111/j.1469-8986.2008.00749.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/AESNATB8/H{\'a}den et al. - 2009 - Timbre-independent extraction of pitch in newborn .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6QM98PNU/j.1469-8986.2008.00749.html:text/html},
	issn = {1469-8986},
	journal = {Psychophysiology},
	keywords = {Development, Event-related brain potentials (ERP), mismatch negativity (MMN), Neonates, Perceived resonator size, Pitch processing, Timbre},
	language = {en},
	month = jan,
	number = {1},
	pages = {69--74},
	title = {Timbre-independent extraction of pitch in newborn infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2008.00749.x},
	urldate = {2018-08-07},
	volume = {46},
	year = {2009},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2008.00749.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1469-8986.2008.00749.x}}

@article{makeig_dynamic_2002,
	abstract = {It has been long debated whether averaged electrical responses recorded from the scalp result from stimulus-evoked brain events or stimulus-induced changes in ongoing brain dynamics. In a human visual selective attention task, we show that nontarget event-related potentials were mainly generated by partial stimulus-induced phase resetting of multiple electroencephalographic processes. Independent component analysis applied to the single-trial data identified at least eight classes of contributing components, including those producing central and lateral posterior alpha, left and right mu, and frontal midline theta rhythms. Scalp topographies of these components were consistent with their generation in compact cortical domains.},
	author = {Makeig, S. and Westerfield, M. and Jung, T.-P. and Enghoff, S. and Townsend, J. and Courchesne, E. and Sejnowski, T. J.},
	doi = {10.1126/science.1066168},
	file = {Snapshot:/Users/Cecile/Zotero/storage/4XUXUR8S/690.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jan,
	number = {5555},
	pages = {690--694},
	pmid = {11809976},
	title = {Dynamic {Brain} {Sources} of {Visual} {Evoked} {Responses}},
	url = {http://science.sciencemag.org/content/295/5555/690},
	urldate = {2018-08-07},
	volume = {295},
	year = {2002},
	bdsk-url-1 = {http://science.sciencemag.org/content/295/5555/690},
	bdsk-url-2 = {https://doi.org/10.1126/science.1066168}}

@article{chapman_evoked_1964,
	abstract = {Evoked Responses to Numerical and Non-Numerical Visual Stimuli while Problem Solving},
	author = {Chapman, Robert M. and Bragdon, Henry R.},
	copyright = {1964 Nature Publishing Group},
	doi = {10.1038/2031155a0},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/B3Q6LZ68/Chapman et Bragdon - 1964 - Evoked Responses to Numerical and Non-Numerical Vi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NWFPP6M5/2031155a0.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = sep,
	number = {4950},
	pages = {1155--1157},
	title = {Evoked {Responses} to {Numerical} and {Non}-{Numerical} {Visual} {Stimuli} while {Problem} {Solving}},
	url = {https://www.nature.com/articles/2031155a0},
	urldate = {2018-08-07},
	volume = {203},
	year = {1964},
	bdsk-url-1 = {https://www.nature.com/articles/2031155a0},
	bdsk-url-2 = {https://doi.org/10.1038/2031155a0}}

@article{kutas_reading_1980,
	abstract = {In a sentence reading task, words that occurred out of context were associated with specific types of event-related brain potentials. Words that were physically aberrant (larger than normal) elecited a late positive series of potentials, whereas semantically inappropriate words elicited a late negative wave (N400). The N400 wave may be an electrophysiological sign of the "reprocessing" of semantically anomalous information.},
	author = {Kutas, M. and Hillyard, S. A.},
	copyright = {{\copyright} 1980},
	doi = {10.1126/science.7350657},
	file = {Snapshot:/Users/Cecile/Zotero/storage/XG5UPF5W/203.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jan,
	number = {4427},
	pages = {203--205},
	pmid = {7350657},
	shorttitle = {Reading senseless sentences},
	title = {Reading senseless sentences: brain potentials reflect semantic incongruity},
	url = {http://science.sciencemag.org/content/207/4427/203},
	urldate = {2018-08-07},
	volume = {207},
	year = {1980},
	bdsk-url-1 = {http://science.sciencemag.org/content/207/4427/203},
	bdsk-url-2 = {https://doi.org/10.1126/science.7350657}}

@article{jenni_development_2004,
	abstract = {The development of nocturnal sleep and the sleep electroencephalogram (EEG) was investigated in a longitudinal study during infancy. All-night polysomnographic recordings were obtained at home at 2 wk and at 2, 4, 6, and 9 mo after birth (analysis of 7 infants). Total sleep time and the percentage of quiet sleep or non-rapid eye movement sleep (QS/NREMS) increased with age, whereas the percentage of active sleep or rapid eye movement sleep (AS/REMS) decreased. Spectral power of the sleep EEG was higher in QS/NREMS than in AS/REMS over a large part of the 0.75- to 25-Hz frequency range. In both QS/NREMS and AS/REMS, EEG power increased with age in the frequency range {\textless}10 Hz and {\textgreater}17 Hz. The largest rise occurred between 2 and 6 mo. A salient feature of the QS/NREMS spectrum was the emergence of a peak in the sigma band (12-14 Hz) at 2 mo that corresponded to the appearance of sleep spindles. Between 2 and 9 mo, low-frequency delta activity (0.75-1.75 Hz) showed an alternating pattern with a high level occurring in every other QS/NREMS episode. At 6 mo, sigma activity showed a similar pattern. In contrast, theta activity (6.5-9 Hz) exhibited a monotonic decline over consecutive QS/NREMS episodes, a trend that at 9 mo could be closely approximated by an exponential function. The results suggest that 1) EEG markers of sleep homeostasis appear in the first postnatal months, and 2) sleep homeostasis goes through a period of maturation. Theta activity and not delta activity seems to reflect the dissipation of sleep propensity during infancy.},
	author = {Jenni, Oskar G. and Borb{\'e}ly, Alexander A. and Achermann, Peter},
	doi = {10.1152/ajpregu.00503.2003},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Q69RMALR/Jenni et al. - 2004 - Development of the nocturnal sleep electroencephal.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZRT9379V/ajpregu.00503.html:text/html},
	issn = {0363-6119},
	journal = {American Journal of Physiology-Regulatory, Integrative and Comparative Physiology},
	month = mar,
	number = {3},
	pages = {R528--R538},
	title = {Development of the nocturnal sleep electroencephalogram in human infants},
	url = {https://www.physiology.org/doi/abs/10.1152/ajpregu.00503.2003},
	urldate = {2018-08-07},
	volume = {286},
	year = {2004},
	bdsk-url-1 = {https://www.physiology.org/doi/abs/10.1152/ajpregu.00503.2003},
	bdsk-url-2 = {https://doi.org/10.1152/ajpregu.00503.2003}}

@article{friederici_neural_2002,
	abstract = {We recorded event-related potentials (ERPs) in 2-month-old infants in two different states of alertness: awake and asleep. Syllables varying in vowel duration (long vs short) were presented in an oddball paradigm, known to elicit a mismatch brain response. ERPs of both groups showed a mismatch response reflected in a positivity followed by a frontal negativity. While the positivity was present as a function of the stimulus type (present for long deviants only), the negativity varied as a function of the state of alertness (present for awake infants only). These data indicate a functional separation between precognitive and cognitive aspects of duration mismatch essential for the distinction between long and short vowels during early infancy.},
	author = {Friederici, Angela D. and Friedrich, Manuela and Weber, Christiane},
	file = {Snapshot:/Users/Cecile/Zotero/storage/8I9ELU99/Neural_manifestation_of_cognitive_and_precognitive.6.html:text/html},
	issn = {0959-4965},
	journal = {NeuroReport},
	language = {en-US},
	month = jul,
	number = {10},
	pages = {1251},
	title = {Neural manifestation of cognitive and precognitive mismatch detection in early infancy},
	url = {https://journals.lww.com/neuroreport/Fulltext/2002/07190/Neural_manifestation_of_cognitive_and_precognitive.6.aspx},
	urldate = {2018-08-07},
	volume = {13},
	year = {2002},
	bdsk-url-1 = {https://journals.lww.com/neuroreport/Fulltext/2002/07190/Neural_manifestation_of_cognitive_and_precognitive.6.aspx}}

@article{myers_developmental_2012,
	abstract = {Objective
To quantify spectral power in frequency specific bands and commonly observed types of bursting activities in the EEG during early human development.
Methods
An extensive archive of EEG data from human infants from 35 to 52weeks postmenstrual age obtained in a prior multi-center study was analyzed using power spectrum analyses and a high frequency burst detection algorithm.
Results
Low frequency power increased with age; however, high frequency power decreased from 35 to 45weeks. This unexpected decrease was largely attributable to a rapid decline in the number of high frequency bursts.
Conclusions
The decline in high frequency bursting activity overlaps with a developmental shift in GABA's actions on neurons from depolarizing to hyperpolarizing and the dissolution of the gap junction circuitry of the cortical subplate.
Significance
We postulate that quantitative characterization of features of the EEG unique to early development provide indices for tracking changes in specific neurophysiologic mechanisms that are critical for normal development of brain function.},
	author = {Myers, M. M. and Grieve, P. G. and Izraelit, A. and Fifer, W. P. and Isler, J. R. and Darnall, R. A. and Stark, R. I.},
	doi = {10.1016/j.clinph.2011.11.264},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/I65L3J52/Myers et al. - 2012 - Developmental profiles of infant EEG Overlap with.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YP66JMJ3/S1388245712000399.html:text/html},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology},
	keywords = {EEG, Infant, Development, GABA, Bursts, Subplate},
	month = aug,
	number = {8},
	pages = {1502--1511},
	shorttitle = {Developmental profiles of infant {EEG}},
	title = {Developmental profiles of infant {EEG}: {Overlap} with transient cortical circuits},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245712000399},
	urldate = {2018-08-07},
	volume = {123},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245712000399},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2011.11.264}}

@article{ellingson_development_1980,
	abstract = {EEG polygraph recordings of 1 to over 4 h duration were obtained during daytime sleeps weekly from birth to 11--13 weeks of age in 17 normal full-term newborns. Analysis of the recordings permitted more precise specification of the time courses of early developmental changes in EEG patterns related to the sleep cycle. The trac{\'e} alternant pattern of quiet sleep was seen up to 2 weeks post term in all subjects, but in none beyond 6 weeks. Active sleep onset occurred in 80\% of daytime sleeps at 1--3 weeks and decreased rapidly over the next 5 weeks, but at 8--13 weeks was still seen in 5--10\% of the recordings. Rolandic sleep spindle bursts appeared in some subjects as early as 4 weeks post term and were present in all beyond 8 weeks. Based upon these 3 criterion variables, the transition from `perinatal' to `infantile' EEG sleep patterns started at a mean age of 30.3 days and was completed at a mean age of 46.6 days. The earliest and latest completions of the transition were at 27 and 66 days, respectively. On the average the transition took just over 2 weeks. Frontal sleep transients were seen until 3 weeks post term in all subjects, but in none beyond 7 weeks. Active sleep decreased from just over 50\% of total sleep time at birth to about 20\% beyond 8 weeks. Percent-time quiet sleep increased proportionately. Indeterminate sleep remained relatively constant at 5--10 percent-time. A tendency for percent-time indeterminate sleep to be elevated in the presences of minor illnesses was observed. The usefulness of these, and other, EEG data in defining mature and immature EEGs in the neonatal period and the clinical significance of EEG immaturity are discussed.
R{\'e}sum{\'e}
Des enregistrements EEG et polygraphiques d'une dur{\'e}e de 1--4 h ont {\'e}t{\'e} obtenus au cours de p{\'e}riodes de sommeil diurne toutes les semaines entre la naissance et 11--13 semaines chez 17 nouveau-n{\'e}s {\`a} terme. L'analyse de ces enregistrements permet de d{\'e}finir de fa{\c c}on plus pr{\'e}cise l'{\'e}volution des modifications pr{\'e}coces du d{\'e}veloppement des patterns EEG des cycles de sommeil. Le pattern `trace' alternant' du sommeil calme s'observe jusqu'{\`a} 2 semaines apr{\`e}s la naissance chez tous les sujets, mais ne s'observe plus chez aucun d'entre eux au-del{\`a} de 6 semaines. L'endormissement en sommeil actif s'observe dans 80\% des sommeils de jour entre 1 et 3 semaines, diminue rapidement au cours des 5 semaines suivantes, mais entre 8 et 13 semaines on l'observe encore dans 5--10\% des enregistrements. Les bouff{\'e}es de spindles rolandiques de sommeil apparaissent chez certains sujets d{\`e}s la 4{\`e}me semaine apr{\`e}s la naissance et s'observent chez tous apr{\`e}s la 8{\`e}me semaine. En se basant sur ces 3 crit{\`e}res, la transition des patterns EEG de sommeil de la p{\'e}riode p{\'e}ri-natale {\`a} la p{\'e}riode infantile d{\'e}bute {\`a} un {\^a}ge moyen de 30,3 jours et se parach{\`e}ve {\`a} un {\^a}ge moyen de 46,6 jours. La r{\'e}alisation compl{\`e}te la plus pr{\'e}coce et la plus tardive de cette transition survient {\`a} 27 et 66 jours respectivement. En moyenne cette transition prend juste un peu plus de 2 semaines. Les transitoires frontales du sommeil s'observent jusqu'{\`a} la 3{\`e}me semaine apr{\`e}s la naissance chez tous les sujets mais chez aucun d'entre eux au-del{\`a} de 7 semaines. Le sommeil actif diminue d'une valeur juste sup{\'e}rieure {\`a} 50\% du sommeil total {\`a} la naissance {\`a} environ 20\% apr{\`e}s 8 semaines. Le pourcentage de temps occup{\'e} par le sommeil calme augmente en proportion. Le sommeil ind{\'e}termin{\'e} reste relativement constant, {\`a} une valeur d'environ 5--10\% du temps de sommeil. On observe une tendance {\`a} ce que le pourcentage de sommeil ind{\'e}termin{\'e} soit {\'e}lev{\'e} en cas de maladies b{\'e}nignes. L'utilit{\'e} de ces donn{\'e}es EEG, et d'autres, pour d{\'e}finir les EEGs matures et immatures {\`a} la p{\'e}riode n{\'e}o-natale et la signification clinique de l'immaturit{\'e} EEG sont discut{\'e}es.},
	author = {Ellingson, Robert J and Peters, Jon F},
	doi = {10.1016/0013-4694(80)90357-0},
	file = {Ellingson et Peters - 1980 - Development of EEG and daytime sleep patterns in n.pdf:/Users/Cecile/Zotero/storage/IBPGK3Q6/Ellingson et Peters - 1980 - Development of EEG and daytime sleep patterns in n.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/J3DTA4WE/Ellingson et Peters - 1980 - Development of EEG and daytime sleep patterns in n.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MIKP5A38/0013469480903570.html:text/html},
	issn = {0013-4694},
	journal = {Electroencephalography and Clinical Neurophysiology},
	month = jul,
	number = {1},
	pages = {112--124},
	shorttitle = {Development of {EEG} and daytime sleep patterns in normal full-term infants during the first 3 months of life},
	title = {Development of {EEG} and daytime sleep patterns in normal full-term infants during the first 3 months of life: {Longitudinal} observations},
	url = {http://www.sciencedirect.com/science/article/pii/0013469480903570},
	urldate = {2018-08-07},
	volume = {49},
	year = {1980},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0013469480903570},
	bdsk-url-2 = {https://doi.org/10.1016/0013-4694(80)90357-0}}

@article{haden_context_2013,
	abstract = {Detecting and orienting towards sounds carrying new information is a crucial feature of the human brain that supports adaptation to the environment. Rare, acoustically widely deviant sounds presented amongst frequent tones elicit large event related brain potentials (ERPs) in neonates. Here we tested whether these discriminative ERP responses reflect only the activation of fresh afferent neuronal populations (i.e., neuronal circuits not affected by the tones) or they also index the processing of contextual mismatch between the rare and the frequent sounds. In two separate experiments, we presented sleeping newborns with 150 different environmental sounds and the same number of white noise bursts. Both sounds served either as deviants in an oddball paradigm with the frequent standard stimulus a tone (Novel/Noise deviant), or as the standard stimulus with the tone as deviant (Novel/Noise standard), or they were delivered alone with the same timing as the deviants in the oddball condition (Novel/Noise alone). Whereas the ERP responses to noise--deviants elicited similar responses as the same sound presented alone, the responses elicited by environmental sounds in the corresponding conditions morphologically differed from each other. Thus whereas the ERP response to the noise sounds can be explained by the different refractory state of stimulus specific neuronal populations, the ERP response to environmental sounds indicated context sensitive processing. These results provide evidence for an innate tendency of context dependent auditory processing as well as a basis for the different developmental trajectories of processing acoustical deviance and contextual novelty.},
	author = {H{\'a}den, G{\'a}bor P{\'e}ter and N{\'e}meth, Ren{\'a}ta and T{\"o}r{\"o}k, Mikl{\'o}s and Dr{\'a}vucz, S{\'a}ndor and Winkler, Istv{\'a}n},
	doi = {10.3389/fpsyg.2013.00674},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UZVGA7CE/H{\'a}den et al. - 2013 - Context effects on processing widely deviant sound.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	keywords = {Auditory Perception, novelty detection, context effects, ERPs (Event-Related Potentials), human newborn},
	language = {English},
	title = {Context effects on processing widely deviant sounds in newborn infants},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00674/full#h3},
	urldate = {2018-08-07},
	volume = {4},
	year = {2013},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00674/full#h3},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2013.00674}}

@article{nemeth_processing_2015,
	abstract = {Objectives: By measuring event-related brain potentials (ERPs), the authors tested the sensitivity of the newborn auditory cortex to sound lateralization and to the most common cues of horizontal sound localization.
        Design: Sixty-eight healthy full-term newborn infants were presented with auditory oddball sequences composed of frequent and rare noise segments in four experimental conditions. The authors tested in them the detection of deviations in the primary cues of sound lateralization (interaural time and level difference) and in actual sound source location (free-field and monaural sound presentation). ERP correlates of deviance detection were measured in two time windows.
        Results: Deviations in both primary sound localization cues and the ear of stimulation elicited a significant ERP difference in the early (90 to 140 msec) time window. Deviance in actual sound source location (the free-field condition) elicited a significant response in the late (290 to 340 msec) time window.
        Conclusions: The early differential response may indicate the detection of a change in the respective auditory features. The authors suggest that the late differential response, which was only elicited by actual sound source location deviation, reflects the detection of location deviance integrating the various cues of sound source location. Although the results suggest that all of the tested binaural cues are processed by the neonatal auditory cortex, utilizing the cues for locating sound sources of these cues may require maturation and learning.},
	author = {N{\'e}meth, Ren{\'a}ta and H{\'a}den, G{\'a}bor P. and T{\"o}r{\"o}k, Mikl{\'o}s and Winkler, Istv{\'a}n},
	doi = {10.1097/AUD.0000000000000160},
	file = {Snapshot:/Users/Cecile/Zotero/storage/CU2Z76T8/Processing_of_Horizontal_Sound_Localization_Cues.6.html:text/html},
	issn = {0196-0202},
	journal = {Ear and Hearing},
	language = {en-US},
	month = oct,
	number = {5},
	pages = {550},
	title = {Processing of {Horizontal} {Sound} {Localization} {Cues} in {Newborn} {Infants}},
	url = {https://journals.lww.com/ear-hearing/fulltext/2015/09000/Processing_of_Horizontal_Sound_Localization_Cues.6.aspx},
	urldate = {2018-08-07},
	volume = {36},
	year = {2015},
	bdsk-url-1 = {https://journals.lww.com/ear-hearing/fulltext/2015/09000/Processing_of_Horizontal_Sound_Localization_Cues.6.aspx},
	bdsk-url-2 = {https://doi.org/10.1097/AUD.0000000000000160}}

@article{toth_large-scale_2017,
	abstract = {The organization of functional brain networks changes across human lifespan. The present study analyzed functional brain networks in healthy full-term infants (N = 139) within 1--6 days from birth by measuring neural synchrony in EEG recordings during quiet sleep. Large-scale phase synchronization was measured in six frequency bands with the Phase Lag Index. Macroscopic network organization characteristics were quantified by constructing unweighted minimum spanning tree graphs. The cortical networks in early infancy were found to be significantly more hierarchical and had a more cost-efficient organization compared with MST of random control networks, more so in the theta and alpha than in other frequency bands. Frontal and parietal sites acted as the main hubs of these networks, the topological characteristics of which were associated with gestation age (GA). This suggests that individual differences in network topology are related to cortical maturation during the prenatal period, when functional networks shift from strictly centralized toward segregated configurations. Hum Brain Mapp 38:4019--4033, 2017. {\copyright} 2017 Wiley Periodicals, Inc.},
	author = {T{\'o}th, Brigitta and Urb{\'a}n, G{\'a}bor and H{\'a}den, G{\'a}bor P. and M{\'a}rk, Moln{\'a}r and T{\"o}r{\"o}k, Mikl{\'o}s and Stam, Cornelis Jan and Winkler, Istv{\'a}n},
	copyright = {{\copyright} 2017 Wiley Periodicals, Inc.},
	doi = {10.1002/hbm.23645},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9KZRZHBP/T{\'o}th et al. - 2017 - Large-scale network organization of EEG functional.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IF9K3AEG/hbm.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {electroencephalography, functional connectivity, graph theory, minimum spanning tree, neonate, network analysis},
	language = {en},
	month = aug,
	number = {8},
	pages = {4019--4033},
	title = {Large-scale network organization of {EEG} functional connectivity in newborn infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23645},
	urldate = {2018-08-07},
	volume = {38},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23645},
	bdsk-url-2 = {https://doi.org/10.1002/hbm.23645}}

@book{noauthor_doi:_nodate,
	abstract = {This copy is for your personal, non-commercial use only. clicking here.colleagues, clients, or customers by, you can order high-quality copies for yourIf you wish to distribute this article to others here.following the guidelines can be obtained byPermission to republish or repurpose articles or portions of articles): April 28, 2013 www.sciencemag.org (this information is current as of The following resources related to this article are available online at},
	file = {Citeseer - Full Text PDF:/Users/Cecile/Zotero/storage/YMYZWMTT/DOI 10.1126science.1232509, 376 (2013)\;340 Scien.pdf:application/pdf;Citeseer - Snapshot:/Users/Cecile/Zotero/storage/HC22WWAB/summary.html:text/html},
	shorttitle = {{DOI}},
	title = {{DOI}: 10.1126/science.1232509, 376 (2013);340 {Science} et al.{Sid} {Kouider} {A} {Neural} {Marker} of {Perceptual} {Consciousness} in {Infants}}}

@misc{noauthor_oms_nodate,
	abstract = {FR CGS - chts\_hcfa\_filles\_z},
	file = {Snapshot:/Users/Cecile/Zotero/storage/ZLVWGNSH/fr.html:text/html},
	journal = {WHO},
	title = {{OMS} {\textbar} {P{\'e}rim{\`e}tre} cr{\^a}nien-pour-l'{\^a}ge},
	url = {http://www.who.int/childgrowth/standards/second_set/chts_hcfa_filles_z/fr/},
	urldate = {2018-08-07},
	bdsk-url-1 = {http://www.who.int/childgrowth/standards/second_set/chts_hcfa_filles_z/fr/}}

@article{laing_tuned_2012,
	abstract = {Voices have unique acoustic signatures, contributing to the acoustic variability listeners must contend with in perceiving speech, and it has long been proposed that listeners normalize speech perception to information extracted from a talker's speech. Initial attempts to explain talker normalization relied on extraction of articulatory referents, but recent studies of context-dependent auditory perception suggest that general auditory referents such as the long-term average spectrum (LTAS) of a talker's speech similarly affect speech perception. The present study aimed to differentiate the contributions of articulatory/linguistic versus auditory referents for context-driven talker normalization effects and, more specifically, to identify the specific constraints under which such contexts impact speech perception. Synthesized sentences manipulated to sound like different talkers influenced categorization of a subsequent speech target only when differences in the sentences' LTAS were in the frequency range of the acoustic cues relevant for the target phonemic contrast. This effect was true both for speech targets preceded by spoken sentence contexts and for targets preceded by nonspeech tone sequences that were LTAS-matched to the spoken sentence contexts. Specific LTAS characteristics, rather than perceived talker, predicted the results suggesting that general auditory mechanisms play an important role in effects considered to be instances of perceptual talker normalization.},
	author = {Laing, Erika J. C. and Liu, Ran and Lotto, Andrew J. and Holt, Lori L.},
	doi = {10.3389/fpsyg.2012.00203},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/D2EVFNKA/Laing et al. - 2012 - Tuned with a Tune Talker Normalization via Genera.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	keywords = {Speech Perception, Auditory cognition, Talker Normalization},
	language = {English},
	shorttitle = {Tuned with a {Tune}},
	title = {Tuned with a {Tune}: {Talker} {Normalization} via {General} {Auditory} {Processes}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00203/full},
	urldate = {2018-08-06},
	volume = {3},
	year = {2012},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00203/full},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2012.00203}}

@article{lachaux_measuring_1999,
	abstract = {This article presents, for the first time, a practical method for the direct quantification of frequency-specific synchronization (i.e., transient phase-locking) between two neuroelectric signals. The motivation for its development is to be able to examine the role of neural synchronies as a putative mechanism for long-range neural integration during cognitive tasks. The method, called phase-locking statistics (PLS), measures the significance of the phase covariance between two signals with a reasonable time-resolution ({\textless}100 ms). Unlike the more traditional method of spectral coherence, PLS separates the phase and amplitude components and can be directly interpreted in the framework of neural integration. To validate synchrony values against background fluctuations, PLS uses surrogate data and thus makes no a priori assumptions on the nature of the experimental data. We also apply PLS to investigate intracortical recordings from an epileptic patient performing a visual discrimination task. We find large-scale synchronies in the gamma band (45 Hz), e.g., between hippocampus and frontal gyrus, and local synchronies, within a limbic region, a few cm apart. We argue that whereas long-scale effects do reflect cognitive processing, short-scale synchronies are likely to be due to volume conduction. We discuss ways to separate such conduction effects from true signal synchrony. Hum Brain Mapping 8:194--208, 1999. {\copyright} 1999 Wiley-Liss, Inc.},
	author = {Lachaux, Jean-Philippe and Rodriguez, Eugenio and Martinerie, Jacques and Varela, Francisco J.},
	copyright = {Copyright {\copyright} 1999 Wiley‐Liss, Inc.},
	doi = {10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C},
	file = {Snapshot:/Users/Cecile/Zotero/storage/UDYWHEGI/(SICI)1097-0193(1999)84194AID-HBM43.0.html:text/html},
	issn = {1097-0193},
	journal = {Human Brain Mapping},
	keywords = {EEG, coherence, deblurring, EcoG, epilepsy, gamma-band, neural synchrony, phase-locking},
	language = {en},
	month = jan,
	number = {4},
	pages = {194--208},
	title = {Measuring phase synchrony in brain signals},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0193%281999%298%3A4%3C194%3A%3AAID-HBM4%3E3.0.CO%3B2-C},
	urldate = {2018-09-09},
	volume = {8},
	year = {1999},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0193%281999%298%3A4%3C194%3A%3AAID-HBM4%3E3.0.CO%3B2-C},
	bdsk-url-2 = {https://doi.org/10.1002/(SICI)1097-0193(1999)8:4%3C194::AID-HBM4%3E3.0.CO;2-C}}

@article{picton_human_2003,
	abstract = {Steady-state evoked potentials can be recorded from the human scalp in response to auditory stimuli presented at rates between 1 and 200 Hz or by periodic modulations of the amplitude and/or frequency of a continuous tone. Responses can be objectively detected using frequency-based analyses. In waking subjects, the responses are particularly prominent at rates near 40 Hz. Responses evoked by more rapidly presented stimuli are less affected by changes in arousal and can be evoked by multiple simultaneous stimuli without significant loss of amplitude. Response amplitude increases as the depth of modulation or the intensity increases. The phase delay of the response increases as the intensity or the carrier frequency decreases. Auditory steady-state responses are generated throughout the auditory nervous system, with cortical regions contributing more than brainstem generators to responses at lower modulation frequencies. These responses are useful for objectively evaluating auditory thresholds, assessing suprathreshold hearing, and monitoring the state of arousal during anesthesia.Los potenciales evocados de estado estable pueden registrarse del cr{\'a}neo humano en respuesta a est{\'\i}mulos auditivos presentados a tasas de 1 y 200 Hz o por modulaciones peri{\'o}dicas de la amplitud y/o de la frecuencia de un tono continue Las respuestas pueden ser detectadas objetivamente por medio de un an{\'a}lisis frecuencial En sujetos en estado de alerta las respuestas son particularmente prominentes con tasas de estimulaci{\'o}n cercanas a 40 Hz. Las respuestas evocadas por est{\'\i}mulos presentados a tasa m{\'a}s r{\'a}pida resultan menos afectadas por cambios del estado de conciencia y pueden ser evocados por est{\'\i}mulos m{\'u}ltiples simult{\'a}neos sin una p{\'e}rdida significativa de la amplitud. La amplitud de la respuesta aumenta conforme la profundidad de la modulaci{\'o}n o de la intensidad aumenta. El retraso de fase de la respuesta aumenta conforme la intensidad de la frecuencia portadora aumenta. Las respuestas auditivas de estado estable se generan a todo lo largo del sistema nervioso auditivo; las regiones corticales contribuyen m{\'a}s que los generadores del tallo cerebral en las respuestas de frecuencias m{\'a}s bajas. Estas respuestas son {\'u}tiles para evaluar objetivamente los umbrales de audici{\'o}n y permiten tambi{\'e}n evaluar la audici{\'o}n supraliminar y monitorizar el estado de conciencia durante la anestesia.},
	author = {Picton, Terence W. and John, M. Sasha and Dimitrijevic, Andrew and Purcell, David},
	doi = {10.3109/14992020309101316},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KF87FIPT/Picton et al. - 2003 - Human auditory steady-state responses Respuestas .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TL4VJUQU/14992020309101316.html:text/html},
	issn = {1499-2027},
	journal = {International Journal of Audiology},
	keywords = {Audiometry, Hearing, Anesthesia, Fourier analysis, Steady-state response},
	month = jan,
	number = {4},
	pages = {177--219},
	shorttitle = {Human auditory steady-state responses},
	title = {Human auditory steady-state responses: {Respuestas} auditivas de estado estable en humanos},
	url = {https://doi.org/10.3109/14992020309101316},
	urldate = {2018-09-09},
	volume = {42},
	year = {2003},
	bdsk-url-1 = {https://doi.org/10.3109/14992020309101316}}

@article{woolley_tuning_2005,
	abstract = {Vocal communicators discriminate conspecific vocalizations from other sounds and recognize the vocalizations of individuals. To identify neural mechanisms for the discrimination of such natural sounds, we compared the linear spectro-temporal tuning properties of auditory midbrain and forebrain neurons in zebra finches with the statistics of natural sounds, including song. Here, we demonstrate that ensembles of auditory neurons are tuned to auditory features that enhance the acoustic differences between classes of natural sounds, and among the songs of individual birds. Tuning specifically avoids the spectro-temporal modulations that are redundant across natural sounds and therefore provide little information; rather, it overlaps with the temporal modulations that differ most across sounds. By comparing the real tuning and a less selective model of spectro-temporal tuning, we found that the real modulation tuning increases the neural discrimination of different sounds. Additionally, auditory neurons discriminate among zebra finch song segments better than among synthetic sound segments.},
	author = {Woolley, Sarah M. N. and Fremouw, Thane E. and Hsu, Anne and Theunissen, Fr{\'e}d{\'e}ric E.},
	copyright = {2005 Nature Publishing Group},
	doi = {10.1038/nn1536},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/5J6JHXRA/Woolley et al. - 2005 - Tuning for spectro-temporal modulations as a mecha.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9U7JDMZD/nn1536.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = oct,
	number = {10},
	pages = {1371--1379},
	title = {Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds},
	url = {https://www.nature.com/articles/nn1536},
	urldate = {2018-09-14},
	volume = {8},
	year = {2005},
	bdsk-url-1 = {https://www.nature.com/articles/nn1536},
	bdsk-url-2 = {https://doi.org/10.1038/nn1536}}

@article{smith_efficient_2005,
	abstract = {Nonstationary acoustic features provide essential cues for many auditory tasks, including sound localization, auditory stream analysis, and speech recognition. These features can best be characterized relative to a precise point in time, such as the onset of a sound or the beginning of a harmonic periodicity. Extracting these types of features is a difficult problem. Part of the difficulty is that with standard block-based signal analysis methods, the representation is sensitive to the arbitrary alignment of the blocks with respect to the signal. Convolutional techniques such as shift-invariant transformations can reduce this sensitivity, but these do not yield a code that is efficient, that is, one that forms a nonredundant representation of the underlying structure. Here, we develop a non-block-based method for signal representation that is both time relative and efficient. Signals are represented using a linear superposition of time-shiftable kernel functions, each with an associated magnitude and temporal position. Signal decomposition in this method is a non-linear process that consists of optimizing the kernel function scaling coefficients and temporal positions to form an efficient, shift-invariant representation. We demonstrate the properties of this representation for the purpose of characterizing structure in various types of nonstationary acoustic signals. The computational problem investigated here has direct relevance to the neural coding at the auditory nerve and the more general issue of how to encode complex, time-varying signals with a population of spiking neurons.},
	author = {Smith, Evan and Lewicki, Michael S.},
	doi = {10.1162/0899766052530839},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7Z3T3Z3I/Smith et Lewicki - 2005 - Efficient Coding of Time-Relative Structure Using .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/R9DZT53C/0899766052530839.html:text/html},
	issn = {0899-7667},
	journal = {Neural Computation},
	month = jan,
	number = {1},
	pages = {19--45},
	title = {Efficient {Coding} of {Time}-{Relative} {Structure} {Using} {Spikes}},
	url = {https://doi.org/10.1162/0899766052530839},
	urldate = {2018-09-14},
	volume = {17},
	year = {2005},
	bdsk-url-1 = {https://doi.org/10.1162/0899766052530839}}

@misc{usakli_improvement_2010,
	abstract = {The aim of this study is to present some practical state-of-the-art considerations in acquiring satisfactory signals for electroencephalographic signal acquisition. These considerations are important for users and system designers. Especially choosing correct electrode and design strategy of the initial electronic circuitry front end plays an important role in improving the system's measurement performance. Considering the pitfalls in the design of biopotential measurement system and recording session conditions creates better accuracy. In electroencephalogram (EEG) recording electrodes, system electronics including filtering, amplifying, signal conversion, data storing, and environmental conditions affect the recording performance. In this paper, EEG electrode principles and main points of electronic noise reduction methods in EEG signal acquisition front end are discussed, and some suggestions for improving signal acquisition are presented.},
	author = {Usakli, Ali Bulent},
	doi = {10.1155/2010/630649},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/H72LNRXA/Usakli - 2010 - Improvement of EEG Signal Acquisition An Electric.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UVRGU6LQ/630649.html:application/xhtml+xml},
	journal = {Computational Intelligence and Neuroscience},
	language = {en},
	pmid = {20148074},
	shorttitle = {Improvement of {EEG} {Signal} {Acquisition}},
	title = {Improvement of {EEG} {Signal} {Acquisition}: {An} {Electrical} {Aspect} for {State} of the {Art} of {Front} {End}},
	type = {Research article},
	url = {https://www.hindawi.com/journals/cin/2010/630649/},
	urldate = {2018-09-12},
	year = {2010},
	bdsk-url-1 = {https://www.hindawi.com/journals/cin/2010/630649/},
	bdsk-url-2 = {https://doi.org/10.1155/2010/630649}}

@article{smith_efficient_2006,
	abstract = {The auditory neural code must serve a wide range of auditory tasks that require great sensitivity in time and frequency and be effective over the diverse array of sounds present in natural acoustic environments. It has been suggested1,2,3,4,5 that sensory systems might have evolved highly efficient coding strategies to maximize the information conveyed to the brain while minimizing the required energy and neural resources. Here we show that, for natural sounds, the complete acoustic waveform can be represented efficiently with a nonlinear model based on a population spike code. In this model, idealized spikes encode the precise temporal positions and magnitudes of underlying acoustic features. We find that when the features are optimized for coding either natural sounds or speech, they show striking similarities to time-domain cochlear filter estimates, have a frequency-bandwidth dependence similar to that of auditory nerve fibres, and yield significantly greater coding efficiency than conventional signal representations. These results indicate that the auditory code might approach an information theoretic optimum and that the acoustic structure of speech might be adapted to the coding capacity of the mammalian auditory system.},
	author = {Smith, Evan C. and Lewicki, Michael S.},
	copyright = {2006 Nature Publishing Group},
	doi = {10.1038/nature04485},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/P38YJ77Q/Smith et Lewicki - 2006 - Efficient auditory coding.pdf:application/pdf},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = feb,
	number = {7079},
	pages = {978--982},
	title = {Efficient auditory coding},
	url = {https://www.nature.com/articles/nature04485},
	urldate = {2018-09-11},
	volume = {439},
	year = {2006},
	bdsk-url-1 = {https://www.nature.com/articles/nature04485},
	bdsk-url-2 = {https://doi.org/10.1038/nature04485}}

@article{weisz_tonotopic_2004,
	abstract = {Using neuromagnetic source imaging, we investigated tonotopic representation and direction sensitivity in the auditory cortex of humans (N=15). For this purpose, source analysis was undertaken at every single sampling point during the presentation of a frequency-modulated tone (FM) sweeping slowly downward or upward across periods of 3 s duration. Stimuli were selected to target response properties of the central part of the primary auditory cortical field, which has been shown to exhibit sensitivity to distinct FM-sound features as compared to the ventral and dorsal part. Linear mixed-effects model statistics confirm tonotopic gradients in medial--lateral and anterior--posterior directions. The high resolution provided by this method revealed that the relationship between frequency and spatial location of the responding neural tissue is nonlinear. The idea that neurons specifically sensitive to the employed sound characteristics (slow, downward modulation) were activated is supported by the fact that the upward sweep of identical duration produced a different pattern of functional organisation.},
	author = {Weisz, Nathan and Wienbruch, Christian and Hoffmeister, Sandra and Elbert, Thomas},
	doi = {10.1016/j.heares.2004.01.012},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QU674YNU/Weisz et al. - 2004 - Tonotopic organization of the human auditory corte.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/SLYV8RLS/S037859550400036X.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	keywords = {MEG, High-resolution, LME, Tonotopy},
	month = may,
	number = {1},
	pages = {49--58},
	title = {Tonotopic organization of the human auditory cortex probed with frequency-modulated tones},
	url = {http://www.sciencedirect.com/science/article/pii/S037859550400036X},
	urldate = {2018-09-09},
	volume = {191},
	year = {2004},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S037859550400036X},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2004.01.012}}

@article{leong_role_2014,
	author = {Leong, Victoria and Stone, Michael A. and Turner, Richard E. and Goswami, Usha},
	doi = {10.1121/1.4883366},
	file = {Leong et al. - 2014 - A role for amplitude modulation phase relationship.pdf:/Users/Cecile/Zotero/storage/HFA794YR/Leong et al. - 2014 - A role for amplitude modulation phase relationship.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U5B4YIJY/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = jul,
	number = {1},
	pages = {366--381},
	title = {A role for amplitude modulation phase relationships in speech rhythm perception},
	url = {https://asa.scitation.org/doi/10.1121/1.4883366},
	urldate = {2018-09-23},
	volume = {136},
	year = {2014},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.4883366},
	bdsk-url-2 = {https://doi.org/10.1121/1.4883366}}

@article{lieberman_intonation_1967,
	abstract = {ATTEMPTED TO DETERMINE HOW PEOPLE ACTUALLY PRODUCE AND PERCEIVE INTONATION AND TO DIFFERENTIATE CLEARLY BETWEEN THE LINGUISTIC AND EMOTIONAL ASPECTS OF INTONATION AND STRESS. EVIDENCE, CONTRARY TO GENERAL ASSUMPTIONS, IS PRESENTED THAT INTONATION IS A CENTRAL RATHER THAT PERIPHERAL LINGUISTIC FEATURE, I.E., AN INNATE RATHER THAN ACQUIRED CHARACTERISTIC; AND THAT IT IS BASED ON UNIVERSAL CONSTANTS OF HUMAN PSYCHOLOGY, AND CONSEQUENTLY IS AN INVARIANT AMONG SPECIFIC LANGUAGE GROUPS. DATA ARE EXAMINED REGARDING THE ARTICULATORY, ACOUSTIC, PERCEPTUAL, PHONETIC, AND SYNTACTIC DIMENSIONS OF INTONATION FOR AMERICAN ENGLISH AND AVAILABLE DATA FOR BOTH RELATED AND UNRELATED LANGUAGES INCLUDING RUSSIAN, FINNISH, JAPANESE, AND SWEDISH. (10 P. REF.) (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	author = {Lieberman, Philip},
	file = {Snapshot:/Users/Cecile/Zotero/storage/FZUDI39N/1967-16665-001.html:text/html},
	journal = {M.I.T. Research Monograph},
	keywords = {Perception, Psycholinguistics, Language, Stress},
	pages = {xiii, 210--xiii, 210},
	title = {Intonation, perception, and language},
	volume = {38},
	year = {1967}}

@article{mampe_newborns_2009,
	abstract = {Summary
Human fetuses are able to memorize auditory stimuli from the external world by the last trimester of pregnancy, with a particular sensitivity to melody contour in both music and language 1, 2, 3. Newborns prefer their mother's voice over other voices 4, 5, 6, 7, 8 and perceive the emotional content of messages conveyed via intonation contours in maternal speech (``motherese'') [9]. Their perceptual preference for the surrounding language 10, 11, 12 and their ability to distinguish between prosodically different languages 13, 14, 15 and pitch changes [16] are based on prosodic information, primarily melody. Adult-like processing of pitch intervals allows newborns to appreciate musical melodies and emotional and linguistic prosody [17]. Although prenatal exposure to native-language prosody influences newborns' perception, the surrounding language affects sound production apparently much later [18]. Here, we analyzed the crying patterns of 30 French and 30 German newborns with respect to their melody and intensity contours. The French group preferentially produced cries with a rising melody contour, whereas the German group preferentially produced falling contours. The data show an influence of the surrounding speech prosody on newborns' cry melody, possibly via vocal learning based on biological predispositions.},
	author = {Mampe, Birgit and Friederici, Angela D. and Christophe, Anne and Wermke, Kathleen},
	doi = {10.1016/j.cub.2009.09.064},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YVDNX7DN/Mampe et al. - 2009 - Newborns' Cry Melody Is Shaped by Their Native Lan.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KQVQU8FF/S0960982209018247.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	keywords = {SYSNEURO},
	month = dec,
	number = {23},
	pages = {1994--1997},
	title = {Newborns' {Cry} {Melody} {Is} {Shaped} by {Their} {Native} {Language}},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982209018247},
	urldate = {2018-09-24},
	volume = {19},
	year = {2009},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982209018247},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2009.09.064}}

@article{moon_language_2013,
	abstract = {Aims To test the hypothesis that exposure to ambient language in the womb alters phonetic perception shortly after birth. This two-country study aimed to see whether neonates demonstrated prenatal learning by how they responded to vowels in a category from their native language and another non-native language, regardless of how much postnatal experience the infants had. Method A counterbalanced experiment was conducted in Sweden (n = 40) and the USA (n = 40) using Swedish and English vowel sounds. The neonates (mean postnatal age = 33 h) controlled audio presentation of either native or non-native vowels by sucking on a pacifier, with the number of times they sucked their pacifier being used to demonstrate what vowel sounds attracted their attention. The vowels were either the English/i/or Swedish/y/in the form of a prototype plus 16 variants of the prototype. Results The infants in the native and non-native groups responded differently. As predicted, the infants responded to the unfamiliar non-native language with higher mean sucks. They also sucked more to the non-native prototype. Time since birth (range: 7--75 h) did not affect the outcome. Conclusion The ambient language to which foetuses are exposed in the womb starts to affect their perception of their native language at a phonetic level. This can be measured shortly after birth by differences in responding to familiar vs. unfamiliar vowels.},
	author = {Moon, Christine and Lagercrantz, Hugo and Kuhl, Patricia K.},
	copyright = {{\copyright}2012 The Author(s)/Acta P{\ae}diatrica {\copyright}2012 Foundation Acta P{\ae}diatrica},
	doi = {10.1111/apa.12098},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/6YICQ4N2/Moon et al. - 2013 - Language experienced in utero affects vowel percep.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5KZ36KE4/apa.html:text/html},
	issn = {1651-2227},
	journal = {Acta Paediatrica},
	keywords = {Learning, Vowels, Language, Foetal, Neonatal},
	language = {en},
	month = feb,
	number = {2},
	pages = {156--160},
	shorttitle = {Language experienced in utero affects vowel perception after birth},
	title = {Language experienced in utero affects vowel perception after birth: a two-country study},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/apa.12098},
	urldate = {2018-09-24},
	volume = {102},
	year = {2013},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/apa.12098},
	bdsk-url-2 = {https://doi.org/10.1111/apa.12098}}

@incollection{lecanuet_speech_1993,
	abstract = {Data from three experimental sources are reviewed in this chapter. They indicate: (a) that maternal and external voices travel to fetal head level, (b) the near term fetus perceives and discriminates speech signals, and (c) that he/she may learn some features of speech sounds to which he/she was exposed during the last trimester of the gestation and remember them post-natally.},
	address = {Dordrecht},
	author = {Lecanuet, J-P. and Granier-Deferre, C.},
	booktitle = {Developmental {Neurocognition}: {Speech} and {Face} {Processing} in the {First} {Year} of {Life}},
	doi = {10.1007/978-94-015-8234-6_20},
	editor = {de Boysson-Bardies, B{\'e}n{\'e}dicte and de Schonen, Scania and Jusczyk, Peter and McNeilage, Peter and Morton, John},
	isbn = {978-94-015-8234-6},
	keywords = {Female Voice, Fetal Heart Rate, Sound Environment, Sound Pressure Level, Speech Sound},
	language = {en},
	pages = {237--248},
	publisher = {Springer Netherlands},
	series = {{NATO} {ASI} {Series}},
	title = {Speech {Stimuli} in the {Fetal} {Environment}},
	url = {https://doi.org/10.1007/978-94-015-8234-6_20},
	urldate = {2018-09-24},
	year = {1993},
	bdsk-url-1 = {https://doi.org/10.1007/978-94-015-8234-6_20}}

@article{abrams_acoustic_2000,
	abstract = {The acoustic environment of the fetus is composed of continuous cardiovascular, respiratory, and intestinal sounds that are punctuated by isolated, shorter bursts during maternal body movements and vocalizations. The distribution of sounds is confined to frequencies below 300 Hz. Additionally, vibrations on the external surface of the maternal abdomen can induce sounds inside the uterus. The half-round sound pressure contours in the abdomen during vibroacoustic stimulation differ from the circular distribution of contours resulting from airborne sound pressure exposure. The static and dynamic forces of the vibrator and the vibrator distance from the target are also factors in sound transmission. Responses to sound are best described in animals and include changes in behavioral state, brain bloodflow, auditory brainstem response, and local cerebral glucose utilization along the central auditory pathway.},
	author = {Abrams, Robert M. and Gerhardt, Kenneth J.},
	copyright = {2000 Nature Publishing Group},
	doi = {10.1038/sj.jp.7200445},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8PHVZPD3/Abrams et Gerhardt - 2000 - The Acoustic Environment and Physiological Respons.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AVXID8JG/7200445.html:text/html},
	issn = {1476-5543},
	journal = {Journal of Perinatology},
	language = {en},
	month = dec,
	number = {S1},
	pages = {S31--S36},
	title = {The {Acoustic} {Environment} and {Physiological} {Responses} of the {Fetus}},
	url = {https://www.nature.com/articles/7200445},
	urldate = {2018-09-24},
	volume = {20},
	year = {2000},
	bdsk-url-1 = {https://www.nature.com/articles/7200445},
	bdsk-url-2 = {https://doi.org/10.1038/sj.jp.7200445}}

@article{mizrahi_single_2014,
	abstract = {The auditory system drives behavior using information extracted from sounds. Early in the auditory hierarchy, circuits are highly specialized for detecting basic sound features. However, already at the level of the auditory cortex the functional organization of the circuits and the underlying coding principles become different. Here, we review some recent progress in our understanding of single neuron and population coding in primary auditory cortex, focusing on natural sounds. We discuss possible mechanisms explaining why single neuron responses to simple sounds cannot predict responses to natural stimuli. We describe recent work suggesting that structural features like local subnetworks rather than smoothly mapped tonotopy are essential components of population coding. Finally, we suggest a synthesis of how single neurons and subnetworks may be involved in coding natural sounds.},
	author = {Mizrahi, Adi and Shalev, Amos and Nelken, Israel},
	doi = {10.1016/j.conb.2013.09.007},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/LMEQT2W7/S0959438813001864.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = feb,
	pages = {103--110},
	series = {Neural maps},
	title = {Single neuron and population coding of natural sounds in auditory cortex},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438813001864},
	urldate = {2018-09-26},
	volume = {24},
	year = {2014},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438813001864},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2013.09.007}}

@article{laudanski_differences_2012,
	abstract = {Spectro-temporal properties of auditory cortex neurons have been extensively studied with artificial sounds but it is still unclear whether they help in understanding neuronal responses to communication sounds. Here, we directly compared spectro-temporal receptive fields (STRFs) obtained from the same neurons using both artificial stimuli (dynamic moving ripples, DMRs) and natural stimuli (conspecific vocalizations) that were matched in terms of spectral content, average power and modulation spectrum. On a population of auditory cortex neurons exhibiting reliable tuning curves when tested with pure tones, significant STRFs were obtained for 62\% of the cells with vocalizations and 68\% with DMR. However, for many cells with significant vocalization-derived STRFs (STRFvoc) and DMR-derived STRFs (STRFdmr), the BF, latency, bandwidth and global STRFs shape differed more than what would be predicted by spiking responses simulated by a linear model based on a non-homogenous Poisson process. Moreover STRFvoc predicted neural responses to vocalizations more accurately than STRFdmr predicted neural response to DMRs, despite similar spike-timing reliability for both sets of stimuli. Cortical bursts, which potentially introduce nonlinearities in evoked responses, did not explain the differences between STRFvoc and STRFdmr. Altogether, these results suggest that the nonlinearity of auditory cortical responses makes it difficult to predict responses to communication sounds from STRFs computed from artificial stimuli.},
	author = {Laudanski, Jonathan and Edeline, Jean-Marc and Huetz, Chlo{\'e}},
	doi = {10.1371/journal.pone.0050539},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CV3VVMZ6/Laudanski et al. - 2012 - Differences between Spectro-Temporal Receptive Fie.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P56CIJVW/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Acoustics, Neuronal tuning, Neurons, Auditory cortex, Action potentials, Bandwidth (signal processing), Guinea pigs, Vocalization},
	language = {en},
	month = nov,
	number = {11},
	pages = {e50539},
	title = {Differences between {Spectro}-{Temporal} {Receptive} {Fields} {Derived} from {Artificial} and {Natural} {Stimuli} in the {Auditory} {Cortex}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0050539},
	urldate = {2018-09-26},
	volume = {7},
	year = {2012},
	bdsk-url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0050539},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0050539}}

@article{amin_selective_2013,
	abstract = {Previous research has shown that postnatal exposure to simple, synthetic sounds can affect the sound representation in the auditory cortex as reflected by changes in the tonotopic map or other relatively simple tuning properties, such as AM tuning. However, their functional implications for neural processing in the generation of ethologically-based perception remain unexplored. Here we examined the effects of noise-rearing and social isolation on the neural processing of communication sounds such as species-specific song, in the primary auditory cortex analog of adult zebra finches. Our electrophysiological recordings reveal that neural tuning to simple frequency-based synthetic sounds is initially established in all the laminae independent of patterned acoustic experience; however, we provide the first evidence that early exposure to patterned sound statistics, such as those found in native sounds, is required for the subsequent emergence of neural selectivity for complex vocalizations and for shaping neural spiking precision in superficial and deep cortical laminae, and for creating efficient neural representations of song and a less redundant ensemble code in all the laminae. Our study also provides the first causal evidence for `sparse coding', such that when the statistics of the stimuli were changed during rearing, as in noise-rearing, that the sparse or optimal representation for species-specific vocalizations disappeared. Taken together, these results imply that a layer-specific differential development of the auditory cortex requires patterned acoustic input, and a specialized and robust sensory representation of complex communication sounds in the auditory cortex requires a rich acoustic and social environment.},
	author = {Amin, Noopur and Gastpar, Michael and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1371/journal.pone.0061417},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UQ8B28WP/Amin et al. - 2013 - Selective and Efficient Neural Coding of Communica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/LZXBESKV/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Acoustics, Neuronal tuning, Neurons, Single neuron function, Bird song, Birds, White noise, Zebra finch},
	language = {en},
	month = apr,
	number = {4},
	pages = {e61417},
	title = {Selective and {Efficient} {Neural} {Coding} of {Communication} {Signals} {Depends} on {Early} {Acoustic} and {Social} {Environment}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061417},
	urldate = {2018-09-26},
	volume = {8},
	year = {2013},
	bdsk-url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061417},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0061417}}

@article{chechik_auditory_2012,
	abstract = {The auditory system extracts behaviorally relevant information from acoustic stimuli. The average activity in auditory cortex is known to be sensitive to spectro-temporal patterns in sounds. However, it is not known whether the auditory cortex also processes more abstract features of sounds, which may be more behaviorally relevant than spectro-temporal patterns. Using recordings from three stations of the auditory pathway, the inferior colliculus (IC), the ventral division of the medial geniculate body (MGB) of the thalamus, and the primary auditory cortex (A1) of the cat in response to natural sounds, we compared the amount of information that spikes contained about two aspects of the stimuli: spectro-temporal patterns, and abstract entities present in the same stimuli such as a bird chirp, its echoes, and the ambient noise. IC spikes conveyed on average approximately the same amount of information about spectro-temporal patterns as they conveyed about abstract auditory entities, but A1 and the MGB neurons conveyed on average three times more information about abstract auditory entities than about spectro-temporal patterns. Thus, the majority of neurons in auditory thalamus and cortex coded well the presence of abstract entities in the sounds without containing much information about their spectro-temporal structure, suggesting that they are sensitive to abstract features in these sounds.},
	author = {Chechik, Gal and Nelken, Israel},
	doi = {10.1073/pnas.1111242109},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/SH8J9DZP/Chechik et Nelken - 2012 - Auditory abstraction from spectro-temporal feature.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/453JJ53N/18968.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = nov,
	number = {46},
	pages = {18968--18973},
	pmid = {23112145},
	title = {Auditory abstraction from spectro-temporal features to coding auditory entities},
	url = {http://www.pnas.org/content/109/46/18968},
	urldate = {2018-09-26},
	volume = {109},
	year = {2012},
	bdsk-url-1 = {http://www.pnas.org/content/109/46/18968},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1111242109}}

@article{garcia-lazaro_tuning_2006,
	abstract = {Summary
The amplitude and pitch fluctuations of natural soundscapes often exhibit ``1/f spectra'' 1, 2, which means that large, abrupt changes in pitch or loudness occur proportionally less frequently in nature than gentle, gradual fluctuations. Furthermore, human listeners reportedly prefer 1/f distributed random melodies to melodies with faster (1/f0) or slower (1/f2) dynamics [3]. One might therefore suspect that neurons in the central auditory system may be tuned to 1/f dynamics, particularly given that recent reports provide evidence for tuning to 1/f dynamics in primary visual cortex [4]. To test whether neurons in primary auditory cortex (A1) are tuned to 1/f dynamics, we recorded responses to random tone complexes in which the fundamental frequency and the envelope were determined by statistically independent ``1/fγ random walks,'' with γ set to values between 0.5 and 4. Many A1 neurons showed clear evidence of tuning and responded with higher firing rates to stimuli with γ between 1 and 1.5. Response patterns elicited by 1/fγ stimuli were more reproducible for values of γ close to 1. These findings indicate that auditory cortex is indeed tuned to the 1/f dynamics commonly found in the statistical distributions of natural soundscapes.},
	author = {Garcia-Lazaro, J. A. and Ahmed, Bashir and Schnupp, J. W. H.},
	doi = {10.1016/j.cub.2005.12.013},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YJG4J3S5/S0960982205015678.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	keywords = {SYSNEURO},
	month = feb,
	number = {3},
	pages = {264--271},
	title = {Tuning to {Natural} {Stimulus} {Dynamics} in {Primary} {Auditory} {Cortex}},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982205015678},
	urldate = {2018-09-26},
	volume = {16},
	year = {2006},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982205015678},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2005.12.013}}

@article{werker_cross-language_1984,
	abstract = {Previous work in which we compared English infants, English adults, and Hindi adults on their ability to discriminate two pairs of Hindi (non-English) speech contrasts has indicated that infants discriminate speech sounds according to phonetic category without prior specific language experience (Werker, Gilbert, Humphrey, \& Tees, 1981), whereas adults and children as young as age 4 (Werker \& Tees, in press), may lose this ability as a function of age and or linguistic experience. The present work was designed to (a) determine the generalizability of such a decline by comparing adult English, adult Salish, and English infant subjects on their perception of a new non-English (Salish) speech contrast, and (b) delineate the time course of the developmental decline in this ability. The results of these experiments replicate our original findings by showing that infants can discriminate nonnative speech contrasts without relevant experience, and that there is a decline in this ability during ontogeny. Furthermore, data from both cross-sectional and longitudinal studies shows that this decline occurs within the first year of life, and that it is a function of specific language experience.},
	author = {Werker, Janet F. and Tees, Richard C.},
	doi = {10.1016/S0163-6383(84)80022-3},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NZ92AZ6W/S0163638384800223.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {speech perception, cross-language, decline, infants},
	month = jan,
	number = {1},
	pages = {49--63},
	shorttitle = {Cross-language speech perception},
	title = {Cross-language speech perception: {Evidence} for perceptual reorganization during the first year of life},
	url = {http://www.sciencedirect.com/science/article/pii/S0163638384800223},
	urldate = {2018-09-27},
	volume = {7},
	year = {1984},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638384800223},
	bdsk-url-2 = {https://doi.org/10.1016/S0163-6383(84)80022-3}}

@article{rabinowitz_contrast_2011,
	abstract = {Summary
The auditory system must represent sounds with a wide range of statistical properties. One important property is the spectrotemporal contrast in the acoustic environment: the variation in sound pressure in each frequency band, relative to the mean pressure. We show that neurons in ferret auditory cortex rescale their gain to partially compensate for the spectrotemporal contrast of recent stimulation. When contrast is low, neurons increase their gain, becoming more sensitive to small changes in the stimulus, although the effectiveness of contrast gain control is reduced at low mean levels. Gain is primarily determined by contrast near each neuron's preferred frequency, but there is also a contribution from contrast in more distant frequency bands. Neural responses are modulated by contrast over timescales of ∼100 ms. By using contrast gain control to expand or compress the representation of its inputs, the auditory system may be seeking an efficient coding of natural sounds.},
	author = {Rabinowitz, Neil C. and Willmore, Ben D. B. and Schnupp, Jan W. H. and King, Andrew J.},
	doi = {10.1016/j.neuron.2011.04.030},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IA3D5VB9/Rabinowitz et al. - 2011 - Contrast Gain Control in Auditory Cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZSUK6CJ8/S0896627311004351.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = jun,
	number = {6},
	pages = {1178--1191},
	title = {Contrast {Gain} {Control} in {Auditory} {Cortex}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627311004351},
	urldate = {2018-09-29},
	volume = {70},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627311004351},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2011.04.030}}

@article{zhang_persistent_2001,
	abstract = {This study demonstrates that the adult form of 'tonotopic maps' of sound frequency in the rat primary auditory cortex (A1) arises from parallel developmental processes involving two cortical zones: the progressive differentiation and refinement of selectively tone-responsive receptive fields within an initially broadly-tuned posterior zone, and the progressive loss of tone-evoked, short-latency response over an initially large, very broadly tuned anterior zone. The formation of tonotopic maps in A1 was specifically influenced by a rat pup's early acoustic environments. Exposure to pulsed tones resulted in accelerated emergence and an expansion of A1 representations of those specific tone frequencies, as well as a deteriorated tonotopicity and broader-than-normal receptive fields. Thus, auditory experiences during early postnatal development are important in shaping the functional development of auditory cortical representations of specific acoustic environments.},
	author = {Zhang, Li I. and Bao, Shaowen and Merzenich, Michael M.},
	copyright = {2001 Nature Publishing Group},
	doi = {10.1038/nn745},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/QYPIT6Y2/Zhang et al. - 2001 - Persistent and specific influences of early acoust.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KKXYY84P/nn745.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = nov,
	number = {11},
	pages = {1123--1130},
	title = {Persistent and specific influences of early acoustic environments on primary auditory cortex},
	url = {https://www.nature.com/articles/nn745},
	urldate = {2018-09-27},
	volume = {4},
	year = {2001},
	bdsk-url-1 = {https://www.nature.com/articles/nn745},
	bdsk-url-2 = {https://doi.org/10.1038/nn745}}

@article{chang_environmental_2003,
	abstract = {The mammalian auditory cortex normally undergoes rapid and progressive functional maturation. Here we show that rearing infant rat pups in continuous, moderate-level noise delayed the emergence of adultlike topographic representational order and the refinement of response selectivity in the primary auditory cortex (A1) long beyond normal developmental benchmarks. When those noise-reared adult rats were subsequently exposed to a pulsed pure-tone stimulus, A1 rapidly reorganized, demonstrating that exposure-driven plasticity characteristic of the critical period was still ongoing. These results demonstrate that A1 organization is shaped by a young animal's exposure to salient, structured acoustic inputs---and implicate noise as a risk factor for abnormal child development.},
	author = {Chang, Edward F. and Merzenich, Michael M.},
	copyright = {American Association for the Advancement of Science},
	doi = {10.1126/science.1082163},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/XD3VR42E/Chang et Merzenich - 2003 - Environmental Noise Retards Auditory Cortical Deve.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/54UNZTCI/498.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = apr,
	number = {5618},
	pages = {498--502},
	pmid = {12702879},
	title = {Environmental {Noise} {Retards} {Auditory} {Cortical} {Development}},
	url = {http://science.sciencemag.org/content/300/5618/498},
	urldate = {2018-09-27},
	volume = {300},
	year = {2003},
	bdsk-url-1 = {http://science.sciencemag.org/content/300/5618/498},
	bdsk-url-2 = {https://doi.org/10.1126/science.1082163}}

@article{webb_mothers_2015,
	abstract = {Brain development is largely shaped by early sensory experience. However, it is currently unknown whether, how early, and to what extent the newborn's brain is shaped by exposure to maternal sounds when the brain is most sensitive to early life programming. The present study examined this question in 40 infants born extremely prematurely (between 25- and 32-wk gestation) in the first month of life. Newborns were randomized to receive auditory enrichment in the form of audio recordings of maternal sounds (including their mother's voice and heartbeat) or routine exposure to hospital environmental noise. The groups were otherwise medically and demographically comparable. Cranial ultrasonography measurements were obtained at 30 $\pm$ 3 d of life. Results show that newborns exposed to maternal sounds had a significantly larger auditory cortex (AC) bilaterally compared with control newborns receiving standard care. The magnitude of the right and left AC thickness was significantly correlated with gestational age but not with the duration of sound exposure. Measurements of head circumference and the widths of the frontal horn (FH) and the corpus callosum (CC) were not significantly different between the two groups. This study provides evidence for experience-dependent plasticity in the primary AC before the brain has reached full-term maturation. Our results demonstrate that despite the immaturity of the auditory pathways, the AC is more adaptive to maternal sounds than environmental noise. Further studies are needed to better understand the neural processes underlying this early brain plasticity and its functional implications for future hearing and language development.},
	author = {Webb, Alexandra R. and Heller, Howard T. and Benson, Carol B. and Lahav, Amir},
	doi = {10.1073/pnas.1414924112},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/D48KFQJS/Webb et al. - 2015 - Mother's voice and heartbeat sounds elicit auditor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2VRTALLV/3152.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {auditory, brain, heartbeat, mother's voice, preterm newborns},
	language = {en},
	month = mar,
	number = {10},
	pages = {3152--3157},
	pmid = {25713382},
	title = {Mother's voice and heartbeat sounds elicit auditory plasticity in the human brain before full gestation},
	url = {http://www.pnas.org/content/112/10/3152},
	urldate = {2018-09-27},
	volume = {112},
	year = {2015},
	bdsk-url-1 = {http://www.pnas.org/content/112/10/3152},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1414924112}}

@article{eisermann_normal_2013,
	abstract = {Summary
The important EEG changes that occur throughout childhood are a major challenge for the neurophysiologist. These reflect brain maturation, which is especially fast during the first year of life. This article describes normal EEG features and variants, characteristic patterns of development, as well as some patterns that are unusual for age, from the neonatal period to adolescence. We also describe how to adapt techniques and prepare patients in order to get interpretable records of appropriate duration, in neonates, infants, and young children.
R{\'e}sum{\'e}
L'organisation spatio-temporelle et les grapho-{\'e}l{\'e}ments physiologiques de l'EEG {\'e}voluent parall{\`e}lement {\`a} la maturation c{\'e}r{\'e}brale, particuli{\`e}rement rapide dans la premi{\`e}re ann{\'e}e de vie. Cet article d{\'e}crit l'EEG normal avec ses variantes et aspects maturatifs caract{\'e}ristiques en fonction de l'{\^a}ge et de l'EEG, qui doivent {\^e}tre connus pour interpr{\'e}ter l'EEG de l'enfant. Nous d{\'e}crivons {\'e}galement les techniques d'enregistrement adapt{\'e}es au nouveau-n{\'e}, au nourrisson et {\`a} l'enfant, indispensables pour obtenir des trac{\'e}s de bonne qualit{\'e}.},
	author = {Eisermann, M. and Kaminska, A. and Moutard, M. -L. and Soufflet, C. and Plouin, P.},
	doi = {10.1016/j.neucli.2012.09.091},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NRZSWVDE/S0987705312003735.html:text/html},
	issn = {0987-7053},
	journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
	keywords = {EEG, Maturation, Electroencephalogram, {\'E}lectroenc{\'e}phalogramme, N{\'e}onatologie, Neonatology, Normal variants, Variantes normales},
	month = jan,
	number = {1},
	pages = {35--65},
	shorttitle = {Normal {EEG} in childhood},
	title = {Normal {EEG} in childhood: {From} neonates to adolescents},
	url = {http://www.sciencedirect.com/science/article/pii/S0987705312003735},
	urldate = {2018-09-29},
	volume = {43},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0987705312003735},
	bdsk-url-2 = {https://doi.org/10.1016/j.neucli.2012.09.091}}

@book{selkirk_phonology_1986,
	address = {Cambridge, MA, USA},
	author = {Selkirk, E O},
	isbn = {0-262-69098-5},
	publisher = {MIT Press},
	shorttitle = {Phonology and {Syntax}},
	title = {Phonology and {Syntax}: {The} {Relationship} {Between} {Sound} and {Structure}},
	year = {1986}}

@article{overath_information_2007,
	abstract = {The entropy metric derived from information theory provides a means to quantify the amount of information transmitted in acoustic streams like speech or music. By systematically varying the entropy of pitch sequences, we sought brain areas where neural activity and energetic demands increase as a function of entropy. Such a relationship is predicted to occur in an efficient encoding mechanism that uses less computational resource when less information is present in the signal: we specifically tested the hypothesis that such a relationship is present in the planum temporale (PT). In two convergent functional MRI studies, we demonstrated this relationship in PT for encoding, while furthermore showing that a distributed fronto-parietal network for retrieval of acoustic information is independent of entropy. The results establish PT as an efficient neural engine that demands less computational resource to encode redundant signals than those with high information content.},
	author = {Overath, Tobias and Cusack, Rhodri and Kumar, Sukhbinder and Kriegstein, Katharina von and Warren, Jason D. and Grube, Manon and Carlyon, Robert P. and Griffiths, Timothy D.},
	doi = {10.1371/journal.pbio.0050288},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Y4EZTGA9/Overath et al. - 2007 - An Information Theoretic Characterisation of Audit.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/W6RCAN2X/article.html:text/html},
	issn = {1545-7885},
	journal = {PLOS Biology},
	keywords = {Acoustics, Fractals, Speech signal processing, Acoustic signals, Entropy, Functional magnetic resonance imaging, Information entropy, Pitch perception},
	language = {en},
	month = oct,
	number = {11},
	pages = {e288},
	title = {An {Information} {Theoretic} {Characterisation} of {Auditory} {Encoding}},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0050288},
	urldate = {2018-09-30},
	volume = {5},
	year = {2007},
	bdsk-url-1 = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0050288},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pbio.0050288}}

@book{nespor_prosodic_2007,
	abstract = {Prosodic Phonology by Marina Nespor and Irene Vogel is now available again. "Nespor \& Vogel 1986" is a citation classic - even after twenty years, it is still recognized as the standard resource on Prosodic Phonology. This groundbreaking work introduces all of the prosodic constituents (syllable, foot, word, clitic group, phonological phrase, intonational phrase and utterance) and provides evidence for each one from numerous languages. Prosodic Phonology also includes a chapter in which experimental psycholinguistic data support the proposed hierarchy.A perceptual study provides evidence that prosodic constituent structure - not syntactic constituent structure - predicts whether listeners are able to disambiguate different types of ambiguous sentences. A chapter on the phonology of poetic meter examines portions of Dante's Divine Comedy.It is demonstrated that the constituents proposed for spoken language also make interesting predictions about literary metrical patterns. Prosodic Phonology is an important reference not only for phonologists, but for all linguists interested in the issue of interfaces among the components of grammar.It is also a basic resource for psycholinguists and cognitive scientists working on linguistic perception and language acquisition.},
	author = {Nespor, Marina and Vogel, Irene},
	isbn = {978-3-11-019789-1},
	keywords = {Language Arts \& Disciplines / Linguistics / General, Language Arts \& Disciplines / Grammar \& Punctuation},
	language = {en},
	note = {Google-Books-ID: VQC9jY2qTCkC},
	publisher = {Walter de Gruyter},
	shorttitle = {Prosodic {Phonology}},
	title = {Prosodic {Phonology}: {With} a {New} {Foreword}},
	year = {2007}}

@article{ding_encoding_2016,
	abstract = {Neural encoding of sensory stimuli is typically studied by averaging neural signals across repetitions of the same stimulus. However, recent work has suggested that the variance of neural activity across repeated trials can also depend on sensory inputs. Here we characterize how intertrial variance of the local field potential (LFP) in primary auditory cortex of awake ferrets is affected by continuous natural sound stimuli. We find that natural sounds often suppress the intertrial variance of low-frequency LFP ({\textless}16 Hz). However, the amount of the variance reduction is not significantly correlated with the amplitude of the mean response at the same recording site. Moreover, the variance changes occur with longer latency than the mean response. Although the dynamics of the mean response and intertrial variance differ, spectro-temporal receptive field analysis reveals that changes in LFP variance have frequency tuning similar to multiunit activity at the same recording site, suggesting a local origin for changes in LFP variance. In summary, the spectral tuning of LFP intertrial variance and the absence of a correlation with the amplitude of the mean evoked LFP suggest substantial heterogeneity in the interaction between spontaneous and stimulus-driven activity across local neural populations in auditory cortex.},
	author = {Ding, Nai and Simon, Jonathan Z. and Shamma, Shihab A. and David, Stephen V.},
	doi = {10.1152/jn.00652.2015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FQ9TIS22/Ding et al. - 2016 - Encoding of natural sounds by variance of the cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8IQGQGSG/jn.00652.html:text/html},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	month = feb,
	number = {5},
	pages = {2389--2398},
	title = {Encoding of natural sounds by variance of the cortical local field potential},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.00652.2015},
	urldate = {2018-10-02},
	volume = {115},
	year = {2016},
	bdsk-url-1 = {https://www.physiology.org/doi/abs/10.1152/jn.00652.2015},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00652.2015}}

@article{mazzoni_encoding_2008,
	abstract = {Recordings of local field potentials (LFPs) reveal that the sensory cortex displays rhythmic activity and fluctuations over a wide range of frequencies and amplitudes. Yet, the role of this kind of activity in encoding sensory information remains largely unknown. To understand the rules of translation between the structure of sensory stimuli and the fluctuations of cortical responses, we simulated a sparsely connected network of excitatory and inhibitory neurons modeling a local cortical population, and we determined how the LFPs generated by the network encode information about input stimuli. We first considered simple static and periodic stimuli and then naturalistic input stimuli based on electrophysiological recordings from the thalamus of anesthetized monkeys watching natural movie scenes. We found that the simulated network produced stimulus-related LFP changes that were in striking agreement with the LFPs obtained from the primary visual cortex. Moreover, our results demonstrate that the network encoded static input spike rates into gamma-range oscillations generated by inhibitory--excitatory neural interactions and encoded slow dynamic features of the input into slow LFP fluctuations mediated by stimulus--neural interactions. The model cortical network processed dynamic stimuli with naturalistic temporal structure by using low and high response frequencies as independent communication channels, again in agreement with recent reports from visual cortex responses to naturalistic movies. One potential function of this frequency decomposition into independent information channels operated by the cortical network may be that of enhancing the capacity of the cortical column to encode our complex sensory environment.},
	author = {Mazzoni, Alberto and Panzeri, Stefano and Logothetis, Nikos K. and Brunel, Nicolas},
	doi = {10.1371/journal.pcbi.1000239},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8D363ZXP/Mazzoni et al. - 2008 - Encoding of Naturalistic Stimuli by Local Field Po.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AGKH7HGB/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Neurons, Action potentials, Membrane potential, Neural networks, Coding mechanisms, Gamma-aminobutyric acid, Signaling networks, Visual cortex},
	language = {en},
	month = dec,
	number = {12},
	pages = {e1000239},
	title = {Encoding of {Naturalistic} {Stimuli} by {Local} {Field} {Potential} {Spectra} in {Networks} of {Excitatory} and {Inhibitory} {Neurons}},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000239},
	urldate = {2018-10-18},
	volume = {4},
	year = {2008},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000239},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1000239}}

@article{steinschneider_spectrotemporal_2008,
	abstract = {Abstract.  Electroencephalography is increasingly being used to probe the functional organization of auditory cortex. Modulation of the electroencephalographic},
	author = {Steinschneider, Mitchell and Fishman, Yonatan I. and Arezzo, Joseph C.},
	doi = {10.1093/cercor/bhm094},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/MUPTXXJL/Steinschneider et al. - 2008 - Spectrotemporal Analysis of Evoked and Induced Ele.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GZPGS3G6/286882.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	language = {en},
	month = mar,
	number = {3},
	pages = {610--625},
	title = {Spectrotemporal {Analysis} of {Evoked} and {Induced} {Electroencephalographic} {Responses} in {Primary} {Auditory} {Cortex} ({A1}) of the {Awake} {Monkey}},
	url = {https://academic.oup.com/cercor/article/18/3/610/286882},
	urldate = {2018-10-17},
	volume = {18},
	year = {2008},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/18/3/610/286882},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhm094}}

@article{churchland_stimulus_2010,
	abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input.},
	author = {Churchland, Mark M. and Yu, Byron M. and Cunningham, John P. and Sugrue, Leo P. and Cohen, Marlene R. and Corrado, Greg S. and Newsome, William T. and Clark, Andrew M. and Hosseini, Paymon and Scott, Benjamin B. and Bradley, David C. and Smith, Matthew A. and Kohn, Adam and Movshon, J. Anthony and Armstrong, Katherine M. and Moore, Tirin and Chang, Steve W. and Snyder, Lawrence H. and Lisberger, Stephen G. and Priebe, Nicholas J. and Finn, Ian M. and Ferster, David and Ryu, Stephen I. and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V.},
	copyright = {2010 Nature Publishing Group},
	doi = {10.1038/nn.2501},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/QKAEQ8V8/Churchland et al. - 2010 - Stimulus onset quenches neural variability a wide.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ELXRGRCN/nn.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = mar,
	number = {3},
	pages = {369--378},
	shorttitle = {Stimulus onset quenches neural variability},
	title = {Stimulus onset quenches neural variability: a widespread cortical phenomenon},
	url = {https://www.nature.com/articles/nn.2501},
	urldate = {2018-10-17},
	volume = {13},
	year = {2010},
	bdsk-url-1 = {https://www.nature.com/articles/nn.2501},
	bdsk-url-2 = {https://doi.org/10.1038/nn.2501}}

@article{ghitza_behavioral_2014,
	abstract = {Studies on the intelligibility of time-compressed speech have shown flawless performance for moderate compression factors, a sharp deterioration for compression factors above three, and an improved performance as a result of "repackaging" -- a process of dividing the time-compressed waveform into fragments, called packets, and delivering the packets in a prescribed rate. This intricate pattern of performance reflects the reliability of the auditory system in processing speech streams with different information transfer rates; the knee-point of performance defines the auditory channel capacity. This study is concerned with the cortical computation principle that determines channel capacity. Oscillation-based models of speech perception hypothesize that the speech decoding process is guided by a cascade of oscillations with θ as "master," capable of tracking the input rhythm, with the θ cycles aligned with the intervocalic speech fragments termed θ-syllables; intelligibility remains high as long as θ is in sync with the input, and it sharply deteriorates once θ is out of sync. In the study described here the hypothesized role of θ was examined by measuring the auditory channel capacity of time-compressed speech undergone repackaging. For all compression factors tested (up to eight), packaging rate at capacity equals 9 packets/sec -- aligned with the upper limit of cortical θ, θmax (about 9 Hz) -- and the packet duration equals the duration of one uncompressed θ-syllable divided by the compression factor. The alignment of both the packaging rate and the packet duration with properties of cortical θ suggests that the auditory channel capacity is determined by θ. Irrespective of speech speed, the maximum information transfer rate through the auditory channel is the information in one uncompressed θ-syllable long speech fragment per one θmax cycle. Equivalently, the auditory channel capacity is 9 θ-syllables/sec.},
	author = {Ghitza, Oded},
	doi = {10.3389/fpsyg.2014.00652},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/E64G7R4X/Ghitza - 2014 - Behavioral evidence for the role of cortical θ osc.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	keywords = {Auditory channel capacity, brain rhythms, fast speech, information transfer rate, intelligibility, phonetic variability, theta oscillations},
	language = {English},
	title = {Behavioral evidence for the role of cortical θ oscillations in determining auditory channel capacity for speech},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00652/full},
	urldate = {2018-10-28},
	volume = {5},
	year = {2014},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00652/full},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2014.00652}}

@article{de_roever_investigation_2018,
	abstract = {It has been 20 years since functional near-infrared spectroscopy (fNIRS) was first used to investigate the evoked haemodynamic response to a stimulus in newborns. The haemodynamic response to functional activation is well-established in adults, with an observed increase in concentration change of oxygenated haemoglobin (∆[HbO2]) and decrease in deoxygenated haemoglobin (∆[HHb]). However, functional studies in newborns have revealed a mixed response, particularly with ∆[HHb] where an inconsistent change in direction is observed. The reason for this heterogeneity is unknown, with potential explanations arising from differing physiology in the developing brain, or differences in instrumentation or methodology. The aim of this review is to collate the findings from studies that have employed fNIRS to monitor cerebral haemodynamics in term newborn infants aged 1 day to 1 month. A total of 46 eligible studies were identified; some studies investigated more than one stimulus type, resulting in a total of 51 reported results. The NIRS parameters reported varied across studies with 50/51 cases reporting ∆[HbO2], 39/51 reporting ∆[HHb] and 13/51 reporting total haemoglobin concentration ∆[HbT] (∆[HbO2] + ∆[HHb]). However, of the 39 cases reporting ∆[HHb] in graphs or tables, only 24 studies explicitly discuss the response (i.e. direction of change) of this variable. In the studies where the fNIRS responses are discussed, 46/51 cases observed an increase in ∆[HbO2], 7/51 observed an increase or varied ∆[HHb] and 2/51 reported a varied or negative ∆[HbT]. An increase in ∆[HbO2] and decrease or no change in ∆[HHb] was observed in 15 studies. By reviewing this body of literature, we have identified that the majority of research articles report an increase in ∆[HbO2] across various functional tasks and did not report the response of ∆[HHb]. Confirming the normal, healthy haemodynamic response in newborns will allow identification of unhealthy patterns and their association to normal neurodevelopment.},
	author = {de Roever, Isabel and Bale, Gemma and Mitra, Subhabrata and Meek, Judith and Robertson, Nicola J. and Tachtsidis, Ilias},
	doi = {10.3389/fnhum.2018.00371},
	file = {de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:/Users/Cecile/Zotero/storage/XYWUFNZN/de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/9YNTN8B9/de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	keywords = {newborns, neonates, Brain activity, functional activation, functional near-infrared spectroscopy (fNIRS), haemodynamic response function, Near-infrared spectroscopy (NIRS), neurovascular coupling, term infant},
	language = {English},
	shorttitle = {Investigation of the {Pattern} of the {Hemodynamic} {Response} as {Measured} by {Functional} {Near}-{Infrared} {Spectroscopy} ({fNIRS}) {Studies} in {Newborns}, {Less} {Than} a {Month} {Old}},
	title = {Investigation of the {Pattern} of the {Hemodynamic} {Response} as {Measured} by {Functional} {Near}-{Infrared} {Spectroscopy} ({fNIRS}) {Studies} in {Newborns}, {Less} {Than} a {Month} {Old}: {A} {Systematic} {Review}},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2018.00371/full},
	urldate = {2018-11-05},
	volume = {12},
	year = {2018},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2018.00371/full},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2018.00371}}

@article{gervain_efficient_2018,
	abstract = {Speech has long been recognized as `special'. Here, we suggest that one of the reasons for speech being special is that our auditory system has evolved to encode it in an efficient, optimal way. The theory of efficient neural coding argues that our perceptual systems have evolved to encode environmental stimuli in the most efficient way. Mathematically, this can be achieved if the optimally efficient codes match the statistics of the signals they represent. Experimental evidence suggests that the auditory code is optimal in this mathematical sense: statistical properties of speech closely match response properties of the cochlea, the auditory nerve, and the auditory cortex. Even more interestingly, these results may be linked to phenomena in auditory and speech perception.},
	author = {Gervain, Judit and Geffen, Maria N.},
	doi = {10.1016/j.tins.2018.09.004},
	file = {Gervain et Geffen - 2018 - Efficient Neural Coding in Auditory and Speech Per.pdf:/Users/Cecile/Zotero/storage/XTZVZQ5C/Gervain et Geffen - 2018 - Efficient Neural Coding in Auditory and Speech Per.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JPQ7V4EJ/S0166223618302467.html:text/html},
	issn = {0166-2236},
	journal = {Trends in Neurosciences},
	keywords = {speech perception, auditory perception, efficient neural coding, information theory},
	month = oct,
	title = {Efficient {Neural} {Coding} in {Auditory} and {Speech} {Perception}},
	url = {http://www.sciencedirect.com/science/article/pii/S0166223618302467},
	urldate = {2018-11-12},
	year = {2018},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223618302467},
	bdsk-url-2 = {https://doi.org/10.1016/j.tins.2018.09.004}}

@article{pena_language_2010,
	abstract = {We tested healthy preterm (born near 28 $\pm$ 2 weeks of gestational age) and full-term infants at various different ages. We compared the two populations on the development of a language acquisition landmark, namely, the ability to distinguish the native language from a rhythmically similar one. This ability is attained 4 months after birth in healthy full-term infants. We measured the induced gamma-band power associated with passive listening to (i) the infants' native language (Spanish), (ii) a rhythmically close language (Italian), and (iii) a rhythmically distant language (Japanese) as a marker of gains in language discrimination. Preterm and full-term infants were matched for neural maturation and duration of exposure to broadcast speech. We found that both full-term and preterm infants only display a response to native speech near 6 months after their term age. Neural maturation seems to constrain advances in speech discrimination at early stages of language acquisition.},
	author = {Pe{\~n}a, Marcela and Pittaluga, Enrica and Mehler, Jacques},
	doi = {10.1073/pnas.0914326107},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LYKIGU6V/Pe{\~n}a et al. - 2010 - Language acquisition in premature and full-term in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/D8JFYLBM/0914326107.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {development, gamma-band oscillations, preterm infant, rhythm, speech},
	language = {en},
	month = jan,
	pages = {200914326},
	pmid = {20133589},
	title = {Language acquisition in premature and full-term infants},
	url = {http://www.pnas.org/content/early/2010/01/22/0914326107},
	urldate = {2018-11-14},
	year = {2010},
	bdsk-url-1 = {http://www.pnas.org/content/early/2010/01/22/0914326107},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0914326107}}

@article{granier-deferre_audition_2011,
	author = {Granier-Deferre, Carolyn and Busnel, Marie-Claire},
	file = {Granier-Deferre et Busnel - 2011 - L'audition pr{\'e}natale, quoi de neuf .pdf:/Users/Cecile/Zotero/storage/GER9A2LB/Granier-Deferre et Busnel - 2011 - L'audition pr{\'e}natale, quoi de neuf .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YZGZYJFH/revue-spirale-2011-3-page-17.html:text/html},
	issn = {1278-4699},
	journal = {Spirale},
	language = {fr},
	month = oct,
	number = {3},
	pages = {17--32},
	title = {L'audition pr{\'e}natale, quoi de neuf ?},
	url = {https://www.cairn.info/revue-spirale-2011-3-page-17.html},
	urldate = {2018-11-19},
	volume = {n$\,^{\circ}$ 59},
	year = {2011},
	bdsk-url-1 = {https://www.cairn.info/revue-spirale-2011-3-page-17.html}}

@article{penn_possible_2018,
	abstract = {The rhythms of speech and the time scales of linguistic units (e.g., syllables) correspond remarkably to cortical oscillations. Previous research has demonstrated that in young adults, the intelligibility of time-compressed speech can be rescued by ``repackaging'' the speech signal through the regular insertion of silent gaps to restore correspondence to the theta oscillator. This experiment tested whether this same phenomenon can be demonstrated in older adults, who show age-related changes in cortical oscillations. The results demonstrated a similar phenomenon for older adults, but that the ``rescue point'' of repackaging is shifted, consistent with a slowing of theta oscillations.},
	author = {Penn, Lana R. and Ayasse, Nicole D. and Wingfield, Arthur and Ghitza, Oded},
	doi = {10.1121/1.5054905},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BFXWH7B7/Penn et al. - 2018 - The possible role of brain rhythms in perceiving f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TMBWZK3V/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = oct,
	number = {4},
	pages = {2088--2094},
	shorttitle = {The possible role of brain rhythms in perceiving fast speech},
	title = {The possible role of brain rhythms in perceiving fast speech: {Evidence} from adult aging},
	url = {https://asa.scitation.org/doi/full/10.1121/1.5054905},
	urldate = {2018-11-19},
	volume = {144},
	year = {2018},
	bdsk-url-1 = {https://asa.scitation.org/doi/full/10.1121/1.5054905},
	bdsk-url-2 = {https://doi.org/10.1121/1.5054905}}

@article{friston_lfp_2015,
	abstract = {*
              A brief treatment of dynamic coordination in terms of predictive coding.
            
            
              *
              Understanding synchronous message passing in terms of hierarchical predictive coding.
            
            
              *
              Characterising cortical gain control with the dynamic causal modelling of neural fields.
            
            
              *
              Characterising pathophysiological oscillations with dynamic causal modelling of neural masses.
            
          
        , This review surveys recent trends in the use of local field potentials---and their non-invasive counterparts---to address the principles of functional brain architectures. In particular, we treat oscillations as the (observable) signature of context-sensitive changes in synaptic efficacy that underlie coordinated dynamics and message-passing in the brain. This rich source of information is now being exploited by various procedures---like dynamic causal modelling---to test hypotheses about neuronal circuits in health and disease. Furthermore, the roles played by neuromodulatory mechanisms can be addressed directly through their effects on oscillatory phenomena. These neuromodulatory or gain control processes are central to many theories of normal brain function (e.g. attention) and the pathophysiology of several neuropsychiatric conditions (e.g. Parkinson's disease).},
	author = {Friston, Karl J and Bastos, Andr{\'e} M and Pinotsis, Dimitris and Litvak, Vladimir},
	doi = {10.1016/j.conb.2014.05.004},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/BEZVT6Z2/Friston et al. - 2015 - LFP and oscillations---what do they tell us.pdf:application/pdf},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	month = apr,
	pages = {1--6},
	pmcid = {PMC4376394},
	pmid = {25079053},
	title = {{LFP} and oscillations---what do they tell us?},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376394/},
	urldate = {2018-11-20},
	volume = {31},
	year = {2015},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376394/},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2014.05.004}}

@article{morillon_asymmetric_2012,
	abstract = {Low-gamma (25-45 Hz) and theta (4-8 Hz) oscillations are proposed to underpin the integration of phonemic and syllabic information, respectively. How these two scales of analysis split functions across hemispheres is unclear. We analyzed cortical responses from an epileptic patient with a rare bilateral electrode implantation (stereotactic EEG) in primary (A1/BA41 and A2/BA42) and association auditory cortices (BA22). Using time-frequency analyses, we confirmed the dominance of a 5-6 Hz theta activity in right and of a low-gamma (25-45 Hz) activity in left primary auditory cortices (A1/A2), during both resting state and syllable processing. We further detected high-theta (7-8 Hz) resting activity in left primary, but also associative auditory regions. In left BA22, its phase correlated with high-gamma induced power. Such a hierarchical relationship across theta and gamma frequency bands (theta/gamma phase-amplitude coupling) could index the process by which the neural code shifts from stimulus feature- to phonological- encoding, and is associated with the transition from evoked to induced power responses. These data suggest that theta and gamma activity in right and left auditory cortices bear different functions. They support a scheme where slow parsing of the acoustic information dominates in right-hemisphere at a syllabic (5-6 Hz) rate, and left auditory cortex exhibits a more complex cascade of oscillations, reflecting the possible extraction of transient acoustic cues at a fast ({\textasciitilde}25-45 Hz) rate, subsequently integrated at a slower, e.g. syllabic one. Slow oscillations could functionally participate to speech processing by structuring gamma activity in left BA22, where abstract percepts emerge.},
	author = {Morillon, Benjamin and Liegeois-Chauvel, Catherine and Arnal, Luc Henri and B{\'e}nar, Christian G. and Giraud, Anne-Lise},
	doi = {10.3389/fpsyg.2012.00248},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RIGNJ5F7/Morillon et al. - 2012 - Asymmetric Function of Theta and Gamma Activity in.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	keywords = {auditory, oscillation, asymmetric sampling, gamma, intra-cortical, theta},
	language = {English},
	shorttitle = {Asymmetric {Function} of {Theta} and {Gamma} {Activity} in {Syllable} {Processing}},
	title = {Asymmetric {Function} of {Theta} and {Gamma} {Activity} in {Syllable} {Processing}: {An} {Intra}-{Cortical} {Study}},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00248/full},
	urldate = {2018-11-22},
	volume = {3},
	year = {2012},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00248/full},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2012.00248}}

@incollection{arnal_temporal_2015,
	author = {Arnal, Luc H. and Poeppel, David and Giraud, Anne-lise},
	booktitle = {Handbook of {Clinical} {Neurology}},
	doi = {10.1016/B978-0-444-62630-1.00005-6},
	file = {Arnal et al. - 2015 - Temporal coding in the auditory cortex.pdf:/Users/Cecile/Zotero/storage/EXRGJIH2/Arnal et al. - 2015 - Temporal coding in the auditory cortex.pdf:application/pdf},
	isbn = {978-0-444-62630-1},
	language = {en},
	pages = {85--98},
	publisher = {Elsevier},
	title = {Temporal coding in the auditory cortex},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444626301000056},
	urldate = {2018-11-22},
	volume = {129},
	year = {2015},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/B9780444626301000056},
	bdsk-url-2 = {https://doi.org/10.1016/B978-0-444-62630-1.00005-6}}

@article{garcia-rosales_neuronal_2018,
	abstract = {Garc{\'\i}a-Rosales et al. identified three distinct neuronal populations within the auditory cortex of awake Carollia perspicillata bats. These neurons responded to different temporal features of communication calls from conspecifics and synchronized to distinct cortical oscillations, suggesting multiscale temporal representation at a cellular level.},
	author = {Garc{\'\i}a-Rosales, Francisco and Beetz, M. Jerome and Cabral-Calderin, Yuranny and K{\"o}ssl, Manfred and Hechavarria, Julio C.},
	copyright = {2018 The Author(s)},
	doi = {10.1038/s42003-018-0205-5},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BL7E9A9S/Garc{\'\i}a-Rosales et al. - 2018 - Neuronal coding of multiscale temporal features in.pdf:application/pdf},
	issn = {2399-3642},
	journal = {Communications Biology},
	language = {en},
	month = nov,
	number = {1},
	pages = {200},
	title = {Neuronal coding of multiscale temporal features in communication sequences within the bat auditory cortex},
	url = {https://www.nature.com/articles/s42003-018-0205-5},
	urldate = {2018-11-26},
	volume = {1},
	year = {2018},
	bdsk-url-1 = {https://www.nature.com/articles/s42003-018-0205-5},
	bdsk-url-2 = {https://doi.org/10.1038/s42003-018-0205-5}}

@article{venezia_hierarchy_2019,
	abstract = {Existing data indicate that cortical speech processing is hierarchically organized. Numerous studies have shown that early auditory areas encode fine acoustic details while later areas encode abstracted speech patterns. However, it remains unclear precisely what speech information is encoded across these hierarchical levels. Estimation of speech-driven spectrotemporal receptive fields (STRFs) provides a means to explore cortical speech processing in terms of acoustic or linguistic information associated with characteristic spectrotemporal patterns. Here, we estimate STRFs from cortical responses to continuous speech in fMRI. Using a novel approach based on filtering randomly-selected spectrotemporal modulations (STMs) from aurally-presented sentences, STRFs were estimated for a group of listeners and categorized using a data-driven clustering algorithm. `Behavioral STRFs' highlighting STMs crucial for speech recognition were derived from intelligibility judgments. Clustering revealed that STRFs in the supratemporal plane represented a broad range of STMs, while STRFs in the lateral temporal lobe represented circumscribed STM patterns important to intelligibility. Detailed analysis recovered a bilateral organization with posterior-lateral regions preferentially processing STMs associated with phonological information and anterior-lateral regions preferentially processing STMs associated with word- and phrase-level information. Regions in lateral Heschl's gyrus preferentially processed STMs associated with vocalic information (pitch).},
	author = {Venezia, Jonathan H. and Thurman, Steven M. and Richards, Virginia M. and Hickok, Gregory},
	doi = {10.1016/j.neuroimage.2018.11.049},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F47ZRPHM/Venezia et al. - 2019 - Hierarchy of speech-driven spectrotemporal recepti.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/B4PD3A4S/S105381191832130X.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {fMRI, Bubbles, Classification images, Spectrotemporal modulations, Speech perception},
	month = feb,
	pages = {647--666},
	title = {Hierarchy of speech-driven spectrotemporal receptive fields in human auditory cortex},
	url = {http://www.sciencedirect.com/science/article/pii/S105381191832130X},
	urldate = {2018-12-03},
	volume = {186},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191832130X},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2018.11.049}}

@article{panzeri_cracking_2017,
	author = {Panzeri, Stefano and Harvey, Christopher D. and Piasini, Eugenio and Latham, Peter E. and Fellin, Tommaso},
	doi = {10.1016/j.neuron.2016.12.036},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RWS3USW2/Panzeri et al. - 2017 - Cracking the Neural Code for Sensory Perception by.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K4N2U4VG/S0896-6273(16)31009-1.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {behavior, information, neural coding, choice, optogenetics, population coding},
	language = {English},
	month = feb,
	number = {3},
	pages = {491--507},
	pmid = {28182905},
	title = {Cracking the {Neural} {Code} for {Sensory} {Perception} by {Combining} {Statistics}, {Intervention}, and {Behavior}},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31009-1},
	urldate = {2019-01-04},
	volume = {93},
	year = {2017},
	bdsk-url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(16)31009-1},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2016.12.036}}

@article{runyan_distinct_2017,
	abstract = {The cortex represents information across widely varying timescales1,2,3,4,5. For instance, sensory cortex encodes stimuli that fluctuate over few tens of milliseconds6,7, whereas in association cortex behavioural choices can require the maintenance of information over seconds8,9. However, it remains poorly understood whether diverse timescales result mostly from features intrinsic to individual neurons or from neuronal population activity. This question remains unanswered, because the timescales of coding in populations of neurons have not been studied extensively, and population codes have not been compared systematically across cortical regions. Here we show that population codes can be essential to achieve long coding timescales. Furthermore, we find that the properties of population codes differ between sensory and association cortices. We compared coding for sensory stimuli and behavioural choices in auditory cortex and posterior parietal cortex as mice performed a sound localization task. Auditory stimulus information was stronger in auditory cortex than in posterior parietal cortex, and both regions contained choice information. Although auditory cortex and posterior parietal cortex coded information by tiling in time neurons that were transiently informative for approximately 200 milliseconds, the areas had major differences in functional coupling between neurons, measured as activity correlations that could not be explained by task events. Coupling among posterior parietal cortex neurons was strong and extended over long time lags, whereas coupling among auditory cortex neurons was weak and short-lived. Stronger coupling in posterior parietal cortex led to a population code with long timescales and a representation of choice that remained consistent for approximately 1 second. In contrast, auditory cortex had a code with rapid fluctuations in stimulus and choice information over hundreds of milliseconds. Our results reveal that population codes differ across cortex and that coupling is a variable property of cortical populations that affects the timescale of information coding and the accuracy of behaviour.},
	author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
	copyright = {2017 Nature Publishing Group},
	doi = {10.1038/nature23020},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CAEV7P2C/Runyan et al. - 2017 - Distinct timescales of population coding across co.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HZVWAW7K/nature23020.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = aug,
	number = {7665},
	pages = {92--96},
	title = {Distinct timescales of population coding across cortex},
	url = {https://www.nature.com/articles/nature23020},
	urldate = {2019-01-04},
	volume = {548},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/nature23020},
	bdsk-url-2 = {https://doi.org/10.1038/nature23020}}

@article{uddin_hearing_2018,
	abstract = {Environmental sounds (ES) can be understood easily when substituted for words in sentences, suggesting that linguistic context benefits may be mediated by processes more general than some language-specific theories assert. However, the underlying neural processing is not understood. EEG was recorded for spoken sentences ending in either a spoken word or a corresponding ES. Endings were either congruent or incongruent with the sentence frame, and thus were expected to produce N400 activity. However, if ES and word meanings are combined with language context by different mechanisms, different N400 responses would be expected. Incongruent endings (both words and ES) elicited frontocentral negativities corresponding to the N400 typically observed to incongruent spoken words. Moreover, sentential constraint had similar effects on N400 topographies to ES and words. Comparison of speech and ES responses suggests that understanding meaning in speech context may be mediated by similar neural mechanisms for these two types of stimuli.},
	author = {Uddin, Sophia and Heald, Shannon L. M. and Van Hedger, Stephen C. and Nusbaum, Howard C.},
	doi = {10.1016/j.bandl.2018.02.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PR5C2WV5/Uddin et al. - 2018 - Hearing sounds as words Neural responses to envir.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/E6GI62AD/S0093934X17303073.html:text/html},
	issn = {0093-934X},
	journal = {Brain and Language},
	keywords = {Event-related potential, Context, N400, Environmental sounds, Language processing, Sentence understanding},
	month = apr,
	pages = {51--61},
	shorttitle = {Hearing sounds as words},
	title = {Hearing sounds as words: {Neural} responses to environmental sounds in the context of fluent speech},
	url = {http://www.sciencedirect.com/science/article/pii/S0093934X17303073},
	urldate = {2018-12-26},
	volume = {179},
	year = {2018},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X17303073},
	bdsk-url-2 = {https://doi.org/10.1016/j.bandl.2018.02.004}}

@article{costafreda_pooling_2009,
	abstract = {The quantitative analysis of pooled data from related fMRI experiments has the potential to significantly accelerate progress in brain mapping. Such data-pooling can be achieved through meta-analysis (the pooled analysis of published results), mega-analysis (the pooled analysis of raw data) or multi-site studies which can be seen as designed mega-analyses. Current limitations in function-location brain mapping and how data-pooling can be used to remediate them are reviewed, with particular attention to power aggregation and mitigation of false positive results. Some recently developed analysis tools for meta- and mega-analysis are also presented, and recommendations for the conduct of valid fMRI data pooling are formulated.},
	author = {Costafreda, Sergi G.},
	doi = {10.3389/neuro.11.033.2009},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4T5ZJ7CZ/Costafreda - 2009 - Pooling fMRI data meta-analysis, mega-analysis an.pdf:application/pdf},
	issn = {1662-5196},
	journal = {Frontiers in Neuroinformatics},
	keywords = {fMRI, false positive results, mega-analysis, Meta-analysis, multi-center studies, power, random effects analysis, Study Design},
	language = {English},
	shorttitle = {Pooling {fMRI} data},
	title = {Pooling {fMRI} data: meta-analysis, mega-analysis and multi-center studies},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.11.033.2009/full},
	urldate = {2019-01-22},
	volume = {3},
	year = {2009},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/neuro.11.033.2009/full},
	bdsk-url-2 = {https://doi.org/10.3389/neuro.11.033.2009}}

@article{kruschke_bayesian_2018,
	abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
	author = {Kruschke, John K. and Liddell, Torrin M.},
	doi = {10.3758/s13423-016-1221-4},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/UAQB2KFE/Kruschke et Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf:application/pdf},
	issn = {1531-5320},
	journal = {Psychonomic Bulletin \& Review},
	keywords = {Meta-analysis, Bayes factor, Bayesian inference, Confidence interval, Credible interval, Effect size, Equivalence testing, Highest density interval, Null hypothesis significance testing, Power analysis, Randomized controlled trial, Region of practical equivalence},
	language = {en},
	month = feb,
	number = {1},
	pages = {178--206},
	shorttitle = {The {Bayesian} {New} {Statistics}},
	title = {The {Bayesian} {New} {Statistics}: {Hypothesis} testing, estimation, meta-analysis, and power analysis from a {Bayesian} perspective},
	url = {https://doi.org/10.3758/s13423-016-1221-4},
	urldate = {2019-01-29},
	volume = {25},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.3758/s13423-016-1221-4}}

@article{mai_sounds_2014,
	abstract = {As one kind of sounds, human voices are important for language acquisition and human-infant relations. Human voices have positive effects on infants, e.g., soothe infants and evoke an infant's smile. Increased left relative to right frontal alpha activity as assessed by the electroencephalogram (EEG) is considered to reflect approach-related emotions. In the present study, we recorded the EEG in thirty-eight 2-month-old infants during a baseline period while listening to sounds, i.e., human voices. Infants displayed increased relative left frontal alpha activity in response to sounds compared to the baseline condition. These results suggest that sounds can elicit relative left frontal activity in young infants, and that this approach-related emotion presents early in life.},
	author = {Mai, Xiaoqin and Xu, Lin and Li, Mingyan and Shao, Jie and Zhao, Zhengyan and Lamm, Connie and Fox, Nathan A. and Nelson, Charles A. and Lozoff, Betsy},
	doi = {10.1016/j.ijpsycho.2014.09.008},
	file = {Version accept{\'e}e:/Users/Cecile/Zotero/storage/VX7HKXBQ/Mai et al. - 2014 - Sounds elicit relative left frontal alpha activity.pdf:application/pdf},
	issn = {1872-7697},
	journal = {International Journal of Psychophysiology: Official Journal of the International Organization of Psychophysiology},
	keywords = {Acoustic Stimulation, Emotions, Female, Frontal Lobe, Functional Laterality, Humans, Infant, Male, Alpha Rhythm, Electroencephalogram (EEG), Frontal lobe, Human voice, Mother-Child Relations},
	language = {eng},
	month = dec,
	number = {3},
	pages = {287--291},
	pmcid = {PMC4339870},
	pmid = {25242501},
	title = {Sounds elicit relative left frontal alpha activity in 2-month-old infants},
	volume = {94},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1016/j.ijpsycho.2014.09.008}}

@article{cristia_responses_2014,
	abstract = {In the adult brain, speech can recruit a brain network that is overlapping with, but not identical to, that involved in perceiving non-linguistic vocalizations. Using the same stimuli that had been presented to human 4-month-olds and adults, as well as adult macaques, we sought to shed light on the cortical networks engaged when human newborns process diverse vocalization types. Near infrared spectroscopy was used to register the response of 40 newborns' perisylvian regions when stimulated with speech, human and macaque emotional vocalizations, as well as auditory controls where the formant structure was destroyed but the long-term spectrum was retained. Left fronto-temporal and parietal regions were significantly activated in the comparison of stimulation versus rest, with unclear selectivity in cortical activation. These results for the newborn brain are qualitatively and quantitatively compared with previous work on newborns, older human infants, adult humans, and adult macaques reported in previous work.},
	author = {Cristia, Alejandrina and Minagawa, Yasuyo and Dupoux, Emmanuel},
	doi = {10.1371/journal.pone.0115162},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NVS7J9ZU/Cristia et al. - 2014 - Responses to Vocalizations and Auditory Controls i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IS3FVFYS/article.html:text/html},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Emotions, Speech, Speech signal processing, Neonates, Vocalization, Adults, Macaque, Monkeys},
	language = {en},
	month = dec,
	number = {12},
	pages = {e115162},
	title = {Responses to {Vocalizations} and {Auditory} {Controls} in the {Human} {Newborn} {Brain}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115162},
	urldate = {2019-02-19},
	volume = {9},
	year = {2014},
	bdsk-url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115162},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0115162}}

@article{vouloumanos_tuned_2004,
	abstract = {Do young infants treat speech as a special signal, compared with structurally similar non-speech sounds? We presented 2- to 7-month-old infants with nonsense speech sounds and complex non-speech analogues. The non-speech analogues retain many of the spectral and temporal properties of the speech signal, including the pitch contour information which is known to be salient to young listeners, and thus provide a stringent test for a potential listening bias for speech. Our results show that infants as young as 2 months of age listened longer to speech sounds. This listening selectivity indicates that early-functioning biases direct infants' attention to speech, granting speech a special status in relation to other sounds.},
	annote = {*},
	author = {Vouloumanos, Athena and Werker, Janet F.},
	date-modified = {2022-04-05 16:59:30 +0200},
	doi = {10.1111/j.1467-7687.2004.00345.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/8L54R3V4/Vouloumanos et Werker - 2004 - Tuned to the signal the privileged status of spee.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6NEE2BYM/j.1467-7687.2004.00345.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	number = {3},
	pages = {270--276},
	shorttitle = {Tuned to the signal},
	title = {Tuned to the signal: the privileged status of speech for young infants},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2004.00345.x},
	urldate = {2019-02-19},
	volume = {7},
	year = {2004},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2004.00345.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-7687.2004.00345.x}}

@article{shultz_three-month-olds_2010,
	abstract = {Human infants show a preference for listening to speech, but little is known about how infants listen to other naturally occurring sounds. Here, we test infants' listening bias for speech against a range of naturally occurring sounds that share properties of speech to varying extents and we aim to better characterize the speech properties that attract infant attention. We compared 3-month-olds' listening patterns for five types of sounds: nonnative speech, rhesus macaque vocalizations, human noncommunicative vocalizations, human communicative nonspeech vocalizations, and environmental sounds. Across three experiments, 3-month-olds preferred speech to the other four types of sounds. The set of acoustic properties we measured---pitch, peak amplitude, nonzero-root mean square amplitude, frequency difference and amplitude variance---did not predict infant looking time. Our results demonstrate that young infants attend selectively to speech over many other naturally occurring stimuli, an important tool for learning language.},
	annote = {*},
	author = {Shultz, Sarah and Vouloumanos, Athena},
	date-modified = {2022-04-05 16:57:34 +0200},
	doi = {10.1080/15475440903507830},
	file = {Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:/Users/Cecile/Zotero/storage/MF96VJHB/Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VA3LY5F3/15475440903507830.html:text/html;Version soumise:/Users/Cecile/Zotero/storage/J525FMXY/Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:application/pdf},
	issn = {1547-5441},
	journal = {Language Learning and Development},
	month = sep,
	number = {4},
	pages = {241--257},
	title = {Three-{Month}-{Olds} {Prefer} {Speech} to {Other} {Naturally} {Occurring} {Signals}},
	url = {https://doi.org/10.1080/15475440903507830},
	urldate = {2019-03-21},
	volume = {6},
	year = {2010},
	bdsk-url-1 = {https://doi.org/10.1080/15475440903507830}}

@article{mcdonald_infant_2019,
	abstract = {Infants are responsive to and show a preference for human vocalizations from very early in development. While previous studies have provided a strong foundation of understanding regarding areas of the infant brain that respond preferentially to social vs. non-social sounds, how the infant brain responds to sounds of varying social significance over time, and how this relates to behavior, is less well understood. The current study uniquely examined longitudinal brain responses to social sounds of differing social-communicative value in infants at 3 and 6 months of age using functional near-infrared spectroscopy (fNIRS). At 3 months, infants showed similar patterns of widespread activation in bilateral temporal cortices to communicative and non-communicative human non-speech vocalizations, while by 6 months infants showed more similar, and focal, responses to social sounds that carried increased social value (infant-directed speech and human non-speech communicative sounds). In addition, we found that brain activity at 3 months of age related to later brain activity and receptive language abilities as measured at 6 months. These findings suggest areas of consistency and change in auditory social perception between 3 and 6 months of age.},
	author = {McDonald, Nicole M. and Perdue, Katherine L. and Eilbott, Jeffrey and Loyal, Jaspreet and Shic, Frederick and Pelphrey, Kevin A.},
	doi = {10.1016/j.dcn.2019.100638},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/83NWVR54/McDonald et al. - 2019 - Infant brain responses to social sounds A longitu.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/IT3ULPGS/S187892931830118X.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Brain development, fNIRS, Auditory stimuli, Infancy, Social perception},
	month = apr,
	pages = {100638},
	shorttitle = {Infant brain responses to social sounds},
	title = {Infant brain responses to social sounds: {A} longitudinal functional near-infrared spectroscopy study},
	url = {http://www.sciencedirect.com/science/article/pii/S187892931830118X},
	urldate = {2019-03-21},
	volume = {36},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S187892931830118X},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2019.100638}}

@article{dehaene-lambertz_neural_2005,
	abstract = {Many people exposed to sinewave analogues of speech first report hearing them as electronic glissando and, later, when they switch into a `speech mode', hearing them as syllables. This perceptual switch modifies their discrimination abilities, enhancing perception of differences that cross phonemic boundaries while diminishing perception of differences within phonemic categories. Using high-density evoked potentials and fMRI in a discrimination paradigm, we studied the changes in brain activity that are related to this change in perception. With ERPs, we observed that phonemic coding is faster than acoustic coding: The electrophysiological mismatch response (MMR) occurred earlier for a phonemic change than for an equivalent acoustic change. The MMR topography was also more asymmetric for a phonemic change than for an acoustic change. In fMRI, activations were also significantly asymmetric, favoring the left hemisphere in both perception modes. Furthermore, switching to the speech mode significantly enhanced activation in the posterior parts of the left superior gyrus and sulcus relative to the non-speech mode. When responses to a change of stimulus were studied, a cluster of voxels in the supramarginal gyrus was activated significantly more by a phonemic change than by an acoustic change. These results demonstrate that phoneme perception in adults relies on a specific and highly efficient left-hemispheric network, which can be activated in top-down fashion when processing ambiguous speech/non-speech stimuli.},
	author = {Dehaene-Lambertz, Ghislaine and Pallier, Christophe and Serniclaes, Willy and Sprenger-Charolles, Liliane and Jobert, Antoinette and Dehaene, Stanislas},
	doi = {10.1016/j.neuroimage.2004.09.039},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JZACHBE6/Dehaene-Lambertz et al. - 2005 - Neural correlates of switching from auditory to sp.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/D39TNUZE/S1053811904005452.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Auditory, ERP, Speech perception, MRI, Non-speech stimuli},
	month = jan,
	number = {1},
	pages = {21--33},
	title = {Neural correlates of switching from auditory to speech perception},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811904005452},
	urldate = {2019-03-27},
	volume = {24},
	year = {2005},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811904005452},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2004.09.039}}

@article{morton_conspec_1991,
	author = {Morton, John and Johnson, Mark H},
	file = {Morton et Johnson - CONSPEC and CONLERN A Two-Process Theory of Infan.pdf:/Users/Cecile/Zotero/storage/NQ3VZVDM/Morton et Johnson - CONSPEC and CONLERN A Two-Process Theory of Infan.pdf:application/pdf},
	journal = {Psychological Review},
	language = {en},
	number = {2},
	pages = {164--181},
	title = {{CONSPEC} and {CONLERN}: {A} {Two}-{Process} {Theory} of {Infant} {Face} {Recognition}},
	volume = {98},
	year = {1991}}

@article{gaucher_cortical_2013,
	abstract = {In all sensory modalities, intracortical inhibition shapes the functional properties of cortical neurons but also influences the responses to natural stimuli. Studies performed in various species have revealed that auditory cortex neurons respond to conspecific vocalizations by temporal spike patterns displaying a high trial-to-trial reliability, which might result from precise timing between excitation and inhibition. Studying the guinea pig auditory cortex, we show that partial blockage of GABAA receptors by gabazine (GBZ) application (10 μm, a concentration that promotes expansion of cortical receptive fields) increased the evoked firing rate and the spike-timing reliability during presentation of communication sounds (conspecific and heterospecific vocalizations), whereas GABAB receptor antagonists [10 μm saclofen; 10--50 μm CGP55845 (p-3-aminopropyl-p-diethoxymethyl phosphoric acid)] had nonsignificant effects. Computing mutual information (MI) from the responses to vocalizations using either the evoked firing rate or the temporal spike patterns revealed that GBZ application increased the MI derived from the activity of single cortical site but did not change the MI derived from population activity. In addition, quantification of information redundancy showed that GBZ significantly increased redundancy at the population level. This result suggests that a potential role of intracortical inhibition is to reduce information redundancy during the processing of natural stimuli.},
	author = {Gaucher, Quentin and Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Edeline, Jean-Marc},
	copyright = {Copyright {\copyright} 2013 the authors 0270-6474/13/3310713-16\$15.00/0},
	doi = {10.1523/JNEUROSCI.0079-13.2013},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/434SN7UY/Gaucher et al. - 2013 - Cortical Inhibition Reduces Information Redundancy.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NN8JDLAQ/10713.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = jun,
	number = {26},
	pages = {10713--10728},
	pmid = {23804094},
	title = {Cortical {Inhibition} {Reduces} {Information} {Redundancy} at {Presentation} of {Communication} {Sounds} in the {Primary} {Auditory} {Cortex}},
	url = {http://www.jneurosci.org/content/33/26/10713},
	urldate = {2019-04-19},
	volume = {33},
	year = {2013},
	bdsk-url-1 = {http://www.jneurosci.org/content/33/26/10713},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.0079-13.2013}}

@article{gaucher_how_2013,
	abstract = {A major goal in auditory neuroscience is to characterize how communication sounds are represented at the cortical level. The present review aims at investigating the role of auditory cortex in the processing of speech, bird songs and other vocalizations, which all are spectrally and temporally highly structured sounds. Whereas earlier studies have simply looked for neurons exhibiting higher firing rates to particular conspecific vocalizations over their modified, artificially synthesized versions, more recent studies determined the coding capacity of temporal spike patterns, which are prominent in primary and non-primary areas (and also in non-auditory cortical areas). In several cases, this information seems to be correlated with the behavioral performance of human or animal subjects, suggesting that spike-timing based coding strategies might set the foundations of our perceptive abilities. Also, it is now clear that the responses of auditory cortex neurons are highly nonlinear and that their responses to natural stimuli cannot be predicted from their responses to artificial stimuli such as moving ripples and broadband noises. Since auditory cortex neurons cannot follow rapid fluctuations of the vocalizations envelope, they only respond at specific time points during communication sounds, which can serve as temporal markers for integrating the temporal and spectral processing taking place at subcortical relays. Thus, the temporal sparse code of auditory cortex neurons can be considered as a first step for generating high level representations of communication sounds independent of the acoustic characteristic of these sounds. This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	author = {Gaucher, Quentin and Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Laudanski, Jonathan and Occelli, Florian and Edeline, Jean-Marc},
	doi = {10.1016/j.heares.2013.03.011},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/SPTXZPCV/S0378595513000920.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = nov,
	pages = {102--112},
	series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	title = {How do auditory cortex neurons represent communication sounds?},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595513000920},
	urldate = {2019-04-19},
	volume = {305},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513000920},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2013.03.011}}

@article{gaucher_how_2012,
	abstract = {Simultaneous recording of multiple neurons, or neuron groups, offers new promise for investigating fundamental questions about the neural code. We used arrays of 16 electrodes in the tonotopic, primary, auditory cortex of guinea pigs and we extracted LFP- and spike-based spectro-temporal receptive fields (STRFs). We confirm here that LFP signals provide broadly tuned activity which lacks frequency resolution compared to multiunit signals and, therefore, lead to large redundancy in neural responses even between recording sites far apart. Thanks to the use of multi-electrode arrays which allows simultaneous recordings, we also focused on functional relationships between neuronal discharges (through cross-correlations) and between LFPs (through coherence). Since the LFP is composed of distinct brain rhythms, the LFP results were split into three frequency bands from the slowest to the fastest components of LFPs. For driven as well as spontaneous activity, we show that components {\textgreater}70Hz in LFPs are much less coherent between recording sites than slower components. In general, coherence between LFPs from two recordings sites is positively correlated with the degree of frequency overlap between the two corresponding STRFs, similar to cross-correlation between multiunit activities. However, coherence is only weakly correlated with cross-correlation in all frequency ranges. Altogether, these results suggest that LFPs reflect global functional connectivity in the thalamocortical auditory system whereas spiking activities reflect more independent local processing.},
	author = {Gaucher, Quentin and Edeline, Jean-Marc and Gour{\'e}vitch, Boris},
	doi = {10.1016/j.jphysparis.2011.09.006},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/QJBACN2K/S0928425711000325.html:text/html},
	issn = {0928-4257},
	journal = {Journal of Physiology-Paris},
	keywords = {Auditory cortex, Coherence, Cross-correlation, LFP, Multi-unit activity, Spectro-temporal receptive field},
	month = may,
	number = {3},
	pages = {93--103},
	series = {Neuronal {Ensemble} {Recordings} in {Integrative} {Neuroscience}},
	shorttitle = {How different are the local field potentials and spiking activities?},
	title = {How different are the local field potentials and spiking activities? {Insights} from multi-electrodes arrays},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425711000325},
	urldate = {2019-04-19},
	volume = {106},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0928425711000325},
	bdsk-url-2 = {https://doi.org/10.1016/j.jphysparis.2011.09.006}}

@article{huetz_neural_2011,
	abstract = {Over the last 15years, an increasing number of studies have described the responsiveness of thalamic and cortical neurons to communication sounds. Whereas initial studies have simply looked for neurons exhibiting higher firing rate to conspecific vocalizations over their modified, artificially synthesized versions, more recent studies determine the relative contribution of ``rate coding'' and ``temporal coding'' to the information transmitted by spike trains. In this article, we aim at reviewing the different strategies employed by thalamic and cortical neurons to encode information about acoustic stimuli, from artificial to natural sounds. Considering data obtained with simple stimuli, we first illustrate that different facets of temporal code, ranging from a strict correspondence between spike-timing and stimulus temporal features to more complex coding strategies, do already exist with artificial stimuli. We then review lines of evidence indicating that spike-timing provides an efficient code for discriminating communication sounds from thalamus, primary and non-primary auditory cortex up to frontal areas. As the neural code probably developed, and became specialized, over evolution to allow precise and reliable processing of sounds that are of survival value, we argue that spike-timing based coding strategies might set the foundations of our perceptive abilities.},
	author = {Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Edeline, Jean-Marc},
	doi = {10.1016/j.heares.2010.01.010},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8PCXJ7TI/S0378595510000237.html:text/html},
	issn = {0378-5955},
	journal = {Hearing Research},
	month = jan,
	number = {1},
	pages = {147--158},
	series = {Auditory {Cortex}: {Current} {Concepts} in {Human} and {Animal} {Research}},
	shorttitle = {Neural codes in the thalamocortical auditory system},
	title = {Neural codes in the thalamocortical auditory system: {From} artificial stimuli to communication sounds},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595510000237},
	urldate = {2019-04-19},
	volume = {271},
	year = {2011},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595510000237},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2010.01.010}}

@article{fulkerson_words_2007,
	abstract = {Recent studies reveal that naming has powerful conceptual consequences within the first year of life. Naming distinct objects with the same word highlights commonalities among the objects and promotes object categorization. In the present experiment, we pursued the origin of this link by examining the influence of words and tones on object categorization in infants at 6 and 12 months. At both ages, infants hearing a novel word for a set of distinct objects successfully formed object categories; those hearing a sequence of tones for the same objects did not. These results support the view that infants are sensitive to powerful and increasingly nuanced links between linguistic and conceptual units very early in the process of lexical acquisition.},
	author = {Fulkerson, Anne L. and Waxman, Sandra R.},
	doi = {10.1016/j.cognition.2006.09.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/W4QZEQUC/Fulkerson et Waxman - 2007 - Words (but not Tones) facilitate object categoriza.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JSVIAAI8/S001002770600196X.html:text/html},
	issn = {0010-0277},
	journal = {Cognition},
	keywords = {Categorization, Infancy, Object naming},
	month = oct,
	number = {1},
	pages = {218--228},
	shorttitle = {Words (but not {Tones}) facilitate object categorization},
	title = {Words (but not {Tones}) facilitate object categorization: {Evidence} from 6- and 12-month-olds},
	url = {http://www.sciencedirect.com/science/article/pii/S001002770600196X},
	urldate = {2019-05-06},
	volume = {105},
	year = {2007},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S001002770600196X},
	bdsk-url-2 = {https://doi.org/10.1016/j.cognition.2006.09.005}}

@article{balaban_words_1997,
	abstract = {Previous research reveals that novel words highlight object categories for preschoolers and infants as young as 12 months. Three experiments extend these findings to 9-month-olds. Infants were familiarized to slides of animals (e.g., rabbits). Infants in theWordcondition heard infant-directed word phrases (``a rabbit'') and infants in theTonecondition heard tones. During familiarization, infants' visual fixation was enhanced on trials with sounds (either words or tones), relative to silent trials. On test trials, a new exemplar from the familiar category (e.g., rabbit) was paired with a novel animal (e.g., pig). Infants in theWordcondition showed greater attention to novelty than those in theTonecondition. A third group of infants who heard content-filtered words responded similarly to infants in theWordcondition. Implications of the facilitative effects of words and content-filtered words on object categorization are discussed within a framework describing infants' emerging appreciation of language over the first year of life.},
	author = {Balaban, Marie T. and Waxman, Sandra R.},
	doi = {10.1006/jecp.1996.2332},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/NJQ9YD4N/Balaban et Waxman - 1997 - Do Words Facilitate Object Categorization in 9-Mon.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MDJ4HRKS/S0022096596923322.html:text/html},
	issn = {0022-0965},
	journal = {Journal of Experimental Child Psychology},
	month = jan,
	number = {1},
	pages = {3--26},
	title = {Do {Words} {Facilitate} {Object} {Categorization} in 9-{Month}-{Old} {Infants}?},
	url = {http://www.sciencedirect.com/science/article/pii/S0022096596923322},
	urldate = {2019-05-06},
	volume = {64},
	year = {1997},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0022096596923322},
	bdsk-url-2 = {https://doi.org/10.1006/jecp.1996.2332}}

@article{ferry_categorization_2010,
	abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	doi = {10.1111/j.1467-8624.2009.01408.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/5LTQDGNY/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/NXRHDH65/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/WX23Q27Y/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/82XHNAUY/j.1467-8624.2009.01408.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/IRBDQHVV/j.1467-8624.2009.01408.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/66LS2LAW/j.1467-8624.2009.01408.html:text/html},
	issn = {1467-8624},
	journal = {Child Development},
	language = {en},
	number = {2},
	pages = {472--479},
	shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	urldate = {2019-05-06},
	volume = {81},
	year = {2010},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{malmierca_pattern-sensitive_2019,
	abstract = {A `pattern alternation paradigm' has been previously used in human ERP recordings to investigate the brain encoding of complex auditory regularities, but prior studies on regularity encoding in animal models to examine mechanisms of adaptation of auditory neuronal responses have used primarily oddball stimulus sequences to study stimulus-specific adaptation alone. In order to examine the sensitivity of neuronal adaptation to expected and unexpected events embedded in a complex sound sequence, we used a similar patterned sequence of sounds. We recorded single unit activity and compared neuronal responses in the rat inferior colliculus (IC) to sound stimuli conforming to pattern alternation regularity with those to stimuli in which occasional sound repetitions violated that alternation. Results show that some neurons in the rat inferior colliculus are sensitive to the history of patterned stimulation and to violations of patterned regularity, demonstrating that there is a population of subcortical neurons, located as early as the level of the midbrain, that can detect more complex stimulus regularities than previously supposed and that are as sensitive to complex statistics as some neurons in primary auditory cortex. Our findings indicate that these pattern-sensitive neurons can extract temporal and spectral regularities between successive acoustic stimuli. This is important because the extraction of regularities from the sound sequences will result in the development of expectancies for future sounds and hence, the present results are compatible with predictive coding models. Our results demonstrate that some collicular neurons, located as early as in the midbrain level, are involved in the generation and shaping of prediction errors in ways not previously considered and thus, the present findings challenge the prevailing view that perceptual organization of sound only emerges at the auditory cortex level.},
	author = {Malmierca, Manuel S. and Ni{\~n}o-Aguill{\'o}n, Blanca E. and Nieto-Diego, Javier and Porteros, {\'A}ngel and P{\'e}rez-Gonz{\'a}lez, David and Escera, Carles},
	doi = {10.1016/j.neuroimage.2018.10.012},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/24ZLSHHX/Malmierca et al. - 2019 - Pattern-sensitive neurons reveal encoding of compl.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZNIRCGAK/S1053811918319712.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {MMN, Auditory midbrain, Pattern alternation paradigm, Predictive coding, Single unit recordings, SSA},
	month = jan,
	pages = {889--900},
	title = {Pattern-sensitive neurons reveal encoding of complex auditory regularities in the rat inferior colliculus},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811918319712},
	urldate = {2019-05-12},
	volume = {184},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811918319712},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2018.10.012}}

@article{boubenec_detecting_2017,
	author = {Boubenec, Yves and Lawlor, Jennifer and G{\'o}rska, Urszula and Shamma, Shihab and Englitz, Bernhard},
	doi = {10.7554/eLife.24910},
	issn = {2050-084X},
	journal = {eLife},
	language = {en},
	month = mar,
	title = {Detecting changes in dynamic and complex acoustic environments},
	url = {https://elifesciences.org/articles/24910},
	urldate = {2019-05-16},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {https://elifesciences.org/articles/24910},
	bdsk-url-2 = {https://doi.org/10.7554/eLife.24910}}

@article{nelken_responses_1999,
	abstract = {Sound-processing strategies that use the highly non-random structure of natural sounds may confer evolutionary advantage to many species. Auditory processing of natural sounds has been studied almost exclusively in the context of species-specific vocalizations1,2,3,4, although these form only a small part of the acoustic biotope5. To study the relationships between properties of natural soundscapes and neuronal processing mechanisms in the auditory system, we analysed sound from a range of different environments. Here we show that for many non-animal sounds and background mixtures of animal sounds, energy in different frequency bands is coherently modulated. Co-modulation of different frequency bands in background noise facilitates the detection of tones in noise by humans, a phenomenon known as co-modulation masking release (CMR)6,7. We show that co-modulation also improves the ability of auditory-cortex neurons to detect tones in noise, and we propose that this property of auditory neurons may underlie behavioural CMR. This correspondence may represent an adaptation of the auditory system for the use of an attribute of natural sounds to facilitate real-world processing tasks.},
	author = {Nelken, Israel and Rotman, Yaron and Yosef, Omer Bar},
	copyright = {1999 Macmillan Magazines Ltd.},
	doi = {10.1038/16456},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LKNM4ADN/Nelken et al. - 1999 - Responses of auditory-cortex neurons to structural.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DRLAN7W7/16456.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {En},
	month = jan,
	number = {6715},
	pages = {154},
	title = {Responses of auditory-cortex neurons to structural features of natural sounds},
	url = {https://www.nature.com/articles/16456},
	urldate = {2019-05-07},
	volume = {397},
	year = {1999},
	bdsk-url-1 = {https://www.nature.com/articles/16456},
	bdsk-url-2 = {https://doi.org/10.1038/16456}}

@article{nelken_encoding_2005,
	abstract = {Neurons can transmit information about sensory stimuli via their firing rate, spike latency, or by the occurrence of complex spike patterns. Identifying which aspects of the neural responses actually encode sensory information remains a fundamental question in neuroscience. Here we compared various approaches for estimating the information transmitted by neurons in auditory cortex in two very different experimental paradigms, one measuring spatial tuning and the other responses to complex natural stimuli. We demonstrate that, in both cases, spike counts and mean response times jointly carry essentially all the available information about the stimuli. Thus, in auditory cortex, whereas spike counts carry only partial information about stimulus identity or location, the additional availability of relatively coarse temporal information is sufficient in order to extract essentially all the sensory information available in the spike discharge pattern, at least for the relatively short stimuli ({\textless} ∼ 100 ms) commonly used in auditory research.},
	author = {Nelken, Israel and Chechik, Gal and Mrsic-Flogel, Thomas D. and King, Andrew J. and Schnupp, Jan W. H.},
	doi = {10.1007/s10827-005-1739-3},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/WRLN849U/Nelken et al. - 2005 - Encoding Stimulus Information by Spike Numbers and.pdf:application/pdf},
	issn = {1573-6873},
	journal = {Journal of Computational Neuroscience},
	keywords = {electrophysiology, auditory cortex, complex sounds, mutual information},
	language = {en},
	month = oct,
	number = {2},
	pages = {199--221},
	title = {Encoding {Stimulus} {Information} by {Spike} {Numbers} and {Mean} {Response} {Time} in {Primary} {Auditory} {Cortex}},
	url = {https://doi.org/10.1007/s10827-005-1739-3},
	urldate = {2019-05-07},
	volume = {19},
	year = {2005},
	bdsk-url-1 = {https://doi.org/10.1007/s10827-005-1739-3}}

@misc{noauthor_responses_nodate,
	file = {Responses of auditory-cortex neurons to structural features of natural sounds | Nature:/Users/Cecile/Zotero/storage/GT2FJ6LT/16456.html:text/html},
	title = {Responses of auditory-cortex neurons to structural features of natural sounds {\textbar} {Nature}},
	url = {https://www.nature.com/articles/16456},
	urldate = {2019-05-07},
	bdsk-url-1 = {https://www.nature.com/articles/16456}}

@article{pick_reproducible_2019,
	abstract = {Research synthesis, such as comparative and meta-analyses, requires the extraction of effect sizes from primary literature, which are commonly calculated from descriptive statistics. However, the exact values of such statistics are commonly hidden in figures. Extracting descriptive statistics from figures can be a slow process that is not easily reproducible. Additionally, current software lacks an ability to incorporate important metadata (e.g. sample sizes, treatment/variable names) about experiments and is not integrated with other software to streamline analysis pipelines. Here we present the r package metaDigitise which extracts descriptive statistics such as means, standard deviations and correlations from four plot types: (a) mean/error plots (e.g. bar graphs with standard errors), (b) box plots, (c) scatter plots and (d) histograms. metaDigitise is user-friendly and easy to learn as it interactively guides the user through the data extraction process. Notably, it enables large-scale extraction by automatically loading image files, letting the user stop processing, edit and add to the resulting data-frame at any point. Digitised data can be easily re-plotted and checked, facilitating reproducible data extraction from plots with little inter-observer bias. We hope that by making the process of figure extraction more flexible and easy to conduct, it will improve the transparency and quality of meta-analyses in the future.},
	author = {Pick, Joel L. and Nakagawa, Shinichi and Noble, Daniel W. A.},
	copyright = {{\copyright} 2018 The Authors. Methods in Ecology and Evolution {\copyright} 2018 British Ecological Society},
	doi = {10.1111/2041-210X.13118},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/AGSJPTMB/Pick et al. - 2019 - Reproducible, flexible and high-throughput data ex.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/A6LE77F8/2041-210X.html:text/html},
	issn = {2041-210X},
	journal = {Methods in Ecology and Evolution},
	keywords = {comparative analysis, data extraction, descriptive statistics, figures, images, meta-analysis, r, reproducibility},
	language = {en},
	number = {3},
	pages = {426--431},
	shorttitle = {Reproducible, flexible and high-throughput data extraction from primary literature},
	title = {Reproducible, flexible and high-throughput data extraction from primary literature: {The} {metaDigitise} r package},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13118},
	urldate = {2019-05-23},
	volume = {10},
	year = {2019},
	bdsk-url-1 = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13118},
	bdsk-url-2 = {https://doi.org/10.1111/2041-210X.13118}}

@article{moher_preferred_2009,
	author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G. and Group, The PRISMA},
	doi = {10.1371/journal.pmed.1000097},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/HFCYZPFE/Moher et al. - 2009 - Preferred Reporting Items for Systematic Reviews a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YWHNN3VJ/article.html:text/html},
	issn = {1549-1676},
	journal = {PLOS Medicine},
	keywords = {Systematic reviews, Meta-analysis, Clinical research design, Database searching, Medical journals, Publication ethics, Research quality assessment, Research reporting guidelines},
	language = {en},
	month = jul,
	number = {7},
	pages = {e1000097},
	shorttitle = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}},
	title = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}: {The} {PRISMA} {Statement}},
	url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000097},
	urldate = {2019-06-19},
	volume = {6},
	year = {2009},
	bdsk-url-1 = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000097},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pmed.1000097}}

@article{clemens_connecting_2015,
	abstract = {Summary
Brains are optimized for processing ethologically relevant sensory signals. However, few studies have characterized the neural coding mechanisms that underlie the transformation from natural sensory information to behavior. Here, we focus on acoustic communication in Drosophila melanogaster and use computational modeling to link natural courtship song, neuronal codes, and female behavioral responses to song. We show that melanogaster females are sensitive to long timescale song structure (on the order of tens of seconds). From intracellular recordings, we generate models that recapitulate neural responses to acoustic stimuli. We link these neural codes with female behavior by generating model neural responses to natural courtship song. Using a simple decoder, we predict female behavioral responses to the same song stimuli with high accuracy. Our modeling approach reveals how long timescale song features are represented by the Drosophila brain and how neural representations can be decoded to generate behavioral selectivity for acoustic communication signals.},
	author = {Clemens, Jan and Girardin, Cyrille C. and Coen, Philip and Guan, Xiao-Juan and Dickson, Barry J. and Murthy, Mala},
	doi = {10.1016/j.neuron.2015.08.014},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KWXYQIQ7/Clemens et al. - 2015 - Connecting Neural Codes with Behavior in the Audit.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7CVJW8VH/S0896627315007084.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = sep,
	number = {6},
	pages = {1332--1343},
	title = {Connecting {Neural} {Codes} with {Behavior} in the {Auditory} {System} of {Drosophila}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627315007084},
	urldate = {2019-07-05},
	volume = {87},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627315007084},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2015.08.014}}

@phdthesis{vouloumanos_is_2004,
	abstract = {Language is a uniquely human adaptation that is hypothesised to require specialised anatomical substrates and dedicated processing mechanisms. Speech, the primary medium for language, is argued to rely on specialised substrates and processing as well. Yet, to date, evidence for the speech specialisation hypothesis has been equivocal. The four experiments in this thesis aim to advance the discussion in two ways. The differential processing of speech by humans was investigated through the use of functional neuroimaging tools (Experiment One), and through developmental studies of young infants' listening biases (Experiments Two-Four). In Experiment One, functional neuroimaging tools are used to investigate the specificity of neural substrates recruited in detecting speech compared with closely matched non-speech controls. This study takes advantage of an event-related imaging design that provides a narrow window of observation for neural recruitment during individual stimulus events. The results of the first study demonstrate that adults activate specific neural substrates when detecting speech sounds, indicating that specialised substrates are involved from the early processing stages. Experiments Two through Four take an ethological approach to speech specialisation and investigate whether young infants show a bias for listening to speech as compared to matched non-speech sounds. In Experiment Two, behavioural methods probe whether young infants of 2 to 7 months show listening preferences for speech compared with non-speech. Experiment Three seeks to establish the roots of a speech bias in the neonatal period. Finally, Experiment Four investigates the origin of the bias, to determine whether the speech bias originates from prenatal experience, or is independent of specific experience. The results of these studies show that differential processing has its roots in early infancy, with infants demonstrating a preference for listening to speech from birth. The speech bias shown by neonates appears not to be based on specific experience with speech sounds, but instead is rooted in human biology. Human infants are prewired to preferentially attend to speech, granting speech a special status in relation to other sounds.},
	author = {Vouloumanos, Athena},
	doi = {10.14288/1.0091926},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/J92J6MZ4/Vouloumanos - 2004 - Is speech special insights from neonates and ne.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2G6B4RNS/1.html:text/html},
	language = {eng},
	school = {University of British Columbia},
	shorttitle = {Is speech special?},
	title = {Is speech special? : insights from neonates and neuroimaging},
	url = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/831/items/1.0091926},
	urldate = {2019-07-05},
	year = {2004},
	bdsk-url-1 = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/831/items/1.0091926},
	bdsk-url-2 = {https://doi.org/10.14288/1.0091926}}

@inproceedings{black_quantifying_2017,
	abstract = {Author: Black, Alexis et al.; Genre: Conference Paper; Published in Print: 2017; Open Access; Title: Quantifying infants\&apos; statistical word segmentation: A meta-analysis},
	author = {Black, Alexis and Bergmann, Christina},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KAIAH7W7/Black et Bergmann - 2017 - Quantifying infants' statistical word segmentation.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5R7Z6Q9K/ViewItemOverviewPage.html:text/html},
	language = {eng},
	pages = {124--129},
	publisher = {Cognitive Science Society},
	shorttitle = {Quantifying infants' statistical word segmentation},
	title = {Quantifying infants' statistical word segmentation: {A} meta-analysis},
	url = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2475527},
	urldate = {2019-07-05},
	year = {2017},
	bdsk-url-1 = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2475527}}

@article{bergmann_promoting_2018,
	abstract = {Previous work suggests that key factors for replicability, a necessary feature for theory building, include statistical power and appropriate research planning. These factors are examined by analyzing a collection of 12 standardized meta-analyses on language development between birth and 5 years. With a median effect size of Cohen's d = .45 and typical sample size of 18 participants, most research is underpowered (range = 6\%--99\%; median = 44\%); and calculating power based on seminal publications is not a suitable strategy. Method choice can be improved, as shown in analyses on exclusion rates and effect size as a function of method. The article ends with a discussion on how to increase replicability in both language acquisition studies specifically and developmental research more generally.},
	author = {Bergmann, Christina and Tsuji, Sho and Piccinini, Page E. and Lewis, Molly L. and Braginsky, Mika and Frank, Michael C. and Cristia, Alejandrina},
	copyright = {{\copyright} 2018 The Authors. Child Development published by Wiley Periodicals, Inc. on behalf of Society for Research in Child Development},
	doi = {10.1111/cdev.13079},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4MFMRSHS/Bergmann et al. - 2018 - Promoting Replicability in Developmental Research .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PRNFGCN8/cdev.html:text/html},
	issn = {1467-8624},
	journal = {Child Development},
	language = {en},
	number = {6},
	pages = {1996--2009},
	shorttitle = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses},
	title = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses: {Insights} {From} {Language} {Acquisition} {Research}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13079},
	urldate = {2019-07-05},
	volume = {89},
	year = {2018},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13079},
	bdsk-url-2 = {https://doi.org/10.1111/cdev.13079}}

@article{oakes_sample_2017,
	abstract = {Infant research is hard. It is difficult, expensive, and time-consuming to identify, recruit, and test infants. As a result, ours is a field of small sample sizes. Many studies using infant looking time as a measure have samples of 8--12 infants per cell, and studies with more than 24 infants per cell are uncommon. This paper examines the effect of such sample sizes on statistical power and the conclusions drawn from infant looking-time research. An examination of the state of the current literature suggests that most published looking-time studies have low power, which leads in the long run to an increase in both false positive and false negative results. Three data sets with relatively large samples ({\textgreater}30 infants) were used to simulate experiments with smaller sample sizes; 1,000 random subsamples of 8, 12, 16, 20, and 24 infants from the overall samples were selected, making it possible to examine the systematic effect of sample size on the results. This approach revealed that despite clear results with the original large samples, the results with smaller subsamples were highly variable, yielding both false positive and false negative outcomes. Finally, a number of emerging possible solutions are discussed.},
	author = {Oakes, Lisa M.},
	copyright = {Copyright {\copyright} International Congress of Infant Studies (ICIS)},
	doi = {10.1111/infa.12186},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BTRW72W4/Oakes - 2017 - Sample Size, Statistical Power, and False Conclusi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8I3TME8W/infa.html:text/html},
	issn = {1532-7078},
	journal = {Infancy},
	language = {en},
	number = {4},
	pages = {436--469},
	title = {Sample {Size}, {Statistical} {Power}, and {False} {Conclusions} in {Infant} {Looking}-{Time} {Research}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12186},
	urldate = {2019-07-05},
	volume = {22},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12186},
	bdsk-url-2 = {https://doi.org/10.1111/infa.12186}}

@article{van_den_heuvel_differences_2015,
	abstract = {Infant auditory event-related potentials (AERPs) show a series of marked changes during the first year of life. These AERP changes indicate important advances in early development. The current study examined AERP differences between 2- and 4-month-old infants. An auditory oddball paradigm was delivered to infants with a frequent repetitive tone and three rare auditory events. The three rare events included a shorter than the regular inter-stimulus interval (ISI-deviant), white noise segments, and environmental sounds. The results suggest that the N250 infantile AERP component emerges during this period in response to white noise but not to environmental sounds, possibly indicating a developmental step towards separating acoustic deviance from contextual novelty. The scalp distribution of the AERP response to both the white noise and the environmental sounds shifted towards frontal areas and AERP peak latencies were overall lower in infants at 4 than at 2months of age. These observations indicate improvements in the speed of sound processing and maturation of the frontal attentional network in infants during this period.},
	author = {van den Heuvel, Marion I. and Otte, Ren{\'e}e A. and Braeken, Marijke A. K. A. and Winkler, Istv{\'a}n and Kushnerenko, Elena and Van den Bergh, Bea R. H.},
	doi = {10.1016/j.ijpsycho.2015.04.003},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RJMJCT93/S0167876015001518.html:text/html},
	issn = {0167-8760},
	journal = {International Journal of Psychophysiology},
	keywords = {Auditory event-related potential, Infancy, Auditory attention, Cognitive development, Oddball paradigm},
	month = jul,
	number = {1},
	pages = {75--83},
	title = {Differences between human auditory event-related potentials ({AERPs}) measured at 2 and 4months after birth},
	url = {http://www.sciencedirect.com/science/article/pii/S0167876015001518},
	urldate = {2019-07-09},
	volume = {97},
	year = {2015},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0167876015001518},
	bdsk-url-2 = {https://doi.org/10.1016/j.ijpsycho.2015.04.003}}

@article{cohen_plasticity_2015,
	abstract = {Maternal behavior can be triggered by auditory and olfactory cues originating from the newborn. Here we report how the transition to motherhood affects excitatory and inhibitory neurons in layer 2/3 (L2/3) of the mouse primary auditory cortex. We used in vivo two-photon targeted cell-attached recording to compare the response properties of parvalbumin-expressing neurons (PVNs) and pyramidal glutamatergic neurons (PyrNs). The transition to motherhood shifts the average best frequency of PVNs to higher frequency by a full octave, with no significant effect on average best frequency of PyrNs. The presence of pup odors significantly reduced the spontaneous and evoked activity of PVN. This reduction of feedforward inhibition coincides with a complimentary increase in spontaneous and evoked activity of PyrNs. The selective shift of PVN frequency tuning should render pup odor-induced disinhibition more effective for high-frequency stimuli, such as ultrasonic vocalizations. Indeed, pup odors increased neuronal responses of PyrNs to pup ultrasonic vocalizations. We conclude that plasticity in the mothers is mediated, at least in part, via modulation of the feedforward inhibition circuitry in the auditory cortex.},
	author = {Cohen, Lior and Mizrahi, Adi},
	copyright = {Copyright {\copyright} 2015 the authors 0270-6474/15/351806-10\$15.00/0},
	doi = {10.1523/JNEUROSCI.1786-14.2015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CUGZF64N/Cohen et Mizrahi - 2015 - Plasticity during Motherhood Changes in Excitator.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RXWR6MJG/1806.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {feed-forward inhibition, motherhood, pup odors, ultrasonic vocalizations},
	language = {en},
	month = jan,
	number = {4},
	pages = {1806--1815},
	pmid = {25632153},
	shorttitle = {Plasticity during {Motherhood}},
	title = {Plasticity during {Motherhood}: {Changes} in {Excitatory} and {Inhibitory} {Layer} 2/3 {Neurons} in {Auditory} {Cortex}},
	url = {https://www.jneurosci.org/content/35/4/1806},
	urldate = {2019-07-13},
	volume = {35},
	year = {2015},
	bdsk-url-1 = {https://www.jneurosci.org/content/35/4/1806},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1786-14.2015}}

@article{de_cheveigne_filters:_2019,
	abstract = {Filters are commonly used to reduce noise and improve data quality. Filter theory is part of a scientist's training, yet the impact of filters on interpreting data is not always fully appreciated. This paper reviews the issue and explains what a filter is, what problems are to be expected when using them, how to choose the right filter, and how to avoid filtering by using alternative tools. Time-frequency analysis shares some of the same problems that filters have, particularly in the case of wavelet transforms. We recommend reporting filter characteristics with sufficient details, including a plot of the impulse or step response as an inset.},
	author = {de Cheveign{\'e}, Alain and Nelken, Israel},
	doi = {10.1016/j.neuron.2019.02.039},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IRDHRTHG/de Cheveign{\'e} et Nelken - 2019 - Filters When, Why, and How (Not) to Use Them.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C3TUFTB6/S0896627319301746.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {oscillations, Fourier analysis, causality, distortions, filter, impulse response, ringing, time-frequency representation},
	month = apr,
	number = {2},
	pages = {280--293},
	shorttitle = {Filters},
	title = {Filters: {When}, {Why}, and {How} ({Not}) to {Use} {Them}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627319301746},
	urldate = {2019-07-23},
	volume = {102},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627319301746},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2019.02.039}}

@article{viechtbauer_conducting_2010,
	author = {Viechtbauer, Wolfgang},
	copyright = {Copyright (c) 2009 Wolfgang Viechtbauer},
	doi = {10.18637/jss.v036.i03},
	file = {Snapshot:/Users/Cecile/Zotero/storage/VPZQ95KL/v036i03.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/7PPLFC92/Viechtbauer - 2010 - Conducting Meta-Analyses in R with the metafor Pac.pdf:application/pdf},
	issn = {1548-7660},
	journal = {Journal of Statistical Software},
	language = {en},
	month = aug,
	number = {1},
	pages = {1--48},
	title = {Conducting {Meta}-{Analyses} in {R} with the metafor {Package}},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v036i03},
	urldate = {2019-07-24},
	volume = {36},
	year = {2010},
	bdsk-url-1 = {https://www.jstatsoft.org/index.php/jss/article/view/v036i03},
	bdsk-url-2 = {https://doi.org/10.18637/jss.v036.i03}}

@article{duval_trim_2000,
	abstract = {Summary. We study recently developed nonparametric methods for estimating the number of missing studies that might exist in a meta-analysis and the effect that these studies might have had on its outcome. These are simple rank-based data augmentation techniques, which formalize the use of funnel plots. We show that they provide effective and relatively powerful tests for evaluating the existence of such publication bias. After adjusting for missing studies, we find that the point estimate of the overall effect size is approximately correct and coverage of the effect size confidence intervals is substantially improved, in many cases recovering the nominal confidence levels entirely. We illustrate the trim and fill method on existing meta-analyses of studies in clinical trials and psychometrics.},
	author = {Duval, Sue and Tweedie, Richard},
	doi = {10.1111/j.0006-341X.2000.00455.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BHXY9THQ/Duval et Tweedie - 2000 - Trim and Fill A Simple Funnel-Plot--Based Method o.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WZ52ULAI/j.0006-341X.2000.00455.html:text/html},
	issn = {1541-0420},
	journal = {Biometrics},
	keywords = {Meta-analysis, Data augmentation, File drawer problem, Funnel plots, IQ, Malaria, Missing studies, Publication bias},
	language = {en},
	number = {2},
	pages = {455--463},
	shorttitle = {Trim and {Fill}},
	title = {Trim and {Fill}: {A} {Simple} {Funnel}-{Plot}--{Based} {Method} of {Testing} and {Adjusting} for {Publication} {Bias} in {Meta}-{Analysis}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00455.x},
	urldate = {2019-07-24},
	volume = {56},
	year = {2000},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00455.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.0006-341X.2000.00455.x}}

@article{anonymous_infant_2019,
	author = {Anonymous},
	file = {DEV-2019-2627_R1_reviewer.pdf:/Users/Cecile/Zotero/storage/GSI6HXZP/DEV-2019-2627_R1_reviewer.pdf:application/pdf},
	journal = {Personal communication},
	month = apr,
	title = {Infant biases for detecting speech in complex scenes},
	year = {2019}}

@article{sorcinelli_preference_2019,
	abstract = {Early emerging biases for conspecific vocalizations are a hallmark of early development. Typically developing neonates listen to speech more than many other sounds, including non-biological non-speech sounds, but listen equally to speech and monkey calls. By 3 months of age, however, infants prefer speech over both non-biological non-speech sounds and monkey calls. We examined whether different listening preferences continue to develop along different developmental trajectories and whether listening preferences are related to developmental outcomes. Given the static preference for speech over non-biological non-speech sounds and the dynamic preference for speech over monkey calls between birth and 3 months, we examined whether 9-month-olds prefer speech over non-biological non-speech sounds (Experiment 1) and prefer speech over monkey calls (Experiment 2). We compared preferences for sounds in infants at low risk (SIBS-TD) and infants at high risk (SIBS-A) of autism spectrum disorder (ASD), a heterogeneous population who differ from typically developing infants in their preferences for speech, and examined whether listening preferences predict vocabulary and autism-like behaviors at 12 months for both groups. At 9 months, SIBS-TD listened longer to speech than to non-speech sounds and listened longer to monkey calls than to speech, whereas SIBS-A listened longer to speech than to non-speech sounds but listened equally to speech and monkey calls. SIBS-TD's preferences did not predict immediate developmental outcomes. In contrast, SIBS-A who preferred speech over non-speech or monkey calls had larger vocabularies and fewer markers of autism-like behaviors at 12 months, which could have positive developmental implications.},
	annote = {*},
	author = {Sorcinelli, Andrea and Ference, Jennifer and Curtin, Suzanne and Vouloumanos, Athena},
	date-modified = {2022-04-05 16:53:42 +0200},
	doi = {10.1016/j.jecp.2018.09.011},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/EVKNDHCV/Shultz et al. - 2014 - Neural specialization for speech in the first mont.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H92S6GRK/S0022096518302285.html:text/html;Sorcinelli et al. - 2019 - Preference for speech in infancy differentially pr.pdf:/Users/Cecile/Zotero/storage/IHYYMDBJ/Sorcinelli et al. - 2019 - Preference for speech in infancy differentially pr.pdf:application/pdf},
	issn = {0022-0965},
	journal = {Journal of Experimental Child Psychology},
	keywords = {Autism spectrum disorder, Language development, Conspecifics, High-risk infant siblings, Social development, Speech perception and bias},
	month = feb,
	pages = {295--316},
	title = {Preference for speech in infancy differentially predicts language skills and autism-like behaviors},
	url = {http://www.sciencedirect.com/science/article/pii/S0022096518302285},
	urldate = {2019-07-25},
	volume = {178},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0022096518302285},
	bdsk-url-2 = {https://doi.org/10.1016/j.jecp.2018.09.011}}

@article{lieder_perceptual_2019,
	abstract = {Lieder et al show that individuals with dyslexia and individuals with ASD rely mostly on recent and earlier perceptual information, respectively, during perceptual tasks. This may explain the unique difficulties associated with the two conditions.},
	author = {Lieder, Itay and Adam, Vincent and Frenkel, Or and Jaffe-Dax, Sagi and Sahani, Maneesh and Ahissar, Merav},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	doi = {10.1038/s41593-018-0308-9},
	file = {Snapshot:/Users/Cecile/Zotero/storage/LGS3XISI/s41593-018-0308-9.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = feb,
	number = {2},
	pages = {256--264},
	title = {Perceptual bias reveals slow-updating in autism and fast-forgetting in dyslexia},
	url = {https://www.nature.com/articles/s41593-018-0308-9},
	urldate = {2019-07-31},
	volume = {22},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41593-018-0308-9},
	bdsk-url-2 = {https://doi.org/10.1038/s41593-018-0308-9}}

@article{bartha-doering_absence_2019,
	abstract = {Children born preterm are at higher risk to develop language deficits. Auditory speech discrimination deficits may be early signs for language developmental problems. The present study used functional near-infrared spectroscopy to investigate neural speech discrimination in 15 preterm infants at term-equivalent age compared to 15 full term neonates. The full term group revealed a significantly greater hemodynamic response to forward compared to backward speech within the left hemisphere extending from superior temporal to inferior parietal and middle and inferior frontal areas. In contrast, the preterm group did not show differences in their hemodynamic responses during forward versus backward speech, thus, they did not discriminate speech from non-speech. Groups differed significantly in their response to forward speech, whereas they did not differ in their responses to backward speech. The significant differences between groups point to an altered development of the functional network underlying language acquisition in preterm infants as early as in term-equivalent age.},
	author = {Bartha-Doering, Lisa and Alexopoulos, Johanna and Giordano, Vito and Stelzer, Lisa and Kainz, Theresa and Benavides-Varela, Silvia and Wartenburger, Isabell and Klebermass-Schrehof, Katrin and Olischar, Monika and Seidl, Rainer and Berger, Angelika},
	doi = {10.1016/j.dcn.2019.100679},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/V4AWY4S3/Bartha-Doering et al. - 2019 - Absence of Neural Speech Discrimination in Preterm.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3VUS7R28/S1878929319300301.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Newborn infants, Near-infrared spectroscopy, Language development, Preterm birth, Speech discrimination},
	month = jul,
	pages = {100679},
	title = {Absence of {Neural} {Speech} {Discrimination} in {Preterm} {Infants} at {Term}-{Equivalent} {Age}},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929319300301},
	urldate = {2019-08-07},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929319300301},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2019.100679}}

@article{picton_human_1978,
	abstract = {In response to a sustained toneburst a negative baseline shift can be recorded from the human fronto-central scalp regions with an onset latency of approximately 150 msec. This auditory sustained potential is distinct both in its scalp distribution and in its stimulus relationships from the transient response occurring at the onset or offset of the toneburst. It differs from the contingent negative variation in that it can occur in the absence of attention or during sleep. Attention to the auditory stimulus can increase the amplitude of the sustained potential, possibly through the addition of an extra negative potential related to auditory expectancy or uncertainty.
R{\'e}sum{\'e}
En r{\'e}ponse {\`a} une bouff{\'e}e de sons prolong{\'e}e, une d{\'e}flection n{\'e}gative de la ligne de base peut {\^e}tre enregistr{\'e}e sur les r{\'e}gions fronto-centrales du scalp chez l'homme avec une latence de d{\'e}but d'environ 150 msec. Ce potentiel auditif prolong{\'e} est diff{\'e}rent dans sa distribution sur le scalp et dans ses relations au stimulus, des r{\'e}ponses transitoires survenat au d{\'e}but et {\`a} la fin de la bouff{\'e}e de sons. Il diff{\`e}re de la variation contigente n{\'e}gative en ce qu'il peut survenir en l'absence d'attention ou au cours du sommeil. L'attention au stimulus auditif peut augmenter l'amplitude de ce potentiel de longue dur{\'e}e peut-{\^e}tre du fait de l'addition d'un potentiel n{\'e}gatif suppl{\'e}mentaire li{\'e} {\`a} l'attente auditive ou {\`a} l'incertitude.},
	author = {Picton, T. W and Woods, D. L and Proulx, G. B},
	doi = {10.1016/0013-4694(78)90003-2},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/CTEB4TVM/Picton et al. - 1978 - Human auditory sustained potentials. I. The nature.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XEV7QC74/0013469478900032.html:text/html},
	issn = {0013-4694},
	journal = {Electroencephalography and Clinical Neurophysiology},
	month = aug,
	number = {2},
	pages = {186--197},
	title = {Human auditory sustained potentials. {I}. {The} nature of the response},
	url = {http://www.sciencedirect.com/science/article/pii/0013469478900032},
	urldate = {2019-08-06},
	volume = {45},
	year = {1978},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0013469478900032},
	bdsk-url-2 = {https://doi.org/10.1016/0013-4694(78)90003-2}}

@article{lopesdasilva_eeg_2013,
	abstract = {To understand dynamic cognitive processes, the high time resolution of EEG/MEG is invaluable. EEG/MEG signals can play an important role in providing measures of functional and effective connectivity in the brain. After a brief description of the foundations and basic methodological aspects of EEG/MEG signals, the relevance of the signals to obtain novel insights into the neuronal mechanisms underlying cognitive processes is surveyed, with emphasis on neuronal oscillations (ultra-slow, theta, alpha, beta, gamma, and HFOs) and combinations of oscillations. Three main functional roles of brain oscillations are put in evidence: (1) coding specific information, (2) setting and modulating brain attentional states, and (3) assuring the communication between neuronal populations such that specific dynamic workspaces may be created. The latter form the material core of cognitive functions.},
	author = {Lopes da Silva, Fernando},
	doi = {10.1016/j.neuron.2013.10.017},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/42U6LPAH/Lopes da Silva - 2013 - EEG and MEG Relevance to Neuroscience.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/J6I5AIB3/S0896627313009203.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	month = dec,
	number = {5},
	pages = {1112--1128},
	shorttitle = {{EEG} and {MEG}},
	title = {{EEG} and {MEG}: {Relevance} to {Neuroscience}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627313009203},
	urldate = {2019-08-06},
	volume = {80},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313009203},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2013.10.017}}

@article{moore_emergent_2019,
	abstract = {Like humans, songbirds learn to communicate vocally early in life. Moore and Woolley taught birds the songs of a different species to identify how vocal experience and auditory tuning mechanisms create neural representations of communication sounds.},
	author = {Moore, Jordan M. and Woolley, Sarah M. N.},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	doi = {10.1038/s41593-019-0458-4},
	file = {Moore et Woolley - 2019 - Emergent tuning for learned vocalizations in audit.pdf:/Users/Cecile/Zotero/storage/JPBXHA2E/Moore et Woolley - 2019 - Emergent tuning for learned vocalizations in audit.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Z2DALUF7/s41593-019-0458-4.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = aug,
	pages = {1--8},
	title = {Emergent tuning for learned vocalizations in auditory cortex},
	url = {https://www.nature.com/articles/s41593-019-0458-4},
	urldate = {2019-08-17},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41593-019-0458-4},
	bdsk-url-2 = {https://doi.org/10.1038/s41593-019-0458-4}}

@article{legendre_sleepers_2019,
	abstract = {Why do we continue processing external events during sleep, yet remain unresponsive? Legendre et al. use electroencephalography to show that sleepers enter a `standby mode', continuing to track relevant signals but doing so transiently.},
	author = {Legendre, Guillaume and Andrillon, Thomas and Koroma, Matthieu and Kouider, Sid},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	doi = {10.1038/s41562-018-0502-5},
	file = {Legendre et al. - 2019 - Sleepers track informative speech in a multitalker.pdf:/Users/Cecile/Zotero/storage/3ETVR59X/Legendre et al. - 2019 - Sleepers track informative speech in a multitalker.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UZIQJZC6/s41562-018-0502-5.html:text/html},
	issn = {2397-3374},
	journal = {Nature Human Behaviour},
	language = {en},
	month = mar,
	number = {3},
	pages = {274--283},
	title = {Sleepers track informative speech in a multitalker environment},
	url = {https://www.nature.com/articles/s41562-018-0502-5},
	urldate = {2019-08-23},
	volume = {3},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41562-018-0502-5},
	bdsk-url-2 = {https://doi.org/10.1038/s41562-018-0502-5}}

@article{mcnamara_spontaneous_2002,
	abstract = {The infant arousal response involves subcortical and cortical responses occurring as a sequence of stereotyped behaviour regardless of the eliciting stimulus. The spontaneous activity of these responses during sleep, however, is uncertain. We examined the spontaneous arousal pattern in normal infants to determine the sequence of responses, and to examine their periodicity and the effects of sleep state. We performed a nap polysomnographic study on 10 normal infants between 2 and 10 weeks of age. Electroencephalographic and electro-oculographic activity, and respiratory airflow and movements were measured, and video recordings were made throughout each study. Different levels of arousal behaviour were examined. We found that spontaneous arousal activity occurred frequently and the majority of responses occurred as a sequence involving an augmented breath followed by a startle and then cortical arousal. Subcortical arousals as reflected by augmented breaths and startles were more common than cortical arousals. Additionally, augmented breaths followed by apnoea were recorded and were not usually associated with other arousal responses. All of the responses occurred periodically either as bursts of activity or as isolated responses. Each of the responses occurred more frequently during rapid eye movement (REM) sleep than during non-rapid eye movement (NREM) sleep. We conclude that there is an endogenous rhythm of spontaneous activity in infants involving excitatory processes from the brainstem, which may or may not be closely followed by cortical excitation. The spontaneous arousal responses occur periodically but with a high level of irregularity and the level of activity is affected by sleep state.},
	author = {McNamara, Frances and Lijowska, Anna S. and Thach, Bradley T.},
	copyright = {{\copyright} 2002 The Journal of Physiology {\copyright} 2002 The Physiological Society},
	doi = {10.1113/jphysiol.2001.012507},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/422ZVER8/McNamara et al. - 2002 - Spontaneous arousal activity in infants during NRE.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6PTJSJ2W/jphysiol.2001.html:text/html},
	issn = {1469-7793},
	journal = {The Journal of Physiology},
	language = {en},
	number = {1},
	pages = {263--269},
	title = {Spontaneous arousal activity in infants during {NREM} and {REM} sleep},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2001.012507},
	urldate = {2019-08-23},
	volume = {538},
	year = {2002},
	bdsk-url-1 = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2001.012507},
	bdsk-url-2 = {https://doi.org/10.1113/jphysiol.2001.012507}}

@article{kouider_neural_2013,
	abstract = {{\textless}p{\textgreater}Infants have a sophisticated behavioral and cognitive repertoire suggestive of a capacity for conscious reflection. Yet, demonstrating conscious access in infants remains challenging, mainly because they cannot report their thoughts. Here, to circumvent this problem, we studied whether an electrophysiological signature of consciousness found in adults, corresponding to a late nonlinear cortical response [{\textasciitilde}300 milliseconds (ms)] to brief pictures, already exists in infants. We recorded event-related potentials while 5-, 12-, and 15-month-old infants (\textit{N} = 80) viewed masked faces at various levels of visibility. In all age groups, we found a late slow wave showing a nonlinear profile at the expected perceptual thresholds. However, this late component shifted from a weak and delayed response in 5-month-olds (starting around 900 ms) to a more sustained and faster response in older infants (around 750 ms). These results reveal that the brain mechanisms underlying the threshold for conscious perception are already present in infancy but undergo a slow acceleration during development.{\textless}/p{\textgreater}},
	author = {Kouider, Sid and Stahlhut, Carsten and Gelskov, Sofie V. and Barbosa, Leonardo S. and Dutat, Michel and Gardelle, Vincent de and Christophe, Anne and Dehaene, Stanislas and Dehaene-Lambertz, Ghislaine},
	copyright = {Copyright {\copyright} 2013, American Association for the Advancement of Science},
	doi = {10.1126/science.1232509},
	file = {1232509-Kouider.SM.pdf:/Users/Cecile/Zotero/storage/8L2UAY8M/1232509-Kouider.SM.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/2A67JLIX/Kouider et al. - 2013 - A Neural Marker of Perceptual Consciousness in Inf.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UIVDHI7U/376.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = apr,
	number = {6130},
	pages = {376--380},
	pmid = {23599498},
	title = {A {Neural} {Marker} of {Perceptual} {Consciousness} in {Infants}},
	url = {https://science.sciencemag.org/content/340/6130/376},
	urldate = {2019-08-30},
	volume = {340},
	year = {2013},
	bdsk-url-1 = {https://science.sciencemag.org/content/340/6130/376},
	bdsk-url-2 = {https://doi.org/10.1126/science.1232509}}

@article{tarullo_sleep_2011,
	abstract = {Human neonates spend the majority of their time sleeping. Despite the limited waking hours available for environmental exploration, the first few months of life are a time of rapid learning about the environment. The organization of neonate sleep differs qualitatively from adult sleep, and the unique characteristics of neonatal sleep may promote learning. Sleep contributes to infant learning in multiple ways. First, sleep facilitates neural maturation, thereby preparing infants to process and explore the environment in increasingly sophisticated ways. Second, sleep plays a role in memory consolidation of material presented while the infant was awake. Finally, emerging evidence indicates that infants process sensory stimuli and learn about contingencies in their environment even while asleep. As infants make the transition from reflexive to cortically mediated control, learned responses to physiological challenges during sleep may be critical adaptations to promote infant survival.},
	author = {Tarullo, Amanda R. and Balsam, Peter D. and Fifer, William P.},
	doi = {10.1002/icd.685},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/JE9U2FA8/Tarullo et al. - 2011 - Sleep and Infant Learning.pdf:application/pdf},
	issn = {1522-7227},
	journal = {Infant and child development},
	month = jan,
	number = {1},
	pages = {35--46},
	pmcid = {PMC3034475},
	pmid = {21311602},
	title = {Sleep and {Infant} {Learning}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3034475/},
	urldate = {2019-08-30},
	volume = {20},
	year = {2011},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3034475/},
	bdsk-url-2 = {https://doi.org/10.1002/icd.685}}

@article{norman-haignere_neural_2018,
	abstract = {A central goal of sensory neuroscience is to construct models that can explain neural responses to natural stimuli. As a consequence, sensory models are often tested by comparing neural responses to natural stimuli with model responses to those stimuli. One challenge is that distinct model features are often correlated across natural stimuli, and thus model features can predict neural responses even if they do not in fact drive them. Here, we propose a simple alternative for testing a sensory model: we synthesize a stimulus that yields the same model response as each of a set of natural stimuli, and test whether the natural and ``model-matched'' stimuli elicit the same neural responses. We used this approach to test whether a common model of auditory cortex---in which spectrogram-like peripheral input is processed by linear spectrotemporal filters---can explain fMRI responses in humans to natural sounds. Prior studies have that shown that this model has good predictive power throughout auditory cortex, but this finding could reflect feature correlations in natural stimuli. We observed that fMRI responses to natural and model-matched stimuli were nearly equivalent in primary auditory cortex (PAC) but that nonprimary regions, including those selective for music or speech, showed highly divergent responses to the two sound sets. This dissociation between primary and nonprimary regions was less clear from model predictions due to the influence of feature correlations across natural stimuli. Our results provide a signature of hierarchical organization in human auditory cortex, and suggest that nonprimary regions compute higher-order stimulus properties that are not well captured by traditional models. Our methodology enables stronger tests of sensory models and could be broadly applied in other domains.},
	author = {Norman-Haignere, Sam V. and McDermott, Josh H.},
	doi = {10.1371/journal.pbio.2005127},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CZLBK25Y/Norman-Haignere et McDermott - 2018 - Neural responses to natural and model-matched stim.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YMN4RI4N/article.html:text/html},
	issn = {1545-7885},
	journal = {PLOS Biology},
	keywords = {Neurons, Auditory cortex, Forecasting, Functional magnetic resonance imaging, Bioacoustics, Matched filters, Research validity, Statistical noise},
	language = {en},
	month = dec,
	number = {12},
	pages = {e2005127},
	title = {Neural responses to natural and model-matched stimuli reveal distinct computations in primary and nonprimary auditory cortex},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005127},
	urldate = {2019-09-13},
	volume = {16},
	year = {2018},
	bdsk-url-1 = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005127},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pbio.2005127}}

@article{curtin_speech_2013,
	abstract = {We examined whether infants' preference for speech at 12 months is associated with autistic-like behaviors at 18 months in infants who are at increased risk for autism spectrum disorder (ASD) because they have an older sibling diagnosed with ASD and in low-risk infants. Only low-risk infants listened significantly longer to speech than to nonspeech at 12 months. In both groups, relative preference for speech correlated positively with general cognitive ability at 12 months. However, in high-risk infants only, preference for speech was associated with autistic-like behavior at 18 months, while in low-risk infants, preference for speech correlated with language abilities. This suggests that in children at risk for ASD an atypical species-specific bias for speech may underlie atypical social development.},
	annote = {*},
	author = {Curtin, Suzanne and Vouloumanos, Athena},
	date-modified = {2022-04-05 16:53:37 +0200},
	doi = {10.1007/s10803-013-1759-1},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/72BYLTIJ/Curtin et Vouloumanos - 2013 - Speech Preference is Associated with Autistic-Like.pdf:application/pdf},
	issn = {1573-3432},
	journal = {Journal of Autism and Developmental Disorders},
	keywords = {Language development, High-risk infant siblings, Autism spectrum disorders, Speech preference},
	language = {en},
	month = sep,
	number = {9},
	pages = {2114--2120},
	title = {Speech {Preference} is {Associated} with {Autistic}-{Like} {Behavior} in 18-{Months}-{Olds} at {Risk} for {Autism} {Spectrum} {Disorder}},
	url = {https://doi.org/10.1007/s10803-013-1759-1},
	urldate = {2019-09-17},
	volume = {43},
	year = {2013},
	bdsk-url-1 = {https://doi.org/10.1007/s10803-013-1759-1}}

@article{vouloumanos_foundational_2014,
	abstract = {Orienting biases for speech may provide a foundation for language development. Although human infants show a bias for listening to speech from birth, the relation of a speech bias to later language development has not been established. Here, we examine whether infants' attention to speech directly predicts expressive vocabulary. Infants listened to speech or non-speech in a preferential listening procedure. Results show that infants' attention to speech at 12 months significantly predicted expressive vocabulary at 18 months, while indices of general development did not. No predictive relationships were found for infants' attention to non-speech, or overall attention to sounds, suggesting that the relationship between speech and expressive vocabulary was not a function of infants' general attentiveness. Potentially ancient evolutionary perceptual capacities such as biases for conspecific vocalizations may provide a foundation for proficiency in formal systems such language, much like the approximate number sense may provide a foundation for formal mathematics.},
	annote = {*},
	author = {Vouloumanos, Athena and Curtin, Suzanne},
	copyright = {Copyright {\copyright} 2014 Cognitive Science Society, Inc.},
	date-modified = {2022-04-05 16:53:48 +0200},
	doi = {10.1111/cogs.12128},
	file = {Snapshot:/Users/Cecile/Zotero/storage/USBB2NWZ/cogs.html:text/html;Vouloumanos et Curtin - 2014 - Foundational Tuning How Infants' Attention to Spe.pdf:/Users/Cecile/Zotero/storage/9WN2W8T4/Vouloumanos et Curtin - 2014 - Foundational Tuning How Infants' Attention to Spe.pdf:application/pdf},
	issn = {1551-6709},
	journal = {Cognitive Science},
	keywords = {Speech perception, Cognitive development, Language acquisition, Longitudinal, Predictor},
	language = {en},
	number = {8},
	pages = {1675--1686},
	shorttitle = {Foundational {Tuning}},
	title = {Foundational {Tuning}: {How} {Infants}' {Attention} to {Speech} {Predicts} {Language} {Development}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12128},
	urldate = {2019-09-17},
	volume = {38},
	year = {2014},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12128},
	bdsk-url-2 = {https://doi.org/10.1111/cogs.12128}}

@article{hedges_robust_2010,
	author = {Hedges, Larry V. and Tipton, Elizabeth and Johnson, Matthew C.},
	doi = {10.1002/jrsm.5},
	file = {Hedges et al. - 2010 - Robust variance estimation in meta-regression with.pdf:/Users/Cecile/Zotero/storage/MGENK2VD/Hedges et al. - 2010 - Robust variance estimation in meta-regression with.pdf:application/pdf},
	issn = {17592879, 17592887},
	journal = {Research Synthesis Methods},
	language = {en},
	month = jan,
	number = {1},
	pages = {39--65},
	title = {Robust variance estimation in meta-regression with dependent effect size estimates},
	url = {http://doi.wiley.com/10.1002/jrsm.5},
	urldate = {2019-09-19},
	volume = {1},
	year = {2010},
	bdsk-url-1 = {http://doi.wiley.com/10.1002/jrsm.5},
	bdsk-url-2 = {https://doi.org/10.1002/jrsm.5}}

@phdthesis{prescott_differential_1985,
	author = {Prescott, Phyllis A.},
	file = {Prescott_uncg_8709241.PDF:/Users/Cecile/Zotero/storage/YJCLNYIL/Prescott_uncg_8709241.PDF:application/pdf},
	school = {The University of North Carolina at Greensboro},
	title = {Differential reinforcing value of speech and heartbeats: a measure of functional lateralization in the neonate.},
	url = {http://libres.uncg.edu/ir/listing.aspx?styp=ti&id=25823},
	year = {1985},
	bdsk-url-1 = {http://libres.uncg.edu/ir/listing.aspx?styp=ti&id=25823}}

@book{borenstein_introduction_2011,
	abstract = {This book provides a clear and thorough introduction to meta-analysis, the process of synthesizing data from a series of separate studies. Meta-analysis has become a critically important tool in fields as diverse as medicine, pharmacology, epidemiology, education, psychology, business, and ecology. Introduction to Meta-Analysis:  Outlines the role of meta-analysis in the research process Shows how to compute effects sizes and treatment effects Explains the fixed-effect and random-effects models for synthesizing data Demonstrates how to assess and interpret variation in effect size across studies Clarifies concepts using text and figures, followed by formulas and examples Explains how to avoid common mistakes in meta-analysis Discusses controversies in meta-analysis Features a web site with additional material and exercises  A superb combination of lucid prose and informative graphics, written by four of the world's leading experts on all aspects of meta-analysis. Borenstein, Hedges, Higgins, and Rothstein provide a refreshing departure from cookbook approaches with their clear explanations of the what and why of meta-analysis. The book is ideal as a course textbook or for self-study. My students, who used pre-publication versions of some of the chapters, raved about the clarity of the explanations and examples. David Rindskopf, Distinguished Professor of Educational Psychology, City University of New York, Graduate School and University Center, \& Editor of the Journal of Educational and Behavioral Statistics. The approach taken by Introduction to Meta-analysis is intended to be primarily conceptual, and it is amazingly successful at achieving that goal. The reader can comfortably skip the formulas and still understand their application and underlying motivation. For the more statistically sophisticated reader, the relevant formulas and worked examples provide a superb practical guide to performing a meta-analysis. The book provides an eclectic mix of examples from education, social science, biomedical studies, and even ecology. For anyone considering leading a course in meta-analysis, or pursuing self-directed study, Introduction to Meta-analysis would be a clear first choice. Jesse A. Berlin, ScD  Introduction to Meta-Analysis is an excellent resource for novices and experts alike. The book provides a clear and comprehensive presentation of all basic and most advanced approaches to meta-analysis. This book will be referenced for decades. Michael A. McDaniel, Professor of Human Resources and Organizational Behavior, Virginia Commonwealth University},
	author = {Borenstein, Michael and Hedges, Larry V. and Higgins, Julian P. T. and Rothstein, Hannah R.},
	isbn = {978-1-119-96437-7},
	keywords = {Mathematics / Probability \& Statistics / Stochastic Processes, Medical / Biostatistics},
	language = {en},
	month = aug,
	note = {Google-Books-ID: JQg9jdrq26wC},
	publisher = {John Wiley \& Sons},
	title = {Introduction to {Meta}-{Analysis}},
	year = {2011}}

@article{doelling_cortical_2015,
	abstract = {Recent studies establish that cortical oscillations track naturalistic speech in a remarkably faithful way. Here, we test whether such neural activity, particularly low-frequency ({\textless}8 Hz; delta--theta) oscillations, similarly entrain to music and whether experience modifies such a cortical phenomenon. Music of varying tempi was used to test entrainment at different rates. In three magnetoencephalography experiments, we recorded from nonmusicians, as well as musicians with varying years of experience. Recordings from nonmusicians demonstrate cortical entrainment that tracks musical stimuli over a typical range of tempi, but not at tempi below 1 note per second. Importantly, the observed entrainment correlates with performance on a concurrent pitch-related behavioral task. In contrast, the data from musicians show that entrainment is enhanced by years of musical training, at all presented tempi. This suggests a bidirectional relationship between behavior and cortical entrainment, a phenomenon that has not previously been reported. Additional analyses focus on responses in the beta range (∼15--30 Hz)---often linked to delta activity in the context of temporal predictions. Our findings provide evidence that the role of beta in temporal predictions scales to the complex hierarchical rhythms in natural music and enhances processing of musical content. This study builds on important findings on brainstem plasticity and represents a compelling demonstration that cortical neural entrainment is tightly coupled to both musical training and task performance, further supporting a role for cortical oscillatory activity in music perception and cognition.},
	author = {Doelling, Keith B. and Poeppel, David},
	doi = {10.1073/pnas.1508431112},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7T5EJS3E/Doelling et Poeppel - 2015 - Cortical entrainment to music and its modulation b.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/94FZVI98/E6233.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {MEG, theta, beta, entrainment, musical expertise},
	language = {en},
	month = nov,
	number = {45},
	pages = {E6233--E6242},
	pmid = {26504238},
	title = {Cortical entrainment to music and its modulation by expertise},
	url = {https://www.pnas.org/content/112/45/E6233},
	urldate = {2019-10-30},
	volume = {112},
	year = {2015},
	bdsk-url-1 = {https://www.pnas.org/content/112/45/E6233},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1508431112}}

@article{schulze_transparent_2018,
	abstract = {The combination of transparency, small brain size and genetic access positions Danionella translucida as a promising model organism for functional imaging of neuronal circuits, especially during complex behaviors in adults.},
	author = {Schulze, Lisanne and Henninger, J{\"o}rg and Kadobianskyi, Mykola and Chaigne, Thomas and Faustino, Ana Isabel and Hakiy, Nahid and Albadri, Shahad and Schuelke, Markus and Maler, Leonard and Bene, Filippo Del and Judkewitz, Benjamin},
	copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	doi = {10.1038/s41592-018-0144-6},
	file = {Snapshot:/Users/Cecile/Zotero/storage/L4UPEXS9/s41592-018-0144-6.html:text/html},
	issn = {1548-7105},
	journal = {Nature Methods},
	language = {en},
	month = nov,
	number = {11},
	pages = {977--983},
	title = {Transparent {Danionella} translucida as a genetically tractable vertebrate brain model},
	url = {https://www.nature.com/articles/s41592-018-0144-6},
	urldate = {2019-11-06},
	volume = {15},
	year = {2018},
	bdsk-url-1 = {https://www.nature.com/articles/s41592-018-0144-6},
	bdsk-url-2 = {https://doi.org/10.1038/s41592-018-0144-6}}

@article{muir_ontogenesis_1979,
	abstract = {Research on the early development of auditory localization responses is reviewed, and the existence of a U-shaped developmental function is described. It has been reported that many newborns turn toward off-centered sound sources reliably at birth and will perform well for approximately the 1st mo of life, poorly during the 2nd and 3rd mo, and well again during the 4th mo. This trend was confirmed in 3 of 4 infants who were tested extensively throughout their early months. The 4th S failed to show reliable orientation toward sounds until the 4th mo of life. During the period of temporary performance decrement, attempts to reinstate reliable responding by either introducing meaningful acoustic stimuli or eliminating possible auditory-visual conflicts were not successful. (French abstract) (48 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Muir, Darwin and Abraham, Wayne and Forbes, Brian and Harris, Leonard},
	doi = {10.1037/h0081729},
	file = {EBSCO Full Text:/Users/Cecile/Zotero/storage/8BP7ZA6C/Muir et al. - 1979 - The ontogenesis of an auditory localization respon.pdf:application/pdf},
	issn = {0008-4255},
	journal = {Canadian Journal of Psychology/Revue canadienne de psychologie},
	keywords = {Auditory Perception, Child Development, Discrimination Learning, Female, Humans, Infant, Infant, Newborn, Male, Auditory Localization, auditory localization response, birth to 4 mo of age, Perceptual Development, Sound Localization},
	month = dec,
	number = {4},
	pages = {320--333},
	series = {Infant {Perceptual} {Development}},
	title = {The ontogenesis of an auditory localization response from birth to four months of age},
	url = {http://sirius.parisdescartes.fr/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=psyh&AN=1981-12511-001&lang=fr&site=eds-live&scope=site},
	urldate = {2019-11-12},
	volume = {33},
	year = {1979},
	bdsk-url-1 = {http://sirius.parisdescartes.fr/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=psyh&AN=1981-12511-001&lang=fr&site=eds-live&scope=site},
	bdsk-url-2 = {https://doi.org/10.1037/h0081729}}

@article{gilley_spectral-temporal_2017,
	abstract = {Oddball paradigms are frequently used to study auditory discrimination by comparing event-related potential (ERP) responses from a standard, high probability sound and to a deviant, low probability sound. Previous research has established that such paradigms, such as the mismatch response or mismatch negativity, are useful for examining auditory processes in young children and infants across various sleep and attention states. The extent to which oddball ERP responses may reflect subtle discrimination effects, such as speech discrimination, is largely unknown, especially in infants that have not yet acquired speech and language.},
	author = {Gilley, Phillip M. and Uhler, Kristin and Watson, Kaylee and Yoshinaga-Itano, Christine},
	doi = {10.1186/s12868-017-0353-4},
	file = {Snapshot:/Users/Cecile/Zotero/storage/EF8N68BJ/s12868-017-0353-4.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/APH5G9C2/Gilley et al. - 2017 - Spectral-temporal EEG dynamics of speech discrimin.pdf:application/pdf},
	issn = {1471-2202},
	journal = {BMC Neuroscience},
	month = mar,
	number = {1},
	pages = {34},
	title = {Spectral-temporal {EEG} dynamics of speech discrimination processing in infants during sleep},
	url = {https://doi.org/10.1186/s12868-017-0353-4},
	urldate = {2019-11-12},
	volume = {18},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1186/s12868-017-0353-4}}

@article{fulkerson_influence_2003,
	abstract = {This experiment examines the joint influence of auditory and social cues on infants' basic-level and global categorization. Nine- and fifteen-month-olds were familiarized to a series of category exemplars in an object-examining task. Objects were introduced with a labeling phrase, a non-labeling sound, or no sound, and auditory input was presented orally by the experimenter or played on a hidden voice recorder. Novel objects from the familiarized category and a contrasting category were then presented. Results of analyses performed on novelty preference scores indicated that infants demonstrated basic-level categorization in all conditions. However, infants at both age levels only demonstrated global categorization when labeling phrases were introduced. In addition, labels led to global categorization in 9-month-olds regardless of the source of those labels; however, labels only led to global categorization in 15-month-olds when the labels were presented orally by the experimenter.},
	author = {Fulkerson, Anne L. and Haaf, Robert A.},
	doi = {10.1207/S15327078IN0403_03},
	file = {Fulkerson et Haaf - 2003 - The Influence of Labels, Non-Labeling Sounds, and .pdf:/Users/Cecile/Zotero/storage/3VI9DWQA/Fulkerson et Haaf - 2003 - The Influence of Labels, Non-Labeling Sounds, and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NG8GSVYG/S15327078IN0403_03.html:text/html},
	issn = {1525-0008},
	journal = {Infancy},
	month = aug,
	number = {3},
	pages = {349--369},
	title = {The {Influence} of {Labels}, {Non}-{Labeling} {Sounds}, and {Source} of {Auditory} {Input} on 9- and 15-{Month}-{Olds}' {Object} {Categorization}},
	url = {https://www.tandfonline.com/doi/abs/10.1207/S15327078IN0403_03},
	urldate = {2019-11-14},
	volume = {4},
	year = {2003},
	bdsk-url-1 = {https://www.tandfonline.com/doi/abs/10.1207/S15327078IN0403_03},
	bdsk-url-2 = {https://doi.org/10.1207/S15327078IN0403_03}}

@article{molfese_ontogeny_1975,
	abstract = {Auditory evoked responses (AER) were recorded from the temporal region of both cerebral hemispheres of human infants, children, and adults in response to four speech and two nonspeech acoustic stimuli. Left hemisphere AERs were larger in amplitude than right hemisphere AERs to speech stimuli for all groups. Nonspeech stimuli produced larger amplitude AERs in the right hemisphere. Lateral differences to both types of stimuli were found to decrease with age.},
	author = {Molfese, Dennis L. and Freeman, Robert B. and Palermo, David S.},
	doi = {10.1016/S0093-934X(75)80076-9},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/8TGVZT65/Molfese et al. - 1975 - The ontogeny of brain lateralization for speech an.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H98M354F/S0093934X75800769.html:text/html},
	issn = {0093-934X},
	journal = {Brain and Language},
	language = {en},
	month = jan,
	pages = {356--368},
	title = {The ontogeny of brain lateralization for speech and nonspeech stimuli},
	url = {http://www.sciencedirect.com/science/article/pii/S0093934X75800769},
	urldate = {2019-11-14},
	volume = {2},
	year = {1975},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X75800769},
	bdsk-url-2 = {https://doi.org/10.1016/S0093-934X(75)80076-9}}

@article{gelman_difference_2006,
	abstract = {It is common to summarize statistical comparisons by declarations of statistical significance or nonsignificance. Here we discuss one problem with such declarations, namely that changes in statistical significance are often not themselves statistically significant. By this, we are not merely making the commonplace observation that any particular threshold is arbitrary---for example, only a small change is required to move an estimate from a 5.1\% significance level to 4.9\%, thus moving it into statistical significance. Rather, we are pointing out that even large changes in significance levels can correspond to small, nonsignificant changes in the underlying quantities.The error we describe is conceptually different from other oft-cited problems---that statistical significance is not the same as practical importance, that dichotomization into significant and nonsignificant results encourages the dismissal of observed differences in favor of the usually less interesting null hypothesis of no difference, and that any particular threshold for declaring significance is arbitrary. We are troubled by all of these concerns and do not intend to minimize their importance. Rather, our goal is to bring attention to this additional error of interpretation. We illustrate with a theoretical example and two applied examples. The ubiquity of this statistical error leads us to suggest that students and practitioners be made more aware that the difference between ``significant'' and ``not significant'' is not itself statistically significant.},
	author = {Gelman, Andrew and Stern, Hal},
	doi = {10.1198/000313006X152649},
	file = {Snapshot:/Users/Cecile/Zotero/storage/JEK3MW34/000313006X152649.html:text/html;Version soumise:/Users/Cecile/Zotero/storage/4HE94A7W/Gelman et Stern - 2006 - The Difference Between ``Significant'' and ``Not Sign.pdf:application/pdf},
	issn = {0003-1305},
	journal = {The American Statistician},
	month = nov,
	number = {4},
	pages = {328--331},
	title = {The {Difference} {Between} ``{Significant}'' and ``{Not} {Significant}'' is not {Itself} {Statistically} {Significant}},
	url = {https://amstat.tandfonline.com/doi/abs/10.1198/000313006X152649},
	urldate = {2019-11-15},
	volume = {60},
	year = {2006},
	bdsk-url-1 = {https://amstat.tandfonline.com/doi/abs/10.1198/000313006X152649},
	bdsk-url-2 = {https://doi.org/10.1198/000313006X152649}}

@article{kiyonaga_practical_2019,
	author = {Kiyonaga, Anastasia and Scimeca, Jason M.},
	doi = {10.1016/j.tins.2019.07.003},
	file = {Snapshot:/Users/Cecile/Zotero/storage/DW55E9MK/S0166-2236(19)30124-9.html:text/html},
	issn = {0166-2236, 1878-108X},
	journal = {Trends in Neurosciences},
	keywords = {open science, preregistration, research practices},
	language = {English},
	month = sep,
	number = {9},
	pages = {568--572},
	pmid = {31470913},
	title = {Practical {Considerations} for {Navigating} {Registered} {Reports}},
	url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(19)30124-9},
	urldate = {2019-11-18},
	volume = {42},
	year = {2019},
	bdsk-url-1 = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(19)30124-9},
	bdsk-url-2 = {https://doi.org/10.1016/j.tins.2019.07.003}}

@book{lipsey_practical_2001,
	abstract = {Meta-analysis can be understood as a form of survey research in which research reports, rather than people, are surveyed. But how does a researcher select relevant research studies, code their various characteristics and quantitative findings, and analyze and describe their collective results in a valid and useful manner? Through an emphasis on practical procedures and a consideration of choices for implementing them, the authors provide readers with an answer to this question in a user-friendly, state-of-the-art presentation of meta-analysis. The authors lay out each step of meta-analysis from problem formulation through statistical analysis and the interpretation of results. In addition, they offer (1) detailed advice about formatting coding forms, estimating effect sizes, and conducting statistical analysis; (2) coverage of meta-analysis with all the effect size statistics commonly used in different fields, plus some specialized ones; (3) macros that can be used with popular statistical programs to perform meta-analysis calculations; and (4) frequent examples to illustrate important points and procedures. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	address = {Thousand Oaks, CA, US},
	author = {Lipsey, Mark W. and Wilson, David B.},
	file = {Snapshot:/Users/Cecile/Zotero/storage/PGK9ZFUW/2000-16602-000.html:text/html},
	isbn = {978-0-7619-2167-7 978-0-7619-2168-4},
	keywords = {Experimental Methods, Meta Analysis},
	publisher = {Sage Publications, Inc},
	series = {Practical meta-analysis},
	title = {Practical meta-analysis},
	year = {2001}}

@article{dunlap_meta-analysis_1996,
	abstract = {Tests for experiments with matched groups or repeated measures designs use error terms that involve the correlation between the measures as well as the variance of the data. The larger the correlation between the measures, the smaller the error and the larger the test statistic. If an effect size is computed from the test statistic without taking the correlation between the measures into account, effect size will be overestimated. Procedures for computing effect size appropriately from matched groups or repeated measures designs are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Dunlap, William P. and Cortina, Jose M. and Vaslow, Joel B. and Burke, Michael J.},
	doi = {10.1037/1082-989X.1.2.170},
	file = {Snapshot:/Users/Cecile/Zotero/storage/WR282X2W/1996-04469-005.html:text/html},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	journal = {Psychological Methods},
	keywords = {Meta Analysis, Effect Size (Statistical), Experimental Design, Repeated Measures},
	number = {2},
	pages = {170--177},
	title = {Meta-analysis of experiments with matched groups or repeated measures designs},
	volume = {1},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1037/1082-989X.1.2.170}}

@article{cooper_developmental_1994,
	abstract = {Across several independent studies, infants from a few days to 9 months of age have shown preferences for infant-directed (ID) over adult-directed (AD) speech. Moreover, 4-month-olds have been shown to prefer sine-wave analogs of the fundamental frequency of ID speech, suggesting that exaggerated pitch contours are prepotent stimuli for infants. The possibility of similar preferences by 1-month-olds was examined in a series of experiments, using a fixation-based preference procedure. Results from the first 2 experiments showed that 1-month-olds did not prefer the lower-frequency pitch characteristics of ID speech, even though 1-month-olds were able to discriminate low-pass filtered ID and AD speech. Since low-pass filtering may have distorted the fundamental frequency characteristics of ID speech, 1-month-olds were also tested with sine-wave analogs of the fundamental frequencies of the ID utterances. Infants in this third experiment also showed no preference for ID pitch contours. In the fourth experiment, 1-month-olds preferred a natural recording of ID speech over a version which preserved only its lower frequency prosodic features. From these results, it is argued that, although young infants are similar to older infants in their attraction to ID speech, their preferences depend on a wider range of acoustic features (e. g., spectral structure). It is suggested that exaggerated pitch contours which characterize ID speech may become salient communicative signals for infants through language-rich, interactive experiences with caretakers and increased perceptual acuity over the first months after birth.},
	annote = {*},
	author = {Cooper, Robin Panneton and Aslin, Richard N.},
	date-modified = {2022-04-05 16:53:07 +0200},
	doi = {10.2307/1131286},
	file = {Cooper et Aslin - 1994 - Developmental Differences in Infant Attention to t.pdf:/Users/Cecile/Zotero/storage/9NY76P9P/Cooper et Aslin - 1994 - Developmental Differences in Infant Attention to t.pdf:application/pdf},
	issn = {0009-3920},
	journal = {Child Development},
	number = {6},
	pages = {1663--1677},
	title = {Developmental {Differences} in {Infant} {Attention} to the {Spectral} {Properties} of {Infant}-{Directed} {Speech}},
	url = {www.jstor.org/stable/1131286},
	urldate = {2019-11-19},
	volume = {65},
	year = {1994},
	bdsk-url-1 = {www.jstor.org/stable/1131286},
	bdsk-url-2 = {https://doi.org/10.2307/1131286}}

@article{segal_listening_2011,
	annote = {*},
	author = {Segal, Osnat and Kishon-Rabin, Liat},
	date-modified = {2022-04-05 16:57:07 +0200},
	doi = {10.1097/AUD.0b013e3182008afc},
	file = {Listening Preference for Child-Directed Speech Versus Nonspeech Stimuli in Normal-Hearing and Hearing-Impaired Infants After Cochlear Implantation | Ovid:/Users/Cecile/Zotero/storage/SCH8D7LH/HTML.html:text/html;Segal et Kishon-Rabin - 2011 - Listening Preference for Child-Directed Speech Ver.pdf:/Users/Cecile/Zotero/storage/56VGVDVI/Segal et Kishon-Rabin - 2011 - Listening Preference for Child-Directed Speech Ver.pdf:application/pdf},
	issn = {0196-0202},
	journal = {Ear and Hearing},
	language = {English},
	month = jun,
	number = {3},
	pages = {358--372},
	title = {Listening {Preference} for {Child}-{Directed} {Speech} {Versus} {Nonspeech} {Stimuli} in {Normal}-{Hearing} and {Hearing}-{Impaired} {Infants} {After} {Cochlear} {Implantation} {\textbar} {Ovid}},
	url = {https://oce.ovid.com/article/00003446-201105000-00009/HTML},
	urldate = {2019-11-19},
	volume = {32},
	year = {2011},
	bdsk-url-1 = {https://oce.ovid.com/article/00003446-201105000-00009/HTML},
	bdsk-url-2 = {https://doi.org/10.1097/AUD.0b013e3182008afc}}

@article{ference_role_2018,
	abstract = {A bias for speech over non-speech emerges at birth in typically developing (TD) infants and a preference for vocalizations generated from one's own species (conspecific) emerges by 3 months. These biases and preferences may direct infants to relevant communicative information in their language learning environments, possibly predicting positive linguistic and social development. The first series of studies explored whether a bias for speech (over non-speech) at 6 and 9 months was predictive of language and social behaviors at 12 months. Whether a preference for conspecific vocalizations (over monkey calls) at 9 months was predictive of these same outcomes was also examined. Infants were biased toward speech over non-speech at 6 and 9 months, but preferred monkey calls over speech at 9 months. However, these listening patterns did not predict language or social developmental outcomes. Understanding these patterns of attention and how experimental procedures may influence preferences is important for advancing our understanding of the relationship between attention to speech and early development. The second series of studies reports findings from high-risk (HR) infant siblings of children diagnosed with Autism Spectrum Disorder (ASD), who participated in these same experiments. HR infants are known to have heterogeneous outcomes by age 3, with about half developing typically, while others present with atypical outcomes, including ASD. Given the hypothesized importance of attention to speech on later development, we explored whether HR infants as a group selectively attended to speech and whether such attention was predictive of early language and social behaviors. HR infants were biased toward speech at 6 months; however, by 9 months, they did not differentially attend to speech over non-speech or monkey calls overall. Despite this, increased attention to speech at 9 months predicted better language and fewer autism-like behaviors at 12 months. Therefore, increased attention to conspecifics may indicate typical outcomes for HR infants. Future directions include following both groups of infants to 3 years of age to explore whether selective attention to speech during the first year is predictive of much later developmental outcomes and/or diagnostic status.},
	annote = {*},
	author = {Ference, Jennifer Diana},
	copyright = {University of Calgary graduate students retain copyright ownership and moral rights for their thesis. You may use this material in any way that is permitted by the Copyright Act or through licensing that has been assigned to the document. For uses that are not allowable under copyright legislation or licensing, you are required to seek permission.},
	date-modified = {2022-04-05 16:54:45 +0200},
	doi = {http://dx.doi.org/10.11575/PRISM/31878},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/763GHHVU/Ference - 2018 - The Role of Attentional Biases for Conspecific Voc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2E4FCYZW/106592.html:text/html},
	language = {eng},
	month = apr,
	title = {The {Role} of {Attentional} {Biases} for {Conspecific} {Vocalizations}},
	url = {https://prism.ucalgary.ca/handle/1880/106592},
	urldate = {2019-11-19},
	year = {2018},
	bdsk-url-1 = {https://prism.ucalgary.ca/handle/1880/106592},
	bdsk-url-2 = {http://dx.doi.org/10.11575/PRISM/31878}}

@article{oller_precursors_1999,
	abstract = {During the canonical stage of infant babbling, infants produce well-formed syllables, often in reduplicated sequences such as ``bababa.'' Although nearly all infants with normal hearing begin the canonical stage by 10 months of age, a few are delayed, and these infants may be of special interest. Recent studies indicate that late onset of canonical babbling may be a predictor of disorders. A simple screening procedure that focuses on canonical babbling was used to evaluate over 3400 infants at risk who were about 10 months of age. Among infants who showed late onset of canonical babbling, fewer than half had been previously diagnosed as having a significant medical problem that might have accounted for the delay. A follow-up study indicated that infants with delayed canonical babbling had smaller production vocabularies at 18, 24, and 30 months than did infants in the control group. The results suggest that late onset of canonical babbling, a factor that can be monitored effectively through an interview with a parent, can predict delay in the onset of speech production.},
	author = {Oller, D. Kimbrough and Eilers, Rebecca E and Neal, A. Rebecca and Schwartz, Heidi K},
	doi = {10.1016/S0021-9924(99)00013-1},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GGVBGMXX/Oller et al. - 1999 - Precursors to speech in infancy The prediction of.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/G83RSMDZ/S0021992499000131.html:text/html},
	issn = {0021-9924},
	journal = {Journal of Communication Disorders},
	keywords = {Phonology, Babbling, Infant vocalization, Screening},
	language = {en},
	month = jul,
	number = {4},
	pages = {223--245},
	shorttitle = {Precursors to speech in infancy},
	title = {Precursors to speech in infancy: {The} prediction of speech and language disorders},
	url = {http://www.sciencedirect.com/science/article/pii/S0021992499000131},
	urldate = {2019-11-19},
	volume = {32},
	year = {1999},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0021992499000131},
	bdsk-url-2 = {https://doi.org/10.1016/S0021-9924(99)00013-1}}

@article{simmons_false-positive_2011,
	abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (≤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	doi = {10.1177/0956797611417632},
	file = {SAGE PDF Full Text:/Users/Cecile/Zotero/storage/778WMGIQ/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf:application/pdf},
	issn = {0956-7976},
	journal = {Psychological Science},
	language = {en},
	month = nov,
	number = {11},
	pages = {1359--1366},
	shorttitle = {False-{Positive} {Psychology}},
	title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	url = {https://doi.org/10.1177/0956797611417632},
	urldate = {2019-11-19},
	volume = {22},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1177/0956797611417632}}

@article{foster_open_2017,
	author = {Foster, Erin D. and Deardorff, Ariel},
	doi = {10.5195/jmla.2017.88},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/DCILBVEV/Foster et Deardorff - 2017 - Open Science Framework (OSF).pdf:application/pdf},
	issn = {1536-5050},
	journal = {Journal of the Medical Library Association : JMLA},
	month = apr,
	number = {2},
	pages = {203--206},
	pmcid = {PMC5370619},
	pmid = {null},
	title = {Open {Science} {Framework} ({OSF})},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	urldate = {2019-11-19},
	volume = {105},
	year = {2017},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	bdsk-url-2 = {https://doi.org/10.5195/jmla.2017.88}}

@misc{r_core_team_r:_2018,
	address = {Vienna, Austria},
	author = {{R Core Team}},
	publisher = {R Foundation for Statistical Computing},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org},
	year = {2018},
	bdsk-url-1 = {https://www.R-project.org}}

@article{calabrese_coding_2015,
	author = {Calabrese, Ana and Woolley, Sarah M. N.},
	doi = {10.1073/pnas.1408545112},
	file = {Calabrese et Woolley - 2015 - Coding principles of the canonical cortical microc.pdf:/Users/Cecile/Zotero/storage/TS4DMR7G/Calabrese et Woolley - 2015 - Coding principles of the canonical cortical microc.pdf:application/pdf},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = mar,
	number = {11},
	pages = {3517--3522},
	title = {Coding principles of the canonical cortical microcircuit in the avian brain},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408545112},
	urldate = {2019-12-03},
	volume = {112},
	year = {2015},
	bdsk-url-1 = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408545112},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1408545112}}

@article{donhauser_two_2019,
	abstract = {During speech listening, the brain could use contextual predictions to optimize sensory sampling and processing. We asked if such predictive processing is organized dynamically into separate oscillatory timescales. We trained a neural network that uses context to predict speech at the phoneme level. Using this model, we estimated contextual uncertainty and surprise of natural speech as factors to explain neurophysiological activity in human listeners. We show, first, that speech-related activity is hierarchically organized into two timescales: fast responses (theta: 4--10 Hz), restricted to early auditory regions, and slow responses (delta: 0.5--4 Hz), dominating in downstream auditory regions. Neural activity in these bands is selectively modulated by predictions: the gain of early theta responses varies according to the contextual uncertainty of speech, while later delta responses are selective to surprising speech inputs. We conclude that theta sensory sampling is tuned to maximize expected information gain, while delta encodes only non-redundant information.},
	author = {Donhauser, Peter W. and Baillet, Sylvain},
	doi = {10.1016/j.neuron.2019.10.019},
	file = {Donhauser et Baillet - 2019 - Two Distinct Neural Timescales for Predictive Spee.pdf:/Users/Cecile/Zotero/storage/PRPGCS47/Donhauser et Baillet - 2019 - Two Distinct Neural Timescales for Predictive Spee.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VVTSSWZF/S0896627319308931.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	keywords = {MEG, auditory processing, speech processing, theta oscillations, delta oscillations, neural networks, predictive coding, surprise, temporal response functions, uncertainty},
	language = {en},
	month = dec,
	title = {Two {Distinct} {Neural} {Timescales} for {Predictive} {Speech} {Processing}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627319308931},
	urldate = {2019-12-09},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627319308931},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2019.10.019}}

@article{puschmann_musicians_2019,
	abstract = {Abstract.  Musical training has been demonstrated to benefit speech-in-noise perception. It is however unknown whether this effect translates to selective liste},
	author = {Puschmann, Sebastian and Baillet, Sylvain and Zatorre, Robert J.},
	doi = {10.1093/cercor/bhy193},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UPJYBYYL/Puschmann et al. - 2019 - Musicians at the Cocktail Party Neural Substrates.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AKL6TRBY/5078215.html:text/html},
	issn = {1047-3211},
	journal = {Cerebral Cortex},
	language = {en},
	month = jul,
	number = {8},
	pages = {3253--3265},
	shorttitle = {Musicians at the {Cocktail} {Party}},
	title = {Musicians at the {Cocktail} {Party}: {Neural} {Substrates} of {Musical} {Training} {During} {Selective} {Listening} in {Multispeaker} {Situations}},
	url = {https://academic.oup.com/cercor/article/29/8/3253/5078215},
	urldate = {2019-12-09},
	volume = {29},
	year = {2019},
	bdsk-url-1 = {https://academic.oup.com/cercor/article/29/8/3253/5078215},
	bdsk-url-2 = {https://doi.org/10.1093/cercor/bhy193}}

@article{disbergen_assessing_2018,
	abstract = {Polyphonic music listening well exemplifies processes typically involved in daily auditory scene analysis situations, relying on an interactive interplay between bottom-up and top-down processes. Most studies investigating scene analysis have used elementary auditory scenes, however real-world scene analysis is far more complex. In particular, music, contrary to most other natural auditory scenes, can be perceived by either integrating or, under attentive control, segregating sound streams, often carried by different instruments. One of the prominent bottom-up cues contributing to multi-instrument music perception is their timbre difference. In this work, we introduce and validate a novel paradigm designed to investigate, within naturalistic musical auditory scenes, attentive modulation as well as its interaction with bottom-up processes. Two psychophysical experiments are described, employing custom-composed two-voice polyphonic music pieces within a framework implementing a behavioral performance metric to validate listener instructions requiring either integration or segregation of scene elements. In experiment 1, the listeners' locus of attention was switched between individual instruments or the aggregate (i.e. both instruments together), via a task requiring the detection of temporal modulations (i.e. triplets) incorporated within or across instruments. Subjects responded post-stimulus whether triplets were present in the to-be-attended instrument(s). Experiment 2 introduced the bottom-up manipulation by adding a three-level morphing of instrument timbre distance to the attentional framework. The task was designed to be used within neuroimaging paradigms; experiment 2 was additionally validated behaviorally in the functional Magnetic Resonance Imaging (fMRI) environment. Experiment 1 subjects (N=29, non-musicians) completed the task at high levels of accuracy, showing no group differences between any experimental conditions. Nineteen listeners also participated in experiment 2, showing a main effect of instrument timbre distance, even though within attention-condition timbre-distance contrasts did not demonstrate any timbre effect. Correlation of overall scores with morph-distance effects, computed by subtracting the largest from the smallest timbre distance scores, showed an influence of general task difficulty on the timbre distance effect. Comparison of laboratory and fMRI data showed scanner noise had no adverse effect on task performance. These experimental paradigms enable to study both bottom-up and top-down contributions to auditory stream segregation and integration within psychophysical and neuroimaging experiments.},
	author = {Disbergen, Niels R. and Valente, Giancarlo and Formisano, Elia and Zatorre, Robert J.},
	doi = {10.3389/fnins.2018.00121},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PHLQJQ7I/Disbergen et al. - 2018 - Assessing Top-Down and Bottom-Up Contributions to .pdf:application/pdf},
	issn = {1662-453X},
	journal = {Frontiers in Neuroscience},
	keywords = {Attention, auditory scene analysis, Auditory Stream Integration, auditory stream segregation, Polyphonic music, timbre},
	language = {English},
	title = {Assessing {Top}-{Down} and {Bottom}-{Up} {Contributions} to {Auditory} {Stream} {Segregation} and {Integration} {With} {Polyphonic} {Music}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00121/full},
	urldate = {2019-12-09},
	volume = {12},
	year = {2018},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00121/full},
	bdsk-url-2 = {https://doi.org/10.3389/fnins.2018.00121}}

@article{buonomano_cortical_1998,
	abstract = {It has been clear for almost two decades that cortical representations in adult animals are not fixed entities, but rather, are dynamic and are continuously modified by experience. The cortex can preferentially allocate area to represent the particular peripheral input sources that are proportionally most used. Alterations in cortical representations appear to underlie learning tasks dependent on the use of the behaviorally important peripheral inputs that they represent. The rules governing this cortical representational plasticity following manipulations of inputs, including learning, are increasingly well understood. In parallel with developments in the field of cortical map plasticity, studies of synaptic plasticity have characterized specific elementary forms of plasticity, including associative long-term potentiation and long-term depression of excitatory postsynaptic potentials. Investigators have made many important strides toward understanding the molecular underpinnings of these fundamental plasticity processes and toward defining the learning rules that govern their induction. The fields of cortical synaptic plasticity and cortical map plasticity have been implicitly linked by the hypothesis that synaptic plasticity underlies cortical map reorganization. Recent experimental and theoretical work has provided increasingly stronger support for this hypothesis. The goal of the current paper is to review the fields of both synaptic and cortical map plasticity with an emphasis on the work that attempts to unite both fields. A second objective is to highlight the gaps in our understanding of synaptic and cellular mechanisms underlying cortical representational plasticity.},
	author = {Buonomano, Dean V. and Merzenich, Michael M.},
	doi = {10.1146/annurev.neuro.21.1.149},
	file = {Buonomano et Merzenich - 1998 - CORTICAL PLASTICITY From Synapses to Maps.pdf:/Users/Cecile/Zotero/storage/6L2RPX3U/Buonomano et Merzenich - 1998 - CORTICAL PLASTICITY From Synapses to Maps.pdf:application/pdf},
	journal = {Annual Review of Neuroscience},
	number = {1},
	pages = {149--186},
	pmid = {9530495},
	shorttitle = {{CORTICAL} {PLASTICITY}},
	title = {{CORTICAL} {PLASTICITY}: {From} {Synapses} to {Maps}},
	url = {https://doi.org/10.1146/annurev.neuro.21.1.149},
	urldate = {2019-12-15},
	volume = {21},
	year = {1998},
	bdsk-url-1 = {https://doi.org/10.1146/annurev.neuro.21.1.149}}

@article{abraham_metaplasticity:_2008,
	abstract = {Synaptic plasticity is central to learning mechanisms, but what keeps the plasticity in check? Abraham reviews our current understanding of the mechanisms of metaplasticity --- the plasticity of synaptic plasticity --- and considers its importance for nervous system function and disease.},
	author = {Abraham, Wickliffe C.},
	copyright = {2008 Nature Publishing Group},
	doi = {10.1038/nrn2356},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DHZQYXHG/Abraham - 2008 - Metaplasticity tuning synapses and networks for p.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MJYZ9UFI/nrn2356.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = may,
	number = {5},
	pages = {387--387},
	shorttitle = {Metaplasticity},
	title = {Metaplasticity: tuning synapses and networks for plasticity},
	url = {https://www.nature.com/articles/nrn2356},
	urldate = {2019-12-23},
	volume = {9},
	year = {2008},
	bdsk-url-1 = {https://www.nature.com/articles/nrn2356},
	bdsk-url-2 = {https://doi.org/10.1038/nrn2356}}

@article{sambeth_sleeping_2008,
	abstract = {Objective
Behavioral experiments show that infants use both prosodic and statistical cues in acquiring language. However, it is not yet clear whether these prosodic and statistical tools are already present at birth.
Methods
We recorded brain responses of sleeping newborns to natural sounds rich in prosody, namely singing and continuous speech, and to two impoverished manipulations of speech. A total of 11 newborns were presented with continuous speech, singing, and degraded speech, while MEG was recorded.
Results
We found that a brain response elicited to the prosodically rich singing and continuous natural speech conditions decreased dramatically when the prosody in the speech was impoverished.
Conclusions
We claim that this response is the indicator of the infants' sensitivity to prosodic cues in language, which is already present at birth during natural sleep.
Significance
The indicators of detection of prosody may be crucial in assessing the normal and abnormal cortical function in newborns, especially of those infants at-risk for language problems.},
	author = {Sambeth, Anke and Ruohio, Katja and Alku, Paavo and Fellman, Vineta and Huotilainen, Minna},
	doi = {10.1016/j.clinph.2007.09.144},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/BL8EIXX2/S1388245707006451.html:text/html},
	issn = {1388-2457},
	journal = {Clinical Neurophysiology},
	keywords = {Prosody, Newborn, Magnetoencephalography, Continuous speech, Degraded speech},
	language = {en},
	month = feb,
	number = {2},
	pages = {332--341},
	title = {Sleeping newborns extract prosody from continuous speech},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245707006451},
	urldate = {2019-12-23},
	volume = {119},
	year = {2008},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245707006451},
	bdsk-url-2 = {https://doi.org/10.1016/j.clinph.2007.09.144}}

@article{baillet_magnetoencephalography_2017,
	abstract = {Magnetoencephalography (MEG) tracks the millisecond electrical activity of the brain noninvasively. This review emphasizes MEG's unique assets, especially in terms of imaging and resolving the mechanisms underlying the apparent complexity of polyrhythmic brain dynamics. It also identifies practical challenges and clarifies misconceptions about the technique.},
	author = {Baillet, Sylvain},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nn.4504},
	file = {Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf:/Users/Cecile/Zotero/storage/LTJ8DINJ/Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BXNDQWYT/nn.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = mar,
	number = {3},
	pages = {327--339},
	title = {Magnetoencephalography for brain electrophysiology and imaging},
	url = {https://www.nature.com/articles/nn.4504},
	urldate = {2019-12-24},
	volume = {20},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/nn.4504},
	bdsk-url-2 = {https://doi.org/10.1038/nn.4504}}

@article{buzsaki_scaling_2013,
	abstract = {Despite the several-thousand-fold increase of brain volume during the course of mammalian evolution, the hierarchy of brain oscillations remains remarkably preserved, allowing for multiple-time-scale communication within and across neuronal networks at approximately the same speed, irrespective of brain size. Deployment of large-diameter axons of long-range neurons could be a key factor in the preserved time management in growing brains. We discuss the consequences of such preserved network constellation in mental disease, drug discovery, and interventional therapies.},
	author = {Buzs{\'a}ki, Gy{\"o}rgy and Logothetis, Nikos and Singer, Wolf},
	doi = {10.1016/j.neuron.2013.10.002},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/2GXZY6MI/Buzs{\'a}ki et al. - 2013 - Scaling Brain Size, Keeping Timing Evolutionary P.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TKIQ6QCB/S0896627313009045.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	language = {en},
	month = oct,
	number = {3},
	pages = {751--764},
	shorttitle = {Scaling {Brain} {Size}, {Keeping} {Timing}},
	title = {Scaling {Brain} {Size}, {Keeping} {Timing}: {Evolutionary} {Preservation} of {Brain} {Rhythms}},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627313009045},
	urldate = {2019-12-27},
	volume = {80},
	year = {2013},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313009045},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2013.10.002}}

@article{bertolero_modular_2015,
	abstract = {Network-based analyses of brain imaging data consistently reveal distinct modules and connector nodes with diverse global connectivity across the modules. How discrete the functions of modules are, how dependent the computational load of each module is to the other modules' processing, and what the precise role of connector nodes is for between-module communication remains underspecified. Here, we use a network model of the brain derived from resting-state functional MRI (rs-fMRI) data and investigate the modular functional architecture of the human brain by analyzing activity at different types of nodes in the network across 9,208 experiments of 77 cognitive tasks in the BrainMap database. Using an author--topic model of cognitive functions, we find a strong spatial correspondence between the cognitive functions and the network's modules, suggesting that each module performs a discrete cognitive function. Crucially, activity at local nodes within the modules does not increase in tasks that require more cognitive functions, demonstrating the autonomy of modules' functions. However, connector nodes do exhibit increased activity when more cognitive functions are engaged in a task. Moreover, connector nodes are located where brain activity is associated with many different cognitive functions. Connector nodes potentially play a role in between-module communication that maintains the modular function of the brain. Together, these findings provide a network account of the brain's modular yet integrated implementation of cognitive functions.},
	author = {Bertolero, Maxwell A. and Yeo, B. T. Thomas and D'Esposito, Mark},
	doi = {10.1073/pnas.1510619112},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/U9HY462I/Bertolero et al. - 2015 - The modular and integrative functional architectur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S9559MML/E6798.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {graph theory, cognition, hubs, modularity, network},
	language = {en},
	month = dec,
	number = {49},
	pages = {E6798--E6807},
	pmid = {26598686},
	title = {The modular and integrative functional architecture of the human brain},
	url = {https://www.pnas.org/content/112/49/E6798},
	urldate = {2020-01-07},
	volume = {112},
	year = {2015},
	bdsk-url-1 = {https://www.pnas.org/content/112/49/E6798},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1510619112}}

@article{amin_development_2007,
	abstract = {In adult songbirds, auditory neurons in the primary auditory forebrain region of field L and a secondary auditory forebrain region of caudal mesopallium (CM) are highly responsive to natural sounds, such as conspecific song. Because these nuclei are involved in sensory representations of songs, we investigated how their function changes during development. We recorded neural responses to conspecific and tutor song and acoustically matched synthetic sounds in field L and lateral CM (CLM) of urethane-anesthetized juvenile male zebra finches of approximately 35 days of age. At this age, juvenile songbirds are memorizing the songs of their adult tutors but do not yet sing mature song. They are also starting to recognize songs of individual conspecifics. Compared with adult auditory forebrain neurons, juvenile neurons in field L were on average less responsive to auditory stimuli and exhibited less selectivity for natural sounds compared with the synthetic sounds. This developmental effect was more pronounced in the secondary subregions of L1 and L3 than in the primary thalamo-recipient subregion L2 of field L. CLM showed adultlike selectivity for natural sounds. Also, we did not find any evidence of memory for the tutor song in either field L or CLM. We note that the neural development of selective responses to conspecific song in the secondary subregions of field L is correlated with the emergence of individual song preference around 35 days of age. Therefore we suggest that the emergence of natural sound selectivity in field L could be important for the behavioral development of song recognition.},
	author = {Amin, Noopur and Doupe, Allison and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1152/jn.01066.2006},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/XECJCAWN/Amin et al. - 2007 - Development of Selectivity for Natural Sounds in t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UHK2MH37/jn.01066.html:text/html},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	month = may,
	number = {5},
	pages = {3517--3531},
	title = {Development of {Selectivity} for {Natural} {Sounds} in the {Songbird} {Auditory} {Forebrain}},
	url = {https://www.physiology.org/doi/full/10.1152/jn.01066.2006},
	urldate = {2020-01-13},
	volume = {97},
	year = {2007},
	bdsk-url-1 = {https://www.physiology.org/doi/full/10.1152/jn.01066.2006},
	bdsk-url-2 = {https://doi.org/10.1152/jn.01066.2006}}

@incollection{cramer_early_2017,
	abstract = {Vocal communication is critical for life in a wide range of vertebrate species. Mammals, birds, frogs, and fishes rely on auditory processing to perceive the vocal signals of others in the environment and gain social information such as the presence of potential mates or predators. Conspecific vocalizations convey information on sex, age, individual identity, and behavioral state. The importance of vocal communication for social behavior places auditory processing at the forefront of brain functions that directly impact fitness. Young humans and songbirds require experience of adult vocal communication to develop their own perceptual and vocal skills. Studies on songbird vocal development and auditory processing are revealing how early experience and developmental plasticity interact to specialize central auditory function for vocal communication. This chapter reviews research findings that shed light on the role of early song experience in shaping adult song perception and the auditory coding of songs.},
	address = {Cham},
	author = {Woolley, Sarah M. N.},
	booktitle = {Auditory {Development} and {Plasticity}},
	doi = {10.1007/978-3-319-21530-3_8},
	editor = {Cramer, Karina S. and Coffin, Allison B. and Fay, Richard R. and Popper, Arthur N.},
	file = {Woolley - 2017 - Early Experience and Auditory Development in Songb.pdf:/Users/Cecile/Zotero/storage/5LT33744/Woolley - 2017 - Early Experience and Auditory Development in Songb.pdf:application/pdf},
	isbn = {978-3-319-21529-7 978-3-319-21530-3},
	language = {en},
	pages = {193--217},
	publisher = {Springer International Publishing},
	title = {Early {Experience} and {Auditory} {Development} in {Songbirds}},
	url = {http://link.springer.com/10.1007/978-3-319-21530-3_8},
	urldate = {2020-01-17},
	volume = {64},
	year = {2017},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-3-319-21530-3_8},
	bdsk-url-2 = {https://doi.org/10.1007/978-3-319-21530-3_8}}

@article{sanes_behavioral_2011,
	author = {Sanes, Dan H. and Woolley, Sarah M. N.},
	doi = {10.1016/j.neuron.2011.12.005},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/KR43VE8W/Sanes et Woolley - 2011 - A Behavioral Framework to Guide Research on Centra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KNM8K459/S0896-6273(11)01047-6.html:text/html},
	issn = {0896-6273},
	journal = {Neuron},
	language = {English},
	month = dec,
	number = {6},
	pages = {912--929},
	pmid = {22196328},
	title = {A {Behavioral} {Framework} to {Guide} {Research} on {Central} {Auditory} {Development} and {Plasticity}},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(11)01047-6},
	urldate = {2020-01-17},
	volume = {72},
	year = {2011},
	bdsk-url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(11)01047-6},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuron.2011.12.005}}

@book{bregman_auditory_1990,
	abstract = {Auditory Scene Analysis addresses the problem of hearing complex auditory environments, using a series of creative analogies to describe the process required of the human auditory system as it analyzes mixtures of sounds to recover descriptions of individual sounds. In a unified and comprehensive way, Bregman establishes a theoretical framework that integrates his findings with an unusually wide range of previous research in psychoacoustics, speech perception, music theory and composition, and computer modeling.},
	author = {Bregman, Albert S.},
	file = {Snapshot:/Users/Cecile/Zotero/storage/HV3VVEAT/auditory-scene-analysis.html:text/html},
	language = {en},
	publisher = {MIT Press},
	title = {Auditory {Scene} {Analysis}},
	url = {https://mitpress.mit.edu/books/auditory-scene-analysis},
	urldate = {2020-01-20},
	year = {1990},
	bdsk-url-1 = {https://mitpress.mit.edu/books/auditory-scene-analysis}}

@article{andoh_insights_2018,
	abstract = {Non-invasive brain stimulation (NIBS) has been widely used as a research tool to modulate cortical excitability of motor as well as non-motor areas, including auditory or language-related areas. NIBS, especially transcranial magnetic stimulation (TMS) and transcranial direct current stimulation (tDCS), have also been used in clinical settings, with however variable therapeutic outcome, highlighting the need to better understand the mechanisms underlying NIBS techniques. TMS was initially used to address causality between specific brain areas and related behaviour, such as language production, providing non-invasive alternatives to lesion studies. Recent literature however suggests that the relationship is not as straightforward as originally thought, and that TMS can show both linear and non-linear modulation of brain responses, highlighting complex network dynamics. In particular, in the last decade, NIBS studies have enabled further advances in our understanding of auditory processing and its underlying functional organization. For instance, NIBS studies showed that even when only one auditory cortex is stimulated unilaterally, bilateral modulation may result, highlighting the influence of functional connectivity between auditory cortices. Additional neuromodulation techniques such as transcranial alternating current stimulation or transcranial random noise stimulation have been used to target frequency-specific neural oscillations of the auditory cortex, providing further insight into modulation of auditory functions. All these NIBS techniques offer different perspectives into the function and organization of auditory cortex. However, further research should be carried out to assess the mode of action and long-term effects of NIBS to optimize their use in clinical settings.},
	author = {Andoh, Jamila and Matsushita, Reiko and Zatorre, Robert J.},
	doi = {10.3389/fnins.2018.00469},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7VB2CMV4/Andoh et al. - 2018 - Insights Into Auditory Cortex Dynamics From Non-in.pdf:application/pdf},
	issn = {1662-453X},
	journal = {Frontiers in Neuroscience},
	keywords = {asymmetry, Auditory Cortex, Interhemispheric interactions, network dynamics, Non-invasive brain stimulation (NIBS)},
	language = {English},
	title = {Insights {Into} {Auditory} {Cortex} {Dynamics} {From} {Non}-invasive {Brain} {Stimulation}},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00469/full},
	urldate = {2020-01-20},
	volume = {12},
	year = {2018},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00469/full},
	bdsk-url-2 = {https://doi.org/10.3389/fnins.2018.00469}}

@article{pearce_auditory_2012,
	abstract = {Following in a psychological and musicological tradition beginning with Leonard Meyer, and continuing through David Huron, we present a functional, cognitive account of the phenomenon of expectation in music, grounded in computational, probabilistic modeling. We summarize a range of evidence for this approach, from psychology, neuroscience, musicology, linguistics, and creativity studies, and argue that simulating expectation is an important part of understanding a broad range of human faculties, in music and beyond.},
	author = {Pearce, Marcus T. and Wiggins, Geraint A.},
	doi = {10.1111/j.1756-8765.2012.01214.x},
	file = {Pearce et Wiggins - 2012 - Auditory Expectation The Information Dynamics of .pdf:/Users/Cecile/Zotero/storage/RCMWRIY5/Pearce et Wiggins - 2012 - Auditory Expectation The Information Dynamics of .pdf:application/pdf},
	issn = {17568757},
	journal = {Topics in Cognitive Science},
	language = {en},
	month = oct,
	number = {4},
	pages = {625--652},
	shorttitle = {Auditory {Expectation}},
	title = {Auditory {Expectation}: {The} {Information} {Dynamics} of {Music} {Perception} and {Cognition}},
	url = {http://doi.wiley.com/10.1111/j.1756-8765.2012.01214.x},
	urldate = {2020-01-20},
	volume = {4},
	year = {2012},
	bdsk-url-1 = {http://doi.wiley.com/10.1111/j.1756-8765.2012.01214.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1756-8765.2012.01214.x}}

@article{pressnitzer_auditory_2011,
	abstract = {In this review paper aimed at the non-specialist, we explore the use that neuroscientists and musicians have made of perceptual illusions based on ambiguity. The pivotal issue is auditory scene analysis, or what enables us to make sense of complex acoustic mixtures in order to follow, for instance, a single melody in the midst of an orchestra. In general, auditory scene analysis uncovers the most likely physical causes that account for the waveform collected at the ears. However, the acoustical problem is ill-posed and it must be solved from noisy sensory input. Recently, the neural mechanisms implicated in the transformation of ambiguous sensory information into coherent auditory scenes have been investigated using so-called bistability illusions (where an unchanging ambiguous stimulus evokes a succession of distinct percepts in the mind of the listener). After reviewing some of those studies, we turn to music, which arguably provides some of the most complex acoustic scenes that a human listener will ever encounter. Interestingly, musicians will not always aim at making each physical source intelligible, but rather to express one or more melodic lines with a small or large number of instruments. By means of a few musical illustrations and by using a computational model inspired by neuro-physiological principles, we suggest that this relies on a detailed (if perhaps implicit) knowledge of the rules of auditory scene analysis and of its inherent ambiguity. We then put forward the opinion that some degree perceptual ambiguity may participate in our appreciation of music.},
	author = {Pressnitzer, Daniel and Suied, Clara and Shamma, Shihab},
	doi = {10.3389/fnhum.2011.00158},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/BUJ8D6SL/Pressnitzer et al. - 2011 - Auditory scene analysis The sweet music of ambigu.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	keywords = {Auditory Perception, Music, Auditory illusions, bistability, perceptual organization},
	language = {English},
	shorttitle = {Auditory scene analysis},
	title = {Auditory scene analysis: {The} sweet music of ambiguity},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2011.00158/full#h6},
	urldate = {2020-01-25},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2011.00158/full#h6},
	bdsk-url-2 = {https://doi.org/10.3389/fnhum.2011.00158}}

@article{shamma_behind_2010,
	abstract = {``Auditory scenes'' often contain contributions from multiple acoustic sources. These are usually heard as separate auditory ``streams'', which can be selectively followed over time. How and where these auditory streams are formed in the auditory system is one of the most fascinating questions facing auditory scientists today. Findings published within the last two years indicate that both cortical and sub-cortical processes contribute to the formation of auditory streams, and they raise important questions concerning the roles of primary and secondary areas of auditory cortex in this phenomenon. In addition, these findings underline the importance of taking into account the relative timing of neural responses, and the influence of selective attention, in the search for neural correlates of the perception of auditory streams.},
	author = {Shamma, Shihab A and Micheyl, Christophe},
	doi = {10.1016/j.conb.2010.03.009},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/NMUNIPNM/Shamma et Micheyl - 2010 - Behind the Scenes of Auditory Perception.pdf:application/pdf},
	issn = {0959-4388},
	journal = {Current opinion in neurobiology},
	month = jun,
	number = {3},
	pages = {361--366},
	pmcid = {PMC2901988},
	pmid = {20456940},
	title = {Behind the {Scenes} of {Auditory} {Perception}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901988/},
	urldate = {2020-01-25},
	volume = {20},
	year = {2010},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901988/},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2010.03.009}}

@article{bregman_progress_2015,
	abstract = {Skip to Next Section
In this paper, I make the following claims: (1) Subjective experience is tremendously useful in guiding productive research. (2) Studies of auditory scene analysis (ASA) in adults, newborn infants, and non-human animals (e.g., in goldfish or pigeons) establish the generality of ASA and suggest that it has an innate foundation. (3) ASA theory does not favor one musical style over another. (4) The principles used in the composition of polyphony (slightly modified) apply not only to one particular musical style or culture but to any form of layered music. (5) Neural explanations of ASA do not supersede explanations in terms of capacities; the two are complementary. (6) In computational auditory scene analysis (CASA) -- ASA by computer systems -- or any adequate theory of ASA, the most difficult challenge will be to discover how the contributions of a very large number of types of acoustical evidence and top-down schemas (acquired knowledge about the sound sources in our environments), can be coordinated without producing conflict that disables the system. (7) Finally I argue that the movement of a listener within the auditory scene provides him/her/it with rich information that should not be ignored by ASA theorists and researchers.},
	author = {Bregman, Albert S.},
	copyright = {{\copyright} 2015 by The Regents of the University of California},
	doi = {10.1525/mp.2015.33.1.12},
	file = {Snapshot:/Users/Cecile/Zotero/storage/NIKMS3K9/12.html:text/html},
	issn = {0730-7829, 1533-8312},
	journal = {Music Perception: An Interdisciplinary Journal},
	keywords = {infants, auditory perception, music, auditory scene analysis, animal perception, ASA, auditory brain, auditory streaming, CASA},
	language = {en},
	month = sep,
	number = {1},
	pages = {12--19},
	title = {Progress in {Understanding} {Auditory} {Scene} {Analysis}},
	url = {https://mp.ucpress.edu/content/33/1/12},
	urldate = {2020-01-27},
	volume = {33},
	year = {2015},
	bdsk-url-1 = {https://mp.ucpress.edu/content/33/1/12},
	bdsk-url-2 = {https://doi.org/10.1525/mp.2015.33.1.12}}

@article{winkler_newborn_2003,
	abstract = {The perceptual world of neonates is usually regarded as not yet being fully organized in terms of objects in the same way as it is for adults. Using a recently developed method based on electric brain responses, we found that, similarly to adults, newborn infants segregate concurrent streams of sound, allowing them to organize the auditory input according to the existing sound source. The segregation of concurrent sound streams is a crucial step in the path leading to the identification of objects in the environment. Its presence in newborn infants shows that the basic abilities required for the development of conceptual objects are available already at the time of birth.},
	author = {Winkler, Istv{\'a}n and Kushnerenko, Elena and Horv{\'a}th, J{\'a}nos and {\v C}eponien{\.e}, Rita and Fellman, Vineta and Huotilainen, Minna and N{\"a}{\"a}t{\"a}nen, Risto and Sussman, Elyse},
	copyright = {Copyright {\copyright} 2003, The National Academy of Sciences},
	doi = {10.1073/pnas.2031891100},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/9VIFJ7IE/Winkler et al. - 2003 - Newborn infants can organize the auditory world.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/296SJZ4F/11812.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = sep,
	number = {20},
	pages = {11812--11815},
	pmid = {14500903},
	title = {Newborn infants can organize the auditory world},
	url = {https://www.pnas.org/content/100/20/11812},
	urldate = {2020-01-27},
	volume = {100},
	year = {2003},
	bdsk-url-1 = {https://www.pnas.org/content/100/20/11812},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.2031891100}}

@article{demany_auditory_1982,
	abstract = {In a rapid and repeating melodic sequence, S = {\ldots} abcdabcd {\ldots}, adults may perceive, instead of one coherent string of tones, several co-occurring segregated streams (e.g., {\ldots} a-c-a-c- {\ldots} and {\ldots} b-d-b-d- {\ldots}); melodic stream segregation obeys the Gestalt principle of pitch similarity. Can evidence for stream segregation processes be found in young infants? We reasoned that S should be discriminable from its retrogradation, Sr = {\ldots} adcbadcb {\ldots}, if adjacent tones are grouped in the same stream, but not if adjacent tones are systematically assigned to separate streams. Same / different judgments were obtained from adults on various S-Sr pairs. The same pairs of sequences were then presented to 7--15-week-old infants in a habituation / dishabituation paradigm. The discriminative abilities of the adults and infants varied in parallel as a function of changes in the melodic structure of S and Sr. Our results suggest that stream segregation processes governed by Gestalt factors are operative very early in life.},
	author = {Demany, Laurent},
	doi = {10.1016/S0163-6383(82)80036-2},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ZHWYJ9X6/Demany - 1982 - Auditory stream segregation in infancy.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9AMBGECC/S0163638382800362.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	language = {en},
	month = jan,
	number = {2},
	pages = {261--276},
	title = {Auditory stream segregation in infancy},
	url = {http://www.sciencedirect.com/science/article/pii/S0163638382800362},
	urldate = {2020-01-27},
	volume = {5},
	year = {1982},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638382800362},
	bdsk-url-2 = {https://doi.org/10.1016/S0163-6383(82)80036-2}}

@article{rauschecker_maps_2009,
	abstract = {As language is unique to humans, it is usually thought that work in other animals has made limited contributions to understanding it. Authors here review work on species-specific vocalizations in nonhuman primates to arrive at a new model for how human speech is processed.},
	author = {Rauschecker, Josef P. and Scott, Sophie K.},
	copyright = {2009 Nature Publishing Group},
	doi = {10.1038/nn.2331},
	file = {Snapshot:/Users/Cecile/Zotero/storage/6RUPJUKB/nn.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/PWPEZ94R/Rauschecker et Scott - 2009 - Maps and streams in the auditory cortex nonhuman .pdf:application/pdf},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = jun,
	number = {6},
	pages = {718--724},
	shorttitle = {Maps and streams in the auditory cortex},
	title = {Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing},
	url = {https://www.nature.com/articles/nn.2331},
	urldate = {2020-01-27},
	volume = {12},
	year = {2009},
	bdsk-url-1 = {https://www.nature.com/articles/nn.2331},
	bdsk-url-2 = {https://doi.org/10.1038/nn.2331}}

@article{tervaniemi_pitch_2005,
	abstract = {Previously, professional violin players were found to automatically discriminate tiny pitch changes, not discriminable by nonmusicians. The present study addressed the pitch processing accuracy in musicians with expertise in playing a wide selection of instruments (e.g., piano; wind and string instruments). Of specific interest was whether also musicians with such divergent backgrounds have facilitated accuracy in automatic and/or attentive levels of auditory processing. Thirteen professional musicians and 13 nonmusicians were presented with frequent standard sounds and rare deviant sounds (0.8, 2, or 4\% higher in frequency). Auditory event-related potentials evoked by these sounds were recorded while first the subjects read a self-chosen book and second they indicated behaviorally the detection of sounds with deviant frequency. Musicians detected the pitch changes faster and more accurately than nonmusicians. The N2b and P3 responses recorded during attentive listening had larger amplitude in musicians than in nonmusicians. Interestingly, the superiority in pitch discrimination accuracy in musicians over nonmusicians was observed not only with the 0.8\% but also with the 2\% frequency changes. Moreover, also nonmusicians detected quite reliably the smallest pitch changes of 0.8\%. However, the mismatch negativity (MMN) and P3a recorded during a reading condition did not differentiate musicians and nonmusicians. These results suggest that musical expertise may exert its effects merely at attentive levels of processing and not necessarily already at the preattentive levels.},
	author = {Tervaniemi, Mari and Just, Viola and Koelsch, Stefan and Widmann, Andreas and Schr{\"o}ger, Erich},
	doi = {10.1007/s00221-004-2044-5},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/YQLW2RX3/Tervaniemi et al. - 2005 - Pitch discrimination accuracy in musicians vs nonm.pdf:application/pdf},
	issn = {1432-1106},
	journal = {Experimental Brain Research},
	keywords = {Mismatch negativity (MMN), Auditory event-related potentials, Complex sounds, Musical expertise, N2b, P3, P3a, Pitch discrimination},
	language = {en},
	month = feb,
	number = {1},
	pages = {1--10},
	shorttitle = {Pitch discrimination accuracy in musicians vs nonmusicians},
	title = {Pitch discrimination accuracy in musicians vs nonmusicians: an event-related potential and behavioral study},
	url = {https://doi.org/10.1007/s00221-004-2044-5},
	urldate = {2020-01-27},
	volume = {161},
	year = {2005},
	bdsk-url-1 = {https://doi.org/10.1007/s00221-004-2044-5}}

@article{mishra_enhanced_2014,
	abstract = {Many features of auditory perception are positively altered in musicians. Traditionally auditory mechanisms in musicians are investigated using the Western-classical musician model. The objective of the present study was to adopt an alternative model---Indian-classical music---to further investigate auditory temporal processing in musicians. This study presents that musicians have significantly lower across-channel gap detection thresholds compared to nonmusicians. Use of the South Indian musician model provides an increased external validity for the prediction, from studies on Western-classical musicians, that auditory temporal coding is enhanced in musicians.},
	author = {Mishra, Srikanta K. and Panda, Manas R. and Herbert, Carolyn},
	doi = {10.1121/1.4890207},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/HBDVIEJW/Mishra et al. - 2014 - Enhanced auditory temporal gap detection in listen.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H6U6RMVP/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = jul,
	number = {2},
	pages = {EL173--EL178},
	title = {Enhanced auditory temporal gap detection in listeners with musical training},
	url = {https://asa.scitation.org/doi/10.1121/1.4890207},
	urldate = {2020-01-27},
	volume = {136},
	year = {2014},
	bdsk-url-1 = {https://asa.scitation.org/doi/10.1121/1.4890207},
	bdsk-url-2 = {https://doi.org/10.1121/1.4890207}}

@article{nieder_neurobiology_2020,
	abstract = {Vocalization is an ancient vertebrate trait essential to many forms of communication, ranging from courtship calls to free verse. Vocalizations may be entirely innate and evoked by sexual cues or emotional state, as with many types of calls made in primates, rodents and birds; volitional, as with innate calls that, following extensive training, can be evoked by arbitrary sensory cues in non-human primates and corvid songbirds; or learned, acoustically flexible and complex, as with human speech and the courtship songs of oscine songbirds. This review compares and contrasts the neural mechanisms underlying innate, volitional and learned vocalizations, with an emphasis on functional studies in primates, rodents and songbirds. This comparison reveals both highly conserved and convergent mechanisms of vocal production in these different groups, despite their often vast phylogenetic separation. This similarity of central mechanisms for different forms of vocal production presents experimentalists with useful avenues for gaining detailed mechanistic insight into how vocalizations are employed for social and sexual signalling, and how they can be modified through experience to yield new vocal repertoires customized to the individual's social group.This article is part of the theme issue `What can animal communication teach us about human language?'},
	author = {Nieder, Andreas and Mooney, Richard},
	doi = {10.1098/rstb.2019.0054},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4MM4D3AD/Nieder et Mooney - 2020 - The neurobiology of innate, volitional and learned.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HK9ETB9L/rstb.2019.html:text/html},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	month = jan,
	number = {1789},
	pages = {20190054},
	title = {The neurobiology of innate, volitional and learned vocalizations in mammals and birds},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0054},
	urldate = {2020-01-28},
	volume = {375},
	year = {2020},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0054},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2019.0054}}

@article{tyack_taxonomy_2020,
	abstract = {Humans and songbirds learn to sing or speak by listening to acoustic models, forming auditory templates, and then learning to produce vocalizations that match the templates. These taxa have evolved specialized telencephalic pathways to accomplish this complex form of vocal learning, which has been reported for very few other taxa. By contrast, the acoustic structure of most animal vocalizations is produced by species-specific vocal motor programmes in the brainstem that do not require auditory feedback. However, many mammals and birds can learn to fine-tune the acoustic features of inherited vocal motor patterns based upon listening to conspecifics or noise. These limited forms of vocal learning range from rapid alteration based on real-time auditory feedback to long-term changes of vocal repertoire and they may involve different mechanisms than complex vocal learning. Limited vocal learning can involve the brainstem, mid-brain and/or telencephalic networks. Understanding complex vocal learning, which underpins human speech, requires careful analysis of which species are capable of which forms of vocal learning. Selecting multiple animal models for comparing the neural pathways that generate these different forms of learning will provide a richer view of the evolution of complex vocal learning and the neural mechanisms that make it possible.This article is part of the theme issue `What can animal communication teach us about human language?'},
	author = {Tyack, Peter L.},
	doi = {10.1098/rstb.2018.0406},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/5MFGAYZV/Tyack - 2020 - A taxonomy for vocal learning.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MUIQJMZC/rstb.2018.html:text/html},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	month = jan,
	number = {1789},
	pages = {20180406},
	title = {A taxonomy for vocal learning},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2018.0406},
	urldate = {2020-01-30},
	volume = {375},
	year = {2020},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2018.0406},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2018.0406}}

@article{fishbein_sound_2020,
	abstract = {The complex and melodic nature of many birds' songs has raised interest in potential parallels between avian vocal sequences and human speech. The similarities between birdsong and speech in production and learning are well established, but surprisingly little is known about how birds perceive song sequences. One popular laboratory songbird, the zebra finch (Taeniopygia guttata), has recently attracted attention as an avian model for human speech, in part because the male learns to produce the individual elements in its song motif in a fixed sequence. But psychoacoustic evidence shows that adult zebra finches are relatively insensitive to the sequential features of song syllables. Instead, zebra finches and other birds seem to be exquisitely sensitive to the acoustic details of individual syllables to a degree that is beyond human hearing capacity. Based on these findings, we present a finite-state model of zebra finch perception of song syllable sequences and discuss the rich informational capacity of their vocal system. Furthermore, we highlight the abilities of budgerigars (Melopsittacus undulatus), a parrot species, to hear sequential features better than zebra finches and suggest that neurophysiological investigations comparing these species could prove fruitful for uncovering neural mechanisms for auditory sequence perception in human speech.This article is part of the theme issue `What can animal communication teach us about human language?'},
	author = {Fishbein, Adam R. and Idsardi, William J. and Ball, Gregory F. and Dooling, Robert J.},
	doi = {10.1098/rstb.2019.0044},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/TBH52ZBA/Fishbein et al. - 2020 - Sound sequences in birdsong how much do birds rea.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DEUK9FUX/rstb.2019.html:text/html},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	month = jan,
	number = {1789},
	pages = {20190044},
	shorttitle = {Sound sequences in birdsong},
	title = {Sound sequences in birdsong: how much do birds really care?},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	urldate = {2020-02-07},
	volume = {375},
	year = {2020},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2019.0044}}

@article{doupe_birdsong_1999,
	abstract = {Human speech and birdsong have numerous parallels. Both humans and songbirds learn their complex vocalizations early in life, exhibiting a strong dependence on hearing the adults they will imitate, as well as themselves as they practice, and a waning of this dependence as they mature. Innate predispositions for perceiving and learning the correct sounds exist in both groups, although more evidence of innate descriptions of species-specific signals exists in songbirds, where numerous species of vocal learners have been compared. Humans also share with songbirds an early phase of learning that is primarily perceptual, which then serves to guide later vocal production. Both humans and songbirds have evolved a complex hierarchy of specialized forebrain areas in which motor and auditory centers interact closely, and which control the lower vocal motor areas also found in nonlearners. In both these vocal learners, however, how auditory feedback of self is processed in these brain areas is surprisingly unclear. Finally, humans and songbirds have similar critical periods for vocal learning, with a much greater ability to learn early in life. In both groups, the capacity for late vocal learning may be decreased by the act of learning itself, as well as by biological factors such as the hormones of puberty. Although some features of birdsong and speech are clearly not analogous, such as the capacity of language for meaning, abstraction, and flexible associations, there are striking similarities in how sensory experience is internalized and used to shape vocal outputs, and how learning is enhanced during a critical period of development. Similar neural mechanisms may therefore be involved.},
	author = {Doupe, Allison J. and Kuhl, Patricia K.},
	doi = {10.1146/annurev.neuro.22.1.567},
	file = {Doupe et Kuhl - 1999 - BIRDSONG AND HUMAN SPEECH Common Themes and Mecha.pdf:/Users/Cecile/Zotero/storage/WHLPTCMW/Doupe et Kuhl - 1999 - BIRDSONG AND HUMAN SPEECH Common Themes and Mecha.pdf:application/pdf},
	journal = {Annual Review of Neuroscience},
	number = {1},
	pages = {567--631},
	pmid = {10202549},
	shorttitle = {{BIRDSONG} {AND} {HUMAN} {SPEECH}},
	title = {{BIRDSONG} {AND} {HUMAN} {SPEECH}: {Common} {Themes} and {Mechanisms}},
	url = {https://doi.org/10.1146/annurev.neuro.22.1.567},
	urldate = {2020-02-07},
	volume = {22},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1146/annurev.neuro.22.1.567}}

@article{schumacher_vocal_nodate,
	author = {Schumacher, Joseph W and Woolley, Sarah M N},
	file = {Schumacher et Woolley - Vocal tutoring drives rapid tuning of neurons in t.pdf:/Users/Cecile/Zotero/storage/C4PK8HAM/Schumacher et Woolley - Vocal tutoring drives rapid tuning of neurons in t.pdf:application/pdf},
	language = {en},
	pages = {41},
	title = {Vocal tutoring drives rapid tuning of neurons in the auditory cortex}}

@article{keller_neural_2009,
	abstract = {Living in noisy colonies, songbird vocal learning requires individuals to differentiate self-generated vocalizations from other sound sources to accurately match the learned song template. However, neurons responding to vocal output have not been identified. This study identifies neurons in the auditory forebrain of zebra finch that specifically responded to either song or playback perturbations, suggesting the existence of a computational error-checking function in the forebrain auditory areas.},
	author = {Keller, Georg B. and Hahnloser, Richard H. R.},
	copyright = {2008 Macmillan Publishers Limited. All rights reserved},
	doi = {10.1038/nature07467},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DEXLEPNH/Keller et Hahnloser - 2009 - Neural processing of auditory feedback during voca.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CPETINXZ/nature07467.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = jan,
	number = {7226},
	pages = {187--190},
	title = {Neural processing of auditory feedback during vocal practice in a songbird},
	url = {https://www.nature.com/articles/nature07467},
	urldate = {2020-02-08},
	volume = {457},
	year = {2009},
	bdsk-url-1 = {https://www.nature.com/articles/nature07467},
	bdsk-url-2 = {https://doi.org/10.1038/nature07467}}

@article{hough_short-term_2002,
	abstract = {Adult zebra finch song is irreversibly altered when birds are deprived of correct feedback by deafening or denervation of the syrinx. To clarify the role of feedback in song maintenance, we developed a reversible technique to distort vocal output without damaging the auditory or vocal systems. We implanted flexible beads adjacent to the syrinx to alter its biomechanics. Immediate song aberrations included low volume, frequency shifts, missing harmonics, and production of click-like syllables. After a few weeks, seven of nine birds stopped producing some syllables. In six of these birds, the gaps left by the silenced syllables gradually shortened, and the lost syllables did not return when beads were removed 16 weeks after treatment began. The nondeleted syllables of all birds regained their preimplant morphology, insofar as could be detected, within 9 d after bead removal. In four other birds, we removed the beads as soon as syllables were deleted, when the silent intervals were still full length. In these birds, all deleted syllables returned within 1 week. Our results indicate that both silenced syllables and syllable morphology can recover as long as the song's temporal structure is maintained, but once altered, changes in the song sequence can be permanent. A hierarchical organization of the song production system has recently been described (). Reversible disruption of song production by our method appears to permanently alter the higher levels of the system that encode song sequence, but not the lower levels that encode individual syllable structure.},
	author = {Hough, Gerald E. and Volman, Susan F.},
	doi = {10.1523/JNEUROSCI.22-03-01177.2002},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Y27T7RPW/Hough et Volman - 2002 - Short-Term and Long-Term Effects of Vocal Distorti.pdf:application/pdf},
	issn = {0270-6474},
	journal = {The Journal of Neuroscience},
	month = feb,
	number = {3},
	pages = {1177--1186},
	pmcid = {PMC6758533},
	pmid = {11826147},
	title = {Short-{Term} and {Long}-{Term} {Effects} of {Vocal} {Distortion} on {Song} {Maintenance} in {Zebra} {Finches}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6758533/},
	urldate = {2020-02-08},
	volume = {22},
	year = {2002},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6758533/},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.22-03-01177.2002}}

@techreport{yamahachi_welfare_2017,
	abstract = {Over the past 50 years, songbirds have become a valuable model organism for scientists studying vocal communication from its behavioral, hormonal, neuronal, and genetic perspectives. Many advances in our understanding of vocal learning result from research using the zebra finch, a close-ended vocal learner. We review some of the manipulations used in zebra finch research, such as isolate housing, transient/irreversible impairment of hearing/vocal organs, implantation of small devices for chronic electrophysiology, head fixation for imaging, aversive song conditioning using sound playback, and mounting of miniature backpacks for behavioral monitoring. We highlight the use of these manipulations in scientific research, and estimate their impact on animal welfare, based on the literature and on data from our past and ongoing work. The assessment of harm-benefits tradeoffs is a legal prerequisite for animal research in Switzerland. We conclude that a diverse set of known stressors reliably lead to suppressed singing rate, and that by contraposition, increased singing rate may be a useful indicator of welfare. We hope that our study can contribute to answering some of the most burning questions about zebra finch welfare in research on vocal behaviors.},
	author = {Yamahachi, Homare and Zai, Anja T. and Tachibana, Ryosuke O. and Stepien, Anna E. and Rodrigues, Diana I. and Cav{\'e}-Lopez, Sophie and Narula, Gagan and Lee, Juneseung and Huang, Ziqiang and H{\"o}rster, Heiko and D{\"u}ring, Daniel and Hahnloser, Richard H. R.},
	doi = {10.1101/154567},
	file = {Yamahachi et al. - 2017 - Welfare of zebra finches used in research.pdf:/Users/Cecile/Zotero/storage/FGFLRTKY/Yamahachi et al. - 2017 - Welfare of zebra finches used in research.pdf:application/pdf},
	institution = {Animal Behavior and Cognition},
	language = {en},
	month = jun,
	title = {Welfare of zebra finches used in research},
	type = {preprint},
	url = {http://biorxiv.org/lookup/doi/10.1101/154567},
	urldate = {2020-02-08},
	year = {2017},
	bdsk-url-1 = {http://biorxiv.org/lookup/doi/10.1101/154567},
	bdsk-url-2 = {https://doi.org/10.1101/154567}}

@article{brown_air_2006,
	abstract = {Air sac cannulas are indicated in birds with upper respiratory obstruction or for ventilation during surgical procedures involving the head and neck. Proper technique, knowledge of potential complications, and an understanding of the indications for air sac tube placement are important for scientists, veterinarians, and technicians who work with birds.},
	author = {Brown, Cyndi and Pilny, Anthony A.},
	copyright = {2006 Nature Publishing Group},
	doi = {10.1038/laban0706-23},
	file = {Snapshot:/Users/Cecile/Zotero/storage/TTL7PNFM/laban0706-23.html:text/html},
	issn = {1548-4475},
	journal = {Lab Animal},
	language = {en},
	month = jul,
	number = {7},
	pages = {23--24},
	title = {Air sac cannula placement in birds},
	url = {https://www.nature.com/articles/laban0706-23},
	urldate = {2020-02-08},
	volume = {35},
	year = {2006},
	bdsk-url-1 = {https://www.nature.com/articles/laban0706-23},
	bdsk-url-2 = {https://doi.org/10.1038/laban0706-23}}

@article{phan_early_2006,
	abstract = {In both humans and songbirds, infants learn vocalizations by imitating the sounds of adult tutors with whom they interact during an early sensitive period. Vocal learning occurs in few animal taxa; similarities in the imitation process between humans and songbirds make the songbird a unique system in which vocal learning mechanisms can be studied at the neurobiological level. One theory of vocal learning proposes that early auditory experience generates auditory memories that subsequently guide vocal imitation. We now present a combination of behavioral and neurophysiological results, obtained in a songbird, that support this theory. We show that neurons in a forebrain auditory area of adult male zebra finches are selectively tuned to the song of a tutor heard early in development. Furthermore, the strength of this selectivity shows a striking correlation with the fidelity of vocal imitation, suggesting that this auditory memory may have served as the model for song learning.},
	author = {Phan, Mimi L. and Pytte, Carolyn L. and Vicario, David S.},
	copyright = {Copyright {\copyright} 2006, The National Academy of Sciences. Freely available online through the PNAS open access option.},
	doi = {10.1073/pnas.0510136103},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T4YJT4SA/Phan et al. - 2006 - Early auditory experience generates long-lasting m.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J2JE9CBZ/1088.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {development, electrophysiology, caudal medial nidopallium, memory, zebra finch},
	language = {en},
	month = jan,
	number = {4},
	pages = {1088--1093},
	pmid = {16418265},
	title = {Early auditory experience generates long-lasting memories that may subserve vocal learning in songbirds},
	url = {https://www.pnas.org/content/103/4/1088},
	urldate = {2020-02-11},
	volume = {103},
	year = {2006},
	bdsk-url-1 = {https://www.pnas.org/content/103/4/1088},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0510136103}}

@article{kelley_generation_2020,
	abstract = {In many species, vocal communication is essential for coordinating social behaviors including courtship, mating, parenting, rivalry, and alarm signaling. Effective communication requires accurate production, detection, and classification of signals, as well as selection of socially appropriate responses. Understanding how signals are generated and how acoustic signals are perceived is key to understanding the neurobiology of social behaviors. Here we review our long-standing research program focused on Xenopus, a frog genus which has provided valuable insights into the mechanisms and evolution of vertebrate social behaviors. In Xenopus laevis, vocal signals differ between the sexes, through development, and across the genus, reflecting evolutionary divergence in sensory and motor circuits that can be interrogated mechanistically. Using two ex vivo preparations, the isolated brain and vocal organ, we have identified essential components of the vocal production system: the sexually differentiated larynx at the periphery, and the hindbrain vocal central pattern generator (CPG) centrally, that produce sex- and species-characteristic sound pulse frequencies and temporal patterns, respectively. Within the hindbrain, we have described how intrinsic membrane properties of neurons in the vocal CPG generate species-specific vocal patterns, how vocal nuclei are connected to generate vocal patterns, as well as the roles of neurotransmitters and neuromodulators in activating the circuit. For sensorimotor integration, we identified a key forebrain node that links auditory and vocal production circuits to match socially appropriate vocal responses to acoustic features of male and female calls. The availability of a well supported phylogeny as well as reference genomes from several species now support analysis of the genetic architecture and the evolutionary divergence of neural circuits for vocal communication. Xenopus thus provides a vertebrate model in which to study vocal communication at many levels, from physiology, to behavior, and from development to evolution. As one of the most comprehensively studied phylogenetic groups within vertebrate vocal communication systems, Xenopus provides insights that can inform social communication across phyla.},
	author = {Kelley, Darcy B. and Ballagh, Irene H. and Barkan, Charlotte L. and Bendesky, Andres and Elliott, Taffeta M. and Evans, Ben J. and Hall, Ian C. and Kwon, Young Mi and Kwong-Brown, Ursula and Leininger, Elizabeth C. and Perez, Emilie C. and Rhodes, Heather J. and Villain, Avelyne and Yamaguchi, Ayako and Zornik, Erik},
	copyright = {Copyright {\copyright} 2020 the authors},
	doi = {10.1523/JNEUROSCI.0736-19.2019},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/H7ZGWF64/Kelley et al. - 2020 - Generation, Coordination, and Evolution of Neural .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GEBBY4MU/22.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {CPG, duets, hindbrain, neuroendocrine, parabrachial, song},
	language = {en},
	month = jan,
	number = {1},
	pages = {22--36},
	pmid = {31896561},
	title = {Generation, {Coordination}, and {Evolution} of {Neural} {Circuits} for {Vocal} {Communication}},
	url = {https://www.jneurosci.org/content/40/1/22},
	urldate = {2020-02-11},
	volume = {40},
	year = {2020},
	bdsk-url-1 = {https://www.jneurosci.org/content/40/1/22},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.0736-19.2019}}

@article{santolin_role_2019,
	abstract = {Speech preferences emerge very early in infancy, pointing to a special status for speech in auditory processing and a crucial role of prosody in driving infant preferences. Recent theoretical models suggest that infant auditory perception may initially encompass a broad range of human and nonhuman vocalizations, then tune in to relevant sounds for the acquisition of species-specific communication sounds. However, little is known about sound properties eliciting infants' tuning-in to speech. To address this issue, we presented a group of 4-month-olds with segments of non-native speech (Mandarin Chinese) and birdsong, a nonhuman vocalization that shares some prosodic components with speech. A second group of infants was presented with the same segment of birdsong paired with Mandarin played in reverse. Infants showed an overall preference for birdsong over non-native speech. Moreover, infants in the Backward condition preferred birdsong over backward speech whereas infants in the Forward condition did not show clear preference. These results confirm the prominent role of prosody in early auditory processing and suggest that infants' preferences may privilege communicative vocalizations featured by certain prosodic dimensions regardless of the biological source of the sound, human or nonhuman.},
	annote = {*},
	author = {Santolin, Chiara and Russo, Sofia and Calignano, Giulia and Saffran, Jenny R. and Valenza, Eloisa},
	copyright = {{\copyright} International Congress of Infant Studies (ICIS)},
	date-modified = {2022-04-05 16:56:36 +0200},
	doi = {10.1111/infa.12295},
	file = {Santolin et al. - 2019 - The role of prosody in infants' preference for spe.pdf:/Users/Cecile/Zotero/storage/9NRXA4WU/Santolin et al. - 2019 - The role of prosody in infants' preference for spe.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7GZ3I4XP/infa.html:text/html},
	issn = {1532-7078},
	journal = {Infancy},
	language = {en},
	number = {5},
	pages = {827--833},
	shorttitle = {The role of prosody in infants' preference for speech},
	title = {The role of prosody in infants' preference for speech: {A} comparison between speech and birdsong},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12295},
	urldate = {2020-02-13},
	volume = {24},
	year = {2019},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12295},
	bdsk-url-2 = {https://doi.org/10.1111/infa.12295}}

@article{brainard_contributions_2004,
	abstract = {The anterior forebrain pathway (AFP) is a basal ganglia-dorsal forebrain circuit that is prominent specifically in birds that learn to sing. This circuit is interconnected with the song motor pathway, is active during song production, and contains neurons that are selective for the sound of the bird's own song, suggesting an important role for the AFP in vocal behavior. However, interruption of the AFP by lesions in adult birds has little overt effect on the production of learned song. In contrast, lesions in juvenile birds prevent the normal progression of song learning. Moreover, lesions in adults, while not disrupting production, can prevent experience-dependent plasticity of song. Such data implicate the AFP specifically in song learning and vocal plasticity. This chapter reviews some of the experimental evidence supporting a role for the AFP in these processes and discusses potential instructive and permissive functions of the AFP in vocal plasticity.},
	author = {Brainard, Michael S.},
	doi = {10.1196/annals.1298.042},
	issn = {0077-8923},
	journal = {Annals of the New York Academy of Sciences},
	keywords = {Animals, Attention, Learning, Models, Biological, Psychomotor Performance, Vocalization, Animal, Feedback, Motivation, Prosencephalon, Songbirds},
	language = {eng},
	month = jun,
	pages = {377--394},
	pmid = {15313786},
	title = {Contributions of the anterior forebrain pathway to vocal plasticity},
	volume = {1016},
	year = {2004},
	bdsk-url-1 = {https://doi.org/10.1196/annals.1298.042}}

@article{perkel_origin_2004,
	abstract = {Abstract: The brain nuclei and pathways comprising the song system of oscine songbirds bear many similarities with circuits in other bird species and in mammals. This suggests that the song system evolved as a specialization of pre-existing circuits and may retain fundamental properties in common with those of other taxa. Here we review evidence for these similarities, including electrophysiological, morphological, and neurochemical data for identifying specific cell types. In addition, we discuss connectional data, addressing similarities in axonal projections among nuclei across taxa. We focus primarily on the anterior forebrain pathway, a circuit essential for song learning and vocal plasticity, because the evidence is strongest that this circuit is homologous to mammalian circuits. These fundamental similarities highlight the importance of comparative approaches; for example, understanding the role the anterior forebrain pathway plays in song plasticity may shed light on general principles of basal ganglia function. In addition, understanding specializations of such circuits in songbirds may illuminate specific innovations critical for vocal learning.},
	author = {Perkel, David J.},
	doi = {10.1196/annals.1298.039},
	file = {Snapshot:/Users/Cecile/Zotero/storage/76N2YE5Y/annals.1298.html:text/html},
	issn = {0077-8923},
	journal = {Annals of the New York Academy of Sciences},
	keywords = {basal ganglia, comparative neurobiology, evolution, striatum},
	month = jun,
	number = {1},
	pages = {736--748},
	title = {Origin of the {Anterior} {Forebrain} {Pathway}},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.039},
	urldate = {2020-02-13},
	volume = {1016},
	year = {2004},
	bdsk-url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.039},
	bdsk-url-2 = {https://doi.org/10.1196/annals.1298.039}}

@article{brainard_auditory_2000,
	abstract = {Songbirds are one of the best-studied examples of vocal learners. Learning of both human speech and birdsong depends on hearing. Once learned, adult song in many species remains unchanging, suggesting a reduced influence of sensory experience. Recent studies have revealed, however, that adult song is not always stable, extending our understanding of the mechanisms involved in song maintenance, and their similarity to those active during song learning. Here we review some of the processes that contribute to song learning and production, with an emphasis on the role of auditory feedback. We then consider some of the possible neural substrates involved in these processes, particularly basal ganglia circuitry. Although a thorough treatment of human speech is beyond the scope of this article, we point out similarities between speech and song learning, and ways in which studies of these disparate behaviours complement each other in developing an understanding of general principles that contribute to learning and maintenance of vocal behaviour.},
	author = {Brainard, Michael S. and Doupe, Allison J.},
	copyright = {2000 Macmillan Magazines Ltd.},
	doi = {10.1038/35036205},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CBGZX6Q4/Brainard et Doupe - 2000 - Auditory feedback in learning and maintenance of v.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CYI4J24U/35036205.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = oct,
	number = {1},
	pages = {31--40},
	title = {Auditory feedback in learning and maintenance of vocal behaviour},
	url = {https://www.nature.com/articles/35036205},
	urldate = {2020-02-14},
	volume = {1},
	year = {2000},
	bdsk-url-1 = {https://www.nature.com/articles/35036205},
	bdsk-url-2 = {https://doi.org/10.1038/35036205}}

@article{theunissen_song_2004,
	abstract = {Abstract: The sensorimotor neurons found in the song-system nuclei are responsive to the sounds of the bird's own song. This selectivity emerges during vocal learning and appears to follow the development of the bird's song vocalization in two ways: at each stage, the neurons are most selective for the bird's current vocalizations and this selectivity increases as the bird learns to produce a stable adult song. Also, because of their location in the sensori-vocal pathway and because their physiological properties are correlated with the motor program, it is postulated that these neurons play a crucial role in interpreting the auditory feedback during song to preserve a desirable vocal output. The neurons found in presynaptic auditory areas lack this selectivity for the bird's own song. Auditory neurons in the secondary auditory areas caudal nidopallium and caudal mesopallium show specific responses to familiar songs or behaviorally relevant songs. These auditory areas might therefore be involved in perceptual tasks. Neurons in the primary forebrain auditory area are selective for the spectrotemporal modulations that are common in song, yielding an efficient neural representation of those sounds. Neurons that are particularly selective for the tutor song at the end of the sensory period have not yet been described in any areas. Although these three levels of selectivity found in the primary auditory forebrain areas, the secondary auditory forebrain areas, and the song system suggest a form of hierarchical sensory processing, the functional connectivity between these areas and the mechanisms generating the specific selectivity for songs that are behaviorally relevant or crucial in song learning and production have yet to be revealed.},
	author = {Theunissen, Fr{\'e}d{\'e}ric E. and Amin, Noopur and Shaevitz, Sarita S. and Woolley, Sarah M. N. and Fremouw, Thane and Hauber, Mark E.},
	doi = {10.1196/annals.1298.023},
	file = {Snapshot:/Users/Cecile/Zotero/storage/VZ72LJ83/annals.1298.html:text/html},
	issn = {0077-8923},
	journal = {Annals of the New York Academy of Sciences},
	keywords = {auditory cortex, natural sounds, vocalizations},
	month = jun,
	number = {1},
	pages = {222--245},
	title = {Song {Selectivity} in the {Song} {System} and in the {Auditory} {Forebrain}},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.023},
	urldate = {2020-02-14},
	volume = {1016},
	year = {2004},
	bdsk-url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.023},
	bdsk-url-2 = {https://doi.org/10.1196/annals.1298.023}}

@article{morillon_motor_2017,
	abstract = {In behavior, action and perception are inherently interdependent. However, the actual mechanistic contributions of the motor system to sensory processing are unknown. We present neurophysiological evidence that the motor system is involved in predictive timing, a brain function that aligns temporal fluctuations of attention with the timing of events in a task-relevant stream, thus facilitating sensory selection and optimizing behavior. In a magnetoencephalography experiment involving auditory temporal attention, participants had to disentangle two streams of sound on the unique basis of endogenous temporal cues. We show that temporal predictions are encoded by interdependent delta and beta neural oscillations originating from the left sensorimotor cortex, and directed toward auditory regions. We also found that overt rhythmic movements improved the quality of temporal predictions and sharpened the temporal selection of relevant auditory information. This latter behavioral and functional benefit was associated with increased signaling of temporal predictions in right-lateralized frontoparietal associative regions. In sum, this study points at a covert form of auditory active sensing. Our results emphasize the key role of motor brain areas in providing contextual temporal information to sensory regions, driving perceptual and behavioral selection.},
	author = {Morillon, Benjamin and Baillet, Sylvain},
	copyright = {{\copyright} . http://www.pnas.org/site/misc/userlicense.xhtml},
	doi = {10.1073/pnas.1705373114},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/2E3VDNEI/Morillon et Baillet - 2017 - Motor origin of temporal predictions in auditory a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YDBHTITD/E8913.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {magnetoencephalography, auditory perception, rhythm, psychophysics, sensorimotor},
	language = {en},
	month = oct,
	number = {42},
	pages = {E8913--E8921},
	pmid = {28973923},
	title = {Motor origin of temporal predictions in auditory attention},
	url = {https://www.pnas.org/content/114/42/E8913},
	urldate = {2020-02-24},
	volume = {114},
	year = {2017},
	bdsk-url-1 = {https://www.pnas.org/content/114/42/E8913},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.1705373114}}

@article{mizuhara_songbirds_2020,
	abstract = {Songbirds as vocal learners have been one of the most popular model species to investigate the biological prerequisite to human language. Their songs consist of syllables, which appear as pulse trains in sound spectrograms. When describing the song sequence, researchers consider the syllable to be the unit of the song. Moreover, artificial grammar learning studies asking whether songbirds recognize structural regularities observed in human language often design stimuli using song syllables as components. However, whether syllables are perceptual units is yet to be determined. We found that Bengalese finches, a species of songbird, responded significantly less to one specific syllable when it was temporally placed close to the preceding syllable. The proximity, or silent interval was within the range of what is produced in the natural songs of both Bengalese and zebra finches, and what has been used in other artificial grammar learning studies using zebra finches. Our results suggest the need for a reinterpretation of the description of birdsong structure and of previous artificial grammar learning studies.},
	author = {Mizuhara, Tomoko and Okanoya, Kazuo},
	doi = {10.1016/j.beproc.2020.104089},
	file = {Mizuhara et Okanoya - 2020 - Do songbirds hear songs syllable by syllable.pdf:/Users/Cecile/Zotero/storage/RGDKU5B7/Mizuhara et Okanoya - 2020 - Do songbirds hear songs syllable by syllable.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/37K4BVJT/S0376635719302669.html:text/html},
	issn = {0376-6357},
	journal = {Behavioural Processes},
	keywords = {Songbirds, Artificial grammar learning, Operant conditioning, Syllable perception},
	language = {en},
	month = may,
	pages = {104089},
	title = {Do songbirds hear songs syllable by syllable?},
	url = {http://www.sciencedirect.com/science/article/pii/S0376635719302669},
	urldate = {2020-02-28},
	volume = {174},
	year = {2020},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0376635719302669},
	bdsk-url-2 = {https://doi.org/10.1016/j.beproc.2020.104089}}

@article{karen_cerebral_2019,
	author = {Karen, Tanja and Kleiser, Stefan and Ostojic, Daniel and Isler, Helene and Guglielmini, Sabino and Bassler, Dirk and Wolf, Martin and Scholkmann, Felix},
	doi = {10.1117/1.NPh.6.4.045005},
	file = {Karen et al. - 2019 - Cerebral hemodynamic responses in preterm-born neo.pdf:/Users/Cecile/Zotero/storage/LKGCU6SP/Karen et al. - 2019 - Cerebral hemodynamic responses in preterm-born neo.pdf:application/pdf},
	issn = {2329-423X},
	journal = {Neurophotonics},
	language = {en},
	month = nov,
	number = {04},
	pages = {1},
	shorttitle = {Cerebral hemodynamic responses in preterm-born neonates to visual stimulation},
	title = {Cerebral hemodynamic responses in preterm-born neonates to visual stimulation: classification according to subgroups and analysis of frontotemporal--occipital functional connectivity},
	url = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-6/issue-04/045005/Cerebral-hemodynamic-responses-in-preterm-born-neonates-to-visual-stimulation/10.1117/1.NPh.6.4.045005.full},
	urldate = {2020-03-05},
	volume = {6},
	year = {2019},
	bdsk-url-1 = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-6/issue-04/045005/Cerebral-hemodynamic-responses-in-preterm-born-neonates-to-visual-stimulation/10.1117/1.NPh.6.4.045005.full},
	bdsk-url-2 = {https://doi.org/10.1117/1.NPh.6.4.045005}}

@article{vates_auditory_1996,
	abstract = {Auditory information is critical for vocal imitation and other elements of social life in songbirds. In zebra finches, neural centers that are necessary for the acquisition and production of learned vocalizations are known, and they all respond to acoustic stimulation. However, the circuits by which conspecific auditory signals are perceived, processed, and stored in long-term memory have not been well documented. In particular, no evidence exists of direct connections between auditory and vocal motor pathways, and two newly identified centers for auditory processing, caudomedial neostriatum (Ncm) and caudomedial hyperstriatum ventrale (cmHV), have no documented place among known auditory circuits. Our goal was to describe anatomically the auditory pathways in adult zebra finch males and, specifically, to show the projections by which Ncm and vocal motor centers may receive auditory input. By using injections of different kinds of neuroanatomical tracers (biotinylated dextran amines, rhodamine-linked dextran amines, biocytin, fluorogold, and rhodamine-linked latex beads), we have shown that, as in other avian groups, the neostriatal field L complex in caudal telencephalon is the primary forebrain relay for pathways originating in the auditory thalamus, i.e., the nucleus ovoidalis complex (Ov). In addition, Ncm and cmHV also receive input from the Ov complex. Ov has been broken down into two parts, the Ov ``core'' and ``shell,'' which project in parallel to different targets in the caudal telencephalon. Parts of the field L complex are connected among themselves and to Ncm, cmHV, and caudolateral HV (cIHV) through a complex web of largely reciprocal pathways. In addition, cIHV and parts of the field L complex project strongly to the ``shelf'' of neostriatum underneath the song control nucleus high vocal center (HVC) and to the ``cup'' of archistriatum rostrodorsal to another song-control nucleus, the robust nucleus of the archistriatum (RA). We have documented two points at which the vocal motor pathway may pick up auditory signals: the HVC-shelf interface and a projection from cIHV to the nucleus interfacialis (NIf), which projects to HVC. These data represent the most complete survey to date of auditory pathways in the adult male zebra finch brain, and of their projections to motor stations of the song system. {\copyright} 1996 Wiley-Liss, Inc.},
	author = {Vates, G. Edward and Broome, Bede M. and Mello, Claudio V. and Nottebohm, Fernando},
	copyright = {Copyright {\copyright} 1996 Wiley‐Liss, Inc.},
	doi = {10.1002/(SICI)1096-9861(19960318)366:4<613::AID-CNE5>3.0.CO;2-7},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/25USM6WF/Vates et al. - 1996 - Auditory pathways of caudal telencephalon and thei.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IWJ7IX8R/(SICI)1096-9861(19960318)3664613AID-CNE53.0.html:text/html},
	issn = {1096-9861},
	journal = {Journal of Comparative Neurology},
	keywords = {birdsong, field L complex, HVC, Ncm, shelf},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291096-9861\%2819960318\%29366\%3A4\%3C613\%3A\%3AAID-CNE5\%3E3.0.CO\%3B2-7},
	number = {4},
	pages = {613--642},
	title = {Auditory pathways of caudal telencephalon and their relation to the song system of adult male zebra finches ({Taenopygia} guttata)},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9861%2819960318%29366%3A4%3C613%3A%3AAID-CNE5%3E3.0.CO%3B2-7},
	urldate = {2020-03-11},
	volume = {366},
	year = {1996},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9861%2819960318%29366%3A4%3C613%3A%3AAID-CNE5%3E3.0.CO%3B2-7},
	bdsk-url-2 = {https://doi.org/10.1002/(SICI)1096-9861(19960318)366:4%3C613::AID-CNE5%3E3.0.CO;2-7}}

@article{rioslopez_development_nodate,
	abstract = {Recent neurophysiological theories propose that the cerebral hemispheres collaborate to resolve the complex temporal nature of speech, such that left-hemisphere (or bilateral) gamma-band oscillatory activity would specialize in coding information at fast rates (phonemic information), whereas right-hemisphere delta- and theta-band activity would code for speech's slow temporal components (syllabic and prosodic information). Despite the relevance that neural entrainment to speech might have for reading acquisition and for core speech perception operations such as the perception of intelligible speech, no study had yet explored its development in young children. In the current study, speech-brain entrainment was recorded via EEG in a cohort of children at three different time points since they were 4--5 to 6--7 years of age. Our results showed that speech-brain entrainment occurred only at delta frequencies (0.5 Hz) at all testing times. The fact that, from the longitudinal perspective, coherence increased in bilateral temporal electrodes suggests that, contrary to previous hypotheses claiming for an innate right-hemispheric bias for processing prosodic information, at 7 years of age the low-frequency components of speech are processed in a bilateral manner. Lastly, delta speech-brain entrainment in the right hemisphere was related to an indirect measure of intelligibility, providing preliminary evidence that the entrainment phenomenon might support core linguistic operations since early childhood.},
	author = {R{\'\i}os‐L{\'o}pez, Paula and Molinaro, Nicola and Bourguignon, Mathieu and Lallier, Marie},
	copyright = {{\copyright} 2020 The Authors. Developmental Science published by John Wiley \& Sons Ltd},
	doi = {10.1111/desc.12947},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/2BPBX7PP/R{\'\i}os‐L{\'o}pez et al. - Development of neural oscillatory activity in resp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VXM37RF8/desc.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	keywords = {coherence, speech perception, language development, language lateralization, neural entrainment, reading acquisition},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12947},
	number = {n/a},
	pages = {e12947},
	title = {Development of neural oscillatory activity in response to speech in children from 4 to 6 years old},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12947},
	urldate = {2020-03-17},
	volume = {n/a},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12947},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12947}}

@article{kalashnikova_infant-directed_2018,
	abstract = {This study assessed cortical tracking of temporal information in incoming natural speech in seven-month-old infants. Cortical tracking refers to the process by which neural activity follows the dynamic patterns of the speech input. In adults, it has been shown to involve attentional mechanisms and to facilitate effective speech encoding. However, in infants, cortical tracking or its effects on speech processing have not been investigated. This study measured cortical tracking of speech in infants and, given the involvement of attentional mechanisms in this process, cortical tracking of both infant-directed speech (IDS), which is highly attractive to infants, and the less captivating adult-directed speech (ADS), were compared. IDS is the speech register parents use when addressing young infants. In comparison to ADS, it is characterised by several acoustic qualities that capture infants' attention to linguistic input and assist language learning. Seven-month-old infants' cortical responses were recorded via electroencephalography as they listened to IDS or ADS recordings. Results showed stronger low-frequency cortical tracking of the speech envelope in IDS than in ADS. This suggests that IDS has a privileged status in facilitating successful cortical tracking of incoming speech which may, in turn, augment infants' early speech processing and even later language development.},
	author = {Kalashnikova, Marina and Peter, Varghese and Liberto, Giovanni M. Di and Lalor, Edmund C. and Burnham, Denis},
	copyright = {2018 The Author(s)},
	doi = {10.1038/s41598-018-32150-6},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PH5TQ53A/Kalashnikova et al. - 2018 - Infant-directed speech facilitates seven-month-old.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7CTKDTBI/s41598-018-32150-6.html:text/html},
	issn = {2045-2322},
	journal = {Scientific Reports},
	language = {en},
	month = sep,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {1--8},
	title = {Infant-directed speech facilitates seven-month-old infants' cortical tracking of speech},
	url = {https://www.nature.com/articles/s41598-018-32150-6},
	urldate = {2020-03-17},
	volume = {8},
	year = {2018},
	bdsk-url-1 = {https://www.nature.com/articles/s41598-018-32150-6},
	bdsk-url-2 = {https://doi.org/10.1038/s41598-018-32150-6}}

@article{peter_mature_2016,
	abstract = {Infant directed speech (IDS), the speech register adults use when talking to infants, has been shown to have positive effects on attracting infants' attention, language learning, and emotional communication. Here event related potentials (ERPs) are used to investigate the neural coding of IDS and ADS (adult directed speech) as well as their discrimination by both infants and adults. Two instances of the vowel /i/, one extracted from ADS and one from IDS, were presented to 9-month-old infants and adults in two oddball conditions: ADS standard/IDS deviant and IDS standard/ADS deviant. In Experiment 1 with adults, the obligatory ERPs that code acoustic information were different for ADS and IDS; and discrimination, indexed by mismatch negativity (MMN) responses, showed that IDS and ADS deviants were discriminated equally well; although, the P3a response was larger for IDS suggesting it captured adults' attention more than did ADS. In infants the obligatory responses did not differ for IDS and ADS, but for discrimination, while IDS deviants generated both a slow-positive mismatch response (MMR) as well as an adult-like MMN, the ADS deviants generated only an MMR. The presence of a mature adult-like MMN suggests that the IDS stimulus is easier to discriminate for infants.},
	author = {Peter, Varghese and Kalashnikova, Marina and Santos, Aimee and Burnham, Denis},
	copyright = {2016 The Author(s)},
	doi = {10.1038/srep34273},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NFNV3X2Z/Peter et al. - 2016 - Mature neural responses to Infant-Directed Speech .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3MS65ZU9/srep34273.html:text/html},
	issn = {2045-2322},
	journal = {Scientific Reports},
	language = {en},
	month = sep,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {1--14},
	title = {Mature neural responses to {Infant}-{Directed} {Speech} but not {Adult}-{Directed} {Speech} in {Pre}-{Verbal} {Infants}},
	url = {https://www.nature.com/articles/srep34273},
	urldate = {2020-03-17},
	volume = {6},
	year = {2016},
	bdsk-url-1 = {https://www.nature.com/articles/srep34273},
	bdsk-url-2 = {https://doi.org/10.1038/srep34273}}

@article{ceponiene_childrens_2001,
	abstract = {Children's long-latency auditory event-related potential (LLAEP) structure differs from that of adults. Functional significance of childhood ERP components is largely unknown. In order to look for the functional correlates in adult and children's LLAEPs, stimulus-complexity effects were investigated in 8--10-year old children. To this end, auditory ERPs to vowels, acoustically matched complex tones, and sinusoidal tones were recorded. All types of stimuli elicited P100-N250-N450 ERP complex. Differences between the sinusoidal and complex tones were confined to the P100 and N250 peaks, complex tones eliciting larger responses. Vowels elicited smaller-amplitude N250 but larger-amplitude N450 than the complex tones. Some stimulus-complexity effects observed for N250 in children corresponded to those observed for the Nl in adults, whereas the N450 peak exhibited behaviour resembling that of the adult ERP components subsequent to the Nl wave.},
	author = {{\v C}eponien{\'e}, Rita and Shestakova, Anna and Balan, Polina and Alku, Paavo and Yiaguchi, Kiyoshi and Naatanen, Risto},
	doi = {10.3109/00207450108986536},
	file = {Snapshot:/Users/Cecile/Zotero/storage/T44L3WVS/00207450108986536.html:text/html},
	issn = {0020-7454},
	journal = {International Journal of Neuroscience},
	keywords = {Children, Event-related potentials (ERP), Long-latency auditory evoked potentials (LLAEP), N250, N450, Nl, Obligatory components, Stimulus complexity},
	month = jan,
	note = {Publisher: Taylor \& Francis \_eprint: https://doi.org/10.3109/00207450108986536},
	number = {3-4},
	pages = {245--260},
	title = {Children's {Auditory} {Event}-{Related} {Potentials} {Index} {Sound} {Complexity} and ``{Speechness}''},
	url = {https://doi.org/10.3109/00207450108986536},
	urldate = {2020-03-18},
	volume = {109},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.3109/00207450108986536}}

@article{kushnerenko_maturation_2002,
	abstract = {This study examined the maturation of cortical auditory event-related potentials (ERPs) from birth until 12 months of age. In the 15 infants studied, all ERP peaks observable at 12 months of age, the P150, N250, P350, and N450 were identifiable already at birth. As in previous studies, the amplitudes of the ERP peaks increased and latencies shortened with increasing age. In addition, the time courses of the amplitude growth of these peaks differed from each other. It was concluded, that the generators of all the infantile ERP peaks are functional already at birth, and that the maturational changes in the waveform morphology can mostly be accounted for by the changing relative strengths of the different generators.},
	author = {Kushnerenko, Elena and Ceponiene, Rita and Balan, Polina and Fellman, Vineta and Huotilainen, Minna and N{\"a}{\"a}t{\"a}nen, Risto},
	file = {Snapshot:/Users/Cecile/Zotero/storage/7V8LF64H/Maturation_of_the_auditory_event_related.14.html:text/html},
	issn = {0959-4965},
	journal = {NeuroReport},
	language = {en-US},
	month = jan,
	number = {1},
	pages = {47--51},
	title = {Maturation of the auditory event-related potentials during the first year of life},
	url = {https://journals.lww.com/neuroreport/Abstract/2002/01210/Maturation_of_the_auditory_event_related.14.aspx},
	urldate = {2020-03-18},
	volume = {13},
	year = {2002},
	bdsk-url-1 = {https://journals.lww.com/neuroreport/Abstract/2002/01210/Maturation_of_the_auditory_event_related.14.aspx}}

@article{konishi_role_1965,
	author = {Konishi, Masakazu},
	copyright = {1965 Blackwell Verlag GmbH},
	doi = {10.1111/j.1439-0310.1965.tb01688.x},
	file = {Snapshot:/Users/Cecile/Zotero/storage/SP9GF7A7/j.1439-0310.1965.tb01688.html:text/html},
	issn = {1439-0310},
	journal = {Zeitschrift f{\"u}r Tierpsychologie},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1439-0310.1965.tb01688.x},
	number = {7},
	pages = {770--783},
	title = {The {Role} of {Auditory} {Feedback} in the {Control} of {Vocalization} in the {White}-{Crowned} {Sparrow1}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1965.tb01688.x},
	urldate = {2020-03-19},
	volume = {22},
	year = {1965},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1965.tb01688.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1439-0310.1965.tb01688.x}}

@article{konishi_role_2004,
	abstract = {Abstract: Young songbirds memorize a tutor song and use the memory trace as a template to shape their own song by auditory feedback. Major issues in birdsong research include the neural sites and mechanisms for song memory and auditory feedback. The brain song control system contains neurons with both premotor and auditory function. Yet no evidence so far shows that they respond to the bird's own song during singing. Also, no neurons have been found to respond to perturbation of auditory feedback in the brain area that is thought to be involved in the feedback control of song. The phenomenon of gating in which neurons respond to playback of the bird's own song only during sleep or under anesthesia is the sole known evidence for control of auditory input to the song system. It is, however, not known whether the gating is involved in switching between the premotor and auditory function of neurons in the song control system.},
	author = {Konishi, Masakazu},
	doi = {10.1196/annals.1298.010},
	file = {Snapshot:/Users/Cecile/Zotero/storage/6I7YGE7C/annals.1298.html:text/html},
	issn = {1749-6632},
	journal = {Annals of the New York Academy of Sciences},
	keywords = {auditory feedback, gating, song learning, songbirds, vocal control system},
	language = {en},
	note = {\_eprint: https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1196/annals.1298.010},
	number = {1},
	pages = {463--475},
	title = {The {Role} of {Auditory} {Feedback} in {Birdsong}},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1196/annals.1298.010},
	urldate = {2020-03-19},
	volume = {1016},
	year = {2004},
	bdsk-url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1196/annals.1298.010},
	bdsk-url-2 = {https://doi.org/10.1196/annals.1298.010}}

@article{bouton_perception_2012,
	abstract = {Purpose
      The present study investigates the perception of phonological features in French-speaking
         children with cochlear implants (CIs) compared with normal-hearing (NH) children matched
         for listening age.
      
      
      Method
      Scores for discrimination and identification of minimal pairs for all features defining
         consonants (e.g., place, voicing, manner, nasality) and vowels (e.g., frontness, nasality,
         aperture) were measured in each listener.
      
      
      Results
      The results indicated no differences in ``categorical perception,'' specified as a similar
         difference between discrimination and identification between CI children and controls.
         However, CI children demonstrated a lower level of ``categorical precision,'' that is,
         lesser accuracy in both feature identification and discrimination, than NH children,
         with the magnitude of the deficit depending on the feature.
      
      
      Conclusions
      If sensitive periods of language development extend well beyond the moment of implantation,
         the consequences of hearing deprivation for the acquisition of categorical perception
         should be fairly important in comparison to categorical precision because categorical
         precision develops more slowly than categorical perception in NH children. These results
         do not support the idea that the sensitive period for development of categorical perception
         is restricted to the first 1--2 years of life. The sensitive period may be significantly
         longer. Differences in precision may reflect the acoustic limitations of the cochlear
         implant, such as coding for temporal fine structure and frequency resolution.},
	author = {Bouton, Sophie and Serniclaes, Willy and Bertoncini, Josiane and Col{\'e}, Pascale},
	doi = {10.1044/1092-4388(2011/10-0330)},
	file = {Snapshot:/Users/Cecile/Zotero/storage/6RGELNW3/10-0330).html:text/html;Version soumise:/Users/Cecile/Zotero/storage/2ZVH8ZMU/Bouton Sophie et al. - 2012 - Perception of Speech Features by French-Speaking C.pdf:application/pdf},
	journal = {Journal of Speech, Language, and Hearing Research},
	month = feb,
	note = {Publisher: American Speech-Language-Hearing Association},
	number = {1},
	pages = {139--153},
	title = {Perception of {Speech} {Features} by {French}-{Speaking} {Children} {With} {Cochlear} {Implants}},
	url = {https://pubs.asha.org/doi/abs/10.1044/1092-4388%282011/10-0330%29},
	urldate = {2020-03-19},
	volume = {55},
	year = {2012},
	bdsk-url-1 = {https://pubs.asha.org/doi/abs/10.1044/1092-4388%282011/10-0330%29},
	bdsk-url-2 = {https://doi.org/10.1044/1092-4388(2011/10-0330)}}

@article{lazard_understanding_2012,
	abstract = {The cochlear implant (CI), by enabling oral communication in severely to profoundly deaf subjects, is one of the major medical advances over the last fifty years. Despite the globally very satisfactory results, individual outcomes vary considerably. The objective of this review is to describe the various factors influencing the results of CI rehabilitation with particular emphasis on the better understanding of neurocognitive mechanisms provided by functional brain imaging. The following aspects will be discussed: 1. Peripheral predictors such as the degree of preservation of nerve structures and the positioning of the electrode array. 2. The duration of auditory deprivation whose influence on brain reorganization is now becoming more clearly understood. 3. The age of initiation of hearing rehabilitation in subjects with pre-lingual deafness influencing the possibility of physiological maturation of nerve structures. 4. The concepts of sensitive period, decoupling and cross-modality. 5. In post-lingually deaf adults, brain plasticity can allow adaptation to the disability induced by deafness, subsequently potentiating CI rehabilitation, particularly as a result of audiovisual interactions. 6. Several studies provide concordant evidence that implanted patients present different phonological analysis and primary linguistic capacities. The results of CI rehabilitation are dependent on factors situated between the cochlea and cortical associative areas. The importance of higher cognitive influences on the functional results of cochlear implantation justify adaptation of coding strategies, as well as global cognitive management of deaf patients by utilising brain plasticity capacities.},
	author = {Lazard, D. S. and Giraud, A. -L. and Gnansia, D. and Meyer, B. and Sterkers, O.},
	doi = {10.1016/j.anorl.2011.06.001},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KDJ5ZZ2X/Lazard et al. - 2012 - Understanding the deafened brain Implications for.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/55UXGB3M/S1879729611001001.html:text/html},
	issn = {1879-7296},
	journal = {European Annals of Otorhinolaryngology, Head and Neck Diseases},
	keywords = {Plasticity, Functional MRI, Maturation, Phonology, Predictor, Cross-modality, Performance, PET, Pre/post-lingual, Rehabilitation},
	language = {en},
	month = apr,
	number = {2},
	pages = {98--103},
	shorttitle = {Understanding the deafened brain},
	title = {Understanding the deafened brain: {Implications} for cochlear implant rehabilitation},
	url = {http://www.sciencedirect.com/science/article/pii/S1879729611001001},
	urldate = {2020-03-19},
	volume = {129},
	year = {2012},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1879729611001001},
	bdsk-url-2 = {https://doi.org/10.1016/j.anorl.2011.06.001}}

@article{geary_contiguity_1954,
	author = {Geary, R. C.},
	doi = {10.2307/2986645},
	issn = {1466-9404},
	journal = {The Incorporated Statistician},
	note = {Publisher: [Royal Statistical Society, Wiley]},
	number = {3},
	pages = {115--146},
	title = {The {Contiguity} {Ratio} and {Statistical} {Mapping}},
	url = {https://www.jstor.org/stable/2986645},
	urldate = {2020-03-19},
	volume = {5},
	year = {1954},
	bdsk-url-1 = {https://www.jstor.org/stable/2986645},
	bdsk-url-2 = {https://doi.org/10.2307/2986645}}

@article{schumacher_anesthetic_2011,
	abstract = {The majority of sensory physiology experiments have used anesthesia to facilitate the recording of neural activity. Current techniques allow researchers to study sensory function in the context of varying behavioral states. To reconcile results across multiple behavioral and anesthetic states, it is important to consider how and to what extent anesthesia plays a role in shaping neural response properties. The role of anesthesia has been the subject of much debate, but the extent to which sensory coding properties are altered by anesthesia has yet to be fully defined. In this study we asked how urethane, an anesthetic commonly used for avian and mammalian sensory physiology, affects the coding of complex communication vocalizations (songs) and simple artificial stimuli in the songbird auditory midbrain. We measured spontaneous and song-driven spike rates, spectrotemporal receptive fields, and neural discriminability from responses to songs in single auditory midbrain neurons. In the same neurons, we recorded responses to pure tone stimuli ranging in frequency and intensity. Finally, we assessed the effect of urethane on population-level representations of birdsong. Results showed that intrinsic neural excitability is significantly depressed by urethane but that spectral tuning, single neuron discriminability, and population representations of song do not differ significantly between unanesthetized and anesthetized animals.},
	author = {Schumacher, Joseph W. and Schneider, David M. and Woolley, Sarah M. N.},
	doi = {10.1152/jn.01072.2010},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NBYYEM6F/Schumacher et al. - 2011 - Anesthetic state modulates excitability but not sp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QBF3BSJ7/jn.01072.html:text/html},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	month = may,
	note = {Publisher: American Physiological Society},
	number = {2},
	pages = {500--514},
	title = {Anesthetic state modulates excitability but not spectral tuning or neural discrimination in single auditory midbrain neurons},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.01072.2010},
	urldate = {2020-03-19},
	volume = {106},
	year = {2011},
	bdsk-url-1 = {https://journals.physiology.org/doi/full/10.1152/jn.01072.2010},
	bdsk-url-2 = {https://doi.org/10.1152/jn.01072.2010}}

@article{issard_infants_nodate,
	abstract = {The human auditory system is amazingly e cient at processing speech, with a preference for this type of sound reported by full term birth. Numerous studies have investigated this preference at a variety of ages, and with a large variety of sounds contrasted to speech, from monkey calls to white noise. Many of these contrasts confound familiar, natural, and/or vocal sounds, inviting a meta-analytic investigation in which these three conceptually distinct explanations (preference for familiar, natural, or vocal sounds) are statistically tested. Moreover, when reviewed qualitatively, previous experimental work suggested that infants' preference for speech would initially encompass a broad range of natural or vocal sounds, and then tune in to species-specific vocalizations, namely speech. A meta-analytic framework allows us to check whether this explanation holds for the entire body of literature. We therefore synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a medium e ect size, with infants preferring speech over other sounds. This preference was not significantly moderated by familiarity with the language of the speech sound, vocal quality, or naturalness of the competitor. We found no e ect of age: infants showed the same strength of preference throughout the first year of life. Speech therefore appears to be preferred from birth, even to other natural or vocal sounds. These results contradict current views of the literature, and call for further investigation of the phenomenon, especially in older infants.},
	author = {Issard, C{\'e}cile and Tsuji, Sho and Cristia, Alejandrina},
	copyright = {Licence Creative Commons Attribution - Pas d'utilisation commerciale - Pas de modification 4.0 International (CC-BY-NC-ND)},
	file = {Issard et al. - Infants' preference for speech decomposed Meta-an.pdf:/Users/Cecile/Zotero/storage/N6BWNWKD/Issard et al. - Infants' preference for speech decomposed Meta-an.pdf:application/pdf},
	language = {en},
	pages = {35},
	title = {Infants' preference for speech decomposed: {Meta}-analytic evidence}}

@article{lakatos_new_2019,
	abstract = {Rhythms are a fundamental and defining feature of neuronal activity in animals including humans. This rhythmic brain activity interacts in complex ways with rhythms in the internal and external environment through the phenomenon of `neuronal entrainment', which is attracting increasing attention due to its suggested role in a multitude of sensory and cognitive processes. Some senses, such as touch and vision, sample the environment rhythmically, while others, like audition, are faced with mostly rhythmic inputs. Entrainment couples rhythmic brain activity to external and internal rhythmic events, serving fine-grained routing and modulation of external and internal signals across multiple spatial and temporal hierarchies. This interaction between a brain and its environment can be experimentally investigated and even modified by rhythmic sensory stimuli or invasive and non-invasive neuromodulation techniques. We provide a comprehensive overview of the topic and propose a theoretical framework of how neuronal entrainment dynamically structures information from incoming neuronal, bodily and environmental sources. We discuss the different types of neuronal entrainment, the conceptual advances in the field, and converging evidence for general principles.},
	author = {Lakatos, Peter and Gross, Joachim and Thut, Gregor},
	doi = {10.1016/j.cub.2019.07.075},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MHZ3ENTU/Lakatos et al. - 2019 - A New Unifying Account of the Roles of Neuronal En.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/F5MUI46K/S0960982219309558.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	language = {en},
	month = sep,
	number = {18},
	pages = {R890--R905},
	title = {A {New} {Unifying} {Account} of the {Roles} of {Neuronal} {Entrainment}},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982219309558},
	urldate = {2020-03-26},
	volume = {29},
	year = {2019},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982219309558},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2019.07.075}}

@article{kuefner_early_2010,
	abstract = {Whether the development of face recognition abilities truly reflects changes in how faces, specifically, are perceived, or rather can be attributed to more general perceptual or cognitive development is debated. Event-related potential (ERP) recordings on the scalp offer promise for this issue because they allow brain responses to complex visual stimuli to be relatively well isolated from other sensory, cognitive and motor processes. ERP studies in 5-16 year-old children report large age-related changes in amplitude, latency (decreases) and topographical distribution of the early visual components, the P1 and the occipito-temporal N170. To test the face specificity of these effects, we recorded high-density ERPs to pictures of faces, cars, and their phase-scrambled versions from 72 children between the ages of 4 and 17, and a group of adults. We found that none of the previously reported age-dependent changes in amplitude, latency or topography of the P1 or N170 were specific to faces. Most importantly, when we controlled for age-related variations of the P1, the N170 appeared remarkably similar in amplitude and topography across development, with much smaller age-related decreases in latencies than previously reported. At all ages the N170 showed equivalent face-sensitivity: it had the same topography and right hemisphere dominance, it was absent for meaningless (scrambled) stimuli, and larger and earlier for faces than cars. The data also illustrate the large amount of inter-individual and inter-trial variance in young children\&rsquo;s data, which causes the N170 to merge with a later component, the N250 in grand-averaged data. Based on our observations, we suggest that the previously reported \&ldquo;bi-fid\&rdquo; N170 of young children is in fact the N250. Overall, our data indicate that the electrophysiological markers of face-sensitive perceptual processes are present from 4 years of age and do not appear to change throughout development.},
	author = {Kuefner, Dana and De Heering, Adelaide and Jacques, Corentin and Palmero-Soler, Ernesto and Rossion, Bruno},
	doi = {10.3389/neuro.09.067.2009},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DEF9MI2Z/Kuefner et al. - 2010 - Early visually evoked electrophysiological respons.pdf:application/pdf},
	issn = {1662-5161},
	journal = {Frontiers in Human Neuroscience},
	keywords = {development, N170, face recognition, ERP},
	language = {English},
	note = {Publisher: Frontiers},
	title = {Early visually evoked electrophysiological responses over the human brain ({P1}, {N170}) show stable patterns of face-sensitivity from 4 years to adulthood},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.09.067.2009/full#h2},
	urldate = {2020-03-26},
	volume = {3},
	year = {2010},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/neuro.09.067.2009/full#h2},
	bdsk-url-2 = {https://doi.org/10.3389/neuro.09.067.2009}}

@article{so_auditory_2020,
	abstract = {Vocal communication relies on the ability of listeners to identify, process, and respond to vocal sounds produced by others in complex environments. To accurately recognize these signals, animals' auditory systems must robustly represent acoustic features that distinguish vocal sounds from other environmental sounds. Vocalizations typically have spectral structure; power regularly fluctuates along the frequency axis, creating spectral contrast. Spectral contrast is closely related to harmonicity, which refers to spectral power peaks occurring at integer multiples of a fundamental frequency. Although both spectral contrast and harmonicity typify natural sounds, they may differ in salience for communication behavior and engage distinct neural mechanisms. Therefore, it is important to understand which of these properties of vocal sounds underlie the neural processing and perception of vocalizations.
Here, we test the importance of vocalization-typical spectral features in behavioral recognition and neural processing of vocal sounds, using male zebra finches. We show that behavioral responses to natural and synthesized vocalizations rely on the presence of discrete frequency components, but not on harmonic ratios between frequencies. We identify a specific population of neurons in primary auditory cortex that are sensitive to the spectral resolution of vocal sounds. We find that behavioral and neural response selectivity is explained by sensitivity to spectral contrast rather than harmonicity. This selectivity emerges within the cortex; it is absent in the thalamorecipient region and present in the deep output region. Further, deep-region neurons that are contrast-sensitive show distinct temporal responses and selectivity for modulation density compared with unselective neurons.
SIGNIFICANCE STATEMENT Auditory coding and perception are critical for vocal communication. Auditory neurons must encode acoustic features that distinguish vocalizations from other sounds in the environment and generate percepts that direct behavior. The acoustic features that drive neural and behavioral selectivity for vocal sounds are unknown, however. Here, we show that vocal response behavior scales with stimulus spectral contrast but not with harmonicity, in songbirds. We identify a distinct population of auditory cortex neurons in which response selectivity parallels behavioral selectivity. This neural response selectivity is explained by sensitivity to spectral contrast rather than to harmonicity. Our findings inform the understanding of how the auditory system encodes socially-relevant signals via detection of an acoustic feature that is ubiquitous in vocalizations.},
	author = {So, Nina L. T. and Edwards, Jacob A. and Woolley, Sarah M. N.},
	copyright = {Copyright {\copyright} 2020 the authors},
	doi = {10.1523/JNEUROSCI.1200-19.2019},
	file = {Snapshot:/Users/Cecile/Zotero/storage/JRMTVXJV/1015.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {auditory cortex, vocalizations, songbirds, harmonic sounds, perception, social communication},
	language = {en},
	month = jan,
	note = {Publisher: Society for Neuroscience Section: Research Articles},
	number = {5},
	pages = {1015--1027},
	pmid = {31826944},
	title = {Auditory {Selectivity} for {Spectral} {Contrast} in {Cortical} {Neurons} and {Behavior}},
	url = {https://www.jneurosci.org/content/40/5/1015},
	urldate = {2020-03-31},
	volume = {40},
	year = {2020},
	bdsk-url-1 = {https://www.jneurosci.org/content/40/5/1015},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.1200-19.2019}}

@article{bauer_synaptic_2008,
	abstract = {Songbirds learn to sing by memorizing a tutor song that they then vocally mimic using auditory feedback. This developmental sequence suggests that brain areas that encode auditory memories communicate with brain areas for learned vocal control. In the songbird, the secondary auditory telencephalic region caudal mesopallium (CM) contains neurons that encode aspects of auditory experience. We investigated whether CM is an important source of auditory input to two sensorimotor structures implicated in singing, the telencephalic song nucleus interface (NIf) and HVC. We used reversible inactivation methods to show that activity in CM is necessary for much of the auditory-evoked activity that can be detected in NIf and HVC of anesthetized adult male zebra finches. Furthermore, extracellular and intracellular recordings along with spike-triggered averaging methods indicate that auditory selectivity for the bird's own song is enhanced between CM and NIf. We used lentiviral-mediated tracing methods to confirm that CM neurons directly innervate NIf. To our surprise, these tracing studies also revealed a direct projection from CM to HVC. We combined irreversible lesions of NIf with reversible inactivation of CM to establish that CM supplies a direct source of auditory drive to HVC. Finally, using chronic recording methods, we found that CM neurons are active in response to song playback and during singing, indicating their potential importance to song perception and processing of auditory feedback. These results establish the functional synaptic linkage between sites of auditory and vocal learning and may identify an important substrate for learned vocal communication.},
	author = {Bauer, Eric E. and Coleman, Melissa J. and Roberts, Todd F. and Roy, Arani and Prather, Jonathan F. and Mooney, Richard},
	copyright = {Copyright {\copyright} 2008 Society for Neuroscience 0270-6474/08/281509-14\$15.00/0},
	doi = {10.1523/JNEUROSCI.3838-07.2008},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/WRYXYPE3/Bauer et al. - 2008 - A Synaptic Basis for Auditory--Vocal Integration in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZV6VZCEN/1509.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {auditory, zebra finch, song, HVC, CM, learning, vocal},
	language = {en},
	month = feb,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {6},
	pages = {1509--1522},
	pmid = {18256272},
	title = {A {Synaptic} {Basis} for {Auditory}--{Vocal} {Integration} in the {Songbird}},
	url = {https://www.jneurosci.org/content/28/6/1509},
	urldate = {2020-03-31},
	volume = {28},
	year = {2008},
	bdsk-url-1 = {https://www.jneurosci.org/content/28/6/1509},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3838-07.2008}}

@article{shaevitz_functional_2007,
	abstract = {A key discovery that has emerged from studies of the vocal system in songbirds is that neurons in these regions respond preferentially to playback of the bird's own song (BOS). This BOS selectivity is not a general property of neurons in primary and secondary auditory forebrain regions, field L and caudolateral mesopallium (CLM). Moreover, anatomical studies have been unable to conclusively define a direct projection from field L and/or CLM to HVC, a central structure for integrating sensory and motor information in the vocal system. To examine the communication between these regions, we used simultaneous dual-electrode recording in anesthetized male zebra finches and cross-correlation analysis to estimate the functional connectivity between auditory areas, field L and CLM, and HVC. We found that ≥18\% of neurons in field L and 33\% of neurons in CLM are functionally connected to HVC, most with auditory forebrain leading-HVC latencies ranging from 0.5 to 15 ms. These results indicate that field L and CLM communicate extensively with HVC through both direct and indirect anatomical connections. To further explore the role of the auditory forebrain cells that are functionally connected with HVC, we assessed their responsiveness and selectivity for a variety of natural and synthetic auditory stimuli. We found that field L and CLM neurons that are functionally connected to HVC exhibit generic auditory forebrain properties including the lack of BOS selectivity. This finding puts further constraints on the neural architecture and the nature of the nonlinearity that leads to BOS-selective auditory responses in the vocal control nuclei.},
	author = {Shaevitz, Sarita S. and Theunissen, Fr{\'e}d{\'e}ric E.},
	doi = {10.1152/jn.00294.2007},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LG8DYC9K/Shaevitz et Theunissen - 2007 - Functional Connectivity Between Auditory Areas Fie.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q24335CE/jn.00294.html:text/html},
	issn = {0022-3077},
	journal = {Journal of Neurophysiology},
	month = nov,
	note = {Publisher: American Physiological Society},
	number = {5},
	pages = {2747--2764},
	title = {Functional {Connectivity} {Between} {Auditory} {Areas} {Field} {L} and {CLM} and {Song} {System} {Nucleus} {HVC} in {Anesthetized} {Zebra} {Finches}},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.00294.2007},
	urldate = {2020-03-31},
	volume = {98},
	year = {2007},
	bdsk-url-1 = {https://journals.physiology.org/doi/full/10.1152/jn.00294.2007},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00294.2007}}

@article{bolhuis_neural_2006,
	abstract = {Birdsong learning in avian species has strong similarities with speech acquisition in human infants. Recent research on the song system has shed fresh light on the neural substrate of song memory and sensorimotor learning in both male and female songbirds.},
	author = {Bolhuis, Johan J. and Gahr, Manfred},
	copyright = {2006 Nature Publishing Group},
	doi = {10.1038/nrn1904},
	file = {Snapshot:/Users/Cecile/Zotero/storage/XYK6XVWA/nrn1904.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = may,
	note = {Number: 5 Publisher: Nature Publishing Group},
	number = {5},
	pages = {347--357},
	title = {Neural mechanisms of birdsong memory},
	url = {https://www.nature.com/articles/nrn1904},
	urldate = {2020-04-01},
	volume = {7},
	year = {2006},
	bdsk-url-1 = {https://www.nature.com/articles/nrn1904},
	bdsk-url-2 = {https://doi.org/10.1038/nrn1904}}

@article{xie_development_2018,
	abstract = {The current study examined the relation between infant sustained attention and infant EEG oscillations. Fifty-nine infants were tested at 6 (N = 15), 8 (N = 17), 10 (N = 14), and 12 (N = 13) months. Three attention phases, stimulus orienting, sustained attention, and attention termination, were defined based on infants' heart rate changes. Frequency analysis using simultaneously recorded EEG focused on infant theta (2--6 Hz), alpha (6--9 Hz), and beta (9--14 Hz) rhythms. Cortical source analysis of EEG oscillations was conducted with realistic infant MRI models. Theta synchronization was found over fontal pole, temporal, and parietal electrodes during infant sustained attention for 10 and 12 months. Alpha desynchronization was found over frontal, central and parietal electrodes during sustained attention. This alpha effect started to emerge at 10 months and became well established by 12 months. No difference was found for the beta rhythm between different attention phases. The theta synchronization effect was localized to the orbital frontal, temporal pole, and ventral temporal areas. The alpha desynchronization effect was localized to the brain regions composing the default mode network including the posterior cingulate cortex and precuneus, medial prefrontal cortex, and inferior parietal gyrus. The alpha desynchronization effect was also localized to the pre- and post-central gyri. The present study demonstrates a connection between infant sustained attention and EEG oscillatory activities.},
	author = {Xie, Wanze and Mallin, Brittany M. and Richards, John E.},
	copyright = {{\copyright} 2017 John Wiley \& Sons Ltd},
	doi = {10.1111/desc.12562},
	file = {Snapshot:/Users/Cecile/Zotero/storage/YNXJB9B4/desc.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/SQ9ZZUJG/Xie et al. - 2018 - Development of infant sustained attention and its .pdf:application/pdf},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12562},
	number = {3},
	pages = {e12562},
	shorttitle = {Development of infant sustained attention and its relation to {EEG} oscillations},
	title = {Development of infant sustained attention and its relation to {EEG} oscillations: an {EEG} and cortical source analysis study},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12562},
	urldate = {2020-04-07},
	volume = {21},
	year = {2018},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12562},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12562}}

@article{musacchia_infant_2015,
	abstract = {Rapid auditory processing and acoustic change detection abilities play a critical role in allowing human infants to efficiently process the fine spectral and temporal changes that are characteristic of human language. These abilities lay the foundation for effective language acquisition; allowing infants to hone in on the sounds of their native language. Invasive procedures in animals and scalp-recorded potentials from human adults suggest that simultaneous, rhythmic activity (oscillations) between and within brain regions are fundamental to sensory development; determining the resolution with which incoming stimuli are parsed. At this time, little is known about oscillatory dynamics in human infant development. However, animal neurophysiology and adult EEG data provide the basis for a strong hypothesis that rapid auditory processing in infants is mediated by oscillatory synchrony in discrete frequency bands. In order to investigate this, 128-channel, high-density EEG responses of 4-month old infants to frequency change in tone pairs, presented in two rate conditions (Rapid: 70 msec ISI and Control: 300 msec ISI) were examined. To determine the frequency band and magnitude of activity, auditory evoked response averages were first co-registered with age-appropriate brain templates. Next, the principal components of the response were identified and localized using a two-dipole model of brain activity. Single-trial analysis of oscillatory power showed a robust index of frequency change processing in bursts of Theta band (3 - 8 Hz) activity in both right and left auditory cortices, with left activation more prominent in the Rapid condition. These methods have produced data that are not only some of the first reported evoked oscillations analyses in infants, but are also, importantly, the product of a well-established method of recording and analyzing clean, meticulously collected, infant EEG and ERPs. In this article, we describe our method for infant EEG net application, recording, dynamic brain response analysis, and representative results.},
	author = {Musacchia, Gabriella and Ortiz-Mantilla, Silvia and Realpe-Bonilla, Teresa and Roesler, Cynthia P. and Benasich, April A.},
	doi = {10.3791/52420},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/X4TCMEKR/Musacchia et al. - 2015 - Infant Auditory Processing and Event-related Brain.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Z72HTKU2/infant-auditory-processing-and-event-related-brain-oscillations.html:text/html},
	issn = {1940-087X},
	journal = {JoVE (Journal of Visualized Experiments)},
	month = jul,
	number = {101},
	pages = {e52420},
	title = {Infant {Auditory} {Processing} and {Event}-related {Brain} {Oscillations}},
	url = {https://www.jove.com/video/52420/infant-auditory-processing-and-event-related-brain-oscillations},
	urldate = {2020-04-07},
	year = {2015},
	bdsk-url-1 = {https://www.jove.com/video/52420/infant-auditory-processing-and-event-related-brain-oscillations},
	bdsk-url-2 = {https://doi.org/10.3791/52420}}

@article{grossmann_social_2007,
	abstract = {Abstract.  Gamma band oscillatory brain activity was measured to examine the neural basis of 4-month-old infants' perception of eye gaze direction. Infants were},
	author = {Grossmann, Tobias and Johnson, Mark H. and Farroni, Teresa and Csibra, Gergely},
	doi = {10.1093/scan/nsm025},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/MAERJL4S/Grossmann et al. - 2007 - Social perception in the infant brain gamma oscil.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RJRZDPMA/1675437.html:text/html},
	issn = {1749-5016},
	journal = {Social Cognitive and Affective Neuroscience},
	language = {en},
	month = dec,
	note = {Publisher: Oxford Academic},
	number = {4},
	pages = {284--291},
	shorttitle = {Social perception in the infant brain},
	title = {Social perception in the infant brain: gamma oscillatory activity in response to eye gaze},
	url = {https://academic.oup.com/scan/article/2/4/284/1675437},
	urldate = {2020-04-07},
	volume = {2},
	year = {2007},
	bdsk-url-1 = {https://academic.oup.com/scan/article/2/4/284/1675437},
	bdsk-url-2 = {https://doi.org/10.1093/scan/nsm025}}

@article{kaufman_oscillatory_2005,
	abstract = {The apparent failure of infants to understand ``object permanence'' by reaching for hidden objects is perhaps the most striking and debated phenomenon in cognitive development. Of particular interest is the extent to which infants perceive and remember objects in a similar way to that of adults. Here we report two findings that clarify infant object processing. The first is that 6-mo-old infants are sensitive to visual cues to occlusion, particularly gradual deletion. The second finding is that oscillatory electroencephalogram activity recorded over right temporal channels is involved in object maintenance. This effect occurs only after disappearance in a manner consistent with occlusion and the object's continued existence.},
	author = {Kaufman, Jordy and Csibra, Gergely and Johnson, Mark H.},
	copyright = {Copyright {\copyright} 2005, The National Academy of Sciences},
	doi = {10.1073/pnas.0507626102},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7EIR6KLA/Kaufman et al. - 2005 - Oscillatory activity in the infant brain reflects .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MGZIN6Y3/15271.html:text/html},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	keywords = {infancy, electroencephalogram, gamma oscillations, object permanence},
	language = {en},
	month = oct,
	note = {Publisher: National Academy of Sciences Section: Social Sciences},
	number = {42},
	pages = {15271--15274},
	pmid = {16230640},
	title = {Oscillatory activity in the infant brain reflects object maintenance},
	url = {https://www.pnas.org/content/102/42/15271},
	urldate = {2020-04-07},
	volume = {102},
	year = {2005},
	bdsk-url-1 = {https://www.pnas.org/content/102/42/15271},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0507626102}}

@article{libertus_induced_2008,
	abstract = {Behavioral studies show that infants are capable of discriminating the number of objects or events in their environment, while also suggesting that number discrimination in infancy may be ratio-dependent. However, due to limitations of the dependent measures used with infant behavioral studies, the evidence for ratio dependence falls short of the vast psychophysical datasets that have established ratio dependence, and thus, adherence to Weber's Law in adults and nonhuman animals. We addressed this issue in two experiments that presented 7-month-old infants with familiar and novel numerosities while electroencephalogram measures of their brain activity were recorded. These data provide convergent evidence that the brains of 7-month-old infants detected numerical novelty. Alpha-band and theta-band oscillations both differed for novel and familiar numerical values. Most importantly, spectral power in the alpha band over midline and right posterior scalp sites was modulated by the ratio between the familiar and novel numerosities. Our findings provide neural evidence that numerical discrimination in infancy is ratio dependent and follows Weber's Law, thus indicating continuity of these cognitive processes over development. Results are also consistent with the idea that networks in the frontal and parietal cortices support ratio-dependent number discrimination in the first year of human life, consistent with what has been reported in neuroimaging studies in adults and older children.},
	author = {Libertus, Melissa E. and Pruitt, Laura B. and Woldorff, Marty G. and Brannon, Elizabeth M.},
	doi = {10.1162/jocn.2008.21162},
	file = {Snapshot:/Users/Cecile/Zotero/storage/8CI7WPYH/jocn.2008.html:text/html},
	issn = {0898-929X},
	journal = {Journal of Cognitive Neuroscience},
	month = nov,
	note = {Publisher: MIT Press},
	number = {12},
	pages = {2398--2406},
	title = {Induced {Alpha}-band {Oscillations} {Reflect} {Ratio}-dependent {Number} {Discrimination} in the {Infant} {Brain}},
	url = {https://doi.org/10.1162/jocn.2008.21162},
	urldate = {2020-04-07},
	volume = {21},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1162/jocn.2008.21162}}

@article{saby_neural_2012,
	abstract = {A foundational aspect of early social--emotional development is the ability to detect and respond to the actions of others who are coordinating their behavior with that of the self. Behavioral work in this area has found that infants show particular preferences for adults who are imitating them rather than adults who are carrying out noncontingent or mismatching actions. Here, we explore the neural processes related to this tendency of infants to prefer others who act like the self. Electroencephalographic (EEG) signals were recorded from 14-month-old infants while they were observing actions that either matched or mismatched the action the infant had just executed. Desynchronization of the EEG mu rhythm was greater when infants observed an action that matched their own most recently executed action. This effect was strongest immediately prior to the culmination of the goal of the observed action, which is consistent with recent ideas about the predictive nature of brain responses during action observation.},
	author = {Saby, Joni N. and Marshall, Peter J. and Meltzoff, Andrew N.},
	doi = {10.1080/17470919.2012.691429},
	file = {Snapshot:/Users/Cecile/Zotero/storage/RJKY4UAD/17470919.2012.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/NXTFFWKZ/Saby et al. - 2012 - Neural correlates of being imitated An EEG study .pdf:application/pdf},
	issn = {1747-0919},
	journal = {Social Neuroscience},
	keywords = {EEG, Infant, Imitation, Mu rhythm, Perception--action},
	month = nov,
	note = {Publisher: Routledge \_eprint: https://doi.org/10.1080/17470919.2012.691429},
	number = {6},
	pages = {650--661},
	pmid = {22646701},
	shorttitle = {Neural correlates of being imitated},
	title = {Neural correlates of being imitated: {An} {EEG} study in preverbal infants},
	url = {https://doi.org/10.1080/17470919.2012.691429},
	urldate = {2020-04-07},
	volume = {7},
	year = {2012},
	bdsk-url-1 = {https://doi.org/10.1080/17470919.2012.691429}}

@article{james_learning_2017,
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Biological predispositions in vocal learning have been proposed to underlie commonalities in vocal sequences, including for speech and birdsong, but cultural propagation could also account for such commonalities [1--4]. Songbirds such as the zebra finch learn the sequencing of their acoustic elements ("syllables") during development [5--8]. Zebra finches are not constrained to learn a specific sequence of syllables, but significant consistencies in the positioning and sequencing of syllables have been observed between individuals within populations and between populations [8--10]. To reveal biological predispositions in vocal sequence learning, we individually tutored juvenile zebra finches with randomized and unbiased sequences of syllables and analyzed the extent to which birds produced common sequences. In support of biological predispositions, birds tutored with randomized sequences produced songs with striking similarities. Birds preferentially started and ended their song sequence with particular syllables, consistently positioned shorter and higher frequency syllables in the middle of their song, and sequenced their syllables such that pitch alternated across adjacent syllables. These patterns are reminiscent of those observed in normally tutored birds, suggesting that birds "creolize" aberrant sequence inputs to produce normal sequence outputs. Similar patterns were also observed for syllables that were not used for tutoring (i.e., unlearned syllables), suggesting that motor biases could contribute to sequence learning biases. Furthermore, zebra finches spontaneously produced acoustic patterns that are commonly observed in speech and music, suggesting that sensorimotor processes that are shared across a wide range of vertebrates could underlie these patterns in humans.{\textless}/p{\textgreater}},
	author = {James, Logan S. and Sakata, Jon T.},
	doi = {10.1016/j.cub.2017.10.019},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/53RRIG4P/James et Sakata - 2017 - Learning Biases Underlie ``Universals'' in Avian Voc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UP985HPU/S0960-9822(17)31322-2.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	language = {English},
	month = dec,
	note = {Publisher: Elsevier},
	number = {23},
	pages = {3676--3682.e4},
	pmid = {29174890},
	title = {Learning {Biases} {Underlie} ``{Universals}'' in {Avian} {Vocal} {Sequencing}},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31322-2},
	urldate = {2020-04-20},
	volume = {27},
	year = {2017},
	bdsk-url-1 = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31322-2},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2017.10.019}}

@article{musacchia_active_2017,
	abstract = {Language acquisition in infants is driven by on-going neural plasticity that is acutely sensitive to environmental acoustic cues. Recent studies showed that attention-based experience with non-linguistic, temporally-modulated auditory stimuli sharpens cortical responses. A previous ERP study from this laboratory showed that interactive auditory experience via behavior-based feedback (AEx), over a 6-week period from 4- to 7-months-of-age, confers a processing advantage, compared to passive auditory exposure (PEx) or maturation alone (Na{\"\i}ve Control, NC). Here, we provide a follow-up investigation of the underlying neural oscillatory patterns in these three groups. In AEx infants, Standard stimuli with invariant frequency (STD) elicited greater Theta-band (4--6 Hz) activity in Right Auditory Cortex (RAC), as compared to NC infants, and Deviant stimuli with rapid frequency change (DEV) elicited larger responses in Left Auditory Cortex (LAC). PEx and NC counterparts showed less-mature bilateral patterns. AEx infants also displayed stronger Gamma (33--37 Hz) activity in the LAC during DEV discrimination, compared to NCs, while NC and PEx groups demonstrated bilateral activity in this band, if at all. This suggests that interactive acoustic experience with non-linguistic stimuli can promote a distinct, robust and precise cortical pattern during rapid auditory processing, perhaps reflecting mechanisms that support fine-tuning of early acoustic mapping.},
	author = {Musacchia, Gabriella and Ortiz-Mantilla, Silvia and Choudhury, Naseem and Realpe-Bonilla, Teresa and Roesler, Cynthia and Benasich, April A.},
	doi = {10.1016/j.dcn.2017.04.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KS5VMYNR/Musacchia et al. - 2017 - Active auditory experience in infancy promotes bra.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XQHV2LXD/S1878929316301542.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {EEG, Plasticity, Infant, Auditory, Development, Brain oscillations},
	language = {en},
	month = aug,
	pages = {9--19},
	title = {Active auditory experience in infancy promotes brain plasticity in {Theta} and {Gamma} oscillations},
	url = {http://www.sciencedirect.com/science/article/pii/S1878929316301542},
	urldate = {2020-04-29},
	volume = {26},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316301542},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2017.04.004}}

@article{isola_manipulations_2020,
	author = {Isola, Gaurav R. and Vochin, Anca and Sakata, Jon T.},
	doi = {10.1152/jn.00142.2019},
	file = {Isola et al. - 2020 - Manipulations of inhibition in cortical circuitry .pdf:/Users/Cecile/Zotero/storage/3Y7QNUIV/Isola et al. - 2020 - Manipulations of inhibition in cortical circuitry .pdf:application/pdf},
	issn = {0022-3077, 1522-1598},
	journal = {Journal of Neurophysiology},
	language = {en},
	month = feb,
	number = {2},
	pages = {815--830},
	title = {Manipulations of inhibition in cortical circuitry differentially affect spectral and temporal features of {Bengalese} finch song},
	url = {https://www.physiology.org/doi/10.1152/jn.00142.2019},
	urldate = {2020-05-05},
	volume = {123},
	year = {2020},
	bdsk-url-1 = {https://www.physiology.org/doi/10.1152/jn.00142.2019},
	bdsk-url-2 = {https://doi.org/10.1152/jn.00142.2019}}

@article{deoni_mapping_2011,
	abstract = {Myelination, the elaboration of myelin surrounding neuronal axons, is essential for normal brain function. The development of the myelin sheath enables rapid synchronized communication across the neural systems responsible for higher order cognitive functioning. Despite this critical role, quantitative visualization of myelination in vivo is not possible with current neuroimaging techniques including diffusion tensor and structural magnetic resonance imaging (MRI). Although these techniques offer insight into structural maturation, they reflect several different facets of development, e.g., changes in axonal size, density, coherence, and membrane structure; lipid, protein, and macromolecule content; and water compartmentalization. Consequently, observed signal changes are ambiguous, hindering meaningful inferences between imaging findings and metrics of learning, behavior or cognition. Here we present the first quantitative study of myelination in healthy human infants, from 3 to 11 months of age. Using a new myelin-specific MRI technique, we report a spatiotemporal pattern beginning in the cerebellum, pons, and internal capsule; proceeding caudocranially from the splenium of the corpus callosum and optic radiations (at 3--4 months); to the occipital and parietal lobes (at 4--6 months); and then to the genu of the corpus callosum and frontal and temporal lobes (at 6--8 months). Our results also offer preliminary evidence of hemispheric myelination rate differences. This work represents a significant step forward in our ability to appreciate the fundamental process of myelination, and provides the first ever in vivo visualization of myelin maturation in healthy human infancy.},
	author = {Deoni, Sean C. L. and Mercure, Evelyne and Blasi, Anna and Gasston, David and Thomson, Alex and Johnson, Mark and Williams, Steven C. R. and Murphy, Declan G. M.},
	copyright = {Copyright {\copyright} 2011 the authors 0270-6474/11/310784-08\$15.00/0},
	doi = {10.1523/JNEUROSCI.2106-10.2011},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ZLTX5NE2/Deoni et al. - 2011 - Mapping Infant Brain Myelination with Magnetic Res.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/LM8C25LV/784.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = jan,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {2},
	pages = {784--791},
	pmid = {21228187},
	title = {Mapping {Infant} {Brain} {Myelination} with {Magnetic} {Resonance} {Imaging}},
	url = {https://www.jneurosci.org/content/31/2/784},
	urldate = {2020-05-05},
	volume = {31},
	year = {2011},
	bdsk-url-1 = {https://www.jneurosci.org/content/31/2/784},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2106-10.2011}}

@article{cheour_speech_2002,
	abstract = {It is not yet clear whether humans are able to learn while they are sleeping1,2. Here we show that full-term human newborns can be taught to discriminate between similar vowel sounds when they are fast asleep. It is possible that such sleep training soon after birth could find application in clinical or educational situations3,4.},
	author = {Cheour, M. and Martynova, O. and N{\"a}{\"a}t{\"a}nen, R. and Erkkola, R. and Sillanp{\"a}{\"a}, M. and Kero, P. and Raz, A. and Kaipio, M.-L. and Hiltunen, J. and Aaltonen, O. and Savela, J. and H{\"a}m{\"a}l{\"a}inen, H.},
	copyright = {2002 Nature Publishing Group},
	doi = {10.1038/415599b},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/34662XQ8/Cheour et al. - 2002 - Speech sounds learned by sleeping newborns.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VQFRDIWZ/415599b.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = feb,
	note = {Number: 6872 Publisher: Nature Publishing Group},
	number = {6872},
	pages = {599--600},
	title = {Speech sounds learned by sleeping newborns},
	url = {https://www.nature.com/articles/415599b},
	urldate = {2020-05-14},
	volume = {415},
	year = {2002},
	bdsk-url-1 = {https://www.nature.com/articles/415599b},
	bdsk-url-2 = {https://doi.org/10.1038/415599b}}

@article{chen_origins_2020,
	abstract = {Acoustic communication is crucial to humans and many other tetrapods, including birds, frogs, crocodilians, and mammals. However, large-scale patterns in its evolution are largely unstudied. Here, we address several fundamental questions about the origins of acoustic communication in terrestrial vertebrates (tetrapods), using phylogenetic methods. We show that origins of acoustic communication are significantly associated with nocturnal activity. We find that acoustic communication does not increase diversification rates, a surprising result given the many speciation-focused studies of frog calls and bird songs. We also demonstrate that the presence of acoustic communication is strongly conserved over time. Finally, we find that acoustic communication evolved independently in most major tetrapod groups, often with remarkably ancient origins ({\textasciitilde}100--200 million years ago). Overall, we show that the role of ecology in shaping signal evolution applies to surprisingly deep timescales, whereas the role of signal evolution in diversification may not.},
	author = {Chen, Zhuo and Wiens, John J.},
	copyright = {2020 The Author(s)},
	doi = {10.1038/s41467-020-14356-3},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NEYXDBYL/Chen et Wiens - 2020 - The origins of acoustic communication in vertebrat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZFTU847L/s41467-020-14356-3.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = jan,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {369},
	title = {The origins of acoustic communication in vertebrates},
	url = {https://www.nature.com/articles/s41467-020-14356-3},
	urldate = {2020-05-15},
	volume = {11},
	year = {2020},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-020-14356-3},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-020-14356-3}}

@article{chen_magnetoencephalography_2019,
	abstract = {Magnetoencephalography (MEG) is a non-invasive neuroimaging technique that provides whole-head measures of neural activity with millisecond temporal resolution. Over the last three decades, MEG has been used for assessing brain activity, most commonly in adults. MEG has been used less often to examine neural function during early development, in large part due to the fact that infant whole-head MEG systems have only recently been developed. In this review, an overview of infant MEG studies is provided, focusing on the period from birth to three years. The advantages of MEG for measuring neural activity in infants are highlighted (See ), including the ability to assess activity in brain (source) space rather than sensor space, thus allowing direct assessment of neural generator activity. Recent advances in MEG hardware and source analysis are also discussed. As the review indicates, efforts in this area demonstrate that MEG is a promising technology for studying the infant brain. As a noninvasive technology, with emerging hardware providing the necessary sensitivity, an expected deliverable is the capability for longitudinal infant MEG studies evaluating the developmental trajectory (maturation) of neural activity. It is expected that departures from neuro-typical trajectories will offer early detection and prognosis insights in infants and toddlers at-risk for neurodevelopmental disorders, thus paving the way for early targeted interventions.},
	author = {Chen, Yu-Han and Saby, Joni and Kuschner, Emily and Gaetz, William and Edgar, J. Christopher and Roberts, Timothy P.L.},
	doi = {10.1016/j.neuroimage.2019.01.059},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Z28W6BRY/Chen et al. - 2019 - Magnetoencephalography and the infant brain.pdf:application/pdf},
	issn = {1053-8119},
	journal = {NeuroImage},
	month = apr,
	pages = {445--458},
	pmcid = {PMC6662211},
	pmid = {30685329},
	title = {Magnetoencephalography and the infant brain},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662211/},
	urldate = {2020-05-25},
	volume = {189},
	year = {2019},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662211/},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2019.01.059}}

@article{wakai_slow_2016,
	abstract = {Objective
To investigate the slow rhythm and its relationship to spindling in early infancy. Methods
We analyzed sleep MEG recordings containing sleep spindles, taken from 7 normal, healthy subjects at conceptional age 46--63 weeks in 21 sessions.
Results
We show that the sleep MEG in early infancy contains a slow rhythm, centered at approximately 0.2Hz, which showed a striking association with spindling. The slow rhythm grouped sleep spindles, which were clock-like with a recurrence rate of approximately 0.1Hz.
Conclusions
The association of the 0.2Hz oscillation and low delta rhythms with spindling was so strong as to suggest that they may play a critical role during brain development in the genesis of sleep spindles.
Significance
Infant brain rhythms exhibit relatively simple, regular behavior, allowing the relationships between them to be more easily discerned.},
	author = {Wakai, R. T. and Lutter, W. J.},
	doi = {10.1016/j.neulet.2016.07.051},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XN3AHWE4/S0304394016305456.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/7AVN5UCN/Wakai et Lutter - 2016 - Slow rhythms and sleep spindles in early infancy.pdf:application/pdf},
	issn = {0304-3940},
	journal = {Neuroscience Letters},
	keywords = {Magnetoencephalography, Sleep spindles, Slow rhythm},
	language = {en},
	month = sep,
	pages = {164--168},
	title = {Slow rhythms and sleep spindles in early infancy},
	url = {http://www.sciencedirect.com/science/article/pii/S0304394016305456},
	urldate = {2020-05-27},
	volume = {630},
	year = {2016},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394016305456},
	bdsk-url-2 = {https://doi.org/10.1016/j.neulet.2016.07.051}}

@techreport{santolin_experience_2020,
	abstract = {Interpreting and predicting direction of preference in infant behavioral research has been a thorny issue for decades. Several factors have been proposed to account for familiarity and novelty preferences in habituation and familiarization studies, including infant age, length of exposure and task complexity. The current study explores an additional dimension that may affect direction of preference: amount of experience with the experimental task. To test this hypothesis, we re-analyzed the data from 4 experiments on artificial grammar learning in 12-month-old infants run using the Head- turn Preference Procedure (HPP). The participants in these studies varied substantially in their number of laboratory visits. Linear mixed-effects results show that the number of HPP studies in which infants had previously participated is related to infants' direction of preference: infants who had no (or limited) experience with the HPP setting were more likely to show familiarity preferences than infants who had amassed more experience with this task in prior study visits. Interestingly, the effect is driven by a significant decrease in looking time for familiar trials. These results have important implications for the interpretation of experimental results: infants' experience with a given paradigm or, more broadly, with the lab environment, may affect their patterns of preferences.},
	author = {Santolin, Chiara and Garc{\'\i}a-Castro, Gonzalo and Zettersten, Martin and Sebastian-Galles, Nuria and Saffran, Jenny},
	doi = {10.31234/osf.io/xgvbh},
	file = {Santolin et al. - 2020 - Experience with research paradigms relates to infa.pdf:/Users/Cecile/Zotero/storage/434G6AG7/Santolin et al. - 2020 - Experience with research paradigms relates to infa.pdf:application/pdf},
	institution = {PsyArXiv},
	language = {en},
	month = mar,
	title = {Experience with research paradigms relates to infants' direction of preference},
	type = {preprint},
	url = {https://osf.io/xgvbh},
	urldate = {2020-05-29},
	year = {2020},
	bdsk-url-1 = {https://osf.io/xgvbh},
	bdsk-url-2 = {https://doi.org/10.31234/osf.io/xgvbh}}

@article{lewkowicz_decline_2006,
	author = {Lewkowicz, D. J. and Ghazanfar, A. A.},
	doi = {10.1073/pnas.0602027103},
	file = {Lewkowicz et Ghazanfar - 2006 - The decline of cross-species intersensory percepti.pdf:/Users/Cecile/Zotero/storage/L42B2CFX/Lewkowicz et Ghazanfar - 2006 - The decline of cross-species intersensory percepti.pdf:application/pdf},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = apr,
	number = {17},
	pages = {6771--6774},
	title = {The decline of cross-species intersensory perception in human infants},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0602027103},
	urldate = {2020-06-11},
	volume = {103},
	year = {2006},
	bdsk-url-1 = {http://www.pnas.org/cgi/doi/10.1073/pnas.0602027103},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0602027103}}

@article{moon_syllables_1990,
	abstract = {Neonates demonstrated two-stimulus auditory operant discrimination by altering nonnutritive sucking patterns during an 18-min session. Discriminative stimuli were two isolated, repeated syllables, and reinforcers were a recording of mother's adult-directed speech and quiet. During the final 6 min, 16 of 20 subjects (M age = 55 hours) initiated bursts of sucking relatively more frequently during the syllable which signalled the availability of the recording of mother's voice versus quiet. In addition to providing new evidence of newborn speech perception and learning capacities, the results suggest a useful method for investigating neonatal auditory perception.},
	author = {Moon, Christine and Fifer, William P.},
	doi = {10.1016/0163-6383(90)90041-6},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/6PG9F6CL/Moon et Fifer - 1990 - Syllables as signals for 2-day-old infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YA8H4ZU2/0163638390900416.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {discrimination, learning, audition, mother's voice, newborn nonnutritive sucking, syllable},
	language = {en},
	month = jul,
	number = {3},
	pages = {377--390},
	title = {Syllables as signals for 2-day-old infants},
	url = {http://www.sciencedirect.com/science/article/pii/0163638390900416},
	urldate = {2020-06-12},
	volume = {13},
	year = {1990},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/0163638390900416},
	bdsk-url-2 = {https://doi.org/10.1016/0163-6383(90)90041-6}}

@article{spence_newborn_1996,
	abstract = {This research examined the hypothesis that prenatally available acoustic properties of the maternal voice support newborns' recognition of the maternal voice. We addressed this question first by assessing infants' preference for maternal voice samples that preserved the lower vocal frequencies which are salient in the uterine environment and second by assessing newborns' preference for maternal whispered voice samples that are produced without voicing and do not contain low frequencies. Infants preferred their mothers' voices over unfamiliar female voices when presented 500-Hz low-pass filtered voice samples in a nonnutritive sucking operant choice procedure. Infants did not prefer their mothers' whispered voices, suggesting that they did not recognize them. Three additional experiments further clarified this interpretation. These experiments demonstrated that infants hear whispered voices and that they discriminate unfamiliar whispered voices. Additionally, whispered voices were not reinforcing for newborns, suggesting that acoustic properties that contribute to the reinforcing value of female voices are not present in whispering. These results indicate that vocal properties that are available prenatally are sufficient to support newborns' preference for the maternal voice, and they suggest that fundamental frequency is important for neonatal voice recognition.},
	author = {Spence, Melanie J. and Freeman, Mark S.},
	doi = {10.1016/S0163-6383(96)90019-3},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/LPH8H62Q/Spence et Freeman - 1996 - Newborn infants prefer the maternal low-pass filte.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/IIPD66C6/S0163638396900193.html:text/html},
	issn = {0163-6383},
	journal = {Infant Behavior and Development},
	keywords = {newborns, auditory preferences, maternal voice recognition prenatal experience, nonnutritive sucking},
	language = {en},
	month = apr,
	number = {2},
	pages = {199--212},
	title = {Newborn infants prefer the maternal low-pass filtered voice, but not the maternal whispered voice},
	url = {http://www.sciencedirect.com/science/article/pii/S0163638396900193},
	urldate = {2020-06-12},
	volume = {19},
	year = {1996},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638396900193},
	bdsk-url-2 = {https://doi.org/10.1016/S0163-6383(96)90019-3}}

@article{simon_sleep_2017,
	abstract = {Infants show robust ability to track transitional probabilities within language and can use this information to extract words from continuous speech. The degree to which infants remember these words across a delay is unknown. Given well-established benefits of sleep on long-term memory retention in adults, we examine whether sleep similarly facilitates memory in 6.5month olds. Infants listened to an artificial language for 7minutes, followed by a period of sleep or wakefulness. After a time-matched delay for sleep and wakefulness dyads, we measured retention using the head-turn-preference procedure. Infants who slept retained memory for the extracted words that was prone to interference during the test. Infants who remained awake showed no retention. Within the nap group, retention correlated with three electrophysiological measures (1) absolute theta across the brain, (2) absolute alpha across the brain, and (3) greater fronto-central slow wave activity (SWA).},
	author = {Simon, Katharine N. S. and Werchan, Denise and Goldstein, Michael R. and Sweeney, Lucia and Bootzin, Richard R. and Nadel, Lynn and G{\'o}mez, Rebecca L.},
	doi = {10.1016/j.bandl.2016.05.002},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/HHIF2VVA/S0093934X15301504.html:text/html},
	issn = {0093-934X},
	journal = {Brain and Language},
	keywords = {Sleep, Infants, Language acquisition, Memory retention, Statistical learning},
	language = {en},
	month = apr,
	pages = {3--12},
	series = {Sleep and language learning},
	title = {Sleep confers a benefit for retention of statistical language learning in 6.5month old infants},
	url = {http://www.sciencedirect.com/science/article/pii/S0093934X15301504},
	urldate = {2020-06-19},
	volume = {167},
	year = {2017},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X15301504},
	bdsk-url-2 = {https://doi.org/10.1016/j.bandl.2016.05.002}}

@article{rovee-collier_development_1999,
	abstract = {Over the first year and a half of life, the duration of memory becomes progressively longer, the specificity of the cues required for recognition progressively decreases after short test delays, and the latency of priming progressively decreases to the adult level. The memory dissociations of very young infants on recognition and priming tasks, which presumably tap different memory systems, are also identical to those of adults. These parallels suggest that both memory systems are present very early in development instead of emerging hierarchically over the 1st year, as previously thought. Finally, even young infants can remember an event over the entire ``infantile amnesia'' period if they are periodically exposed to appropriate nonverbal reminders. In short, the same fundamental mechanisms appear to underlie memory processing in infants and adults.},
	author = {Rovee-Collier, Carolyn},
	doi = {10.1111/1467-8721.00019},
	file = {SAGE PDF Full Text:/Users/Cecile/Zotero/storage/5YRYWVCK/Rovee-Collier - 1999 - The Development of Infant Memory.pdf:application/pdf},
	issn = {0963-7214},
	journal = {Current Directions in Psychological Science},
	language = {en},
	month = jun,
	note = {Publisher: SAGE Publications Inc},
	number = {3},
	pages = {80--85},
	title = {The {Development} of {Infant} {Memory}},
	url = {https://doi.org/10.1111/1467-8721.00019},
	urldate = {2020-06-19},
	volume = {8},
	year = {1999},
	bdsk-url-1 = {https://doi.org/10.1111/1467-8721.00019}}

@article{kurth_sleep_2015,
	abstract = {Sleep is increasingly recognized as a key process in neurodevelopment. Animal data show that sleep is essential for the maturation of fundamental brain functions, and growing epidemiological findings indicate that children with early sleep disturbance suffer from later cognitive, attentional, and psychosocial problems. Still, major gaps exist in understanding processes underlying links between sleep and neurodevelopment. One challenge is to translate findings from animal research to humans. In this review, we describe parallels and differences in sleep and development of the cortex in humans and animals and discuss emerging questions.},
	author = {Kurth, Salome and Olini, Nadja and Huber, Reto and LeBourgeois, Monique},
	doi = {10.1007/s40675-014-0002-8},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/MSM9FPE9/Kurth et al. - 2015 - Sleep and Early Cortical Development.pdf:application/pdf},
	issn = {2198-6401},
	journal = {Current Sleep Medicine Reports},
	language = {en},
	month = mar,
	number = {1},
	pages = {64--73},
	title = {Sleep and {Early} {Cortical} {Development}},
	url = {https://doi.org/10.1007/s40675-014-0002-8},
	urldate = {2020-06-19},
	volume = {1},
	year = {2015},
	bdsk-url-1 = {https://doi.org/10.1007/s40675-014-0002-8}}

@article{ednick_review_2009,
	abstract = {Abstract.  During the first year of life, infants spend most of their time in the sleeping state. Assessment of sleep during infancy presents an opportunity to},
	author = {Ednick, Mathew and Cohen, Aliza P. and McPhail, Gary L. and Beebe, Dean and Simakajornboon, Narong and Amin, Raouf S.},
	doi = {10.1093/sleep/32.11.1449},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IF5PDHBE/Ednick et al. - 2009 - A Review of the Effects of Sleep During the First .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q6JEU6J9/2454347.html:text/html},
	issn = {0161-8105},
	journal = {Sleep},
	language = {en},
	month = nov,
	note = {Publisher: Oxford Academic},
	number = {11},
	pages = {1449--1458},
	title = {A {Review} of the {Effects} of {Sleep} {During} the {First} {Year} of {Life} on {Cognitive}, {Psychomotor}, and {Temperament} {Development}},
	url = {https://academic.oup.com/sleep/article/32/11/1449/2454347},
	urldate = {2020-06-19},
	volume = {32},
	year = {2009},
	bdsk-url-1 = {https://academic.oup.com/sleep/article/32/11/1449/2454347},
	bdsk-url-2 = {https://doi.org/10.1093/sleep/32.11.1449}}

@article{feigenson_conceptual_2008,
	author = {Feigenson, L. and Halberda, J.},
	doi = {10.1073/pnas.0709884105},
	file = {Feigenson et Halberda - 2008 - Conceptual knowledge increases infants' memory cap.pdf:/Users/Cecile/Zotero/storage/IP5IDNVS/Feigenson et Halberda - 2008 - Conceptual knowledge increases infants' memory cap.pdf:application/pdf},
	issn = {0027-8424, 1091-6490},
	journal = {Proceedings of the National Academy of Sciences},
	language = {en},
	month = jul,
	number = {29},
	pages = {9926--9930},
	title = {Conceptual knowledge increases infants' memory capacity},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0709884105},
	urldate = {2020-06-19},
	volume = {105},
	year = {2008},
	bdsk-url-1 = {http://www.pnas.org/cgi/doi/10.1073/pnas.0709884105},
	bdsk-url-2 = {https://doi.org/10.1073/pnas.0709884105}}

@article{friedrich_sleep-dependent_2020,
	abstract = {Any experienced event may be encoded and retained in detail as part of our episodic memory, and may also refer and contribute to our generalized knowledge stored in semantic memory. The beginnings of this declarative memory formation are only poorly understood. Even less is known about the interrelation between episodic and semantic memory during the earliest developmental stages. Here, we show that the formation of episodic memories in 14- to 17-month-old infants depends on sleep, subsequent to exposure to novel events. Infant brain responses reveal that, after sleep-dependent consolidation, the newly stored events are not processed semantically, although appropriate lexical-semantic memories are present and accessible by similar events that were not experienced before the nap. We propose that temporarily disabled semantic processing protects precise episodic memories from interference with generalized semantic memories. Selectively restricted semantic access could also trigger semantic refinement, and thus, might even improve semantic memory.},
	author = {Friedrich, Manuela and M{\"o}lle, Matthias and Friederici, Angela D. and Born, Jan},
	copyright = {2020 The Author(s)},
	doi = {10.1038/s41467-020-14850-8},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/T62662UN/Friedrich et al. - 2020 - Sleep-dependent memory consolidation in infants pr.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2D5U7XQY/s41467-020-14850-8.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = mar,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {1298},
	title = {Sleep-dependent memory consolidation in infants protects new episodic memories from existing semantic memories},
	url = {https://www.nature.com/articles/s41467-020-14850-8},
	urldate = {2020-06-22},
	volume = {11},
	year = {2020},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-020-14850-8},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-020-14850-8}}

@misc{santolin_infants_2020,
	abstract = {Data and experimental materials for experiments on infants' preferences for auditory stimuli},
	annote = {*},
	author = {Santolin, Chiara and Zettersten, Martin and Saffran, Jenny R.},
	copyright = {MIT License , MIT License},
	date-modified = {2022-04-05 16:56:31 +0200},
	month = jul,
	note = {original-date: 2020-07-15T23:50:27Z},
	title = {Infants' preference for non-native speech versus birdsong. {Unpublished} data.},
	url = {https://github.com/mzettersten/birdsong},
	urldate = {2020-07-17},
	year = {2020},
	bdsk-url-1 = {https://github.com/mzettersten/birdsong}}

@article{turati_why_2004,
	author = {Turati, Chiara},
	doi = {10.1111/j.0963-7214.2004.01301002.x},
	issn = {0963-7214, 1467-8721},
	journal = {Current Directions in Psychological Science},
	language = {en},
	month = feb,
	number = {1},
	pages = {5--8},
	shorttitle = {Why {Faces} {Are} {Not} {Special} to {Newborns}},
	title = {Why {Faces} {Are} {Not} {Special} to {Newborns}: {An} {Alternative} {Account} of the {Face} {Preference}},
	url = {http://journals.sagepub.com/doi/10.1111/j.0963-7214.2004.01301002.x},
	urldate = {2020-07-08},
	volume = {13},
	year = {2004},
	bdsk-url-1 = {http://journals.sagepub.com/doi/10.1111/j.0963-7214.2004.01301002.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.0963-7214.2004.01301002.x}}

@article{layden_experience_2020,
	abstract = {One of the central questions of neuroethology is how specialized brain areas communicate to form dynamic networks that support complex cognitive and behavioral processes. Developmental song learning in the male zebra finch songbird (Taeniopygia guttata) provides a unique window into the complex interplay among sensory, sensorimotor, and motor network nodes. The foundation of a young male's song structure is the sensory memory he forms during interactions with an adult "tutor." However, even in the absence of tutoring, juveniles produce a song-like behavior. Thus, by controlling a juvenile male's tutor exposure, we can examine how tutor experience affects distributed neural networks and how network properties predict behavior. Here, we used longitudinal, resting-state fMRI (rs-fMRI) functional connectivity (FC) and song analyses to examine known nodes of the song network, and to allow discovery of additional areas functionally related to song learning. We present three major novel findings. First, tutor deprivation significantly reduced the global FC strength of the caudomedial nidopallium (NCM) subregion of the auditory forebrain required for sensory song learning. Second, tutor deprivation resulted in reduced FC between NCM and cerebellar lobule VI, a region analogous to areas that regulate limbic, social, and language functions in humans. Third, NCM FC strength predicted song stereotypy and mediated the relationship between tutoring and stereotypy, thus completing the link between experience, neural network properties, and complex learned behavior.},
	author = {Layden, Elliot A. and Li, Huibo and Schertz, Kathryn E. and Berman, Marc G. and London, Sarah E.},
	doi = {10.1016/j.neuroimage.2020.117218},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/7UHSW32Y/Layden et al. - 2020 - Experience selectively alters functional connectiv.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T974ABH6/S1053811920307047.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {songbird, zebra finch, song learning, auditory forebrain, critical period, neural plasticity},
	language = {en},
	month = aug,
	pages = {117218},
	title = {Experience selectively alters functional connectivity within a neural network to predict learned behavior in juvenile songbirds},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811920307047},
	urldate = {2020-08-06},
	year = {2020},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811920307047},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2020.117218}}

@article{yanagihara_auditory_2016,
	abstract = {As in human speech acquisition, songbird vocal learning depends on early auditory experience. During development, juvenile songbirds listen to and form auditory memories of adult tutor songs, which they use to shape their own vocalizations in later sensorimotor learning. The higher-level auditory cortex, called the caudomedial nidopallium (NCM), is a potential storage site for tutor song memory, but no direct electrophysiological evidence of tutor song memory has been found. Here, we identify the neuronal substrate for tutor song memory by recording single-neuron activity in the NCM of behaving juvenile zebra finches. After tutor song experience, a small subset of NCM neurons exhibit highly selective auditory responses to the tutor song. Moreover, blockade of GABAergic inhibition, and sleep decrease their selectivity. Taken together, these results suggest that experience-dependent recruitment of GABA-mediated inhibition shapes auditory cortical circuits, leading to sparse representation of tutor song memory in auditory cortical neurons.},
	author = {Yanagihara, Shin and Yazaki-Sugiyama, Yoko},
	copyright = {2016 The Author(s)},
	doi = {10.1038/ncomms11946},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ISWRHPDS/Yanagihara et Yazaki-Sugiyama - 2016 - Auditory experience-dependent cortical circuit sha.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/93KXV9S3/ncomms11946.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = jun,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {11946},
	title = {Auditory experience-dependent cortical circuit shaping for memory formation in bird song learning},
	url = {https://www.nature.com/articles/ncomms11946},
	urldate = {2020-08-11},
	volume = {7},
	year = {2016},
	bdsk-url-1 = {https://www.nature.com/articles/ncomms11946},
	bdsk-url-2 = {https://doi.org/10.1038/ncomms11946}}

@article{london_functional_2008,
	abstract = {A young male zebra finch (Taeniopygia guttata) learns to sing by copying the vocalizations of an older tutor in a process that parallels human speech acquisition. Brain pathways that control song production are well defined, but little is known about the sites and mechanisms of tutor song memorization. Here we test the hypothesis that molecular signaling in a sensory brain area outside of the song system is required for developmental song learning. Using controlled tutoring and a pharmacological inhibitor, we transiently suppressed the extracellular signal--regulated kinase signaling pathway in a portion of the auditory forebrain specifically during tutor song exposure. On maturation, treated birds produced poor copies of tutor song, whereas controls copied the tutor song effectively. Thus the foundation of normal song learning, the formation of a sensory memory of tutor song, requires a conserved molecular pathway in a brain area that is distinct from the circuit for song motor control.},
	author = {London, Sarah E. and Clayton, David F.},
	copyright = {2008 Nature Publishing Group},
	doi = {10.1038/nn.2103},
	file = {Snapshot:/Users/Cecile/Zotero/storage/UTQHKQAE/nn.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/I7W6BW4T/London et Clayton - 2008 - Functional identification of sensory mechanisms re.pdf:application/pdf},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = may,
	note = {Number: 5 Publisher: Nature Publishing Group},
	number = {5},
	pages = {579--586},
	title = {Functional identification of sensory mechanisms required for developmental song learning},
	url = {https://www.nature.com/articles/nn.2103},
	urldate = {2020-08-13},
	volume = {11},
	year = {2008},
	bdsk-url-1 = {https://www.nature.com/articles/nn.2103},
	bdsk-url-2 = {https://doi.org/10.1038/nn.2103}}

@article{heron-delaney_infants_2011,
	abstract = {Recognition of individuals at first sight is important for social species and can be achieved by attending to facial or body information. Previous research suggests that infants possess a perceptual template for evolutionarily relevant stimuli, which may include humans, dangerous animals (e.g. snakes), but not non-dangerous animals. To be effective, such a mechanism should result in a systematic preference for attending to humans over non-dangerous animals. Using a preferential looking paradigm, the present studies investigated the nature of infants' early representation of humans. We show that 3.5- and six-month-old infants attend more to human beings than non-human primates (a gorilla or monkey) which are examplars of non-dangerous animals. This occurred when infants were presented with head or body information in isolation, as well as when both are presented simultaneously. This early preference for humans by 3.5 months of age suggests that there is a basic representation for humans, which includes both head and/or body information. However, neonates demonstrated a preference only for human faces over non-human primate faces, not for humans over non-human primates when the stimuli were presented with both head and body simultaneously. The results show that although neonates display a preference for human faces over others, preference for the human body only develops later, in the first few months of life. This suggests that infants have acquired some knowledge about the human body at 3.5 months of age that may have developed from their privileged experience with other humans in the first few months of life, rather than an innate ability to detect humans in their entirety.},
	author = {Heron-Delaney, Michelle and Wirth, Sylvia and Pascalis, Olivier},
	doi = {10.1098/rstb.2010.0371},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LSHDHWTF/Heron-Delaney et al. - 2011 - Infants' knowledge of their own species.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RQRKM3AY/rstb.2010.html:text/html},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	month = jun,
	note = {Publisher: Royal Society},
	number = {1571},
	pages = {1753--1763},
	title = {Infants' knowledge of their own species},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2010.0371},
	urldate = {2020-08-19},
	volume = {366},
	year = {2011},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2010.0371},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2010.0371}}

@incollection{bem_writing_2004,
	abstract = {The purpose of this chapter is to enhance the chances that academic psychologists get their empirical articles published. Because I write, review, and edit primarily for journals in personality and social psychology, I have drawn most of my examples from those areas. Colleagues assure me, however, that the guidelines set forth are also pertinent for articles in experimental psychology and biopsychology. Similarly, this chapter focuses on an empirical study, but the general writing suggestions apply as well to the theoretical articles, literature reviews, and methodological contributions that also appear in psychology journals. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	address = {Washington, DC, US},
	author = {Bem, Daryl J.},
	booktitle = {The compleat academic: {A} career guide, 2nd ed},
	file = {Bem - Writing the Empirical Journal Article.pdf:/Users/Cecile/Zotero/storage/LNSFVVSE/Bem - Writing the Empirical Journal Article.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U4WVG5ER/2003-06256-010.html:text/html},
	isbn = {978-1-59147-035-9},
	keywords = {Experimental Psychology, Scientific Communication, Written Communication},
	pages = {185--219},
	publisher = {American Psychological Association},
	title = {Writing the empirical journal article},
	year = {2004}}

@article{eyre_developing_2020,
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}The Developing Human Connectome Project (dHCP) is an Open Science project which provides the first large sample of neonatal functional MRI (fMRI) data with high temporal and spatial resolution. This data enables mapping of intrinsic functional connectivity between spatially distributed brain regions under normal and adverse perinatal circumstances, offering a framework to study the ontogeny of large-scale brain organisation in humans. Here, we characterise in unprecedented detail the maturation and integrity of resting-state networks (RSNs) at normal term age in 337 infants (including 65 born preterm).{\textless}/p{\textgreater}{\textless}p{\textgreater}First, we applied group independent component analysis (ICA) to define 11 RSNs in term-born infants scanned at 43.5-44.5 weeks postmenstrual age (PMA). Adult-like topography was observed in RSNs encompassing primary sensorimotor, visual and auditory cortices. Among six higher-order, association RSNs, analogues of the adult networks for language and ocular control were identified, but a complete default mode network precursor was not. Next, we regressed the subject-level datasets from an independent cohort of infants scanned at 37-43.5 weeks PMA against the group-level RSNs to test for the effects of age, sex and preterm birth. Brain mapping in term-born infants revealed areas of positive association with age across four of six association RSNs, indicating active maturation in functional connectivity from 37 to 43.5 weeks PMA. Female infants showed increased connectivity in inferotemporal regions of the visual association network. Preterm birth was associated with striking impairments of functional connectivity across all RSNs in a dose-dependent manner; conversely, connectivity of the superior parietal lobules within the lateral motor network was abnormally increased in preterm infants, suggesting a possible mechanism for specific difficulties such as developmental coordination disorder which occur frequently in preterm children.{\textless}/p{\textgreater}{\textless}p{\textgreater}Overall, we find a robust, modular, symmetrical functional brain organisation at normal term age. A complete set of adult-equivalent primary RSNs is already instated, alongside emerging connectivity in immature association RSNs, consistent with a primary-to-higher-order ontogenetic sequence of brain development. The early developmental disruption imposed by preterm birth is associated with extensive alterations in functional connectivity.{\textless}/p{\textgreater}},
	author = {Eyre, Michael and Fitzgibbon, Sean P. and Ciarrusta, Judit and Cordero-Grande, Lucilio and Price, Anthony N. and Poppe, Tanya and Schuh, Andreas and Hughes, Emer and O'Keeffe, Camilla and Brandon, Jakki and Cromb, Daniel and Vecchiato, Katy and Andersson, Jesper and Duff, Eugene P. and Counsell, Serena J. and Smith, Stephen M. and Rueckert, Daniel and Hajnal, Joseph V. and Arichi, Tomoki and O'Muircheartaigh, Jonathan and Batalle, Dafnis and Edwards, A. David},
	copyright = {{\copyright} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	doi = {10.1101/2020.01.20.912881},
	journal = {bioRxiv},
	language = {en},
	month = jan,
	note = {Publisher: Cold Spring Harbor Laboratory Section: New Results},
	pages = {2020.01.20.912881},
	shorttitle = {The {Developing} {Human} {Connectome} {Project}},
	title = {The {Developing} {Human} {Connectome} {Project}: typical and disrupted functional connectivity across the perinatal period},
	url = {https://www.biorxiv.org/content/10.1101/2020.01.20.912881v1},
	urldate = {2020-09-02},
	year = {2020},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/2020.01.20.912881v1},
	bdsk-url-2 = {https://doi.org/10.1101/2020.01.20.912881}}

@article{van_dyke_development_2017,
	abstract = {Purpose
This study investigates the development of phase locking and frequency representation in infants using the frequency-following response to consonant--vowel syllables.

Method
The frequency-following response was recorded in 56 infants and 15 young adults to 2 speech syllables (/ba/ and /ga/), which were presented in randomized order to the right ear. Signal-to-noise ratio and Fsp analyses were used to verify that individual responses were present above the noise floor. Thirty-six and 39 infants met these criteria for the /ba/ or /ga/ syllables, respectively, and 31 infants met the criteria for both syllables. Data were analyzed to obtain measures of phase-locking strength and spectral magnitudes.

Results
Phase-locking strength to the fine structure in the consonant--vowel transition was higher in young adults than in infants, but phase locking was equivalent at the fundamental frequency between infants and adults. However, frequency representation of the fundamental frequency was higher in older infants than in either the younger infants or adults.

Conclusion
Although spectral amplitudes changed during the first year of life, no changes were found with respect to phase locking to the stimulus envelope. These findings demonstrate the feasibility of obtaining these measures of phase locking and fundamental pitch strength in infants as young as 2 months of age.},
	author = {Van Dyke, Katlyn B. and Lieberman, Rachel and Presacco, Alessandro and Anderson, Samira},
	doi = {10.1044/2017_JSLHR-H-16-0263},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/EPG49NVW/Van Dyke et al. - 2017 - Development of Phase Locking and Frequency Represe.pdf:application/pdf},
	issn = {1092-4388},
	journal = {Journal of Speech, Language, and Hearing Research : JSLHR},
	month = sep,
	number = {9},
	pages = {2740--2751},
	pmcid = {PMC5831628},
	pmid = {28832878},
	title = {Development of {Phase} {Locking} and {Frequency} {Representation} in the {Infant} {Frequency}-{Following} {Response}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831628/},
	urldate = {2020-09-02},
	volume = {60},
	year = {2017},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831628/},
	bdsk-url-2 = {https://doi.org/10.1044/2017_JSLHR-H-16-0263}}

@misc{noauthor_systematic_nodate,
	title = {Systematic mapping of developmental milestones in wild chimpanzees - {Br{\"u}ndl} - - {Developmental} {Science} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12988},
	urldate = {2020-09-29},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/full/10.1111/desc.12988}}

@misc{noauthor_chimpanzee_nodate,
	title = {Chimpanzee {Alarm} {Call} {Production} {Meets} {Key} {Criteria} for {Intentionality}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076674},
	urldate = {2020-09-29},
	bdsk-url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076674}}

@article{schel_chimpanzee_2013,
	abstract = {Determining the intentionality of primate communication is critical to understanding the evolution of human language. Although intentional signalling has been claimed for some great ape gestural signals, comparable evidence is currently lacking for their vocal signals. We presented wild chimpanzees with a python model and found that two of three alarm call types exhibited characteristics previously used to argue for intentionality in gestural communication. These alarm calls were: (i) socially directed and given to the arrival of friends, (ii) associated with visual monitoring of the audience and gaze alternations, and (iii) goal directed, as calling only stopped when recipients were safe from the predator. Our results demonstrate that certain vocalisations of our closest living relatives qualify as intentional signals, in a directly comparable way to many great ape gestures. We conclude that our results undermine a central argument of gestural theories of language evolution and instead support a multimodal origin of human language.},
	author = {Schel, Anne Marijke and Townsend, Simon W. and Machanda, Zarin and Zuberb{\"u}hler, Klaus and Slocombe, Katie E.},
	doi = {10.1371/journal.pone.0076674},
	issn = {1932-6203},
	journal = {PLOS ONE},
	keywords = {Primates, Acoustic signals, Vocalization, Animal behavior, Animal communication, Animal sociality, Chimpanzees, Snakes},
	language = {en},
	month = oct,
	note = {Publisher: Public Library of Science},
	number = {10},
	pages = {e76674},
	title = {Chimpanzee {Alarm} {Call} {Production} {Meets} {Key} {Criteria} for {Intentionality}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076674},
	urldate = {2020-09-29},
	volume = {8},
	year = {2013},
	bdsk-url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0076674},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pone.0076674}}

@article{brundl_systematic_nodate,
	abstract = {Postnatal development is protracted relative to lifespan in many primates, including modern humans (Homo sapiens), facilitating the acquisition of key motor, communication and social skills that can maximize fitness later in life. Nevertheless, it remains unclear what evolutionary drivers led to extended immature periods. While the developmental milestone literature is well established in humans, insight we can gain from one-species models is limited. By comparing the timing of relatable developmental milestones in a closely related species, the chimpanzee (Pan troglodytes), we can gain further understanding of the evolution of such an extended developmental phase. To date, few studies have specifically attempted to estimate developmental milestones in a manner comparable to the human literature, and existing studies lack sufficient sample sizes to estimate which milestones are more plastic with higher inter-individual variation in the timing of their emergence. Here, we describe the emergence of gross motor, fine motor, social interaction and communication traits from a longitudinal sample of 19 wild chimpanzee infants (8 females and 11 males), Ta{\"\i} National Park, C{\^o}te d'Ivoire. Gross motor traits emerged at a mean of 4 months, communication traits at 12 months, social interaction traits at 14 months and fine motor traits at 15 months, with later emerging milestones demonstrating greater inter-individual variation in the timing of the emergence. This pattern of milestone emergence is broadly comparable to observations in humans, suggesting selection for a prolonged infantile phase and that sustained skills development has a deep evolutionary history, with implications for theories on primate brain development.},
	author = {Br{\"u}ndl, Aisha C. and Tkaczynski, Patrick J. and Kohou, Gr{\'e}goire Nohon and Boesch, Christophe and Wittig, Roman M. and Crockford, Catherine},
	copyright = {{\copyright} 2020 The Authors. Developmental Science published by John Wiley \& Sons Ltd},
	doi = {10.1111/desc.12988},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/GTXBJV43/Br{\"u}ndl et al. - Systematic mapping of developmental milestones in .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VUSMXMS4/desc.html:text/html},
	issn = {1467-7687},
	journal = {Developmental Science},
	keywords = {communication, fine and gross motor, life-history theory, ontogeny, Pan troglodytes, social},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12988},
	number = {n/a},
	pages = {e12988},
	title = {Systematic mapping of developmental milestones in wild chimpanzees},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12988},
	urldate = {2020-09-29},
	volume = {n/a},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12988},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12988}}

@article{townsend_exorcising_2017,
	abstract = {Language's intentional nature has been highlighted as a crucial feature distinguishing it from other communication systems. Specifically, language is often thought to depend on highly structured intentional action and mutual mindreading by a communicator and recipient. Whilst similar abilities in animals can shed light on the evolution of intentionality, they remain challenging to detect unambiguously. We revisit animal intentional communication and suggest that progress in identifying analogous capacities has been complicated by (i) the assumption that intentional (that is, voluntary) production of communicative acts requires mental-state attribution, and (ii) variation in approaches investigating communication across sensory modalities. To move forward, we argue that a framework fusing research across modalities and species is required. We structure intentional communication into a series of requirements, each of which can be operationalised, investigated empirically, and must be met for purposive, intentionally communicative acts to be demonstrated. Our unified approach helps elucidate the distribution of animal intentional communication and subsequently serves to clarify what is meant by attributions of intentional communication in animals and humans.},
	author = {Townsend, Simon W. and Koski, Sonja E. and Byrne, Richard W. and Slocombe, Katie E. and Bickel, Balthasar and Boeckle, Markus and Goncalves, Ines Braga and Burkart, Judith M. and Flower, Tom and Gaunet, Florence and Glock, Hans Johann and Gruber, Thibaud and Jansen, David A. W. A. M. and Liebal, Katja and Linke, Angelika and Mikl{\'o}si, {\'A}d{\'a}m and Moore, Richard and Schaik, Carel P. van and Stoll, Sabine and Vail, Alex and Waller, Bridget M. and Wild, Markus and Zuberb{\"u}hler, Klaus and Manser, Marta B.},
	copyright = {{\copyright} 2016 Cambridge Philosophical Society},
	doi = {10.1111/brv.12289},
	file = {Snapshot:/Users/Cecile/Zotero/storage/GITE7YE5/brv.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/X25EY4KG/Townsend et al. - 2017 - Exorcising Grice's ghost an empirical approach to.pdf:application/pdf},
	issn = {1469-185X},
	journal = {Biological Reviews},
	keywords = {communication, gesture, intentionality, language evolution, vocalisation},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/brv.12289},
	number = {3},
	pages = {1427--1433},
	shorttitle = {Exorcising {Grice}'s ghost},
	title = {Exorcising {Grice}'s ghost: an empirical approach to studying intentional communication in animals},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/brv.12289},
	urldate = {2020-09-29},
	volume = {92},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/brv.12289},
	bdsk-url-2 = {https://doi.org/10.1111/brv.12289}}

@article{margoliash_rhythm_2020,
	author = {Margoliash, Daniel},
	doi = {10.1016/j.cub.2020.07.087},
	file = {Snapshot:/Users/Cecile/Zotero/storage/4VQCUVPM/S0960-9822(20)31146-5.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	language = {English},
	month = sep,
	note = {Publisher: Elsevier},
	number = {18},
	pages = {R1056--R1058},
	pmid = {32961164},
	shorttitle = {Rhythm},
	title = {Rhythm: {Similar} {Structure} in {Birdsong} and {Music} {Gives} {Neuroethological} {Insight}},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(20)31146-5},
	urldate = {2020-10-02},
	volume = {30},
	year = {2020},
	bdsk-url-1 = {https://www.cell.com/current-biology/abstract/S0960-9822(20)31146-5},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2020.07.087}}

@article{dezecache_development_2019,
	abstract = {Animals have evolved a range of communicative behaviours in the presence of danger. Although the mechanisms and functions of some of these behaviours have been relatively well researched, comparatively little is known about their ontogeny, including how animals learn to inform social partners about impending danger. In adult chimpanzees, behaviours in response to dangers involve several channels, particularly alarm calls and simultaneous gaze alternations with nearby recipients. Gaze alternations may allow inexperienced individuals to learn from more experienced ones by assessing their reactions to unfamiliar objects or events, but they may also provide the basis for more advanced social referencing. Here, we were interested in the development of these two common behaviours, alarm calling and gaze alternations, in wild chimpanzees (Pan troglodytes schweinfurthii) confronted with a threat. Using a cross-sectional design, we investigated those in 8 infant and 8 juveniles by experimentally exposing them to an unfamiliar but potentially dangerous object, a large, remotely controlled, moving spider model. For alarm calling, we found a positive relation with age, starting at around 28 months, although alarm calls were not consistently emitted until after 80 months. For gaze alternations, we found no age effect, with some of the youngest infants already showing the behaviour. Although its function remains unclear in infant and juvenile chimpanzees, gaze alternations emerge early in chimpanzee development. Alarm calling may require more advanced developmental stages, such as greater perceptual abilities, categorical capacities or more sophisticated social cognition, i.e. an understanding that danger is a collective experience that requires communication.},
	author = {Dezecache, Guillaume and Crockford, Catherine and Zuberb{\"u}hler, Klaus},
	doi = {10.1007/s00265-019-2716-6},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/QB8XRYJK/Dezecache et al. - 2019 - The development of communication in alarm contexts.pdf:application/pdf},
	issn = {1432-0762},
	journal = {Behavioral Ecology and Sociobiology},
	language = {en},
	month = jul,
	number = {8},
	pages = {104},
	title = {The development of communication in alarm contexts in wild chimpanzees},
	url = {https://doi.org/10.1007/s00265-019-2716-6},
	urldate = {2020-10-08},
	volume = {73},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s00265-019-2716-6}}

@article{draganova_fetal_2018,
	abstract = {The human fetal auditory system is functional around the 25th week of gestational age when the thalamocortical connections are established. Fetal magnetoencephalography (fMEG) provides evidence for fetal auditory brain responses to pure tones and syllables. Fifty-five pregnant women between 31 and 40 weeks of gestation were included in the study. Fetal MEG was recorded during the presentation of an amplitude modulated tone (AM) with a carrier frequency of 500 Hz to the maternal abdomen modulated by low modulation rates (MRs) - 2/s and 4/s, middle MR - 8/s and high MRs - 27/s, 42/s, 78/s and 91/s. The aim was to determine whether the fetal brain responds differently to envelope slopes and intensity change at the onset of the AM sounds.},
	author = {Draganova, R. and Schollbach, A. and Schleger, F. and Braendle, J. and Brucker, S. and Abele, H. and Kagan, K.O. and Wallwiener, D. and Fritsche, A. and Eswaran, H. and Preissl, H.},
	doi = {10.1016/j.heares.2018.03.005},
	file = {Draganova et al. - 2018 - Fetal auditory evoked responses to onset of amplit.pdf:/Users/Cecile/Zotero/storage/6CDT7J85/Draganova et al. - 2018 - Fetal auditory evoked responses to onset of amplit.pdf:application/pdf},
	issn = {03785955},
	journal = {Hearing Research},
	language = {en},
	month = jun,
	pages = {70--77},
	title = {Fetal auditory evoked responses to onset of amplitude modulated sounds. {A} fetal magnetoencephalography ({fMEG}) study},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378595517303064},
	urldate = {2020-10-09},
	volume = {363},
	year = {2018},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0378595517303064},
	bdsk-url-2 = {https://doi.org/10.1016/j.heares.2018.03.005}}

@article{jeng_cross-linguistic_2011,
	abstract = {Objectives: 
        Cross-language studies, as reflected by the scalp-recorded frequency-following response (FFR) to voice pitch, have shown the influence of dominant linguistic environments on the encoding of voice pitch at the brainstem level in normal-hearing adults. Research questions that remained unanswered included the characteristics of the FFR to voice pitch in neonates during their immediate postnatal period and the relative contributions of the biological capacities present at birth versus the influence of the listener's postnatal linguistic experience. The purpose of this study was to investigate the characteristics of FFR to voice pitch in neonates during their first few days of life and to examine the relative contributions of the ``biological capacity'' versus ``linguistic experience'' influences on pitch processing in the human brainstem.
        Design: 
        Twelve American neonates (five males, 1--3 days old) and 12 Chinese neonates (seven males, 1--3 days old) were recruited to examine the characteristics of the FFRs during their immediate postnatal days of life. Twelve American adults (three males; age: mean $\pm$ SD = 24.6 $\pm$ 3.0 yr) and 12 Chinese adults (six males; age: mean $\pm$ SD = 25.3 $\pm$ 2.6 yr) were also recruited to determine the relative contributions of biological and linguistic influences. A Chinese monosyllable that mimics the English vowel /i/ with a rising pitch (117--166 Hz) was used to elicit the FFR to voice pitch in all participants.
        Results: 
        Two-way analysis of variance (i.e., the language [English versus Chinese] and age [neonate versus adult] factors) showed a significant difference in Pitch Strength for language (p = 0.035, F = 4.716). A post hoc Tukey-Kramer analysis further demonstrated that Chinese adults had significantly larger Pitch Strength values than Chinese neonates (p = 0.024). This finding, coupled with the fact that American neonates and American adults had comparable Pitch Strength values, supported the linguistic experience model. On the other hand, Pitch Strength obtained from the American neonates, American adults, and Chinese neonates were not significantly different from each other, supporting the biological capacity model.
        Conclusions: 
        This study demonstrated an early maturation of voice-pitch processing in neonates starting from 1 to 3 days after birth and a significant effect of linguistic experience on the neural processing of voice pitch at the brainstem level. These findings provide a significant conceptual advancement and a basis for further examination of developmental maturation of subcortical representation of speech features, such as pitch, timing, and harmonics. These findings can also be used to help identify neonates at risk for delays in voice-pitch perception and provide new directions for preventive and therapeutic interventions for patients with central auditory processing deficits, hearing loss, and other types of communication disorders.},
	author = {Jeng, Fuh-Cherng and Hu, Jiong and Dickman, Brenda and Montgomery-Reagan, Karen and Tong, Meiling and Wu, Guangqiang and Lin, Chia-Der},
	doi = {10.1097/AUD.0b013e31821cc0df},
	issn = {0196-0202},
	journal = {Ear and Hearing},
	language = {en-US},
	month = dec,
	number = {6},
	pages = {699--707},
	title = {Cross-{Linguistic} {Comparison} of {Frequency}-{Following} {Responses} to {Voice} {Pitch} in {American} and {Chinese} {Neonates} and {Adults}},
	url = {https://journals.lww.com/ear-hearing/Abstract/2011/11000/Cross_Linguistic_Comparison_of_Frequency_Following.3.aspx},
	urldate = {2020-10-16},
	volume = {32},
	year = {2011},
	bdsk-url-1 = {https://journals.lww.com/ear-hearing/Abstract/2011/11000/Cross_Linguistic_Comparison_of_Frequency_Following.3.aspx},
	bdsk-url-2 = {https://doi.org/10.1097/AUD.0b013e31821cc0df}}

@article{scher_ontogeny_2008,
	abstract = {Serial neonatal and infant electroencephalographic (EEG)--polysomnographic studies document the ontogeny of cerebral and noncerebral physiologic behaviors based on visual inspection or computer analyses. EEG patterns and their relationship to other physiologic signals serve as templates for normal brain organization and maturation, subserving multiple interconnected neuronal networks. Interpretation of serial EEG-sleep patterns also helps track the continuity of brain functions from intrauterine to extrauterine time periods. Recognition of the ontogeny of behavioral and electrographic patterns provides insight into the developmental neurophysiological expression of neural plasticity. Sleep ontogenesis from neonatal and infancy periods documents expected patterns of postnatal brain maturation, which allows for alterations from genetically programmed neuronal processes under stressful and/or pathological conditions. Automated analyses of cerebral and noncerebral signals provide time- and frequency-dependent computational phenotypes of brain organization and maturation in healthy or diseased states. Research pertaining to the developmental origins of health and disease can use these computational phenotypes to design longitudinal studies for the assessment of gene--environment interactions. Computational strategies may ultimately improve our diagnostic skills to identify special-needs children and to track the neurorehabilitative care of the high-risk fetus, neonate, and infant.},
	author = {Scher, Mark S.},
	doi = {10.1016/j.sleep.2007.08.014},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/B88CYE5H/S1389945707003164.html:text/html},
	issn = {1389-9457},
	journal = {Sleep Medicine},
	keywords = {Infant, Neonate, Computer analyses, Developmental origins of health and disease, EEG-sleep, Neural plasticity, Ontogeny},
	language = {en},
	month = aug,
	number = {6},
	pages = {615--636},
	title = {Ontogeny of {EEG}-sleep from neonatal through infancy periods},
	url = {http://www.sciencedirect.com/science/article/pii/S1389945707003164},
	urldate = {2020-10-16},
	volume = {9},
	year = {2008},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1389945707003164},
	bdsk-url-2 = {https://doi.org/10.1016/j.sleep.2007.08.014}}

@book{louis_developmental_2016,
	abstract = {The neonatal EEG has some very different clinical considerations for recording and interpretation. Understanding certain clinical details, such as the conceptional (aka conceptual) age (CA) and the clinical state of the recorded patient, is essential for interpretation of the neonatal EEG.},
	author = {Louis, Erik K. St and Frey, Lauren C. and Britton, Jeffrey W. and Frey, Lauren C. and Hopp, Jennifer L. and Korb, Pearce and Koubeissi, Mohamad Z. and Lievens, William E. and Pestana-Knight, Elia M. and Louis, Erik K. St},
	file = {Snapshot:/Users/Cecile/Zotero/storage/K3B45RK9/NBK390356.html:text/html},
	language = {en},
	note = {Publication Title: Electroencephalography (EEG): An Introductory Text and Atlas of Normal and Abnormal Findings in Adults, Children, and Infants [Internet]},
	publisher = {American Epilepsy Society},
	shorttitle = {The {Developmental} {EEG}},
	title = {The {Developmental} {EEG}: {Premature}, {Neonatal}, {Infant}, and {Children}},
	url = {https://www.ncbi.nlm.nih.gov/books/NBK390356/},
	urldate = {2020-10-22},
	year = {2016},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/books/NBK390356/}}

@article{scher_comparisons_1994,
	abstract = {Summary:.  Differences in state-specific electroencephalographic (EEG) spectral values are described between groups of preterm and full-term neonates at compara},
	author = {Scher, Mark S. and Sun, Mingui and Steppe, Doris A. and Banks, David L. and Guthrie, Robert D. and Sclabassi, Robert J.},
	doi = {10.1093/sleep/17.1.47},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NPMLKQL7/Scher et al. - 1994 - Comparisons of EEG Sleep State-Specific Spectral V.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K6FB73FG/2749442.html:text/html},
	issn = {0161-8105},
	journal = {Sleep},
	language = {en},
	month = jan,
	note = {Publisher: Oxford Academic},
	number = {1},
	pages = {47--51},
	title = {Comparisons of {EEG} {Sleep} {State}-{Specific} {Spectral} {Values} {Between} {Healthy} {Full}-{Term} and {Preterm} {Infants} at {Comparable} {Postconceptional} {Ages}},
	url = {https://academic.oup.com/sleep/article/17/1/47/2749442},
	urldate = {2020-10-22},
	volume = {17},
	year = {1994},
	bdsk-url-1 = {https://academic.oup.com/sleep/article/17/1/47/2749442},
	bdsk-url-2 = {https://doi.org/10.1093/sleep/17.1.47}}

@article{dereymaeker_review_2017,
	abstract = {Neonatal sleep is a crucial state that involves endogenous driven brain activity, important for neuronal survival and guidance of brain networks. Sequential EEG-sleep analysis in preterm infants provides insights into functional brain integrity and can document deviations of the biologically pre-programmed process of sleep ontogenesis during the neonatal period., Visual assessment of neonatal sleep-EEG, with integration of both cerebral and non-cerebral measures to better define neonatal state, is still considered the gold standard. Electrographic patterns evolve over time and are gradually time locked with behavioural characteristics which allow classification of quiet sleep and active sleep periods during the last 10 weeks of gestation. Near term age, the neonate expresses a short ultradian sleep cycle, with two distinct active and quiet sleep, as well as brief periods of transitional or indeterminate sleep. Qualitative assessment of neonatal sleep is however challenged by biological and environmental variables that influence the expression of EEG-sleep patterns and sleep organization. Developing normative EEG-sleep data with the aid of automated analytic methods, can further improve our understanding of extra-uterine brain development and state organization under stressful or pathological conditions. Based on those developmental biomarkers of normal and abnormal brain function, research can be conducted to support and optimise sleep in the NICU, with the ultimate goal to improve therapeutic interventions and neurodevelopmental outcome.},
	author = {Dereymaeker, Anneleen and Pillay, Kirubin and Vervisch, Jan and De Vos, Maarten and Van Huffel, Sabine and Jansen, Katrien and Naulaers, Gunnar},
	doi = {10.1016/j.earlhumdev.2017.07.003},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/HGCY95MJ/Dereymaeker et al. - 2017 - Review of sleep-EEG in preterm and term neonates.pdf:application/pdf},
	issn = {0378-3782},
	journal = {Early human development},
	month = oct,
	pages = {87--103},
	pmcid = {PMC6342258},
	pmid = {28711233},
	title = {Review of sleep-{EEG} in preterm and term neonates},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6342258/},
	urldate = {2020-10-26},
	volume = {113},
	year = {2017},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6342258/},
	bdsk-url-2 = {https://doi.org/10.1016/j.earlhumdev.2017.07.003}}

@article{makov_sleep_2017,
	abstract = {The extent to which the sleeping brain processes sensory information remains unclear. This is particularly true for continuous and complex stimuli such as speech, in which information is organized into hierarchically embedded structures. Recently, novel metrics for assessing the neural representation of continuous speech have been developed using noninvasive brain recordings that have thus far only been tested during wakefulness. Here we investigated, for the first time, the sleeping brain's capacity to process continuous speech at different hierarchical levels using a newly developed Concurrent Hierarchical Tracking (CHT) approach that allows monitoring the neural representation and processing-depth of continuous speech online. Speech sequences were compiled with syllables, words, phrases, and sentences occurring at fixed time intervals such that different linguistic levels correspond to distinct frequencies. This enabled us to distinguish their neural signatures in brain activity. We compared the neural tracking of intelligible versus unintelligible (scrambled and foreign) speech across states of wakefulness and sleep using high-density EEG in humans. We found that neural tracking of stimulus acoustics was comparable across wakefulness and sleep and similar across all conditions regardless of speech intelligibility. In contrast, neural tracking of higher-order linguistic constructs (words, phrases, and sentences) was only observed for intelligible speech during wakefulness and could not be detected at all during nonrapid eye movement or rapid eye movement sleep. These results suggest that, whereas low-level auditory processing is relatively preserved during sleep, higher-level hierarchical linguistic parsing is severely disrupted, thereby revealing the capacity and limits of language processing during sleep.
SIGNIFICANCE STATEMENT Despite the persistence of some sensory processing during sleep, it is unclear whether high-level cognitive processes such as speech parsing are also preserved. We used a novel approach for studying the depth of speech processing across wakefulness and sleep while tracking neuronal activity with EEG. We found that responses to the auditory sound stream remained intact; however, the sleeping brain did not show signs of hierarchical parsing of the continuous stream of syllables into words, phrases, and sentences. The results suggest that sleep imposes a functional barrier between basic sensory processing and high-level cognitive processing. This paradigm also holds promise for studying residual cognitive abilities in a wide array of unresponsive states.},
	author = {Makov, Shiri and Sharon, Omer and Ding, Nai and Ben-Shachar, Michal and Nir, Yuval and Golumbic, Elana Zion},
	copyright = {Copyright {\copyright} 2017 the authors 0270-6474/17/377772-10\$15.00/0},
	doi = {10.1523/JNEUROSCI.0168-17.2017},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RCCF8JDI/Makov et al. - 2017 - Sleep Disrupts High-Level Speech Parsing Despite S.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K3BVDC8I/7772.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {speech processing, entrainment, attention, sleep},
	language = {en},
	month = aug,
	note = {Publisher: Society for Neuroscience Section: Research Articles},
	number = {32},
	pages = {7772--7781},
	pmid = {28626013},
	title = {Sleep {Disrupts} {High}-{Level} {Speech} {Parsing} {Despite} {Significant} {Basic} {Auditory} {Processing}},
	url = {https://www.jneurosci.org/content/37/32/7772},
	urldate = {2020-10-30},
	volume = {37},
	year = {2017},
	bdsk-url-1 = {https://www.jneurosci.org/content/37/32/7772},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.0168-17.2017}}

@article{andrillon_vigilant_2020,
	abstract = {Sleep suppresses the ability to react to environmental demands. It has been proposed that a phenomenon of sensory isolation, whereby sensory inputs fail to reach cortical brain regions during sleep, would be responsible for this absence of responses. How and why this decoupling is implemented has been intensively investigated. However, sleepers might not be fully disconnected from their environment. We review here the empirical evidence showing that sleepers can perform a surprisingly large range of cognitive processes. We describe potential mechanisms explaining sleepers' ability to maintain covert cognitive processes as well as their suppression. Rather than being isolated from the environment, sleepers seem to enter a standby mode, allowing them to balance the monitoring of their surroundings with sensory isolation. This balance could allow sleepers to determine when to stay asleep or when to wake up, and might be essential for the fulfilment of sleep functions, notably memory consolidation.},
	author = {Andrillon, Thomas and Kouider, Sid},
	doi = {10.1016/j.cophys.2019.12.002},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QDZJ2YED/Andrillon et Kouider - 2020 - The vigilant sleeper neural mechanisms of sensory.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KCZAUAYR/S2468867319301889.html:text/html},
	issn = {2468-8673},
	journal = {Current Opinion in Physiology},
	language = {en},
	month = jun,
	pages = {47--59},
	series = {Physiology of sleep},
	shorttitle = {The vigilant sleeper},
	title = {The vigilant sleeper: neural mechanisms of sensory (de)coupling during sleep},
	url = {http://www.sciencedirect.com/science/article/pii/S2468867319301889},
	urldate = {2020-10-30},
	volume = {15},
	year = {2020},
	bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S2468867319301889},
	bdsk-url-2 = {https://doi.org/10.1016/j.cophys.2019.12.002}}

@article{arcaro_hierarchical_2017,
	abstract = {The adult primate visual system comprises a series of hierarchically organized areas. Each cortical area contains a topographic map of visual space, with different areas extracting different kinds of information from the retinal input. Here we asked to what extent the newborn visual system resembles the adult organization. We find that hierarchical, topographic organization is present at birth and therefore constitutes a proto-organization for the entire primate visual system. Even within inferior temporal cortex, this proto-organization was already present, prior to the emergence of category selectivity (e.g., faces or scenes). We propose that this topographic organization provides the scaffolding for the subsequent development of visual cortex that commences at the onset of visual experience},
	author = {Arcaro, Michael J and Livingstone, Margaret S},
	doi = {10.7554/eLife.26196},
	editor = {Pasternak, Tatiana},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/2IBGZ7JM/Arcaro et Livingstone - 2017 - A hierarchical, retinotopic proto-organization of .pdf:application/pdf},
	issn = {2050-084X},
	journal = {eLife},
	keywords = {hierarchy, proto-organization, retinotopy, vision, visual development},
	month = jul,
	note = {Publisher: eLife Sciences Publications, Ltd},
	pages = {e26196},
	title = {A hierarchical, retinotopic proto-organization of the primate visual system at birth},
	url = {https://doi.org/10.7554/eLife.26196},
	urldate = {2020-11-12},
	volume = {6},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.7554/eLife.26196}}

@article{livingstone_development_2017,
	abstract = {Face recognition is highly proficient in humans and other social primates; it emerges in infancy, but the development of the neural mechanisms supporting this behaviour is largely unknown. We use blood-volume functional MRI to monitor longitudinally the responsiveness to faces, scrambled faces, and objects in macaque inferotemporal cortex (IT) from 1 month to 2 years of age. During this time selective responsiveness to monkey faces emerges. Some functional organization is present at 1 month; face-selective patches emerge over the first year of development, and are remarkably stable once they emerge. Face selectivity is refined by a decreasing responsiveness to non-face stimuli.},
	author = {Livingstone, Margaret S. and Vincent, Justin L. and Arcaro, Michael J. and Srihasam, Krishna and Schade, Peter F. and Savage, Tristram},
	copyright = {2017 The Author(s)},
	doi = {10.1038/ncomms14897},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/FAWWDLCQ/Livingstone et al. - 2017 - Development of the macaque face-patch system.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7KSQGXXI/ncomms14897.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = mar,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {14897},
	title = {Development of the macaque face-patch system},
	url = {https://www.nature.com/articles/ncomms14897},
	urldate = {2020-11-12},
	volume = {8},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/ncomms14897},
	bdsk-url-2 = {https://doi.org/10.1038/ncomms14897}}

@article{arcaro_seeing_2017,
	abstract = {Monkeys, like humans, normally have face domains in inferotemporal cortex; however, monkeys raised without exposure to faces do not develop face patches. Normally reared monkeys, like humans, preferentially look at faces, but face-deprived monkeys do not. These results highlight the importance of early experience for normal sensory and cognitive development.},
	author = {Arcaro, Michael J. and Schade, Peter F. and Vincent, Justin L. and Ponce, Carlos R. and Livingstone, Margaret S.},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nn.4635},
	file = {Snapshot:/Users/Cecile/Zotero/storage/5T4T8VFP/nn.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/Y3MR2758/Arcaro et al. - 2017 - Seeing faces is necessary for face-domain formatio.pdf:application/pdf},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = oct,
	note = {Number: 10 Publisher: Nature Publishing Group},
	number = {10},
	pages = {1404--1412},
	title = {Seeing faces is necessary for face-domain formation},
	url = {https://www.nature.com/articles/nn.4635},
	urldate = {2020-11-12},
	volume = {20},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/nn.4635},
	bdsk-url-2 = {https://doi.org/10.1038/nn.4635}}

@incollection{boesch_why_2019,
	author = {Crockford, Catherine},
	booktitle = {The {Chimpanzees} of the {Ta{\"\i}} {Forest}},
	doi = {10.1017/9781108674218.025},
	edition = {1},
	editor = {Boesch, Christophe and Wittig, Roman and Crockford, Catherine and Vigilant, Linda and Deschner, Tobias and Leendertz, Fabian},
	file = {Crockford - 2019 - Why does the chimpanzee vocal repertoire remain po.pdf:/Users/Cecile/Zotero/storage/GE2XH34V/Crockford - 2019 - Why does the chimpanzee vocal repertoire remain po.pdf:application/pdf},
	isbn = {978-1-108-67421-8 978-1-108-48155-7 978-1-108-72292-6},
	language = {en},
	month = nov,
	pages = {394--409},
	publisher = {Cambridge University Press},
	title = {Why does the chimpanzee vocal repertoire remain poorly understood and what can be done about it?},
	url = {https://www.cambridge.org/core/product/identifier/9781108674218%23CN-bp-24/type/book_part},
	urldate = {2020-11-30},
	year = {2019},
	bdsk-url-1 = {https://www.cambridge.org/core/product/identifier/9781108674218%23CN-bp-24/type/book_part},
	bdsk-url-2 = {https://doi.org/10.1017/9781108674218.025}}

@article{dezecache_machine_2020,
	abstract = {Distress calls are an acoustically variable group of vocalizations ubiquitous in mammals and other animals. Their presumed function is to recruit help, but there has been much debate on whether the nature of the disturbance can be inferred from the acoustics of distress calls. We used machine learning to analyse episodes of distress calls of wild infant chimpanzees. We extracted exemplars from those distress call episodes and examined them in relation to the external event triggering them and the distance to the mother. In further steps, we tested whether the acoustic variants were associated with particular maternal responses. Our results suggest that, although infant chimpanzee distress calls are highly graded, they can convey information about discrete problems experienced by the infant and about distance to the mother, which in turn may help guide maternal parenting decisions. The extent to which mothers rely on acoustic cues alone (versus integrate other contextual-visual information) to decide upon intervening should be the focus of future research.},
	author = {Dezecache, Guillaume and Zuberb{\"u}hler, Klaus and Davila-Ross, Marina and Dahl, Christoph D.},
	doi = {10.1007/s10071-020-01437-5},
	file = {Version soumise:/Users/Cecile/Zotero/storage/R9R4NQ2Y/Dezecache et al. - 2020 - A machine learning approach to infant distress cal.pdf:application/pdf},
	issn = {1435-9456},
	journal = {Animal Cognition},
	language = {en},
	month = oct,
	title = {A machine learning approach to infant distress calls and maternal behaviour of wild chimpanzees},
	url = {https://doi.org/10.1007/s10071-020-01437-5},
	urldate = {2020-11-30},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1007/s10071-020-01437-5}}

@article{assaneo_spontaneous_2019,
	abstract = {We introduce a deceptively simple behavioral task that robustly identifies two qualitatively different groups within the general population. When presented with an isochronous train of random syllables, some listeners are compelled to align their own concurrent syllable production with the perceived rate, whereas others remain impervious to the external rhythm. Using both neurophysiological and structural imaging approaches, we show group differences with clear consequences for speech processing and language learning. When listening passively to speech, high synchronizers show increased brain-to-stimulus synchronization over frontal areas, and this localized pattern correlates with precise microstructural differences in the white matter pathways connecting frontal to auditory regions. Finally, the data expose a mechanism that underpins performance on an ecologically relevant word-learning task. We suggest that this task will help to better understand and characterize individual performance in speech processing and language learning.},
	author = {Assaneo, M. Florencia and Ripoll{\'e}s, Pablo and Orpella, Joan and Lin, Wy Ming and de Diego-Balaguer, Ruth and Poeppel, David},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	doi = {10.1038/s41593-019-0353-z},
	file = {Snapshot:/Users/Cecile/Zotero/storage/3JE88HQD/s41593-019-0353-z.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/LJM8XNIQ/Assaneo et al. - 2019 - Spontaneous synchronization to speech reveals neur.pdf:application/pdf},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = apr,
	note = {Number: 4 Publisher: Nature Publishing Group},
	number = {4},
	pages = {627--632},
	title = {Spontaneous synchronization to speech reveals neural mechanisms facilitating language learning},
	url = {https://www.nature.com/articles/s41593-019-0353-z},
	urldate = {2020-12-18},
	volume = {22},
	year = {2019},
	bdsk-url-1 = {https://www.nature.com/articles/s41593-019-0353-z},
	bdsk-url-2 = {https://doi.org/10.1038/s41593-019-0353-z}}

@article{assaneo_speaking_2020,
	abstract = {Evidence suggests that temporal predictions arising from the motor system can enhance auditory perception. However, in speech perception, we lack evidence of perception being modulated by production. Here we show a behavioural protocol that captures the existence of such auditory--motor interactions. Participants performed a syllable discrimination task immediately after producing periodic syllable sequences. Two speech rates were explored: a `natural' (individually preferred) and a fixed `non-natural' (2 Hz) rate. Using a decoding approach, we show that perceptual performance is modulated by the stimulus phase determined by a participant's own motor rhythm. Remarkably, for `natural' and `non-natural' rates, this finding is restricted to a subgroup of the population with quantifiable auditory--motor coupling. The observed pattern is compatible with a neural model assuming a bidirectional interaction of auditory and speech motor cortices. Crucially, the model matches the experimental results only if it incorporates individual differences in the strength of the auditory--motor connection.},
	author = {Assaneo, M. Florencia and Rimmele, Johanna M. and Sanz Perl, Yonatan and Poeppel, David},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	doi = {10.1038/s41562-020-00962-0},
	file = {Snapshot:/Users/Cecile/Zotero/storage/9NRQ425G/s41562-020-00962-0.html:text/html},
	issn = {2397-3374},
	journal = {Nature Human Behaviour},
	language = {en},
	month = oct,
	note = {Publisher: Nature Publishing Group},
	pages = {1--12},
	title = {Speaking rhythmically can shape hearing},
	url = {https://www.nature.com/articles/s41562-020-00962-0},
	urldate = {2020-12-18},
	year = {2020},
	bdsk-url-1 = {https://www.nature.com/articles/s41562-020-00962-0},
	bdsk-url-2 = {https://doi.org/10.1038/s41562-020-00962-0}}

@article{assaneo_coupling_2018,
	abstract = {The relation between perception and action remains a fundamental question for neuroscience. In the context of speech, existing data suggest an interaction between auditory and speech-motor cortices, but the underlying mechanisms remain incompletely characterized. We fill a basic gap in our understanding of the sensorimotor processing of speech by examining the synchronization between auditory and speech-motor regions over different speech rates, a fundamental parameter delimiting successful perception. First, using magnetoencephalography, we measure synchronization between auditory and speech-motor regions while participants listen to syllables at various rates. We show, surprisingly, that auditory-motor synchrony is significant only over a restricted range and is enhanced at {\textasciitilde}4.5 Hz, a value compatible with the mean syllable rate across languages. Second, neural modeling reveals that this modulated coupling plausibly emerges as a consequence of the underlying neural architecture. The findings suggest that the temporal patterns of speech emerge as a consequence of the intrinsic rhythms of cortical areas.
Auditory-motor neural synchronization during perception is restricted to a narrow frequency range and enhanced at {\textasciitilde}4.5 Hz.
Auditory-motor neural synchronization during perception is restricted to a narrow frequency range and enhanced at {\textasciitilde}4.5 Hz.},
	author = {Assaneo, M. Florencia and Poeppel, David},
	copyright = {Copyright {\copyright} 2018 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial license, which permits use, distribution, and reproduction in any medium, so long as the resultant use is not for commercial advantage and provided the original work is properly cited.},
	doi = {10.1126/sciadv.aao3842},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NKXFAMAP/Assaneo et Poeppel - 2018 - The coupling between auditory and motor cortices i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/SSUVS4HU/eaao3842.html:text/html},
	issn = {2375-2548},
	journal = {Science Advances},
	language = {en},
	month = feb,
	note = {Publisher: American Association for the Advancement of Science Section: Research Article},
	number = {2},
	pages = {eaao3842},
	shorttitle = {The coupling between auditory and motor cortices is rate-restricted},
	title = {The coupling between auditory and motor cortices is rate-restricted: {Evidence} for an intrinsic speech-motor rhythm},
	url = {https://advances.sciencemag.org/content/4/2/eaao3842},
	urldate = {2020-12-18},
	volume = {4},
	year = {2018},
	bdsk-url-1 = {https://advances.sciencemag.org/content/4/2/eaao3842},
	bdsk-url-2 = {https://doi.org/10.1126/sciadv.aao3842}}

@incollection{fay_avian_2004,
	address = {New York, NY},
	author = {Brenowitz, Eliot A. and Woolley, Sarah M. N.},
	booktitle = {Plasticity of the {Auditory} {System}},
	doi = {10.1007/978-1-4757-4219-0_6},
	editor = {Fay, Richard R. and Popper, Arthur N. and Parks, Thomas N. and Rubel, Edwin W. and Popper, Arthur N. and Fay, Richard R.},
	file = {Brenowitz et Woolley - 2004 - The Avian Song Control System A Model for Underst.pdf:/Users/Cecile/Zotero/storage/535JT92I/Brenowitz et Woolley - 2004 - The Avian Song Control System A Model for Underst.pdf:application/pdf},
	isbn = {978-1-4419-1932-8 978-1-4757-4219-0},
	language = {en},
	note = {Series Title: Springer Handbook of Auditory Research},
	pages = {228--284},
	publisher = {Springer New York},
	shorttitle = {The {Avian} {Song} {Control} {System}},
	title = {The {Avian} {Song} {Control} {System}: {A} {Model} for {Understanding} {Changes} in {Neural} {Structure} and {Function}},
	url = {http://link.springer.com/10.1007/978-1-4757-4219-0_6},
	urldate = {2021-02-04},
	volume = {23},
	year = {2004},
	bdsk-url-1 = {http://link.springer.com/10.1007/978-1-4757-4219-0_6},
	bdsk-url-2 = {https://doi.org/10.1007/978-1-4757-4219-0_6}}

@article{woolley_coevolution_2011,
	author = {Woolley, Sarah M. N. and Moore, Jordan M.},
	doi = {10.1111/j.1749-6632.2011.05989.x},
	file = {Woolley et Moore - 2011 - Coevolution in communication senders and receivers.pdf:/Users/Cecile/Zotero/storage/Q6F5EXR9/Woolley et Moore - 2011 - Coevolution in communication senders and receivers.pdf:application/pdf},
	issn = {00778923},
	journal = {Annals of the New York Academy of Sciences},
	language = {en},
	month = apr,
	number = {1},
	pages = {155--165},
	shorttitle = {Coevolution in communication senders and receivers},
	title = {Coevolution in communication senders and receivers: vocal behavior and auditory processing in multiple songbird species},
	url = {http://doi.wiley.com/10.1111/j.1749-6632.2011.05989.x},
	urldate = {2021-02-08},
	volume = {1225},
	year = {2011},
	bdsk-url-1 = {http://doi.wiley.com/10.1111/j.1749-6632.2011.05989.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1749-6632.2011.05989.x}}

@article{vanden_bosch_der_nederlanden_music_2020,
	abstract = {Neural activity synchronizes with the rhythmic input of many environmental signals, but the capacity of neural activity to entrain to the slow rhythms of speech is particularly important for successful communication. Compared to speech, song has greater rhythmic regularity, a more stable fundamental frequency, discrete pitch movements, and a metrical structure, this may provide a temporal framework that helps listeners neurally track information better than the rhythmically irregular rhythms of speech. The current study used EEG to examine whether entrainment to the syllable rate of linguistic utterances, as indexed by cerebro-acoustic phase coherence, was greater when listeners heard sung than spoken sentences. We assessed listeners phase-locking in both easy (no time compression) and hard (50\% time-compression) utterance conditions. Adults phase-locked equally well to speech and song in the easy listening condition. However, in the time-compressed condition, phase-locking was greater for sung than spoken utterances in the theta band (3.67--5 ​Hz). Thus, the musical temporal and spectral characteristics of song related to better phase-locking to the slow phrasal and syllable information (4--7 ​Hz) in the speech stream. These results highlight the possibility of using song as a tool for improving speech processing in individuals with language processing deficits, such as dyslexia.},
	author = {Vanden Bosch der Nederlanden, Christina M. and Joanisse, Marc F. and Grahn, Jessica A.},
	doi = {10.1016/j.neuroimage.2020.116767},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4XK53QMB/Vanden Bosch der Nederlanden et al. - 2020 - Music as a scaffold for listening to speech Bette.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/78MAUMJJ/S1053811920302548.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Music, Rhythm, Language, Phase-locking, Entrainment, Theta},
	language = {en},
	month = jul,
	pages = {116767},
	shorttitle = {Music as a scaffold for listening to speech},
	title = {Music as a scaffold for listening to speech: {Better} neural phase-locking to song than speech},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920302548},
	urldate = {2021-02-12},
	volume = {214},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811920302548},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2020.116767}}

@article{bolhuis_twitter_2010,
	abstract = {Unlike non-human primates, songbirds learn to vocalize very much like human infants learn to speak. In both cases, young individuals form auditory memories of the vocalizations of adults during a sensitive period, and they acquire their own vocalizations through a transitional phase that is called 'subsong' in birds and 'babbling' in infants.In songbirds, a network of interconnected brain nuclei, known as the song system, is involved in the perception, learning and production of song. Parts of the song system are analogous --- and possibly homologous --- to human basal ganglia as well as regions in the frontal cortex that are involved in speech.In songbirds, regions outside the song system, in the caudal pallium, are involved in auditory memory; activation of one of these regions, the caudiomedial nidopallium (NCM), is related to the strength of tutor song memory. These pallial regions are analogous --- and possibly homologous --- to a region in the human temporal lobe known as the auditory association cortex that is involved in speech processing.In both humans and songbirds, the vocal 'motor regions' are also involved in auditory perception. For learning and maintenance of speech and birdsong, continual interaction between auditory and motor regions to match what is heard and what is produced is necessary.Some species of songbirds including Bengalese finches (Lonchura striata domestica) have types of note-to-note transition rules that could be expressed as 'finite-state syntax', which is a simpler form of human syntax.FOXP2 is the first gene specifically implicated in speech and language, and its sequences are more than 90\% conserved between birds and mammals. FOXP2 is regulated developmentally and seasonally and by singing activity in songbirds, and experimentally downregulated FOXP2 levels impair song learning.Further multidisciplinary research is needed to study the molecular, neural and cognitive mechanisms of birdsong, and its similarities with human speech. Such analyses may ultimately have heuristic value for the study of speech acquisition and production in humans and its underlying mechanisms.},
	author = {Bolhuis, Johan J. and Okanoya, Kazuo and Scharff, Constance},
	copyright = {2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nrn2931},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Y85P8NFL/Bolhuis et al. - 2010 - Twitter evolution converging mechanisms in birdso.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7HPCLA59/nrn2931.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = nov,
	note = {Number: 11 Publisher: Nature Publishing Group},
	number = {11},
	pages = {747--759},
	shorttitle = {Twitter evolution},
	title = {Twitter evolution: converging mechanisms in birdsong and human speech},
	url = {https://www.nature.com/articles/nrn2931},
	urldate = {2021-02-17},
	volume = {11},
	year = {2010},
	bdsk-url-1 = {https://www.nature.com/articles/nrn2931},
	bdsk-url-2 = {https://doi.org/10.1038/nrn2931}}

@article{dooling_auditory_2002,
	author = {Dooling, Robert J. and Leek, Marjorie R. and Gleich, Otto and Dent, Micheal L.},
	doi = {10.1121/1.1494447},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7AI2VL9G/Dooling et al. - 2002 - Auditory temporal resolution in birds Discriminat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NV78EZHI/1.html:text/html},
	issn = {0001-4966},
	journal = {The Journal of the Acoustical Society of America},
	month = jul,
	note = {Publisher: Acoustical Society of America},
	number = {2},
	pages = {748--759},
	shorttitle = {Auditory temporal resolution in birds},
	title = {Auditory temporal resolution in birds: {Discrimination} of harmonic complexes},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1494447},
	urldate = {2021-02-18},
	volume = {112},
	year = {2002},
	bdsk-url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1494447},
	bdsk-url-2 = {https://doi.org/10.1121/1.1494447}}

@article{mcclelland_place_2009,
	abstract = {I consider the role of cognitive modeling in cognitive science. Modeling, and the computers that enable it, are central to the field, but the role of modeling is often misunderstood. Models are not intended to capture fully the processes they attempt to elucidate. Rather, they are explorations of ideas about the nature of cognitive processes. In these explorations, simplification is essential---through simplification, the implications of the central ideas become more transparent. This is not to say that simplification has no downsides; it does, and these are discussed. I then consider several contemporary frameworks for cognitive modeling, stressing the idea that each framework is useful in its own particular ways. Increases in computer power (by a factor of about 4 million) since 1958 have enabled new modeling paradigms to emerge, but these also depend on new ways of thinking. Will new paradigms emerge again with the next 1,000-fold increase?},
	author = {McClelland, James L.},
	doi = {https://doi.org/10.1111/j.1756-8765.2008.01003.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/3U32GBW6/McClelland - 2009 - The Place of Modeling in Cognitive Science.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YF799NC3/j.1756-8765.2008.01003.html:text/html},
	issn = {1756-8765},
	journal = {Topics in Cognitive Science},
	keywords = {Bayesian approaches, Cognitive architectures, Computer simulation, Connectionist models, Dynamical systems, Hybrid models, Modeling frameworks, Symbolic models of cognition},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1756-8765.2008.01003.x},
	number = {1},
	pages = {11--38},
	title = {The {Place} of {Modeling} in {Cognitive} {Science}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01003.x},
	urldate = {2021-03-01},
	volume = {1},
	year = {2009},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-8765.2008.01003.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1756-8765.2008.01003.x}}

@article{hollich_combining_2006,
	abstract = {This paper provides three representative examples that highlight the ways in which procedures can be combined to study interactions across traditional domains of study: segmentation, word learning, and grammar. The first section uses visual familiarization prior to the Headturn Preference Procedure to demonstrate that synchronized visual information aids in speech segmentation in noise. The second section uses audio familiarization prior to the Preferential Looking Procedure to demonstrate that speech perception aids in the learning of meaning. The third section uses visual familiarization prior to the Preferential Looking Procedure to demonstrate that attentional distractions inhibit grammatical understanding. Thus, what infants see affects what they hear. What infants hear affects the words they learn. What infants remember affects the sentences they understand.},
	author = {Hollich, George},
	doi = {10.1177/00238309060490010201},
	file = {Hollich - 2006 - Combining Techniques to Reveal Emergent Effects in.pdf:/Users/Cecile/Zotero/storage/VGFZ9CNY/Hollich - 2006 - Combining Techniques to Reveal Emergent Effects in.pdf:application/pdf},
	issn = {0023-8309, 1756-6053},
	journal = {Language and Speech},
	language = {en},
	month = mar,
	number = {1},
	pages = {3--19},
	title = {Combining {Techniques} to {Reveal} {Emergent} {Effects} in {Infants}' {Segmentation}, {Word} {Learning}, and {Grammar}},
	url = {http://journals.sagepub.com/doi/10.1177/00238309060490010201},
	urldate = {2021-03-02},
	volume = {49},
	year = {2006},
	bdsk-url-1 = {http://journals.sagepub.com/doi/10.1177/00238309060490010201},
	bdsk-url-2 = {https://doi.org/10.1177/00238309060490010201}}

@article{creutzfeldt_neuronal_1989,
	abstract = {We have recorded neuronal responses in the lateral temporal lobe of man to overt speech during open brain surgery for epilepsy. Tests included overt naming of objects and reading words or short sentences shown on a projector screen, repetition of tape recorded words or sentences presented over a loudspeaker, and free conversation. Neuronal activity in the dominant and non-dominant temporal lobe were about equally affected by overt speech. As during listening to language (see Creutzfeldt et al. 1989), responses differed between recordings from sites in the superior and the middle or inferior temporal gyrus. In the superior temporal gyrus all neurons responded clearly and each in a characteristic manner. Activation could be related to phonemic aspects, to segmentation or to the length of spoken words or sentences. However, neurons were mostly differently affected by listening to words and language as compared to overt speaking. In neuronal populations recorded simultaneously with one or two microelectrodes, some neurons responded predominantly to one or the other type of speech. Excitatory responses during overt speaking were always auditory. In the middle temporal gyrus more neurons (about 2/3) responded to overt speaking than to listening alone. Activations elicited during overt speech were seen in about 1/3 of our sample, but they were more sluggish than those recorded in the superior gyrus. A prominent feature was suppression of on-going activity, which we found in about 1/3 of middle and in some superior temporal gyrus neurons. This suppression could preced vocalization by up to a few hundred ms, and could outlast it by up to 1 s. Evoked ECoG-potentials to words heard or spoken were different, and those to overt speech were more widespread.},
	author = {Creutzfeldt, O. and Ojemann, G. and Lettich, E.},
	doi = {10.1007/BF00249601},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/IVR43GR6/Creutzfeldt et al. - 1989 - Neuronal activity in the human lateral temporal lo.pdf:application/pdf},
	issn = {1432-1106},
	journal = {Experimental Brain Research},
	language = {en},
	month = oct,
	number = {3},
	pages = {476--489},
	title = {Neuronal activity in the human lateral temporal lobe},
	url = {https://doi.org/10.1007/BF00249601},
	urldate = {2021-03-04},
	volume = {77},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1007/BF00249601}}

@article{rivera_avian_2018,
	abstract = {Prenatal auditory stimulation is known to critically affect the development of acoustic preference and species recognition throughout ontogeny in birds. We focus our review on experimental studies that have used birds as model systems to explore the effects of prenatal auditory stimulation on the developing organism. To begin, we introduce concepts and terms of embryonic stages and learning and review the development of auditory perception and responsivity to acoustic stimulation in avian embryos. We then analyze studies that provide specific details of the effects of prenatal acoustic stimulation on the behavior, social preferences, and vocal production of both pre- and postnatal birds and discuss nuanced effects of the social and perceptual environment to which embryos may be exposed. We conclude that acoustic stimulation of avian embryos is a viable and critical model for future studies on the role of early experiences on the development of neural substrates and the resulting social affiliation patterns.},
	author = {Rivera, Moises and Louder, Matthew I. M. and Kleindorfer, Sonia and Liu, Wan-chun and Hauber, Mark E.},
	doi = {10.1007/s00265-018-2528-0},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/88ZBIWLK/Rivera et al. - 2018 - Avian prenatal auditory stimulation progress and .pdf:application/pdf},
	issn = {1432-0762},
	journal = {Behavioral Ecology and Sociobiology},
	language = {en},
	month = jun,
	number = {7},
	pages = {112},
	shorttitle = {Avian prenatal auditory stimulation},
	title = {Avian prenatal auditory stimulation: progress and perspectives},
	url = {https://doi.org/10.1007/s00265-018-2528-0},
	urldate = {2021-03-17},
	volume = {72},
	year = {2018},
	bdsk-url-1 = {https://doi.org/10.1007/s00265-018-2528-0}}

@article{mol_prosody_2017,
	abstract = {Birdsong shows striking parallels with human speech. Previous comparisons between birdsong and human vocalizations focused on syntax, phonology and phonetics. In this review, we propose that future comparative research should expand its focus to include prosody, i.e. the temporal and melodic properties that extend over larger units of song. To this end, we consider the similarities between birdsong structure and the prosodic hierarchy in human speech and between context-dependent acoustic variations in birdsong and the biological codes in human speech. Moreover, we discuss songbirds' sensitivity to prosody-like acoustic features and the role of such features in song segmentation and song learning in relation to infants' sensitivity to prosody and the role of prosody in early language acquisition. Finally, we make suggestions for future comparative birdsong research, including a framework of how prosody in birdsong can be studied. In particular, we propose to analyze birdsong as a multidimensional signal composed of specific acoustic features, and to assess whether these acoustic features are organized into prosody-like structures.},
	author = {Mol, Carien and Chen, Aoju and Kager, Ren{\'e} W. J. and Ter Haar, Sita M.},
	doi = {10.1016/j.neubiorev.2017.02.016},
	issn = {1873-7528},
	journal = {Neuroscience and Biobehavioral Reviews},
	keywords = {Animals, Humans, Language Development, Phonetics, Pitch Perception, Species Specificity, Speech, Vocalization, Animal, Prosody, Songbirds, Acoustic features, Birdsong, Human speech, Prosodic hierarchy, Vocal learning},
	language = {eng},
	month = oct,
	number = {Pt B},
	pages = {167--180},
	pmid = {28232050},
	shorttitle = {Prosody in birdsong},
	title = {Prosody in birdsong: {A} review and perspective},
	volume = {81},
	year = {2017},
	bdsk-url-1 = {https://doi.org/10.1016/j.neubiorev.2017.02.016}}

@article{yates_emergence_2021,
	abstract = {Adult cognitive neuroscience has guided the study of human brain development by identifying regions associated with cognitive functions at maturity. The activity, connectivity, and structure of a region can be compared across ages to characterize the developmental trajectory of the corresponding function. However, developmental differences may reflect both the maturation of the function and also its organization across the brain. That is, a function may be present in children but supported by different brain regions, leading its maturity to be underestimated. Here we test the presence, maturity, and localization of adult functions in children using shared response modeling, a machine learning approach for functional alignment. After learning a lower-dimensional feature space from fMRI activity as adults watched a movie, we translated these shared features into the anatomical brain space of children 3--12 years old. To evaluate functional maturity, we correlated this reconstructed activity with children's actual fMRI activity as they watched the same movie. We found reliable correlations throughout cortex, even in the youngest children. The strength of the correlation in the precuneus, inferior frontal gyrus, and lateral occipital cortex predicted chronological age. These age-related changes were driven by three types of developmental trajectories: emergence from absence to presence, consistency in anatomical expression, and reorganization from one anatomical region to another. We also found evidence that the processing of pain-related events in the movie underwent reorganization across childhood. This data-driven, naturalistic approach provides a new perspective on the development of functional neuroanatomy throughout childhood.},
	author = {Yates, Tristan S. and Ellis, Cameron T. and Turk-Browne, Nicholas B.},
	doi = {10.1016/j.neuroimage.2020.117606},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/R8ZSPFAC/Yates et al. - 2021 - Emergence and organization of adult brain function.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YL3GDCLI/S1053811920310910.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {fMRI, Developmental neuroscience, Brain maturation, Child development, Machine learning, Naturalistic perception, Shared response modeling},
	language = {en},
	month = feb,
	pages = {117606},
	title = {Emergence and organization of adult brain function throughout child development},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920310910},
	urldate = {2021-03-18},
	volume = {226},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811920310910},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2020.117606}}

@article{deco_emerging_2011,
	abstract = {Spontaneous ongoing global activity of the brain at rest is highly structured in spatiotemporal patterns called resting-state networks.Resting-state networks are related to the underlying neuroanatomical structure, but they emerge as a result of the interplay between dynamics and structure.Resting-state networks therefore reflect the intrinsic properties of the brain network. These include neuroanatomical structure, local neuronal dynamics, signal transmission delays and genuine noise.The formation and dissolution of resting-state networks reflects the exploration of possible functional network configurations around a stable anatomical framework.Brain networks generally possess a small-world construction, in which there are multiple ways for different network elements to interact. This anatomical architecture provides the landscape within which different possible network configurations occur. In the absence of external stimulation, noise drives the network dynamics such that the system will visit these network configurations spontaneously.Resting-state networks were originally characterized by indirect and slow measures of neuronal activity (for example, by blood oxygen level-dependent (BOLD) functional MRI (fMRI)). However, it is now clear that large-scale resting-state networks correlate with neuronal rhythms at faster frequencies.},
	author = {Deco, Gustavo and Jirsa, Viktor K. and McIntosh, Anthony R.},
	copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nrn2961},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/P7S9Q78V/Deco et al. - 2011 - Emerging concepts for the dynamical organization o.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8JWMBUZE/nrn2961.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	language = {en},
	month = jan,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {43--56},
	title = {Emerging concepts for the dynamical organization of resting-state activity in the brain},
	url = {https://www.nature.com/articles/nrn2961},
	urldate = {2021-03-22},
	volume = {12},
	year = {2011},
	bdsk-url-1 = {https://www.nature.com/articles/nrn2961},
	bdsk-url-2 = {https://doi.org/10.1038/nrn2961}}

@article{vanderwal_movies_2019,
	abstract = {The use of movie-watching as an acquisition state for functional connectivity (FC) MRI has recently enabled multiple groups to obtain rich data sets in younger children with both substantial sample sizes and scan durations. Using naturalistic paradigms such as movies has also provided analytic flexibility for these developmental studies that extends beyond conventional resting state approaches. This review highlights the advantages and challenges of using movies for developmental neuroimaging and explores some of the methodological issues involved in designing pediatric studies with movies. Emerging themes from movie-watching studies are discussed, including an emphasis on intersubject correlations, developmental changes in network interactions under complex naturalistic conditions, and dynamic age-related changes in both sensory and higher-order network FC even in narrow age ranges. Converging evidence suggests an enhanced ability to identify brain-behavior correlations in children when using movie-watching data relative to both resting state and conventional tasks. Future directions and cautionary notes highlight the potential and the limitations of using movies to study FC in pediatric populations.},
	author = {Vanderwal, Tamara and Eilbott, Jeffrey and Castellanos, F. Xavier},
	doi = {10.1016/j.dcn.2018.10.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KQMLJW39/Vanderwal et al. - 2019 - Movies in the magnet Naturalistic paradigms in de.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/F36MXY9I/S1878929318301178.html:text/html},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Children, Head motion, Intersubject correlations, Movies, Naturalistic viewing, Resting state},
	language = {en},
	month = apr,
	pages = {100600},
	shorttitle = {Movies in the magnet},
	title = {Movies in the magnet: {Naturalistic} paradigms in developmental functional neuroimaging},
	url = {https://www.sciencedirect.com/science/article/pii/S1878929318301178},
	urldate = {2021-03-24},
	volume = {36},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1878929318301178},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2018.10.004}}

@article{sonkusare_naturalistic_2019,
	abstract = {Cognitive neuroscience has traditionally focused on simple tasks, presented sparsely and using abstract stimuli. While this approach has yielded fundamental insights into functional specialisation in the brain, its ecological validity remains uncertain. Do these tasks capture how brains function `in the wild', where stimuli are dynamic, multimodal, and crowded? Ecologically valid paradigms that approximate real life scenarios, using stimuli such as films, spoken narratives, music, and multiperson games emerged in response to these concerns over a decade ago. We critically appraise whether this approach has delivered on its promise to deliver new insights into brain function. We highlight the challenges, technological innovations, and clinical opportunities that are required should this field meet its full potential.},
	author = {Sonkusare, Saurabh and Breakspear, Michael and Guo, Christine},
	doi = {10.1016/j.tics.2019.05.004},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/FHQGVAJ3/Sonkusare et al. - 2019 - Naturalistic Stimuli in Neuroscience Critically A.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/DWZYQNI8/S1364661319301275.html:text/html},
	issn = {1364-6613},
	journal = {Trends in Cognitive Sciences},
	keywords = {social cognition, memory, critical dynamics, emotion, fMRI analysis, movies, naturalistic stimuli, resting-state fMRI},
	language = {en},
	month = aug,
	number = {8},
	pages = {699--714},
	shorttitle = {Naturalistic {Stimuli} in {Neuroscience}},
	title = {Naturalistic {Stimuli} in {Neuroscience}: {Critically} {Acclaimed}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661319301275},
	urldate = {2021-03-24},
	volume = {23},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1364661319301275},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2019.05.004}}

@article{yates_emergence_2021-1,
	abstract = {Adult cognitive neuroscience has guided the study of human brain development by identifying regions associated with cognitive functions at maturity. The activity, connectivity, and structure of a region can be compared across ages to characterize the developmental trajectory of the corresponding function. However, developmental differences may reflect both the maturation of the function and also its organization across the brain. That is, a function may be present in children but supported by different brain regions, leading its maturity to be underestimated. Here we test the presence, maturity, and localization of adult functions in children using shared response modeling, a machine learning approach for functional alignment. After learning a lower-dimensional feature space from fMRI activity as adults watched a movie, we translated these shared features into the anatomical brain space of children 3--12 years old. To evaluate functional maturity, we correlated this reconstructed activity with children's actual fMRI activity as they watched the same movie. We found reliable correlations throughout cortex, even in the youngest children. The strength of the correlation in the precuneus, inferior frontal gyrus, and lateral occipital cortex predicted chronological age. These age-related changes were driven by three types of developmental trajectories: emergence from absence to presence, consistency in anatomical expression, and reorganization from one anatomical region to another. We also found evidence that the processing of pain-related events in the movie underwent reorganization across childhood. This data-driven, naturalistic approach provides a new perspective on the development of functional neuroanatomy throughout childhood.},
	author = {Yates, Tristan S. and Ellis, Cameron T. and Turk-Browne, Nicholas B.},
	doi = {10.1016/j.neuroimage.2020.117606},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/X9VJIDEM/Yates et al. - 2021 - Emergence and organization of adult brain function.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/DAYSPL2M/S1053811920310910.html:text/html},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {fMRI, Developmental neuroscience, Brain maturation, Child development, Machine learning, Naturalistic perception, Shared response modeling},
	language = {en},
	month = feb,
	pages = {117606},
	title = {Emergence and organization of adult brain function throughout child development},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811920310910},
	urldate = {2021-03-24},
	volume = {226},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811920310910},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2020.117606}}

@article{turbek_rapid_2021,
	abstract = {Choosy females drive isolation
Rapid radiations of recently diverged species represent an excellent opportunity for exploring drivers of speciation. The capuchino seedeaters, a group of South American birds, include a number of species that, in the field, are often discernable only through male plumage and song. Turbek et al. used genomes and behavioral experiments to identify potential isolating factors in two members of this group and found that, though entirely sympatric, females mated only with conspecific males and that only a few genes differed between the species (see the Perspective by Jarvis). Thus, a small reshuffling of genes and reinforcement through mate choice has driven divergence in these overlapping and very similar species.
Science, this issue p. eabc0256; see also p. 1312
Structured Abstract
INTRODUCTIONOrganisms in the early stages of speciation provide an opportunity to understand the processes that govern reproductive isolation between taxa. Ecological or behavioral mechanisms can serve as powerful barriers to the interbreeding of co-occurring species at the onset of their divergence. Tracking mating decisions within wild populations early in speciation can improve our understanding of how behavioral isolation promotes divergence.
RATIONALEThe southern capuchino seedeaters (Sporophila) are one of the most rapid avian radiations, showing remarkably low ecological and genomic divergence. We took advantage of the recent discovery of a capuchino species, the Iber{\'a} Seedeater (S. iberaensis), to study the origin and importance of pre-mating barriers early in speciation. By combining genomic and behavioral analyses, we examined (i) the role of assortative mating in the maintenance of species boundaries, (ii) the phenotypic traits underlying species recognition, (iii) the genomic basis of such traits, and (iv) the origin of these genomic variants.
RESULTSSporophila iberaensis was first observed in 2001 and co-occurs with S. hypoxantha throughout its main breeding location in the northern portion of the Iber{\'a} wetlands of Argentina. Across two breeding seasons, we located nests and collected genomic samples from both species. We found extremely low genome-wide differentiation, with the exception of three narrow regions located on different chromosomes. These regions contained 12 genes, three of which are involved in plumage coloration (TYRP1, OCA2, and HERC2). Sporophila hypoxantha and S. iberaensis males differ in coloration and song, but females are indistinguishable in coloration across the avian visual spectrum. We therefore used genomic data to quantify assortative mating. Each female's species-specific genotype always matched the genotype of her mate, demonstrating strong assortative mating despite these two species holding neighboring breeding territories, breeding synchronously, and foraging together on the same grasses. We tested the importance of divergent plumage patterning and song in species recognition and pre-mating isolation through playback experiments in the field. We presented territorial males with combinations of conspecific and heterospecific song and plumage, and assessed their aggressive behavioral responses. Each species responded most aggressively to conspecific song and plumage, confirming that both traits are used to recognize sexual competitors. Finally, we investigated the origin of the novel S. iberaensis plumage phenotype by examining genomic differentiation across the broader capuchino radiation. Although multiple species shared variants with S. iberaensis in the areas of elevated differentiation, the specific combination of these variants across the divergent regions distinguished S. iberaensis from all other capuchinos.
CONCLUSIONOur findings point to pre-mating isolation through assortative mate choice, based on both plumage coloration and song, as a primary mechanism promoting divergence between these co-occurring capuchino species. Although the ultimate fate of the incipient S. iberaensis species remains uncertain, our findings illustrate how lineages can form and quickly become reproductively isolated from co-occurring, syntopic species. Our results further suggest that the reshuffling of existing genetic variation can generate novel phenotypes that are then targeted by sexual selection. Assortative mating based on these traits may maintain species boundaries early in speciation while subsequent reproductive barriers accumulate. {\textless}img class="fragment-image" aria-describedby="F1-caption" src="https://science.sciencemag.org/content/sci/371/6536/eabc0256/F1.medium.gif"/{\textgreater} Download high-res image Open in new tab Download Powerpoint Novel mating signals restrict gene flow between co-occurring bird species.Sporophila iberaensis was first observed in 2001 and has a breeding range contained entirely within that of S. hypoxantha. Despite extremely low genomic differentiation, both species mate assortatively. Genetic differentiation is concentrated near genes known to be involved in plumage coloration. Field experiments show that both song and plumage are used to recognize sexual competitors.
Behavioral isolation can catalyze speciation and permit the slow accumulation of additional reproductive barriers between co-occurring organisms. We illustrate how this process occurs by examining the genomic and behavioral bases of pre-mating isolation between two bird species (Sporophila hypoxantha and the recently discovered S. iberaensis) that belong to the southern capuchino seedeaters, a recent, rapid radiation characterized by variation in male plumage coloration and song. Although these two species co-occur without obvious ecological barriers to reproduction, we document behaviors indicating species recognition by song and plumage traits and strong assortative mating associated with genomic regions underlying male plumage patterning. Plumage differentiation likely originated through the reassembly of standing genetic variation, indicating how novel sexual signals may quickly arise and maintain species boundaries.
Females' choices have driven assortative mating and speciation in capuchino seedeater birds in a national park in Argentina.
Females' choices have driven assortative mating and speciation in capuchino seedeater birds in a national park in Argentina.},
	author = {Turbek, Sheela P. and Browne, Melanie and Giacomo, Adri{\'a}n S. Di and Kopuchian, Cecilia and Hochachka, Wesley M. and Estalles, Cecilia and Lijtmaer, Dar{\'\i}o A. and Tubaro, Pablo L. and Silveira, Lu{\'\i}s F{\'a}bio and Lovette, Irby J. and Safran, Rebecca J. and Taylor, Scott A. and Campagna, Leonardo},
	copyright = {Copyright {\copyright} 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. https://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	doi = {10.1126/science.abc0256},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IAEJN5H9/Turbek et al. - 2021 - Rapid speciation via the evolution of pre-mating i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/24X9G5H8/tab-pdf.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = mar,
	note = {Publisher: American Association for the Advancement of Science Section: Research Article},
	number = {6536},
	pmid = {33766854},
	title = {Rapid speciation via the evolution of pre-mating isolation in the {Iber{\'a}} {Seedeater}},
	url = {https://science.sciencemag.org/content/371/6536/eabc0256},
	urldate = {2021-04-02},
	volume = {371},
	year = {2021},
	bdsk-url-1 = {https://science.sciencemag.org/content/371/6536/eabc0256},
	bdsk-url-2 = {https://doi.org/10.1126/science.abc0256}}

@article{oliu-barton_sars-cov-2_2021,
	abstract = {The trade-off between different objectives is at the heart of political decision making.
Public health, economic growth, democratic solidarity, and civil liberties are important
factors when evaluating pandemic responses. There is mounting evidence that these
objectives do not need to be in conflict in the COVID-19 response. Countries that
consistently aim for elimination---ie, maximum action to control SARS-CoV-2 and stop
community transmission as quickly as possible---have generally fared better than countries
that opt for mitigation---ie, action increased in a stepwise, targeted way to reduce
cases so as not to overwhelm health-care systems.},
	author = {Oliu-Barton, Miquel and Pradelski, Bary S. R. and Aghion, Philippe and Artus, Patrick and Kickbusch, Ilona and Lazarus, Jeffrey V. and Sridhar, Devi and Vanderslott, Samantha},
	doi = {10.1016/S0140-6736(21)00978-8},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/A93ITT52/Oliu-Barton et al. - 2021 - SARS-CoV-2 elimination, not mitigation, creates be.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6GKV5F6J/fulltext.html:text/html},
	issn = {0140-6736, 1474-547X},
	journal = {The Lancet},
	language = {English},
	month = apr,
	note = {Publisher: Elsevier},
	number = {0},
	pmid = {33932328},
	title = {{SARS}-{CoV}-2 elimination, not mitigation, creates best outcomes for health, the economy, and civil liberties},
	url = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00978-8/abstract},
	urldate = {2021-05-12},
	volume = {0},
	year = {2021},
	bdsk-url-1 = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00978-8/abstract},
	bdsk-url-2 = {https://doi.org/10.1016/S0140-6736(21)00978-8}}

@article{spool_genetically-identified_2020,
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}In vertebrates, advanced cognitive abilities are associated with a highly developed telencephalic pallium. In mammals, the six-layered neocortex of the pallium is composed of excitatory neurons and inhibitory interneurons, organized across layers into microcircuits. These organizational principles are proposed to support efficient, high-level information processing. Comparative perspectives across vertebrates provide a lens to understand what common features of pallium are important for complex cognition. For non-mammalian vertebrates that exhibit complex cognitive abilities, such as birds, the physiology of identified pallial cell types and their circuit organization are largely unresolved. Using viral tools to target excitatory vs. inhibitory neurons in the zebra finch auditory association pallium, we systematically tested predictions derived from mammalian neocortex. We identify two segregated neuronal populations that exhibit profound physiological and computational similarities with mammalian excitatory and inhibitory neocortical cells. Specifically, despite dissimilarities in gross architecture, avian association pallium exhibits neocortex-typical coding principles, and inhibitory-dependent cortical synchrony, gamma oscillations, and local suppression. Our findings suggest parallel evolution of physiological and network roles for pallial cell types in amniotes with substantially divergent pallial organization.{\textless}/p{\textgreater}},
	author = {Spool, Jeremy A. and Macedo-Lima, Matheus and Scarpa, Garrett and Morohashi, Yuichi and Yazaki-Sugiyama, Yoko and Remage-Healey, Luke},
	copyright = {{\copyright} 2020, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	doi = {10.1101/2020.11.11.374553},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/E56G8AAD/Spool et al. - 2020 - Genetically-identified cell types in avian pallium.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DG7KG23H/2020.11.11.374553v1.html:text/html},
	journal = {bioRxiv},
	keywords = {auditory, songbird, evolution, calcium/calmodulin-dependent kinase II alpha, cell type, gamma oscillation, glutamate decarboxylase 1, interneuron, pallium, principal cell},
	language = {en},
	month = nov,
	note = {Publisher: Cold Spring Harbor Laboratory Section: New Results},
	pages = {2020.11.11.374553},
	title = {Genetically-identified cell types in avian pallium mirror core principles of excitatory and inhibitory neurons in mammalian cortex},
	url = {https://www.biorxiv.org/content/10.1101/2020.11.11.374553v1},
	urldate = {2021-05-10},
	year = {2020},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/2020.11.11.374553v1},
	bdsk-url-2 = {https://doi.org/10.1101/2020.11.11.374553}}

@article{scharff_comparative_1991,
	abstract = {Song production in song birds is controlled by an efferent pathway. Appended to this pathway is a ``recursive loop'' that is necessary for song acquisition but not for the production of learned song. Since zebra finches learn their song by imitating external models, we speculated that the importance of the recursive loop for learning might derive from its processing of auditory feedback during song acquisition. This hypothesis was tested by comparing the effects on song in birds deafened early in life and birds with early lesions in either of two nuclei--Area X and the lateral magnocellular nucleus of the anterior neostriatum (LMAN). These nuclei are part of the recursive loop. The three treatments affected song development differently, as reflected by various parameters of the adult song of these birds. Whereas LMAN lesions resulted in songs with monotonous repetitions of a single note complex, songs of Area X-lesioned birds consisted of rambling series of unusually long and variable notes. Furthermore, whereas song of LMAN lesioned birds stabilized early, song stability as seen in intact birds was never achieved in Area X-lesioned birds. Early deafness also resulted in poorly structured and unstable song. We conclude that Area X and LMAN contribute differently to song acquisition: the song variability that is typical of vocal development persists following early deafness or lesions of Area X but ends abruptly following removal of LMAN. Apparently, LMAN plays a crucial role in fostering the kinds of circuit plasticity necessary for learning.},
	author = {Scharff, C. and Nottebohm, F.},
	copyright = {{\copyright} 1991 by Society for Neuroscience},
	doi = {10.1523/JNEUROSCI.11-09-02896.1991},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/I3XZS4WU/Scharff and Nottebohm - 1991 - A comparative study of the behavioral deficits fol.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WBVIB67F/2896.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = sep,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {9},
	pages = {2896--2913},
	pmid = {1880555},
	shorttitle = {A comparative study of the behavioral deficits following lesions of various parts of the zebra finch song system},
	title = {A comparative study of the behavioral deficits following lesions of various parts of the zebra finch song system: implications for vocal learning},
	url = {https://www.jneurosci.org/content/11/9/2896},
	urldate = {2021-05-14},
	volume = {11},
	year = {1991},
	bdsk-url-1 = {https://www.jneurosci.org/content/11/9/2896},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.11-09-02896.1991}}

@article{lipkind_songbirds_2017,
	abstract = {While acquiring motor skills, animals transform their plastic motor sequences to match desired targets. However, because both the structure and temporal position of individual gestures are adjustable, the number of possible motor transformations increases exponentially with sequence length. Identifying the optimal transformation towards a given target is therefore a computationally intractable problem. Here we show an evolutionary workaround for reducing the computational complexity of song learning in zebra finches. We prompt juveniles to modify syllable phonology and sequence in a learned song to match a newly introduced target song. Surprisingly, juveniles match each syllable to the most spectrally similar sound in the target, regardless of its temporal position, resulting in unnecessary sequence errors, that they later try to correct. Thus, zebra finches prioritize efficient learning of syllable vocabulary, at the cost of inefficient syntax learning. This strategy provides a non-optimal but computationally manageable solution to the task of vocal sequence learning.},
	author = {Lipkind, Dina and Zai, Anja T. and Hanuschkin, Alexander and Marcus, Gary F. and Tchernichovski, Ofer and Hahnloser, Richard H. R.},
	copyright = {2017 The Author(s)},
	doi = {10.1038/s41467-017-01436-0},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DENA49LV/Lipkind et al. - 2017 - Songbirds work around computational complexity by .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HV2YEEEN/s41467-017-01436-0.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = nov,
	note = {Number: 1 Publisher: Nature Publishing Group},
	number = {1},
	pages = {1247},
	title = {Songbirds work around computational complexity by learning song vocabulary independently of sequence},
	url = {https://www.nature.com/articles/s41467-017-01436-0},
	urldate = {2021-05-12},
	volume = {8},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-017-01436-0},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-017-01436-0}}

@phdthesis{monnen_effects_nodate,
	abstract = {The estrildid finches of Africa, Australia, and Asia are social birds that rely on specialized acoustic communication for behaviors critical to survival and mating. Within the family Estrildidae, song learning is a complex process in which adults tutor young birds, who in turn listen, rehearse, and perfect a species-typical song. According to existing literature, the birds' song syllables (distinct vocal units) and syntax (the ordering of these syllables) may be coded neuronally by distinct circuits, with syllable copying being accomplished during development but influenced by individual exposure to adult tutors, and syntax being hardwired for the species. These studies suggest that juveniles cross-tutored by members of a different species could develop songs with features of both their natal and their cross-tutor species. The present study aims to explore whether juvenile Bengalese finches (Lonchura striata domestica, BF) cross-tutored by adult long-tailed finches (Poephila acuticauda, LF) develop songs with elements of their cross-tutor's song. Specifically, it examines whether the cross-tutees' songs exhibit probabilistic syntax (the variable ordering of syllables typical of BFs) or deterministic syntax (the predictable ordering of syllables typical of LFs), as compared to the songs of male BFs tutored by conspecific parents. To test this, I transferred a group of BF nestlings from the biological parents' nest into an LF nest to be raised and tutored by foster LF parents while another group of BF nestlings remained in the natal nest to be raised and tutored by conspecific parents. Juveniles of both groups were recorded individually on a weekly basis to monitor their song development from approximately 50 days post-hatch into adulthood at 120 days posthatch. I analyzed recordings for the songs' broad acoustic features using frequency power spectra and modulation power spectra, as well as the songs' transition and syllable features.},
	author = {Monnen, Christina},
	file = {Monnen - Effects of Long-Tailed Finch (Poephila acuticauda).pdf:/Users/Cecile/Zotero/storage/2MRLKZDX/Monnen - Effects of Long-Tailed Finch (Poephila acuticauda).pdf:application/pdf},
	language = {en},
	title = {Effects of {Long}-{Tailed} {Finch} ({Poephila} acuticauda) {Cross}-{Tutoring} on {Juvenile} {Bengalese} {Finch} ({Lonchura} striata domestica) {Song} {Development}}}

@article{james_phylogeny_2021,
	author = {James, Logan S. and Mori, Chihiro and Wada, Kazuhiro and Sakata, Jon T.},
	doi = {10.1016/j.cub.2021.04.015},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LUIXU9SD/James et al. - 2021 - Phylogeny and mechanisms of shared hierarchical pa.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TXEFMB6F/S0960-9822(21)00528-5.html:text/html},
	issn = {0960-9822},
	journal = {Current Biology},
	keywords = {songbird, speech, music, communication, compression, cultural evolution, linguistics, Menzerath's law, motor biases, universals},
	language = {English},
	month = may,
	note = {Publisher: Elsevier},
	number = {0},
	pmid = {33989526},
	title = {Phylogeny and mechanisms of shared hierarchical patterns in birdsong},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(21)00528-5},
	urldate = {2021-05-18},
	volume = {0},
	year = {2021},
	bdsk-url-1 = {https://www.cell.com/current-biology/abstract/S0960-9822(21)00528-5},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2021.04.015}}

@article{tierney_empirical_2008,
	abstract = {In music, large intervals ("pitch skips") are often followed by reversals, and phrases often have an arch-like shape and final durational lengthening. These regularities could reflect motor constraints on pitch production or could reflect the melodic characteristics of speech. To distinguish between these possibilities we compared pitch patterns in instrumental musical themes, sentences, and birdsongs. Patterns due to production-related constraints should be common to all three domains, whereas patterns due to statistical learning from speech should be present in speech but not birdsong. Sequences were taken from English and French instrumental classical music, sentences from 4 languages, and songs of 56 songbird families. For sentences and birdsongs each syllablenote was assigned one pitch. For each sequence, we quantified patterns of post-skip reversals, the direction of the initial and final interval, the relative duration of the final syllablenote, and the pitch contour shape. Post-skip reversals predominated in all domains, likely reflecting a shared constraint: skips frequently take melodies toward the edges of the pitch range, forcing a subsequent reversal (as suggested by Von Hippel \& Huron, 2000). Arch-like contours and final lengthening were found in music and speech but not birdsong, possibly reflecting an influence of speech patterns on musical structure.},
	author = {Tierney, Adam and Russo, Frank and Patel, Aniruddh},
	doi = {10.1121/1.2935184},
	journal = {The Journal of the Acoustical Society of America},
	month = may,
	pages = {3721},
	title = {Empirical comparisons of pitch patterns in music, speech, and birdsong},
	volume = {123},
	year = {2008},
	bdsk-url-1 = {https://doi.org/10.1121/1.2935184}}

@article{ten_cate_phonetic_2014,
	abstract = {Like speech and language, the songs of many songbirds consist of learned, rapidly produced, structured sequences of distinct vocal units, originating from an interplay between experience and learning biases. Songs are species specific, but also show considerable within species variation in elements or element sequencing. This variation implies that birds possess mechanisms to identify, categorize and combine sounds. I review the abilities for speech sound perception and categorization, as well as for grammatical rule learning by birds. Speech sound perception in birds is in many ways comparable to human speech perception. Birds can also detect and generalize patterns underlying artificially arranged strings of vocal elements. However, there is a need for more comparative studies to examine the limits of their rule learning abilities and how they relate to those of humans.},
	author = {ten Cate, Carel},
	doi = {10.1016/j.conb.2014.07.019},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MPJ76R8U/ten Cate - 2014 - On the phonetic and syntactic processing abilities.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/I8UD4Y2W/S0959438814001561.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	language = {en},
	month = oct,
	pages = {157--164},
	series = {{SI}: {Communication} and language},
	shorttitle = {On the phonetic and syntactic processing abilities of birds},
	title = {On the phonetic and syntactic processing abilities of birds: {From} songs to speech and artificial grammars},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438814001561},
	urldate = {2021-05-18},
	volume = {28},
	year = {2014},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0959438814001561},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2014.07.019}}

@article{kagawa_domestication_2014,
	abstract = {Birdsongs are acquired by imitating the sounds produced by conspecifics. Within a species, songs diverge by cultural transmission, but the range of species-specific features is restricted by innate constraints. Bengalese finches (Lonchura striata var. domestica) are a domesticated strain of the wild White-rumped munia (Lonchura striata). The songs of the domesticated strain have more tonal sounds and more variable sequences than those of the wild strain. We compared the features of songs that were produced by normal birds, isolation-reared birds, and cross-fostered birds in both White-rumped munias and Bengalese finches to identify differences in the genetic and environmental factors of their songs. Factor analyses were conducted based on 17 song measurements. We found that isolated songs differed from normal and cross-fostered songs, especially in unstable prosodic features. In addition, there were significant differences in sound property of mean frequency between the two strains regardless of the rearing conditions. Thus, innate constraints that partially determine birdsong phenotypes may be altered through domestication.},
	author = {Kagawa, Hiroko and Suzuki, Kenta and Takahasi, Miki and Okanoya, Kazuo},
	doi = {10.1016/j.beproc.2014.04.011},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/HXN6F3SS/Kagawa et al. - 2014 - Domestication changes innate constraints for birds.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5QSKLVIN/S0376635714001132.html:text/html},
	issn = {0376-6357},
	journal = {Behavioural Processes},
	keywords = {Learning, Bengalese finches, Evolution, Songbird, White rumped munias},
	language = {en},
	month = jul,
	pages = {91--97},
	title = {Domestication changes innate constraints for birdsong learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0376635714001132},
	urldate = {2021-05-18},
	volume = {106},
	year = {2014},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0376635714001132},
	bdsk-url-2 = {https://doi.org/10.1016/j.beproc.2014.04.011}}

@article{okanoya_adult_1997,
	abstract = {Songbirds develop their songs by imitating songs of adults. For song learning to proceed normally, the bird's hearing must remain intact throughout the song development process. In many species, song learning takes place during one period early in life, and no more new song elements are learned thereafter. In these so-called close-ended learners, it has long been assumed that once song development is complete, audition is no longer necessary to maintain the motor patterns of full song. However, many of these close-ended learners maintain plasticity in overall song organization; the number and the sequence of song elements included in a song of an individual vary from one utterance to another, although no new song elements are added or lost in adulthood. It is conceivable that these species rely on continued auditory feedback to produce normal song syntax. The Bengalese finch is a close-ended learner that produces considerably variable songs as an adult. In the present study, we found that Bengalese finches require real-time auditory feedback for motor control even after song learning is complete; deafening adult finches resulted in development of abnormal song syntax in as little as 5 days. We also found that there was considerable individual variation in the degree of song deterioration after deafening. The neural mechanisms underlying adult song production in different species of songbirds may be more diverse than has been traditionally considered. {\copyright} 1997 John Wiley \& Sons, Inc. J Neurobiol 33: 343--356, 1997},
	author = {Okanoya, Kazuo and Yamaguchi, Ayako},
	copyright = {Copyright {\copyright} 1997 John Wiley \& Sons, Inc.},
	doi = {https://doi.org/10.1002/(SICI)1097-4695(199710)33:4<343::AID-NEU1>3.0.CO;2-A},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/NYUZL8CF/Okanoya et Yamaguchi - 1997 - Adult bengalese finches (Lonchura striata var. dom.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QJ7KBPIX/(SICI)1097-4695(199710)334343AID-NEU13.0.html:text/html},
	issn = {1097-4695},
	journal = {Journal of Neurobiology},
	keywords = {auditory feedback, close-ended learner, deafening, Lonchura striata, vocal motor control},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291097-4695\%28199710\%2933\%3A4\%3C343\%3A\%3AAID-NEU1\%3E3.0.CO\%3B2-A},
	number = {4},
	pages = {343--356},
	title = {Adult bengalese finches ({Lonchura} striata var. domestica) require real-time auditory feedback to produce normal song syntax},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4695%28199710%2933%3A4%3C343%3A%3AAID-NEU1%3E3.0.CO%3B2-A},
	urldate = {2021-05-18},
	volume = {33},
	year = {1997},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-4695%28199710%2933%3A4%3C343%3A%3AAID-NEU1%3E3.0.CO%3B2-A},
	bdsk-url-2 = {https://doi.org/10.1002/(SICI)1097-4695(199710)33:4%3C343::AID-NEU1%3E3.0.CO;2-A}}

@article{clayton_effects_1989,
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}div id="" class="section"{\textgreater}{\textless}h3 class="abstractTitle text-title my-1" id="d40403282e95"{\textgreater}Abstract{\textless}/h3{\textgreater}{\textless}p{\textgreater}Male zebra finches, Taeniopygia guttata, which have been cross-fostered to Bengalesc finches, Lonchura striata, learn Bengalese finch song elements with as much accuracy as a male learning from his natural father. However, these elements are sung in phrases which are more nearly zebra finch length and lack the repetitiveness typical of the elements in a Bengalese finch phrase. Male Bengalese finches are also capable of learning song from a zebra finch foster-father. Males vary substantially but they tend to produce fewer, more widely spaced zebra finch elements in a Bengalese finch-length phrase. Both species show selective song learning and it is suggested that phrase length and the absence or presence of repeated elements might act as important cues for species-specific learning. Cross-fostered Bengalese finches seem to learn less than cross-fostered zebra finches: possible reasons for this are discussed.{\textless}/p{\textgreater}{\textless}/div{\textgreater}{\textless}/section{\textgreater}},
	author = {Clayton, N. S.},
	doi = {10.1163/156853989X00204},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/VIY2PWHJ/Clayton - 1989 - The Effects of Cross-Fostering On Selective Song L.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RJEWUF4Z/article-p163_1.html:text/html},
	issn = {0005-7959, 1568-539X},
	journal = {Behaviour},
	language = {en},
	month = jan,
	note = {Publisher: Brill Section: Behaviour},
	number = {3-4},
	pages = {163--174},
	title = {The {Effects} of {Cross}-{Fostering} {On} {Selective} {Song} {Learning} in {Estrildid} {Finches}},
	url = {https://brill.com/view/journals/beh/109/3-4/article-p163_1.xml},
	urldate = {2021-05-18},
	volume = {109},
	year = {1989},
	bdsk-url-1 = {https://brill.com/view/journals/beh/109/3-4/article-p163_1.xml},
	bdsk-url-2 = {https://doi.org/10.1163/156853989X00204}}

@article{gadagkar_dopamine_2016,
	abstract = {Birds of a feather sing together
How do birds know that a song that they hear is from a member of their own species, and how do they learn their songs in the first place? Araki et al. identified two types of brain cells involved in how finches learn their songs (see the Perspective by Tchernichovski and Lipkind). When zebra finches were raised by Bengalese finch foster parents, they learned a song whose morphology resembled that of their foster father. However, the temporal structure remained zebra finch--specific, suggesting that it is innate. Gadagkar et al. recorded activity in specific dopamine neurons in singing zebra finches while controlling perceived song quality with distorted auditory feedback. This distorted feedback represented worse performance than predicted and resulted in negative prediction errors. These findings suggest again that finches have an innate internal goal for their learned songs.
Science, this issue p. 1282, p. 1234; see also p. 1278
Many behaviors are learned through trial and error by matching performance to internal goals. Yet neural mechanisms of performance evaluation remain poorly understood. We recorded basal ganglia--projecting dopamine neurons in singing zebra finches as we controlled perceived song quality with distorted auditory feedback. Dopamine activity was phasically suppressed after distorted syllables, consistent with a worse-than-predicted outcome, and was phasically activated at the precise moment of the song when a predicted distortion did not occur, consistent with a better-than-predicted outcome. Error response magnitude depended on distortion probability. Thus, dopaminergic error signals can evaluate behaviors that are not learned for reward and are instead learned by matching performance outcomes to internal goals.
Zebra finch brains compare the quality of their song relative to internal benchmarks.
Zebra finch brains compare the quality of their song relative to internal benchmarks.},
	author = {Gadagkar, Vikram and Puzerey, Pavel A. and Chen, Ruidong and Baird-Daniel, Eliza and Farhang, Alexander R. and Goldberg, Jesse H.},
	copyright = {Copyright {\copyright} 2016, American Association for the Advancement of Science},
	doi = {10.1126/science.aah6837},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/2M5872XV/Gadagkar et al. - 2016 - Dopamine neurons encode performance error in singi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZM2EQ74M/1278.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = dec,
	note = {Publisher: American Association for the Advancement of Science Section: Reports},
	number = {6317},
	pages = {1278--1282},
	pmid = {27940871},
	title = {Dopamine neurons encode performance error in singing birds},
	url = {https://science.sciencemag.org/content/354/6317/1278},
	urldate = {2021-06-09},
	volume = {354},
	year = {2016},
	bdsk-url-1 = {https://science.sciencemag.org/content/354/6317/1278},
	bdsk-url-2 = {https://doi.org/10.1126/science.aah6837}}

@article{araki_mind_2016,
	abstract = {Birds of a feather sing together
How do birds know that a song that they hear is from a member of their own species, and how do they learn their songs in the first place? Araki et al. identified two types of brain cells involved in how finches learn their songs (see the Perspective by Tchernichovski and Lipkind). When zebra finches were raised by Bengalese finch foster parents, they learned a song whose morphology resembled that of their foster father. However, the temporal structure remained zebra finch--specific, suggesting that it is innate. Gadagkar et al. recorded activity in specific dopamine neurons in singing zebra finches while controlling perceived song quality with distorted auditory feedback. This distorted feedback represented worse performance than predicted and resulted in negative prediction errors. These findings suggest again that finches have an innate internal goal for their learned songs.
Science, this issue p. 1282, p. 1234; see also p. 1278
Juvenile songbirds learn vocal communication from adult tutors of the same species but not from adults of other species. How species-specific learning emerges from the basic features of song prosody remains unknown. In the zebra finch auditory cortex, we discovered a class of neurons that register the silent temporal gaps between song syllables and are distinct from neurons encoding syllable morphology. Behavioral learning and neuronal coding of temporal gap structure resisted song tutoring from other species: Zebra finches fostered by Bengalese finch parents learned Bengalese finch song morphology transposed onto zebra finch temporal gaps. During the vocal learning period, temporal gap neurons fired selectively to zebra finch song. The innate temporal coding of intersyllable silent gaps suggests a neuronal barcode for conspecific vocal learning and social communication in acoustically diverse environments.
Zebra finches fostered by Bengalese finch parents learn Bengalese finch songs but with zebra finch timing.
Zebra finches fostered by Bengalese finch parents learn Bengalese finch songs but with zebra finch timing.},
	author = {Araki, Makoto and Bandi, M. M. and Yazaki-Sugiyama, Yoko},
	copyright = {Copyright {\copyright} 2016, American Association for the Advancement of Science},
	doi = {10.1126/science.aah6799},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/C3LNKWBL/Araki et al. - 2016 - Mind the gap Neural coding of species identity in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/F4ENM822/1282.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = dec,
	note = {Publisher: American Association for the Advancement of Science Section: Reports},
	number = {6317},
	pages = {1282--1287},
	pmid = {27940872},
	shorttitle = {Mind the gap},
	title = {Mind the gap: {Neural} coding of species identity in birdsong prosody},
	url = {https://science.sciencemag.org/content/354/6317/1282},
	urldate = {2021-06-09},
	volume = {354},
	year = {2016},
	bdsk-url-1 = {https://science.sciencemag.org/content/354/6317/1282},
	bdsk-url-2 = {https://doi.org/10.1126/science.aah6799}}

@article{woolley_developmental_2010,
	abstract = {In songbirds, species identity and developmental experience shape vocal behavior and behavioral responses to vocalizations. The interaction of species identity and developmental experience may also shape the coding properties of sensory neurons. We tested whether responses of auditory midbrain and forebrain neurons to songs differed between species and between groups of conspecific birds with different developmental exposure to song. We also compared responses of individual neurons to conspecific and heterospecific songs. Zebra and Bengalese finches that were raised and tutored by conspecific birds, and zebra finches that were cross-tutored by Bengalese finches were studied. Single-unit responses to zebra and Bengalese finch songs were recorded and analyzed by calculating mutual information (MI), response reliability, mean spike rate, fluctuations in time-varying spike rate, distributions of time-varying spike rates, and neural discrimination of individual songs. MI quantifies a response's capacity to encode information about a stimulus. In midbrain and forebrain neurons, MI was significantly higher in normal zebra finch neurons than in Bengalese finch and cross-tutored zebra finch neurons, but not between Bengalese finch and cross-tutored zebra finch neurons. Information rate differences were largely due to spike rate differences. MI did not differ between responses to conspecific and heterospecific songs. Therefore, neurons from normal zebra finches encoded more information about songs than did neurons from other birds, but conspecific and heterospecific songs were encoded equally. Neural discrimination of songs and MI were highly correlated. Results demonstrate that developmental exposure to vocalizations shapes the information coding properties of songbird auditory neurons. {\copyright} 2009 Wiley Periodicals, Inc. Develop Neurobiol 70: 235--252, 2010.},
	author = {Woolley, Sarah M. N. and Hauber, Mark E. and Theunissen, Frederic E.},
	copyright = {Copyright {\copyright} 2010 Wiley Periodicals, Inc.},
	doi = {10.1002/dneu.20783},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/B9ZB2LE4/Woolley et al. - 2010 - Developmental experience alters information coding.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BI47CAL9/dneu.html:text/html},
	issn = {1932-846X},
	journal = {Developmental Neurobiology},
	keywords = {inferior colliculus, neural coding, vocalization, songbird, song},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/dneu.20783},
	number = {4},
	pages = {235--252},
	title = {Developmental experience alters information coding in auditory midbrain and forebrain neurons},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dneu.20783},
	urldate = {2021-06-10},
	volume = {70},
	year = {2010},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dneu.20783},
	bdsk-url-2 = {https://doi.org/10.1002/dneu.20783}}

@article{segal_osnat_infants_nodate,
	abstract = {Purpose
      This study aims to examine the development of auditory selective attention to speech
         in noise by examining the ability of infants to prefer child-directed speech (CDS)
         over time-reversed speech (TRS) presented in ``on-channel'' and ``off-channel'' noise.
      
      Method
      A total of 32 infants participated in the study. Sixteen typically developing infants
         were tested at 7 and 11 months of age using the central fixation procedure with CDS
         and TRS in two types of noise at +10 dB signal-to-noise ratio. One type of noise was
         an ``on-channel'' masker with a spectrum overlapping that of the CDS (energetic masking),
         and the second was an ``off-channel'' masker with frequencies that were outside the
         spectrum of the CDS (distractive masking). An additional group of sixteen 11-month-old
         infants were tested in quiet and served as controls for the ``off-frequency'' masker
         condition.
      
      Results
      Infants preferred CDS over TRS in both age groups, but this preference was more pronounced
         with ``off-channel'' masker regardless of age. Also, older infants demonstrated longer
         looking time for the target stimuli when presented with an ``off-channel'' masker compared
         to the ``on-channel'' masker. Looking time in quiet was similar to looking time in the
         ``off-channel'' condition, and looking time for CDS was longer in quiet compared to
         the ``on-channel'' condition.
      
      Conclusions
      These findings support the notion that (a) infants as young as 7 months of age are
         already showing preference for speech in noise, regardless of type of masker; (b)
         by 11 months of age, listening with the ``off-channel'' condition did not yield different
         results than in quiet. Thus, by 11 months of age, infants' cognitive--attentional abilities
         may be more developed.},
	author = {{Segal Osnat} and {Kligler Nitzan} and {Kishon-Rabin Liat}},
	doi = {10.1044/2021_JSLHR-20-00279},
	file = {Snapshot:/Users/Cecile/Zotero/storage/ID2G6LHS/2021_JSLHR-20-00279.html:text/html},
	journal = {Journal of Speech, Language, and Hearing Research},
	note = {Publisher: American Speech-Language-Hearing Association},
	title = {Infants' {Preference} for {Child}-{Directed} {Speech} {Over} {Time}-{Reversed} {Speech} in {On}-{Channel} and {Off}-{Channel} {Masking}},
	url = {https://pubs.asha.org/doi/10.1044/2021_JSLHR-20-00279},
	urldate = {2021-07-01},
	bdsk-url-1 = {https://pubs.asha.org/doi/10.1044/2021_JSLHR-20-00279},
	bdsk-url-2 = {https://doi.org/10.1044/2021_JSLHR-20-00279}}

@article{toda_early_2021,
	abstract = {{\textless}p{\textgreater}Early events in the evolutionary history of a clade can shape the sensory systems of descendant lineages. Although the avian ancestor may not have had a sweet receptor, the widespread incidence of nectar-feeding birds suggests multiple acquisitions of sugar detection. In this study, we identify a single early sensory shift of the umami receptor (the T1R1-T1R3 heterodimer) that conferred sweet-sensing abilities in songbirds, a large evolutionary radiation containing nearly half of all living birds. We demonstrate sugar responses across species with diverse diets, uncover critical sites underlying carbohydrate detection, and identify the molecular basis of sensory convergence between songbirds and nectar-specialist hummingbirds. This early shift shaped the sensory biology of an entire radiation, emphasizing the role of contingency and providing an example of the genetic basis of convergence in avian evolution.{\textless}/p{\textgreater}},
	author = {Toda, Yasuka and Ko, Meng-Ching and Liang, Qiaoyi and Miller, Eliot T. and Rico-Guevara, Alejandro and Nakagita, Tomoya and Sakakibara, Ayano and Uemura, Kana and Sackton, Timothy and Hayakawa, Takashi and Sin, Simon Yung Wa and Ishimaru, Yoshiro and Misaka, Takumi and Oteiza, Pablo and Crall, James and Edwards, Scott V. and Buttemer, William and Matsumura, Shuichi and Baldwin, Maude W.},
	copyright = {Copyright {\copyright} 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. https://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	doi = {10.1126/science.abf6505},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/97G6WGHE/Toda et al. - 2021 - Early origin of sweet perception in the songbird r.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZM47KFSH/226.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = jul,
	note = {Publisher: American Association for the Advancement of Science Section: Report},
	number = {6551},
	pages = {226--231},
	title = {Early origin of sweet perception in the songbird radiation},
	url = {https://science.sciencemag.org/content/373/6551/226},
	urldate = {2021-07-08},
	volume = {373},
	year = {2021},
	bdsk-url-1 = {https://science.sciencemag.org/content/373/6551/226},
	bdsk-url-2 = {https://doi.org/10.1126/science.abf6505}}

@article{mori_recurrent_2018,
	abstract = {Complex learned behaviors, like bird song and human speech, develop under the influence of both genetic and environmental factors. Accordingly, learned behaviors comprise species specificity and individual variability. Auditory information plays a critical role in vocal learning by songbirds, both to memorize tutor songs and to monitor own vocalizations. Nevertheless, audition-deprived songbirds develop structured, species-specific song patterns. It remains to be elucidated how the auditory input contributes to the development of individual variability of song characteristics. Here we show that an open-ended vocal learner, the canary, annually recapitulates individually unique songs without audition. Although the total number of syllable types was reduced by auditory deprivation, other vocal phenotypes examined in the syllable, phrase, and syntax of songs were conserved between the 1st and 2nd years, both in deafened and intact birds. In deafened canaries, approximately 60\% of the syllables were yearly reproduced with consistent acoustic features, whereas the remaining syllables were replaced with new ones in an annual cycle of song development. These results indicate that the open-ended vocal learning of canaries involves an audition-independent mechanism for the development of recurrent song idiosyncrasy.},
	author = {Mori, Chihiro and Liu, Wan-chun and Wada, Kazuhiro},
	copyright = {2018 The Author(s)},
	doi = {10.1038/s41598-018-27046-4},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/A2SY69KG/Mori et al. - 2018 - Recurrent development of song idiosyncrasy without.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8ID4YFPZ/s41598-018-27046-4.html:text/html},
	issn = {2045-2322},
	journal = {Scientific Reports},
	language = {en},
	month = jun,
	note = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Number: 1 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Animal behaviour;Birdsong Subject\_term\_id: animal-behaviour;birdsong},
	number = {1},
	pages = {8732},
	title = {Recurrent development of song idiosyncrasy without auditory inputs in the canary, an open-ended vocal learner},
	url = {https://www.nature.com/articles/s41598-018-27046-4},
	urldate = {2021-07-11},
	volume = {8},
	year = {2018},
	bdsk-url-1 = {https://www.nature.com/articles/s41598-018-27046-4},
	bdsk-url-2 = {https://doi.org/10.1038/s41598-018-27046-4}}

@article{gardner_freedom_2005,
	abstract = {Canary song is hierarchically structured: Short stereotyped syllables are repeated to form phrases, which in turn are arranged to form songs. This structure occurs even in the songs of young isolates, which suggests that innate rules govern canary song development. However, juveniles that had never heard normal song imitated abnormal synthetic songs with great accuracy, even when the tutor songs lacked phrasing. As the birds matured, imitated songs were reprogrammed to form typical canary phrasing. Thus, imitation and innate song constraints are separate processes that can be segregated in time: freedom in youth, rules in adulthood.
Young canaries easily learn a synthetic song, but later adapt it to fit the phrasing and restricted vocabulary typical of adult canaries.
Young canaries easily learn a synthetic song, but later adapt it to fit the phrasing and restricted vocabulary typical of adult canaries.},
	author = {Gardner, Timothy J. and Naef, Felix and Nottebohm, Fernando},
	copyright = {American Association for the Advancement of Science},
	doi = {10.1126/science.1108214},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/HW2VAI8W/Gardner et al. - 2005 - Freedom and Rules The Acquisition and Reprogrammi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TRTVP9WW/1046.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = may,
	note = {Publisher: American Association for the Advancement of Science Section: Report},
	number = {5724},
	pages = {1046--1049},
	pmid = {15890887},
	shorttitle = {Freedom and {Rules}},
	title = {Freedom and {Rules}: {The} {Acquisition} and {Reprogramming} of a {Bird}'s {Learned} {Song}},
	url = {https://science.sciencemag.org/content/308/5724/1046},
	urldate = {2021-07-11},
	volume = {308},
	year = {2005},
	bdsk-url-1 = {https://science.sciencemag.org/content/308/5724/1046},
	bdsk-url-2 = {https://doi.org/10.1126/science.1108214}}

@article{dubois_dynamics_2019,
	abstract = {In the human brain, the appearance of cortical sulci is a complex process that takes place mostly during the second half of pregnancy, with a relatively stable temporal sequence across individuals. Since deviant gyrification patterns have been observed in many neurodevelopmental disorders, mapping cortical development in vivo from the early stages on is an essential step to uncover new markers for diagnosis or prognosis. Recently this has been made possible by MRI combined with post-processing tools, but the reported results are still fragmented. Here we aimed to characterize the typical folding progression ex utero from the pre- to the post-term period, by considering 58 healthy preterm and full-term newborns and infants imaged between 27 and 62 weeks of post-menstrual age. Using a method of spectral analysis of gyrification (SPANGY), we detailed the spatial-frequency structure of cortical patterns in a quantitative way. The modeling of developmental trajectories revealed three successive waves that might correspond to primary, secondary and tertiary folding. Some deviations were further detected in 10 premature infants without apparent neurological impairment and imaged at term equivalent age, suggesting that our approach is sensitive enough to highlight the subtle impact of preterm birth and extra-uterine life on folding.},
	author = {Dubois, Jessica and Lef{\`e}vre, Julien and Angleys, Hugo and Leroy, Fran{\c c}ois and Fischer, Clara and Lebenberg, Jessica and Dehaene-Lambertz, Ghislaine and Borradori-Tolsa, Cristina and Lazeyras, Fran{\c c}ois and Hertz-Pannier, Lucie and Mangin, Jean-Fran{\c c}ois and H{\"u}ppi, Petra S. and Germanaud, David},
	doi = {10.1016/j.neuroimage.2018.03.005},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QYSER7J9/Dubois et al. - 2019 - The dynamics of cortical folding waves and prematu.pdf:application/pdf},
	issn = {1053-8119},
	journal = {NeuroImage},
	keywords = {Cortex, Development, Magnetic resonance imaging (MRI), Prematurity, Sulcation},
	language = {en},
	month = jan,
	pages = {934--946},
	title = {The dynamics of cortical folding waves and prematurity-related deviations revealed by spatial and spectral analysis of gyrification},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918301903},
	urldate = {2021-08-03},
	volume = {185},
	year = {2019},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811918301903},
	bdsk-url-2 = {https://doi.org/10.1016/j.neuroimage.2018.03.005}}

@article{lobato_mismatch_2015,
	abstract = {Brain song control regions of adult passerine birds are sexually dimorphic in species such as the zebra finch (Taeniopygia guttata) in which males sing whereas females do not. In many tropical bird species, however, females sing as well. Here we study for the first time the ontogeny of the song control system and the song in a species, in which both male and female sing regularly. In blue-capped cordon-bleus (Uraeginthus cyanocephalus), a distant relative of the zebra finch, both males and females start singing at around 30-40 day post-hatching (dph). First we quantified that sex-specific differences in song features emerged only in adulthood, after 250 dph of age: Adult females sang complex songs, which were slightly shorter and contained fewer syllables as compared to the males. Second, the development of forebrain song control regions HVC (proper name) and RA (nucleus robustus arcopallii) of blue-capped cordon-bleus was quantified in both sexes at 20, 30, 50, 100, 150, 250 dph as well as in old adults. The volume and neuron numbers of the HVC and RA were sexually dimorphic throughout the entire development and remained sexually dimorphic in adulthood. Since singing developed in a non sex-specific way until 250 dph, neural sex differences to a large extend precede the behavioral (song) sex differences. This suggests that these neuroanatomical sex differences are not causally related to the sexual differentiation of song patterns in this species.},
	author = {Lobato, Muriele and Vellema, Michiel and Gahr, Christoph and Leit{\~a}o, Albertine and de Lima, Silene M. A. and Geberzahn, Nicole and Gahr, Manfred},
	doi = {10.3389/fevo.2015.00117},
	file = {Full Text:/Users/Cecile/Zotero/storage/MU4L7WVW/Lobato et al. - 2015 - Mismatch in sexual dimorphism of developing song a.pdf:application/pdf},
	issn = {2296-701X},
	journal = {Frontiers in Ecology and Evolution},
	keywords = {female songbird, male songbird, sexual dimorphism, song development, song system},
	language = {English},
	note = {Publisher: Frontiers},
	title = {Mismatch in sexual dimorphism of developing song and song control system in blue-capped cordon-bleus, a songbird species with singing females and males},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2015.00117/full},
	urldate = {2021-07-19},
	volume = {0},
	year = {2015},
	bdsk-url-1 = {https://www.frontiersin.org/articles/10.3389/fevo.2015.00117/full},
	bdsk-url-2 = {https://doi.org/10.3389/fevo.2015.00117}}

@article{odom_female_2014,
	abstract = {Bird song has historically been considered an almost exclusively male trait, an observation fundamental to the formulation of Darwin's theory of sexual selection. Like other male ornaments, song is used by male songbirds to attract females and compete with rivals. Thus, bird song has become a textbook example of the power of sexual selection to lead to extreme neurological and behavioural sex differences. Here we present an extensive survey and ancestral state reconstruction of female song across songbirds showing that female song is present in 71\% of surveyed species including 32 families, and that females sang in the common ancestor of modern songbirds. Our results reverse classical assumptions about the evolution of song and sex differences in birds. The challenge now is to identify whether sexual selection alone or broader processes, such as social or natural selection, best explain the evolution of elaborate traits in both sexes.},
	author = {Odom, Karan J. and Hall, Michelle L. and Riebel, Katharina and Omland, Kevin E. and Langmore, Naomi E.},
	copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/ncomms4379},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/387234TW/Odom et al. - 2014 - Female song is widespread and ancestral in songbir.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GWWKQZGN/ncomms4379.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	language = {en},
	month = mar,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 1 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Sexual selection Subject\_term\_id: sexual-selection},
	number = {1},
	pages = {3379},
	title = {Female song is widespread and ancestral in songbirds},
	url = {https://www.nature.com/articles/ncomms4379},
	urldate = {2021-07-19},
	volume = {5},
	year = {2014},
	bdsk-url-1 = {https://www.nature.com/articles/ncomms4379},
	bdsk-url-2 = {https://doi.org/10.1038/ncomms4379}}

@article{segal_infants_2021,
	abstract = {Purpose: This study aims to examine the development of auditory selective attention to speech in noise by examining the ability of infants to prefer child-directed speech (CDS) over time-reversed speech (TRS) presented in "on-channel" and "off-channel" noise. Method: A total of 32 infants participated in the study. Sixteen typically developing infants were tested at 7 and 11 months of age using the central fixation procedure with CDS and TRS in two types of noise at +10 dB signal-to-noise ratio. One type of noise was an "on-channel" masker with a spectrum overlapping that of the CDS (energetic masking), and the second was an "off-channel" masker with frequencies that were outside the spectrum of the CDS (distractive masking). An additional group of sixteen 11-month-old infants were tested in quiet and served as controls for the "off-frequency" masker condition. Results: Infants preferred CDS over TRS in both age groups, but this preference was more pronounced with "off-channel" masker regardless of age. Also, older infants demonstrated longer looking time for the target stimuli when presented with an "off-channel" masker compared to the "on-channel" masker. Looking time in quiet was similar to looking time in the "off-channel" condition, and looking time for CDS was longer in quiet compared to the "on-channel" condition. Conclusions: Thesefindingssupportthenotionthat (a) infants as young as 7 months of age are already showing preference for speech in noise, regardless of type of masker; (b) by 11 months of age, listening with the "off-channel" condition did not yield different results than in quiet. Thus, by 11 months of age, infants' cognitive--attentional abilities may be more developed.},
	annote = {*},
	author = {Segal, Osnat and Kligler, Nitzan and Kishon-Rabin, Liat},
	date-modified = {2022-04-05 16:57:00 +0200},
	doi = {10.1044/2021_JSLHR-20-00279},
	file = {EBSCO Full Text:/Users/Cecile/Zotero/storage/7HSY4KCF/Segal et al. - 2021 - Infants' Preference for Child-Directed Speech Over.pdf:application/pdf},
	issn = {10924388},
	journal = {Journal of Speech, Language \& Hearing Research},
	keywords = {ANALYSIS of variance, AUDITORY perception, CHILDREN, COGNITION, COMPARATIVE studies, DATA analysis software, DESCRIPTIVE statistics, LANGUAGE acquisition, MEAN length of utterance, NOISE, PAIRED comparisons (Mathematics), QUESTIONNAIRES, REPEATED measures design, SPEECH, TEACHING methods},
	month = jul,
	note = {Publisher: American Speech-Language-Hearing Association},
	number = {7},
	pages = {2897--2908},
	title = {Infants' {Preference} for {Child}-{Directed} {Speech} {Over} {Time}-{Reversed} {Speech} in {On}-{Channel} and {Off}-{Channel} {Masking}},
	url = {https://ezproxy.cul.columbia.edu/login?qurl=https%3a%2f%2fsearch.ebscohost.com%2flogin.aspx%3fdirect%3dtrue%26db%3da2h%26AN%3d151481535%26site%3dehost-live%26scope%3dsite},
	urldate = {2021-08-05},
	volume = {64},
	year = {2021},
	bdsk-url-1 = {https://ezproxy.cul.columbia.edu/login?qurl=https%3a%2f%2fsearch.ebscohost.com%2flogin.aspx%3fdirect%3dtrue%26db%3da2h%26AN%3d151481535%26site%3dehost-live%26scope%3dsite},
	bdsk-url-2 = {https://doi.org/10.1044/2021_JSLHR-20-00279}}

@article{mets_automated_2018,
	abstract = {Studies of learning mechanisms critically depend on the ability to accurately assess learning outcomes. This assessment can be impeded by the often complex, multidimensional nature of behavior. We present a novel, automated approach to evaluating imitative learning. Conceptually, our approach estimates how much of the content present in a reference behavior is absent from the learned behavior. We validate our approach through examination of songbird vocalizations, complex learned behaviors the study of which has provided many insights into sensory-motor learning in general and vocal learning in particular. Historically, learning has been holistically assessed by human inspection or through comparison of specific song features selected by experimenters (e.g. fundamental frequency, spectral entropy). In contrast, our approach uses statistical models to broadly capture the structure of each song, and then estimates the divergence between the two models. We show that our measure of song learning (the Kullback-Leibler divergence between two distributions corresponding to specific song data, or, Song DKL) is well correlated with human evaluation of song learning. We then expand the analysis beyond learning and show that Song DKL also detects the typical song deterioration that occurs following deafening. Finally, we illustrate how this measure can be extended to quantify differences in other complex behaviors such as human speech and handwriting. This approach potentially provides a framework for assessing learning across a broad range of behaviors like song that can be described as a set of discrete and repeated motor actions.},
	author = {Mets, David G. and Brainard, Michael S.},
	doi = {10.1371/journal.pcbi.1006437},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/I7S4QPET/Mets et Brainard - 2018 - An automated approach to the quantitation of vocal.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CBI3CCGS/article.html:text/html},
	issn = {1553-7358},
	journal = {PLOS Computational Biology},
	keywords = {Learning, Syllables, Speech, Human learning, Vocalization, Bird song, Birds, Statistical models},
	language = {en},
	month = aug,
	note = {Publisher: Public Library of Science},
	number = {8},
	pages = {e1006437},
	title = {An automated approach to the quantitation of vocalizations and vocal learning in the songbird},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006437},
	urldate = {2021-08-12},
	volume = {14},
	year = {2018},
	bdsk-url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006437},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pcbi.1006437}}

@article{feher_novo_2009,
	abstract = {We tend to think of culture --- in humans and in other animals --- as something that is passed on through social learning. But the species-typical nature of some aspects of cultural diversity, and variations between individuals of a particular species, point to possible genetic origins. Feh{\'e}r et al. explored this latter point by analysing the establishment of socially learned birdsong in an island colony of naive zebra finches. Although the original founding members of the colony were never exposed to tutored birdsong during development, and exhibited a song that differed markedly from wild-type, in as few as three or four generations, the tutored song approached that of the wild-type. These findings suggest that species-specific song culture can develop de novo, and echo the well known instance of de novo evolution of Nicaraguan sign language, spontaneously developed by deaf children in Managua, showing grammatical similarities to spoken human languages.},
	author = {Feh{\'e}r, Olga and Wang, Haibin and Saar, Sigal and Mitra, Partha P. and Tchernichovski, Ofer},
	copyright = {2009 Macmillan Publishers Limited. All rights reserved},
	doi = {10.1038/nature07994},
	file = {Snapshot:/Users/Cecile/Zotero/storage/4MPYY9WW/nature07994.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/HLCH3HUT/Feh{\'e}r et al. - 2009 - De novo establishment of wild-type song culture in.pdf:application/pdf},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = may,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 7246 Primary\_atype: Research Publisher: Nature Publishing Group},
	number = {7246},
	pages = {564--568},
	title = {De novo establishment of wild-type song culture in the zebra finch},
	url = {https://www.nature.com/articles/nature07994},
	urldate = {2021-08-12},
	volume = {459},
	year = {2009},
	bdsk-url-1 = {https://www.nature.com/articles/nature07994},
	bdsk-url-2 = {https://doi.org/10.1038/nature07994}}

@article{noauthor_building_2018,
	abstract = {The songbird system has shed light on how the brain produces precisely timed behavioral sequences, and how the brain implements reinforcement learning{\ldots}},
	doi = {10.1016/j.conb.2017.12.001},
	file = {Snapshot:/Users/Cecile/Zotero/storage/TFXR8MYM/S0959438817302349.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	language = {en},
	month = apr,
	note = {Publisher: Elsevier Current Trends},
	pages = {59--68},
	title = {Building a state space for song learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438817302349},
	urldate = {2021-08-25},
	volume = {49},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0959438817302349},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2017.12.001}}

@article{mackevicius_building_2018,
	abstract = {The songbird system has shed light on how the brain produces precisely timed behavioral sequences, and how the brain implements reinforcement learning (RL). RL is a powerful strategy for learning what action to produce in each state, but requires a unique representation of the states involved in the task. Songbird RL circuitry is thought to operate using a representation of each moment within song syllables, consistent with the sparse sequential bursting of neurons in premotor cortical nucleus HVC. However, such sparse sequences are not present in very young birds, which sing highly variable syllables of random lengths. Here, we review and expand upon a model for how the songbird brain could construct latent sequences to support RL, in light of new data elucidating connections between HVC and auditory cortical areas. We hypothesize that learning occurs via four distinct plasticity processes: 1) formation of `tutor memory' sequences in auditory areas; 2) formation of appropriately-timed latent HVC sequences, seeded by inputs from auditory areas spontaneously replaying the tutor song; 3) strengthening, during spontaneous replay, of connections from HVC to auditory neurons of corresponding timing in the `tutor memory' sequence, aligning auditory and motor representations for subsequent song evaluation; and 4) strengthening of connections from premotor neurons to motor output neurons that produce the desired sounds, via well-described song RL circuitry.},
	author = {Mackevicius, Emily Lambert and Fee, Michale Sean},
	doi = {10.1016/j.conb.2017.12.001},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/H4FE7GSD/Mackevicius et Fee - 2018 - Building a state space for song learning.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MMTGPHHU/S0959438817302349.html:text/html},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	language = {en},
	month = apr,
	pages = {59--68},
	series = {Neurobiology of {Behavior}},
	title = {Building a state space for song learning},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438817302349},
	urldate = {2021-08-25},
	volume = {49},
	year = {2018},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0959438817302349},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2017.12.001}}

@article{fernandez_babbling_2021,
	abstract = {Babbling bats
A notable aspect of language development in humans is the babbling stage. During this time, toddlers make a range of specific sounds as they practice and imitate adult speech. Humans are not the only vocal learners, however, so might we expect such babbling among others? Fernandez et al. recorded the vocalizations of sac-winged bat pups in the wild and found clear evidence of babbling that was consistent with that seen in humans. The shared babbling components suggest that vocal learning may have similar specific mechanisms across a wide array of mammalian species.
Science, abf9279, this issue p. 923
Babbling is a production milestone in infant speech development. Evidence for babbling in nonhuman mammals is scarce, which has prevented cross-species comparisons. In this study, we investigated the conspicuous babbling behavior of Saccopteryx bilineata, a bat capable of vocal production learning. We analyzed the babbling of 20 bat pups in the field during their 3-month ontogeny and compared its features to those that characterize babbling in human infants. Our findings demonstrate that babbling in bat pups is characterized by the same eight features as babbling in human infants, including the conspicuous features reduplication and rhythmicity. These parallels in vocal ontogeny between two mammalian species offer future possibilities for comparison of cognitive and neuromolecular mechanisms and adaptive functions of babbling in bats and humans.
Young Saccopteryx bilineata bat pups babble as they learn to vocalize, with similar features to those that define babbling in human infants.
Young Saccopteryx bilineata bat pups babble as they learn to vocalize, with similar features to those that define babbling in human infants.},
	author = {Fernandez, Ahana A. and Burchardt, Lara S. and Nagy, Martina and Kn{\"o}rnschild, Mirjam},
	copyright = {Copyright {\copyright} 2021 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. https://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	doi = {10.1126/science.abf9279},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/RGBK5NQ2/Fernandez et al. - 2021 - Babbling in a vocal learning bat resembles human i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/44AYFGJ9/923.html:text/html},
	issn = {0036-8075, 1095-9203},
	journal = {Science},
	language = {en},
	month = aug,
	note = {Publisher: American Association for the Advancement of Science Section: Report},
	number = {6557},
	pages = {923--926},
	pmid = {34413237},
	title = {Babbling in a vocal learning bat resembles human infant babbling},
	url = {https://science.sciencemag.org/content/373/6557/923},
	urldate = {2021-08-25},
	volume = {373},
	year = {2021},
	bdsk-url-1 = {https://science.sciencemag.org/content/373/6557/923},
	bdsk-url-2 = {https://doi.org/10.1126/science.abf9279}}

@article{roberts_identification_2017,
	abstract = {Although vocal learning is widely speculated to depend on motor to auditory (i.e., forward) pathways, the neurons that convey forward signals important to vocal learning remain unknown. Here the authors identify neurons that transmit signals from songbird motor to auditory regions and demonstrate their role in vocal learning.},
	author = {Roberts, Todd F. and Hisey, Erin and Tanaka, Masashi and Kearney, Matthew G. and Chattree, Gaurav and Yang, Cindy F. and Shah, Nirao M. and Mooney, Richard},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nn.4563},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PA8S7K2F/Roberts et al. - 2017 - Identification of a motor-to-auditory pathway impo.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XVV22W4P/nn.html:text/html},
	issn = {1546-1726},
	journal = {Nature Neuroscience},
	language = {en},
	month = jul,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 7 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Birdsong;Neural circuits Subject\_term\_id: birdsong;neural-circuit},
	number = {7},
	pages = {978--986},
	title = {Identification of a motor-to-auditory pathway important for vocal learning},
	url = {https://www.nature.com/articles/nn.4563},
	urldate = {2021-08-25},
	volume = {20},
	year = {2017},
	bdsk-url-1 = {https://www.nature.com/articles/nn.4563},
	bdsk-url-2 = {https://doi.org/10.1038/nn.4563}}

@article{bauer_synaptic_2008-1,
	abstract = {Songbirds learn to sing by memorizing a tutor song that they then vocally mimic using auditory feedback. This developmental sequence suggests that brain areas that encode auditory memories communicate with brain areas for learned vocal control. In the songbird, the secondary auditory telencephalic region caudal mesopallium (CM) contains neurons that encode aspects of auditory experience. We investigated whether CM is an important source of auditory input to two sensorimotor structures implicated in singing, the telencephalic song nucleus interface (NIf) and HVC. We used reversible inactivation methods to show that activity in CM is necessary for much of the auditory-evoked activity that can be detected in NIf and HVC of anesthetized adult male zebra finches. Furthermore, extracellular and intracellular recordings along with spike-triggered averaging methods indicate that auditory selectivity for the bird's own song is enhanced between CM and NIf. We used lentiviral-mediated tracing methods to confirm that CM neurons directly innervate NIf. To our surprise, these tracing studies also revealed a direct projection from CM to HVC. We combined irreversible lesions of NIf with reversible inactivation of CM to establish that CM supplies a direct source of auditory drive to HVC. Finally, using chronic recording methods, we found that CM neurons are active in response to song playback and during singing, indicating their potential importance to song perception and processing of auditory feedback. These results establish the functional synaptic linkage between sites of auditory and vocal learning and may identify an important substrate for learned vocal communication.},
	author = {Bauer, Eric E. and Coleman, Melissa J. and Roberts, Todd F. and Roy, Arani and Prather, Jonathan F. and Mooney, Richard},
	copyright = {Copyright {\copyright} 2008 Society for Neuroscience 0270-6474/08/281509-14\$15.00/0},
	doi = {10.1523/JNEUROSCI.3838-07.2008},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DHQ2SFY6/Bauer et al. - 2008 - A Synaptic Basis for Auditory--Vocal Integration in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JN6T549A/1509.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {auditory, zebra finch, song, HVC, CM, learning, vocal},
	language = {en},
	month = feb,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {6},
	pages = {1509--1522},
	pmid = {18256272},
	title = {A {Synaptic} {Basis} for {Auditory}--{Vocal} {Integration} in the {Songbird}},
	url = {https://www.jneurosci.org/content/28/6/1509},
	urldate = {2021-08-25},
	volume = {28},
	year = {2008},
	bdsk-url-1 = {https://www.jneurosci.org/content/28/6/1509},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.3838-07.2008}}

@article{akutagawa_new_2010,
	abstract = {Songbirds use a complex network of discrete brain areas and connecting fiber tracts to sing their song, but our knowledge of this circuitry may be incomplete. The forebrain area, ``caudal mesopallium'' (CM), has received much attention recently for its song-related activities. HVC, a prominent song system nucleus, projects to a restricted area of the CM known as the avalanche nucleus (Av). However, the other connections of Av remain unknown. Here we used tract-tracing methods to examine the connections of Av to other song system nuclei. Injections of biotinylated dextran amine (BDA) into Av labeled both afferent terminals and neurons in HVC and the interfacial nucleus of the nidopallium (NIf), suggesting that there is complex feedforward and feedback communication between these nuclei (HVC↔Av↔NIf). Labeled neurons were also found in the uvaeform nucleus (Uva), which was substantiated by BDA injections into Uva that labeled terminals in Av. Double fluorescent tracing experiments confirm that both HVC and Uva project to Av. The present study adds complex new connections that expand the traditional song system circuitry into the caudal mesopallium. These new pathways are likely to have broad implications for deciphering how this intricate system works. J. Comp. Neurol. 518:3086--3100, 2010. {\copyright} 2010 Wiley-Liss, Inc.},
	author = {Akutagawa, Eugene and Konishi, Masakazu},
	doi = {10.1002/cne.22383},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/WDGYFUP2/Akutagawa et Konishi - 2010 - New brain pathways found in the vocal control syst.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DPHAG3FF/cne.html:text/html},
	issn = {1096-9861},
	journal = {Journal of Comparative Neurology},
	keywords = {complexity, feedback, mesopallium, networks},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.22383},
	number = {15},
	pages = {3086--3100},
	title = {New brain pathways found in the vocal control system of a songbird},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.22383},
	urldate = {2021-08-25},
	volume = {518},
	year = {2010},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.22383},
	bdsk-url-2 = {https://doi.org/10.1002/cne.22383}}

@article{benichov_forebrain_2016,
	abstract = {The dichotomy between vocal learners and non-learners is a fundamental distinction in the study of animal communication. Male zebra finches (Taeniopygia guttata) are vocal learners that acquire a song resembling their tutors', whereas females can only produce innate calls. The acoustic structure of short calls, produced by both males and females, is not learned. However, these calls can be precisely coordinated across individuals. To examine how birds learn to synchronize their calls, we developed a vocal robot that exchanges calls with a partner bird. Because birds answer the robot with stereotyped latencies, we could program it to disrupt each bird's responses by producing calls that are likely to coincide with the bird's. Within minutes, the birds learned to avoid this disruptive masking (jamming) by adjusting the timing of their responses. Notably, females exhibited greater adaptive timing plasticity than males. Further, when challenged with complex rhythms containing jamming elements, birds dynamically adjusted the timing of their calls in anticipation of jamming. Blocking the song system cortical output dramatically reduced the precision of birds' response timing and abolished their ability to avoid jamming. Surprisingly, we observed this effect in both males and females, indicating that the female song system is functional rather than vestigial. We suggest that descending forebrain projections, including the song-production pathway, function as a general-purpose sensorimotor communication system. In the case of calls, it enables plasticity in vocal timing to facilitate social interactions, whereas in the case of songs, plasticity extends to developmental changes in vocal structure.},
	author = {Benichov, Jonathan I. and Benezra, Sam E. and Vallentin, Daniela and Globerson, Eitan and Long, Michael A. and Tchernichovski, Ofer},
	doi = {10.1016/j.cub.2015.12.037},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2ZJ374QW/S0960982215015687.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/2I7EMUCE/Benichov et al. - 2016 - The Forebrain Song System Mediates Predictive Call.pdf:application/pdf},
	issn = {0960-9822},
	journal = {Current Biology},
	language = {en},
	month = feb,
	number = {3},
	pages = {309--318},
	title = {The {Forebrain} {Song} {System} {Mediates} {Predictive} {Call} {Timing} in {Female} and {Male} {Zebra} {Finches}},
	url = {https://www.sciencedirect.com/science/article/pii/S0960982215015687},
	urldate = {2021-09-04},
	volume = {26},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0960982215015687},
	bdsk-url-2 = {https://doi.org/10.1016/j.cub.2015.12.037}}

@article{shaughnessy_female_2019,
	abstract = {Adult female zebra finches (Taeniopygia guttata), which do not produce learned songs, have long been thought to possess only vestiges of the forebrain network that supports learned song in males. This view ostensibly explains why females do not sing---many of the neural populations and pathways that make up the male song control network appear rudimentary or even missing in females. For example, classic studies of vocal-premotor cortex (HVC, acronym is name) in male zebra finches identified prominent efferent pathways from HVC to vocal-motor cortex (RA, robust nucleus of the arcopallium) and from HVC to the avian basal ganglia (Area X). In females, by comparison, the efferent targets of HVC were thought to be only partially innervated by HVC axons (RA) or absent (Area X). Here, using a novel visually guided surgical approach to target tracer injections with precision, we mapped the extrinsic connectivity of the adult female HVC. We find that female HVC shows a mostly male-typical pattern of afferent and efferent connectivity, including robust HVC innervation of RA and Area X. As noted by earlier investigators, we find large sex differences in the volume of many regions that control male singing (male {\textgreater} female). However, sex differences in volume were diminished in regions that convey ascending afferent input to HVC. Our findings do not support a vestigial interpretation of the song control network in females. Instead, our findings support the emerging view that the song control network may have an altogether different function in nonsinging females.},
	author = {Shaughnessy, Derrick W. and Hyson, Richard L. and Bertram, Richard and Wu, Wei and Johnson, Frank},
	doi = {10.1002/cne.24569},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7BIHGSSN/Shaughnessy et al. - 2019 - Female zebra finches do not sing yet share neural .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5NXDJX77/cne.html:text/html},
	issn = {1096-9861},
	journal = {Journal of Comparative Neurology},
	keywords = {zebra finch, premotor cortex, RRID:SCR\_001775, RRID:SCR\_002798, sex difference, vocal learning},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cne.24569},
	number = {4},
	pages = {843--855},
	title = {Female zebra finches do not sing yet share neural pathways necessary for singing in males},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.24569},
	urldate = {2021-09-04},
	volume = {527},
	year = {2019},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.24569},
	bdsk-url-2 = {https://doi.org/10.1002/cne.24569}}

@article{colombo_method_1981,
	annote = {*},
	author = {Colombo, John and Bundy, Robert S.},
	date-modified = {2022-04-05 16:52:16 +0200},
	doi = {10.1016/S0163-6383(81)80025-2},
	file = {Colombo et Bundy - 1981 - A method for the measurement of infant auditory se.pdf:/Users/Cecile/Zotero/storage/UXPS426N/Colombo et Bundy - 1981 - A method for the measurement of infant auditory se.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JTQFMQ5X/Colombo et Bundy - 1981 - A method for the measurement of infant auditory se.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KAIVD9M2/S0163638381800252.html:text/html},
	issn = {01636383},
	journal = {Infant Behavior and Development},
	language = {en},
	month = mar,
	pages = {219--223},
	title = {A method for the measurement of infant auditory selectivity},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0163638381800252},
	urldate = {2021-09-06},
	volume = {4},
	year = {1981},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0163638381800252},
	bdsk-url-2 = {https://doi.org/10.1016/S0163-6383(81)80025-2}}

@article{yamashiro_does_2020,
	abstract = {Human infants show a robust preference for speech over many other sounds, helping them learn language and interact with others. Lacking a preference for speech may underlie some language and social-pragmatic difficulties in children with ASD. But, it's unclear how an early speech preference supports later language and social-pragmatic abilities. We show that across infants displaying and not displaying later ASD symptoms, a greater speech preference at 9 months is related to increased attention to a person when they speak at 12 months, and better expressive language at 24 months, but is not related to later social-pragmatic attention or outcomes. Understanding how an early speech preference supports language outcomes could inform targeted and individualized interventions for children with ASD.},
	annote = {*},
	author = {Yamashiro, Amy and Curtin, Suzanne and Vouloumanos, Athena},
	date-modified = {2022-04-05 16:53:54 +0200},
	doi = {10.1007/s10803-019-03924-2},
	file = {Yamashiro et al. - 2020 - Does an Early Speech Preference Predict Linguistic.pdf:/Users/Cecile/Zotero/storage/ABMVBYDM/Yamashiro et al. - 2020 - Does an Early Speech Preference Predict Linguistic.pdf:application/pdf},
	issn = {0162-3257, 1573-3432},
	journal = {Journal of Autism and Developmental Disorders},
	language = {en},
	month = jul,
	number = {7},
	pages = {2475--2490},
	title = {Does an {Early} {Speech} {Preference} {Predict} {Linguistic} and {Social}-{Pragmatic} {Attention} in {Infants} {Displaying} and {Not} {Displaying} {Later} {ASD} {Symptoms}?},
	url = {http://link.springer.com/10.1007/s10803-019-03924-2},
	urldate = {2021-09-06},
	volume = {50},
	year = {2020},
	bdsk-url-1 = {http://link.springer.com/10.1007/s10803-019-03924-2},
	bdsk-url-2 = {https://doi.org/10.1007/s10803-019-03924-2}}

@article{gemignani_comparing_2021,
	abstract = {Functional Near Infrared Spectroscopy (fNIRS) is an important neuroimaging technique in cognitive developmental neuroscience. Nevertheless, there is no general consensus yet about best pre-processing practices. This issue is highly relevant, especially since the development and variability of the infant hemodynamic response (HRF) is not fully known. Systematic comparisons between analysis methods are thus necessary. We investigated the performance of five different pipelines, selected on the basis of a systematic search of the infant NIRS literature, in two experiments. In Experiment 1, we used synthetic data to compare the recovered HRFs with the true HRF and to assess the robustness of each method against increasing levels of noise. In Experiment 2, we analyzed experimental data from a published study, which assessed the neural correlates of artificial grammar processing in newborns. We found that with motion artifact correction (as opposed to rejection) a larger number of trials were retained, but HRF amplitude was often strongly reduced. By contrast, artifact rejection resulted in a high exclusion rate but preserved adequately the characteristics of the HRF. We also found that the performance of all pipelines declined as the noise increased, but significantly less so than if no pre-processing was applied. Finally, we found no difference between running the pre-processing on optical density or concentration change data. These results suggest that pre-processing should thus be optimized as a function of the specific quality issues a give dataset exhibits.},
	author = {Gemignani, Jessica and Gervain, Judit},
	doi = {10.1016/j.dcn.2021.100943},
	file = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PXBESD2X/S1878929321000347.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/VESBA44B/Gemignani et Gervain - 2021 - Comparing different pre-processing routines for in.pdf:application/pdf},
	issn = {1878-9293},
	journal = {Developmental Cognitive Neuroscience},
	keywords = {Infant, fNIRS, Cognitive developmental neuroscience, Pre-processing},
	language = {en},
	month = apr,
	pages = {100943},
	title = {Comparing different pre-processing routines for infant {fNIRS} data},
	url = {https://www.sciencedirect.com/science/article/pii/S1878929321000347},
	urldate = {2021-09-15},
	volume = {48},
	year = {2021},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S1878929321000347},
	bdsk-url-2 = {https://doi.org/10.1016/j.dcn.2021.100943}}

@article{zann_structure_1993,
	abstract = {Songs from 402 Zebra Finches (Taeniopygia guttata castanotis) were sampled in order to describe the structure of the song phrase and the relationship of its elements to the call repertoire. The song of wild birds was also compared to that of 47 domesticated Zebra Finches from two European laboratories in order to examine the effects of domestication on song structure. The stereotyped phrase, which is the repetitive unit of the song, had a mean number of 6.75 elements and a mean duration of 0.86 s in wild birds. Elements were sung in sequence that defined three parts to the phrase-a start, a middle and an end. Fourteen types of elements were identified of which four were sung by the vast majority of males; three of these "primary" elements were "borrowed" unmodified from the call repertoire, and formed the start and end sections of the phrase. "Secondary" elements, which were less frequently represented across males, constituted the middle of the phrase and appeared to be modified versions of the Distance-call Element, the loudest element in the phrase. I tentatively conclude that Zebra Finch song may have evolved from the calls associated with flight intention and take-off. Domestication has led to changes in element morphology, frequency of occurrence, and rate of singing (elements/s), but not in number of elements per phrase.},
	author = {Zann, Richard},
	doi = {10.2307/4088626},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/WTSAR5VQ/Zann - 1993 - Structure, Sequence and Evolution of Song Elements.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IFLY6QFZ/5173425.html:text/html},
	issn = {1938-4254},
	journal = {The Auk},
	month = oct,
	number = {4},
	pages = {702--715},
	title = {Structure, {Sequence} and {Evolution} of {Song} {Elements} in {Wild} {Australian} {Zebra} {Finches}},
	url = {https://doi.org/10.2307/4088626},
	urldate = {2021-09-22},
	volume = {110},
	year = {1993},
	bdsk-url-1 = {https://doi.org/10.2307/4088626}}

@article{williams_changes_1992,
	abstract = {Adult male zebra finches (Taeniopygia guttata), as closed-ended learners, normally crystallize their songs at 90 days of age, and the song remains fixed throughout life (Price, 1979). We show that injuring the tracheosyringeal nerve(s) (each of which innervates the ipsilateral half of the syrinx, the avian vocal organ) results in a short-term deficit in the syllables forming adult male song; this deficit disappears after is nerve regeneration. However, when adult males were followed for a period of several weeks after unilateral tracheosyringeal nerve injury, long-term changes occurred in the temporal patterning of song. Syllables were deleted, remaining portions of the song were linked, and new syllables were added. Syllables with call-like morphology were less likely to be deleted from and more likely to be added to the song. Deletions were most often contiguous chunks of syllables. Changes in the temporal patterning of song occurred during specific periods following nerve injury, were completed within 100 days after nerve transection, and were not dependent upon regeneration of the is nerve. The resulting newly formed song patterns were stable, remaining unchanged up to 1 year later. The ability of adult male zebra finches to make specific types of changes to crystallized song indicates that some form of vocal plasticity remains even after song learning is completed, though this plasticity may be restricted to a subset of song characteristics. The limitations on the types of changes that are possible may reflect how song is centrally organized.},
	author = {Williams, Heather and McKibben, Jessica R.},
	doi = {10.1016/0163-1047(92)90768-Y},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SHXW4WPX/Williams et McKibben - 1992 - Changes in stereotyped central motor patterns cont.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/E36PGYSR/016310479290768Y.html:text/html},
	issn = {0163-1047},
	journal = {Behavioral and Neural Biology},
	language = {en},
	month = jan,
	number = {1},
	pages = {67--78},
	title = {Changes in stereotyped central motor patterns controlling vocalization are induced by peripheral nerve injury},
	url = {https://www.sciencedirect.com/science/article/pii/016310479290768Y},
	urldate = {2021-09-22},
	volume = {57},
	year = {1992},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/016310479290768Y},
	bdsk-url-2 = {https://doi.org/10.1016/0163-1047(92)90768-Y}}

@book{thorpe_bird_1969,
	address = {London},
	annote = {Foreword, by K. Z. Lorenz.--Tonal quality of bird sounds, by P. Marler.--Experimental studies in the ontogeny of avian vocalizations, by M. Konishi and F. Nottebohm.--Song as a reinforcer, by J. G. Stevenson.--Song development in the zebra finch and other Estrildid finches, by K. Immelmann.--The control of avian vocalization by the central nervous system, by J. L. Brown--The effects of testosterone on avian vocalizations, by R. J. Andrew.--Roles of budgerigar vocalization in the integration of breeding behaviour, by B. F. Brockway.--Communication in canary courtship calls, by J. A. Mulligan and K. C. Olsen.--Duetting, by T. Hooker and B. I. Hooker (Lade).--Functions of territorial song in the white-throated sparrow, by J. B. Falls.--Embryonic communication, respiration and the synchronization of hatching, by M. A. Vince.--Functional and ecological aspects of vocalization in weaverbirds, by J. H. Crook.--Vocal characters and avian systematics, by W. E. Lanyon.--Geographic variation in bird vocalizations, by G. Thielcke.--Aspects of the evolution of man's appreciation of bird song, by E. A. Armstrong.--The aesthetic content of bird song, by J. Hall-Craggs},
	editor = {Thorpe, W. H. and Hinde, Robert A.},
	file = {Bird vocalizations\: their relations to current problems in biology and psychology\; essays presented to W. H. Thorpe - CLIO:/Users/Cecile/Zotero/storage/VBCP9NMT/SCSB-10045622.html:text/html},
	isbn = {978-0-521-07409-4},
	keywords = {Vocalization, Birds, Birdsongs},
	publisher = {Cambridge U.P},
	shorttitle = {Bird vocalizations},
	title = {Bird vocalizations: their relations to current problems in biology and psychology; essays presented to {W}. {H}. {Thorpe}},
	year = {1969}}

@article{price_developmental_1979,
	abstract = {Zebra finches (Taeniopygia guttata) possess highly organized species-uniform song structure. The present author explored song determinants by a series of 5 studies in which a total of 85 young Ss were (a) reared in social contact with zebra finch adults, (b) reared in isolation from adult song, (c) deafened early in life, (d) tutored by zebra finch males they could not see, or (e) tutored with sounds other than zebra finch song. The main song determinants appear to be (a) learning, which probably determines song structure accurately for a limited number of generations; (b) inherited neuromotor constraints that specify basic temporal patterning within song; and (c) infusion of developmentally conservative calls and noncall isolate note types into song. Limitations on song development imposed by effector organs are relatively permissive, and the role of inherited auditory specifications (template) is uncertain. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Price, Philip H.},
	doi = {10.1037/h0077553},
	file = {Snapshot:/Users/Cecile/Zotero/storage/ZPPJ4AJI/1980-22754-001.html:text/html},
	issn = {0021-9940},
	journal = {Journal of Comparative and Physiological Psychology},
	keywords = {Lesions, Birds, Animal Development, Animal Environments, Animal Social Behavior, Animal Vocalizations, Sensory Deprivation, Social Isolation},
	note = {Place: US Publisher: American Psychological Association},
	number = {2},
	pages = {260--277},
	title = {Developmental determinants of structure in zebra finch song},
	volume = {93},
	year = {1979},
	bdsk-url-1 = {https://doi.org/10.1037/h0077553}}

@article{price_developmental_nodate,
	author = {Price, Philip H.},
	doi = {10.1037/h0077553},
	file = {Price - Developmental determinants of structure in zebra f.pdf:/Users/Cecile/Zotero/storage/69IB4VQM/Price - Developmental determinants of structure in zebra f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XARJ42LZ/1980-22754-001.html:text/html},
	issn = {0021-9940},
	journal = {Journal of Comparative and Physiological Psychology},
	note = {Publisher: US: American Psychological Association},
	number = {2},
	pages = {260},
	title = {Developmental determinants of structure in zebra finch song.},
	url = {https://psycnet.apa.org/fulltext/1980-22754-001.pdf},
	urldate = {2021-09-22},
	volume = {93},
	bdsk-url-1 = {https://psycnet.apa.org/fulltext/1980-22754-001.pdf},
	bdsk-url-2 = {https://doi.org/10.1037/h0077553}}

@article{williams_models_1990,
	abstract = {Previous research with individually caged breeding pairs of zebra finches, Taenopygia guttata, led to the conclusion that young males imprint upon their fathers at an early age, and model their songs upon their fathers' songs. In this study, an aviary containing 10 breeding paris of zebra finches and two non-breeding males was observed while the offspring were raised to independence. The young remained in the colony until sexual maturity (90 days), when song learning is complete. The songs of young males and their putative fathers were then analysed and compared. The mean number of syllables in the sons' songs was greater than the number in the fathers' songs. Portions of each adult male's song were copied by at least one young male, but sons did not preferentially copy their putative fathers' songs. The majority of the sons copied syllables from at least two of the adult males in the parental population. Two adult males were chosen as song models by a disproportionate number of young males; these two adult males had a greater number of interactions with fledglings and gave a greater amount of parental care to fledglings (including those that were not their own) than did the other adult males in the colony. Young male zebra finches reared in a colonial environment are not restricted to one song model, but may instead make choices about which adult males to copy and, hence, how to represent themselves through their own songs. Likewise, adult males may be able to pass on their songs without successfully reproducing.},
	author = {Williams, Heather},
	doi = {10.1016/S0003-3472(05)80386-0},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/AFKAQ7QJ/Williams - 1990 - Models for song learning in the zebra finch fathe.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/IYVFIZ6G/S0003347205803860.html:text/html},
	issn = {0003-3472},
	journal = {Animal Behaviour},
	language = {en},
	month = apr,
	number = {4},
	pages = {745--757},
	shorttitle = {Models for song learning in the zebra finch},
	title = {Models for song learning in the zebra finch: fathers or others?},
	url = {https://www.sciencedirect.com/science/article/pii/S0003347205803860},
	urldate = {2021-09-22},
	volume = {39},
	year = {1990},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0003347205803860},
	bdsk-url-2 = {https://doi.org/10.1016/S0003-3472(05)80386-0}}

@article{bohner_early_1990,
	abstract = {Young zebra finch males were tested for their ability to acquire species-specific song before reaching independence. Song copies developed by males kept with their fathers up to 35 days posthatching were as complete as those of males that remained in contact with their fathers until day 100, when song crystallization has finished. Young males can learn the entire song during a brief period early in life. This early acquisition phase and its influence on further song learning at a later age make it likely that males in the field will develop a song similar to that of their fathers.},
	author = {B{\"o}hner, J{\"o}rg},
	doi = {10.1016/S0003-3472(05)80883-8},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ZD2BHYIK/B{\"o}hner - 1990 - Early acquisition of song in the zebra finch, Taen.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/W74Z4FQC/S0003347205808838.html:text/html},
	issn = {0003-3472},
	journal = {Animal Behaviour},
	language = {en},
	month = feb,
	number = {2},
	pages = {369--374},
	title = {Early acquisition of song in the zebra finch, {Taeniopygia} guttata},
	url = {https://www.sciencedirect.com/science/article/pii/S0003347205808838},
	urldate = {2021-09-22},
	volume = {39},
	year = {1990},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0003347205808838},
	bdsk-url-2 = {https://doi.org/10.1016/S0003-3472(05)80883-8}}

@article{nottebohm_song_1990,
	abstract = {The vocal control system of oscine songbirds has some perplexing properties - e.g. laterality, adult neurogenesis, neuronal replacement --- that are not predicted by common views of how vocal learning takes place. Similarly, we do not understand the relation between the direct pathway for the control of learned song and the recursive pathway necessary for song learning. Some of the paradoxes of the vocal system of birds may disappear once the relation between the perception and production of learned vocalizations is better understood. To some extent, perception and production may be two closely related states of a same system.},
	author = {Nottebohm, Fernando and Alvarez-Buylla, Arturo and Cynx, Jeffrey and Kirn, John and Ling, Chang-ying and Nottebohm, Marta and Suter, Robert and Tolles, Amanda and Williams, Heather and Krebs, John Richard and Horn, Gabriel},
	doi = {10.1098/rstb.1990.0156},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CCBXTXNC/Nottebohm et al. - 1990 - Song learning in birds the relation between perce.pdf:application/pdf},
	journal = {Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
	month = aug,
	note = {Publisher: Royal Society},
	number = {1253},
	pages = {115--124},
	shorttitle = {Song learning in birds},
	title = {Song learning in birds: the relation between perception and production},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.1990.0156},
	urldate = {2021-09-22},
	volume = {329},
	year = {1990},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/abs/10.1098/rstb.1990.0156},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.1990.0156}}

@article{katz_auditory_1981,
	abstract = {Vocal learning in songbirds is critically dependent on auditory information. Intracellular electrophysiological recordings, combined with horseradish peroxidase staining of single cells has revealed neurons within one central nervous system vocal control nucleus, hyperstriatum ventrale, pars caudale (HVc) that show responses to auditory stimuli. Auditory and non-auditory neurons fall into distinct morphological classes, based on soma size, dendritic field structure, and efferent projections. The neurons described may play a role in conveying auditory information into the vocal control system.},
	author = {Katz, Lawrence C. and Gurney, Mark E.},
	doi = {10.1016/0006-8993(81)91073-8},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YQA4N44N/Katz et Gurney - 1981 - Auditory responses in the zebra finch's motor syst.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/6NYCX9SD/0006899381910738.html:text/html},
	issn = {0006-8993},
	journal = {Brain Research},
	keywords = {auditory, songbird, hyperstriatum ventrale pars caudale, intracellular HRP-staining, intracellular recording},
	language = {en},
	month = sep,
	number = {1},
	pages = {192--197},
	title = {Auditory responses in the zebra finch's motor system for song},
	url = {https://www.sciencedirect.com/science/article/pii/0006899381910738},
	urldate = {2021-09-22},
	volume = {221},
	year = {1981},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/0006899381910738},
	bdsk-url-2 = {https://doi.org/10.1016/0006-8993(81)91073-8}}

@article{nordeen_projection_1988,
	abstract = {Many birds learn song during a restricted 'sensitive' period1. Juveniles memorize a song model, and then learn the pattern of muscle contractions necessary to reproduce the song. Of the neural changes accompanying avian song learning, perhaps the most remarkable is the production of new neurons which are inserted into the hyperstriatum ventralis pars caudalis (HVc)2, a region critical for song production3. We report here that in young male zebra finches many of the new neurons incorporated into the HVc innervate the robust nucleus of the archistriatum (RA) which projects to motor neurons controlling the vocal musculature3. Furthermore, far fewer of these new neurons are incorporated into the HVc of either adult males that are beyond the sensitive learning period, or young females (who do not develop song). Thus, a major portion of the vocal motor pathway is actually created during song learning. This may enable early sensory experience and vocal practice to not only modify existing neuronal circuits, but also shape the insertion and initial synaptic contacts of neurons controlling adult song.},
	author = {Nordeen, Kathy W. and Nordeen, Ernest J.},
	copyright = {1988 Nature Publishing Group},
	doi = {10.1038/334149a0},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/PR7W6KIP/Nordeen et Nordeen - 1988 - Projection neurons within a vocal motor pathway ar.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IN73FUFH/334149a0.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = jul,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 6178 Primary\_atype: Research Publisher: Nature Publishing Group},
	number = {6178},
	pages = {149--151},
	title = {Projection neurons within a vocal motor pathway are born during song learning in zebra finches},
	url = {https://www.nature.com/articles/334149a0},
	urldate = {2021-09-22},
	volume = {334},
	year = {1988},
	bdsk-url-1 = {https://www.nature.com/articles/334149a0},
	bdsk-url-2 = {https://doi.org/10.1038/334149a0}}

@article{williams_multiple_1989,
	abstract = {Bird song learning depends on the simultaneous comparison of multiple representations of song as well as interactions between auditory and motor modes: A motor pattern yields a vocalization that is analyzed as a sound by the bird's auditory system and then compared with a stored auditory model of the target song, resulting in changes in the motor pattern. The network of known song system nuclei has 2 main branches: one descends to the motor neurons controlling respiration and the vocal organ, and the other forms a recursive loop between 2 nuclei of the descending branch. Only one nucleus, the high vocal center (HVc), sends efferents to both branches of the song system; HVc is necessary for song production and has neurons showing song-specific auditory responses. An elaboration of general brain mechanisms may be necessary for such complex behaviors as imitative learning. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	author = {Williams, Heather},
	doi = {10.1111/j.1749-6632.1989.tb42196.x},
	file = {Snapshot:/Users/Cecile/Zotero/storage/UHWRDSWM/1991-11976-001.html:text/html},
	issn = {0077-8923},
	journal = {Annals of the New York Academy of Sciences},
	keywords = {Auditory Perception, Learning, Neural Pathways, Birds, Animal Vocalizations, Motor Processes},
	note = {Place: US Publisher: New York Academy of Sciences},
	pages = {148--164},
	title = {Multiple representations and auditory-motor interactions in the avian song system},
	volume = {563},
	year = {1989},
	bdsk-url-1 = {https://doi.org/10.1111/j.1749-6632.1989.tb42196.x}}

@article{williams_multiple_1989-1,
	author = {Williams, Heather},
	doi = {10.1111/j.1749-6632.1989.tb42196.x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/HTGJNYE9/Williams - 1989 - Multiple Representations and Auditory-Motor Intera.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T4HE5FCR/j.1749-6632.1989.tb42196.html:text/html},
	issn = {1749-6632},
	journal = {Annals of the New York Academy of Sciences},
	language = {en},
	note = {\_eprint: https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.1989.tb42196.x},
	number = {1},
	pages = {148--164},
	title = {Multiple {Representations} and {Auditory}-{Motor} {Interactions} in the {Avian} {Song} {System}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1989.tb42196.x},
	urldate = {2021-09-22},
	volume = {563},
	year = {1989},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.1989.tb42196.x},
	bdsk-url-2 = {https://doi.org/10.1111/j.1749-6632.1989.tb42196.x}}

@incollection{immelmann_song_1969,
	address = {London},
	author = {Immelmann, Klaus},
	booktitle = {Bird vocalizations: their relations to current problems in biology and psychology; essays presented to {W}. {H}. {Thorpe}, edited by {R}. {A}. {Hinde}.},
	language = {English},
	pages = {64--74},
	publisher = {Cambridge University Press},
	title = {Song {Development} in the {Zebra} {Finch} and other estrildid finches},
	year = {1969}}

@article{jarvis_neural_2007,
	abstract = {I present here a synopsis on a hypothesis that I derived on the similarities and differences of vocal learning systems in vocal learning birds for learned song and in humans for spoken language. This hypothesis states that vocal learning birds---songbirds, parrots, and hummingbirds---and humans have comparable specialized forebrain regions that are not found in their close vocal non-learning relatives. In vocal learning birds, these forebrain regions appear to be divided into two sub-pathways, a vocal motor pathway mainly used to produce learned vocalizations and a pallial--basal--ganglia--thalamic loop mainly used to learn and modify the vocalizations. I propose that humans have analogous forebrain pathways within and adjacent to the motor and pre-motor cortices, respectively, used to produce and learn speech. Recent advances have supported the existence of the seven cerebral vocal nuclei in the vocal learning birds and the proposed brain regions in humans. The results in birds suggest that the reason why the forebrain regions are similar across distantly related vocal learners is that the vocal pathways may have evolved out of a pre-existing motor pathway that predates the ancient split from the common ancestor of birds and mammals. Although this hypothesis will require the development of novel technologies to be fully tested, the existing evidence suggest that there are strong genetic constraints on how vocal learning neural systems can evolve.},
	author = {Jarvis, Erich D.},
	doi = {10.1007/s10336-007-0243-0},
	file = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/H7SGLPQ4/Jarvis - 2007 - Neural systems for vocal learning in birds and hum.pdf:application/pdf},
	issn = {1439-0361},
	journal = {Journal of Ornithology},
	language = {en},
	month = dec,
	number = {1},
	pages = {35--44},
	shorttitle = {Neural systems for vocal learning in birds and humans},
	title = {Neural systems for vocal learning in birds and humans: a synopsis},
	url = {https://doi.org/10.1007/s10336-007-0243-0},
	urldate = {2021-10-03},
	volume = {148},
	year = {2007},
	bdsk-url-1 = {https://doi.org/10.1007/s10336-007-0243-0}}

@techreport{benjamin_tracking_2021,
	abstract = {Since speech is a continuous stream with no systematic boundaries between words, how do pre-verbal infants manage to discover words? A proposed solution is that they might use the transitional probability between adjacent syllables, which drops at word boundaries. Here, we tested the limits of this mechanism by increasing the size of the word-unit to 4 syllables, and its automaticity by testing asleep neonates. Using markers of statistical learning in neonates' EEG, compared to adult' behavioral performances in the same task, we confirmed that statistical learning is automatic enough to be efficient even in sleeping neonates. But we also revealed that: 1) Successfully tracking transition probabilities in a sequence is not sufficient to segment it 2) Prosodic cues, as subtle as subliminal pauses, enable to recover segmenting capacities 3) Adults' and neonates' capacities are remarkably similar despite the difference of maturation and expertise. Finally, we observed that learning increased the similarity of neural responses across infants, providing a new neural marker to monitor learning. Thus, from birth, infants are equipped with adult-like tools, allowing to extract small coherent word-like units within auditory streams, based on the combination of statistical analyses and prosodic cues.},
	author = {Benjamin, Lucas and Fl{\'o}, Ana and Palu, Marie and Naik, Shruit and Melloni, Lucia and Dehane-Lambertz, Ghislaine},
	copyright = {{\copyright} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	doi = {10.1101/2021.09.02.458702},
	file = {Snapshot:/Users/Cecile/Zotero/storage/AVYP7Y3M/2021.09.02.458702v1.html:text/html},
	language = {en},
	month = sep,
	note = {Company: Cold Spring Harbor Laboratory Distributor: Cold Spring Harbor Laboratory Label: Cold Spring Harbor Laboratory Section: New Results Type: article},
	pages = {2021.09.02.458702},
	title = {Tracking transitional probabilities and segmenting auditory sequences are dissociable processes in adults and neonates},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.02.458702v1},
	urldate = {2021-10-07},
	year = {2021},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/2021.09.02.458702v1},
	bdsk-url-2 = {https://doi.org/10.1101/2021.09.02.458702}}

@techreport{benjamin_tracking_2021-1,
	abstract = {Since speech is a continuous stream with no systematic boundaries between words, how do pre-verbal infants manage to discover words? A proposed solution is that they might use the transitional probability between adjacent syllables, which drops at word boundaries. Here, we tested the limits of this mechanism by increasing the size of the word-unit to 4 syllables, and its automaticity by testing asleep neonates. Using markers of statistical learning in neonates' EEG, compared to adult' behavioral performances in the same task, we confirmed that statistical learning is automatic enough to be efficient even in sleeping neonates. But we also revealed that: 1) Successfully tracking transition probabilities in a sequence is not sufficient to segment it 2) Prosodic cues, as subtle as subliminal pauses, enable to recover segmenting capacities 3) Adults' and neonates' capacities are remarkably similar despite the difference of maturation and expertise. Finally, we observed that learning increased the similarity of neural responses across infants, providing a new neural marker to monitor learning. Thus, from birth, infants are equipped with adult-like tools, allowing to extract small coherent word-like units within auditory streams, based on the combination of statistical analyses and prosodic cues.},
	author = {Benjamin, Lucas and Fl{\'o}, Ana and Palu, Marie and Naik, Shruit and Melloni, Lucia and Dehane-Lambertz, Ghislaine},
	copyright = {{\copyright} 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	doi = {10.1101/2021.09.02.458702},
	language = {en},
	month = sep,
	note = {Company: Cold Spring Harbor Laboratory Distributor: Cold Spring Harbor Laboratory Label: Cold Spring Harbor Laboratory Section: New Results Type: article},
	pages = {2021.09.02.458702},
	title = {Tracking transitional probabilities and segmenting auditory sequences are dissociable processes in adults and neonates},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.02.458702v1},
	urldate = {2021-10-07},
	year = {2021},
	bdsk-url-1 = {https://www.biorxiv.org/content/10.1101/2021.09.02.458702v1},
	bdsk-url-2 = {https://doi.org/10.1101/2021.09.02.458702}}

@article{balmer_modulation_2009,
	abstract = {Neural circuits and behavior are shaped during developmental phases of maximal plasticity known as sensitive or critical periods. Neural correlates of sensory critical periods have been identified, but their roles remain unclear. Factors that define critical periods in sensorimotor circuits and behavior are not known. Birdsong learning in the zebra finch occurs during a sensitive period similar to that for human speech. We now show that perineuronal nets, which correlate with sensory critical periods, surround parvalbumin-positive neurons in brain areas that are dedicated to singing. The percentage of both total and parvalbumin-positive neurons with perineuronal nets increased with development. In HVC (this acronym is the proper name), a song area important for sensorimotor integration, the percentage of parvalbumin neurons with perineuronal nets correlated with song maturity. Shifting the vocal critical period with tutor song deprivation decreased the percentage of neurons that were parvalbumin positive and the relative staining intensity of both parvalbumin and a component of perineuronal nets. Developmental song learning shares key characteristics with sensory critical periods, suggesting shared underlying mechanisms.},
	author = {Balmer, Timothy S. and Carels, Vanessa M. and Frisch, Jillian L. and Nick, Teresa A.},
	copyright = {Copyright {\copyright} 2009 Society for Neuroscience 0270-6474/09/2912878-08\$15.00/0},
	doi = {10.1523/JNEUROSCI.2974-09.2009},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CX2U4QNQ/Balmer et al. - 2009 - Modulation of Perineuronal Nets and Parvalbumin wi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T37V7J4V/12878.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = oct,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {41},
	pages = {12878--12885},
	pmid = {19828802},
	title = {Modulation of {Perineuronal} {Nets} and {Parvalbumin} with {Developmental} {Song} {Learning}},
	url = {https://www.jneurosci.org/content/29/41/12878},
	urldate = {2021-10-18},
	volume = {29},
	year = {2009},
	bdsk-url-1 = {https://www.jneurosci.org/content/29/41/12878},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2974-09.2009}}

@article{bao_cortical_2001,
	abstract = {Representations of sensory stimuli in the cerebral cortex can undergo progressive remodelling according to the behavioural importance of the stimuli1,2. The cortex receives widespread projections from dopamine neurons in the ventral tegmental area (VTA)3,4,5, which are activated by new stimuli or unpredicted rewards6,7, and are believed to provide a reinforcement signal for such learning-related cortical reorganization8. In the primary auditory cortex (AI) dopamine release has been observed during auditory learning that remodels the sound-frequency representations9,10. Furthermore, dopamine modulates long-term potentiation11,12, a putative cellular mechanism underlying plasticity13. Here we show that stimulating the VTA together with an auditory stimulus of a particular tone increases the cortical area and selectivity of the neural responses to that sound stimulus in AI. Conversely, the AI representations of nearby sound frequencies are selectively decreased. Strong, sharply tuned responses to the paired tones also emerge in a second cortical area, whereas the same stimuli evoke only poor or non-selective responses in this second cortical field in naive animals. In addition, we found that strong long-range coherence of neuronal discharge emerges between AI and this secondary auditory cortical area.},
	author = {Bao, Shaowen and Chan, Vincent T. and Merzenich, Michael M.},
	copyright = {2001 Macmillan Magazines Ltd.},
	doi = {10.1038/35083586},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/7DF9IRJD/Bao et al. - 2001 - Cortical remodelling induced by activity of ventra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CBQBNQQ3/35083586.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	language = {en},
	month = jul,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 6842 Primary\_atype: Research Publisher: Nature Publishing Group},
	number = {6842},
	pages = {79--83},
	title = {Cortical remodelling induced by activity of ventral tegmental dopamine neurons},
	url = {https://www.nature.com/articles/35083586},
	urldate = {2021-10-18},
	volume = {412},
	year = {2001},
	bdsk-url-1 = {https://www.nature.com/articles/35083586},
	bdsk-url-2 = {https://doi.org/10.1038/35083586}}

@article{macedo-lima_dopamine_2021,
	abstract = {Vocal learning species must form and extensively hone associations between sounds and social contingencies. In songbirds, dopamine signaling guides song motor production, variability, and motivation, but it is unclear how dopamine regulates fundamental auditory associations for learning new sounds. We hypothesized that dopamine regulates learning in the auditory pallium, in part by interacting with local neuroestradiol signaling. Here, we show that zebra finch auditory neurons frequently coexpress D1 receptor (D1R) protein, neuroestradiol-synthase, GABA, and parvalbumin (PV). Auditory classical conditioning increased neuroplasticity gene induction in D1R-positive neurons. In vitro, D1R pharmacological activation reduced the amplitude of GABAergic and glutamatergic currents and increased the latter's frequency. In vivo, D1R activation reduced the firing of putative interneurons, increased the firing of putative excitatory neurons, and made both neuronal types unable to adapt to novel stimuli. Together, these findings support the hypothesis that dopamine acting via D1Rs modulates auditory association in the songbird sensory pallium.
SIGNIFICANCE STATEMENT Our key finding is that auditory forebrain D1 receptors (D1Rs) modulate auditory plasticity, in support of the hypothesis that dopamine modulates the formation of associations between sounds and outcomes. Recent work in songbirds has identified roles for dopamine in driving reinforcement learning and motor variability in song production. This leaves open whether dopamine shapes the initial events that are critical for learning vocalizations, e.g., auditory learning. Our study begins to address this question in the songbird caudomedial nidopallium (NCM), an analog of the mammalian secondary auditory cortex. Our findings indicate that dopamine receptors are important modulators of excitatory/inhibitory balance and sound association learning mechanisms in the NCM, a system that could be a fundamental feature of vertebrate ascending auditory pathways.},
	author = {Macedo-Lima, Matheus and Boyd, Hannah M. and Remage-Healey, Luke},
	copyright = {Copyright {\copyright} 2021 the authors. SfN exclusive license.},
	doi = {10.1523/JNEUROSCI.2823-20.2021},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/LAZEYPCR/Macedo-Lima et al. - 2021 - Dopamine D1 Receptor Activation Drives Plasticity .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MRPUUT5X/6050.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	keywords = {auditory, songbird, plasticity, neuromodulation},
	language = {en},
	month = jul,
	note = {Publisher: Society for Neuroscience Section: Research Articles},
	number = {28},
	pages = {6050--6069},
	pmid = {34083251},
	title = {Dopamine {D1} {Receptor} {Activation} {Drives} {Plasticity} in the {Songbird} {Auditory} {Pallium}},
	url = {https://www.jneurosci.org/content/41/28/6050},
	urldate = {2021-10-18},
	volume = {41},
	year = {2021},
	bdsk-url-1 = {https://www.jneurosci.org/content/41/28/6050},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.2823-20.2021}}

@article{nowicki_evolution_2014,
	author = {Nowicki, Stephen and Searcy, William A},
	doi = {10.1016/j.conb.2014.06.007},
	file = {Nowicki et Searcy - 2014 - The evolution of vocal learning.pdf:/Users/Cecile/Zotero/storage/TICE9ZMP/Nowicki et Searcy - 2014 - The evolution of vocal learning.pdf:application/pdf},
	issn = {09594388},
	journal = {Current Opinion in Neurobiology},
	language = {en},
	month = oct,
	pages = {48--53},
	title = {The evolution of vocal learning},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001196},
	urldate = {2021-11-23},
	volume = {28},
	year = {2014},
	bdsk-url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0959438814001196},
	bdsk-url-2 = {https://doi.org/10.1016/j.conb.2014.06.007}}

@article{imai_quantitative_2016,
	abstract = {Background
Songbirds are a preeminent animal model for understanding the neural basis underlying the development and evolution of a complex learned behavior, bird song. However, only a few quantitative methods exist to analyze these species-specific sequential behaviors in multiple species using the same calculation method.
New method
We report a method of analysis that focuses on calculating the frequency of characteristic syllable transitions in songs. This method comprises two steps: The first step involves forming correlation matrices of syllable similarity scores, named syllable similarity matrices (SSMs); these are obtained by calculating the round-robin comparison of all the syllables in two songs, while maintaining the sequential order of syllables in the songs. In the second step, each occurrence rate of three patterns of binarized ``2 rows×2 columns'' cells in the SSMs is calculated to extract information on the characteristic syllable transitions.
Results
The SSM analysis method allowed obtaining species-specific features of song patterns and intraspecies individual variability simultaneously. Furthermore, it enabled quantitative tracking of the developmental trajectory of the syllable sequence patterns.
Comparison with existing method
This method enables us to extract the species-specific song patterns and dissect the regulation of song syntax development without human-biased procedures for syllable identification. This method can be adapted to study the acoustic communication systems in several animal species, such as insects and mammals.
Conclusions
This present method provides a comprehensive qualitative approach for understanding the regulation of species specificity and its development in vocal learning.},
	author = {Imai, Raimu and Sawai, Azusa and Hayase, Shin and Furukawa, Hiroyuki and Asogwa, Chinweike Norman and Sanchez, Miguel and Wang, Hongdi and Mori, Chihiro and Wada, Kazuhiro},
	doi = {10.1016/j.jneumeth.2016.06.023},
	file = {Texte int{\'e}gral:/Users/Cecile/Zotero/storage/HESEBHIT/Imai et al. - 2016 - A quantitative method for analyzing species-specif.pdf:application/pdf},
	issn = {0165-0270},
	journal = {Journal of Neuroscience Methods},
	keywords = {Syntax, Zebra finch, Vocal learning, Individual variation, Song learning, Species specificity, Vocal development},
	language = {en},
	month = sep,
	pages = {25--33},
	title = {A quantitative method for analyzing species-specific vocal sequence pattern and its developmental dynamics},
	url = {https://www.sciencedirect.com/science/article/pii/S0165027016301522},
	urldate = {2021-11-25},
	volume = {271},
	year = {2016},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0165027016301522},
	bdsk-url-2 = {https://doi.org/10.1016/j.jneumeth.2016.06.023}}

@article{araya-salas_warbler_2017,
	abstract = {Animal acoustic communication is one of the most fruitful research areas in behavioural and evolutionary biology. Work in this area depends largely on quantifying the structure of acoustic signals, which has often depended upon closed-source or graphical user interface (GUI)-based software. Here, we describe the r package warbleR, a new package for the analysis of animal acoustic signal structure. The package offers functions for downloading avian vocalizations from the open-access online repository Xeno-Canto, displaying the geographic extent of the recordings, manipulating sound files, detecting acoustic signals or importing detected signals from other software, assessing performance of methods that measure acoustic similarity, conducting cross-correlations, measuring acoustic parameters and analysing interactive vocal signals, among others. Functions working iteratively allow parallelization to improve computational efficiency. We present a case study showing how warbleR functions can be used in a workflow to evaluate the structure of acoustic signals. We analyse geographic variation in long-billed hermit hummingbirds (Phaethornis longirostris) songs obtained from Xeno-Canto. The code in warbleR can be executed by less experienced r users, but has also been thoroughly commented, which will facilitate further customization by advanced users. The combination of the tools described here with other acoustic analysis packages in r should significantly expand the range of analytical approaches available.},
	author = {Araya-Salas, Marcelo and Smith-Vidaurre, Grace},
	doi = {10.1111/2041-210X.12624},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/WEQRBKU4/Araya-Salas et Smith-Vidaurre - 2017 - warbleR an r package to streamline analysis of an.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3NZHVSL6/2041-210X.html:text/html},
	issn = {2041-210X},
	journal = {Methods in Ecology and Evolution},
	keywords = {bioinformatics, evolutionary biology, software},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12624},
	number = {2},
	pages = {184--191},
	shorttitle = {{warbleR}},
	title = {{warbleR}: an r package to streamline analysis of animal acoustic signals},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12624},
	urldate = {2021-11-25},
	volume = {8},
	year = {2017},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12624},
	bdsk-url-2 = {https://doi.org/10.1111/2041-210X.12624}}

@article{moulin-frier_self-organization_2014,
	abstract = {We bridge the gap between two issues in infant development: vocal development and intrinsic motivation. We propose and experimentally test the hypothesis that general mechanisms of intrinsically motivated spontaneous exploration, also called curiosity-driven learning, can self-organize developmental stages during early vocal learning. We introduce a computational model of intrinsically motivated vocal exploration, which allows the learner to autonomously structure its own vocal experiments, and thus its own learning schedule, through a drive to maximize competence progress. This model relies on a physical model of the vocal tract, the auditory system and the agent's motor control as well as vocalizations of social peers. We present computational experiments that show how such a mechanism can explain the adaptive transition from vocal self-exploration with little influence from the speech environment, to a later stage where vocal exploration becomes influenced by vocalizations of peers. Within the initial self-exploration phase, we show that a sequence of vocal production stages self-organizes, and shares properties with data from infant developmental psychology: the vocal learner first discovers how to control phonation, then focuses on vocal variations of unarticulated sounds, and finally automatically discovers and focuses on babbling with articulated proto-syllables. As the vocal learner becomes more proficient at producing complex sounds, imitating vocalizations of peers starts to provide high learning progress explaining an automatic shift from self-exploration to vocal imitation.},
	author = {Moulin-Frier, Cl{\'e}ment and Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
	doi = {10.3389/fpsyg.2013.01006},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ZZZ6I3I7/Moulin-Frier et al. - 2014 - Self-organization of early vocal development in in.pdf:application/pdf},
	issn = {1664-1078},
	journal = {Frontiers in Psychology},
	pages = {1006},
	shorttitle = {Self-organization of early vocal development in infants and machines},
	title = {Self-organization of early vocal development in infants and machines: the role of intrinsic motivation},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2013.01006},
	urldate = {2021-11-25},
	volume = {4},
	year = {2014},
	bdsk-url-1 = {https://www.frontiersin.org/article/10.3389/fpsyg.2013.01006},
	bdsk-url-2 = {https://doi.org/10.3389/fpsyg.2013.01006}}

@article{bergmann_computational_2014,
	abstract = {Babies learn words from the speakers in their environment. This project / thesis was inspired by the question how babies can discover words in the speech signal. This signal is continuous, unlabelled, and not divided into shorter units that coincide with sound- or word-boundaries. So far, research on infants' input concentrated on the main caregiver, usually the mother. The assumption was that the main caregiver provides most of the information babies need to learn their native language. The role of other speakers as largely been unknown.
This project used computational models to simulate the language acquisition process. This allowed for full control over the input and over all processes inside the simulated baby's mind. Computer models learned words from real speech, without intervening processed that described the continuous signal in terms of single sounds or words.
It turned out that these models could learn words and that we can even simulate babies in experiments successfully with such a model.
Additional studies revealed that hearing many speakers, both men and women, can help the word learning process. Hearing variable input led to very successful word learning overall. Especially in tricky conditions, such as noise or encountering yet another unknown speaker, the models who learned from many speakers usually fared better.
In conclusion, variability and different voices in the speech signal can be very valuable when learning words.},
	author = {Bergmann, C.},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/UEFXJS43/Bergmann - 2014 - Computational models of early language acquisition.pdf:application/pdf},
	language = {English (eng)},
	note = {Accepted: 2014-06-25T21:02:38Z Publisher: S.l. : s.n.},
	title = {Computational models of early language acquisition and the role of different voices},
	url = {https://repository.ubn.ru.nl/handle/2066/127847},
	urldate = {2021-12-02},
	year = {2014},
	bdsk-url-1 = {https://repository.ubn.ru.nl/handle/2066/127847}}

@article{bergmann_computational_2014-1,
	abstract = {Babies learn words from the speakers in their environment. This project / thesis was inspired by the question how babies can discover words in the speech signal. This signal is continuous, unlabelled, and not divided into shorter units that coincide with sound- or word-boundaries. So far, research on infants' input concentrated on the main caregiver, usually the mother. The assumption was that the main caregiver provides most of the information babies need to learn their native language. The role of other speakers as largely been unknown.
This project used computational models to simulate the language acquisition process. This allowed for full control over the input and over all processes inside the simulated baby's mind. Computer models learned words from real speech, without intervening processed that described the continuous signal in terms of single sounds or words.
It turned out that these models could learn words and that we can even simulate babies in experiments successfully with such a model.
Additional studies revealed that hearing many speakers, both men and women, can help the word learning process. Hearing variable input led to very successful word learning overall. Especially in tricky conditions, such as noise or encountering yet another unknown speaker, the models who learned from many speakers usually fared better.
In conclusion, variability and different voices in the speech signal can be very valuable when learning words.},
	author = {Bergmann, C.},
	language = {English (eng)},
	note = {Accepted: 2014-06-25T21:02:38Z Publisher: S.l. : s.n.},
	title = {Computational models of early language acquisition and the role of different voices},
	url = {https://repository.ubn.ru.nl/handle/2066/127847},
	urldate = {2021-12-02},
	year = {2014},
	bdsk-url-1 = {https://repository.ubn.ru.nl/handle/2066/127847}}

@article{volman_development_1993,
	abstract = {Juvenile white-crowned sparrows learn to sing by first memorizing an adult's song and then progressively matching their vocalizations to this model during plastic song. Previous studies have shown that neurons in the song-system nucleus HVC of adult sparrows respond preferentially to a bird's own song. In this study, the auditory selectivity of HVC neurons in subadult birds was examined. In young, nonsinging birds who had been song tutored, these cells responded to song stimuli, and at some recording sites had distinct preferences for one song or another. As a population, however, HVC neurons in these birds showed no preference for familiar song. They were no more likely to prefer normal tutor song to reversed tutor song or to the song of another white-crowned subspecies. By contrast, in birds producing plastic song, HVC neurons were selective for the bird's own songs, even in preference to their tutor song. Therefore, during song learning the response properties of HVC neurons appear to be dynamically modified, perhaps by auditory feedback from the bird's own vocalizations. The emergence of song selectivity during plastic song may be significant both for song learning and for song perception in adult birds.},
	author = {Volman, S. F.},
	copyright = {{\copyright} 1993 by Society for Neuroscience},
	doi = {10.1523/JNEUROSCI.13-11-04737.1993},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CBPJVZCE/Volman - 1993 - Development of neural selectivity for birdsong dur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2KGSPM57/4737.html:text/html},
	issn = {0270-6474, 1529-2401},
	journal = {Journal of Neuroscience},
	language = {en},
	month = nov,
	note = {Publisher: Society for Neuroscience Section: Articles},
	number = {11},
	pages = {4737--4747},
	pmid = {8229196},
	title = {Development of neural selectivity for birdsong during vocal learning},
	url = {https://www.jneurosci.org/content/13/11/4737},
	urldate = {2021-12-06},
	volume = {13},
	year = {1993},
	bdsk-url-1 = {https://www.jneurosci.org/content/13/11/4737},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.13-11-04737.1993}}

@article{roberts_rapid_2010,
	abstract = {Previous studies have demonstrated a correlation between structural changes in the brain and sensory experience, but whether similar changes accompany learning is uncertain. High-resolution two-photon in vivo imaging of individual neurons in the song control nucleus HVC (higher vocal centre) of juvenile zebra finches that were learning adult song patterns suggests that learning does involve such changes. Within 24 hours of learning their first song, the normally dynamic dendritic spines in the HVC of the zebra finches become larger and more stable, and synaptic activity is enhanced.},
	author = {Roberts, Todd F. and Tschida, Katherine A. and Klein, Marguerita E. and Mooney, Richard},
	copyright = {2010 Macmillan Publishers Limited. All rights reserved},
	doi = {10.1038/nature08759},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/TBHAKKCE/Roberts et al. - 2010 - Rapid spine stabilization and synaptic enhancement.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2TTW94QK/nature08759.html:text/html},
	issn = {1476-4687},
	journal = {Nature},
	keywords = {Learning and memory, Sensory systems, Spine structure},
	language = {en},
	month = feb,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 7283 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Learning and memory;Sensory systems;Spine structure Subject\_term\_id: learning-and-memory;sensory-systems;spine-structure},
	number = {7283},
	pages = {948--952},
	title = {Rapid spine stabilization and synaptic enhancement at the onset of behavioural learning},
	url = {https://www.nature.com/articles/nature08759},
	urldate = {2021-12-06},
	volume = {463},
	year = {2010},
	bdsk-url-1 = {https://www.nature.com/articles/nature08759},
	bdsk-url-2 = {https://doi.org/10.1038/nature08759}}

@article{mackevicius_avian_2020,
	abstract = {How are brain circuits constructed to achieve complex goals? The brains of young songbirds develop motor circuits that achieve the goal of imitating a specific tutor song to which they are exposed. Here, we set out to examine how song-generating circuits may be influenced early in song learning by a cortical region (NIf) at the interface between auditory and motor systems. Single-unit recordings reveal that, during juvenile babbling, NIf neurons burst at syllable onsets, with some neurons exhibiting selectivity for particular emerging syllable types. When juvenile birds listen to their tutor, NIf neurons are also activated at tutor syllable onsets, and are often selective for particular syllable types. We examine a simple computational model in which tutor exposure imprints the correct number of syllable patterns as ensembles in an interconnected NIf network. These ensembles are then reactivated during singing to train a set of syllable sequences in the motor network.},
	author = {Mackevicius, Emily L. and Happ, Michael T. L. and Fee, Michale S.},
	copyright = {2020 The Author(s)},
	doi = {10.1038/s41467-020-18732-x},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/Q7N57L6Z/Mackevicius et al. - 2020 - An avian cortical circuit for chunking tutor song .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WWRIES9H/s41467-020-18732-x.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	keywords = {Birdsong, Learning and memory, Network models},
	language = {en},
	month = oct,
	note = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Number: 1 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Birdsong;Learning and memory;Network models Subject\_term\_id: birdsong;learning-and-memory;network-models},
	number = {1},
	pages = {5029},
	title = {An avian cortical circuit for chunking tutor song syllables into simple vocal-motor units},
	url = {https://www.nature.com/articles/s41467-020-18732-x},
	urldate = {2021-12-06},
	volume = {11},
	year = {2020},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-020-18732-x},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-020-18732-x}}

@article{searcy_variation_2021,
	abstract = {Songbirds as a whole are considered to be vocal production learners, meaning that they modify the structure of their vocalizations as a result of experience with the vocalizations of others. The more than 4000 species of songbirds, however, vary greatly in crucial features of song development. Variable features include: (i) the normality of the songs of early-deafened birds, reflecting the importance of innate motor programmes in song development; (ii) the normality of the songs of isolation-reared birds, reflecting the combined importance of innate auditory templates and motor programmes; (iii) the degree of selectivity in choice of external models; (iv) the accuracy of copying from external models; and (v) whether or not learning from external models continues into adulthood. We suggest that because of this variability, some songbird species, specifically those that are able to develop songs in the normal range without exposure to external models, can be classified as limited vocal learners. Those species that require exposure to external models to develop songs in the normal range can be considered complex vocal learners.
            This article is part of the theme issue `Vocal learning in animals and humans'.},
	author = {Searcy, William A. and Soha, Jill and Peters, Susan and Nowicki, Stephen},
	doi = {10.1098/rstb.2020.0257},
	file = {Searcy et al. - 2021 - Variation in vocal production learning across song.pdf:/Users/Cecile/Zotero/storage/RTANFZX6/Searcy et al. - 2021 - Variation in vocal production learning across song.pdf:application/pdf},
	issn = {0962-8436, 1471-2970},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	language = {en},
	month = oct,
	number = {1836},
	pages = {20200257},
	title = {Variation in vocal production learning across songbirds},
	url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0257},
	urldate = {2021-12-06},
	volume = {376},
	year = {2021},
	bdsk-url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2020.0257},
	bdsk-url-2 = {https://doi.org/10.1098/rstb.2020.0257}}

@article{funabiki_long_2003,
	author = {Funabiki, Yasuko and Konishi, Masakazu},
	doi = {10.1523/JNEUROSCI.23-17-06928.2003},
	file = {Funabiki et Konishi - 2003 - Long Memory in Song Learning by Zebra Finches.pdf:/Users/Cecile/Zotero/storage/U29N6ZYT/Funabiki et Konishi - 2003 - Long Memory in Song Learning by Zebra Finches.pdf:application/pdf},
	issn = {0270-6474, 1529-2401},
	journal = {The Journal of Neuroscience},
	language = {en},
	month = jul,
	number = {17},
	pages = {6928--6935},
	title = {Long {Memory} in {Song} {Learning} by {Zebra} {Finches}},
	url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-17-06928.2003},
	urldate = {2021-12-06},
	volume = {23},
	year = {2003},
	bdsk-url-1 = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-17-06928.2003},
	bdsk-url-2 = {https://doi.org/10.1523/JNEUROSCI.23-17-06928.2003}}

@article{tchernichovski_dynamics_2001,
	abstract = {Song imitation in birds provides good material for studying the basic biology of vocal learning. Techniques were developed for inducing the rapid onset of song imitation in young zebra finches and for tracking trajectories of vocal change over a 7-week period until a match to a model song was achieved. Exposure to a model song induced the prompt generation of repeated structured sounds (prototypes) followed by a slow transition from repetitive to serial delivery of syllables. Tracking this transition revealed two phenomena: (i) Imitations of dissimilar sounds can emerge from successive renditions of the same prototype, and (ii) developmental trajectories for some sounds followed paths of increasing acoustic mismatch until an abrupt correction occurred by period doubling. These dynamics are likely to reflect underlying neural and articulatory constraints on the production and imitation of sounds.},
	annote = {Cited By :348},
	author = {Tchernichovski, O. and Mitra, P.P. and Lints, T. and Nottebohm, F.},
	doi = {10.1126/science.1058522},
	file = {Snapshot:/Users/Cecile/Zotero/storage/XCLQ2VT6/display.html:text/html},
	issn = {0036-8075},
	journal = {Science},
	language = {English},
	number = {5513},
	pages = {2564--2569},
	shorttitle = {Dynamics of the vocal imitation process},
	title = {Dynamics of the vocal imitation process: {How} a zebra finch learns its song},
	volume = {291},
	year = {2001},
	bdsk-url-1 = {https://doi.org/10.1126/science.1058522}}

@article{faust_origins_2020,
	abstract = {Human infants are altricial, born relatively helpless and dependent on parental care for an extended period of time. This protracted time to maturity is typically regarded as a necessary epiphenomenon of evolving and developing large brains. We argue that extended altriciality is itself adaptive, as a prolonged necessity for parental care allows extensive social learning to take place. Human adults possess a suite of complex social skills, such as language, empathy, morality, and theory of mind. Rather than requiring hardwired, innate knowledge of social abilities, evolution has outsourced the necessary information to parents. Critical information for species-typical development, such as species recognition, may originate from adults rather than from genes, aided by underlying perceptual biases for attending to social stimuli and capacities for statistical learning of social actions. We draw on extensive comparative findings to illustrate that, across species, altriciality functions as an adaptation for social learning from caregivers.},
	author = {Faust, Katerina M. and Carouso-Peck, Samantha and Elson, Mary R. and Goldstein, Michael H.},
	doi = {10.1146/annurev-devpsych-051820-121446},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/ZQK7BAWF/Faust et al. - 2020 - The Origins of Social Knowledge in Altricial Speci.pdf:application/pdf},
	journal = {Annual Review of Developmental Psychology},
	keywords = {social learning, altriciality, comparative development, developmental niche, exogenetic inheritance},
	note = {\_eprint: https://doi.org/10.1146/annurev-devpsych-051820-121446},
	number = {1},
	pages = {225--246},
	title = {The {Origins} of {Social} {Knowledge} in {Altricial} {Species}},
	url = {https://doi.org/10.1146/annurev-devpsych-051820-121446},
	urldate = {2021-12-08},
	volume = {2},
	year = {2020},
	bdsk-url-1 = {https://doi.org/10.1146/annurev-devpsych-051820-121446}}

@article{vallentin_inhibition_2016,
	author = {Vallentin, Daniela and Kosche, Georg and Lipkind, Dina and Long, Michael A.},
	doi = {10.1126/science.aad3023},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/JUSJBVED/Vallentin et al. - 2016 - Inhibition protects acquired song segments during .pdf:application/pdf},
	journal = {Science},
	month = jan,
	note = {Publisher: American Association for the Advancement of Science},
	number = {6270},
	pages = {267--271},
	title = {Inhibition protects acquired song segments during vocal learning in zebra finches},
	url = {https://www.science.org/doi/10.1126/science.aad3023},
	urldate = {2021-12-10},
	volume = {351},
	year = {2016},
	bdsk-url-1 = {https://www.science.org/doi/10.1126/science.aad3023},
	bdsk-url-2 = {https://doi.org/10.1126/science.aad3023}}

@article{tchernichovski_procedure_2000,
	abstract = {Assessment of vocal imitation requires a widely accepted way of describing and measuring any similarities between the song of a tutor and that of its pupil. Quantifying the similarity between two songs, however, can be difficult and fraught with subjective bias. We present a fully automated procedure that measures parametrically the similarity between songs. We tested its performance on a large database of zebra finch, Taeniopygia guttata, songs. The procedure uses an analytical framework of modern spectral analysis to characterize the acoustic structure of a song. This analysis provides a superior sound spectrogram that is then reduced to a set of simple acoustic features. Based on these features, the procedure detects similar sections between songs automatically. In addition, the procedure can be used to examine: (1) imitation accuracy across acoustic features; (2) song development; (3) the effect of brain lesions on specific song features; and (4) variability across different renditions of a song or a call produced by the same individual, across individuals and across populations. By making the procedure available we hope to promote the adoption of a standard, automated method for measuring similarity between songs or calls.},
	author = {Tchernichovski, Ofer and Nottebohm, Fernando and Ho, Ching Elizabeth and Pesaran, Bijan and Mitra, Partha Pratim},
	doi = {10.1006/anbe.1999.1416},
	file = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/U6QJHNCC/Tchernichovski et al. - 2000 - A procedure for an automated measurement of song s.pdf:application/pdf},
	issn = {0003-3472},
	journal = {Animal Behaviour},
	language = {en},
	month = jun,
	number = {6},
	pages = {1167--1176},
	title = {A procedure for an automated measurement of song similarity},
	url = {https://www.sciencedirect.com/science/article/pii/S0003347299914161},
	urldate = {2021-12-13},
	volume = {59},
	year = {2000},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0003347299914161},
	bdsk-url-2 = {https://doi.org/10.1006/anbe.1999.1416}}

@article{vouloumanos_listen_2014,
	abstract = {Infants' exposure to human speech within the first year of life promotes more than speech processing and language acquisition: new developmental evidence suggests that listening to speech shapes infants' fundamental cognitive and social capacities. Speech streamlines infants' learning, promotes the formation of object categories, signals communicative partners, highlights information in social interactions, and offers insight into the minds of others. These results, which challenge the claim that for infants, speech offers no special cognitive advantages, suggests a new synthesis: Far earlier than researchers had imagined, an intimate and powerful connection between human speech and cognition guides infant development, advancing infants' acquisition of fundamental psychological processes.},
	author = {Vouloumanos, Athena and Waxman, Sandra R.},
	doi = {10.1016/j.tics.2014.10.001},
	file = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/ZTVLQG64/Vouloumanos et Waxman - 2014 - Listen up! Speech is for thinking during infancy.pdf:application/pdf},
	issn = {1364-6613},
	journal = {Trends in cognitive sciences},
	month = dec,
	number = {12},
	pages = {642--646},
	pmcid = {PMC4324625},
	pmid = {25457376},
	title = {Listen up! {Speech} is for thinking during infancy},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4324625/},
	urldate = {2021-12-14},
	volume = {18},
	year = {2014},
	bdsk-url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4324625/},
	bdsk-url-2 = {https://doi.org/10.1016/j.tics.2014.10.001}}

@article{benichov_inhibition_2020,
	abstract = {Vocal turn-taking is a fundamental organizing principle of human conversation but the neural circuit mechanisms that structure coordinated vocal interactions are unknown. The ability to exchange vocalizations in an alternating fashion is also exhibited by other species, including zebra finches. With a combination of behavioral testing, electrophysiological recordings, and pharmacological manipulations we demonstrate that activity within a cortical premotor nucleus orchestrates the timing of calls in socially interacting zebra finches. Within this circuit, local inhibition precedes premotor neuron activation associated with calling. Blocking inhibition results in faster vocal responses as well as an impaired ability to flexibly avoid overlapping with a partner. These results support a working model in which premotor inhibition regulates context-dependent timing of vocalizations and enables the precise interleaving of vocal signals during turn-taking.},
	author = {Benichov, Jonathan I. and Vallentin, Daniela},
	copyright = {2020 The Author(s)},
	doi = {10.1038/s41467-019-13938-0},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/IJ7X7VX6/Benichov et Vallentin - 2020 - Inhibition within a premotor circuit controls the .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/LYEDLS3R/s41467-019-13938-0.html:text/html},
	issn = {2041-1723},
	journal = {Nature Communications},
	keywords = {Motor control, Neural circuits, Social behaviour},
	language = {en},
	month = jan,
	note = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Number: 1 Primary\_atype: Research Publisher: Nature Publishing Group Subject\_term: Motor control;Neural circuits;Social behaviour Subject\_term\_id: motor-control;neural-circuit;social-behaviour},
	number = {1},
	pages = {221},
	title = {Inhibition within a premotor circuit controls the timing of vocal turn-taking in zebra finches},
	url = {https://www.nature.com/articles/s41467-019-13938-0},
	urldate = {2021-12-22},
	volume = {11},
	year = {2020},
	bdsk-url-1 = {https://www.nature.com/articles/s41467-019-13938-0},
	bdsk-url-2 = {https://doi.org/10.1038/s41467-019-13938-0}}

@article{hickok_computational_2012,
	abstract = {The study of speech production has largely been divided into investigations of lower-level articulatory motor control and of higher-level linguistic processing, with these research traditions rarely interacting. In this Opinion article, Hickok argues that these approaches have much to offer each other, and he presents a model of speech production that incorporates ideas from both research traditions and findings from neuroscientific studies of sensorimotor integration.},
	author = {Hickok, Gregory},
	copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	doi = {10.1038/nrn3158},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/764QKZLN/Hickok - 2012 - Computational neuroanatomy of speech production.pdf:application/pdf},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	keywords = {Sensory systems, Motor control, Computational neuroscience, Somatosensory system},
	language = {en},
	month = feb,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 2 Primary\_atype: Reviews Publisher: Nature Publishing Group Subject\_term: Computational neuroscience;Motor control;Sensory systems;Somatosensory system Subject\_term\_id: computational-neuroscience;motor-control;sensory-systems;somatosensory-system},
	number = {2},
	pages = {135--145},
	title = {Computational neuroanatomy of speech production},
	url = {https://www.nature.com/articles/nrn3158},
	urldate = {2022-01-17},
	volume = {13},
	year = {2012},
	bdsk-url-1 = {https://www.nature.com/articles/nrn3158},
	bdsk-url-2 = {https://doi.org/10.1038/nrn3158}}

@article{hickok_cortical_2007,
	abstract = {Decades of research have not yet succeeded in definitively characterizing the neuroanatomy of speech processing. Hickok and Poeppel describe a dual-stream model of speech processing and discuss how this model can account for some of the field's paradoxical findings.},
	author = {Hickok, Gregory and Poeppel, David},
	copyright = {2007 Nature Publishing Group},
	doi = {10.1038/nrn2113},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/CVWKJID7/Hickok et Poeppel - 2007 - The cortical organization of speech processing.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4P6UYP2J/nrn2113.html:text/html},
	issn = {1471-0048},
	journal = {Nature Reviews Neuroscience},
	keywords = {Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, general, Neurobiology, Neurosciences},
	language = {en},
	month = may,
	note = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Number: 5 Primary\_atype: Reviews Publisher: Nature Publishing Group},
	number = {5},
	pages = {393--402},
	title = {The cortical organization of speech processing},
	url = {https://www.nature.com/articles/nrn2113},
	urldate = {2022-01-17},
	volume = {8},
	year = {2007},
	bdsk-url-1 = {https://www.nature.com/articles/nrn2113},
	bdsk-url-2 = {https://doi.org/10.1038/nrn2113}}

@article{sainburg_parametric_2021,
	abstract = {UMAP is a nonparametric graph-based dimensionality reduction algorithm using applied Riemannian geometry and algebraic topology to find low-dimensional embeddings of structured data. The UMAP algorithm consists of two steps: (1) computing a graphical representation of a data set (fuzzy simplicial complex) and (2) through stochastic gradient descent, optimizing a low-dimensional embedding of the graph. Here, we extend the second step of UMAP to a parametric optimization over neural network weights, learning a parametric relationship between data and embedding. We first demonstrate that parametric UMAP performs comparably to its nonparametric counterpart while conferring the benefit of a learned parametric mapping (e.g., fast online embeddings for new data). We then explore UMAP as a regularization, constraining the latent distribution of autoencoders, parametrically varying global structure preservation, and improving classifier accuracy for semisupervised learning by capturing structure in unlabeled data.1},
	author = {Sainburg, Tim and McInnes, Leland and Gentner, Timothy Q.},
	doi = {10.1162/neco_a_01434},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/4QKY3BRH/Sainburg et al. - 2021 - Parametric UMAP Embeddings for Representation and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4QHP2DKY/Parametric-UMAP-Embeddings-for-Representation-and.html:text/html},
	issn = {0899-7667},
	journal = {Neural Computation},
	month = oct,
	number = {11},
	pages = {2881--2907},
	title = {Parametric {UMAP} {Embeddings} for {Representation} and {Semisupervised} {Learning}},
	url = {https://doi.org/10.1162/neco_a_01434},
	urldate = {2022-01-21},
	volume = {33},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1162/neco_a_01434}}

@article{vanden_bosch_der_nederlanden_infant_2021,
	abstract = {How do infants learn the sounds of their native language when there are many simultaneous sounds competing for their attention? Adults and children detect when speech sounds change in complex scenes better than when other sounds change. We examined whether infants have similar biases to detect when human speech changes better than nonspeech sounds including musical instruments, water, and animal calls in complex auditory scenes. We used a change deafness paradigm to examine whether 5-month-olds' change detection is biased toward certain sounds within high-level categories (e.g., biological or generated by humans) or whether change detection depends on low-level salient physical features such that detection is better for sounds with more distinct acoustic properties, such as water. In Experiment 1, 5-month-olds showed some evidence for detecting speech and music changes better than no change trials. In Experiment 2, when speech and music were compared separately with animal and water sounds, infants detected when speech and water changed, but not when music changed across scenes. Infants' change detection is both biased for certain sound categories, as they detected small speech changes better than other sounds, and affected by the size of the acoustic change, similar to young infants' attentional priorities in complex visual scenes. By 5 months, infants show some preferential processing of speech changes in complex auditory environments, which could help bootstrap the language learning process. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
	annote = {*},
	author = {Vanden Bosch der Nederlanden, Christina M. and Vouloumanos, Athena},
	date-modified = {2022-04-05 16:58:03 +0200},
	doi = {10.1037/dev0000974},
	file = {Snapshot:/Users/Cecile/Zotero/storage/2NITYN8U/2022-02010-001.html:text/html},
	issn = {1939-0599},
	journal = {Developmental Psychology},
	keywords = {Music, Speech Perception, Infant Development, Attentional Bias, Auditory Scene Analysis, Auditory Stimulation, Knowledge (General), Oral Communication, Stimulus Change},
	note = {Place: US Publisher: American Psychological Association},
	number = {9},
	pages = {1411--1422},
	title = {Infant biases for detecting speech in complex scenes},
	volume = {57},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1037/dev0000974}}

@article{bergmann_development_2016,
	abstract = {Infants start learning words, the building blocks of language, at least by 6 months. To do so, they must be able to extract the phonological form of words from running speech. A rich literature has investigated this process, termed word segmentation. We addressed the fundamental question of how infants of different ages segment words from their native language using a meta-analytic approach. Based on previous popular theoretical and experimental work, we expected infants to display familiarity preferences early on, with a switch to novelty preferences as infants become more proficient at processing and segmenting native speech. We also considered the possibility that this switch may occur at different points in time as a function of infants' native language and took into account the impact of various task- and stimulus-related factors that might affect difficulty. The combined results from 168 experiments reporting on data gathered from 3774 infants revealed a persistent familiarity preference across all ages. There was no significant effect of additional factors, including native language and experiment design. Further analyses revealed no sign of selective data collection or reporting. We conclude that models of infant information processing that are frequently cited in this domain may not, in fact, apply in the case of segmenting words from native speech.},
	author = {Bergmann, Christina and Cristia, Alejandrina},
	doi = {10.1111/desc.12341},
	file = {Snapshot:/Users/Cecile/Zotero/storage/PBSKN3FN/desc.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/MVCW2YQU/Bergmann et Cristia - 2016 - Development of infants' segmentation of words from.pdf:application/pdf},
	issn = {1467-7687},
	journal = {Developmental Science},
	language = {en},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12341},
	number = {6},
	pages = {901--917},
	shorttitle = {Development of infants' segmentation of words from native speech},
	title = {Development of infants' segmentation of words from native speech: a meta-analytic approach},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12341},
	urldate = {2022-01-26},
	volume = {19},
	year = {2016},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12341},
	bdsk-url-2 = {https://doi.org/10.1111/desc.12341}}

@article{cox2022bayesian,
	author = {Cox, Christopher Martin Mikkelsen and Keren-Portnoy, Tamar and Roepstorff, Andreas and Fusaroli, Riccardo},
	journal = {Infancy},
	number = {1},
	pages = {67--96},
	publisher = {Wiley Online Library},
	title = {A Bayesian meta-analysis of infants? ability to perceive audio--visual congruence for speech},
	volume = {27},
	year = {2022}}

@article{nguyen2021systematic,
	author = {Nguyen, Vivian and Versyp, Otto and Cox, Christopher Martin Mikkelsen and Fusaroli, Riccardo},
	publisher = {PsyArXiv},
	title = {A systematic review and Bayesian meta-analysis of the development of turn taking in adult-child vocal interactions},
	year = {2021}}

@techreport{cristia_meta-analytic_2021,
	abstract = {Theories are a key part of the scientific process. How should we evaluate theories against evidence? The two traditional and most widespread approaches use single studies and qualitative reviews to evaluate theories; more recently, large-scale replications entered the picture. We argue here that none of these approaches fits in with cumulative science tenets. We propose instead Community-Augmented Meta-Analyses (CAMAs) which are cumulative and open, built using all available data, with mechanisms in place to prevent data overfitting and to statistically model methodological "noise". When using CAMAs as the basis for  theory evaluation, it becomes a transparent, replicable endeavor. We provide step-by-step recommendations for how to implement this approach -- and what it means when one cannot. This leads us to conclude that CAMAs highlight areas of uncertainty better than the alternative theory evaluation approaches, and can trigger a much needed shift towards a cumulative mindset both with respect to theory and data, leading us to do experiments and qualitative reviews differently.},
	author = {Cristia, Alejandrina and Tsuji, Sho and Bergmann, Christina},
	doi = {10.31219/osf.io/83kg2},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/DDIVSY9Q/Cristia et al. - 2020 - A meta-analytic approach to evaluating the explana.pdf:application/pdf},
	institution = {OSF Preprints},
	journal = {MetaPsychology},
	keywords = {open science, bias, computational modeling, cumulative science, empirical research, large-scale replications, meta-analyses, Methodology: behavioral, methodology: quantitative, methodology: scientific, Psychology, Social and Behavioral Sciences, theory adjudication},
	language = {en-us},
	month = jul,
	note = {type: article},
	title = {A meta-analytic approach to evaluating the explanatory adequacy of theories},
	url = {https://osf.io/83kg2/},
	urldate = {2022-01-26},
	year = {2021},
	bdsk-url-1 = {https://osf.io/83kg2/},
	bdsk-url-2 = {https://doi.org/10.31219/osf.io/83kg2}}

@article{ioannidis_why_2005,
	abstract = {Summary There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
	author = {Ioannidis, John P. A.},
	doi = {10.1371/journal.pmed.0020124},
	file = {Full Text PDF:/Users/Cecile/Zotero/storage/V5LCHFP3/Ioannidis - 2005 - Why Most Published Research Findings Are False.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KAYYL3XG/article.html:text/html},
	issn = {1549-1676},
	journal = {PLOS Medicine},
	keywords = {Cancer risk factors, Finance, Genetic epidemiology, Genetics of disease, Metaanalysis, Randomized controlled trials, Research design, Schizophrenia},
	language = {en},
	month = aug,
	note = {Publisher: Public Library of Science},
	number = {8},
	pages = {e124},
	title = {Why {Most} {Published} {Research} {Findings} {Are} {False}},
	url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124},
	urldate = {2022-01-26},
	volume = {2},
	year = {2005},
	bdsk-url-1 = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124},
	bdsk-url-2 = {https://doi.org/10.1371/journal.pmed.0020124}}

@article{noauthor_bayesian_nodate,
	doi = {10.1111/infa.12436},
	file = {Snapshot:/Users/Cecile/Zotero/storage/CN3X5AGA/infa.html:text/html;Version soumise:/Users/Cecile/Zotero/storage/3YADFTZD/A Bayesian meta‐analysis of infants' ability to pe.pdf:application/pdf},
	language = {en},
	title = {A {Bayesian} meta‐analysis of infants' ability to perceive audio--visual congruence for speech},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/infa.12436},
	urldate = {2022-03-30},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/10.1111/infa.12436},
	bdsk-url-2 = {https://doi.org/10.1111/infa.12436}}
