%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for CÃ©cile Issard at 2020-06-16 13:53:15 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@article{friedrich_n400-like_2004,
	Abstract = {To understand mechanisms of early language acquisition, it is important to know whether the child's brain acts in an adult-like manner when processing words in meaningful contexts. The N400, a negative component in the event-related potential (ERP) of adults, is a sensitive index of semantic processing reflecting neural mechanisms of semantic integration into context. In the present study, we investigated whether the mechanisms indexed by the N400 are already working during early language acquisition. While 19-month-olds were looking at sequentially presented pictures, they were acoustically presented with words that were either congruous or incongruous to the picture content. The ERP averaged across the group of 55 children revealed an N400-like semantic incongruity effect in addition to an early phonological--lexical priming effect. The results suggest that both lexical expectations facilitating early phonological processing and mechanisms of semantic priming facilitating integration into semantic context are already present in 19-month-olds. The child's specific comprehension abilities are reflected in strength, latency, and hemispheric differences of the semantic incongruity effect. Spatio-temporal differences in that effect, thus, indicate changes in the organization of brain activity correlated with the child's behavioral development.},
	Author = {Friedrich, Manuela and Friederici, Angela D.},
	Doi = {10.1162/0898929042304705},
	File = {Snapshot:/Users/Cecile/Zotero/storage/2V4W9CXZ/0898929042304705.html:text/html},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = oct,
	Number = {8},
	Pages = {1465--1477},
	Shorttitle = {N400-like {Semantic} {Incongruity} {Effect} in 19-{Month}-{Olds}},
	Title = {N400-like {Semantic} {Incongruity} {Effect} in 19-{Month}-{Olds}: {Processing} {Known} {Words} in {Picture} {Contexts}},
	Url = {http://www.mitpressjournals.org/doi/10.1162/0898929042304705},
	Urldate = {2017-07-24},
	Volume = {16},
	Year = {2004},
	Bdsk-Url-1 = {http://www.mitpressjournals.org/doi/10.1162/0898929042304705},
	Bdsk-Url-2 = {https://doi.org/10.1162/0898929042304705}}

@article{shamir_representation_2009,
	Abstract = {Author Summary
Sensory processing of time-varying stimuli, such as speech, is associated with high-frequency oscillatory cortical activity, the functional significance of which is still unknown. One possibility is that the oscillations are part of a stimulus-encoding mechanism. Here, we investigate a computational model of such a mechanism, a spiking neuronal network whose intrinsic oscillations interact with external input (waveforms simulating short speech segments in a single acoustic frequency band) to encode stimuli that extend over a time interval longer than the oscillation's period. The network implements a temporally sparse encoding, whose robustness to time warping and neuronal noise we quantify. To our knowledge, this study is the first to demonstrate that a biophysically plausible model of oscillations occurring in the processing of auditory input may generate a representation of signals that span multiple oscillation cycles.},
	Author = {Shamir, Maoz and Ghitza, Oded and Epstein, Steven and Kopell, Nancy},
	Doi = {10.1371/journal.pcbi.1000370},
	File = {PLoS Snapshot:/Users/Cecile/Zotero/storage/6J2AUV5C/infodoi10.1371journal.pcbi.html:text/html},
	Journal = {PLoS Comput Biol},
	Month = may,
	Number = {5},
	Pages = {e1000370},
	Title = {Representation of {Time}-{Varying} {Stimuli} by a {Network} {Exhibiting} {Oscillations} on a {Faster} {Time} {Scale}},
	Url = {http://dx.doi.org/10.1371/journal.pcbi.1000370},
	Urldate = {2014-10-21},
	Volume = {5},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1000370}}

@article{vouloumanos_five-month-old_2009,
	Abstract = {Humans speak, monkeys grunt, and ducks quack. How do we come to know which vocalizations animals produce? Here we explore this question by asking whether young infants expect humans, but not other animals, to produce speech, and further, whether infants have similarly restricted expectations about the sources of vocalizations produced by other species. Five-month-old infants matched speech, but not human nonspeech vocalizations, specifically to humans, looking longer at static human faces when human speech was played than when either rhesus monkey or duck calls were played. They also matched monkey calls to monkey faces, looking longer at static rhesus monkey faces when rhesus monkey calls were played than when either human speech or duck calls were played. However, infants failed to match duck vocalizations to duck faces, even though infants likely have more experience with ducks than monkeys. Results show that by 5 months of age, human infants generate expectations about the sources of some vocalizations, mapping human faces to speech and rhesus faces to rhesus calls. Infants' matching capacity does not appear to be based on a simple associative mechanism or restricted to their specific experiences. We discuss these findings in terms of how infants may achieve such competence, as well as its specificity and relevance to acquiring language.},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena and Druhen, Madelynn J and Hauser, Marc D and Huizink, Anouk T},
	Date-Modified = {2020-06-16 13:45:14 +0200},
	Doi = {10.1073/pnas.0906049106},
	Issn = {1091-6490},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Acoustic Stimulation, Animals, Face, Humans, Infant, Macaca mulatta, Photic Stimulation, Speech, Time Factors, Vocalization, Animal},
	Language = {eng},
	Month = nov,
	Number = {44},
	Pages = {18867--18872},
	Pmid = {19846770},
	Title = {Five-month-old infants' identification of the sources of vocalizations},
	Volume = {106},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1073/pnas.0906049106}}

@article{barlow_possible_1961,
	Author = {Barlow, Horace B.},
	File = {Barlow - 1961 - Possible principles underlying the transformation .pdf:/Users/Cecile/Zotero/storage/Q7RF5ZPJ/Barlow - 1961 - Possible principles underlying the transformation .pdf:application/pdf},
	Journal = {Sensory Communication},
	Pages = {217--234},
	Title = {Possible principles underlying the transformation of sensory messages},
	Year = {1961}}

@article{ghitza_possible_2009,
	Author = {Ghitza, Oded and Greenberg, Steven},
	Doi = {10.1159/000208934},
	File = {Ghitzaetal2009.pdf:/Users/Cecile/Zotero/storage/K9FFKIBB/Ghitzaetal2009.pdf:application/pdf;Phonetica 2009, Vol. 66, No. 1-2 - On the Possible Role of Brain Rhythms in Speech Perception\: Intelligibility of Time-Compressed Speech with Periodic and Aperiodic Insertions of Silence - FullText - Karger Publishers:/Users/Cecile/Zotero/storage/M7WFNFKI/208934.html:text/html},
	Issn = {1423-0321, 0031-8388},
	Journal = {Phonetica},
	Language = {en},
	Number = {1-2},
	Pages = {113--126},
	Shorttitle = {On the {Possible} {Role} of {Brain} {Rhythms} in {Speech} {Perception}},
	Title = {On the {Possible} {Role} of {Brain} {Rhythms} in {Speech} {Perception}: {Intelligibility} of {Time}-{Compressed} {Speech} with {Periodic} and {Aperiodic} {Insertions} of {Silence}},
	Url = {http://www.karger.com/Article/FullText/208934},
	Urldate = {2014-10-21},
	Volume = {66},
	Year = {2009},
	Bdsk-Url-1 = {http://www.karger.com/Article/FullText/208934},
	Bdsk-Url-2 = {https://doi.org/10.1159/000208934}}

@article{mahmoudzadeh_syllabic_2013,
	Abstract = {The ontogeny of linguistic functions in the human brain remains elusive. Although some auditory capacities are described before term, whether and how such immature cortical circuits might process speech are unknown. Here we used functional optical imaging to evaluate the cerebral responses to syllables at the earliest age at which cortical responses to external stimuli can be recorded in humans (28- to 32-wk gestational age). At this age, the cortical organization in layers is not completed. Many neurons are still located in the subplate and in the process of migrating to their final location. Nevertheless, we observed several points of similarity with the adult linguistic network. First, whereas syllables elicited larger right than left responses, the posterior temporal region escaped this general pattern, showing faster and more sustained responses over the left than over the right hemisphere. Second, discrimination responses to a change of phoneme (ba vs. ga) and a change of human voice (male vs. female) were already present and involved inferior frontal areas, even in the youngest infants (29-wk gestational age). Third, whereas both types of changes elicited responses in the right frontal region, the left frontal region only reacted to a change of phoneme. These results demonstrate a sophisticated organization of perisylvian areas at the very onset of cortical circuitry, 3 mo before term. They emphasize the influence of innate factors on regions involved in linguistic processing and social communication in humans.},
	Author = {Mahmoudzadeh, Mahdi and Dehaene-Lambertz, Ghislaine and Fournier, Marc and Kongolo, Guy and Goudjil, Sabrina and Dubois, Jessica and Grebe, Reinhard and Wallois, Fabrice},
	Doi = {10.1073/pnas.1212220110},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BCBUMFCR/Mahmoudzadeh et al. - 2013 - Syllabic discrimination in premature human infants.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8N7FG7ZW/1212220110.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {hemispheric lateralization, hemodynamic response, near infrared spectroscopy, premature human brain, language},
	Language = {en},
	Month = feb,
	Pages = {201212220},
	Pmid = {23440196},
	Title = {Syllabic discrimination in premature human infants prior to complete formation of cortical layers},
	Url = {http://www.pnas.org/content/early/2013/02/19/1212220110},
	Urldate = {2013-10-16},
	Year = {2013},
	Bdsk-Url-1 = {http://www.pnas.org/content/early/2013/02/19/1212220110},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1212220110}}

@article{grossmann_developmental_2010,
	Abstract = {In human adults, voices are processed in specialized brain regions in superior temporal cortices. We examined the development of this cortical organization during infancy by using near-infrared spectroscopy. In experiment 1, 7-month-olds but not 4-month-olds showed increased responses in left and right superior temporal cortex to the human voice when compared to nonvocal sounds, suggesting that voice-sensitive brain systems emerge between 4 and 7 months of age. In experiment 2, 7-month-old infants listened to words spoken with neutral, happy, or angry prosody. Hearing emotional prosody resulted in increased responses in a voice-sensitive region in the right hemisphere. Moreover, a region in right inferior frontal cortex taken to serve evaluative functions in the adult brain showed particular sensitivity to happy prosody. The pattern of findings suggests that temporal regions specialize in processing voices very early in development and that, already in infancy, emotions differentially modulate voice processing in the right hemisphere.},
	Author = {Grossmann, Tobias and Oberecker, Regine and Koch, Stefan Paul and Friederici, Angela D.},
	Doi = {10.1016/j.neuron.2010.03.001},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/S8PDXM32/Grossmann et al. - 2010 - The Developmental Origins of Voice Processing in t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WD8XHDSG/S0896-6273(10)00170-4.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {SYSNEURO},
	Language = {English},
	Month = mar,
	Number = {6},
	Pages = {852--858},
	Pmid = {20346760},
	Title = {The {Developmental} {Origins} of {Voice} {Processing} in the {Human} {Brain}},
	Url = {http://www.cell.com/article/S0896627310001704/abstract},
	Urldate = {2015-01-07},
	Volume = {65},
	Year = {2010},
	Bdsk-Url-1 = {http://www.cell.com/article/S0896627310001704/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2010.03.001}}

@article{futagi_theta_1998,
	Abstract = {In order to specify the locations and to clarify the electrophysiological significance of the transitory rhythmic theta activities detected on scalp electrodes in infants, we performed simultaneous EEG and video recording with power spectral map analysis in 29 normal infants of less than 1 year of age. The rhythmic theta activities appeared in posterior temporal regions with sucking or crying, in the parietal region with gazing, and in the frontal region with handling. Each specific location of the theta rhythm seemed to correspond to the functional localization in the infant's brain. We thus concluded that these rhythmic theta activities might originate from direct cortical activation, or from the cortical activation driven by the neuronal impulses from the limbic system through the connection between that system and the cortex.},
	Author = {Futagi, Yasuyuki and Ishihara, Tsutomu and Tsuda, Kumi and Suzuki, Yasuhiro and Goto, Megumi},
	Doi = {10.1016/S0013-4694(98)00002-9},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/Z5WSCZ9K/Futagi et al. - 1998 - Theta rhythms associated with sucking, crying, gaz.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/6VQEWKQU/S0013469498000029.html:text/html},
	Issn = {0013-4694},
	Journal = {Electroencephalography and Clinical Neurophysiology},
	Keywords = {Power spectral map analysis, EEG, Infants, Theta Rhythm},
	Month = may,
	Number = {5},
	Pages = {392--399},
	Title = {Theta rhythms associated with sucking, crying, gazing and handling in infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S0013469498000029},
	Urldate = {2016-06-02},
	Volume = {106},
	Year = {1998},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0013469498000029},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0013-4694(98)00002-9}}

@article{anne_fernald_four-month-old_1985,
	Author = {{Anne Fernald}},
	File = {Four-month-old infants prefer to listen to motherese:/Users/Cecile/Zotero/storage/D8KIQMCK/S0163638385800059.html:text/html},
	Journal = {Infant Behavior and Development},
	Month = jun,
	Number = {2},
	Pages = {181--195},
	Title = {Four-month-old infants prefer to listen to motherese},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059},
	Urldate = {2014-09-06},
	Volume = {8},
	Year = {1985},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059}}

@article{spence_prenatal_1987,
	Abstract = {By sucking on a nonnutritive nipple in the presence of one discriminative stimulus, newborns were reinforced with a low-pass filtered tape recording of their mothers' voices. Sucking in the presence of a different discriminative stimulus was reinforced with unfiltered maternal-voice recordings. Filtered versions simulated maternal-voice sounds that were available before birth and unfiltered versions simulated maternal-voice sounds available after birth. Newborns in the control group could be reinforced with the same stimuli in the same way, but the voices were unfamiliar to them. Infants hearing their mothers' voices had no preference for either version, but infants hearing the unfamiliar voices preferred the unfiltered version. The difference in the between-groups responsiveness to the low-pass voice samples is consistent with the hypothesis that prenatal experience with low-frequency characteristics of maternal voices influences early postnatal perception of maternal voices.},
	Annote = {meta-analysis},
	Author = {Spence, Melanie J. and DeCasper, Anthony J.},
	Date-Modified = {2020-06-16 13:51:00 +0200},
	Doi = {10.1016/0163-6383(87)90028-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/WAHTJQC4/Spence et DeCasper - 1987 - Prenatal experience with low-frequency maternal-vo.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AIZIMENP/0163638387900282.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Keywords = {auditory preception, auditory preference, maternal voice, newborn perception, prenatal sensory experience, voice perception},
	Month = apr,
	Number = {2},
	Pages = {133--142},
	Title = {Prenatal experience with low-frequency maternal-voice sounds influence neonatal perception of maternal voice samples},
	Url = {http://www.sciencedirect.com/science/article/pii/0163638387900282},
	Urldate = {2016-01-26},
	Volume = {10},
	Year = {1987},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0163638387900282},
	Bdsk-Url-2 = {https://doi.org/10.1016/0163-6383(87)90028-2}}

@article{gervain_prosody_2013,
	Abstract = {A central problem in language acquisition is how children effortlessly acquire the grammar of their native language even though speech provides no direct information about underlying structure. This learning problem is even more challenging for dual language learners, yet bilingual infants master their mother tongues as efficiently as monolinguals do. Here we ask how bilingual infants succeed, investigating the particularly challenging task of learning two languages with conflicting word orders (English: eat an apple versus Japanese: ringo-wo taberu `apple.acc eat'). We show that 7-month-old bilinguals use the characteristic prosodic cues (pitch and duration) associated with different word orders to solve this problem. Thus, the complexity of bilingual acquisition is countered by bilinguals' ability to exploit relevant cues. Moreover, the finding that perceptually available cues like prosody can bootstrap grammatical structure adds to our understanding of how and why infants acquire grammar so early and effortlessly.},
	Author = {Gervain, Judit and Werker, Janet F.},
	Copyright = {{\copyright} 2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/ncomms2430},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3T8TARD2/Gervain et Werker - 2013 - Prosody cues word order in 7-month-old bilingual i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VPNSKMTV/ncomms2430.html:text/html},
	Journal = {Nature Communications},
	Keywords = {Biological sciences, neuroscience},
	Language = {en},
	Month = feb,
	Pages = {1490},
	Title = {Prosody cues word order in 7-month-old bilingual infants},
	Url = {http://www.nature.com/ncomms/journal/v4/n2/full/ncomms2430.html},
	Urldate = {2014-06-02},
	Volume = {4},
	Year = {2013},
	Bdsk-Url-1 = {http://www.nature.com/ncomms/journal/v4/n2/full/ncomms2430.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/ncomms2430}}

@article{nordt_use_2016,
	Abstract = {Repetition suppression paradigms allow a more detailed look at brain functioning than classical paradigms and have been applied vigorously in adult cognitive neuroscience. These paradigms are well suited for studies in the field of developmental cognitive neuroscience as they can be applied without collecting a behavioral response and across all age groups. Furthermore, repetition suppression paradigms can be employed in various neuroscience techniques, such as functional magnetic resonance imaging (fMRI), functional near-infrared spectroscopy (fNIRS), electroencephalography (EEG) and magnetoencephalography (MEG). In the present article we review studies using repetition suppression paradigms in developmental cognitive neuroscience covering the age range from infancy to adolescence. Our first goal is to point out characteristics of developmental repetition suppression effects. In doing so, we discuss the relationship of the direction of repetition effects (suppression vs enhancement) with developmental factors, and address the question how the direction of repetition effects might be related to looking-time effects in behavioral infant paradigms, the most prominently used behavioral measure in infant research. To highlight the potential of repetition suppression paradigms, our second goal is to provide an overview on the insights recently obtained by applying repetition paradigms in neurodevelopmental studies, including research on children with autism spectrum disorders (ASDs). We conclude that repetition suppression paradigms are valuable tools for investigating neurodevelopmental processes, while at the same time we highlight the necessity for further studies that disentangle methodological and developmental factors.},
	Author = {Nordt, Marisa and Hoehl, Stefanie and Weigelt, Sarah},
	Doi = {10.1016/j.cortex.2016.04.002},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GST3AEDS/Nordt et al. - The use of repetition suppression paradigms in dev.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2Q9U2CP4/S0010945216300612.html:text/html},
	Issn = {0010-9452},
	Journal = {Cortex},
	Keywords = {Adaptation, Brain development, Habituation, repetition suppression, Development},
	Title = {The use of repetition suppression paradigms in developmental cognitive neuroscience},
	Url = {http://www.sciencedirect.com/science/article/pii/S0010945216300612},
	Urldate = {2016-05-23},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0010945216300612},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cortex.2016.04.002}}

@article{gervain_neonate_2008,
	Abstract = {What are the origins of the efficient language learning abilities that allow humans to acquire their mother tongue in just a few years very early in life? Although previous studies have identified different mechanisms underlying the acquisition of auditory and speech patterns in older infants and adults, the earliest sensitivities remain unexplored. To address this issue, we investigated the ability of newborns to learn simple repetition-based structures in two optical brain-imaging experiments. In the first experiment, 22 neonates listened to syllable sequences containing immediate repetitions (ABB; e.g., ``mubaba,'' ``penana''), intermixed with random control sequences (ABC; e.g., ``mubage,'' ``penaku''). We found increased responses to the repetition sequences in the temporal and left frontal areas, indicating that the newborn brain differentiated the two patterns. The repetition sequences evoked greater activation than the random sequences during the first few trials, suggesting the presence of an automatic perceptual mechanism to detect repetitions. In addition, over the subsequent trials, activation increased further in response to the repetition sequences but not in response to the random sequences, indicating that recognition of the ABB pattern was enhanced by repeated exposure. In the second experiment, in which nonadjacent repetitions (ABA; e.g., ``bamuba,'' ``napena'') were contrasted with the same random controls, no discrimination was observed. These findings suggest that newborns are sensitive to certain input configurations in the auditory domain, a perceptual ability that might facilitate later language development.},
	Author = {Gervain, Judit and Macagno, Francesco and Cogoi, Silvia and Pe{\~n}a, Marcela and Mehler, Jacques},
	Doi = {10.1073/pnas.0806530105},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/96PUNDAW/Gervain et al. - 2008 - The neonate brain detects speech structure.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/D9TNZ9HQ/14222.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {language acquisition, newborns, optical imaging, perceptual primitives, speech perception, Speech Perception},
	Language = {en},
	Month = sep,
	Number = {37},
	Pages = {14222--14227},
	Pmid = {18768785},
	Title = {The neonate brain detects speech structure},
	Url = {http://www.pnas.org/content/105/37/14222},
	Urldate = {2014-01-20},
	Volume = {105},
	Year = {2008},
	Bdsk-Url-1 = {http://www.pnas.org/content/105/37/14222},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0806530105}}

@article{oherron_neural_2016,
	Abstract = {Neural activation increases blood flow locally. This vascular signal is used by functional imaging techniques to infer the location and strength of neural activity. However, the precise spatial scale over which neural and vascular signals are correlated is unknown. Furthermore, the relative role of synaptic and spiking activity in driving haemodynamic signals is controversial. Previous studies recorded local field potentials as a measure of synaptic activity together with spiking activity and low-resolution haemodynamic imaging. Here we used two-photon microscopy to measure sensory-evoked responses of individual blood vessels (dilation, blood velocity) while imaging synaptic and spiking activity in the surrounding tissue using fluorescent glutamate and calcium sensors. In cat primary visual cortex, where neurons are clustered by their preference for stimulus orientation, we discovered new maps for excitatory synaptic activity, which were organized similarly to those for spiking activity but were less selective for stimulus orientation and direction. We generated tuning curves for individual vessel responses for the first time and found that parenchymal vessels in cortical layer 2/3 were orientation selective. Neighbouring penetrating arterioles had different orientation preferences. Pial surface arteries in cats, as well as surface arteries and penetrating arterioles in rat visual cortex (where orientation maps do not exist), responded to visual stimuli but had no orientation selectivity. We integrated synaptic or spiking responses around individual parenchymal vessels in cats and established that the vascular and neural responses had the same orientation preference. However, synaptic and spiking responses were more selective than vascular responses---vessels frequently responded robustly to stimuli that evoked little to no neural activity in the surrounding tissue. Thus, local neural and haemodynamic signals were partly decoupled. Together, these results indicate that intrinsic cortical properties, such as propagation of vascular dilation between neighbouring columns, need to be accounted for when decoding haemodynamic signals.},
	Author = {O'Herron, Philip and Chhatbar, Pratik Y. and Levy, Manuel and Shen, Zhiming and Schramm, Adrien E. and Lu, Zhongyang and Kara, Prakash},
	Copyright = {{\copyright} 2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/nature17965},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9S9CRFCP/O'Herron et al. - 2016 - Neural correlates of single-vessel haemodynamic re.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VA7VT957/nature17965.html:text/html},
	Issn = {0028-0836},
	Journal = {Nature},
	Language = {en},
	Month = may,
	Title = {Neural correlates of single-vessel haemodynamic responses in vivo},
	Url = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature17965.html},
	Urldate = {2016-05-30},
	Volume = {advance online publication},
	Year = {2016},
	Bdsk-Url-1 = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature17965.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature17965}}

@article{saby_utility_2012,
	Abstract = {Research employing electroencephalographic (EEG) techniques with infants and young children has flourished in recent years due to increased interest in understanding the neural processes involved in early social and cognitive development. This review focuses on the functional characteristics of the alpha, theta, and gamma frequency bands in the developing EEG. Examples of how analyses of EEG band power have been applied to specific lines of developmental research are also discussed. These examples include recent work on the infant mu rhythm and action processing, frontal alpha asymmetry and approach-withdrawal tendencies, and EEG power measures in the study of early psychosocial adversity.},
	Author = {Saby, Joni N. and Marshall, Peter J.},
	Doi = {10.1080/87565641.2011.614663},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/IW5JS6EZ/Saby et Marshall - 2012 - The Utility of EEG Band Power Analysis in the Stud.pdf:application/pdf},
	Issn = {8756-5641},
	Journal = {Developmental Neuropsychology},
	Month = apr,
	Number = {3},
	Pages = {253--273},
	Pmcid = {PMC3347767},
	Pmid = {22545661},
	Title = {The {Utility} of {EEG} {Band} {Power} {Analysis} in the {Study} of {Infancy} and {Early} {Childhood}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3347767/},
	Urldate = {2016-06-02},
	Volume = {37},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3347767/},
	Bdsk-Url-2 = {https://doi.org/10.1080/87565641.2011.614663}}

@article{vouloumanos_tuning_2010,
	Abstract = {Human neonates prefer listening to speech compared to many nonspeech sounds, suggesting that humans are born with a bias for speech. However, neonates' preference may derive from properties of speech that are not unique but instead are shared with the vocalizations of other species. To test this, thirty neonates and sixteen 3-month-olds were presented with nonsense speech and rhesus monkey vocalizations. Neonates showed no preference for speech over rhesus vocalizations but showed a preference for both these sounds over synthetic sounds. In contrast, 3-month-olds preferred speech to rhesus vocalizations. Neonates' initial biases minimally include speech and monkey vocalizations. These listening preferences are sharpened over 3 months, yielding a species-specific preference for speech, paralleling findings on infant face perception.},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena and Hauser, Marc D and Werker, Janet F and Martin, Alia},
	Date-Modified = {2020-06-16 13:47:44 +0200},
	Doi = {10.1111/j.1467-8624.2009.01412.x},
	Issn = {1467-8624},
	Journal = {Child development},
	Keywords = {Acoustic Stimulation, Animals, Arousal, Attention, Auditory Perception, Child Psychology, Choice Behavior, Female, Follow-Up Studies, Humans, Infant, Newborn, Language Development, Macaca mulatta, Male, Sound Spectrography, Vocalization, Animal, speech perception, Speech Perception},
	Language = {eng},
	Month = apr,
	Number = {2},
	Pages = {517--527},
	Pmid = {20438457},
	Title = {The tuning of human neonates' preference for speech},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1111/j.1467-8624.2009.01412.x}}

@article{poeppel_analysis_2003,
	Abstract = {The `asymmetric sampling in time' (AST) hypothesis developed here provides a framework for understanding a range of psychophysical and neuropsychological data on speech perception in the context of a revised cortical functional anatomic model. The AST model is motivated by observations from psychophysics and cognitive neuroscience that speak to the fractionation of auditory processing, in general, and speech perception, in particular. Building on the observations (1) that the speech signal contains more than one time scale relevant to auditory cognition (e.g. time scales commensurate with processing formant transitions versus scales commensurate with syllabicity and intonation contours), and (2) that speech perception is mediated by both left and right auditory cortices, AST suggests a time-based perspective that maintains anatomic symmetry while permitting functional asymmetry. AST proposes that the input speech signal has a neural representation that is bilaterally symmetric at an early representational level. Beyond the initial representation, however, the signal is elaborated asymmetrically in the time domain: left auditory areas preferentially extract information from short (â¼20--40 ms) temporal integration windows. The right hemisphere homologues preferentially extract information from long (â¼150--250 ms) integration windows. It is suggested that temporal integration is reflected as oscillatory neuronal activity in different frequency bands (gamma, theta).},
	Author = {Poeppel, David},
	Doi = {10.1016/S0167-6393(02)00107-3},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/HNMHBJ8I/Poeppel - 2003 - The analysis of speech in different temporal integ.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZCWXHPRH/S0167639302001073.html:text/html},
	Issn = {0167-6393},
	Journal = {Speech Communication},
	Keywords = {Gamma band, Hemispheric asymmetry, Neural basis of speech, Oscillations, Temporal integration, Theta band, Timing, Auditory cortex},
	Month = aug,
	Number = {1},
	Pages = {245--255},
	Series = {The {Nature} of {Speech} {Perception}},
	Shorttitle = {The analysis of speech in different temporal integration windows},
	Title = {The analysis of speech in different temporal integration windows: cerebral lateralization as `asymmetric sampling in time'},
	Url = {http://www.sciencedirect.com/science/article/pii/S0167639302001073},
	Urldate = {2014-10-21},
	Volume = {41},
	Year = {2003},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0167639302001073},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0167-6393(02)00107-3}}

@article{ding_cortical_2014,
	Abstract = {Auditory cortical activity is entrained to the temporal envelope of speech, which corresponds to the syllabic rhythm of speech. Such entrained cortical activity can be measured from subjects naturally listening to sentences or spoken passages, providing a reliable neural marker of online speech processing. A central question still remains to be answered about whether cortical entrained activity is more closely related to speech perception or non-speech-specific auditory encoding. Here, we review a few hypotheses about the functional roles of cortical entrainment to speech, e.g., encoding acoustic features, parsing syllabic boundaries, and selecting sensory information in complex listening environments. It is likely that speech entrainment is not a homogeneous response and these hypotheses apply separately for speech entrainment generated from different neural sources. The relationship between entrained activity and speech intelligibility is also discussed. A tentative conclusion is that theta-band entrainment (4--8 Hz) encodes speech features critical for intelligibility while delta-band entrainment (1--4 Hz) is related to the perceived, non-speech-specific acoustic rhythm. To further understand the functional properties of speech entrainment, a splitter's approach will be needed to investigate (1) not just the temporal envelope but what specific acoustic features are encoded and (2) not just speech intelligibility but what specific psycholinguistic processes are encoded by entrained cortical activity. Similarly, the anatomical and spectro-temporal details of entrained activity need to be taken into account when investigating its functional properties.},
	Author = {Ding, Nai and Simon, Jonathan Z.},
	Doi = {10.3389/fnhum.2014.00311},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/JBXMPBAS/Ding et Simon - 2014 - Cortical entrainment to continuous speech functio.pdf:application/pdf},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {Speech Intelligibility, cocktail party problem, entrainment of rhythms, speech envelope, speech perception in noise, Auditory cortex},
	Pages = {311},
	Shorttitle = {Cortical entrainment to continuous speech},
	Title = {Cortical entrainment to continuous speech: functional roles and interpretations},
	Url = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00311/abstract},
	Urldate = {2015-10-22},
	Volume = {8},
	Year = {2014},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2014.00311/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2014.00311}}

@article{voss_1/f_1978,
	Abstract = {The spectral density of fluctuations in the audio power of many musical selections and of English speech varies approximately as 1/f (f is the frequency) down to a frequency of 5Ã10â4 Hz. This result implies that the audioâpower fluctuations are correlated over all times in the same manner as ''1/f noise'' in electronic components. The frequency fluctuations of music also have a 1/f spectral density at frequencies down to the inverse of the length of the piece of music. The frequency fluctuations of English speech have a quite different behavior, with a single characteristic time of about 0.1 s, the average length of a syllable. The observations on music suggest that 1/fnoise is a good choice for stochastic composition. Compositions in which the frequency and duration of each note were determined by 1/fnoise sources sounded pleasing. Those generated by whiteânoise sources sounded too random, while those generated by 1/f 2noisesounded too correlated.},
	Author = {Voss, Richard F. and Clarke, John},
	Doi = {10.1121/1.381721},
	File = {Snapshot:/Users/Cecile/Zotero/storage/BB8SEDJE/1.html:text/html;voss-clarke.pdf:/Users/Cecile/Zotero/storage/R7J3BBIQ/voss-clarke.pdf:application/pdf},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {1/f noise, Acoustic noise, Acoustic source localization, Electronic devices, Speech},
	Month = jan,
	Number = {1},
	Pages = {258--263},
	Shorttitle = {''1/f noise'' in music},
	Title = {''1/f noise'' in music: {Music} from 1/f noise},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/63/1/10.1121/1.381721},
	Urldate = {2015-12-16},
	Volume = {63},
	Year = {1978},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/63/1/10.1121/1.381721},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.381721}}

@article{remez_2_2008,
	Author = {Remez, Robert E.},
	File = {RemezPercOrg2005.pdf:/Users/Cecile/Zotero/storage/WF3IT8EP/RemezPercOrg2005.pdf:application/pdf},
	Journal = {The handbook of speech perception},
	Pages = {28},
	Title = {2 {Perceptual} {Organization} of {Speech}},
	Url = {http://books.google.com/books?hl=en&lr=&id=EwY15naRiFgC&oi=fnd&pg=PA28&dq=%22perception+obliges+the+models+to+admit+severe+and+unintended+constraints%22+%22speech+alone,+there+has+been+a+plausible+and+convenient+way+to+persist%22+%22constituents+of+a+speech+signal,+the+perceptual+organization+of+speech%22+&ots=0NZ9A87_aO&sig=auGhQjQdfpaL6lJfH_ONOmQv0_s},
	Urldate = {2015-10-02},
	Year = {2008},
	Bdsk-Url-1 = {http://books.google.com/books?hl=en&lr=&id=EwY15naRiFgC&oi=fnd&pg=PA28&dq=%22perception+obliges+the+models+to+admit+severe+and+unintended+constraints%22+%22speech+alone,+there+has+been+a+plausible+and+convenient+way+to+persist%22+%22constituents+of+a+speech+signal,+the+perceptual+organization+of+speech%22+&ots=0NZ9A87_aO&sig=auGhQjQdfpaL6lJfH_ONOmQv0_s}}

@article{gomez_language_2014,
	Abstract = {The evolution of human languages is driven both by primitive biases present in the human sensorimotor systems and by cultural transmission among speakers. However, whether the design of the language faculty is further shaped by linguistic biological biases remains controversial. To address this question, we used near-infrared spectroscopy to examine whether the brain activity of neonates is sensitive to a putatively universal phonological constraint. Across languages, syllables like blif are preferred to both lbif and bdif. Newborn infants (2--5 d old) listening to these three types of syllables displayed distinct hemodynamic responses in temporal-perisylvian areas of their left hemisphere. Moreover, the oxyhemoglobin concentration changes elicited by a syllable type mirrored both the degree of its preference across languages and behavioral linguistic preferences documented experimentally in adulthood. These findings suggest that humans possess early, experience-independent, linguistic biases concerning syllable structure that shape language perception and acquisition.},
	Author = {G{\'o}mez, David Maximiliano and Berent, Iris and Benavides-Varela, Silvia and Bion, Ricardo A. H. and Cattarossi, Luigi and Nespor, Marina and Mehler, Jacques},
	Doi = {10.1073/pnas.1318261111},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/SKNV7WIX/G{\'o}mez et al. - 2014 - Language universals at birth.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/VMJPRHQN/G{\'o}mez et al. - 2014 - Language universals at birth.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MXGT7I9P/5837.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/NMXGMN4J/5837.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {NIRS, Phonology, human newborns, sonority, speech perception, Speech Perception},
	Language = {en},
	Month = apr,
	Number = {16},
	Pages = {5837--5841},
	Pmid = {24706790},
	Title = {Language universals at birth},
	Url = {http://www.pnas.org/content/111/16/5837},
	Urldate = {2015-01-05},
	Volume = {111},
	Year = {2014},
	Bdsk-Url-1 = {http://www.pnas.org/content/111/16/5837},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1318261111}}

@article{querleu_fetal_1988,
	Abstract = {The fetus can hear during the last trimester of pregnancy. Consistent responses to acoustic stimuli have been observed from 28 weeks onwards. Animal experiments as well as investigations in the human lead to the conclusion that sounds from outside the mother are attenuated, but rarely by more than 30 decibels; external conversations are audible. Only 30\% of the phonetic information is available to the fetus, but intonation is almost perfectly transmitted to the amniotic sac. Evidence is accumulating that the mother's voice or different sound patterns from the same voice are learnt by the fetus. Thus there are indications that short-term auditory memory may be present by the end of pregnancy.},
	Author = {Querleu, Denis and Renard, Xavier and Versyp, Fabienne and Paris-Delrue, Laurence and Cr{\`e}pin, Gilles},
	Doi = {10.1016/0028-2243(88)90030-5},
	File = {1-s2.0-0028224388900305-main.pdf:/Users/Cecile/Zotero/storage/5ER53AI3/1-s2.0-0028224388900305-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4EVU6CKR/0028224388900305.html:text/html},
	Issn = {0301-2115},
	Journal = {European Journal of Obstetrics \& Gynecology and Reproductive Biology},
	Keywords = {Attachment, Developmental neurology, Fetal hearing, Fetal reactivity},
	Month = jul,
	Number = {3},
	Pages = {191--212},
	Title = {Fetal hearing},
	Url = {http://www.sciencedirect.com/science/article/pii/0028224388900305},
	Urldate = {2016-01-26},
	Volume = {28},
	Year = {1988},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0028224388900305},
	Bdsk-Url-2 = {https://doi.org/10.1016/0028-2243(88)90030-5}}

@article{noauthor_development_2000,
	Abstract = {JPER is a multi-disciplinary journal that promotes the health of the preterm infant.},
	Copyright = {{\copyright} 2000 Nature Publishing Group},
	Doi = {10.1038/sj.jp.7200439},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/97M3ZAWE/2000 - Development of the Ear and Hearing.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DA5SS8HS/7200439a.html:text/html},
	Journal = {, Published online: 01 December 2000; {\textbar} doi:10.1038/sj.jp.7200439},
	Language = {en},
	Month = dec,
	Title = {Development of the {Ear} and {Hearing}},
	Url = {http://www.nature.com/jp/journal/v20/n1s/abs/7200439a.html},
	Urldate = {2015-04-01},
	Volume = {20},
	Year = {2000},
	Bdsk-Url-1 = {http://www.nature.com/jp/journal/v20/n1s/abs/7200439a.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/sj.jp.7200439}}

@article{decasper_human_1980,
	Abstract = {By sucking on a nonnutritive nipple in different ways, a newborn human could produce either its mother's voice or the voice of another female. Infants learned how to produce the mother's voice and produced it more often than the other voice. The neonate's preference for the maternal voice suggests that the period shortly after birth may be important for initiating infant bonding to the mother.},
	Author = {DeCasper, A. J. and Fifer, W. P.},
	Copyright = {{\copyright} 1980},
	Doi = {10.1126/science.7375928},
	File = {Snapshot:/Users/Cecile/Zotero/storage/GTTGVNWM/1174.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jun,
	Number = {4448},
	Pages = {1174--1176},
	Pmid = {7375928},
	Shorttitle = {Of human bonding},
	Title = {Of human bonding: newborns prefer their mothers' voices},
	Url = {http://science.sciencemag.org/content/208/4448/1174},
	Urldate = {2016-02-01},
	Volume = {208},
	Year = {1980},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/208/4448/1174},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.7375928}}

@article{kayser_rhythmic_2015,
	Abstract = {The phase of low-frequency network activity in the auditory cortex captures changes in neural excitability, entrains to the temporal structure of natural sounds, and correlates with the perceptual performance in acoustic tasks. Although these observations suggest a causal link between network rhythms and perception, it remains unknown how precisely they affect the processes by which neural populations encode sounds. We addressed this question by analyzing neural responses in the auditory cortex of anesthetized rats using stimulus--response models. These models included a parametric dependence on the phase of local field potential rhythms in both stimulus-unrelated background activity and the stimulus--response transfer function. We found that phase-dependent models better reproduced the observed responses than static models, during both stimulation with a series of natural sounds and epochs of silence. This was attributable to two factors: (1) phase-dependent variations in background firing (most prominent for delta; 1--4 Hz); and (2) modulations of response gain that rhythmically amplify and attenuate the responses at specific phases of the rhythm (prominent for frequencies between 2 and 12 Hz). These results provide a quantitative characterization of how slow auditory cortical rhythms shape sound encoding and suggest a differential contribution of network activity at different timescales. In addition, they highlight a putative mechanism that may implement the selective amplification of appropriately timed sound tokens relative to the phase of rhythmic auditory cortex activity.},
	Author = {Kayser, Christoph and Wilson, Caroline and Safaai, Houman and Sakata, Shuzo and Panzeri, Stefano},
	Doi = {10.1523/JNEUROSCI.0268-15.2015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8G7V78MT/Kayser et al. - 2015 - Rhythmic Auditory Cortex Activity at Multiple Time.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4IUQPJ4M/7750.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Keywords = {LNP models, information coding, network state, neural coding, receptive fields, Delta Rhythm},
	Language = {en},
	Month = may,
	Number = {20},
	Pages = {7750--7762},
	Title = {Rhythmic {Auditory} {Cortex} {Activity} at {Multiple} {Timescales} {Shapes} {Stimulus}--{Response} {Gain} and {Background} {Firing}},
	Url = {http://www.jneurosci.org/content/35/20/7750},
	Urldate = {2015-05-26},
	Volume = {35},
	Year = {2015},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/35/20/7750},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.0268-15.2015}}

@article{atencio_hierarchical_2009,
	Abstract = {Sensory cortical anatomy has identified a canonical microcircuit underlying computations between and within layers. This feed-forward circuit processes information serially from granular to supragranular and to infragranular layers. How this substrate correlates with an auditory cortical processing hierarchy is unclear. We recorded simultaneously from all layers in cat primary auditory cortex (AI) and estimated spectrotemporal receptive fields (STRFs) and associated nonlinearities. Spike-triggered averaged STRFs revealed that temporal precision, spectrotemporal separability, and feature selectivity varied with layer according to a hierarchical processing model. STRFs from maximally informative dimension (MID) analysis confirmed hierarchical processing. Of two cooperative MIDs identified for each neuron, the first comprised the majority of stimulus information in granular layers. Second MID contributions and nonlinear cooperativity increased in supragranular and infragranular layers. The AI microcircuit provides a valid template for three independent hierarchical computation principles. Increases in processing complexity, STRF cooperativity, and nonlinearity correlate with the synaptic distance from granular layers.},
	Author = {Atencio, Craig A. and Sharpee, Tatyana O. and Schreiner, Christoph E.},
	Doi = {10.1073/pnas.0908383106},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RK3R3QWV/Atencio et al. - 2009 - Hierarchical computation in the canonical auditory.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MBBEX89C/21894.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {cortical laminae, information, spectrotemporal receptive field, Auditory cortex},
	Language = {en},
	Month = dec,
	Number = {51},
	Pages = {21894--21899},
	Pmid = {19918079},
	Title = {Hierarchical computation in the canonical auditory cortical circuit},
	Url = {http://www.pnas.org/content/106/51/21894},
	Urldate = {2015-05-22},
	Volume = {106},
	Year = {2009},
	Bdsk-Url-1 = {http://www.pnas.org/content/106/51/21894},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0908383106}}

@article{hepper_development_1994,
	Abstract = {Previous research has revealed that the human fetus responds to sound, but to date there has been little systematic investigation of the development of fetal hearing. The development of fetal behavioural responsiveness to pure tone auditory stimuli (100 Hz, 250 Hz, 500 Hz, 1000 Hz, and 3000 Hz) was examined from 19 to 35 weeks of gestational age. Stimuli were presented by a loudspeaker placed on the maternal abdomen and the fetus's response, a movement, recorded by ultrasound. The fetus responded first to the 500 Hz tone, where the first response was observed at 19 weeks of gestational age. The range of frequencies responded to expanded first downwards to lower frequencies, 100 Hz and 250 Hz, and then upwards to higher frequencies, 1000 Hz and 3000 Hz. At 27 weeks of gestational age, 96\% of fetuses responded to the 250 Hz and 500 Hz tones but none responded to the 1000 Hz and 3000 Hz tones. Responsiveness to 1000 Hz and 3000 Hz tones was observed in all fetuses at 33 and 35 weeks of gestational age, respectively. For all frequencies there was a large decrease (20-30 dB) in the intensity level required to elicit a response as the fetus matured. The observed pattern of behavioural responsiveness reflects underlying maturation of the auditory system. The sensitivity of the fetus to sounds in the low frequency range may promote language acquisition and result in increased susceptibility to auditory system damage arising from exposure to intense low frequency sounds.},
	Author = {Hepper, Peter G and Shahidullah, B Sara},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/KAT78TV6/Hepper et Shahidullah - 1994 - Development of fetal hearing.pdf:application/pdf},
	Issn = {1359-2998},
	Journal = {Archives of Disease in Childhood Fetal and Neonatal edition},
	Month = sep,
	Number = {2},
	Pages = {F81--F87},
	Pmcid = {PMC1061088},
	Pmid = {7979483},
	Title = {Development of fetal hearing},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1061088/},
	Urldate = {2015-04-01},
	Volume = {71},
	Year = {1994},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1061088/}}

@article{saoud_brainspeech_2012,
	Abstract = {Asymmetry in auditory cortical oscillations could play a role in speech perception by fostering hemispheric triage of information across the two hemispheres. Due to this asymmetry, fast speech temporal modulations relevant for phonemic analysis could be best perceived by the left auditory cortex, while slower modulations conveying vocal and paralinguistic information would be better captured by the right one. It is unclear, however, whether and how early oscillation-based selection influences speech perception. Using a dichotic listening paradigm in human participants, where we provided different parts of the speech envelope to each ear, we show that word recognition is facilitated when the temporal properties of speech match the rhythmic properties of auditory cortices. We further show that the interaction between speech envelope and auditory cortices rhythms translates in their level of neural activity (as measured with fMRI). In the left auditory cortex, the neural activity level related to stimulus--brain rhythm interaction predicts speech perception facilitation. These data demonstrate that speech interacts with auditory cortical rhythms differently in right and left auditory cortex, and that in the latter, the interaction directly impacts speech perception performance.},
	Author = {Saoud, Houda and Josse, Goulven and Bertasi, Eric and Truy, Eric and Chait, Maria and Giraud, Anne-Lise},
	Doi = {10.1523/JNEUROSCI.3970-11.2012},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UMBIN5FF/Saoud et al. - 2012 - Brain--Speech Alignment Enhances Auditory Cortical .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DTZD2493/275.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = apr,
	Number = {1},
	Pages = {275--281},
	Pmid = {22219289},
	Title = {Brain--{Speech} {Alignment} {Enhances} {Auditory} {Cortical} {Responses} and {Speech} {Perception}},
	Url = {http://www.jneurosci.org/content/32/1/275},
	Urldate = {2015-01-07},
	Volume = {32},
	Year = {2012},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/32/1/275},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.3970-11.2012}}

@article{steinschneider_representation_2013,
	Abstract = {Successful categorization of phonemes in speech requires that the brain analyze the acoustic signal along both spectral and temporal dimensions. Neural encoding of the stimulus amplitude envelope is critical for parsing the speech stream into syllabic units. Encoding of voice onset time (VOT) and place of articulation (POA), cues necessary for determining phonemic identity, occurs within shorter time frames. An unresolved question is whether the neural representation of speech is based on processing mechanisms that are unique to humans and shaped by learning and experience, or is based on rules governing general auditory processing that are also present in non-human animals. This question was examined by comparing the neural activity elicited by speech and other complex vocalizations in primary auditory cortex of macaques, who are limited vocal learners, with that in Heschl's gyrus, the putative location of primary auditory cortex in humans. Entrainment to the amplitude envelope is neither specific to humans nor to human speech. VOT is represented by responses time-locked to consonant release and voicing onset in both humans and monkeys. Temporal representation of VOT is observed both for isolated syllables and for syllables embedded in the more naturalistic context of running speech. The fundamental frequency of male speakers is represented by more rapid neural activity phase-locked to the glottal pulsation rate in both humans and monkeys. In both species, the differential representation of stop consonants varying in their POA can be predicted by the relationship between the frequency selectivity of neurons and the onset spectra of the speech sounds. These findings indicate that the neurophysiology of primary auditory cortex is similar in monkeys and humans despite their vastly different experience with human speech, and that Heschl's gyrus is engaged in general auditory, and not language-specific, processing.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	Author = {Steinschneider, Mitchell and Nourski, Kirill V. and Fishman, Yonatan I.},
	Doi = {10.1016/j.heares.2013.05.013},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SSE3WWW4/Steinschneider et al. - 2013 - Representation of speech in human auditory cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/FZGPASR2/S0378595513001433.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = nov,
	Pages = {57--73},
	Series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	Shorttitle = {Representation of speech in human auditory cortex},
	Title = {Representation of speech in human auditory cortex: {Is} it special?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513001433},
	Urldate = {2014-10-31},
	Volume = {305},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001433},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.05.013}}

@article{benson_parametrically_2001,
	Abstract = {Candidate brain regions constituting a neural network for preattentive phonetic perception were identified with fMRI and multivariate multiple regression of imaging data. Stimuli contrasted along speech/nonspeech, acoustic, or phonetic complexity (three levels each) and natural/synthetic dimensions. Seven distributed brain regions' activity correlated with speech and speech complexity dimensions, including five left-sided foci [posterior superior temporal gyrus (STG), angular gyrus, ventral occipitotemporal cortex, inferior/posterior supramarginal gyrus, and middle frontal gyrus (MFG)] and two right-sided foci (posterior STG and anterior insula). Only the left MFG discriminated natural and synthetic speech. The data also supported a parallel rather than serial model of auditory speech and nonspeech perception.},
	Author = {Benson, Randall R. and Whalen, D. H. and Richardson, Matthew and Swainson, Brook and Clark, Vincent P. and Lai, Song and Liberman, Alvin M.},
	Doi = {10.1006/brln.2001.2484},
	File = {Bensonetal2001.pdf:/Users/Cecile/Zotero/storage/2Q38P758/Bensonetal2001.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8B5A7NRR/S0093934X01924848.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Keywords = {Imaging, Key Words: brain, Perception, Speech, Wernicke, auditory, fMRI, parametric, phonetic, language},
	Month = sep,
	Number = {3},
	Pages = {364--396},
	Title = {Parametrically {Dissociating} {Speech} and {Nonspeech} {Perception} in the {Brain} {Using} {fMRI}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X01924848},
	Urldate = {2014-10-21},
	Volume = {78},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X01924848},
	Bdsk-Url-2 = {https://doi.org/10.1006/brln.2001.2484}}

@article{wild_adult-like_2017,
	Abstract = {Functional neuroimaging has been used to show that the developing auditory cortex of very young human infants responds, in some way, to sound. However, impoverished stimuli and uncontrolled designs have made it difficult to attribute brain responses to specific auditory features, and thus made it difficult to assess the maturity of feature tuning in auditory cortex. To address this, we used functional magnetic resonance imaging (fMRI) to measure the brain activity evoked by naturalistic sounds (a series of sung lullabies) in two groups of infants (3 and 9 months) and adults. We developed a novel analysis method -- inter-subject regression (ISR) -- to quantify the similarity of cortical responses between infants and adults, and to decompose components of the response due to different auditory features. We found that the temporal pattern of activity in infant auditory cortex shared similarity with adults. Some of this shared response could be attributed to simple acoustic features, such as frequency, pitch, envelope, but other parts were not, suggesting that even more complex adult-like features are represented in auditory cortex in early infancy.},
	Author = {Wild, Conor J. and Linke, Annika C. and Zubiaurre-Elorza, Leire and Herzmann, Charlotte and Duffy, Hester and Han, Victor K. and Lee, David S. C. and Cusack, Rhodri},
	Doi = {10.1016/j.neuroimage.2017.06.038},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9HSDS4PK/S1053811917305062.html:text/html;Wild et al. - 2017 - Adult-like processing of naturalistic sounds in au.pdf:/Users/Cecile/Zotero/storage/DZ8UWJWA/Wild et al. - 2017 - Adult-like processing of naturalistic sounds in au.pdf:application/pdf},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = aug,
	Number = {Supplement C},
	Pages = {623--634},
	Title = {Adult-like processing of naturalistic sounds in auditory cortex by 3- and 9-month old infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811917305062},
	Volume = {157},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811917305062},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2017.06.038}}

@article{aslin_methodological_2005,
	Abstract = {Studies of cognitive development in human infants have relied almost entirely on descriptive data at the behavioral level -- the age at which a particular ability emerges. The underlying mechanisms of cognitive development remain largely unknown, despite attempts to correlate behavioral states with brain states. We argue that research on cognitive development must focus on theories of learning, and that these theories must reveal both the computational principles and the set of constraints that underlie developmental change. We discuss four specific issues in infant learning that gain renewed importance in light of this opinion.},
	Author = {Aslin, Richard N. and Fiser, J{\'o}zsef},
	Doi = {10.1016/j.tics.2005.01.003},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UN7M4VGI/Aslin et Fiser - 2005 - Methodological challenges for understanding cognit.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GCH78ZSX/S1364661305000227.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Month = mar,
	Number = {3},
	Pages = {92--98},
	Series = {Special issue: {Developmental} cognitive neuroscience},
	Title = {Methodological challenges for understanding cognitive development in infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S1364661305000227},
	Urldate = {2014-09-25},
	Volume = {9},
	Year = {2005},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661305000227},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2005.01.003}}

@article{liberman_specialization_1989,
	Abstract = {The processes that underlie perception of consonants and vowels are specifically phonetic, distinct from those that localize sources and assign auditory qualities to the sound from each source. This specialization, or module, increases the rate of information flow, establishes the parity between sender and receiver that every communication system must have, and provides for the natural development of phonetic structures in the species and in the individual. The phonetic module has certain properties in common with modules that are "closed" (for example, sound localization or echo ranging in bats) and, like other members of this class, is so placed in the architecture of the auditory system as to preempt information that is relevant to its special function. Accordingly, this information is not available to such "open" modules as those for pitch, loudness, and timbre.},
	Author = {Liberman, A. M. and Mattingly, I. G.},
	Doi = {10.1126/science.2643163},
	File = {Liberman et Mattingly - 1989 - A specialization for speech perception.pdf:/Users/Cecile/Zotero/storage/SU3YFIP3/Liberman et Mattingly - 1989 - A specialization for speech perception.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PCRQBNDK/489.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jan,
	Number = {4890},
	Pages = {489--494},
	Pmid = {2643163},
	Title = {A specialization for speech perception},
	Url = {http://www.sciencemag.org/content/243/4890/489},
	Urldate = {2014-06-01},
	Volume = {243},
	Year = {1989},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/243/4890/489},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.2643163}}

@article{adank_perceptual_2009,
	Abstract = {Speakers vary their speech rate considerably during a conversation, and listeners are able to quickly adapt to these variations in speech rate. Adaptation to fast speech rates is usually measured using artificially time-compressed speech. This study examined adaptation to two types of fast speech: artificially time-compressed speech and natural fast speech. Listeners performed a speeded sentence verification task on three series of sentences: normal-speed sentences, time-compressed sentences, and natural fast sentences. Listeners were divided into two groups to evaluate the possibility of transfer of learning between the time-compressed and natural fast conditions. The first group verified the natural fast before the time-compressed sentences, while the second verified the time-compressed before the natural fast sentences. The results showed transfer of learning when the time-compressed sentences preceded the natural fast sentences, but not when natural fast sentences preceded the time-compressed sentences. The results are discussed in the framework of theories on perceptual learning. Second, listeners show adaptation to the natural fast sentences, but performance for this type of fast speech does not improve to the level of time-compressed sentences.},
	Author = {Adank, Patti and Janse, Esther},
	Doi = {10.1121/1.3216914},
	File = {AdankJanse_JASA09.pdf:/Users/Cecile/Zotero/storage/823D88AS/AdankJanse_JASA09.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NQV5KZR5/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Acoustics, Spectral properties, Speech, Speech analysis, Time measurement},
	Month = nov,
	Number = {5},
	Pages = {2649--2659},
	Title = {Perceptual learning of time-compressed and natural fast speech},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/126/5/10.1121/1.3216914},
	Urldate = {2014-10-21},
	Volume = {126},
	Year = {2009},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/126/5/10.1121/1.3216914},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.3216914}}

@article{rankin_fractal_2014,
	Abstract = {1/f serial correlations and statistical self-similarity (fractal structure) have been measured in various dimensions of musical compositions. Musical performances also display 1/f properties in expressive tempo fluctuations, and listeners predict tempo changes when synchronizing. Here the authors show that the 1/f structure is sufficient for listeners to predict the onset times of upcoming musical events. These results reveal what information listeners use to anticipate events in complex, non-isochronous acoustic rhythms, and this will entail innovative models of temporal synchronization. This finding could improve therapies for Parkinson\&apos;s and related disorders and inform deeper understanding of how endogenous neural rhythms anticipate events in complex, temporally structured communication signals.},
	Author = {Rankin, Summer K. and Fink, Philip W. and Large, Edward W.},
	Doi = {10.1121/1.4890198},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CM6ASTSW/Rankin et al. - 2014 - Fractal structure enables temporal prediction in m.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZM9APUJ5/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Acoustic modeling, Fractals, Musical analysis, Pitch, Time series analysis},
	Month = oct,
	Number = {4},
	Pages = {EL256--EL262},
	Title = {Fractal structure enables temporal prediction in music},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/136/4/10.1121/1.4890198},
	Urldate = {2014-10-31},
	Volume = {136},
	Year = {2014},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/136/4/10.1121/1.4890198},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.4890198}}

@article{joanisse_sensitivity_2014,
	Abstract = {Functional Magnetic Resonance Imaging (fMRI) was used to investigate the extent, magnitude, and pattern of brain activity in response to rapid frequency-modulated sounds. We examined this by manipulating the direction (rise vs. fall) and the rate (fast vs. slow) of the apparent pitch of iterated rippled noise (IRN) bursts. Acoustic parameters were selected to capture features used in phoneme contrasts, however the stimuli themselves were not perceived as speech per se. Participants were scanned as they passively listened to sounds in an event-related paradigm. Univariate analyses revealed a greater level and extent of activation in bilateral auditory cortex in response to frequency-modulated sweeps compared to steady-state sounds. This effect was stronger in the left hemisphere. However, no regions showed selectivity for either rate or direction of frequency modulation. In contrast, multivoxel pattern analysis (MVPA) revealed feature-specific encoding for direction of modulation in auditory cortex bilaterally. Moreover, this effect was strongest when analyses were restricted to anatomical regions lying outside Heschl's gyrus. We found no support for feature-specific encoding of frequency modulation rate. Differential findings of modulation rate and direction of modulation are discussed with respect to their relevance to phonetic discrimination.},
	Author = {Joanisse, Marc F. and DeSouza, Diedre D.},
	Doi = {10.3389/fnins.2014.00306},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/FHAGNGU9/Joanisse et DeSouza - 2014 - Sensitivity of human auditory cortex to rapid freq.pdf:application/pdf},
	Issn = {1662-4548},
	Journal = {Frontiers in Neuroscience},
	Month = sep,
	Pmcid = {PMC4179761},
	Pmid = {25324713},
	Title = {Sensitivity of human auditory cortex to rapid frequency modulation revealed by multivariate representational similarity analysis},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4179761/},
	Urldate = {2014-10-31},
	Volume = {8},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4179761/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2014.00306}}

@article{carruthers_emergence_2015,
	Author = {Carruthers, Isaac M. and Laplagne, Diego A. and Jaegle, Andrew and Briguglio, John and Mwilambwe-Tshilobo, Laetitia and Natan, Ryan G. and Geffen, Maria Neimark},
	Doi = {10.1152/jn.00095.2015},
	File = {2726.full.pdf:/Users/Cecile/Zotero/storage/BRZ55V79/2726.full.pdf:application/pdf;Carruthers2015_Figures.pdf:/Users/Cecile/Zotero/storage/737CUTBZ/Carruthers2015_Figures.pdf:application/pdf},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = aug,
	Pages = {jn.00095.2015},
	Title = {Emergence of invariant representation of vocalizations in the auditory cortex.},
	Url = {http://jn.physiology.org.gate1.inist.fr/lens/jn/114/5/2726},
	Urldate = {2016-01-13},
	Year = {2015},
	Bdsk-Url-1 = {http://jn.physiology.org.gate1.inist.fr/lens/jn/114/5/2726},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00095.2015}}

@article{leong_infant-directed_2014,
	Author = {Leong, Victoria and Kalashnikova, Marina and Burnham, Denis and Goswami, Usha},
	File = {Leongetal2014.pdf:/Users/Cecile/Zotero/storage/JEI6SZIQ/Leongetal2014.pdf:application/pdf},
	Journal = {Int Speech Commun Assoc},
	Pages = {2563--7},
	Title = {Infant-directed speech enhances temporal rhythmic structure in the envelope},
	Url = {http://mazsola.iit.uni-miskolc.hu/~czap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140053.PDF},
	Urldate = {2015-10-02},
	Volume = {2014},
	Year = {2014},
	Bdsk-Url-1 = {http://mazsola.iit.uni-miskolc.hu/~czap/letoltes/IS14/IS2014/PDF/AUTHOR/IS140053.PDF}}

@article{wolf_progress_2007,
	Author = {Wolf, Martin and Ferrari, Marco and Quaresima, Valentina},
	Doi = {10.1117/1.2804899},
	Issn = {1083-3668},
	Journal = {Journal of Biomedical Optics},
	Language = {en},
	Month = nov,
	Number = {6},
	Pages = {062104},
	Title = {Progress of near-infrared spectroscopy and topography for brain and muscle clinical applications},
	Url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.2804899},
	Urldate = {2017-12-07},
	Volume = {12},
	Year = {2007},
	Bdsk-Url-1 = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.2804899},
	Bdsk-Url-2 = {https://doi.org/10.1117/1.2804899}}

@article{homae_neural_2014,
	Abstract = {Infants often pay special attention to speech sounds, and they appear to detect key features of these sounds. To investigate the neural foundation of speech perception in infants, we measured cortical activation using near-infrared spectroscopy. We presented the following three types of auditory stimuli while 3-month-old infants watched a silent movie: (1) normal speech sounds; (2) sine wave speech (SWS) sounds consisting of three sine waves that tracked the first, second, and third formants of speech sounds; and (3) synthesized tones composed of three pure tones. Statistical analyses of oxygenated hemoglobin (oxy-Hb) signals revealed significant activation in the left and right auditory areas in all conditions. Direct comparisons of oxy-Hb signal changes between SWS and synthesized tones showed significant differences in the left frontal and temporal regions. Furthermore, comparisons of oxy-Hb signal changes between speech sounds and SWS exhibited significant differences in a left posterior temporal region. These results demonstrated that functional differentiation occurs in the left temporal cortex while infants perceive different types of auditory information. Coactivation of the left temporal and frontal regions by speech sounds suggests the initial formation of a left fronto-temporal network related to infant speech processing. Clarification of the functional role of this left-lateralized network will help understand the speech code.},
	Author = {Homae, Fumitaka and Watanabe, Hama and Taga, Gentaro},
	Copyright = {{\copyright} 2014 Language Learning Research Club, University of Michigan},
	Doi = {10.1111/lang.12076},
	File = {homae14.pdf:/Users/Cecile/Zotero/storage/CXMVXRSW/homae14.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2ATGI3NU/abstract.html:text/html},
	Issn = {1467-9922},
	Journal = {Language Learning},
	Keywords = {Functional connectivity, NIRS, developing brain, formant, functional differentiation, language acquisition, language network, speech sounds},
	Language = {en},
	Month = sep,
	Number = {s2},
	Pages = {6--26},
	Title = {The {Neural} {Substrates} of {Infant} {Speech} {Perception}},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/lang.12076/abstract},
	Urldate = {2014-09-06},
	Volume = {64},
	Year = {2014},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/lang.12076/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/lang.12076}}

@article{bennur_understanding_2013,
	Abstract = {Acoustic communication between animals requires them to detect, discriminate, and categorize conspecific or heterospecific vocalizations in their natural environment. Laboratory studies of the auditory-processing abilities that facilitate these tasks have typically employed a broad range of acoustic stimuli, ranging from natural sounds like vocalizations to ``artificial'' sounds like pure tones and noise bursts. However, even when using vocalizations, laboratory studies often test abilities like categorization in relatively artificial contexts. Consequently, it is not clear whether neural and behavioral correlates of these tasks (1) reflect extensive operant training, which drives plastic changes in auditory pathways, or (2) the innate capacity of the animal and its auditory system. Here, we review a number of recent studies, which suggest that adopting more ethological paradigms utilizing natural communication contexts are scientifically important for elucidating how the auditory system normally processes and learns communication sounds. Additionally, since learning the meaning of communication sounds generally involves social interactions that engage neuromodulatory systems differently than laboratory-based conditioning paradigms, we argue that scientists need to pursue more ethological approaches to more fully inform our understanding of how the auditory system is engaged during acoustic communication.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	Author = {Bennur, Sharath and Tsunada, Joji and Cohen, Yale E. and Liu, Robert C.},
	Doi = {10.1016/j.heares.2013.08.008},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PWUI4ZPM/Bennur et al. - 2013 - Understanding the neurophysiological basis of audi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/39GTTUPF/S0378595513001998.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = nov,
	Pages = {3--9},
	Series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	Shorttitle = {Understanding the neurophysiological basis of auditory abilities for social communication},
	Title = {Understanding the neurophysiological basis of auditory abilities for social communication: {A} perspective on the value of ethological paradigms},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	Urldate = {2014-10-31},
	Volume = {305},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.08.008}}

@article{dupoux_perceptual_1997,
	Abstract = {This study investigated the perceptual adjustments that occur when listeners recognize highly compressed speech. In Experiment 1, adjustment was examined as a function of the amount of exposure to compressed speech by use of 2 different speakers and compression rates. The results demonstrated that adjustment takes place over a number of sentences, depending on the compression rate. Lower compression rates required less experience before full adjustment occurred. In Experiment 2, the impact of an abrupt change in talker characteristics was investigated; in Experiment 3, the impact of an abrupt change in compression rate was studied. The results of these 2 experiments indicated that sudden changes in talker characteristics or compression rate had little impact on the adjustment process. The findings are discussed with respect to the level of speech processing at which such adjustment might occur.},
	Author = {Dupoux, Emmanuel and Green, Kerry},
	Copyright = {(c) 2012 APA, all rights reserved},
	Doi = {10.1037/0096-1523.23.3.914},
	File = {Dupoux_Green_1997_adaptation_speech_compression.JEPHPP.pdf:/Users/Cecile/Zotero/storage/ZJ28JZWI/Dupoux_Green_1997_adaptation_speech_compression.JEPHPP.pdf:application/pdf},
	Issn = {1939-1277(Electronic);0096-1523(Print)},
	Journal = {Journal of Experimental Psychology: Human Perception and Performance},
	Keywords = {*Compressed Speech, *Speech Characteristics, *Speech Perception, Verbal Stimuli},
	Number = {3},
	Pages = {914--927},
	Shorttitle = {Perceptual adjustment to highly compressed speech},
	Title = {Perceptual adjustment to highly compressed speech: {Effects} of talker and rate changes},
	Volume = {23},
	Year = {1997},
	Bdsk-Url-1 = {https://doi.org/10.1037/0096-1523.23.3.914}}

@article{ghitza_linking_2011,
	Abstract = {The premise of this study is that current models of speech perception, which are driven by acoustic features alone, are incomplete, and that the role of decoding time during memory access must be incorporated to account for the patterns of observed recognition phenomena. It is postulated that decoding time is governed by a cascade of neuronal oscillators, which guide template-matching operations at a hierarchy of temporal scales. Cascaded cortical oscillations in the theta, beta, and gamma frequency bands are argued to be crucial for speech intelligibility. Intelligibility is high so long as these oscillations remain phase locked to the auditory input rhythm. A model (Tempo) is presented which is capable of emulating recent psychophysical data on the intelligibility of speech sentences as a function of ``packaging'' rate (Ghitza and Greenberg, ). The data show that intelligibility of speech that is time-compressed by a factor of 3 (i.e., a high syllabic rate) is poor (above 50\% word error rate), but is substantially restored when the information stream is re-packaged by the insertion of silent gaps in between successive compressed-signal intervals -- a counterintuitive finding, difficult to explain using classical models of speech perception, but emerging naturally from the Tempo architecture.},
	Author = {Ghitza, Oded},
	Doi = {10.3389/fpsyg.2011.00130},
	File = {Ghitza_11.pdf:/Users/Cecile/Zotero/storage/NI8RNPK9/Ghitza_11.pdf:application/pdf;PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/HMSWWZMC/Ghitza - 2011 - Linking Speech Perception and Neurophysiology Spe.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Month = jun,
	Pmcid = {PMC3127251},
	Pmid = {21743809},
	Shorttitle = {Linking {Speech} {Perception} and {Neurophysiology}},
	Title = {Linking {Speech} {Perception} and {Neurophysiology}: {Speech} {Decoding} {Guided} by {Cascaded} {Oscillators} {Locked} to the {Input} {Rhythm}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3127251/},
	Urldate = {2014-10-21},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3127251/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00130}}

@article{hutt_auditory_1968,
	Author = {Hutt, S. J. and Hutt, Corinne and Lenard, H. G. and Bernuth, H. V. and Muntjewerff, W. J.},
	Copyright = {{\copyright} 1968 Nature Publishing Group},
	Doi = {10.1038/218888a0},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/J23JBV2M/Hutt et al. - 1968 - Auditory Responsivity in the Human Neonate.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K4TDPU33/218888a0.html:text/html},
	Journal = {Nature},
	Language = {en},
	Month = jun,
	Number = {5144},
	Pages = {888--890},
	Title = {Auditory {Responsivity} in the {Human} {Neonate}},
	Url = {http://www.nature.com/nature/journal/v218/n5144/abs/218888a0.html},
	Urldate = {2015-01-07},
	Volume = {218},
	Year = {1968},
	Bdsk-Url-1 = {http://www.nature.com/nature/journal/v218/n5144/abs/218888a0.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/218888a0}}

@article{bernard_prosodic_2012,
	Abstract = {Within language, systematic correlations exist between syntactic structure and prosody. Prosodic prominence, for instance, falls on the complement and not the head of syntactic phrases, and its realization depends on the phrasal position of the prominent element. Thus, in Japanese, a functor-final language, prominence is phrase-initial, and realized as increased pitch ({\textasciicircum} T{\=o}ky{\=o} ni ``Tokyo to''), whereas in French, English, or Italian, functor-initial languages, it manifests itself as phrase-final lengthening (to Rome). Prosody is readily available in the linguistic signal even to the youngest infants. It has, therefore, been proposed that young learners might be able to exploit its correlations with syntax to bootstrap language structure. In this study, we tested this hypothesis, investigating how 8-month-old monolingual French infants processed an artificial grammar manipulating the relative position of prosodic prominence and word frequency. In Condition 1, we created a speech stream in which the two cues, prosody and frequency, were aligned, frequent words being prosodically non-prominent and infrequent ones being prominent, as is the case in natural language (functors are prosodically minimal compared to content words). In Condition 2, the two cues were misaligned, with frequent words carrying prosodic prominence, unlike in natural language. After familiarization with the aligned or the misaligned stream in a headturn preference procedure, we tested infants' preference for test items having a frequent word initial or a frequent word final word order. We found that infants' familiarized with the aligned stream showed the expected preference for the frequent word initial test items, mimicking the functor-initial word order of French. Infants in the misaligned condition showed no preference. These results suggest that infants are able to use word frequency and prosody as early cues to word order and they integrate them into a coherent representation.},
	Author = {Bernard, Carline and Gervain, Judit},
	Doi = {10.3389/fpsyg.2012.00451},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/MERXQJP8/Bernard et Gervain - 2012 - Prosodic cues to word order what level of represe.pdf:application/pdf},
	Journal = {Language Sciences},
	Keywords = {French, language acquisition, prosodic bootstrapping, word order},
	Pages = {451},
	Shorttitle = {Prosodic cues to word order},
	Title = {Prosodic cues to word order: what level of representation?},
	Url = {http://journal.frontiersin.org/Journal/10.3389/fpsyg.2012.00451/abstract},
	Urldate = {2014-06-02},
	Volume = {3},
	Year = {2012},
	Bdsk-Url-1 = {http://journal.frontiersin.org/Journal/10.3389/fpsyg.2012.00451/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2012.00451}}

@article{emberson_decoding_2017,
	Abstract = {The MRI environment restricts the types of populations and tasks that can be studied by cognitive neuroscientists (e.g., young infants, face-to-face communication). FNIRS is a neuroimaging modality that records the same physiological signal as fMRI but without the constraints of MRI, and with better spatial localization than EEG. However, research in the fNIRS community largely lacks the analytic sophistication of analogous fMRI work, restricting the application of this imaging technology. The current paper presents a method of multivariate pattern analysis for fNIRS that allows the authors to decode the infant mind (a key fNIRS population). Specifically, multivariate pattern analysis (MVPA) employs a correlation-based decoding method where a group model is constructed for all infants except one; both average patterns (i.e., infant-level) and single trial patterns (i.e., trial-level) of activation are decoded. Between subjects decoding is a particularly difficult task, because each infant has their own somewhat idiosyncratic patterns of neural activation. The fact that our method succeeds at across-subject decoding demonstrates the presence of group-level multi-channel regularities across infants. The code for implementing these analyses has been made readily available online to facilitate the quick adoption of this method to advance the methodological tools available to the fNIRS researcher.},
	Author = {Emberson, Lauren L. and Zinszer, Benjamin D. and Raizada, Rajeev D. S. and Aslin, Richard N.},
	Doi = {10.1371/journal.pone.0172500},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8872UVFS/Emberson et al. - 2017 - Decoding the infant mind Multivariate pattern ana.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VCAT948W/article.pdf:application/pdf},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Multivariate analysis, Electroencephalography, Hemodynamics, neuroimaging, Infants, Near-infrared spectroscopy, functional magnetic resonance imaging, Magnetic resonance imaging},
	Month = apr,
	Number = {4},
	Pages = {e0172500},
	Shorttitle = {Decoding the infant mind},
	Title = {Decoding the infant mind: {Multivariate} pattern analysis ({MVPA}) using {fNIRS}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0172500},
	Urldate = {2017-10-11},
	Volume = {12},
	Year = {2017},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0172500},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0172500}}

@article{vagharchakian_temporal_2012,
	Abstract = {Humans can understand spoken or written sentences presented at extremely fast rates of â¼400 wpm, far exceeding the normal speech rate (â¼150 wpm). How does the brain cope with speeded language? And what processing bottlenecks eventually make language incomprehensible above a certain presentation rate? We used time-resolved fMRI to probe the brain responses to spoken and written sentences presented at five compression rates, ranging from intelligible (60--100\% of the natural duration) to challenging (40\%) and unintelligible (20\%). The results show that cortical areas differ sharply in their activation speed and amplitude. In modality-specific sensory areas, activation varies linearly with stimulus duration. However, a large modality-independent left-hemispheric language network, including the inferior frontal gyrus (pars orbitalis and triangularis) and the superior temporal sulcus, shows a remarkably time-invariant response, followed by a sudden collapse for unintelligible stimuli. Finally, linear and nonlinear responses, reflecting a greater effort as compression increases, are seen at various prefrontal and parietal sites. We show that these profiles fit with a simple model according to which the higher stages of language processing operate at a fixed speed and thus impose a temporal bottleneck on sentence comprehension. At presentation rates faster than this internal processing speed, incoming words must be buffered, and intelligibility vanishes when buffer storage and retrieval operations are saturated. Based on their temporal and amplitude profiles, buffer regions can be identified with the left inferior frontal/anterior insula, precentral cortex, and mesial frontal cortex.},
	Author = {Vagharchakian, Laurianne and Dehaene-Lambertz, Ghislaine and Pallier, Christophe and Dehaene, Stanislas},
	Doi = {10.1523/JNEUROSCI.5685-11.2012},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/TK6HHAF7/Vagharchakian et al. - 2012 - A Temporal Bottleneck in the Language Comprehensio.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HDG7TU3K/9089.html:text/html;Vagharchakianetal2012.pdf:/Users/Cecile/Zotero/storage/DB7T2W77/Vagharchakianetal2012.pdf:application/pdf},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = jun,
	Number = {26},
	Pages = {9089--9102},
	Pmid = {22745508},
	Title = {A {Temporal} {Bottleneck} in the {Language} {Comprehension} {Network}},
	Url = {http://www.jneurosci.org/content/32/26/9089},
	Urldate = {2015-07-13},
	Volume = {32},
	Year = {2012},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/32/26/9089},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.5685-11.2012}}

@article{arnal_human_2015,
	Abstract = {Screaming is arguably one of the most relevant communication signals for survival in humans. Despite their practical relevance and their theoretical significance as innate [ 1 ] and virtually universal [ 2, 3 ] vocalizations, what makes screams a unique signal and how they are processed is not known. Here, we use acoustic analyses, psychophysical experiments, and neuroimaging to isolate those features that confer to screams their alarming nature, and we track their processing in the human brain. Using the modulation power spectrum (MPS [ 4, 5 ]), a recently developed, neurally informed characterization of sounds, we demonstrate that human screams cluster within restricted portion of the acoustic space (between â¼30 and 150 Hz modulation rates) that corresponds to a well-known perceptual attribute, roughness. In contrast to the received view that roughness is irrelevant for communication [ 6 ], our data reveal that the acoustic space occupied by the rough vocal regime is segregated from other signals, including speech, a pre-requisite to avoid false alarms in normal vocal communication. We show that roughness is present in natural alarm signals as well as in artificial alarms and that the presence of roughness in sounds boosts their detection in various tasks. Using fMRI, we show that acoustic roughness engages subcortical structures critical to rapidly appraise danger. Altogether, these data demonstrate that screams occupy a privileged acoustic niche that, being separated from other communication signals, ensures their biological and ultimately social efficiency.},
	Author = {Arnal, Luc H. and Flinker, Adeen and Kleinschmidt, Andreas and Giraud, Anne-Lise and Poeppel, David},
	Doi = {10.1016/j.cub.2015.06.043},
	File = {Arnal et al. Current Biology 15+SM.pdf:/Users/Cecile/Zotero/storage/IEVCC2EJ/Arnal et al. Current Biology 15+SM.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/FEIB9UWN/S0960-9822(15)00737-X.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Language = {English},
	Month = aug,
	Number = {15},
	Pages = {2051--2056},
	Pmid = {26190070},
	Title = {Human {Screams} {Occupy} a {Privileged} {Niche} in the {Communication} {Soundscape}},
	Url = {http://www.cell.com/article/S096098221500737X/abstract},
	Urldate = {2015-10-22},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cell.com/article/S096098221500737X/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2015.06.043}}

@article{bertoncini_six-month-old_2011,
	Author = {Bertoncini, Josiane and Nazzi, Thierry and Cabrera, Laurianne and Lorenzi, Christian},
	Doi = {10.1121/1.3571424},
	File = {Six-month-old infants discriminate voicing on the basis of temporal envelope cues (L) (PDF Download Available):/Users/Cecile/Zotero/storage/3JAQJIEU/51123038_Six-month-old_infants_discriminate_voicing_on_the_basis_of_temporal_envelope_cues_L.html:text/html;Six-month-old infants discriminate voicing on the basis of temporal envelope cues (L) (PDF Download Available):/Users/Cecile/Zotero/storage/KWHCJGNK/51123038_Six-month-old_infants_discriminate_voicing_on_the_basis_of_temporal_envelope_cues_L.html:text/html},
	Issn = {1520-8524},
	Journal = {The Journal of the Acoustical Society of America},
	Number = {5},
	Pages = {2761--4},
	Title = {Six-month-old infants discriminate voicing on the basis of temporal envelope cues ({L})},
	Volume = {129},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1121/1.3571424}}

@article{gervain_binding_2012,
	Abstract = {Breaking the linguistic code requires the extraction of at least two types of information from the speech signal: the relations between linguistic units and their sequential position. Further, these different types of information need to be integrated into a coherent representation of language structure. The brain networks responsible for these abilities are well-known in adults, but not in young infants. Our results show that the neural architecture underlying these abilities is operational at birth. In three optical imaging studies, we found that the newborn brain detects identity relations, as evidenced by enhanced activation in the bilateral superior temporal and left inferior frontal regions. More importantly, the newborn brain can also determine whether such identity relations hold for the initial or final positions of speech sequences, as indicated by increased activity in the inferior frontal regions, possibly Broca's area. This implies that the neural foundations of language acquisition are in place from birth.},
	Author = {Gervain, Judit and Berent, Iris and Werker, Janet F.},
	Doi = {10.1162/jocn_a_00157},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/V7PV2BFA/ContentServer.asp.pdf:application/pdf},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = mar,
	Number = {3},
	Pages = {564--574},
	Pmcid = {PMC3270491},
	Pmid = {22066581},
	Shorttitle = {Binding at birth},
	Title = {Binding at birth: {The} newborn brain detects identity relations and sequential position in speech},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3270491/},
	Urldate = {2014-05-22},
	Volume = {24},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3270491/},
	Bdsk-Url-2 = {https://doi.org/10.1162/jocn_a_00157}}

@article{hickok_rhythm_2015,
	Abstract = {Acoustic rhythms are pervasive in speech, music, and environmental sounds. Recent evidence for neural codes representing periodic information suggests that they may be a neural basis for the ability to detect rhythm. Further, rhythmic information has been found to modulate auditory-system excitability, which provides a potential mechanism for parsing the acoustic stream. Here, we explored the effects of a rhythmic stimulus on subsequent auditory perception. We found that a low-frequency (3 Hz), amplitude-modulated signal induces a subsequent oscillation of the perceptual detectability of a brief nonperiodic acoustic stimulus (1-kHz tone); the frequency but not the phase of the perceptual oscillation matches the entrained stimulus-driven rhythmic oscillation. This provides evidence that rhythmic contexts have a direct influence on subsequent auditory perception of discrete acoustic events. Rhythm coding is likely a fundamental feature of auditory-system design that predates the development of explicit human enjoyment of rhythm in music or poetry.},
	Author = {Hickok, Gregory and Farahbod, Haleh and Saberi, Kourosh},
	Doi = {10.1177/0956797615576533},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZSHMJQZZ/Hickok et al. - 2015 - The Rhythm of Perception Entrainment to Acoustic R.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8W4M9U5V/0956797615576533.html:text/html},
	Issn = {0956-7976, 1467-9280},
	Journal = {Psychological Science},
	Keywords = {Auditory Perception, Music, Perception, Rhythm, neural oscillations, speech perception, Speech Perception},
	Language = {en},
	Month = may,
	Pages = {0956797615576533},
	Pmid = {25968248},
	Title = {The {Rhythm} of {Perception} {Entrainment} to {Acoustic} {Rhythms} {Induces} {Subsequent} {Perceptual} {Oscillation}},
	Url = {http://pss.sagepub.com/content/early/2015/05/11/0956797615576533},
	Urldate = {2015-05-22},
	Year = {2015},
	Bdsk-Url-1 = {http://pss.sagepub.com/content/early/2015/05/11/0956797615576533},
	Bdsk-Url-2 = {https://doi.org/10.1177/0956797615576533}}

@book{jusczyk_discovery_2000,
	Address = {Cambridge, Mass},
	Annote = {"A Bradford book."},
	Author = {Jusczyk, Peter W.},
	Edition = {1st MIT Press pbk. ed},
	File = {jusczyk.pdf:/Users/Cecile/Zotero/storage/WJ9EXXR6/jusczyk.pdf:application/pdf},
	Isbn = {0-262-60036-6 0-262-10058-4},
	Keywords = {Psycholinguistics, Speech perception in infants, Speech perception in newborn infants, language acquisition},
	Publisher = {MIT Press},
	Series = {Language, speech, and communication},
	Title = {The discovery of spoken language},
	Year = {2000}}

@article{norman-haignere_distinct_2015,
	Abstract = {The organization of human auditory cortex remains unresolved, due in part to the small stimulus sets common to fMRI studies and the overlap of neural populations within voxels. To address these challenges, we measured fMRI responses to 165 natural sounds and inferred canonical response profiles (``components'') whose weighted combinations explained voxel responses throughout auditory cortex. This analysis revealed six components, each with interpretable response characteristics despite being unconstrained by prior functional hypotheses. Four components embodied selectivity for particular acoustic features (frequency, spectrotemporal modulation, pitch). Two others exhibited pronounced selectivity for music and speech, respectively, and were not explainable by standard acoustic features. Anatomically, music and speech selectivity concentrated in distinct regions of non-primary auditory cortex. However, music selectivity was weak in raw voxel responses, and its detection required a decomposition method. Voxel decomposition identifies primary dimensions of response variation across natural sounds, revealing distinct cortical pathways for music and speech.},
	Author = {Norman-Haignere, Sam V. and Kanwisher, Nancy G. and McDermott, Josh H.},
	Doi = {10.1016/j.neuron.2015.11.035},
	File = {Norman-Haignere_Kanwisher_McDermott_2015.pdf:/Users/Cecile/Zotero/storage/IAARZS3M/Norman-Haignere_Kanwisher_McDermott_2015.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DJPAUPVV/S0896-6273(15)01071-5.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Language = {English},
	Month = dec,
	Number = {6},
	Pages = {1281--1296},
	Title = {Distinct {Cortical} {Pathways} for {Music} and {Speech} {Revealed} by {Hypothesis}-{Free} {Voxel} {Decomposition}},
	Url = {http://www.cell.com/article/S0896627315010715/abstract},
	Urldate = {2016-02-19},
	Volume = {88},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cell.com/article/S0896627315010715/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2015.11.035}}

@misc{noauthor_four-month-old_nodate,
	File = {Four-month-old infants prefer to listen to motherese:/Users/Cecile/Zotero/storage/2WBEP55J/S0163638385800059.html:text/html},
	Title = {Four-month-old infants prefer to listen to motherese},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059},
	Urldate = {2014-09-06},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0163638385800059}}

@article{scholkmann_general_2013,
	Abstract = {Abstract. 
Continuous-wave near-infrared spectroscopy and near-infrared imaging enable the measurement of relative concentration changes in oxy- and deoxyhemoglobin and thus hemodynamics and oxygenation. The accuracy of determined changes depends mainly on the modeling of the light transport through the probed tissue. Due to the highly scattering nature of tissue, the light path is longer than the source--detector separation (d). This is incorporated in modeling by multiplying d by a differential pathlength factor (DPF) which depends on several factors such as wavelength, age of the subject, and type of tissue. In the present work, we derive a general DPF equation for the frontal human head, incorporating dependency on wavelength and age, based on published data. We validated the equation using different data sets of experimentally determined DPFs from six independent studies.},
	Author = {Scholkmann, Felix and Wolf, Martin},
	Doi = {10.1117/1.JBO.18.10.105004},
	Issn = {1083-3668},
	Journal = {Journal of Biomedical Optics},
	Number = {10},
	Pages = {105004--105004},
	Title = {General equation for the differential pathlength factor of the frontal human head depending on wavelength and age},
	Url = {http://dx.doi.org/10.1117/1.JBO.18.10.105004},
	Urldate = {2017-02-27},
	Volume = {18},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1117/1.JBO.18.10.105004}}

@article{honey_not_2012,
	Abstract = {How similar are the brains of listeners who hear the same content expressed in different languages? We directly compared the fMRI response time courses of English speakers and Russian speakers who listened to a real-life Russian narrative and its English translation. In the translation, we tried to preserve the content of the narrative while reducing the structural similarities across languages. The story evoked similar brain responses, invariant to the structural changes across languages, beginning just outside early auditory areas and extending through temporal, parietal, and frontal cerebral cortices. The similarity of responses across languages was nearly equal to the similarity of responses within each language group. The present results demonstrate that the human brain processes real-life information in a manner that is largely insensitive to the language in which that information is conveyed. The methods introduced here can potentially be used to quantify the transmission of meaning across cultural and linguistic boundaries.},
	Author = {Honey, Christopher J and Thompson, Christopher R and Lerner, Yulia and Hasson, Uri},
	Doi = {10.1523/JNEUROSCI.1800-12.2012},
	Issn = {1529-2401},
	Journal = {The Journal of neuroscience: the official journal of the Society for Neuroscience},
	Keywords = {Acoustic Stimulation, Adult, Brain Mapping, Cerebral Cortex, Cluster Analysis, Comprehension, Female, Algorithms, Humans, Image Processing, Computer-Assisted, Male, Memory, Multilingualism, Oxygen, Psycholinguistics, Young Adult, language, Brain, Magnetic resonance imaging},
	Language = {eng},
	Month = oct,
	Number = {44},
	Pages = {15277--15283},
	Pmcid = {PMC3525075},
	Pmid = {23115166},
	Shorttitle = {Not lost in translation},
	Title = {Not lost in translation: neural responses shared across languages},
	Volume = {32},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1523/JNEUROSCI.1800-12.2012}}

@article{werker_whos_2000,
	Abstract = {Sophisticated processing of language is considered a unique characteristic of humans. However, as Werker and Vouloumanos discuss in a Perspective, nonhuman primates also have the ability to distinguish natural rhythmicities in speech. They explain new findings ( Ramus et al.) demonstrating that both cotton-top tamarin monkeys and human newborn infants can distinguish between two languages (Dutch and Japanese) when the languages are played forward but not backward. The remarkable finding that tamarins may share this fundamental speech processing capability with human newborns raises questions about the uniqueness of human language.},
	Author = {Werker, Janet F. and Vouloumanos, Athena},
	Doi = {10.1126/science.288.5464.280},
	File = {Snapshot:/Users/Cecile/Zotero/storage/DU82KD4G/280.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = apr,
	Number = {5464},
	Pages = {280--281},
	Pmid = {10777409},
	Title = {Who's {Got} {Rhythm}?},
	Url = {http://www.sciencemag.org/content/288/5464/280},
	Urldate = {2013-07-17},
	Volume = {288},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/288/5464/280},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.288.5464.280}}

@article{remez_speech_1981,
	Author = {Remez, R. E. and Rubin, P. E. and Pisoni, D. B. and Carrell, T. D.},
	Doi = {10.1126/science.7233191},
	File = {Snapshot:/Users/Cecile/Zotero/storage/C6RPHZ3U/947.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = may,
	Number = {4497},
	Pages = {947--949},
	Pmid = {7233191},
	Title = {Speech perception without traditional speech cues},
	Url = {http://www.sciencemag.org/content/212/4497/947},
	Urldate = {2014-04-09},
	Volume = {212},
	Year = {1981},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/212/4497/947},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.7233191}}

@article{peelle_dissociable_2004,
	Author = {Peelle, Jonathan E. and McMillan, Corey and Moore, Peachie and Grossman, Murray and Wingfield, Arthur},
	Doi = {10.1016/j.bandl.2004.05.007},
	File = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech\: Evidence from fMRI:/Users/Cecile/Zotero/storage/DEJSBBPS/S0093934X04000781.html:text/html},
	Issn = {0093934X},
	Journal = {Brain and Language},
	Month = dec,
	Number = {3},
	Pages = {315--325},
	Shorttitle = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech},
	Title = {Dissociable patterns of brain activity during comprehension of rapid and syntactically complex speech: {Evidence} from {fMRI}},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0093934X04000781},
	Urldate = {2013-10-02},
	Volume = {91},
	Year = {2004},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S0093934X04000781},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2004.05.007}}

@article{gervain_neural_2016,
	Abstract = {Sensory systems are thought to have evolved to efficiently represent the full range of sensory stimuli encountered in the natural world. The statistics of natural environmental sounds are characterized by scale-invariance: the property of exhibiting similar patterns at different levels of observation. The statistical structure of scale-invariant sounds remains constant at different spectro-temporal scales. Scale-invariance plays a fundamental role in how efficiently animals and human adults perceive acoustic signals. However, the developmental origins and brain correlates of the neural encoding of scale-invariant environmental sounds remain unexplored. Here, we investigate whether the human brain extracts the statistical property of scale-invariance. Synthetic sounds generated by a mathematical model to respect scale-invariance or violate it were presented to newborns. In alternating blocks, the two sound types were presented together in an alternating fashion, whereas in non-alternating blocks, only one type of sound was presented. Newborns' brain responses were measured using near-infrared spectroscopy. We found that scale-invariant and variable-scale sounds were discriminated by the newborn brain, as suggested by differential activation in the left frontal and temporal areas to alternating vs. non-alternating blocks. These results indicate that newborns already detect and encode scale-invariance as a characteristic feature of acoustic stimuli. This suggests that the mathematical principle of efficient coding of information guides the auditory neural code from the beginning of human development, a finding that may help explain how evolution has prepared the brain for perceiving the natural world.},
	Author = {Gervain, Judit and Werker, Janet F. and Black, Alexis and Geffen, Maria N.},
	Doi = {10.1016/j.neuroimage.2016.03.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4B6IXJ66/Gervain et al. - The neural correlates of processing scale-invarian.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2XX8EIJK/S1053811916001968.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Auditory Perception, Efficient neural coding, newborns, scale-invariance, Near-infrared spectroscopy},
	Title = {The neural correlates of processing scale-invariant environmental sounds at birth},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811916001968},
	Urldate = {2016-03-14},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811916001968},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2016.03.001}}

@article{foulke_review_1969,
	Abstract = {Time-compressed or accelerated speech is speech which has been reproduced in less than the original production time. Such speech may prove to be useful in a variety of situations in which people must rely upon listening to obtain the information specified by language. It may also prove to be a useful tool in studying the temporal requirements of the listener as he processes spoken language. Methods for the generation of time compressed speech are reviewed. Methods for the assessment of the effect of compression on word intelligibility and listening comprehension are discussed. Experiments dealing with the effect of time compression upon word intelligibility and upon the comprehensibility of connected discourse, and experiments concerned with the influence of stimulus variables, such as signal distortion, and organismic variables such as intelligence, are reviewed. The general finding that compression in time has a different effect upon the comprehensibility of connected discourse than upon word intelligibility is discussed, and a tentative explanation of this difference is offered. (63 ref.) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	Author = {Foulke, Emerson and Sticht, Thomas G.},
	Doi = {10.1037/h0027575},
	File = {EBSCO Full Text:/Users/Cecile/Zotero/storage/GEBIJV6G/Foulke et Sticht - 1969 - Review of research on the intelligibility and comp.pdf:application/pdf},
	Issn = {0033-2909},
	Journal = {Psychological Bulletin},
	Keywords = {Auditory Discrimination, Experimentation, Literature Review, Thinking, intelligibility \& comprehension of accelerated speech, review of research, speech perception, Speech Perception},
	Month = jul,
	Number = {1},
	Pages = {50--62},
	Title = {Review of research on the intelligibility and comprehension of accelerated speech},
	Url = {https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1969-12922-001&lang=fr&site=ehost-live},
	Urldate = {2013-10-17},
	Volume = {72},
	Year = {1969},
	Bdsk-Url-1 = {https://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=1969-12922-001&lang=fr&site=ehost-live},
	Bdsk-Url-2 = {https://doi.org/10.1037/h0027575}}

@article{theunissen_neural_2014,
	Abstract = {We might be forced to listen to a high-frequency tone at our audiologist's office or we might enjoy falling asleep with a white-noise machine, but the sounds that really matter to us are the voices of our companions or music from our favourite radio station. The auditory system has evolved to process behaviourally relevant natural sounds. Research has shown not only that our brain is optimized for natural hearing tasks but also that using natural sounds to probe the auditory system is the best way to understand the neural computations that enable us to comprehend speech or appreciate music.
View full text},
	Author = {Theunissen, Fr{\'e}d{\'e}ric E. and Elie, Julie E.},
	Copyright = {{\copyright} 2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/nrn3731},
	File = {Snapshot:/Users/Cecile/Zotero/storage/TCE3J5NV/nrn3731.html:text/html;Theunissen et Elie - 2014 - Neural processing of natural sounds.pdf:/Users/Cecile/Zotero/storage/4KBS7HRF/Theunissen et Elie - 2014 - Neural processing of natural sounds.pdf:application/pdf},
	Issn = {1471-003X},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {355--366},
	Title = {Neural processing of natural sounds},
	Url = {http://www.nature.com/nrn/journal/v15/n6/abs/nrn3731.html},
	Urldate = {2014-05-26},
	Volume = {15},
	Year = {2014},
	Bdsk-Url-1 = {http://www.nature.com/nrn/journal/v15/n6/abs/nrn3731.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn3731}}

@article{ghitza_neuronal_2013,
	Abstract = {A recent opinion article (Neural oscillations in speech: do not be enslaved by the envelope. Obleser et al., ) questions the validity of a class of speech perception models inspired by the possible role of neuronal oscillations in decoding speech (e.g., Ghitza, ; Giraud and Poeppel, ). The authors criticize, in particular, what they see as an over-emphasis of the role of temporal speech envelope information, and an over-emphasis of entrainment to the input rhythm while neglecting the role of top-down processes in modulating the entrainment of neuronal oscillations. Here we respond to these arguments, referring to the phenomenological model of Ghitza (), taken as a representative of the criticized approach.},
	Author = {Ghitza, Oded and Giraud, Anne-Lise and Poeppel, David},
	Doi = {10.3389/fnhum.2012.00340},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Z7QI5S8V/Ghitza et al. - 2013 - Neuronal oscillations and speech perception criti.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = jan,
	Pmcid = {PMC3539830},
	Pmid = {23316150},
	Shorttitle = {Neuronal oscillations and speech perception},
	Title = {Neuronal oscillations and speech perception: critical-band temporal envelopes are the essence},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3539830/},
	Urldate = {2014-10-31},
	Volume = {6},
	Year = {2013},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3539830/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2012.00340}}

@article{minagawa-kawai_optical_2011,
	Abstract = {This study uses near-infrared spectroscopy in young infants in order to elucidate the nature of functional cerebral processing for speech. Previous imaging studies of infants' speech perception revealed left-lateralized responses to native language. However, it is unclear if these activations were due to language per se rather than to some low-level acoustic correlate of spoken language. Here we compare native (L1) and non-native (L2) languages with 3 different nonspeech conditions including emotional voices, monkey calls, and phase scrambled sounds that provide more stringent controls. Hemodynamic responses to these stimuli were measured in the temporal areas of Japanese 4 month-olds. The results show clear left-lateralized responses to speech, prominently to L1, as opposed to various activation patterns in the nonspeech conditions. Furthermore, implementing a new analysis method designed for infants, we discovered a slower hemodynamic time course in awake infants. Our results are largely explained by signal-driven auditory processing. However, stronger activations to L1 than to L2 indicate a language-specific neural factor that modulates these responses. This study is the first to discover a significantly higher sensitivity to L1 in 4 month-olds and reveals a neural precursor of the functional specialization for the higher cognitive network.},
	Author = {Minagawa-Kawai, Yasuyo and van der Lely, Heather and Ramus, Franck and Sato, Yutaka and Mazuka, Reiko and Dupoux, Emmanuel},
	Doi = {10.1093/cercor/bhq082},
	Issn = {1460-2199},
	Journal = {Cerebral cortex (New York, N.Y.: 1991)},
	Keywords = {Acoustic Stimulation, Brain Mapping, Child Development, Emotions, Female, Functional Laterality, Hemoglobins, Humans, Infant, Male, Numerical Analysis, Computer-Assisted, Reaction Time, Spectroscopy, Near-Infrared, Temporal Lobe, Time Factors, language, speech perception, Speech Perception},
	Language = {eng},
	Month = feb,
	Number = {2},
	Pages = {254--261},
	Pmid = {20497946},
	Title = {Optical brain imaging reveals general auditory and language-specific processing in early infant development},
	Volume = {21},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1093/cercor/bhq082}}

@article{winkler_newborn_2009,
	Abstract = {To shed light on how humans can learn to understand music, we need to discover what the perceptual capabilities with which infants are born. Beat induction, the detection of a regular pulse in an auditory signal, is considered a fundamental human trait that, arguably, played a decisive role in the origin of music. Theorists are divided on the issue whether this ability is innate or learned. We show that newborn infants develop expectation for the onset of rhythmic cycles (the downbeat), even when it is not marked by stress or other distinguishing spectral features. Omitting the downbeat elicits brain activity associated with violating sensory expectations. Thus, our results strongly support the view that beat perception is innate.},
	Author = {Winkler, Istv{\'a}n and H{\'a}den, G{\'a}bor P. and Ladinig, Olivia and Sziller, Istv{\'a}n and Honing, Henkjan},
	Doi = {10.1073/pnas.0809035106},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Q7QEBGWQ/Winkler et al. - 2009 - Newborn infants detect the beat in music.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9MQ38THX/0809035106.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {Rhythm, event-related brain potentials (ERP), neonates},
	Language = {en},
	Month = jan,
	Pages = {pnas.0809035106},
	Pmid = {19171894},
	Title = {Newborn infants detect the beat in music},
	Url = {http://www.pnas.org/content/early/2009/01/26/0809035106},
	Urldate = {2016-03-14},
	Year = {2009},
	Bdsk-Url-1 = {http://www.pnas.org/content/early/2009/01/26/0809035106},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0809035106}}

@article{adank_-line_2010,
	Abstract = {Listeners show remarkable flexibility in processing variation in speech signal. One striking example is the ease with which they adapt to novel speech distortions such as listening to someone with a foreign accent. Behavioural studies suggest that significant improvements in comprehension occur rapidly --- often within 10--20 sentences. In the present experiment, we investigate the neural changes underlying on-line adaptation to distorted speech using time-compressed speech. Listeners performed a sentence verification task on normal-speed and time-compressed sentences while their neural responses were recorded using fMRI. The results showed that rapid learning of the time-compressed speech occurred during presentation of the first block of 16 sentences and was associated with increased activation in left and right auditory association cortices and in left ventral premotor cortex. These findings suggest that the ability to adapt to a distorted speech signal may, in part, rely on mapping novel acoustic patterns onto existing articulatory motor plans, consistent with the idea that speech perception involves integrating multi-modal information including auditory and motoric cues.},
	Author = {Adank, Patti and Devlin, Joseph T.},
	Doi = {10.1016/j.neuroimage.2009.07.032},
	Issn = {1053-8119},
	Journal = {Neuroimage},
	Month = jan,
	Number = {1},
	Pages = {1124--1132},
	Pmcid = {PMC2775905},
	Pmid = {19632341},
	Shorttitle = {On-line plasticity in spoken sentence comprehension},
	Title = {On-line plasticity in spoken sentence comprehension: {Adapting} to time-compressed speech},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775905/},
	Urldate = {2014-01-20},
	Volume = {49},
	Year = {2010},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2775905/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2009.07.032}}

@article{ahissar_speech_2001,
	Abstract = {Speech comprehension depends on the integrity of both the spectral content and temporal envelope of the speech signal. Although neural processing underlying spectral analysis has been intensively studied, less is known about the processing of temporal information. Most of speech information conveyed by the temporal envelope is confined to frequencies below 16 Hz, frequencies that roughly match spontaneous and evoked modulation rates of primary auditory cortex neurons. To test the importance of cortical modulation rates for speech processing, we manipulated the frequency of the temporal envelope of speech sentences and tested the effect on both speech comprehension and cortical activity. Magnetoencephalographic signals from the auditory cortices of human subjects were recorded while they were performing a speech comprehension task. The test sentences used in this task were compressed in time. Speech comprehension was degraded when sentence stimuli were presented in more rapid (more compressed) forms. We found that the average comprehension level, at each compression, correlated with (i) the similarity between the frequencies of the temporal envelopes of the stimulus and the subject's cortical activity (``stimulus-cortex frequency-matching'') and (ii) the phase-locking (PL) between the two temporal envelopes (``stimulus-cortex PL''). Of these two correlates, PL was significantly more indicative for single-trial success. Our results suggest that the match between the speech rate and the a priori modulation capacities of the auditory cortex is a prerequisite for comprehension. However, this is not sufficient: stimulus-cortex PL should be achieved during actual sentence presentation.},
	Author = {Ahissar, Ehud and Nagarajan, Srikantan and Ahissar, Merav and Protopapas, Athanassios and Mahncke, Henry and Merzenich, Michael M.},
	Doi = {10.1073/pnas.201400998},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/HUZW8ESF/pq013367.pdf:application/pdf},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Month = nov,
	Number = {23},
	Pages = {13367--13372},
	Pmcid = {PMC60877},
	Pmid = {11698688},
	Title = {Speech comprehension is correlated with temporal response patterns recorded from auditory cortex},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC60877/},
	Urldate = {2014-10-21},
	Volume = {98},
	Year = {2001},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC60877/},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.201400998}}

@article{matsui_referential_2014,
	Abstract = {Functional near infrared spectroscopy (fNIRS), which is compact, portable, and tolerant of body movement, is suitable for monitoring infant brain functions. Nevertheless, fNIRS also poses a technical problem in that it cannot provide structural information. Supplementation with structural magnetic resonance images (MRI) is not always feasible for infants who undergo fNIRS measurement. Probabilistic registration methods using an MRI database instead of subjects' own MRIs are optimized for adult studies and offer only limited resources for infant studies. To overcome this, we used high-quality infant MRI data for a 12-month-old infant and manually delineated segmented gyri from among the highly visible macroanatomies on the lateral cortical surface. These macroanatomical regions are primarily linked to the spherical coordinate system based on external cranial landmarks, and further to traditional 10-20-based head-surface positioning systems. While macroanatomical structures were generally comparable between adult and infant atlases, differences were found in the parietal lobe, which was positioned posteriorly at the vertex in the infant brain. The present study provides a referential framework for macroanatomical analyses in infant fNIRS studies. With this resource, multichannel fNIRS functional data could be analyzed in reference to macroanatomical structures through virtual and probabilistic registrations without acquiring subject-specific MRIs.},
	Author = {Matsui, Mie and Homae, Fumitaka and Tsuzuki, Daisuke and Watanabe, Hama and Katagiri, Masatoshi and Uda, Satoshi and Nakashima, Mitsuhiro and Dan, Ippeita and Taga, Gentaro},
	Doi = {10.1016/j.neures.2014.01.003},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RFK66AEA/Matsui et al. - 2014 - Referential framework for transcranial anatomical .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2PSGZMXS/S0168010214000042.html:text/html},
	Issn = {0168-0102},
	Journal = {Neuroscience Research},
	Keywords = {Baby, Manual tracing, Optical topography, Parcellation, Sulcus, Transcranial neuroimaging},
	Month = mar,
	Pages = {55--68},
	Title = {Referential framework for transcranial anatomical correspondence for {fNIRS} based on manually traced sulci and gyri of an infant brain},
	Url = {http://www.sciencedirect.com/science/article/pii/S0168010214000042},
	Urldate = {2015-01-28},
	Volume = {80},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010214000042},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neures.2014.01.003}}

@article{remez_perceptual_1994,
	Abstract = {A general account of auditory perceptual organization has developed in the past 2 decades. It relies on primitive devices akin to the Gestalt principles of organization to assign sensory elements to probable groupings and invokes secondary schematic processes to confirm or to repair the possible organization. Although this conceptualization is intended to apply universally, the variety and arrangement of acoustic constituents of speech violate Gestalt principles at numerous junctures, cohering perceptually, nonetheless. The authors report 3 experiments on organization in phonetic perception, using sine wave synthesis to evade the Gestalt rules and the schematic processes alike. These findings falsify a general auditory account, showing that phonetic perceptual organization is achieved by specific sensitivity to the acoustic modulations characteristic of speech signals.},
	Author = {Remez, R. E. and Rubin, P. E. and Berns, S. M. and Pardo, J. S. and Lang, J. M.},
	Issn = {0033-295X},
	Journal = {Psychological Review},
	Keywords = {Adult, Attention, Female, Gestalt Theory, Humans, Male, Phonetics, Psychoacoustics, Sound Spectrography, speech perception, Speech Perception},
	Language = {eng},
	Month = jan,
	Number = {1},
	Pages = {129--156},
	Pmid = {8121955},
	Title = {On the perceptual organization of speech},
	Volume = {101},
	Year = {1994}}

@article{poldrack_relations_2001,
	Abstract = {Functional magnetic resonance imaging (fMRI) was used to examine how the brain responds to temporal compression of speech and to determine whether the same regions are also involved in phonological processes associated with reading. Recorded speech was temporally compressed to varying degrees and presented in a sentence verification task. Regions involved in phonological processing were identified in a separate scan using a rhyming judgment task with pseudowords compared to a lettercase judgment task. The left inferior frontal and left superior temporal regions (Broca's and Wernicke's areas), along with the right inferior frontal cortex, demonstrated a convex response to speech compression; their activity increased as compression increased, but then decreased when speech became incomprehensible. Other regions exhibited linear increases in activity as compression increased, including the middle frontal gyri bilaterally. The auditory cortices exhibited compression-related decreases bilaterally, primarily reflecting a decrease in activity when speech became incomprehensible. Rhyme judgments engaged two left inferior frontal gyrus regions (pars triangularis and pars opercularis), of which only the pars triangularis region exhibited significant compression-related activity. These results directly demonstrate that a subset of the left inferior frontal regions involved in phonological processing is also sensitive to transient acoustic features within the range of comprehensible speech.},
	Author = {Poldrack, R. A. and Temple, E. and Protopapas, A. and Nagarajan, S. and Tallal, P. and Merzenich, M. and Gabrieli, J. D.},
	Doi = {10.1162/089892901750363235},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Keywords = {Adult, Auditory Perception, Mental Processes, Periodicity, Brain Mapping, Female, Humans, Male, Phonetics, Sound, Time Factors, Brain},
	Language = {eng},
	Month = jul,
	Number = {5},
	Pages = {687--697},
	Pmid = {11506664},
	Shorttitle = {Relations between the neural bases of dynamic auditory processing and phonological processing},
	Title = {Relations between the neural bases of dynamic auditory processing and phonological processing: evidence from {fMRI}},
	Volume = {13},
	Year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.1162/089892901750363235}}

@article{schneider_sparse_2013,
	Abstract = {Vocal communicators such as humans and songbirds readily recognize individual vocalizations, even in distracting auditory environments. This perceptual ability is likely subserved by auditory neurons whose spiking responses to individual vocalizations are minimally affected by background sounds. However, auditory neurons that produce background-invariant responses to vocalizations in auditory scenes have not been found. Here, we describe a population of neurons in the zebra finch auditory cortex that represent vocalizations with a sparse code and that maintain their vocalization-like firing patterns in levels of background sound that permit behavioral recognition. These same neurons decrease or stop spiking in levels of background sound that preclude behavioral recognition. In contrast, upstream neurons represent vocalizations with dense and background-corrupted responses. We provide experimental evidence suggesting that sparse coding is mediated by feedforward suppression. Finally, we show through simulations that feedforward inhibition can transform a dense representation of vocalizations into a sparse and background-invariant representation.},
	Author = {Schneider, David M. and Woolley, Sarah M. N.},
	Doi = {10.1016/j.neuron.2013.04.038},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EPQITPHS/Schneider et Woolley - 2013 - Sparse and Background-Invariant Coding of Vocaliza.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RNS3BIVG/S0896627313003693.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = jul,
	Number = {1},
	Pages = {141--152},
	Title = {Sparse and {Background}-{Invariant} {Coding} of {Vocalizations} in {Auditory} {Scenes}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627313003693},
	Urldate = {2015-09-30},
	Volume = {79},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313003693},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2013.04.038}}

@article{wang_representation_1995,
	Abstract = {1. The temporal and spectral characteristics of neural representations of a behaviorally important species-specific vocalization were studied in neuronal populations of the primary auditory cortex (A1) of barbiturate-anesthetized adult common marmosets (Callithrix jacchus), using both natural and synthetic vocalizations. The natural vocalizations used in electrophysiological experiments were recorded from the animals under study or from their conspecifics. These calls were frequently produced in vocal exchanges between members of our marmoset colony and are part of the well-defined and highly stereotyped vocal repertoire of this species. 2. The spectrotemporal discharge pattern of spatially distributed neuron populations in cortical field A1 was found to be correlated with the spectrotemporal acoustic pattern of a complex natural vocalization. However, the A1 discharge pattern was not a faithful replication of the acoustic parameters of a vocalization stimulus, but had been transformed into a more abstract representation than that in the auditory periphery. 3. Subpopulations of A1 neurons were found to respond selectively to natural vocalizations as compared with synthetic variations that had the same spectral but different temporal characteristics. A subpopulation responding selectively to a given monkey's call shared some but not all of its neuronal memberships with other individual-call-specific neuronal subpopulations. 4. In the time domain, responses of individual A1 units were phase-locked to the envelope of a portion of a complex vocalization, which was centered around a unit's characteristic frequency (CF). As a whole, discharges of A1 neuronal populations were phase-locked to discrete stimulus events but not to their rapidly changing spectral contents. The consequence was a reduction in temporal complexity and an increase in cross-population response synchronization. 5. In the frequency domain, major features of the stimulus spectrum were reflected in rate-CF profiles. The spectral features of a natural call were equally or more strongly represented by a subpopulation of A1 neurons that responded selectively to that call as compared with the entire responding A1 population. 6. Neuronal responses to a complex call were distributed very widely across cortical field A1. At the same time, the responses evoked by a vocalization scattered in discrete cortical patches were strongly synchronized to stimulus events and to each other. As a result, at any given time during the course of a vocalization, a coherent representation of the integrated spectrotemporal characteristics of a particular vocalization was present in a specific neuronal population. 7. These results suggest that the representation of behaviorally important and spectrotemporally complex species-specific vocalizations in A1 is 1) temporally integrated and 2) spectrally distributed in nature, and that the representation is carried by spatially dispersed and synchronized cortical cell assemblies that correspond to each individual's vocalizations in a specific and abstracted way.},
	Author = {Wang, X. and Merzenich, M. M. and Beitel, R. and Schreiner, C. E.},
	Copyright = {Copyright {\copyright} 1995 the American Physiological Society},
	File = {Snapshot:/Users/Cecile/Zotero/storage/5UE8KEGG/2685.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = dec,
	Number = {6},
	Pages = {2685--2706},
	Pmid = {8747224},
	Shorttitle = {Representation of a species-specific vocalization in the primary auditory cortex of the common marmoset},
	Title = {Representation of a species-specific vocalization in the primary auditory cortex of the common marmoset: temporal and spectral characteristics},
	Url = {http://jn.physiology.org/content/74/6/2685},
	Urldate = {2015-05-22},
	Volume = {74},
	Year = {1995},
	Bdsk-Url-1 = {http://jn.physiology.org/content/74/6/2685}}

@article{saliba_functional_2016,
	Abstract = {Functional neuroimaging can provide insight into the neurobiological factors that contribute to the variations in individual hearing outcomes following cochlear implantation. To date, measuring neural activity within the auditory cortex of cochlear implant (CI) recipients has been challenging, primarily because the use of traditional neuroimaging techniques is limited in people with CIs. Functional near-infrared spectroscopy (fNIRS) is an emerging technology that offers benefits in this population because it is non-invasive, compatible with CI devices, and not subject to electrical artifacts. However, there are important considerations to be made when using fNIRS to maximize the signal to noise ratio and to best identify meaningful cortical responses. This review considers these issues, the current data, and future directions for using fNIRS as a clinical application in individuals with CIs.

This article is part of a Special Issue entitled \&lt;Annual Reviews 2016\&gt;.},
	Author = {Saliba, Joe and Bortfeld, Heather and Levitin, Daniel J. and Oghalai, John S.},
	Doi = {10.1016/j.heares.2016.02.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BFG8TJHM/Saliba et al. - 2016 - Functional near-infrared spectroscopy for neuroima.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/CTBTIGQG/S0378595515301891.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Keywords = {Cochlear implant, Hearing loss, Speech, fNIRS, neuroimaging},
	Month = aug,
	Pages = {64--75},
	Series = {Special {Issue}: {Annual} {Reviews} 2016},
	Title = {Functional near-infrared spectroscopy for neuroimaging in cochlear implant recipients},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595515301891},
	Urldate = {2016-11-14},
	Volume = {338},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595515301891},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2016.02.005}}

@inproceedings{attias_temporal_1997,
	Abstract = {The annual conference on Neural Information Processing Systems (NIPS) is the flagshipconference on neural computation. It draws preeminent academic researchers from around the world andis widely considered to be a showcase conference for new developments in network algorithms andarchitectures. The broad range of interdisciplinary research areas represented includes neuralnetworks and genetic algorithms, cognitive science, neuroscience and biology, computer science, AI,applied mathematics, physics, and many branches of engineering. Only about 30\% of the paperssubmitted are accepted for presentation at NIPS, so the quality is exceptionally high. All of thepapers presented appear in these proceedings.},
	Author = {Attias, H. and Schreiner, Christoph E},
	Booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 9: {Proceedings} of the 1996 {Conference}},
	File = {AttiasSchneirer1997.pdf:/Users/Cecile/Zotero/storage/PU4CTUPW/AttiasSchneirer1997.pdf:application/pdf},
	Isbn = {978-0-262-10065-6},
	Keywords = {Computers / Neural Networks, Medical / Neuroscience},
	Language = {en},
	Publisher = {MIT Press},
	Title = {Temporal {Low}-{Order} {Statistics} of {Natural} {Sounds}},
	Year = {1997}}

@article{byrne_international_1994,
	Abstract = {The longâterm average speech spectrum (LTASS) and some dynamic characteristics of speech were determined for 12 languages: English (several dialects), Swedish, Danish, German, French (Canadian), Japanese, Cantonese, Mandarin, Russian, Welsh, Singhalese, and Vietnamese. The LTASS only was also measured for Arabic. Speech samples (18) were recorded, using standardized equipment and procedures, in 15 localities for (usually) ten male and ten female talkers. All analyses were conducted at the National Acoustic Laboratories, Sydney. The LTASS was similar for all languages although there were many statistically significant differences. Such differences were small and not always consistent for male and female samples of the same language. For oneâthird octave bands of speech, the maximum shortâterm rms level was 10 dB above the maximum longâterm rms level, consistent across languages and frequency. A ``universal'' LTASS is suggested as being applicable, across languages, for many purposes including use in hearing aid prescription procedures and in the Articulation Index.},
	Author = {Byrne, Denis and Dillon, Harvey and Tran, Khanh and Arlinger, Stig and Wilbraham, Keith and Cox, Robyn and Hagerman, Bjorn and Hetu, Raymond and Kei, Joseph and Lui, C. and Kiessling, Jurgen and Kotby, M. Nasser and Nasser, Nasser H. A. and Kholy, Wafaa A. H. El and Nakanishi, Yasuko and Oyer, Herbert and Powell, Richard and Stephens, Dafydd and Meredith, Rhys and Sirimanna, Tony and Tavartkiladze, George and Frolenkov, Gregory I. and Westerman, Soren and Ludvigsen, Carl},
	Doi = {10.1121/1.410152},
	File = {Byrne et al. - 1994 - An international comparison of longâterm average s.pdf:/Users/Cecile/Zotero/storage/466ZTW8Z/Byrne et al. - 1994 - An international comparison of longâterm average s.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMKKCQ6C/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Acoustic analysis, Hearing, Spectral properties, Speech},
	Month = oct,
	Number = {4},
	Pages = {2108--2120},
	Title = {An international comparison of longâterm average speech spectra},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/96/4/10.1121/1.410152},
	Urldate = {2015-02-13},
	Volume = {96},
	Year = {1994},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/96/4/10.1121/1.410152},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.410152}}

@article{latinus_human_2011,
	Abstract = {We are all voice experts. First and foremost, we can produce and understand speech, and this makes us a unique species. But in addition to speech perception, we routinely extract from voices a wealth of socially-relevant information in what constitutes a more primitive, and probably more universal, non-linguistic mode of communication. Consider the following example: you are sitting in a plane, and you can hear a conversation in a foreign language in the row behind you. You do not see the speakers' faces, and you cannot understand the speech content because you do not know the language. Yet, an amazing amount of information is available to you. You can evaluate the physical characteristics of the different protagonists, including their gender, approximate age and size, and associate an identity to the different voices. You can form a good idea of the different speaker's mood and affective state, as well as more subtle cues as the perceived attractiveness or dominance of the protagonists. In brief, you can form a fairly detailed picture of the type of social interaction unfolding, which a brief glance backwards can on the occasion help refine --- sometimes surprisingly so. What are the acoustical cues that carry these different types of vocal information? How does our brain process and analyse this information? Here we briefly review an emerging field and the main tools used in voice perception research.},
	Author = {Latinus, Marianne and Belin, Pascal},
	Doi = {10.1016/j.cub.2010.12.033},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/5XC8UWZ8/Latinus et Belin - 2011 - Human voice perception.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/84RXFEWK/S096098221001701X.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Month = feb,
	Number = {4},
	Pages = {R143--R145},
	Title = {Human voice perception},
	Url = {http://www.cell.com/current-biology/abstract/S0960-9822(10)01701-X},
	Urldate = {2014-02-01},
	Volume = {21},
	Year = {2011},
	Bdsk-Url-1 = {http://www.cell.com/current-biology/abstract/S0960-9822(10)01701-X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2010.12.033}}

@article{moon_what_2014,
	Abstract = {Complex sound like speech can be characterized as the sum of number of amplitude-modulated signals representing the outputs of an array of narrow frequency bands. Temporal information at the output of each band can be separated into temporal fine structure (TFS), the rapid oscillations close to the center frequency and temporal envelope (ENV), slower amplitude modulations superimposed on the TFS. TFS information can be carried in the pattern of phase locking to the stimulus waveform, while ENV by the changes in firing rate over time. The relative importance of temporal ENV and TFS information in understanding speech has been studied using various sound-processing techniques. A number of studies demonstrated that ENV cues are associated with speech recognition in quiet, while TFS cues are possibly linked to melody/pitch perception and listening to speech in a competing background. However, there are evidences that recovered ENV from TFS as well as TFS itself may be partially responsible for speech recognition. Current technologies used in cochlear implants (CI) are not efficient in delivering the TFS cues, and new attempts have been made to deliver TFS information into sound-processing strategy in CI. We herein discuss the current updated findings of TFS with a literature review.},
	Author = {Moon, Il Joon and Hong, Sung Hwa},
	Doi = {10.7874/kja.2014.18.1.1},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/A8FUASN5/Moon et Hong - 2014 - What Is Temporal Fine Structure and Why Is It Impo.pdf:application/pdf},
	Issn = {2092-9862},
	Journal = {Korean Journal of Audiology},
	Month = apr,
	Number = {1},
	Pages = {1--7},
	Pmcid = {PMC4003734},
	Pmid = {24782944},
	Title = {What {Is} {Temporal} {Fine} {Structure} and {Why} {Is} {It} {Important}?},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4003734/},
	Urldate = {2016-09-07},
	Volume = {18},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4003734/},
	Bdsk-Url-2 = {https://doi.org/10.7874/kja.2014.18.1.1}}

@article{averbeck_neural_2006,
	Abstract = {How the brain encodes information in population activity, and how it combines and manipulates that activity as it carries out computations, are questions that lie at the heart of systems neuroscience. During the past decade, with the advent of multi-electrode recording and improved theoretical models, these questions have begun to yield answers. However, a complete understanding of neuronal variability, and, in particular, how it affects population codes, is missing. This is because variability in the brain is typically correlated, and although the exact effects of these correlations are not known, it is known that they can be large. Here, we review studies that address the interaction between neuronal noise and population codes, and discuss their implications for population coding in general.},
	Author = {Averbeck, Bruno B. and Latham, Peter E. and Pouget, Alexandre},
	Copyright = {{\copyright} 2006 Nature Publishing Group},
	Doi = {10.1038/nrn1888},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FGERE66D/Averbeck et al. - 2006 - Neural correlations, population coding and computa.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J4P4ZZEU/nrn1888.html:text/html},
	Issn = {1471-003X},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = may,
	Number = {5},
	Pages = {358--366},
	Title = {Neural correlations, population coding and computation},
	Url = {http://www.nature.com/nrn/journal/v7/n5/full/nrn1888.html},
	Urldate = {2015-05-22},
	Volume = {7},
	Year = {2006},
	Bdsk-Url-1 = {http://www.nature.com/nrn/journal/v7/n5/full/nrn1888.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn1888}}

@article{tang_sound_nodate,
	Abstract = {Objective
This study investigated auditory cortical processing of linguistically-relevant temporal modulations in the developing brains of young children.
Methods
Auditory envelope following responses to white noise amplitude modulated at rates of 1--80 Hz in healthy children (aged 3--5 years) and adults were recorded using a paediatric magnetoencephalography (MEG) system and a conventional MEG system, respectively.
Results
For children, there were envelope following responses to slow modulations but no significant responses to rates higher than about 25 Hz, whereas adults showed significant envelope following responses to almost the entire range of stimulus rates.
Conclusion
Our results show that the auditory cortex of preschool-aged children has a sharply limited capacity to process rapid amplitude modulations in sounds, as compared to the auditory cortex of adults.
Significance
These neurophysiological results are consistent with previous psychophysical evidence for a protracted maturational time course for auditory temporal processing. The findings are also in good agreement with current linguistic theories that posit a perceptual bias for low frequency temporal information in speech during language acquisition. These insights also have clinical relevance for our understanding of language disorders that are associated with difficulties in processing temporal information in speech.},
	Author = {Tang, Huizhen and Brock, Jon and Johnson, Blake W.},
	Doi = {10.1016/j.clinph.2015.07.038},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TTBHF2IZ/Tang et al. - Sound envelope processing in the developing human .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TAKEUEK9/S1388245715007944.html:text/html},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology},
	Keywords = {Auditory steady state response, Envelope following response, Temporal processing, language acquisition, Development, Auditory cortex},
	Shorttitle = {Sound envelope processing in the developing human brain},
	Title = {Sound envelope processing in the developing human brain: {A} {MEG} study},
	Url = {http://www.sciencedirect.com/science/article/pii/S1388245715007944},
	Urldate = {2015-12-03},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245715007944},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2015.07.038}}

@article{moon_two-day-olds_1993,
	Abstract = {Newborn infants whose mothers were monolingual speakers of Spanish or English were tested with audio recordings of female strangers speaking either Spanish or English. Infant sucking controlled the presentation of auditory stimuli. Infants activated recordings of their native language for longer periods than the foreign language.},
	Author = {Moon, Christine and Cooper, Robin Panneton and Fifer, William P.},
	Doi = {10.1016/0163-6383(93)80007-U},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/FR2F2X3B/016363839380007U.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Keywords = {Perception, nonnutritive, preference, sucking, language, Newborn},
	Month = oct,
	Number = {4},
	Pages = {495--500},
	Title = {Two-day-olds prefer their native language},
	Url = {http://www.sciencedirect.com/science/article/pii/016363839380007U},
	Urldate = {2014-06-01},
	Volume = {16},
	Year = {1993},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/016363839380007U},
	Bdsk-Url-2 = {https://doi.org/10.1016/0163-6383(93)80007-U}}

@article{starr_development_1977,
	Abstract = {Auditory brainstem potentials were recorded from scalp electrodes in 42 infants ranging in gestational age from 25 to 44 weeks. The latencies of the various potential components decreased with maturation. Wave V, evoked by 65-dB sensation level clicks, changed in latency from 9.9 msec at 26 weeks of gestation of 6.9 msec at 40 weeks of gestation. Central conduction times in the auditory pathway also decreased with maturation from 7.2 msec at 26 weeks to 5.2 msec at 40 weeks. The effects of brainstem and cochlear disorders on auditory brainstem potentials were noted in several abnormal infants. The application of all of these techniques could permit an objective definition of both normal and abnormal sensory processes in newborn infants.},
	Author = {Starr, A. and Amlie, R. N. and Martin, W. H. and Sanders, S.},
	Issn = {0031-4005},
	Journal = {Pediatrics},
	Keywords = {Auditory Pathways, Bone Conduction, Brain Stem, Cochlea, Deafness, Electrodes, Female, Humans, Infant, Newborn, Infant, Newborn, Diseases, Action potentials},
	Language = {eng},
	Month = dec,
	Number = {6},
	Pages = {831--839},
	Pmid = {600595},
	Title = {Development of auditory function in newborn infants revealed by auditory brainstem potentials},
	Volume = {60},
	Year = {1977}}

@article{tremblay_processing_2013,
	Abstract = {The supratemporal plane contains several functionally heterogeneous subregions that respond strongly to speech. Much of the prior work on the issue of speech processing in the supratemporal plane has focused on neural responses to single speech vs. non-speech sounds rather than focusing on higher-level computations that are required to process more complex auditory sequences. Here we examined how information is integrated over time for speech and non-speech sounds by quantifying the BOLD fMRI response to stochastic (non-deterministic) sequences of speech and non-speech naturalistic sounds that varied in their statistical structure (from random to highly structured sequences) during passive listening. Behaviorally, the participants were accurate in segmenting speech and non-speech sequences, though they were more accurate for speech. Several supratemporal regions showed increased activation magnitude for speech sequences (preference), but, importantly, this did not predict sensitivity to statistical structure: (i) several areas showing a speech preference were sensitive to statistical structure in both speech and non-speech sequences, and (ii) several regions that responded to both speech and non-speech sounds showed distinct responses to statistical structure in speech and non-speech sequences. While the behavioral findings highlight the tight relation between statistical structure and segmentation processes, the neuroimaging results suggest that the supratemporal plane mediates complex statistical processing for both speech and non-speech sequences and emphasize the importance of studying the neurocomputations associated with auditory sequence processing. These findings identify new partitions of functionally distinct areas in the supratemporal plane that cannot be evoked by single stimuli. The findings demonstrate the importance of going beyond input preference to examine the neural computations implemented in the superior temporal plane.},
	Author = {Tremblay, P. and Baroni, M. and Hasson, U.},
	Doi = {10.1016/j.neuroimage.2012.10.055},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BPFQH4XA/Tremblay et al. - 2013 - Processing of speech and non-speech sounds in the .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AQ4F5C4M/S1053811912010580.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Speech processing, Statistical regularities, Supratemporal plane, language},
	Month = feb,
	Pages = {318--332},
	Shorttitle = {Processing of speech and non-speech sounds in the supratemporal plane},
	Title = {Processing of speech and non-speech sounds in the supratemporal plane: {Auditory} input preference does not predict sensitivity to statistical structure},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811912010580},
	Urldate = {2014-10-21},
	Volume = {66},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912010580},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.10.055}}

@article{vouloumanos_listening_2007,
	Abstract = {The nature and origin of the human capacity for acquiring language is not yet fully understood. Here we uncover early roots of this capacity by demonstrating that humans are born with a preference for listening to speech. Human neonates adjusted their high amplitude sucking to preferentially listen to speech, compared with complex non-speech analogues that controlled for critical spectral and temporal parameters of speech. These results support the hypothesis that human infants begin language acquisition with a bias for listening to speech. The implications of these results for language and communication development are discussed. For a commentary on this article see Rosen and Iverson (2007).},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena and Werker, Janet F},
	Date-Modified = {2020-06-16 13:47:04 +0200},
	Doi = {10.1111/j.1467-7687.2007.00549.x},
	File = {Vouloumanos_2007_series.pdf:/Users/Cecile/Zotero/storage/BDIA78F9/Vouloumanos_2007_series.pdf:application/pdf},
	Issn = {1363-755X},
	Journal = {Developmental science},
	Keywords = {Acoustic Stimulation, Attention, Humans, Infant Behavior, Infant, Newborn, Sound Spectrography, Sucking Behavior, language, speech perception, Speech Perception},
	Language = {eng},
	Month = mar,
	Number = {2},
	Pages = {159--164},
	Pmid = {17286838},
	Shorttitle = {Listening to language at birth},
	Title = {Listening to language at birth: evidence for a bias for speech in neonates},
	Volume = {10},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1111/j.1467-7687.2007.00549.x}}

@article{belin_before_2010,
	Abstract = {In this issue of Neuron, Grossmann et al. provide the first evidence of voice-sensitive regions in the brain of 7-month-old, but not 4-month-old, infants. We discuss the implications of these findings for our understanding of cerebral voice processing in the first months of life.},
	Author = {Belin, Pascal and Grosbras, Marie-H{\'e}l{\`e}ne},
	Doi = {10.1016/j.neuron.2010.03.018},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/674TFQ39/Belin et Grosbras - 2010 - Before Speech Cerebral Voice Processing in Infant.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZFBZ3MND/S0896627310001893.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = mar,
	Number = {6},
	Pages = {733--735},
	Shorttitle = {Before {Speech}},
	Title = {Before {Speech}: {Cerebral} {Voice} {Processing} in {Infants}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627310001893},
	Urldate = {2016-03-17},
	Volume = {65},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627310001893},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2010.03.018}}

@article{woldorff_distortion_1993,
	Abstract = {In studies of event-related potentials (ERPs), short interstimulus intervals (ISIs) are often employed to investigate certain neural or psychological phenomena. At short ISIs, however, the ERP responses to successive stimuli may overlap, thereby distorting the ERP averages. This paper describes a signal processing approach for analyzing the distortion of ERP averages due to such overlap. In general, the distortion is modeled in terms of mathematical convolutions of the ERP waveform elicited by each type of adjacent stimulus with the corresponding distribution in time of those stimuli relative to the averaging epoch. Using this framework, a number of implications of ERP overlap for experimental design and interpretation are examined, with special emphasis given to selective attention paradigms. It is shown that the possibility of confound due to ERP overlap is widespread in short-ISI experiments, and even the widely used procedure of stimulus randomization does not necessarily control for differential distortion of the ERPs to attended versus unattended stimuli. Problems due to ERP overlap can be particularly serious in short-ISI studies that examine how ERPs (and associated perceptual processes) are influenced by the nature of the preceding stimulus (i.e., stimulus sequence effects). A set of algorithms is presented for estimating and removing the residual distortion due to response overlap from recorded ERP averages. The use of these algorithms, collectively termed the Adjacent Response (Adjar) Technique, can alleviate many of the overlap-related problems that arise when short ISIs are used, thereby enhancing the power of the ERP technique.},
	Author = {Woldorff, M. G.},
	Issn = {0048-5772},
	Journal = {Psychophysiology},
	Keywords = {Arousal, Attention, Cerebral Cortex, Artifacts, Dominance, Cerebral, Pitch Discrimination, Electroencephalography, Evoked Potentials, Auditory, Algorithms, Humans, Signal Processing, Computer-Assisted},
	Language = {eng},
	Month = jan,
	Number = {1},
	Pages = {98--119},
	Pmid = {8416067},
	Shorttitle = {Distortion of {ERP} averages due to overlap from temporally adjacent {ERPs}},
	Title = {Distortion of {ERP} averages due to overlap from temporally adjacent {ERPs}: analysis and correction},
	Volume = {30},
	Year = {1993}}

@article{henry_frequency_2012,
	Abstract = {The human ability to continuously track dynamic environmental stimuli, in particular speech, is proposed to profit from ``entrainment'' of endogenous neural oscillations, which involves phase reorganization such that ``optimal'' phase comes into line with temporally expected critical events, resulting in improved processing. The current experiment goes beyond previous work in this domain by addressing two thus far unanswered questions. First, how general is neural entrainment to environmental rhythms: Can neural oscillations be entrained by temporal dynamics of ongoing rhythmic stimuli without abrupt onsets? Second, does neural entrainment optimize performance of the perceptual system: Does human auditory perception benefit from neural phase reorganization? In a human electroencephalography study, listeners detected short gaps distributed uniformly with respect to the phase angle of a 3-Hz frequency-modulated stimulus. Listeners' ability to detect gaps in the frequency-modulated sound was not uniformly distributed in time, but clustered in certain preferred phases of the modulation. Moreover, the optimal stimulus phase was individually determined by the neural delta oscillation entrained by the stimulus. Finally, delta phase predicted behavior better than stimulus phase or the event-related potential after the gap. This study demonstrates behavioral benefits of phase realignment in response to frequency-modulated auditory stimuli, overall suggesting that frequency fluctuations in natural environmental input provide a pacing signal for endogenous neural oscillations, thereby influencing perceptual processing.},
	Author = {Henry, Molly J. and Obleser, Jonas},
	Doi = {10.1073/pnas.1213390109},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Q6E87GZI/Henry et Obleser - 2012 - Frequency modulation entrains slow neural oscillat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JQSRBSF2/20095.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {EEG, FM, auditory processing, pre-stimulus phase},
	Language = {en},
	Month = apr,
	Number = {49},
	Pages = {20095--20100},
	Pmid = {23151506},
	Title = {Frequency modulation entrains slow neural oscillations and optimizes human listening behavior},
	Url = {http://www.pnas.org/content/109/49/20095},
	Urldate = {2014-10-31},
	Volume = {109},
	Year = {2012},
	Bdsk-Url-1 = {http://www.pnas.org/content/109/49/20095},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1213390109}}

@article{millman_role_2015,
	Author = {Millman, Rebecca E. and Johnson, Sam R. and Prendergast, Garreth},
	Doi = {10.1162/jocn_a_00719},
	File = {jocn_MillmanJohnsonPrendengast.pdf:/Users/Cecile/Zotero/storage/B2TR4AXD/jocn_MillmanJohnsonPrendengast.pdf:application/pdf},
	Issn = {0898-929X, 1530-8898},
	Journal = {Journal of Cognitive Neuroscience},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {533--545},
	Title = {The {Role} of {Phase}-locking to the {Temporal} {Envelope} of {Speech} in {Auditory} {Perception} and {Speech} {Intelligibility}},
	Url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00719},
	Urldate = {2015-07-30},
	Volume = {27},
	Year = {2015},
	Bdsk-Url-1 = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn_a_00719},
	Bdsk-Url-2 = {https://doi.org/10.1162/jocn_a_00719}}

@article{shannon_speech_1995,
	Abstract = {Nearly perfect speech recognition was observed under conditions of greatly reduced spectral information. Temporal envelopes of speech were extracted from broad frequency bands and were used to modulate noises of the same bandwidths. This manipulation preserved temporal envelope cues in each band but restricted the listener to severely degraded information on the distribution of spectral energy. The identification of consonants, vowels, and words in simple sentences improved markedly as the number of bands increased; high speech recognition performance was obtained with only three bands of modulated noise. Thus, the presentation of a dynamic temporal pattern in only a few broad spectral regions is sufficient for the recognition of speech.},
	Author = {Shannon, Robert V. and Zeng, Fan-Gang and Kamath, Vivek and Wygonski, John and Ekelid, Michael},
	Doi = {10.1126/science.270.5234.303},
	File = {Snapshot:/Users/Cecile/Zotero/storage/3KKNMHWK/303.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = oct,
	Number = {5234},
	Pages = {303--304},
	Pmid = {7569981},
	Title = {Speech {Recognition} with {Primarily} {Temporal} {Cues}},
	Url = {http://www.sciencemag.org/content/270/5234/303},
	Urldate = {2013-10-17},
	Volume = {270},
	Year = {1995},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/270/5234/303},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.270.5234.303}}

@incollection{vaissiere_language-independent_1983,
	Abstract = {The purpose of this contribution is to investigate the similarities in form and function of prosody among diverse languages. All speakers, regardless of their specific language, are equipped with the same production and perception apparatus, and consequently have the same capabilities and must face the same physiological constraints. Such similarities should be reflected in the acoustic production of any speaker. The first specific aim of this contribution is to review a number of striking acoustic similarities in the suprasegmental aspects of neutral sentences in different languages, together with possible physiological explanations for them.},
	Author = {Vaissi{\`e}re, Jacqueline},
	Booktitle = {Prosody: {Models} and {Measurements}},
	Copyright = {{\copyright}1983 Springer-Verlag Berlin Heidelberg},
	Editor = {Cutler, Anne and Ladd, Robert D.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/RHZ8GS5K/978-3-642-69103-4_5.html:text/html},
	Isbn = {978-3-642-69105-8 978-3-642-69103-4},
	Keywords = {Acoustics},
	Language = {en},
	Month = jan,
	Number = {14},
	Pages = {53--66},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Springer {Series} in {Language} and {Communication}},
	Title = {Language-{Independent} {Prosodic} {Features}},
	Url = {http://link.springer.com/chapter/10.1007/978-3-642-69103-4_5},
	Urldate = {2013-12-15},
	Year = {1983},
	Bdsk-Url-1 = {http://link.springer.com/chapter/10.1007/978-3-642-69103-4_5}}

@article{delivoria-papadopoulos_postnatal_1971,
	Author = {Delivoria-Papadopoulos, Maria and Roncevic, Nevenka P and Oski, Franck A},
	File = {Pediatric Research - Abstract of article\: Postnatal Changes in Oxygen Transport of Term, Premature, and Sick Infants\: The Role of Red Cell 2,3-Diphosphoglycerate and Adult Hemoglobin:/Users/Cecile/Zotero/storage/QQCXF7KN/pr1971100a.html:text/html},
	Journal = {Pediatric Research},
	Number = {5},
	Pages = {235--245},
	Title = {Postnatal {Changes} in {Oxygen} {Transport} of {Term}, {Premature}, and {Sick} {Infants}: {The} {Role} of {Red} {Cell} 2,3-{Diphosphoglycerate} and {Adult} {Hemoglobin}},
	Url = {http://www.nature.com/pr/journal/v5/n6/abs/pr1971100a.html},
	Urldate = {2017-02-28},
	Year = {1971},
	Bdsk-Url-1 = {http://www.nature.com/pr/journal/v5/n6/abs/pr1971100a.html}}

@article{r._wise_distribution_1991,
	Author = {{R. Wise} and {F. Chollet,} and {U. Hadar} and {K. Friston} and {E. Hoffner} and {R. Frackowiak}},
	Journal = {Brain},
	Month = aug,
	Number = {4},
	Pages = {1803--1817},
	Title = {Distribution of cortical neural networks involved in word comprehension and word retrieval},
	Volume = {114},
	Year = {1991}}

@article{vanrullen_how_2016,
	Abstract = {A growing number of studies endeavor to reveal periodicities in sensory and cognitive functions, by comparing the distribution of ongoing (pre-stimulus) oscillatory phases between two (or more) trial groups reflecting distinct experimental outcomes. A systematic relation between the phase of spontaneous electrophysiological signals, before a stimulus is even presented, and the eventual result of sensory or cognitive processing for that stimulus, would be indicative of an intrinsic periodicity in the underlying neural process. Prior studies of phase-dependent perception have used a variety of analytical methods to measure and evaluate phase differences, and there is currently no established standard practice in this field. The present report intends to remediate this need, by systematically comparing the statistical power of various measures of ``phase opposition'' between two trial groups, in a number of real and simulated experimental situations. Seven measures were evaluated: one parametric test (circular Watson-Williams test), and three distinct measures of phase opposition (phase bifurcation index, phase opposition sum, and phase opposition product) combined with two procedures for non-parametric statistical testing (permutation, or a combination of z-score and permutation). While these are obviously not the only existing or conceivable measures, they have all been used in recent studies. All tested methods performed adequately on a previously published dataset (Busch et al., ). On a variety of artificially constructed datasets, no single measure was found to surpass all others, but instead the suitability of each measure was contingent on several experimental factors: the time, frequency, and depth of oscillatory phase modulation; the absolute and relative amplitudes of post-stimulus event-related potentials for the two trial groups; the absolute and relative trial numbers for the two groups; and the number of permutations used for non-parametric testing. The concurrent use of two phase opposition measures, the parametric Watson-Williams test and a non-parametric test based on summing inter-trial coherence values for the two trial groups, appears to provide the most satisfactory outcome in all situations tested. Matlab code is provided to automatically compute these phase opposition measures.},
	Author = {VanRullen, Rufin},
	Doi = {10.3389/fnins.2016.00426},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/E9KJ66W8/VanRullen - 2016 - How to Evaluate Phase Differences between Trial Gr.pdf:application/pdf},
	Issn = {1662-4548},
	Journal = {Frontiers in Neuroscience},
	Month = sep,
	Pmcid = {PMC5021700},
	Pmid = {27683543},
	Title = {How to {Evaluate} {Phase} {Differences} between {Trial} {Groups} in {Ongoing} {Electrophysiological} {Signals}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5021700/},
	Urldate = {2017-10-12},
	Volume = {10},
	Year = {2016},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5021700/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2016.00426}}

@article{saberi_cognitive_1999,
	Abstract = {Speech is the most complex auditory signal and requires the most processing. The human brain devotes large cortical areas, to deciphering the information it contains, as well as parsing speech sounds produced simultaneously by several speakers. The brain can also invoke corrective measures to restore distortions in speech; for example, if a brief speech sound is replaced by an interfering sound that masks it, such as a cough, the listener perceives the missing speech as if the brain interpolates through the absent segment. We have studied the intelligibility of speech, and find it is resistant to time reversal of local segments of a spoken sentence, which has been described as "the most drastic form of time scale distortion".},
	Author = {Saberi, Kourosh and Perrott, David R.},
	Copyright = {{\copyright} 1999 Nature Publishing Group},
	Doi = {10.1038/19652},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4BKPT5XU/Saberi et Perrott - 1999 - Cognitive restoration of reversed speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CHD2QI6N/398760a0.html:text/html},
	Issn = {0028-0836},
	Journal = {Nature},
	Language = {en},
	Month = apr,
	Number = {6730},
	Pages = {760--760},
	Title = {Cognitive restoration of reversed speech},
	Url = {http://www.nature.com/nature/journal/v398/n6730/full/398760a0.html},
	Urldate = {2015-12-15},
	Volume = {398},
	Year = {1999},
	Bdsk-Url-1 = {http://www.nature.com/nature/journal/v398/n6730/full/398760a0.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/19652}}

@article{carral_kind_2005,
	Abstract = {`Primitive intelligence' in audition refers to the capacity of the auditory system to adaptatively model the acoustic regularity and react neurophysiologically to violations of such regularity, thus supporting the ability to predict future auditory events. In the present study, event-related brain potentials to pairs of tones were recorded in 11 human newborns to determine the infants' ability to extract an abstract acoustic rule, the direction of a frequency change. Most of the pairs (standard, P = 0.875) were of ascending frequency (i.e. the second tone higher than the first), while the remaining pairs (deviant, P = 0.125) were of descending frequency (the second tone being lower). Their frequencies varied among seven levels to prevent discrimination between standard and deviant pairs on the basis of absolute frequencies. We found that event-related brain potentials to deviant pairs differed in amplitude from those to standard pairs at 50--450 ms from the onset of the second tone of a pair, indicating the infants' ability to represent the abstract rule. This finding suggests the early ontogenetic origin of `primitive intelligence' in audition that eventually may form a prerequisite for later language acquisition.},
	Author = {Carral, Vanessa and Huotilainen, Minna and Ruusuvirta, Timo and Fellman, Vineta and N{\"a}{\"a}t{\"a}nen, Risto and Escera, Carles},
	Doi = {10.1111/j.1460-9568.2005.04144.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T6HNXWES/Carral et al. - 2005 - A kind of auditory `primitive intelligence' alread.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GWRPZ9WN/abstract\;jsessionid=35A2C645937DC92F340D9889BE2DA89F.html:text/html},
	Issn = {1460-9568},
	Journal = {European Journal of Neuroscience},
	Keywords = {Auditory Perception, abstract regularities, change detection, human infant, Mismatch negativity},
	Language = {en},
	Month = jun,
	Number = {11},
	Pages = {3201--3204},
	Title = {A kind of auditory `primitive intelligence' already present at birth},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1460-9568.2005.04144.x/abstract},
	Urldate = {2016-03-14},
	Volume = {21},
	Year = {2005},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1460-9568.2005.04144.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1460-9568.2005.04144.x}}

@article{buzsaki_origin_2012,
	Abstract = {Neuronal activity in the brain gives rise to transmembrane currents that can be measured in the extracellular medium. Although the major contributor of the extracellular signal is the synaptic transmembrane current, other sources --- including Na+ and Ca2+ spikes, ionic fluxes through voltage- and ligand-gated channels, and intrinsic membrane oscillations --- can substantially shape the extracellular field. High-density recordings of field activity in animals and subdural grid recordings in humans, combined with recently developed data processing tools and computational modelling, can provide insight into the cooperative behaviour of neurons, their average synaptic input and their spiking output, and can increase our understanding of how these processes contribute to the extracellular signal.},
	Author = {Buzs{\'a}ki, Gy{\"o}rgy and Anastassiou, Costas A. and Koch, Christof},
	Copyright = {{\copyright} 2012 Nature Publishing Group},
	Doi = {10.1038/nrn3241},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6CJM6MS4/Buzs{\'a}ki et al. - 2012 - The origin of extracellular fields and currents --- .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/V57BQ3SP/nrn3241.html:text/html},
	Issn = {1471-003X},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {407--420},
	Title = {The origin of extracellular fields and currents --- {EEG}, {ECoG}, {LFP} and spikes},
	Url = {http://www.nature.com/nrn/journal/v13/n6/abs/nrn3241.html},
	Urldate = {2015-07-13},
	Volume = {13},
	Year = {2012},
	Bdsk-Url-1 = {http://www.nature.com/nrn/journal/v13/n6/abs/nrn3241.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn3241}}

@article{averbeck_principal_2004,
	Author = {Averbeck, B. B.},
	Doi = {10.1152/jn.01103.2003},
	File = {Web of Knowledge [v.5.10] - All Databases:/Users/Cecile/Zotero/storage/7K9U5F82/full_record.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Month = jun,
	Number = {6},
	Pages = {2897--2909},
	Shorttitle = {Principal and {Independent} {Components} of {Macaque} {Vocalizations}},
	Title = {Principal and {Independent} {Components} of {Macaque} {Vocalizations}: {Constructing} {Stimuli} to {Probe} {High}-{Level} {Sensory} {Processing}},
	Url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=11&SID=P2539gp3JpbfaaifH6k&page=8&doc=77&cacheurlFromRightClick=no},
	Urldate = {2013-07-17},
	Volume = {91},
	Year = {2004},
	Bdsk-Url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=11&SID=P2539gp3JpbfaaifH6k&page=8&doc=77&cacheurlFromRightClick=no},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.01103.2003}}

@article{ding_cortical_2015,
	Abstract = {The most critical attribute of human language is its unbounded combinatorial nature: smaller elements can be combined into larger structures on the basis of a grammatical system, resulting in a hierarchy of linguistic units, such as words, phrases and sentences. Mentally parsing and representing such structures, however, poses challenges for speech comprehension. In speech, hierarchical linguistic structures do not have boundaries that are clearly defined by acoustic cues and must therefore be internally and incrementally constructed during comprehension. We found that, during listening to connected speech, cortical activity of different timescales concurrently tracked the time course of abstract linguistic structures at different hierarchical levels, such as words, phrases and sentences. Notably, the neural tracking of hierarchical linguistic structures was dissociated from the encoding of acoustic cues and from the predictability of incoming words. Our results indicate that a hierarchy of neural processing timescales underlies grammar-based internal construction of hierarchical linguistic structure.},
	Author = {Ding, Nai and Melloni, Lucia and Zhang, Hang and Tian, Xing and Poeppel, David},
	Copyright = {{\copyright} 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/nn.4186},
	File = {Ding Poeppel etal 2015 Hierarchical linguistic structures MEG.pdf:/Users/Cecile/Zotero/storage/K6GH3BE7/Ding Poeppel etal 2015 Hierarchical linguistic structures MEG.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IEMRXBQD/nn.4186.html:text/html},
	Issn = {1097-6256},
	Journal = {Nature Neuroscience},
	Keywords = {Psychology, Sensory processing, language},
	Language = {en},
	Month = dec,
	Title = {Cortical tracking of hierarchical linguistic structures in connected speech},
	Url = {http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn.4186.html},
	Urldate = {2015-12-16},
	Volume = {advance online publication},
	Year = {2015},
	Bdsk-Url-1 = {http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn.4186.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.4186}}

@article{kisilevsky_effects_2003,
	Abstract = {The ability of human fetuses to recognize their own mother's voice was examined. Sixty term fetuses were assigned to one of two conditions during which they were exposed to a tape recording of their mother or a female stranger reading a passage. Voice stimuli were delivered through a loudspeaker held approximately 10 cm above the maternal abdomen and played at an average of 95 dB SPL. Each condition consisted of three 2-min periods: no stimulus, voice (mother or stranger), and no stimulus. Fetal heart rate increased in response to the mother's voice and decreased in response to the stranger's; both responses were sustained for 4 min. The finding of differential behavior in response to a familiar versus a novel voice provides evidence that experience influences fetal voice processing. It supports an epigenetic model of speech perception, presuming an interaction between genetic expression of neural development and species-specific experience.},
	Author = {Kisilevsky, Barbara S. and Hains, Sylvia M. J. and Lee, Kang and Xie, Xing and Huang, Hefeng and Ye, Hai Hui and Zhang, Ke and Wang, Zengping},
	Doi = {10.1111/1467-9280.02435},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/SQNT6FEF/Kisilevsky et al. - 2003 - Effects of Experience on Fetal Voice Recognition.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4ZZM6D9F/220.html:text/html},
	Issn = {0956-7976, 1467-9280},
	Journal = {Psychological Science},
	Language = {en},
	Month = may,
	Number = {3},
	Pages = {220--224},
	Pmid = {12741744},
	Title = {Effects of {Experience} on {Fetal} {Voice} {Recognition}},
	Url = {http://pss.sagepub.com/content/14/3/220},
	Urldate = {2015-04-01},
	Volume = {14},
	Year = {2003},
	Bdsk-Url-1 = {http://pss.sagepub.com/content/14/3/220},
	Bdsk-Url-2 = {https://doi.org/10.1111/1467-9280.02435}}

@article{ramus_correlates_2000,
	Abstract = {Spoken languages have been classified by linguists according to their rhythmic properties, and psycholinguists have relied on this classification to account for infants' capacity to discriminate languages. Although researchers have measured many speech signal properties, they have failed to identify reliable acoustic characteristics for language classes. This paper presents instrumental measurements based on a consonant/vowel segmentation for eight languages. The measurements suggest that intuitive rhythm types reflect specific phonological properties, which in turn are signaled by the acoustic/phonetic properties of speech. The data support the notion of rhythm classes and also allow the simulation of infant language discrimination, consistent with the hypothesis that newborns rely on a coarse segmentation of speech. A hypothesis is proposed regarding the role of rhythm perception in language acquisition.},
	Author = {Ramus, Franck and Nespor, Marina and Mehler, Jacques},
	Doi = {10.1016/S0010-0277(00)00101-3},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/G68EZW2I/Ramus et al. - 2000 - Correlates of linguistic rhythm in the speech sign.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PAGB43HS/S0010027700001013.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Keywords = {Language discrimination, Phonological bootstrapping, Speech rhythm, Syllable structure, language acquisition, prosody},
	Month = apr,
	Number = {1},
	Pages = {AD3--AD30},
	Title = {Correlates of linguistic rhythm in the speech signal},
	Url = {http://www.sciencedirect.com/science/article/pii/S0010027700001013},
	Urldate = {2013-12-06},
	Volume = {75},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0010027700001013},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0010-0277(00)00101-3}}

@article{ming_efficient_2009,
	Abstract = {Natural sounds possess characteristic statistical regularities. Recent research suggests that mammalian auditory processing maximizes information about these regularities in its internal representation while minimizing encoding cost [Smith, E. C. and Lewicki, M. S. (2006). Nature (London) 439, 978--982]. Evidence for this ``efficient coding hypothesis'' comes largely from neurophysiology and theoretical modeling [Olshausen, B. A., and Field, D. (2004). Curr. Opin. Neurobiol. 14, 481--487; DeWeese, M., et al. (2003). J. Neurosci. 23, 7940--7949; Klein, D. J., et al. (2003). EURASIP J. Appl. Signal Process. 7, 659--667]. The present research provides behavioral evidence for efficient coding in human auditory perception using six-channel noise-vocoded speech, which drastically limits spectral information and degrades recognition accuracy. Two experiments compared recognition accuracy of vocoder speech created using theoretically-motivated, efficient coding filterbanks derived from the statistical regularities of speech against recognition using standard cochleotopic (logarithmic) or linear filterbanks. Recognition of the speech created using efficient encoding filterbanks was significantly more accurate than either of the other classes. These findings suggest potential applications to cochlear implant design.},
	Author = {Ming, Vivienne L. and Holt, Lori L.},
	Doi = {10.1121/1.3158939},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/SHAC8PXC/Ming et Holt - 2009 - Efficient coding in human auditory perception.pdf:application/pdf},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = sep,
	Number = {3},
	Pages = {1312--1320},
	Pmcid = {PMC2809690},
	Pmid = {19739745},
	Title = {Efficient coding in human auditory perception},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809690/},
	Urldate = {2015-02-02},
	Volume = {126},
	Year = {2009},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2809690/},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.3158939}}

@article{cabrera_perception_2013,
	Author = {Cabrera, Laurianne and Bertoncini, Josiane and Lorenzi, Christian},
	Doi = {10.1044/1092-4388(2013/12-0169)},
	File = {Perception of Speech Modulation Cues by 6-Month-Old Infants:/Users/Cecile/Zotero/storage/BB429Q3E/256491224_Perception_of_Speech_Modulation_Cues_by_6-Month-Old_Infants.html:text/html},
	Issn = {1558-9102},
	Journal = {Journal of speech, language, and hearing research : JSLHR},
	Number = {6},
	Title = {Perception of {Speech} {Modulation} {Cues} by 6-{Month}-{Old} {Infants}},
	Volume = {56},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1044/1092-4388(2013/12-0169)}}

@article{kayser_analysis_2012,
	Abstract = {Neurons in sensory cortices encode objects in our sensory environment by varying the timing and number of action potentials that they emit. Brain networks that `decode' this information need to partition those spike trains into their individual informative units. Experimenters achieve such partitioning by exploiting their knowledge about the millisecond precise timing of individual spikes relative to externally presented sensory stimuli. The brain, however, does not have access to this information and has to partition and decode spike trains using intrinsically available temporal reference frames. We show that slow (4--8 Hz) oscillatory network activity can provide such an intrinsic temporal reference. Specifically, we analyzed neural responses recorded in primary auditory and visual cortices. This revealed that the oscillatory reference frame performs nearly as well as the precise stimulus-locked reference frame and renders neural encoding robust to sensory noise and temporal uncertainty that naturally occurs during decoding. These findings provide a computational proof-of-concept that slow oscillatory network activity may serve the crucial function as temporal reference frame for sensory coding.},
	Author = {Kayser, Christoph and Ince, Robin A. A. and Panzeri, Stefano},
	Doi = {10.1371/journal.pcbi.1002717},
	File = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/W78DVIBJ/Kayser et al. - 2012 - Analysis of Slow (Theta) Oscillations as a Potenti.pdf:application/pdf;PLoS Snapshot:/Users/Cecile/Zotero/storage/WHAAVUMF/infodoi10.1371journal.pcbi.html:text/html;SinghTheunissen2003.pdf:/Users/Cecile/Zotero/storage/RA88M7IH/SinghTheunissen2003.pdf:application/pdf},
	Journal = {PLoS Comput Biol},
	Month = oct,
	Number = {10},
	Pages = {e1002717},
	Title = {Analysis of {Slow} ({Theta}) {Oscillations} as a {Potential} {Temporal} {Reference} {Frame} for {Information} {Coding} in {Sensory} {Cortices}},
	Url = {http://dx.doi.org/10.1371/journal.pcbi.1002717},
	Urldate = {2014-10-31},
	Volume = {8},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1002717}}

@article{rossi_shedding_2012,
	Abstract = {Investigating the neuronal network underlying language processing may contribute to a better understanding of how the brain masters this complex cognitive function with surprising ease and how language is acquired at a fast pace in infancy. Modern neuroimaging methods permit to visualize the evolvement and the function of the language network. The present paper focuses on a specific methodology, functional near-infrared spectroscopy (fNIRS), providing an overview over studies on auditory language processing and acquisition. The methodology detects oxygenation changes elicited by functional activation of the cerebral cortex. The main advantages for research on auditory language processing and its development during infancy are an undemanding application, the lack of instrumental noise, and its potential to simultaneously register electrophysiological responses. Also it constitutes an innovative approach for studying developmental issues in infants and children. The review will focus on studies on word and sentence processing including research in infants and adults.},
	Author = {Rossi, Sonja and Telkemeyer, Silke and Wartenburger, Isabell and Obrig, Hellmuth},
	Doi = {10.1016/j.bandl.2011.03.008},
	Issn = {1090-2155},
	Journal = {Brain and Language},
	Keywords = {Adult, Brain Mapping, Child, Humans, Infant, Language Development, Spectroscopy, Near-Infrared, language, speech perception, Brain, Speech Perception},
	Language = {eng},
	Month = may,
	Number = {2},
	Pages = {152--163},
	Pmid = {21546074},
	Shorttitle = {Shedding light on words and sentences},
	Title = {Shedding light on words and sentences: near-infrared spectroscopy in language research},
	Volume = {121},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.bandl.2011.03.008}}

@article{guediche_speech_2014,
	Abstract = {Adult speech perception reflects the long-term regularities of the native language, but it is also flexible such that it accommodates and adapts to adverse listening conditions and short-term deviations from native-language norms. The purpose of this article is to examine how the broader neuroscience literature can inform and advance research efforts in understanding the neural basis of flexibility and adaptive plasticity in speech perception. Specifically, we highlight the potential role of learning algorithms that rely on prediction error signals and discuss specific neural structures that are likely to contribute to such learning. To this end, we review behavioral studies, computational accounts, and neuroimaging findings related to adaptive plasticity in speech perception. Already, a few studies have alluded to a potential role of these mechanisms in adaptive plasticity in speech perception. Furthermore, we consider research topics in neuroscience that offer insight into how perception can be adaptively tuned to short-term deviations while balancing the need to maintain stability in the perception of learned long-term regularities. Consideration of the application and limitations of these algorithms in characterizing flexible speech perception under adverse conditions promises to inform theoretical models of speech.},
	Author = {Guediche, Sara and Blumstein, Sheila E. and Fiez, Julie A. and Holt, Lori L.},
	Doi = {10.3389/fnsys.2013.00126},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/SXTMAZED/Guediche et al. - 2014 - Speech perception under adverse conditions insigh.pdf:application/pdf},
	Issn = {1662-5137},
	Journal = {Frontiers in Systems Neuroscience},
	Month = jan,
	Pmcid = {PMC3879477},
	Pmid = {24427119},
	Shorttitle = {Speech perception under adverse conditions},
	Title = {Speech perception under adverse conditions: insights from behavioral, computational, and neuroscience research},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3879477/},
	Urldate = {2015-06-15},
	Volume = {7},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3879477/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnsys.2013.00126}}

@article{nazzi_language_1998,
	Abstract = {Three experiments investigated the ability of French newborns to discriminate between sets of sentences in different foreign languages. The sentences were low-pass filtered to reduce segmental information while sparing prosodic information. Infants discriminated between stress-timed English and mora-timed Japanese (Experiment 1) but failed to discriminate between stress-timed English and stress-timed Dutch (Experiment 2). In Experiment 3, infants heard different combinations of sentences from English, Dutch, Spanish, and Italian. Discrimination was observed only when English and Dutch sentences were contrasted with Spanish and Italian sentences. These results suggest that newborns use prosodic and, more specifically, rhythmic information to classify utterances into broad language classes defined according to global rhythmic properties. Implications of this for the acquisition of the rhythmic properties of the native language are discussed.},
	Author = {Nazzi, Thierry and Bertoncini, Josiane and Mehler, Jacques},
	Copyright = {(c) 2012 APA, all rights reserved},
	Doi = {10.1037/0096-1523.24.3.756},
	File = {Nazzi et al. - 1998 - Language discrimination by newborns Toward an und.pdf:/Users/Cecile/Zotero/storage/97AP3SZI/Nazzi et al. - 1998 - Language discrimination by newborns Toward an und.pdf:application/pdf},
	Issn = {1939-1277(Electronic);0096-1523(Print)},
	Journal = {Journal of Experimental Psychology: Human Perception and Performance},
	Keywords = {*Auditory Discrimination, *Foreign Languages, *Neonatal Development, *Rhythm, Verbal Communication},
	Number = {3},
	Pages = {756--766},
	Shorttitle = {Language discrimination by newborns},
	Title = {Language discrimination by newborns: {Toward} an understanding of the role of rhythm},
	Volume = {24},
	Year = {1998},
	Bdsk-Url-1 = {https://doi.org/10.1037/0096-1523.24.3.756}}

@article{elliott_modulation_2009,
	Abstract = {Author Summary
The sound signal of speech is rich in temporal and frequency patterns. These fluctuations of power in time and frequency are called modulations. Despite their acoustic complexity, spoken words remain intelligible after drastic degradations in either time or frequency. To fully understand the perception of speech and to be able to reduce speech to its most essential components, we need to completely characterize how modulations in amplitude and frequency contribute together to the comprehensibility of speech. Hallmark research distorted speech in either time or frequency but described the arbitrary manipulations in terms limited to one domain or the other, without quantifying the remaining and missing portions of the signal. Here, we use a novel sound filtering technique to systematically investigate the joint features in time and frequency that are crucial for understanding speech. Both the modulation-filtering approach and the resulting characterization of speech have the potential to change the way that speech is compressed in audio engineering and how it is processed in medical applications such as cochlear implants.},
	Author = {Elliott, Taffeta M. and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1371/journal.pcbi.1000302},
	File = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/IZKFACBS/Elliott et Theunissen - 2009 - The Modulation Transfer Function for Speech Intell.pdf:application/pdf},
	Journal = {PLoS Comput Biol},
	Month = mar,
	Number = {3},
	Pages = {e1000302},
	Title = {The {Modulation} {Transfer} {Function} for {Speech} {Intelligibility}},
	Url = {http://dx.doi.org/10.1371/journal.pcbi.1000302},
	Urldate = {2015-10-22},
	Volume = {5},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pcbi.1000302}}

@incollection{helmchen_two-photon_2009,
	Abstract = {For centuries scientists have been fascinated by the structure of the brain, all the more since the middle of the 19th century when advances in staining techniques enabled high-resolution light microscopic studies of brain cell morphology. Compared to studying cell morphology, it has been more difficult to experimentally investigate the dynamic nature of brain cells, including their morphological transformations, as well as the molecular and electrical signaling events underlying their specific functions. Still today, it remains challenging to study neural dynamics on the cellular level in intact brains of living animals. For many years, in vivo studies of brain cell dynamics relied solely on electrical recordings of neuronal activity, using either extracellular recordings of neuronal spike patterns or intracellular recordings of membrane potential dynamics. Strong light-scattering of neural tissue generally precluded optical imaging with cellular and subcellular resolution in the intact brain (with few exceptions in favorable cases [1]). A major breakthrough in 1990 was the invention of two-photon excited fluorescence laser scanning microscopy (TPLSM) [2], which enabled optical studies of brain cell morphology and function in vivo [3,4]. The success of TPLSM has been fostered by the parallel development of various novel staining techniques for in vivo labeling of brain cells with fluorescent markers. Expression of variants of fluorescent proteins by genetic means [5,6] complements the in vivo imaging capabilities of TPLSM particularly well. The combination of high-contrast fluorescence labeling of brain cells---neurons as well as glial cells---with high-resolution imaging in vivo has opened new research fields in neuroscience. It is now possible to watch brain cells ``at work'' so that neuroscientists can directly study cellular and molecular mechanisms underlying both normal brain function as well as brain diseases. Because of its great potential for gaining fundamental insights into how the brain develops, how it computes, and how it can adapt, in vivo two-photon imaging of brain cell dynamics has enormously expanded over the past decade, and it is still growing at a rapid pace. This chapter provides an overview of two-photon imaging of brain cell dynamics in vivo. Because the principles of two-photon fluorescence excitation and TPLSM technology are treated in detail in Chapter 3, I focus here on the principles of dynamic measurements of single-cell and network activity using state-of-the-art labeling methods and various laser-scanning approaches. A key aspect of ``activity'' is that it always refers to processes evolving in the temporal domain, be it electrical or chemical signaling, turnover of proteins, or changes in cell morphology. Therefore, imaging modes capable of reading out the ``dynamics'' of living brain cells over a wide range of time scales will be particularly highlighted. In vivo calcium imaging studies---as the most prominent, current approach for functional measurements---will be summarized, and examples from mammalian brain imaging will be provided on both the single-cell as well as the population level. The chapter ends with an outlook discussing ongoing developments that are expected to become important research directions in the next years.},
	Address = {Boca Raton (FL)},
	Author = {Helmchen, Fritjof},
	Booktitle = {In {Vivo} {Optical} {Imaging} of {Brain} {Function}},
	Copyright = {Copyright {\copyright} 2009, Taylor \& Francis Group, LLC.},
	Edition = {2nd},
	Editor = {Frostig, Ron D.},
	File = {Printable HTML:/Users/Cecile/Zotero/storage/2FRX72HG/NBK20230.html:text/html},
	Isbn = {978-1-4200-7684-4},
	Language = {eng},
	Pmid = {26844324},
	Publisher = {CRC Press/Taylor \& Francis},
	Series = {Frontiers in {Neuroscience}},
	Title = {Two-{Photon} {Functional} {Imaging} of {Neuronal} {Activity}},
	Url = {http://www.ncbi.nlm.nih.gov/books/NBK20230/},
	Urldate = {2016-09-16},
	Year = {2009},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/books/NBK20230/}}

@article{joly_processing_2012,
	Abstract = {Humans and many other animals use acoustical signals to mediate social interactions with conspecifics. The evolution of sound-based communication is still poorly understood and its neural correlates have only recently begun to be investigated. In the present study, we applied functional MRI to humans and macaque monkeys listening to identical stimuli in order to compare the cortical networks involved in the processing of vocalizations. At the first stages of auditory processing, both species showed similar fMRI activity maps within and around the lateral sulcus (the Sylvian fissure in humans). Monkeys showed remarkably similar responses to monkey calls and to human vocal sounds (speech or otherwise), mainly in the lateral sulcus and the adjacent superior temporal gyrus (STG). In contrast, a preference for human vocalizations and especially for speech was observed in the human STG and superior temporal sulcus (STS). The STS and Broca's region were especially responsive to intelligible utterances. The evolution of the language faculty in humans appears to have recruited most of the STS. It may be that in monkeys, a much simpler repertoire of vocalizations requires less involvement of this temporal territory.},
	Author = {Joly, Olivier and Pallier, Christophe and Ramus, Franck and Pressnitzer, Daniel and Vanduffel, Wim and Orban, Guy A},
	Doi = {10.1016/j.neuroimage.2012.05.070},
	Issn = {1095-9572},
	Journal = {NeuroImage},
	Keywords = {Animal Communication, Animals, Auditory Perception, Female, Humans, Macaca mulatta, Male, Vocalization, Animal, Young Adult, Brain, Magnetic resonance imaging},
	Language = {eng},
	Month = sep,
	Number = {3},
	Pages = {1376--1389},
	Pmid = {22659478},
	Shorttitle = {Processing of vocalizations in humans and monkeys},
	Title = {Processing of vocalizations in humans and monkeys: a comparative {fMRI} study},
	Volume = {62},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2012.05.070}}

@article{morais_does_1979,
	Abstract = {It was found that illiterate adults could neither delete nor add a phone at the beginning of a non-word; but these tasks were rather easily performed by people with similar environment and childhood experiences, who learned to read rudimentarily as adults. Awareness of speech as a sequence of phones is thus not attained spontaneously in the course of general cognitive growth, but demands some specific training, which, for most persons, is probably provided by learning to read in the alphabetic system.},
	Author = {Morais, Jos{\'e} and Cary, Luz and Alegria, J{\'e}sus and Bertelson, Paul},
	Doi = {10.1016/0010-0277(79)90020-9},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EHMQGIUE/Morais et al. - 1979 - Does awareness of speech as a sequence of phones a.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/2ATCCZBU/0010027779900209.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Number = {4},
	Pages = {323--331},
	Title = {Does awareness of speech as a sequence of phones arise spontaneously?},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027779900209},
	Urldate = {2014-12-04},
	Volume = {7},
	Year = {1979},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0010027779900209},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(79)90020-9}}

@article{coulon_effects_2013,
	Abstract = {For several decades, many authors have claimed the existence, early in life, of a tight link between perceptual and productive systems in speech. However, the question whether this link is acquired or is already present at birth remains open. This study aimed at investigating this question by employing the paradigm of neonatal facial imitation. We compared imitative responses of newborn infants presented either visual-only, audiovisual congruent, or audiovisual incongruent models. Our results revealed that the newborns imitated significantly more quickly the movements of the model's mouth when this model was audiovisual congruent rather than visual-only. Moreover, when observing an audiovisual incongruent model, the newborns did not produce imitative behavior. These findings, by highlighting the influence of speech perception on newborns' imitative responses, suggest that the neural architecture for perception--production is already in place at birth. The implications of these results are discussed in terms of a link between language and neonatal imitation, which could represent a precursor of more mature forms of vocal imitation and speech development in general.},
	Author = {Coulon, Marion and Hemimou, Cherhazad and Streri, Arlette},
	Copyright = {Copyright {\copyright} International Society on Infant Studies (ISIS)},
	Doi = {10.1111/infa.12001},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZQ8JF4UQ/Coulon et al. - 2013 - Effects of Seeing and Hearing Vowels on Neonatal F.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3ERBGMED/full.html:text/html},
	Issn = {1532-7078},
	Journal = {Infancy},
	Language = {en},
	Month = sep,
	Number = {5},
	Pages = {782--796},
	Title = {Effects of {Seeing} and {Hearing} {Vowels} on {Neonatal} {Facial} {Imitation}},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/infa.12001/abstract},
	Urldate = {2015-11-18},
	Volume = {18},
	Year = {2013},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/infa.12001/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/infa.12001}}

@article{peelle_hierarchical_2010,
	Author = {Peelle, Jonathan E. and Johnsrude, Ingrid S. and Davis, Matthew H.},
	Doi = {10.3389/fnhum.2010.00051},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/3FN2NCM2/Peelle et al. - 2010 - Hierarchical Processing for Speech in Human Audito.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = jun,
	Pmcid = {PMC2907234},
	Pmid = {20661456},
	Title = {Hierarchical {Processing} for {Speech} in {Human} {Auditory} {Cortex} and {Beyond}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2907234/},
	Urldate = {2015-05-22},
	Volume = {4},
	Year = {2010},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2907234/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2010.00051}}

@article{young_neural_2008,
	Abstract = {Speech is the most interesting and one of the most complex sounds dealt with by the auditory system. The neural representation of speech needs to capture those features of the signal on which the brain depends in language communication. Here we describe the representation of speech in the auditory nerve and in a few sites in the central nervous system from the perspective of the neural coding of important aspects of the signal. The representation is tonotopic, meaning that the speech signal is decomposed by frequency and different frequency components are represented in different populations of neurons. Essential to the representation are the properties of frequency tuning and nonlinear suppression. Tuning creates the decomposition of the signal by frequency, and nonlinear suppression is essential for maintaining the representation across sound levels. The representation changes in central auditory neurons by becoming more robust against changes in stimulus intensity and more transient. However, it is probable that the form of the representation at the auditory cortex is fundamentally different from that at lower levels, in that stimulus features other than the distribution of energy across frequency are analysed.},
	Author = {Young, Eric D.},
	Doi = {10.1098/rstb.2007.2151},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Q6Z6VMR7/Young - 2008 - Neural representation of spectral and temporal inf.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/XAN866PQ/Young - 2008 - Neural representation of spectral and temporal inf.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/445FPFPN/923.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/GGCIQVMN/923.html:text/html},
	Issn = {0962-8436, 1471-2970},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Keywords = {Speech, auditory nerve, discrimination, inferior colliculus, tonotopic, Auditory cortex},
	Language = {en},
	Month = dec,
	Number = {1493},
	Pages = {923--945},
	Pmid = {17827107},
	Title = {Neural representation of spectral and temporal information in speech},
	Url = {http://rstb.royalsocietypublishing.org/content/363/1493/923},
	Urldate = {2014-09-25},
	Volume = {363},
	Year = {2008},
	Bdsk-Url-1 = {http://rstb.royalsocietypublishing.org/content/363/1493/923},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2007.2151}}

@article{hyafil_speech_2015,
	Author = {Hyafil, Alexandre and Fontolan, Lorenzo},
	Doi = {10.7554/eLife.06213},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T7SFANC8/Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamm.pdf:application/pdf;Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamma oscillations.pdf:/Users/Cecile/Zotero/storage/WSZT5B57/Hyafil et al. - 2015 - Speech encoding by coupled cortical theta and gamma oscillations.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ACX8HQZ3/eLife.06213.html:text/html;Speech encoding by coupled cortical theta and gamma oscillations (PDF Download Available):/Users/Cecile/Zotero/storage/VAD3BREB/277407075_Speech_encoding_by_coupled_cortical_theta_and_gamma_oscillations.html:text/html},
	Issn = {2050-084X},
	Journal = {eLife},
	Title = {Speech encoding by coupled cortical theta and gamma oscillations},
	Volume = {4},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.7554/eLife.06213}}

@article{segaert_suppression_2013,
	Abstract = {Repetition suppression in fMRI studies is generally thought to underlie behavioural facilitation effects (i.e., priming) and it is often used to identify the neuronal representations associated with a stimulus. However, this pays little heed to the large number of repetition enhancement effects observed under similar conditions. In this review, we identify several cognitive variables biasing repetition effects in the BOLD response towards enhancement instead of suppression. These variables are stimulus recognition, learning, attention, expectation and explicit memory. We also evaluate which models can account for these repetition effects and come to the conclusion that there is no one single model that is able to embrace all repetition enhancement effects. Accumulation, novel network formation as well as predictive coding models can all explain subsets of repetition enhancement effects.},
	Author = {Segaert, Katrien and Weber, Kirsten and de Lange, Floris P. and Petersson, Karl Magnus and Hagoort, Peter},
	Doi = {10.1016/j.neuropsychologia.2012.11.006},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/5IC62V2R/Segaert et al. - 2013 - The suppression of repetition enhancement A revie.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7KDZE4IE/S0028393212004733.html:text/html},
	Issn = {0028-3932},
	Journal = {Neuropsychologia},
	Keywords = {fMRI adaptation, priming, repetition enhancement, repetition suppression},
	Month = jan,
	Number = {1},
	Pages = {59--66},
	Shorttitle = {The suppression of repetition enhancement},
	Title = {The suppression of repetition enhancement: {A} review of {fMRI} studies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0028393212004733},
	Urldate = {2016-09-19},
	Volume = {51},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0028393212004733},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuropsychologia.2012.11.006}}

@article{dicarlo_untangling_2007,
	Abstract = {Despite tremendous variation in the appearance of visual objects, primates can recognize a multitude of objects, each in a fraction of a second, with no apparent effort. However, the brain mechanisms that enable this fundamental ability are not understood. Drawing on ideas from neurophysiology and computation, we present a graphical perspective on the key computational challenges of object recognition, and argue that the format of neuronal population representation and a property that we term `object tangling' are central. We use this perspective to show that the primate ventral visual processing stream achieves a particularly effective solution in which single-neuron invariance is not the goal. Finally, we speculate on the key neuronal mechanisms that could enable this solution, which, if understood, would have far-reaching implications for cognitive neuroscience.},
	Author = {DiCarlo, James J. and Cox, David D.},
	Doi = {10.1016/j.tics.2007.06.010},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EU788PCW/DiCarlo et Cox - 2007 - Untangling invariant object recognition.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/U5ZPX7WE/S1364661307001593.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Month = aug,
	Number = {8},
	Pages = {333--341},
	Title = {Untangling invariant object recognition},
	Url = {http://www.sciencedirect.com/science/article/pii/S1364661307001593},
	Urldate = {2015-05-22},
	Volume = {11},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661307001593},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2007.06.010}}

@article{dehaene-lambertz_functional_2006,
	Abstract = {We examined the functional organization of cerebral activity in 3-month-old infants when they were listening to their mother language. Short sentences were presented in a slow event-related functional MRI paradigm. We then parsed the infant's network of perisylvian responsive regions into functionally distinct regions based on their speed of activation and sensitivity to sentence repetition. An adult-like structure of functional MRI response delays was observed along the superior temporal regions, suggesting a hierarchical processing scheme. The fastest responses were recorded in the vicinity of Heschl's gyrus, whereas responses became increasingly slower toward the posterior part of the superior temporal gyrus and toward the temporal poles and inferior frontal regions (Broca's area). Activation in the latter region increased when the sentence was repeated after a 14-s delay, suggesting the early involvement of Broca's area in verbal memory. The fact that Broca's area is active in infants before the babbling stage implies that activity in this region is not the consequence of sophisticated motor learning but, on the contrary, that this region may drive, through interactions with the perceptual system, the learning of the complex motor sequences required for future speech production. Our results point to a complex, hierarchical organization of the human brain in the first months of life, which may play a crucial role in language acquisition in our species.},
	Author = {Dehaene-Lambertz, Ghislaine and Hertz-Pannier, Lucie and Dubois, Jessica and M{\'e}riaux, S{\'e}bastien and Roche, Alexis and Sigman, Mariano and Dehaene, Stanislas},
	Doi = {10.1073/pnas.0606302103},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Adult, Animals, Brain Mapping, Female, Frontal Lobe, Humans, Infant, Male, Temporal Lobe, language, speech perception, Magnetic resonance imaging, Speech Perception},
	Language = {eng},
	Month = sep,
	Number = {38},
	Pages = {14240--14245},
	Pmcid = {PMC1599941},
	Pmid = {16968771},
	Title = {Functional organization of perisylvian activation during presentation of sentences in preverbal infants},
	Volume = {103},
	Year = {2006},
	Bdsk-Url-1 = {https://doi.org/10.1073/pnas.0606302103}}

@article{muller_repetition_2013,
	Abstract = {Upon repetition, certain stimuli induce reduced neural responses (i.e., repetition suppression), whereas others evoke stronger signals (i.e., repetition enhancement). It has been hypothesized that stimulus properties (e.g., visibility) determine the direction of the repetition effect. Here, we show that the very same stimuli can induce both repetition suppression and enhancement, whereby the only determining factor is the number of repetitions. Repeating the same, initially novel low-visible pictures of scenes for up to 5 times enhanced the blood oxygen level--dependent (BOLD) response in scene-selective areas, that is, the parahippocampal place area (PPA) and the transverse occipital sulcus (TOS), presumably reflecting the strengthening of the internal representation. Additional repetitions (6--9) resulted in progressively attenuated neural responses indicating a more efficient representation of the now familiar stimulus. Behaviorally, repetition led to increasingly faster responses and higher visibility ratings. Novel scenes induced the largest BOLD response in the PPA and also higher activity in yet another scene-selective region, the retrospenial cortex (RSC). We propose that 2 separable processes modulate activity in the PPA: one process optimizes the internal stimulus representation and involves TOS and the other differentiates between familiar and novel scenes and involves RSC.},
	Author = {M{\"u}ller, Notger G. and Strumpf, H. and Scholz, M. and Baier, B. and Melloni, L.},
	Doi = {10.1093/cercor/bhs009},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NJJJVVF7/M{\"u}ller et al. - 2013 - Repetition Suppression versus Enhancement---It's Qua.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M8563SI6/315.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Keywords = {novelty detection, fMRI, priming, repetition suppression},
	Language = {en},
	Month = jan,
	Number = {2},
	Pages = {315--322},
	Pmid = {22314047},
	Title = {Repetition {Suppression} versus {Enhancement}---{It}'s {Quantity} {That} {Matters}},
	Url = {http://cercor.oxfordjournals.org/content/23/2/315},
	Urldate = {2016-09-19},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org/content/23/2/315},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhs009}}

@article{simoncelli_natural_2001,
	Abstract = {It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954)Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons.},
	Author = {Simoncelli, E P and Olshausen, B A},
	Doi = {10.1146/annurev.neuro.24.1.1193},
	Issn = {0147-006X},
	Journal = {Annual review of neuroscience},
	Keywords = {Animals, Brain Mapping, Environment, Humans, Image Processing, Computer-Assisted, Pattern Recognition, Visual, Visual Cortex, Visual Perception, Neurons},
	Language = {eng},
	Pages = {1193--1216},
	Pmid = {11520932},
	Title = {Natural image statistics and neural representation},
	Volume = {24},
	Year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev.neuro.24.1.1193}}

@article{raschle_pediatric_2012,
	Abstract = {Structural and functional magnetic resonance imaging (fMRI) has been used increasingly to investigate typical and atypical brain development. However, in contrast to studies in school-aged children and adults, MRI research in young pediatric age groups is less common. Practical and technical challenges occur when imaging infants and children, which presents clinicians and research teams with a unique set of problems. These include procedural difficulties (e.g., participant anxiety or movement restrictions), technical obstacles (e.g., availability of child-appropriate equipment or pediatric MR head coils), and the challenge of choosing the most appropriate analysis methods for pediatric imaging data. Here, we summarize and review pediatric imaging and analysis tools and present neuroimaging protocols for young nonsedated children and infants, including guidelines and procedures that have been successfully implemented in research protocols across several research sites.},
	Author = {Raschle, Nora and Zuk, Jennifer and Ortiz-Mantilla, Silvia and Sliva, Danielle D. and Franceschi, Angela and Grant, P. Ellen and Benasich, April A. and Gaab, Nadine},
	Doi = {10.1111/j.1749-6632.2012.06457.x},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/WKF5DAFZ/Raschle et al. - 2012 - Pediatric neuroimaging in early childhood and infa.pdf:application/pdf},
	Issn = {0077-8923},
	Journal = {Annals of the New York Academy of Sciences},
	Month = apr,
	Pages = {43--50},
	Pmcid = {PMC3499030},
	Pmid = {22524338},
	Shorttitle = {Pediatric neuroimaging in early childhood and infancy},
	Title = {Pediatric neuroimaging in early childhood and infancy: challenges and practical guidelines},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3499030/},
	Urldate = {2016-09-19},
	Volume = {1252},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3499030/},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1749-6632.2012.06457.x}}

@article{scholkmann_review_2014,
	Author = {Scholkmann, Felix and Kleiser, Stefan and Metz, Andreas Jaakko and Zimmermann, Raphael and Mata Pavia, Juan and Wolf, Ursula and Wolf, Martin},
	Doi = {10.1016/j.neuroimage.2013.05.004},
	File = {A review on continuous wave functional near-infrared spectroscopy and imaging instrumentation and methodology:/Users/Cecile/Zotero/storage/4KFPVM4A/S1053811913004941.html:text/html;Scholkmannetal14.pdf:/Users/Cecile/Zotero/storage/J7WFB77F/Scholkmannetal14.pdf:application/pdf},
	Issn = {10538119},
	Journal = {NeuroImage},
	Month = jan,
	Pages = {6--27},
	Title = {A review on continuous wave functional near-infrared spectroscopy and imaging instrumentation and methodology},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811913004941#},
	Urldate = {2013-12-10},
	Volume = {85},
	Year = {2014},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811913004941#},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2013.05.004}}

@article{decharms_neural_2000,
	Abstract = {The principle function of the central nervous system is to represent and transform information and thereby mediate appropriate decisions and behaviors. The cerebral cortex is one of the primary seats of the internal representations maintained and used in perception, memory, decision making, motor control, and subjective experience, but the basic coding scheme by which this information is carried and transformed by neurons is not yet fully understood. This article defines and reviews how information is represented in the firing rates and temporal patterns of populations of cortical neurons, with a particular emphasis on how this information mediates behavior and experience.},
	Author = {deCharms, R. Christopher and Zador, Anthony},
	Doi = {10.1146/annurev.neuro.23.1.613},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3KSVM2SZ/deCharms et Zador - 2000 - Neural Representation and the Cortical Code.pdf:application/pdf},
	Journal = {Annual Review of Neuroscience},
	Number = {1},
	Pages = {613--647},
	Pmid = {10845077},
	Title = {Neural {Representation} and the {Cortical} {Code}},
	Url = {http://dx.doi.org/10.1146/annurev.neuro.23.1.613},
	Urldate = {2015-05-22},
	Volume = {23},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1146/annurev.neuro.23.1.613}}

@article{gagnepain_spoken_2008,
	Abstract = {Previous neuroimaging studies in the visual domain have shown that neurons along the perceptual processing pathway retain the physical properties of written words, faces, and objects. The aim of this study was to reveal the existence of similar neuronal properties within the human auditory cortex. Brain activity was measured using functional magnetic resonance imaging during a repetition priming paradigm, with words and pseudowords heard in an acoustically degraded format. Both the amplitude and peak latency of the hemodynamic response (HR) were assessed to determine the nature of the neuronal signature of spoken word priming. A statistically significant stimulus type by repetition interaction was found in various bilateral auditory cortical areas, demonstrating either HR suppression and enhancement for repeated spoken words and pseudowords, respectively, or word-specific repetition suppression without any significant effects for pseudowords. Repetition latency shift only occurred with word-specific repetition suppression in the right middle/posterior superior temporal sulcus. In this region, both repetition suppression and latency shift were related to behavioral priming. Our findings highlight for the first time the existence of long-term spoken word memory traces within the human auditory cortex. The timescale of auditory information integration and the neuronal mechanisms underlying priming both appear to differ according to the level of representations coded by neurons. Repetition may ``sharpen'' word-nonspecific representations coding short temporal variations, whereas a complex interaction between the activation strength and temporal integration of neuronal activity may occur in neuronal populations coding word-specific representations within longer temporal windows.},
	Author = {Gagnepain, Pierre and Ch{\'e}telat, Gael and Landeau, Brigitte and Dayan, Jacques and Eustache, Francis and Lebreton, Karine},
	Doi = {10.1523/JNEUROSCI.0565-08.2008},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DDM6R4SH/Gagnepain et al. - 2008 - Spoken Word Memory Traces within the Human Auditor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PRCT38HX/5281.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Keywords = {repetition priming, spoken word, fMRI, repetition enhancement, repetition suppression, Auditory cortex},
	Language = {en},
	Month = may,
	Number = {20},
	Pages = {5281--5289},
	Pmid = {18480284},
	Title = {Spoken {Word} {Memory} {Traces} within the {Human} {Auditory} {Cortex} {Revealed} by {Repetition} {Priming} and {Functional} {Magnetic} {Resonance} {Imaging}},
	Url = {http://www.jneurosci.org/content/28/20/5281},
	Urldate = {2016-09-19},
	Volume = {28},
	Year = {2008},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/28/20/5281},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.0565-08.2008}}

@article{lee_acoustic_2016,
	Author = {Lee, Yune-Sang and Min, Nam Eun and Wingfield, Arthur and Grossman, Murray and Peelle, Jonathan E.},
	Doi = {10.1016/j.heares.2015.12.008},
	File = {Lee-2016-Acoustic_richness_modulates_the_neural_networks_supporting_intelligible_speech_processing.pdf:/Users/Cecile/Zotero/storage/Q5AU4DBJ/Lee-2016-Acoustic_richness_modulates_the_neural_networks_supporting_intelligible_speech_processing.pdf:application/pdf},
	Issn = {03785955},
	Journal = {Hearing Research},
	Language = {en},
	Month = mar,
	Pages = {108--117},
	Title = {Acoustic richness modulates the neural networks supporting intelligible speech processing},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595515301969},
	Urldate = {2016-09-19},
	Volume = {333},
	Year = {2016},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378595515301969},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2015.12.008}}

@article{mehler_understanding_1993,
	Author = {Mehler, Jacques and Sebastian, Nuria and Altmann, Gerry and Dupoux, Emmanuel and Christophe, Anne and Pallier, Christophe},
	Doi = {10.1111/j.1749-6632.1993.tb22975.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BZVX2W6Q/Mehler et al. - 1993 - Understanding Compressed Sentences The Role of Rh.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2636T75N/abstract\;jsessionid=433CB7D845A881D1700FC231A486EC18.html:text/html},
	Issn = {1749-6632},
	Journal = {Annals of the New York Academy of Sciences},
	Language = {en},
	Month = jun,
	Number = {1},
	Pages = {272--282},
	Shorttitle = {Understanding {Compressed} {Sentences}},
	Title = {Understanding {Compressed} {Sentences}: {The} {Role} of {Rhythm} and {Meaning} a},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1993.tb22975.x/abstract},
	Urldate = {2015-07-30},
	Volume = {682},
	Year = {1993},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1993.tb22975.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1749-6632.1993.tb22975.x}}

@incollection{van_santen_prosodic_2008,
	Author = {van Santen, Jan and Mishra, Taniya and Klabbers, Esther},
	Booktitle = {Springer {Handbook} of {Speech} {Processing}},
	File = {ProsodicProcessing.pdf:/Users/Cecile/Zotero/storage/9V422AH2/ProsodicProcessing.pdf:application/pdf},
	Pages = {471--488},
	Publisher = {Springer},
	Title = {Prosodic processing},
	Url = {http://link.springer.com/10.1007/978-3-540-49127-9_23},
	Urldate = {2016-09-19},
	Year = {2008},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/978-3-540-49127-9_23}}

@article{park_frontal_nodate,
	Abstract = {Summary
Humans show a remarkable ability to understand continuous speech even under adverse listening conditions. This ability critically relies on dynamically updated predictions of incoming sensory information, but exactly how top-down predictions improve speech processing is still unclear. Brain oscillations are a likely mechanism for these top-down predictions [1, 2]. Quasi-rhythmic components in speech are known to entrain low-frequency oscillations in auditory areas [3, 4], and this entrainment increases with intelligibility [5]. We hypothesize that top-down signals from frontal brain areas causally modulate the phase of brain oscillations in auditory cortex. We use magnetoencephalography (MEG) to monitor brain oscillations in 22 participants during continuous speech perception. We characterize prominent spectral components of speech-brain coupling in auditory cortex and use causal connectivity analysis (transfer entropy) to identify the top-down signals driving this coupling more strongly during intelligible speech than during unintelligible speech. We report three main findings. First, frontal and motor cortices significantly modulate the phase of speech-coupled low-frequency oscillations in auditory cortex, and this effect depends on intelligibility of speech. Second, top-down signals are significantly stronger for left auditory cortex than for right auditory cortex. Third, speech-auditory cortex coupling is enhanced as a function of stronger top-down signals. Together, our results suggest that low-frequency brain oscillations play a role in implementing predictive top-down control during continuous speech perception and that top-down control is largely directed at left auditory cortex. This suggests a close relationship between (left-lateralized) speech production areas and the implementation of top-down control in continuous speech perception.},
	Author = {Park, Hyojin and Ince, Robin A. A. and Schyns, Philippe G. and Thut, Gregor and Gross, Joachim},
	Doi = {10.1016/j.cub.2015.04.049},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/R843RC5W/Park et al. - Frontal Top-Down Signals Increase Coupling of Audi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/CQJ6PXX2/S096098221500500X.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Title = {Frontal {Top}-{Down} {Signals} {Increase} {Coupling} of {Auditory} {Low}-{Frequency} {Oscillations} to {Continuous} {Speech} in {Human} {Listeners}},
	Url = {http://www.sciencedirect.com/science/article/pii/S096098221500500X},
	Urldate = {2015-06-02},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S096098221500500X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2015.04.049}}

@misc{noauthor_analyzing_nodate,
	Abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, and LFP recordings.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/SMANU6F7/analyzing-neural-time-series-data.html:text/html},
	Journal = {MIT Press},
	Title = {Analyzing {Neural} {Time} {Series} {Data}},
	Url = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data},
	Urldate = {2015-12-11},
	Bdsk-Url-1 = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data}}

@article{poeppel_pure_2001,
	Abstract = {The analysis of pure word deafness (PWD) suggests that speech perception, construed as the integration of acoustic information to yield representations that enter into the linguistic computational system, (i) is separable in a modular sense from other aspects of auditory cognition and (ii) is mediated by the posterior superior temporal cortex in both hemispheres. PWD data are consistent with neuropsychological and neuroimaging evidence in a manner that suggests that the speech code is analyzed bilaterally. The typical lateralization associated with language processing is a property of the computational system that acts beyond the analysis of the input signal. The hypothesis of the bilateral mediation of the speech code does not imply that both sides execute the same computation. It is proposed that the speech signal is asymmetrically analyzed in the time domain, with left-hemisphere mechanisms preferentially extracting information over shorter (25--50 ms) temporal integration windows and right mechanisms over longer (150--250 ms) windows.},
	Author = {Poeppel, David},
	Doi = {10.1016/S0364-0213(01)00050-7},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8G2R2CUS/S0364021301000507.html:text/html},
	Issn = {0364-0213},
	Journal = {Cognitive Science},
	Keywords = {Auditory agnosia, Hemispheric asymmetry, Imaging, Lesions, Neural basis of speech, Temporal processing, speech perception, Speech Perception},
	Month = sep,
	Number = {5},
	Pages = {679--693},
	Title = {Pure word deafness and the bilateral processing of the speech code},
	Url = {http://www.sciencedirect.com/science/article/pii/S0364021301000507},
	Urldate = {2014-06-01},
	Volume = {25},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0364021301000507},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0364-0213(01)00050-7}}

@article{santoro_encoding_2014,
	Abstract = {Author Summary  How does the human brain analyze natural sounds? Previous functional neuroimaging research could only describe the response patterns that sounds evoke in the human brain at the level of preferential regional activations. A comprehensive account of the neural basis of human hearing, however, requires deriving computational models that are able to provide quantitative predictions of brain responses to natural sounds. Here, we make a significant step in this direction by combining functional magnetic resonance imaging (fMRI) with computational modeling. We compare competing computational models of sound representations and select the model that most accurately predicts the measured fMRI response patterns. The computational models describe the processing of three relevant properties of natural sounds: frequency, temporal modulations and spectral modulations. We find that a model that represents spectral and temporal modulations jointly and in a frequency-dependent fashion provides the best account of fMRI responses and that the functional specialization of auditory cortical fields can be partially accounted for by their modulation tuning. Our results provide insights on how natural sounds are encoded in human auditory cortex and our methodological approach constitutes an advance in the way this question can be addressed in future studies.},
	Author = {Santoro, Roberta and Moerel, Michelle and Martino, Federico De and Goebel, Rainer and Ugurbil, Kamil and Yacoub, Essa and Formisano, Elia},
	Doi = {10.1371/journal.pcbi.1003412},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2U4H9PVT/Santoro et al. - 2014 - Encoding of Natural Sounds at Multiple Spectral an.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DFWMWMMH/article.html:text/html},
	Issn = {1553-7358},
	Journal = {PLOS Comput Biol},
	Keywords = {Permutation, Topographic maps, auditory system, behavior, Modulation, Neuronal tuning, functional magnetic resonance imaging, Auditory cortex},
	Month = jan,
	Number = {1},
	Pages = {e1003412},
	Title = {Encoding of {Natural} {Sounds} at {Multiple} {Spectral} and {Temporal} {Resolutions} in the {Human} {Auditory} {Cortex}},
	Url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003412},
	Urldate = {2016-03-17},
	Volume = {10},
	Year = {2014},
	Bdsk-Url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003412},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pcbi.1003412}}

@article{may_language_2011,
	Abstract = {Previous research has shown that by the time of birth, the neonate brain responds specially to the native language when compared to acoustically similar non-language stimuli. In the current study, we use near-infrared spectroscopy to ask how prenatal language experience might shape the brain response to language in newborn infants. To do so, we examine the neural response of neonates when listening to familiar versus unfamiliar language, as well as to non language stimuli. Twenty monolingual English-exposed neonates aged 0-3âdays were tested. Each infant heard low-pass filtered sentences of forward English (familiar language), forward Tagalog (unfamiliar language), and backward English and Tagalog (non-language). During exposure, neural activation was measured across 12 channels on each hemisphere. Our results indicate a bilateral effect of language familiarity on neonates' brain response to language. Differential brain activation was seen when neonates listened to forward Tagalog (unfamiliar language) as compared to other types of language stimuli. We interpret these results as evidence that the prenatal experience with the native language gained in utero influences how the newborn brain responds to language across brain regions sensitive to speech processing.},
	Author = {May, Lillian and Byers-Heinlein, Krista and Gervain, Judit and Werker, Janet F},
	Doi = {10.3389/fpsyg.2011.00222},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/AN5FPDXG/May et al. - 2011 - Language and the Newborn Brain Does Prenatal Lang.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in psychology},
	Keywords = {Near-infrared spectroscopy, language, neonates},
	Language = {eng},
	Pages = {222},
	Pmid = {21960980},
	Shorttitle = {Language and the newborn brain},
	Title = {Language and the newborn brain: does prenatal language experience shape the neonate neural response to speech?},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.3389/fpsyg.2011.00222}}

@article{kaas_subdivisions_1998,
	Abstract = {In a series of experiments on New World and Old World monkeys, architectonic features of auditory cortex were related to tone frequency maps and patterns of connections to generate and evaluate theories of cortical organization. The results suggest that cortical processing of auditory information involves a number of functionally distinct fields that can be broadly grouped into four or more levels of processing. At the first level, there are three primary-like areas, each with a discrete pattern of tonotopic organization, koniocortical histological features, and direct inputs from the ventral division of the medial geniculate complex. These three core areas are interconnected and project to a narrow surrounding belt of perhaps seven areas which receive thalamic input from the major divisions of the medial geniculate complex, the suprageniculate/limitans complex, and the medial pulvinar. The belt areas connect with a lateral parabelt region of two or more fields that are almost devoid of direct connections with the core and the ventral division of the medial geniculate complex. The parabelt fields connect with more distant cortex in the superior temporal gyrus, superior temporal sulcus, and prefrontal cortex. The results indicate that auditory processing involves 15 or more cortical areas, each of which is interconnected with a number of other fields, especially adjoining fields of the same level.},
	Author = {Kaas, J. H. and Hackett, T. A.},
	Issn = {1420-3030},
	Journal = {Audiology \& Neuro-Otology},
	Keywords = {Animals, Auditory Perception, Primates, Auditory cortex, Brain},
	Language = {eng},
	Month = jun,
	Number = {2-3},
	Pages = {73--85},
	Pmid = {9575378},
	Title = {Subdivisions of auditory cortex and levels of processing in primates},
	Volume = {3},
	Year = {1998}}

@article{minagawa-kawai_cerebral_2011,
	Author = {Minagawa-Kawai, Yasuyo and Cristi{\`a}, Alejandrina and Dupoux, Emmanuel},
	Doi = {10.1016/j.dcn.2011.03.005},
	File = {MinagawaKawaietal11.pdf:/Users/Cecile/Zotero/storage/F6EDV992/MinagawaKawaietal11.pdf:application/pdf},
	Issn = {18789293},
	Journal = {Developmental Cognitive Neuroscience},
	Language = {en},
	Month = jul,
	Number = {3},
	Pages = {217--232},
	Shorttitle = {Cerebral lateralization and early speech acquisition},
	Title = {Cerebral lateralization and early speech acquisition: {A} developmental scenario},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S1878929311000302},
	Urldate = {2014-05-29},
	Volume = {1},
	Year = {2011},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1878929311000302},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2011.03.005}}

@incollection{werner_morphological_2012,
	Address = {New York, NY},
	Author = {Eggermont, Jos J. and Moore, Jean K.},
	Booktitle = {Human {Auditory} {Development}},
	Editor = {Werner, Lynne and Fay, Richard R. and Popper, Arthur N.},
	File = {Morphological and Functional Development of the Auditory Nervous System_chapter.pdf:/Users/Cecile/Zotero/storage/XJRHEM7S/Morphological and Functional Development of the Auditory Nervous System_chapter.pdf:application/pdf},
	Isbn = {978-1-4614-1420-9 978-1-4614-1421-6},
	Pages = {61--105},
	Publisher = {Springer New York},
	Title = {Morphological and {Functional} {Development} of the {Auditory} {Nervous} {System}},
	Url = {http://link.springer.com/10.1007/978-1-4614-1421-6_3},
	Urldate = {2015-07-30},
	Volume = {42},
	Year = {2012},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/978-1-4614-1421-6_3}}

@article{rosen_temporal_1992,
	Abstract = {The temporal properties of speech appear to play a more important role in linguistic contrasts than has hitherto been appreciated. Therefore, a new framework for describing the acoustic structure of speech based purely on temporal aspects has been developed. From this point of view, speech can be said to be comprised of three main temporal features, based on dominant fluctuation rates: envelope, periodicity, and fine-structure. Each feature has distinct acoustic manifestations, auditory and perceptual correlates, and roles in linguistic contrasts. The applicability of this three-featured temporal system is discussed in relation to hearing-impaired and normal listeners.},
	Author = {Rosen, Stuart},
	Doi = {10.1098/rstb.1992.0070},
	File = {Rosen 1992 Temporal info in speech.pdf:/Users/Cecile/Zotero/storage/7VSWFWTZ/Rosen 1992 Temporal info in speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8KZE74RP/367.html:text/html},
	Issn = {0962-8436, 1471-2970},
	Journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
	Language = {en},
	Month = jun,
	Number = {1278},
	Pages = {367--373},
	Pmid = {1354376},
	Shorttitle = {Temporal {Information} in {Speech}},
	Title = {Temporal {Information} in {Speech}: {Acoustic}, {Auditory} and {Linguistic} {Aspects}},
	Url = {http://rstb.royalsocietypublishing.org/content/336/1278/367},
	Urldate = {2016-01-30},
	Volume = {336},
	Year = {1992},
	Bdsk-Url-1 = {http://rstb.royalsocietypublishing.org/content/336/1278/367},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.1992.0070}}

@article{decasper_prenatal_1986,
	Abstract = {Pregnant women recited a particular speech passage aloud each day during their last 6 weeks of pregnancy. Their newborns were tested with an operant-choice procedure to determine whether the sounds of the recited passage were more reinforcing than the sounds of a novel passage. The previously recited passage was more reinforcing. The reinforcing value of the two passages did not differ for a matched group of control subjects. Thus, third-trimester fetuses experience their mothers' speech sounds and that prenatal auditory experience can influence postnatal auditory preferences.},
	Author = {DeCasper, Anthony J. and Spence, Melanie J.},
	Doi = {10.1016/0163-6383(86)90025-1},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/34NZAJPI/0163638386900251.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Keywords = {Auditory Perception, fetal experience, maternal voice, newborn perception, prenatal learning, prenatal sensory experience, speech perception, Speech Perception},
	Month = apr,
	Number = {2},
	Pages = {133--150},
	Title = {Prenatal maternal speech influences newborns' perception of speech sounds},
	Url = {http://www.sciencedirect.com/science/article/pii/0163638386900251},
	Urldate = {2014-06-01},
	Volume = {9},
	Year = {1986},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0163638386900251},
	Bdsk-Url-2 = {https://doi.org/10.1016/0163-6383(86)90025-1}}

@article{garcia-lazaro_emergence_2011,
	Abstract = {We have previously shown that neurons in primary auditory cortex (A1) of anaesthetized (ketamine/medetomidine) ferrets respond more strongly and reliably to dynamic stimuli whose statistics follow "natural" 1/f dynamics than to stimuli exhibiting pitch and amplitude modulations that are faster (1/f(0.5)) or slower (1/f(2)) than 1/f. To investigate where along the central auditory pathway this 1/f-modulation tuning arises, we have now characterized responses of neurons in the central nucleus of the inferior colliculus (ICC) and the ventral division of the mediate geniculate nucleus of the thalamus (MGV) to 1/f(Î³) distributed stimuli with Î³ varying between 0.5 and 2.8. We found that, while the great majority of neurons recorded from the ICC showed a strong preference for the most rapidly varying (1/f(0.5) distributed) stimuli, responses from MGV neurons did not exhibit marked or systematic preferences for any particular Î³ exponent. Only in A1 did a majority of neurons respond with higher firing rates to stimuli in which Î³ takes values near 1. These results indicate that 1/f tuning emerges at forebrain levels of the ascending auditory pathway.},
	Author = {Garcia-Lazaro, Jose A and Ahmed, Bashir and Schnupp, Jan W H},
	Doi = {10.1371/journal.pone.0022584},
	Issn = {1932-6203},
	Journal = {PloS one},
	Keywords = {Acoustic Stimulation, Animals, Auditory Pathways, Electrophysiology, Ferrets, Inferior Colliculi, Thalamus, Neurons},
	Language = {eng},
	Number = {8},
	Pages = {e22584},
	Pmid = {21850231},
	Title = {Emergence of tuning to natural stimulus statistics along the central auditory pathway},
	Volume = {6},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1371/journal.pone.0022584}}

@article{beauchemin_mother_2011,
	Abstract = {In the mature adult brain, there are voice selective regions that are especially tuned to familiar voices. Yet, little is known about how the infant's brain treats such information. Here, we investigated, using electrophysiology and source analyses, how newborns process their mother's voice compared with that of a stranger. Results suggest that, shortly after birth, newborns distinctly process their mother's voice at an early preattentional level and at a later presumably cognitive level. Activation sources revealed that exposure to the maternal voice elicited early language-relevant processing, whereas the stranger's voice elicited more voice-specific responses. A central probably motor response was also observed at a later time, which may reflect an innate auditory-articulatory loop. The singularity of left-dominant brain activation pattern together with its ensuing sustained greater central activation in response to the mother's voice may provide the first neurophysiologic index of the preferential mother's role in language acquisition.},
	Author = {Beauchemin, Maude and Gonz{\'a}lez-Frankenberger, Berta and Tremblay, Julie and Vannasing, Phetsamone and Mart{\'\i}nez-Montes, Eduardo and Belin, Pascal and B{\'e}land, Ren{\'e}e and Francoeur, Diane and Carceller, Ana-Maria and Wallois, Fabrice and Lassonde, Maryse},
	Doi = {10.1093/cercor/bhq242},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IITUAC7E/Beauchemin et al. - 2011 - Mother and Stranger An Electrophysiological Study.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/35QU3P8H/1705.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Keywords = {newborns, source analyses, voice processing, Mismatch negativity},
	Language = {en},
	Month = jan,
	Number = {8},
	Pages = {1705--1711},
	Pmid = {21149849},
	Shorttitle = {Mother and {Stranger}},
	Title = {Mother and {Stranger}: {An} {Electrophysiological} {Study} of {Voice} {Processing} in {Newborns}},
	Url = {http://cercor.oxfordjournals.org/content/21/8/1705},
	Urldate = {2015-04-01},
	Volume = {21},
	Year = {2011},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org/content/21/8/1705},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhq242}}

@article{huotilainen_short-term_2005,
	Abstract = {Studies in fetuses and in prematurely born infants show that auditory discriminative skills are present prior to birth. The magnetic fields generated by the fetal brain activity pass the maternal tissues and, despite their weakness, can be detected externally using MEG. Recent studies on the auditory evoked magnetic responses show that the fetal brain responds to sound onset. In contrast, higher-level auditory skills, such as those involving discriminative and memory functions, were not so far studied in fetuses with MEG. Here we show that fetal responses related to discriminating sounds can be recorded, implicating that the auditory change-detection system is functional. These results open new views to developmental neuroscience by enabling one to determine the sensory capabilities as well as the extent and accuracy of the short-term memory system of the fetus, and, further, to follow the development of these crucial processes.},
	Author = {Huotilainen, Minna and Kujala, Anu and Hotakainen, Merja and Parkkonen, Lauri and Taulu, Samu and Simola, Juha and Nenonen, Jukka and Karjalainen, Matti and N{\"a}{\"a}t{\"a}nen, Risto},
	Issn = {0959-4965},
	Journal = {Neuroreport},
	Keywords = {Adult, Auditory Perception, Female, Fetus, Gestational Age, Humans, Memory, Pregnancy, Reaction Time, magnetoencephalography},
	Language = {eng},
	Month = jan,
	Number = {1},
	Pages = {81--84},
	Pmid = {15618896},
	Title = {Short-term memory functions of the human fetus recorded with magnetoencephalography},
	Volume = {16},
	Year = {2005}}

@article{moerel_processing_2013,
	Author = {Moerel, M. and De Martino, F. and Santoro, R. and Ugurbil, K. and Goebel, R. and Yacoub, E. and Formisano, E.},
	Doi = {10.1523/JNEUROSCI.5306-12.2013},
	File = {Web of Knowledge [v.5.12] - All Databases Full Record:/Users/Cecile/Zotero/storage/PE9H7RQB/full_record.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Month = jul,
	Number = {29},
	Pages = {11888--11898},
	Shorttitle = {Processing of {Natural} {Sounds}},
	Title = {Processing of {Natural} {Sounds}: {Characterization} of {Multipeak} {Spectral} {Tuning} in {Human} {Auditory} {Cortex}},
	Url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=3&SID=Y1kaUFcp3zqegByBfKv&page=1&doc=3},
	Urldate = {2013-12-09},
	Volume = {33},
	Year = {2013},
	Bdsk-Url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=UA&search_mode=CitingArticles&qid=3&SID=Y1kaUFcp3zqegByBfKv&page=1&doc=3},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.5306-12.2013}}

@article{peelle_neural_2012,
	Abstract = {A key feature of speech is the quasi-regular rhythmic information contained in its slow amplitude modulations. In this article we review the information conveyed by speech rhythm, and the role of ongoing brain oscillations in listeners' processing of this content. Our starting point is the fact that speech is inherently temporal, and that rhythmic information conveyed by the amplitude envelope contains important markers for place and manner of articulation, segmental information, and speech rate. Behavioral studies demonstrate that amplitude envelope information is relied upon by listeners and plays a key role in speech intelligibility. Extending behavioral findings, data from neuroimaging -- particularly electroencephalography (EEG) and magnetoencephalography (MEG) -- point to phase locking by ongoing cortical oscillations to low-frequency information ({\textasciitilde}4--8âHz) in the speech envelope. This phase modulation effectively encodes a prediction of when important events (such as stressed syllables) are likely to occur, and acts to increase sensitivity to these relevant acoustic cues. We suggest a framework through which such neural entrainment to speech rhythm can explain effects of speech rate on word and segment perception (i.e., that the perception of phonemes and words in connected speech is influenced by preceding speech rate). Neuroanatomically, acoustic amplitude modulations are processed largely bilaterally in auditory cortex, with intelligible speech resulting in differential recruitment of left-hemisphere regions. Notable among these is lateral anterior temporal cortex, which we propose functions in a domain-general fashion to support ongoing memory and integration of meaningful input. Together, the reviewed evidence suggests that low-frequency oscillations in the acoustic speech signal form the foundation of a rhythmic hierarchy supporting spoken language, mirrored by phase-locked oscillations in the human brain.},
	Author = {Peelle, Jonathan E. and Davis, Matthew H.},
	Doi = {10.3389/fpsyg.2012.00320},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/W4A3DM74/Peelle et Davis - 2012 - Neural Oscillations Carry Speech Rhythm through to.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Month = sep,
	Pmcid = {PMC3434440},
	Pmid = {22973251},
	Title = {Neural {Oscillations} {Carry} {Speech} {Rhythm} through to {Comprehension}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434440/},
	Urldate = {2014-10-31},
	Volume = {3},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3434440/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2012.00320}}

@article{bremer_cerebral_1958,
	Author = {Bremer, Fr{\'e}d{\'e}ric},
	File = {Snapshot:/Users/Cecile/Zotero/storage/WHXIMV4X/357.html:text/html},
	Journal = {Physiological Reviews},
	Language = {en},
	Month = jul,
	Number = {3},
	Pages = {357--388},
	Pmid = {13567040},
	Title = {Cerebral and {Cerebellar} {Potentials}},
	Url = {http://physrev.physiology.org/content/38/3/357},
	Urldate = {2014-11-26},
	Volume = {38},
	Year = {1958},
	Bdsk-Url-1 = {http://physrev.physiology.org/content/38/3/357}}

@article{kabdebon_anatomical_2014,
	Abstract = {Developmental research, as well as paediatric clinical activity crucially depends on non-invasive and painless brain recording techniques, such as electroencephalography (EEG), and near infrared spectroscopy (NIRS). However, both of these techniques measure cortical activity from the scalp without precise knowledge of the recorded cerebral structures. An accurate and reliable mapping between external anatomical landmarks and internal cerebral structures is therefore fundamental to localise brain sources in a non-invasive way. Here, using MRI, we examined the relations between the 10--20 sensor placement system and cerebral structures in 16 infants (3--17 weeks post-term). We provided an infant template parcelled in 94 regions on which we reported the variability of sensors locations, concurrently with the anatomical variability of six main cortical sulci (superior and inferior frontal sulcus, central sulcus, sylvian fissure, superior temporal sulcus, and intraparietal sulcus) and of the distances between the sensors and important cortical landmarks across these infants. The main difference between infants and adults was observed for the channels O1--O2, T5--T6, which projected over lower structures than in adults. We did not find any asymmetry in the distances between the scalp and the brain envelope. However, because of the Yakovlean torque pushing dorsally and frontally the right sylvian fissure, P3--P4 were not at the same distance from the posterior end of this structure. This study should help to refine hypotheses on functional cognitive development by providing an accurate description of the localization of standardised channels relative to infants' brain structures. Template and atlas are publicly available on our Web site (http://www.unicog.org/pm/pmwiki.php/Site/InfantTemplate).},
	Author = {Kabdebon, C. and Leroy, F. and Simmonet, H. and Perrot, M. and Dubois, J. and Dehaene-Lambertz, G.},
	Doi = {10.1016/j.neuroimage.2014.05.046},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UV3H23AA/Kabdebon et al. - 2014 - Anatomical correlations of the international 10--20.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WSW96C9V/S105381191400411X.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Cognition, EEG, NIRS, Source modelling, Development, Brain},
	Month = oct,
	Pages = {342--356},
	Title = {Anatomical correlations of the international 10--20 sensor placement system in infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S105381191400411X},
	Urldate = {2014-11-03},
	Volume = {99},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191400411X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.05.046}}

@article{nir_regional_2011,
	Abstract = {Summary
The most prominent EEG events in sleep are slow waves, reflecting a slow (\&lt;1 Hz) oscillation between up and down states in cortical neurons. It is unknown whether slow oscillations are synchronous across the majority or the minority of brain regions---are they a global or local phenomenon? To examine this, we recorded simultaneously scalp EEG, intracerebral EEG, and unit firing in multiple brain regions of neurosurgical patients. We find that most sleep slow waves and the underlying active and inactive neuronal states occur locally. Thus, especially in late sleep, some regions can be active while others are silent. We also find that slow waves can propagate, usually from medial prefrontal cortex to the medial temporal lobe and hippocampus. Sleep spindles, the other hallmark of NREM sleep EEG, are likewise predominantly local. Thus, intracerebral communication during sleep is constrained because slow and spindle oscillations often occur out-of-phase in different brain regions.
Video Abstract},
	Author = {Nir, Yuval and Staba, Richard J. and Andrillon, Thomas and Vyazovskiy, Vladyslav V. and Cirelli, Chiara and Fried, Itzhak and Tononi, Giulio},
	Doi = {10.1016/j.neuron.2011.02.043},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JCRFCSPI/Nir et al. - 2011 - Regional Slow Waves and Spindles in Human Sleep.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5A6MHIJN/S0896627311001668.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = apr,
	Number = {1},
	Pages = {153--169},
	Title = {Regional {Slow} {Waves} and {Spindles} in {Human} {Sleep}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627311001668},
	Urldate = {2013-12-18},
	Volume = {70},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627311001668},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2011.02.043}}

@article{massaro_motor_2008,
	Author = {Massaro, D. W. and Chen, T. H.},
	Doi = {10.3758/PBR.15.2.453},
	File = {Web of Knowledge [v.5.11] - Web of Science Full Record:/Users/Cecile/Zotero/storage/6F5FAICI/full_record.html:text/html},
	Issn = {1069-9384, 1531-5320},
	Journal = {Psychonomic Bulletin \& Review},
	Month = apr,
	Number = {2},
	Pages = {453--457},
	Title = {The motor theory of speech perception revisited},
	Url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=8&SID=W2jwcCJ3GJscqSTzLfG&page=1&doc=5},
	Urldate = {2013-09-16},
	Volume = {15},
	Year = {2008},
	Bdsk-Url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=8&SID=W2jwcCJ3GJscqSTzLfG&page=1&doc=5},
	Bdsk-Url-2 = {https://doi.org/10.3758/PBR.15.2.453}}

@article{dehaene-lambertz_functional_2002,
	Abstract = {Human infants begin to acquire their native language in the first months of life. To determine which brain regions support language processing at this young age, we measured with functional magnetic resonance imaging the brain activity evoked by normal and reversed speech in awake and sleeping 3-month-old infants. Left-lateralized brain regions similar to those of adults, including the superior temporal and angular gyri, were already active in infants. Additional activation in right prefrontal cortex was seen only in awake infants processing normal speech. Thus, precursors of adult cortical language areas are already active in infants, well before the onset of speech production.},
	Author = {Dehaene-Lambertz, Ghislaine and Dehaene, Stanislas and Hertz-Pannier, Lucie},
	Doi = {10.1126/science.1077066},
	File = {2013.full.pdf:/Users/Cecile/Zotero/storage/EXG5YBDI/2013.full.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/UFTBSK4D/Dehaene-Lambertz et al. - 2002 - Functional Neuroimaging of Speech Perception in In.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GE28SSTG/2013.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jun,
	Number = {5600},
	Pages = {2013--2015},
	Pmid = {12471265},
	Title = {Functional {Neuroimaging} of {Speech} {Perception} in {Infants}},
	Url = {http://www.sciencemag.org/content/298/5600/2013},
	Urldate = {2014-01-20},
	Volume = {298},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/298/5600/2013},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1077066}}

@article{kabdebon_electrophysiological_2015,
	Author = {Kabdebon, C. and Pena, M. and Buiatti, M. and Dehaene-Lambertz, G.},
	Doi = {10.1016/j.bandl.2015.03.005},
	File = {Kabdebon et al 2015 Electrophysiological evidence of statistical learning of long distance dependencies in 8 mo Preterm and Fullterm.pdf:/Users/Cecile/Zotero/storage/4I4EM6SH/Kabdebon et al 2015 Electrophysiological evidence of statistical learning of long distance dependencies in 8 mo Preterm and Fullterm.pdf:application/pdf},
	Issn = {0093934X},
	Journal = {Brain and Language},
	Language = {en},
	Month = sep,
	Pages = {25--36},
	Title = {Electrophysiological evidence of statistical learning of long-distance dependencies in 8-month-old preterm and full-term infants},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0093934X15000565},
	Urldate = {2016-01-13},
	Volume = {148},
	Year = {2015},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0093934X15000565},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2015.03.005}}

@article{licklider_process_1952,
	Abstract = {The process of speech perception is analyzed into three main operations: (1) translation of the speech signal into form suitable for the nervous system, (2) identification of discrete speech elements, and (3) comprehension of meaning. The first operation appears to correspond roughly to the transformation made by the sound spectrograph. The second may be carried out by the neural equivalent of a set of matched filters. The third appears to involve a neural form of crossâcorrelation that exhibits some of the properties of the analogous electronic process.},
	Author = {Licklider, J. C. R.},
	Doi = {10.1121/1.1906938},
	File = {Snapshot:/Users/Cecile/Zotero/storage/TG6TE735/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Nervous system, Speech, Speech analysis, speech perception, Speech Perception},
	Month = nov,
	Number = {6},
	Pages = {590--594},
	Title = {On the {Process} of {Speech} {Perception}},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/24/6/10.1121/1.1906938},
	Urldate = {2014-07-26},
	Volume = {24},
	Year = {1952},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/24/6/10.1121/1.1906938},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1906938}}

@article{yovel_unified_2013,
	Abstract = {Both faces and voices are rich in socially-relevant information, which humans are remarkably adept at extracting, including a person's identity, age, gender, affective state, personality, etc. Here, we review accumulating evidence from behavioral, neuropsychological, electrophysiological, and neuroimaging studies which suggest that the cognitive and neural processing mechanisms engaged by perceiving faces or voices are highly similar, despite the very different nature of their sensory input. The similarity between the two mechanisms likely facilitates the multi-modal integration of facial and vocal information during everyday social interactions. These findings emphasize a parsimonious principle of cerebral organization, where similar computational problems in different modalities are solved using similar solutions.},
	Author = {Yovel, Galit and Belin, Pascal},
	Doi = {10.1016/j.tics.2013.04.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/XKPDESMC/Yovel et Belin - 2013 - A unified coding strategy for processing faces and.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EH8GT2MT/S1364661313000776.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Keywords = {Visual Cortex, face recognition, neural selectivity, sensory coding, voice recognition, Auditory cortex},
	Month = jun,
	Number = {6},
	Pages = {263--271},
	Title = {A unified coding strategy for processing faces and voices},
	Url = {http://www.sciencedirect.com/science/article/pii/S1364661313000776},
	Urldate = {2017-03-09},
	Volume = {17},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661313000776},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2013.04.004}}

@inproceedings{guiraud_adaptation_2013,
	Author = {Guiraud, H{\'e}l{\`e}ne and Ferragne, Emmanuel and Bedoin, Nathalie and Boulenger, V{\'e}ronique},
	Booktitle = {{INTERSPEECH}},
	File = {Guiraudetal13.pdf:/Users/Cecile/Zotero/storage/S2E7HCF8/Guiraudetal13.pdf:application/pdf},
	Pages = {1370--1374},
	Publisher = {Citeseer},
	Title = {Adaptation to natural fast speech and time-compressed speech in children.},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.3884&rep=rep1&type=pdf},
	Urldate = {2015-10-02},
	Year = {2013},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.447.3884&rep=rep1&type=pdf}}

@article{averbeck_coding_2004,
	Abstract = {The brain processes information about sensory stimuli and motor intentions using a massive ensemble of neurons arrayed in parallel. Individual neurons receive convergent inputs from thousands of other neurons, leading to the possibility that patterns of spikes across the input neurons might be crucial components of the neural code. Recently, advances in multielectrode recording techniques have allowed several laboratories to investigate the nature of the interactions between neurons, and their potential role in information coding. Several recent studies have found that the amount of information coded by correlated activity about sensory and motor variables is small, casting doubt on the hypothesis that correlations between pairs of neurons are important for information coding. However, other studies have documented the appearance of coherent oscillations, during particular task epochs and conditions that require selective processing of sensory information, supporting the hypothesis that coherent oscillations between neurons might reflect the dynamic flow of information in the brain.},
	Author = {Averbeck, Bruno B. and Lee, Daeyeol},
	Doi = {10.1016/j.tins.2004.02.006},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/K64H7GUA/Averbeck et Lee - 2004 - Coding and transmission of information by neural e.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/K4AHUSQN/S0166223604000578.html:text/html},
	Issn = {0166-2236},
	Journal = {Trends in Neurosciences},
	Month = apr,
	Number = {4},
	Pages = {225--230},
	Title = {Coding and transmission of information by neural ensembles},
	Url = {http://www.sciencedirect.com/science/article/pii/S0166223604000578},
	Urldate = {2015-05-22},
	Volume = {27},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223604000578},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2004.02.006}}

@article{luo_phase_2007,
	Abstract = {Summary
How natural speech is represented in the auditory cortex constitutes a major challenge for cognitive neuroscience. Although many single-unit and neuroimaging studies have yielded valuable insights about the processing of speech and matched complex sounds, the mechanisms underlying the analysis of speech dynamics in human auditory cortex remain largely unknown. Here, we show that the phase pattern of theta band (4--8 Hz) responses recorded from human auditory cortex with magnetoencephalography (MEG) reliably tracks and discriminates spoken sentences and that this discrimination ability is correlated with speech intelligibility. The findings suggest that an â¼200 ms temporal window (period of theta oscillation) segments the incoming speech signal, resetting and sliding to track speech dynamics. This hypothesized mechanism for cortical speech analysis is based on the stimulus-induced modulation of inherent cortical rhythms and provides further evidence implicating the syllable as a computational primitive for the representation of spoken language.},
	Author = {Luo, Huan and Poeppel, David},
	Doi = {10.1016/j.neuron.2007.06.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/3DBK6VTX/Luo et Poeppel - 2007 - Phase Patterns of Neuronal Responses Reliably Disc.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NM26FX4W/S0896627307004138.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {SYSNEURO},
	Month = jun,
	Number = {6},
	Pages = {1001--1010},
	Title = {Phase {Patterns} of {Neuronal} {Responses} {Reliably} {Discriminate} {Speech} in {Human} {Auditory} {Cortex}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627307004138},
	Urldate = {2014-10-21},
	Volume = {54},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627307004138},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2007.06.004}}

@article{ramus_language_2002,
	Abstract = {Speech rhythm has long been claimed to be a useful bootstrapping cue in the very first steps of language acquisition. Previous studies have suggested that newborn infants do categorize varieties of speech rhythm, as demonstrated by their ability to discriminate between certain languages. However, the existing evidence is not unequivocal: in previous studies, stimuli discriminated by newborns always contained additional speech cues on top of rhythm. Here, we conducted a series of experiments assessing discrimination between Dutch and Japanese by newborn infants, using a speech resynthesis technique to progressively degrade non-rhythmical properties of the sentences. When the stimuli are resynthesized using identical phonemes and artificial intonation contours for the two languages, thereby preserving only their rhythmic and broad phonotactic structure, newborns still seem to be able to discriminate between the two languages, but the effect is weaker than when intonation is present. This leaves open the possibility that the temporal correlation between intonational and rhythmic cues might actually facilitate the processing of speech rhythm.},
	Author = {Ramus, Franck},
	Doi = {10.1075/arla.2.05ram},
	File = {Ramus - 2002 - Language discrimination by newborns Teasing apart.pdf:/Users/Cecile/Zotero/storage/2CBXYQPJ/Ramus - 2002 - Language discrimination by newborns Teasing apart.pdf:application/pdf},
	Journal = {Annual Review of Language Acquisition},
	Keywords = {Bootstrapping, Language discrimination, Newborn Speech Perception, Rhythm, Intonation, prosody},
	Number = {1},
	Pages = {85--115},
	Shorttitle = {Language discrimination by newborns},
	Title = {Language discrimination by newborns: {Teasing} apart phonotactic, rhythmic, and intonational cues},
	Volume = {2},
	Year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1075/arla.2.05ram}}

@article{mesgarani_selective_2012,
	Abstract = {Humans possess a remarkable ability to attend to a single speaker's voice in a multi-talker background. How the auditory system manages to extract intelligible speech under such acoustically complex and adverse listening conditions is not known, and, indeed, it is not clear how attended speech is internally represented. Here, using multi-electrode surface recordings from the cortex of subjects engaged in a listening task with two simultaneous speakers, we demonstrate that population responses in non-primary human auditory cortex encode critical features of attended speech: speech spectrograms reconstructed based on cortical responses to the mixture of speakers reveal the salient spectral and temporal features of the attended speaker, as if subjects were listening to that speaker alone. A simple classifier trained solely on examples of single speakers can decode both attended words and speaker identity. We find that task performance is well predicted by a rapid increase in attention-modulated neural selectivity across both single-electrode and population-level cortical responses. These findings demonstrate that the cortical representation of speech does not merely reflect the external acoustic environment, but instead gives rise to the perceptual aspects relevant for the listener's intended goal.},
	Author = {Mesgarani, Nima and Chang, Edward F.},
	Doi = {10.1038/nature11020},
	Issn = {1476-4687},
	Journal = {Nature},
	Keywords = {Acoustic Stimulation, Acoustics, Attention, Electrodes, Female, Humans, Male, Models, Neurological, Noise, Sound Spectrography, Speech, language, speech perception, Auditory cortex, Speech Perception},
	Language = {eng},
	Month = may,
	Number = {7397},
	Pages = {233--236},
	Pmcid = {PMC3870007},
	Pmid = {22522927},
	Title = {Selective cortical representation of attended speaker in multi-talker speech perception},
	Volume = {485},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1038/nature11020}}

@article{uhlhaas_neural_2010,
	Abstract = {Recent data indicate that the synchronisation of oscillatory activity is relevant for the development of cortical circuits as demonstrated by the involvement of neural synchrony in synaptic plasticity and changes in the frequency and synchronisation of neural oscillations during development. Analyses of resting-state and task-related neural synchrony indicate that gamma-oscillations emerge during early childhood and precise temporal coordination through neural synchrony continues to mature until early adulthood. The late maturation of neural synchrony is compatible with changes in the myelination of cortico-cortical connections and with late development of GABAergic neurotransmission. These findings highlight the role of neural synchrony for normal brain development as well as its potential importance for understanding neurodevelopmental disorders, such as autism spectrum disorders (ASDs) and schizophrenia.},
	Author = {Uhlhaas, Peter J. and Roux, Fr{\'e}d{\'e}ric and Rodriguez, Eugenio and Rotarska-Jagiela, Anna and Singer, Wolf},
	Doi = {10.1016/j.tics.2009.12.002},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/42UFTEGQ/S1364661309002824.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Month = feb,
	Number = {2},
	Pages = {72--80},
	Title = {Neural synchrony and the development of cortical networks},
	Url = {http://www.sciencedirect.com/science/article/pii/S1364661309002824},
	Urldate = {2015-12-03},
	Volume = {14},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661309002824},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2009.12.002}}

@article{atick_could_1991,
	Abstract = {The sensory pathways of animals are well adapted to processing a special class of signals, namely stimuli from the animal's environment. An important fact about natural stimuli is that they are typically very redundant and hence the sampled representation of these signals formed by the array of sensory cells is inefficient. One could argue for some animals and pathways, as we do in this review, that efficiency of information representation in the nervous system has several evolutionary advantages. Consequently, one might expect that much of the processing in the early levels of these sensory pathways could be dedicated towards recoding incoming signals into a more efficient form. In this review, we explore the principle of efficiency of information representation as a design principle for sensory processing. We give a preliminary discussion on how this principle could be applied in general to predict neural processing and then discuss concretely some neural systems where it recently has been shown to be successful. In particular, we examine the fly's LMC coding strategy and the mammalian retinal coding in the spatial, temporal and chromatic domains.},
	Author = {Atick, Joseph J},
	Doi = {10.3109/0954898X.2011.638888},
	File = {Atick_1992.pdf:/Users/Cecile/Zotero/storage/GNEZX6JW/Atick_1992.pdf:application/pdf},
	Issn = {1361-6536},
	Journal = {Network (Bristol, England)},
	Keywords = {Animals, Ecology, Humans, Information Theory, Neural Networks (Computer), Neural Pathways},
	Language = {eng},
	Number = {1-4},
	Pages = {4--44},
	Pmid = {22149669},
	Title = {Could information theory provide an ecological theory of sensory processing?},
	Volume = {22},
	Year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.3109/0954898X.2011.638888}}

@article{bieser_auditory_1996,
	Abstract = {The neural response to amplitude-modulated sinus sounds (AM sound) was investigated in the auditory cortex and insula of the awake squirrel monkey. It was found that 78.1\% of all acoustically driven neurons encoded the envelope of the AM sound; the remaining 21.9\% displayed simple On, On/Off or Off responses at the beginning or the end of the stimulus sound. Those neurons with AM coding were able to encode the AM sound frequency in two different ways: (1) the spikes followed the amplitude modulation envelopes in a phase locked manner; (2) the spike rate changed significantly with changing modulation frequencies. As reported in other species, the modulation transfer functions for rate showed higher modulation frequencies than the phase-locked response. Both AM codings exhibited a filter characteristic for AM sound. Whereas 46.6\% of all neurons had the same filter characteristic for both the spike discharge and the phase-locked response, the remaining neurons displayed combinations of different filter types. The discharge pattern of a neuron to simple tone or noise bursts suggests the behaviour of this neuron when AM sound is used as the stimulus. Neurons with strong onset responses to tone/noise bursts tended to have higher phase-locked AM responses than neurons with weak onset responses. The spike rate maxima for AM sound showed no relation to the tone/noise burst discharge patterns. Varying modulation depth was encoded by the neuron's ability to follow the envelope cycles and not by the non-phase-locked spike rate frequency. The organization of the squirrel monkey's auditory cortex has previously been established by an anatomical study. We have added two new fields using physiological parameters. All fields investigated showed a clear functional separation for time-critical information processing. The best temporal resolution was shown by the primary auditory field (AI), the first-temporal field (T1) and the parainsular auditory field (Pi). The neural data in these fields and the amplitude modulation frequency range of squirrel monkey calls suggest a similar correlation between vocalization and perception as in human psychophysical data for speech and hearing sensation. The anterior fields in particular failed to follow the AM envelopes. For the first time in a primate, the insula was tested with different sound parameters ranging from simple tone bursts to AM sound. It is suggested that this cortical region plays a role in time-critical aspects of acoustic information processing. The observed best frequencies covered the same spectrum as AI. As in the auditory fields, most neurons in the insula encoded AM sound with different filter types. The high proportion of neurons unable to encode AM sound (40.6\%) and the low mean best modulation frequency (9.9 Hz) do not support a prominent role of the insula in temporal information processing.},
	Author = {Bieser, A. and M{\"u}ller-Preuss, P.},
	Issn = {0014-4819},
	Journal = {Experimental Brain Research},
	Keywords = {Acoustic Stimulation, Animals, Auditory Perception, Evoked Potentials, Auditory, Neurons, Afferent, Noise, Pitch Perception, Saimiri, Auditory cortex},
	Language = {eng},
	Month = mar,
	Number = {2},
	Pages = {273--284},
	Pmid = {8815035},
	Shorttitle = {Auditory responsive cortex in the squirrel monkey},
	Title = {Auditory responsive cortex in the squirrel monkey: neural responses to amplitude-modulated sounds},
	Volume = {108},
	Year = {1996}}

@article{obleser_neural_2012,
	Author = {Obleser, Jonas and Herrmann, Bjorn and Henry, Molly J.},
	Doi = {10.3389/fnhum.2012.00250},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/K3V4W2AZ/Obleser et al. - 2012 - Neural Oscillations in Speech Don't be Enslaved b.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = aug,
	Pmcid = {PMC3431501},
	Pmid = {22969717},
	Shorttitle = {Neural {Oscillations} in {Speech}},
	Title = {Neural {Oscillations} in {Speech}: {Don}'t be {Enslaved} by the {Envelope}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431501/},
	Urldate = {2014-10-31},
	Volume = {6},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3431501/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2012.00250}}

@phdthesis{turner_statistical_2010,
	Abstract = {It is important to understand the rich structure of natural sounds in order to solve important
tasks, like automatic speech recognition, and to understand auditory processing
in the brain. This thesis takes a step in this direction by characterising the statistics of
simple natural sounds. We focus on the statistics because perception often appears to
depend on them, rather than on the raw waveform. For example the perception of auditory
textures, like running water, wind, fire and rain, depends on summary-statistics,
like the rate of falling rain droplets, rather than on the exact details of the physical
source.
In order to analyse the statistics of sounds accurately it is necessary to improve a
number of traditional signal processing methods, including those for amplitude demodulation,
time-frequency analysis, and sub-band demodulation. These estimation tasks
are ill-posed and therefore it is natural to treat them as Bayesian inference problems.
The new probabilistic versions of these methods have several advantages. For example,
they perform more accurately on natural signals and are more robust to noise,
they can also fill-in missing sections of data, and provide error-bars. Furthermore,
free-parameters can be learned from the signal. Using these new algorithms we demonstrate
that the energy, sparsity, modulation depth and modulation time-scale in each
sub-band of a signal are critical statistics, together with the dependencies between the
sub-band modulators. In order to validate this claim, a model containing co-modulated
coloured noise carriers is shown to be capable of generating a range of realistic sounding
auditory textures.
Finally, we explored the connection between the statistics of natural sounds and perception.
We demonstrate that inference in the model for auditory textures qualitatively
replicates the primitive grouping rules that listeners use to understand simple acoustic
scenes. This suggests that the auditory system is optimised for the statistics of natural
sounds.},
	Author = {Turner, R. E.},
	Copyright = {open},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZDT7GCDI/Turner - 2010 - Statistical models for natural sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U8NV8BEP/19231.html:text/html},
	Language = {eng},
	Month = jan,
	School = {UCL (University College London)},
	Title = {Statistical models for natural sounds},
	Type = {Doctoral},
	Url = {http://eprints.ucl.ac.uk/19231/},
	Urldate = {2013-12-13},
	Year = {2010},
	Bdsk-Url-1 = {http://eprints.ucl.ac.uk/19231/}}

@article{spierings_zebra_2014,
	Abstract = {Variation in pitch, amplitude and rhythm adds crucial paralinguistic information to human speech. Such prosodic cues can reveal information about the meaning or emphasis of a sentence or the emotional state of the speaker. To examine the hypothesis that sensitivity to prosodic cues is language independent and not human specific, we tested prosody perception in a controlled experiment with zebra finches. Using a go/no-go procedure, subjects were trained to discriminate between speech syllables arranged in XYXY patterns with prosodic stress on the first syllable and XXYY patterns with prosodic stress on the final syllable. To systematically determine the salience of the various prosodic cues (pitch, duration and amplitude) to the zebra finches, they were subjected to five tests with different combinations of these cues. The zebra finches generalized the prosodic pattern to sequences that consisted of new syllables and used prosodic features over structural ones to discriminate between stimuli. This strong sensitivity to the prosodic pattern was maintained when only a single prosodic cue was available. The change in pitch was treated as more salient than changes in the other prosodic features. These results show that zebra finches are sensitive to the same prosodic cues known to affect human speech perception.},
	Author = {Spierings, Michelle J. and Cate, Carel ten},
	Copyright = {{\copyright} 2014 The Author(s) Published by the Royal Society. All rights reserved.},
	Doi = {10.1098/rspb.2014.0480},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3GC3W45F/Spierings et Cate - 2014 - Zebra finches are sensitive to prosodic features o.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9FHVNZ5T/20140480.html:text/html},
	Issn = {0962-8452, 1471-2954},
	Journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	Language = {en},
	Month = jul,
	Number = {1787},
	Pages = {20140480},
	Pmid = {24870039},
	Title = {Zebra finches are sensitive to prosodic features of human speech},
	Url = {http://rspb.royalsocietypublishing.org/content/281/1787/20140480},
	Urldate = {2015-12-07},
	Volume = {281},
	Year = {2014},
	Bdsk-Url-1 = {http://rspb.royalsocietypublishing.org/content/281/1787/20140480},
	Bdsk-Url-2 = {https://doi.org/10.1098/rspb.2014.0480}}

@article{gerhardt_cochlear_1992,
	Abstract = {Purpose: Sounds present within the uterus stimulate the fetal inner ear and central auditory pathway. This study was undertaken to determine the efficiency of transmission of exogenous airborne stimuli to the fetal inner ear. In this way, we may quantify the extent to which the fetal auditory system is isolated from sounds produced outside the mother.

Materials and Methods: Cochlear microphonics were recorded from fetal and newborn sheep to evaluate the extent to which the fetus is isolated from sounds exogenous to the ewe. Electrodes were surgically placed in contact with the round window membrane in nine near-term fetal sheep. Cochlear microphonics were recorded in response to 13 octave-band noises (0.125 to 2.0 kHz) delivered through a loudspeaker 1.8 m from one side of the pregnant ewe. Sound pressure levels generated by the noises were simultaneously recorded ex utero with a microphone and in utero with a hydrophone previously sutured to the fetal neck. After cochlear microphonic amplitudes were recorded, the fetus was delivered through an abdominal incision. Recordings were repeated from the newborn lamb. Fetal sound isolation was calculated as the difference between the sound pressure levels that were necessary to evoke equal cochlear microphonic amplitudes from the fetus and from the newborn lamb.

Results: The sound attenuation observed was variable for all frequencies. The fetus was isolated from external sounds by 11.1 dB for 0.125 kHz, 19.8 dB for 0.25 kHz, 35.3 dB for 0.5 kHz, 38.2 dB for 1.0 kHz, and 45.0 dB for 2.0 kHz.

Conclusions: Other investigators have demonstrated that the immature auditory system is more susceptible to damage produced by noise exposure than is the mature auditory system. Low-frequency noise produces damaged cells that later in life code higher frequencies. A possibility of fetal hearing loss produced by intense noise exposure needs more careful evaluation.},
	Author = {Gerhardt, Kenneth J and Otto, Randal and Abrams, Robert M and Colle, Joy J and Burchfield, David J and Peters, Aemil J. M},
	Doi = {10.1016/0196-0709(92)90026-P},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IJKBZ79T/Gerhardt et al. - 1992 - Cochlear microphonics recorded from fetal and newb.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7PN66QQ4/019607099290026P.html:text/html},
	Issn = {0196-0709},
	Journal = {American Journal of Otolaryngology},
	Month = jul,
	Number = {4},
	Pages = {226--233},
	Title = {Cochlear microphonics recorded from fetal and newborn sheep},
	Url = {http://www.sciencedirect.com/science/article/pii/019607099290026P},
	Urldate = {2016-01-30},
	Volume = {13},
	Year = {1992},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/019607099290026P},
	Bdsk-Url-2 = {https://doi.org/10.1016/0196-0709(92)90026-P}}

@article{minagawa-kawai_insights_2013,
	Abstract = {Each language has a unique set of phonemic categories and phonotactic rules which determine permissible sound sequences in that language. Behavioral research demonstrates that one's native language shapes the perception of both sound categories and sound sequences in adults, and neuroimaging results further indicate that the processing of native phonemes and phonotactics involves a left-dominant perisylvian brain network. Recent work using a novel technique, functional Near InfraRed Spectroscopy (NIRS), has suggested that a left-dominant network becomes evident toward the end of the first year of life as infants process phonemic contrasts. The present research project attempted to assess whether the same pattern would be seen for native phonotactics. We measured brain responses in Japanese- and French-learning infants to two contrasts: Abuna vs. Abna (a phonotactic contrast that is native in French, but not in Japanese) and Abuna vs. Abuuna (a vowel length contrast that is native in Japanese, but not in French). Results did not show a significant response to either contrast in either group, unlike both previous behavioral research on phonotactic processing and NIRS work on phonemic processing. To understand these null results, we performed similar NIRS experiments with Japanese adult participants. These data suggest that the infant null results arise from an interaction of multiple factors, involving the suitability of the experimental paradigm for NIRS measurements and stimulus perceptibility. We discuss the challenges facing this novel technique, particularly focusing on the optimal stimulus presentation which could yield strong enough hemodynamic responses when using the change detection paradigm.},
	Author = {Minagawa-Kawai, Yasuyo and Cristia, Alejandrina and Long, Bria and Vendelin, Inga and Hakuno, Yoko and Dutat, Michel and Filippin, Luca and Cabrol, Dominique and Dupoux, Emmanuel},
	Doi = {10.3389/fpsyg.2013.00170},
	Journal = {Language Sciences},
	Keywords = {Infant, near infrared spectroscopy, phoneme perception, phonotactics, speech perception, Speech Perception},
	Pages = {170},
	Title = {Insights on {NIRS} sensitivity from a cross-linguistic study on the emergence of phonological grammar},
	Url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00170/abstract},
	Urldate = {2016-03-28},
	Volume = {4},
	Year = {2013},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00170/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2013.00170}}

@article{pena_sounds_2003,
	Abstract = {Does the neonate's brain have left hemisphere (LH) dominance for speech? Twelve full-term neonates participated in an optical topography study designed to assess whether the neonate brain responds specifically to linguistic stimuli. Participants were tested with normal infant-directed speech, with the same utterances played in reverse and without auditory stimulation. We used a 24-channel optical topography device to assess changes in the concentration of total hemoglobin in response to auditory stimulation in 12 areas of the right hemisphere and 12 areas of the LH. We found that LH temporal areas showed significantly more activation when infants were exposed to normal speech than to backward speech or silence. We conclude that neonates are born with an LH superiority to process specific properties of speech.},
	Author = {Pe{\~n}a, Marcela and Maki, Atsushi and Kovacic, Damir and Dehaene-Lambertz, Ghislaine and Koizumi, Hideaki and Bouquet, Furio and Mehler, Jacques},
	Doi = {10.1073/pnas.1934290100},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/F673HJHG/Pena et al. - 2003 - Sounds and silence An optical topography study of.pdf:application/pdf},
	Issn = {0027-8424},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Month = sep,
	Number = {20},
	Pages = {11702--11705},
	Pmcid = {PMC208821},
	Pmid = {14500906},
	Shorttitle = {Sounds and silence},
	Title = {Sounds and silence: {An} optical topography study of language recognition at birth},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC208821/},
	Urldate = {2013-06-18},
	Volume = {100},
	Year = {2003},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC208821/},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1934290100}}

@article{benavides-varela_newborns_2012,
	Abstract = {Recent research has shown that specific areas of the human brain are activated by speech from the time of birth. However, it is currently unknown whether newborns' brains also encode and remember the sounds of words when processing speech. The present study investigates the type of information that newborns retain when they hear words and the brain structures that support word-sound recognition. Forty-four healthy newborns were tested with the functional near-infrared spectroscopy method to establish their ability to memorize the sound of a word and distinguish it from a phonetically similar one, 2 min after encoding. Right frontal regions--comparable to those activated in adults during retrieval of verbal material--showed a characteristic neural signature of recognition when newborns listened to a test word that had the same vowel of a previously heard word. In contrast, a characteristic novelty response was found when a test word had different vowels than the familiar word, despite having the same consonants. These results indicate that the information carried by vowels is better recognized by newborns than the information carried by consonants. Moreover, these data suggest that right frontal areas may support the recognition of speech sequences from the very first stages of language acquisition.},
	Author = {Benavides-Varela, Silvia and Hochmann, Jean-R{\'e}my and Macagno, Francesco and Nespor, Marina and Mehler, Jacques},
	Doi = {10.1073/pnas.1205413109},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IFQV3AEA/Benavides-Varela et al. - 2012 - Newborn's brain activity signals the origin of wor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BU2M8GKX/17908.html:text/html},
	Issn = {1091-6490},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Acoustic Stimulation, Female, Humans, Infant, Newborn, Male, Memory, Spectroscopy, Near-Infrared, Speech, neonate's memory, oxyhemoglobin, right frontal lobe, sound encoding, speech perception, Brain},
	Language = {eng},
	Month = oct,
	Number = {44},
	Pages = {17908--17913},
	Pmcid = {PMC3497807},
	Pmid = {23071325},
	Title = {Newborn's brain activity signals the origin of word memories},
	Volume = {109},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1073/pnas.1205413109}}

@article{telkemeyer_sensitivity_2009,
	Abstract = {Understanding the rapidly developing building blocks of speech perception in infancy requires a close look at the auditory prerequisites for speech sound processing. Pioneering studies have demonstrated that hemispheric specializations for language processing are already present in early infancy. However, whether these computational asymmetries can be considered a function of linguistic attributes or a consequence of basic temporal signal properties is under debate. Several studies in adults link hemispheric specialization for certain aspects of speech perception to an asymmetry in cortical tuning and reveal that the auditory cortices are differentially sensitive to spectrotemporal features of speech. Applying concurrent electrophysiological (EEG) and hemodynamic (near-infrared spectroscopy) recording to newborn infants listening to temporally structured nonspeech signals, we provide evidence that newborns process nonlinguistic acoustic stimuli that share critical temporal features with language in a differential manner. The newborn brain preferentially processes temporal modulations especially relevant for phoneme perception. In line with multi-time-resolution conceptions, modulations on the time scale of phonemes elicit strong bilateral cortical responses. Our data furthermore suggest that responses to slow acoustic modulations are lateralized to the right hemisphere. That is, the newborn auditory cortex is sensitive to the temporal structure of the auditory input and shows an emerging tendency for functional asymmetry. Hence, our findings support the hypothesis that development of speech perception is linked to basic capacities in auditory processing. From birth, the brain is tuned to critical temporal properties of linguistic signals to facilitate one of the major needs of humans: to communicate.},
	Author = {Telkemeyer, Silke and Rossi, Sonja and Koch, Stefan P. and Nierhaus, Till and Steinbrink, Jens and Poeppel, David and Obrig, Hellmuth and Wartenburger, Isabell},
	Doi = {10.1523/JNEUROSCI.1246-09.2009},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/EMWR48U6/Telkemeyer et al. - 2009 - Sensitivity of Newborn Auditory Cortex to the Temp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JUNBPS7R/14726.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = nov,
	Number = {47},
	Pages = {14726--14733},
	Pmid = {19940167},
	Title = {Sensitivity of {Newborn} {Auditory} {Cortex} to the {Temporal} {Structure} of {Sounds}},
	Url = {http://www.jneurosci.org/content/29/47/14726},
	Urldate = {2015-02-06},
	Volume = {29},
	Year = {2009},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/29/47/14726},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1246-09.2009}}

@article{friederici_brain_2007,
	Author = {Friederici, Angela D. and Friedrich, Manuela and Christophe, Anne},
	Doi = {10.1016/j.cub.2007.06.011},
	File = {Friedericietal07.pdf:/Users/Cecile/Zotero/storage/EWQRG8J4/Friedericietal07.pdf:application/pdf},
	Issn = {09609822},
	Journal = {Current Biology},
	Language = {en},
	Month = jul,
	Number = {14},
	Pages = {1208--1211},
	Title = {Brain {Responses} in 4-{Month}-{Old} {Infants} {Are} {Already} {Language} {Specific}},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982207015114},
	Urldate = {2015-07-30},
	Volume = {17},
	Year = {2007},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0960982207015114},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2007.06.011}}

@article{friederici_cortical_2012,
	Abstract = {Over the years, a large body of work on the brain basis of language comprehension has accumulated, paving the way for the formulation of a comprehensive model. The model proposed here describes the functional neuroanatomy of the different processing steps from auditory perception to comprehension as located in different gray matter brain regions. It also specifies the information flow between these regions, taking into account white matter fiber tract connections. Bottom-up, input-driven processes proceeding from the auditory cortex to the anterior superior temporal cortex and from there to the prefrontal cortex, as well as top-down, controlled and predictive processes from the prefrontal cortex back to the temporal cortex are proposed to constitute the cortical language circuit.},
	Author = {Friederici, Angela D.},
	Doi = {10.1016/j.tics.2012.04.001},
	File = {Friederici12.pdf:/Users/Cecile/Zotero/storage/WUW32Q3U/Friederici12.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/SEH36SDA/S1364-6613(12)00079-4.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Language = {English},
	Month = may,
	Number = {5},
	Pages = {262--268},
	Pmid = {22516238},
	Shorttitle = {The cortical language circuit},
	Title = {The cortical language circuit: from auditory perception to sentence comprehension},
	Url = {http://www.cell.com/article/S1364661312000794/abstract},
	Urldate = {2014-06-01},
	Volume = {16},
	Year = {2012},
	Bdsk-Url-1 = {http://www.cell.com/article/S1364661312000794/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2012.04.001}}

@article{grill-spector_fmr-adaptation:_2001,
	Abstract = {The invariant properties of human cortical neurons cannot be studied directly by fMRI due to its limited spatial resolution. One voxel obtained from a fMRI scan contains several hundred thousands neurons. Therefore, the fMRI signal may average out a heterogeneous group of highly selective neurons. Here, we present a novel experimental paradigm for fMRI, functional magnetic resonance-adaptation (fMR-A), that enables to tag specific neuronal populations within an area and investigate their functional properties. This approach contrasts with conventional mapping methods that measure the averaged activity of a region. The application of fMR-A to study the functional properties of cortical neurons proceeds in two stages: First, the neuronal population is adapted by repeated presentation of a single stimulus. Second, some property of the stimulus is varied and the recovery from adaptation is assessed. If the signal remains adapted, it will indicate that the neurons are invariant to that attribute. However, if the fMRI signal will recover from the adapted state it would imply that the neurons are sensitive to the property that was varied. Here, an application of fMR-A for studying the invariant properties of high-order object areas (lateral occipital complex -- LOC) to changes in object size, position, illumination and rotation is presented. The results show that LOC is less sensitive to changes in object size and position compared to changes of illumination and viewpoint. fMR-A can be extended to other neuronal systems in which adaptation is manifested and can be used with event-related paradigms as well. By manipulating experimental parameters and testing recovery from adaptation it should be possible to gain insight into the functional properties of cortical neurons which are beyond the spatial resolution limits imposed by conventional fMRI.},
	Author = {Grill-Spector, Kalanit and Malach, Rafael},
	Doi = {10.1016/S0001-6918(01)00019-1},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MXVQN8X9/Grill-Spector et Malach - 2001 - fMR-adaptation a tool for studying the functional.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZJCGV8S5/S0001691801000191.html:text/html},
	Issn = {0001-6918},
	Journal = {Acta Psychologica},
	Keywords = {Human visual areas, Object recognition, Occipital cortex, fMR-adaptation, fMRI},
	Month = apr,
	Number = {1--3},
	Pages = {293--321},
	Series = {Beyond the decade of the brain: {Towards} functional neuronanatomy of the mind},
	Shorttitle = {{fMR}-adaptation},
	Title = {{fMR}-adaptation: a tool for studying the functional properties of human cortical neurons},
	Url = {http://www.sciencedirect.com/science/article/pii/S0001691801000191},
	Urldate = {2016-09-27},
	Volume = {107},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0001691801000191},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0001-6918(01)00019-1}}

@article{hickok_cortical_2007,
	Author = {Hickok, Gregory and Poeppel, David},
	File = {The cortical organization of speech processing \: Abstract \: Nature Reviews Neuroscience:/Users/Cecile/Zotero/storage/QTFPD9AP/nrn2113.html:text/html},
	Month = may,
	Pages = {393--402},
	Series = {Nature {Reviews} {Neuroscience}},
	Title = {The cortical organization of speech processing},
	Url = {http://www.nature.com/nrn/journal/v8/n5/abs/nrn2113.html},
	Urldate = {2014-01-20},
	Volume = {8},
	Year = {2007},
	Bdsk-Url-1 = {http://www.nature.com/nrn/journal/v8/n5/abs/nrn2113.html}}

@article{torkildsen_brain_2009,
	Abstract = {The present study investigated the brain mechanisms involved during young children's receptive familiarization with new words, and whether the dynamics of these mechanisms are related to the child's productive vocabulary size. To this end, we recorded event-related potentials (ERPs) from 20-month-old children in a pseudoword repetition task. Results revealed distinct patterns of repetition effects for children with large and small productive vocabularies. High producers showed evidence of recognizing the novel words already after three presentations, while the low producers needed five presentations to display a recognition effect. The familiarization process was manifested in the modulations of two components, the N200--400 and a later fronto-central component, which appeared to increase in amplitude until a certain level of encoding was reached and then decrease with further repetition. These findings suggest a relation between the onset of the productive vocabulary spurt and the rate of receptive word familiarization.},
	Author = {Torkildsen, Janne von Koss and Friis Hansen, Hanna and Svangstu, Janne Mari and Smith, Lars and Simonsen, Hanne Gram and Moen, Inger and Lindgren, Magnus},
	Doi = {10.1016/j.bandl.2008.09.005},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/CH2QHJ4M/S0093934X08001259.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Keywords = {Word processing, Vocabulary spurt, Repetition, N200--400, ERP, Nc, Development},
	Month = feb,
	Number = {2},
	Pages = {73--88},
	Shorttitle = {Brain dynamics of word familiarization in 20-month-olds},
	Title = {Brain dynamics of word familiarization in 20-month-olds: {Effects} of productive vocabulary size},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X08001259},
	Urldate = {2017-07-24},
	Volume = {108},
	Year = {2009},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X08001259},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2008.09.005}}

@article{osullivan_attentional_2015,
	Abstract = {How humans solve the cocktail party problem remains unknown. However, progress has been made recently thanks to the realization that cortical activity tracks the amplitude envelope of speech. This has led to the development of regression methods for studying the neurophysiology of continuous speech. One such method, known as stimulus-reconstruction, has been successfully utilized with cortical surface recordings and magnetoencephalography (MEG). However, the former is invasive and gives a relatively restricted view of processing along the auditory hierarchy, whereas the latter is expensive and rare. Thus it would be extremely useful for research in many populations if stimulus-reconstruction was effective using electroencephalography (EEG), a widely available and inexpensive technology. Here we show that single-trial (â60 s) unaveraged EEG data can be decoded to determine attentional selection in a naturalistic multispeaker environment. Furthermore, we show a significant correlation between our EEG-based measure of attention and performance on a high-level attention task. In addition, by attempting to decode attention at individual latencies, we identify neural processing at â¼200 ms as being critical for solving the cocktail party problem. These findings open up new avenues for studying the ongoing dynamics of cognition using EEG and for developing effective and natural brain--computer interfaces.},
	Author = {O'Sullivan, James A. and Power, Alan J. and Mesgarani, Nima and Rajaram, Siddharth and Foxe, John J. and Shinn-Cunningham, Barbara G. and Slaney, Malcolm and Shamma, Shihab A. and Lalor, Edmund C.},
	Doi = {10.1093/cercor/bht355},
	File = {Cereb. Cortex-2015-O'Sullivan-1697-706.pdf:/Users/Cecile/Zotero/storage/TMBQ8HG7/Cereb. Cortex-2015-O'Sullivan-1697-706.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TRXVVEXT/login.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Keywords = {Attention, EEG, Speech, BCI, cocktail party, stimulus-reconstruction},
	Language = {en},
	Month = jan,
	Number = {7},
	Pages = {1697--1706},
	Pmid = {24429136},
	Title = {Attentional {Selection} in a {Cocktail} {Party} {Environment} {Can} {Be} {Decoded} from {Single}-{Trial} {EEG}},
	Url = {http://cercor.oxfordjournals.org.gate1.inist.fr/content/25/7/1697},
	Urldate = {2016-05-11},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org.gate1.inist.fr/content/25/7/1697},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bht355}}

@article{dehaene-lambertz_language_2010,
	Abstract = {Understanding how language emerged in our species calls for a detailed investigation of the initial specialization of the human brain for speech processing. Our earlier research demonstrated that an adult-like left-lateralized network of perisylvian areas is already active when infants listen to sentences in their native language, but did not address the issue of the specialization of this network for speech processing. Here we used fMRI to study the organization of brain activity in two-month-old infants when listening to speech or to music. We also explored how infants react to their mother's voice relative to an unknown voice. The results indicate that the well-known structural asymmetry already present in the infants' posterior temporal areas has a functional counterpart: there is a left-hemisphere advantage for speech relative to music at the level of the planum temporale. The posterior temporal regions are thus differently sensitive to the auditory environment very early on, channelling speech inputs preferentially to the left side. Furthermore, when listening to the mother's voice, activation was modulated in several areas, including areas involved in emotional processing (amygdala, orbito-frontal cortex), but also, crucially, a large extent of the left posterior temporal lobe, suggesting that the mother's voice plays a special role in the early shaping of posterior language areas. Both results underscore the joint contributions of genetic constraints and environmental inputs in the fast emergence of an efficient cortical network for language processing in humans.},
	Author = {Dehaene-Lambertz, G and Montavont, A and Jobert, A and Allirol, L and Dubois, J and Hertz-Pannier, L and Dehaene, S},
	Doi = {10.1016/j.bandl.2009.09.003},
	Issn = {1090-2155},
	Journal = {Brain and language},
	Keywords = {Acoustic Stimulation, Amygdala, Auditory Pathways, Female, Frontal Lobe, Humans, Infant, Language Development, Male, Mothers, Music, Phonetics, Temporal Lobe, Voice, speech perception, Auditory cortex, Magnetic resonance imaging, Speech Perception},
	Language = {eng},
	Month = aug,
	Number = {2},
	Pages = {53--65},
	Pmid = {19864015},
	Shorttitle = {Language or music, mother or {Mozart}?},
	Title = {Language or music, mother or {Mozart}? {Structural} and environmental influences on infants' language networks},
	Volume = {114},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.bandl.2009.09.003}}

@article{schnupp_plasticity_2006,
	Abstract = {It has been suggested that ``call-selective'' neurons may play an important role in the encoding of vocalizations in primary auditory cortex (A1). For example, marmoset A1 neurons often respond more vigorously to natural than to time-reversed twitter calls, although the spectral energy distribution in the natural and time-reversed signals is the same. Neurons recorded in cat A1, in contrast, showed no such selectivity for natural marmoset calls. To investigate whether call selectivity in A1 can arise purely as a result of auditory experience, we recorded responses to marmoset calls in A1 of naive ferrets, as well as in ferrets that had been trained to recognize these natural marmoset calls. We found that training did not induce call selectivity for the trained vocalizations in A1. However, although ferret A1 neurons were not call selective, they efficiently represented the vocalizations through temporal pattern codes, and trained animals recognized marmoset twitters with a high degree of accuracy. These temporal patterns needed to be analyzed at timescales of 10--50 ms to ensure efficient decoding. Training led to a substantial increase in the amount of information transmitted by these temporal discharge patterns, but the fundamental nature of the temporal pattern code remained unaltered. These results emphasize the importance of temporal discharge patterns and cast doubt on the functional significance of call-selective neurons in the processing of animal communication sounds at the level of A1.},
	Author = {Schnupp, Jan W. H. and Hall, Thomas M. and Kokelaar, Rory F. and Ahmed, Bashir},
	Doi = {10.1523/JNEUROSCI.4330-05.2006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UR3V7GVA/Schnupp et al. - 2006 - Plasticity of Temporal Pattern Codes for Vocalizat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QQIXQDAT/4785.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Keywords = {Sound, behavior, temporal coding, training, vocalization, Auditory cortex},
	Language = {en},
	Month = mar,
	Number = {18},
	Pages = {4785--4795},
	Pmid = {16672651},
	Title = {Plasticity of {Temporal} {Pattern} {Codes} for {Vocalization} {Stimuli} in {Primary} {Auditory} {Cortex}},
	Url = {http://www.jneurosci.org/content/26/18/4785},
	Urldate = {2015-07-15},
	Volume = {26},
	Year = {2006},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/26/18/4785},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.4330-05.2006}}

@article{abboub_prosodic_2016,
	Abstract = {Experience with spoken language starts prenatally, as hearing becomes operational during the second half of gestation. While maternal tissues filter out many aspects of speech, they readily transmit speech prosody and rhythm. These properties of the speech signal then play a central role in early language acquisition. In this study, we ask how the newborn brain uses variation in duration, pitch and intensity (the three acoustic cues that carry prosodic information in speech) to group sounds. In four near-infrared spectroscopy studies (NIRS), we demonstrate that perceptual biases governing how sound sequences are perceived and organized are present in newborns from monolingual and bilingual language backgrounds. Importantly, however, these prosodic biases are present only for acoustic patterns found in the prosody of their native languages. These findings advance our understanding of how prenatal language experience lays the foundations for language development.},
	Author = {Abboub, Nawal and Nazzi, Thierry and Gervain, Judit},
	Doi = {10.1016/j.bandl.2016.08.002},
	Issn = {1090-2155},
	Journal = {Brain and Language},
	Keywords = {Newborn infants, Perceptual biases, Prenatal exposure, Prosodic grouping, bilingualism, Near-infrared spectroscopy},
	Language = {ENG},
	Month = aug,
	Pages = {46--59},
	Pmid = {27567401},
	Title = {Prosodic grouping at birth},
	Volume = {162},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.bandl.2016.08.002}}

@article{teinonen_statistical_2009,
	Abstract = {BACKGROUND: Statistical learning is a candidate for one of the basic prerequisites underlying the expeditious acquisition of spoken language. Infants from 8 months of age exhibit this form of learning to segment fluent speech into distinct words. To test the statistical learning skills at birth, we recorded event-related brain responses of sleeping neonates while they were listening to a stream of syllables containing statistical cues to word boundaries.
RESULTS: We found evidence that sleeping neonates are able to automatically extract statistical properties of the speech input and thus detect the word boundaries in a continuous stream of syllables containing no morphological cues. Syllable-specific event-related brain responses found in two separate studies demonstrated that the neonatal brain treated the syllables differently according to their position within pseudowords.
CONCLUSION: These results demonstrate that neonates can efficiently learn transitional probabilities or frequencies of co-occurrence between different syllables, enabling them to detect word boundaries and in this way isolate single words out of fluent natural speech. The ability to adopt statistical structures from speech may play a fundamental role as one of the earliest prerequisites of language acquisition.},
	Author = {Teinonen, Tuomas and Fellman, Vineta and N{\"a}{\"a}t{\"a}nen, Risto and Alku, Paavo and Huotilainen, Minna},
	Doi = {10.1186/1471-2202-10-21},
	Issn = {1471-2202},
	Journal = {BMC neuroscience},
	Keywords = {Auditory Perception, Cues, Evoked Potentials, Electroencephalography, Female, Humans, Infant, Newborn, Language Development, Male, Phonetics, Verbal Learning, speech perception, Brain, Speech Perception},
	Language = {eng},
	Pages = {21},
	Pmcid = {PMC2670827},
	Pmid = {19284661},
	Title = {Statistical language learning in neonates revealed by event-related brain potentials},
	Volume = {10},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1186/1471-2202-10-21}}

@article{friederici_lateralization_2004,
	Abstract = {Spoken language comprehension requires the coordination of different subprocesses in time. After the initial acoustic analysis the system has to extract segmental information such as phonemes, syntactic elements and lexical-semantic elements as well as suprasegmental information such as accentuation and intonational phrases, i.e., prosody. According to the dynamic dual pathway model of auditory language comprehension syntactic and semantic information are primarily processed in a left hemispheric temporo-frontal pathway including separate circuits for syntactic and semantic information whereas sentence level prosody is processed in a right hemispheric temporo-frontal pathway. The relative lateralization of these functions occurs as a result of stimulus properties and processing demands. The observed interaction between syntactic and prosodic information during auditory sentence comprehension is attributed to dynamic interactions between the two hemispheres.},
	Author = {Friederici, Angela D and Alter, Kai},
	Doi = {10.1016/S0093-934X(03)00351-1},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RTBN92UT/Friederici et Alter - 2004 - Lateralization of auditory language functions A d.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TIBKV57Q/S0093934X03003511.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Month = may,
	Number = {2},
	Pages = {267--276},
	Series = {Language and {MotorIntegration}},
	Shorttitle = {Lateralization of auditory language functions},
	Title = {Lateralization of auditory language functions: {A} dynamic dual pathway model},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X03003511},
	Urldate = {2016-01-30},
	Volume = {89},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X03003511},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0093-934X(03)00351-1}}

@article{fitch_neurobiology_1997,
	Abstract = {The mechanisms by which human speech is processed in the brain are reviewed from both behavioral and neurobiological perspectives. Special consideration is given to the separation of speech processing as a complex acoustic-processing task versus a linguistic task. Relevant animal research is reviewed, insofar as these data provide insight into the neurobiological basis of complex acoustic processing in the brain.},
	Author = {Fitch, R. Holly and Miller, Steve and Tallal, Paula},
	Doi = {10.1146/annurev.neuro.20.1.331},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6NT4BBV7/Fitch et al. - 1997 - Neurobiology of Speech Perception.pdf:application/pdf},
	Journal = {Annual Review of Neuroscience},
	Keywords = {Temporal processing, Timing, Wernicke's area, acoustic cues, auditory system},
	Number = {1},
	Pages = {331--353},
	Pmid = {9056717},
	Title = {Neurobiology of {Speech} {Perception}},
	Url = {http://dx.doi.org/10.1146/annurev.neuro.20.1.331},
	Urldate = {2015-05-22},
	Volume = {20},
	Year = {1997},
	Bdsk-Url-1 = {http://dx.doi.org/10.1146/annurev.neuro.20.1.331}}

@article{shi_infant_2011,
	Abstract = {Background
Studies for infants are usually hindered by the insufficient image contrast, especially for neonates. Prior knowledge, in the form of atlas, can provide additional guidance for the data processing such as spatial normalization, label propagation, and tissue segmentation. Although it is highly desired, there is currently no such infant atlas which caters for all these applications. The reason may be largely due to the dramatic early brain development, image processing difficulties, and the need of a large sample size. 
         
         
           Methodology 
           To this end, after several years of subject recruitment and data acquisition, we have collected a unique longitudinal dataset, involving 95 normal infants (56 males and 39 females) with MRI scanned at 3 ages, i.e., neonate, 1-year-old, and 2-year-old. State-of-the-art MR image segmentation and registration techniques were employed, to construct which include the templates (grayscale average images), tissue probability maps (TPMs), and brain parcellation maps (i.e., meaningful anatomical regions of interest) for each age group. In addition, the longitudinal correspondences between age-specific atlases were also obtained. Experiments of typical infant applications validated that the proposed atlas outperformed other atlases and is hence very useful for infant-related studies. 
         
         
           Conclusions 
           We expect that the proposed infant 0--1--2 brain atlases would be significantly conducive to structural and functional studies of the infant brains. These atlases are publicly available in our website,  http://bric.unc.edu/ideagroup/free-softwares/ .},
	Author = {Shi, Feng and Yap, Pew-Thian and Wu, Guorong and Jia, Hongjun and Gilmore, John H. and Lin, Weili and Shen, Dinggang},
	Doi = {10.1371/journal.pone.0018746},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/N42XSPWJ/Shi et al. - 2011 - Infant Brain Atlases from Neonates to 1- and 2-Yea.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZGUNHVQG/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Age groups, Deformation, Imaging techniques, neuroimaging, Infants, neonates, Brain, Magnetic resonance imaging},
	Month = apr,
	Number = {4},
	Pages = {e18746},
	Title = {Infant {Brain} {Atlases} from {Neonates} to 1- and 2-{Year}-{Olds}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018746},
	Urldate = {2016-09-28},
	Volume = {6},
	Year = {2011},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0018746},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0018746}}

@article{price_review_2012,
	Author = {Price, Cathy J.},
	Doi = {https://dx-doi-org.frodon.univ-paris5.fr/10.1016/j.neuroimage.2012.04.062},
	File = {A review and synthesis of the first 20years of PET and fMRI studies of heard speech, spoken language and reading:/Users/Cecile/Zotero/storage/9XNWIMTP/S1053811912004703.html:text/html;Price12.pdf:/Users/Cecile/Zotero/storage/ZEH7XXBG/Price12.pdf:application/pdf},
	Journal = {NeuroImage},
	Month = aug,
	Number = {2},
	Pages = {816--847},
	Title = {A review and synthesis of the first 20years of {PET} and {fMRI} studies of heard speech, spoken language and reading},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811912004703},
	Urldate = {2014-06-01},
	Volume = {62},
	Year = {2012},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1053811912004703},
	Bdsk-Url-2 = {https://dx-doi-org.frodon.univ-paris5.fr/10.1016/j.neuroimage.2012.04.062}}

@article{nourski_representation_2011,
	Abstract = {Temporal information in acoustic signals is important for the perception of environmental sounds, including speech. This review focuses on several aspects of temporal processing within human auditory cortex and its relevance for the processing of speech sounds. Periodic non-speech sounds, such as trains of acoustic clicks and bursts of amplitude-modulated noise or tones, can elicit different percepts depending on the pulse repetition rate or modulation frequency. Such sounds provide convenient methodological tools to study representation of timing information in the auditory system. At low repetition rates of up to 8-10 Hz, each individual stimulus (a single click or a sinusoidal amplitude modulation cycle) within the sequence is perceived as a separate event. As repetition rates increase up to and above approximately 40 Hz, these events blend together, giving rise first to the percept of flutter and then to pitch. The extent to which neural responses of human auditory cortex encode temporal features of acoustic stimuli is discussed within the context of these perceptual classes of periodic stimuli and their relationship to speech sounds. Evidence for neural coding of temporal information at the level of the core auditory cortex in humans suggests possible physiological counterparts to perceptual categorical boundaries for periodic acoustic stimuli. Temporal coding is less evident in auditory cortical fields beyond the core. Finally, data suggest hemispheric asymmetry in temporal cortical processing.},
	Author = {Nourski, Kirill V. and Brugge, John F.},
	Doi = {10.1515/RNS.2011.016},
	File = {NourskiBrugge2011.pdf:/Users/Cecile/Zotero/storage/KSRKK3PJ/NourskiBrugge2011.pdf:application/pdf},
	Issn = {0334-1763},
	Journal = {Reviews in the Neurosciences},
	Keywords = {Acoustic Stimulation, Auditory Perception, Brain Waves, Humans, Models, Neurological, Sound, Speech, Auditory cortex},
	Language = {eng},
	Number = {2},
	Pages = {187--203},
	Pmid = {21476940},
	Title = {Representation of temporal sound features in the human auditory cortex},
	Volume = {22},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1515/RNS.2011.016}}

@article{nelken_ear_2013,
	Author = {Nelken, Israel and de Cheveign{\'e}, Alain},
	Doi = {10.1038/nn.3360},
	Issn = {1546-1726},
	Journal = {Nature neuroscience},
	Keywords = {Acoustic Stimulation, Auditory Perception, Discrimination Learning, Female, Humans, Male, Psychomotor Performance},
	Language = {eng},
	Month = apr,
	Number = {4},
	Pages = {381--382},
	Pmid = {23528936},
	Title = {An ear for statistics},
	Volume = {16},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.3360}}

@article{lewicki_information_2010,
	Abstract = {Approaches that abandon traditional speech categories offer promise for developing statistical descriptions that encapsulate how speech conveys information. Grandparents would be among the beneficiaries.},
	Author = {Lewicki, Michael S.},
	Copyright = {{\copyright} 2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/466821a},
	File = {A Signal Take On Speech:/Users/Cecile/Zotero/storage/NHHVZGCB/Lewicki10ASignalTakeOnSpeech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XZ4ZCZ8J/466821a.html:text/html},
	Issn = {0028-0836},
	Journal = {Nature},
	Language = {en},
	Month = aug,
	Number = {7308},
	Pages = {821--822},
	Shorttitle = {Information theory},
	Title = {Information theory: {A} signal take on speech},
	Url = {http://www.nature.com/nature/journal/v466/n7308/full/466821a.html?message-global=remove},
	Urldate = {2015-02-04},
	Volume = {466},
	Year = {2010},
	Bdsk-Url-1 = {http://www.nature.com/nature/journal/v466/n7308/full/466821a.html?message-global=remove},
	Bdsk-Url-2 = {https://doi.org/10.1038/466821a}}

@article{gilden_1/f_1995,
	Abstract = {When a person attempts to produce from memory a given spatial or temporal interval, there is inevitably some error associated with the estimate. The time course of this error was measured in a series of experiments where subjects repeatedly attempted to replicate given target intervals. Sequences of the errors in both spatial and temporal replications were found to fluctuate as 1/f noises. 1/f noise is encountered in a wide variety of physical systems and is theorized to be a characteristic signature of complexity.},
	Author = {Gilden, D. L. and Thornton, T. and Mallon, M. W.},
	Doi = {10.1126/science.7892611},
	File = {Snapshot:/Users/Cecile/Zotero/storage/GTQZFAUU/1837.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = mar,
	Number = {5205},
	Pages = {1837--1839},
	Pmid = {7892611},
	Title = {1/f noise in human cognition},
	Url = {http://www.sciencemag.org/content/267/5205/1837},
	Urldate = {2015-12-16},
	Volume = {267},
	Year = {1995},
	Bdsk-Url-1 = {http://www.sciencemag.org/content/267/5205/1837},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.7892611}}

@article{sharpee_hierarchical_2011,
	Abstract = {Understanding the neural mechanisms of invariant object recognition remains one of the major unsolved problems in neuroscience. A common solution that is thought to be employed by diverse sensory systems is to create hierarchical representations of increasing complexity and tolerance. However, in the mammalian auditory system many aspects of this hierarchical organization remain undiscovered, including the prominent classes of high-level representations (that would be analogous to face selectivity in the visual system or selectivity to bird's own song in the bird) and the dominant types of invariant transformations. Here we review the recent progress that begins to probe the hierarchy of auditory representations, and the computational approaches that can be helpful in achieving this feat.},
	Author = {Sharpee, Tatyana O. and Atencio, Craig A. and Schreiner, Christoph E.},
	Doi = {10.1016/j.conb.2011.05.027},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NWS9KRXF/S095943881100095X.html:text/html},
	Issn = {1873-6882},
	Journal = {Current Opinion in Neurobiology},
	Keywords = {Acoustic Stimulation, Animals, Auditory Pathways, Computer Simulation, Humans, Models, Biological, Auditory cortex},
	Language = {eng},
	Month = oct,
	Number = {5},
	Pages = {761--767},
	Pmcid = {PMC3223290},
	Pmid = {21704508},
	Title = {Hierarchical representations in the auditory cortex},
	Volume = {21},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.conb.2011.05.027}}

@book{dayan_theoretical_2005,
	Address = {Cambridge, Mass.},
	Author = {Dayan, Peter},
	Edition = {New Ed},
	Isbn = {978-0-262-54185-5},
	Language = {Anglais},
	Month = sep,
	Publisher = {MIT Press},
	Title = {Theoretical {Neuroscience} - {Computational} and {Mathematical} {Modeling} of {Neural} {Systems}},
	Year = {2005}}

@article{toga_mapping_2006,
	Abstract = {Human brain maturation is a complex, lifelong process that can now be examined in detail using neuroimaging techniques. Ongoing projects scan subjects longitudinally with structural magnetic resonance imaging (MRI), enabling the time-course and anatomical sequence of development to be reconstructed. Here, we review recent progress on imaging studies of development. We focus on cortical and subcortical changes observed in healthy children, and contrast them with abnormal developmental changes in early-onset schizophrenia, fetal alcohol syndrome, attention-deficit--hyperactivity disorder (ADHD) and Williams syndrome. We relate these structural changes to the cellular processes that underlie them, and to cognitive and behavioral changes occurring throughout childhood and adolescence.},
	Author = {Toga, Arthur W. and Thompson, Paul M. and Sowell, Elizabeth R.},
	Doi = {10.1016/j.tins.2006.01.007},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/M84B7UKC/Toga et al. - 2006 - Mapping brain maturation.pdf:application/pdf},
	Issn = {0166-2236},
	Journal = {Trends in neurosciences},
	Month = mar,
	Number = {3},
	Pages = {148--159},
	Pmcid = {PMC3113697},
	Pmid = {16472876},
	Title = {Mapping brain maturation},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3113697/},
	Urldate = {2017-02-09},
	Volume = {29},
	Year = {2006},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3113697/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2006.01.007}}

@article{binder_human_2000,
	Abstract = {Functional organization of the lateral temporal cortex in humans is not well understood. We recorded blood oxygenation signals from the temporal lobes of normal volunteers using functional magnetic resonance imaging during stimulation with unstructured noise, frequency-modulated (FM) tones, reversed speech, pseudowords and words. For all conditions, subjects performed a material- nonspecific detection response when a train of stimuli began or ceased. Dorsal areas surrounding Heschl's gyrus bilaterally, particularly the planum temporale and dorsolateral superior temporal gyrus, were more strongly activated by FM tones than by noise, suggesting a role in processing simple temporally encoded auditory information. Distinct from these dorsolateral areas, regions centered in the superior temporal sulcus bilaterally were more activated by speech stimuli than by FM tones. Identical results were obtained in this region using words, pseudowords and reversed speech, suggesting that the speech--tones activation difference is due to acoustic rather than linguistic factors. In contrast, previous comparisons between word and nonword speech sounds showed left-lateralized activation differences in more ventral temporal and temporoparietal regions that are likely involved in processing lexical--semantic or syntactic information associated with words. The results indicate functional subdivision of the human lateral temporal cortex and provide a preliminary framework for understanding the cortical processing of speech sounds.},
	Author = {Binder, J. R. and Frost, J. A. and Hammeke, T. A. and Bellgowan, P. S. F. and Springer, J. A. and Kaufman, J. N. and Possing, E. T.},
	Doi = {10.1093/cercor/10.5.512},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KNRFNDHU/Binder et al. - 2000 - Human Temporal Lobe Activation by Speech and Nonsp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H5QAGS44/512.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Language = {en},
	Month = jan,
	Number = {5},
	Pages = {512--528},
	Pmid = {10847601},
	Title = {Human {Temporal} {Lobe} {Activation} by {Speech} and {Nonspeech} {Sounds}},
	Url = {http://cercor.oxfordjournals.org/content/10/5/512},
	Urldate = {2013-12-15},
	Volume = {10},
	Year = {2000},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org/content/10/5/512},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/10.5.512}}

@article{kvale_short-term_2004,
	Abstract = {Short-term adaptation and recovery from adaptation have a strong impact on the processing of dynamic stimuli. Adaptive effects on neuronal activity have been studied most commonly for changes in first-order statistics of stimuli such as stepwise increments or decrements in stimulus amplitude. However, changes in higher moment statistics, such as the variance of the amplitude distribution in visual stimuli, also can invoke pronounced adaptation behavior. We demonstrate here that neurons in the inferior colliculus (ICC) of the cat show adaptation to dynamic auditory stimuli that differ in the variance of their modulation depth distribution. In addition, it is shown that neurons show adaptation to other higher moment statistics (e.g., kurtosis) of the modulation envelope. The time course of adaptation is specific for the altered stimulus property and the direction of parameter change. The use of dynamic stimuli allows an estimate of the effects of the adaptation on the temporal response properties of the neurons. We demonstrate that temporal receptive fields of neurons undergo change during the course of adaptation. We show that adaptation to variance in the ICC has many similarities to that in the retina and suggest that adaptation to variance is a general property of sensory systems that allows them to effectively deal with a nonstationary environment.},
	Author = {Kvale, Mark N. and Schreiner, Christoph E.},
	Doi = {10.1152/jn.00484.2003},
	File = {Snapshot:/Users/Cecile/Zotero/storage/A7HSMT4T/604.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Keywords = {Acoustic Stimulation, Adaptation, Biological, Animals, Cats, Evoked Potentials, Auditory, Brain Stem, Inferior Colliculi, Time Factors},
	Language = {eng},
	Month = feb,
	Number = {2},
	Pages = {604--612},
	Pmid = {14762146},
	Title = {Short-term adaptation of auditory receptive fields to dynamic stimuli},
	Volume = {91},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1152/jn.00484.2003}}

@article{gervain_near-infrared_2011,
	Author = {Gervain, Judit and Mehler, Jacques and Werker, Janet F. and Nelson, Charles A. and Csibra, Gergely and Lloyd-Fox, Sarah and Shukla, Mohinish and Aslin, Richard N.},
	Doi = {10.1016/j.dcn.2010.07.004},
	File = {1-s2.0-S1878929310000058-main.pdf:/Users/Cecile/Zotero/storage/MEFCFPZA/1-s2.0-S1878929310000058-main.pdf:application/pdf;Near-infrared spectroscopy\: A report from the McDonnell infant methodology consortium:/Users/Cecile/Zotero/storage/PVDMCMGU/S1878929310000058.html:text/html},
	Issn = {18789293},
	Journal = {Developmental Cognitive Neuroscience},
	Month = jan,
	Number = {1},
	Pages = {22--46},
	Shorttitle = {Near-infrared spectroscopy},
	Title = {Near-infrared spectroscopy: {A} report from the {McDonnell} infant methodology consortium},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1878929310000058},
	Urldate = {2013-06-20},
	Volume = {1},
	Year = {2011},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/S1878929310000058},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2010.07.004}}

@article{tsuzuki_spatial_2014,
	Abstract = {Functional near-infrared spectroscopy (fNIRS) has now become widely accepted as a common functional imaging modality. In order for fNIRS to achieve genuine neuroimaging citizenship, it would ideally be equipped with functional and structural image analyses. However, fNIRS measures cortical activities from the head surface without anatomical information of the object being measured. In this review article, we will present a methodological overview of spatial registration of fNIRS data to overcome this technical drawback of fNIRS. We first introduce and explore the use of standard stereotaxic space and anatomical labeling. Second, we explain different ways of describing scalp landmarks using 10-20 based systems. Third, we describe the simplest case of fNIRS data co-registration to a subject's own MRI. Fourth, we extend the concept to fNIRS data registration of group data. Fifth, we describe probabilistic registration methods, which use a reference-MRI database instead of a subject's own MRIs, and thus enable MRI-free registration for standalone fNIRS data. Sixth, we further extend the concept of probabilistic registration to three-dimensional image reconstruction in diffuse optical tomography. Seventh, we describe a 3D-digitizer-free method for the virtual registration of fNIRS data. Eighth, we provide practical guidance on how these techniques are implemented in software. Finally, we provide information on current resources and limitations for spatial registration of child and infant data. Through these technical descriptions, we stress the importance of presenting fNIRS data on a common platform to facilitate both intra- and inter-modal data sharing among the neuroimaging community.},
	Author = {Tsuzuki, Daisuke and Dan, Ippeita},
	Doi = {10.1016/j.neuroimage.2013.07.025},
	Issn = {1095-9572},
	Journal = {NeuroImage},
	Keywords = {Adult, Child, Child, Preschool, Functional Neuroimaging, Algorithms, Humans, Image Processing, Computer-Assisted, Imaging, Three-Dimensional, Infant, Infant, Newborn, Scalp, Software, Spectroscopy, Near-Infrared, Stereotaxic Techniques, Magnetic resonance imaging},
	Language = {eng},
	Month = jan,
	Pages = {92--103},
	Pmid = {23891905},
	Shorttitle = {Spatial registration for functional near-infrared spectroscopy},
	Title = {Spatial registration for functional near-infrared spectroscopy: from channel position on the scalp to cortical location in individual and group analyses},
	Volume = {85 Pt 1},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2013.07.025}}

@article{attneave_informational_1954,
	Author = {Attneave, Fred},
	Doi = {10.1037/h0054663},
	File = {Web of Knowledge [v.5.11] - Web of Science Full Record:/Users/Cecile/Zotero/storage/C9ZXMBX9/full_record.html:text/html},
	Issn = {0033-295X},
	Journal = {Psychological Review},
	Number = {3},
	Pages = {183--193},
	Title = {Some informational aspects of visual perception.},
	Url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=1&SID=P2ojBCV1Rdt1XniwInN&page=1&doc=1},
	Urldate = {2013-10-23},
	Volume = {61},
	Year = {1954},
	Bdsk-Url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=1&SID=P2ojBCV1Rdt1XniwInN&page=1&doc=1},
	Bdsk-Url-2 = {https://doi.org/10.1037/h0054663}}

@article{urakawa_selective_2015,
	Abstract = {To investigate the role of the prefrontal cortex (PFC) in processing multimodal communicative ostensive signals in infants, we measured cerebral hemodynamic responses by using near-infrared spectroscopy (NIRS) during the social interactive play ``peek-a-boo'', in which both visual (direct gaze) and auditory (infant-directed speech) stimuli were presented. The infants (mean age, around 7 months) sat on their mother's lap, equipped with an NIRS head cap, and looked at a partner's face during ``peek-a-boo''. An eye-tracking system simultaneously monitored the infants' visual fixation patterns. The results indicate that, when the partner presented a direct gaze, rather than an averted gaze, toward an infant during social play, the infant fixated on the partner's eye region for a longer duration. Furthermore, hemodynamic activity increased more prominently dorsomedial prefrontal cortex (mPFC) in response to social play with a partner's direct gaze compared to an averted gaze. In contrast, hemodynamic activity increased in the right dorsolateral prefrontal cortex (R-lPFC) regardless of a partner's eye gaze direction. These results indicate that a partner's direct gaze shifts an infant's attention to the partner's eyes for interactive communication, and specifically activates the mPFC. The differences in hemodynamic responses between the mPFC and R-lPFC suggest functional differentiation within the PFC, and a specific role of the mPFC in the perception of face-to-face communication, especially in mutual gaze, which is essential for social interaction.},
	Author = {Urakawa, Susumu and Takamoto, Kouichi and Ishikawa, Akihiro and Ono, Taketoshi and Nishijo, Hisao},
	Doi = {10.1007/s10548-014-0414-2},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/32DDQX7E/Urakawa et al. - 2015 - Selective Medial Prefrontal Cortex Responses Durin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DE5X8894/s10548-014-0414-2.html:text/html},
	Issn = {0896-0267, 1573-6792},
	Journal = {Brain Topography},
	Language = {en},
	Month = sep,
	Number = {5},
	Pages = {691--701},
	Shorttitle = {Selective {Medial} {Prefrontal} {Cortex} {Responses} {During} {Live} {Mutual} {Gaze} {Interactions} in {Human} {Infants}},
	Title = {Selective {Medial} {Prefrontal} {Cortex} {Responses} {During} {Live} {Mutual} {Gaze} {Interactions} in {Human} {Infants}: {An} {fNIRS} {Study}},
	Url = {https://link.springer.com/article/10.1007/s10548-014-0414-2},
	Urldate = {2017-12-07},
	Volume = {28},
	Year = {2015},
	Bdsk-Url-1 = {https://link.springer.com/article/10.1007/s10548-014-0414-2},
	Bdsk-Url-2 = {https://doi.org/10.1007/s10548-014-0414-2}}

@article{pickover_fractal_1986,
	Abstract = {Mandelbrot's fractal geometry has provided a new qualitative and quantitative approach for understanding the complex shapes of nature. In this paper, the fractal structure of speech waveforms is studied at time scales where important phonetic and prosodic information reside. We have found, using methods commonly applied to complex shapes such as coastlines, that speech exhibits fractal characteristics. We have made measurements of the fractal dimension (D) for sentences and have found that D â¼ 1.66 with little change between speakers and sentences.},
	Author = {Pickover, Clifford A. and Khorasani, Al},
	Doi = {10.1016/0097-8493(86)90068-3},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UAI98QTW/0097849386900683.html:text/html},
	Issn = {0097-8493},
	Journal = {Computers \& Graphics},
	Number = {1},
	Pages = {51--61},
	Title = {Fractal characterization of speech waveform graphs},
	Url = {http://www.sciencedirect.com/science/article/pii/0097849386900683},
	Urldate = {2013-11-12},
	Volume = {10},
	Year = {1986},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0097849386900683},
	Bdsk-Url-2 = {https://doi.org/10.1016/0097-8493(86)90068-3}}

@article{gratton_toward_2000,
	Abstract = {The event-related optical signal (EROS) has been recently proposed as a method for studying noninvasively the time course of activity in localized cortical areas (G. Gratton and M. Fabiani, 1998, Psychonomic Bull. Rev. 5: 535--563). Previous data have shown that EROS has very good temporal resolution and can provide detailed surface activity maps. In the present study we investigated whether the depth of the active area can also be estimated. Nine subjects were run in a study in which the eccentricity of the visual stimuli was varied, and EROS was recorded from medial occipital areas using multiple source--detector distances. Seven of the same subjects were also run through a functional magnetic resonance imaging (fMRI) study using the same protocol. The fMRI data indicated that the depth from the head surface to the cortical area activated increased systematically with the eccentricity of the visual stimuli. The EROS recording indicated a response with a latency of 60--80 ms from stimulation. This response varied systematically with eccentricity, so that the greater the eccentricity of the stimuli, the longer the source--detector distance (and thus the depth) at which the EROS effect was observed. The depth of the brain area generating the EROS effect was estimated using a simple algorithm derived from phantom studies on homogeneous media. The average depth estimates for each eccentricity condition obtained with EROS corresponded with those obtained with fMRI, with discrepancies of less than 1 mm. These data demonstrate that multiple source--detector distances can be used to estimate the depth of the cortical areas responsible for the EROS effects.},
	Author = {Gratton, Gabriele and Sarno, Anita and Maclin, Ed and Corballis, Paul M. and Fabiani, Monica},
	Doi = {10.1006/nimg.2000.0565},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GHNUQWZF/S1053811900905652.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {event-related optical signal (EROS), functional magnetic resonance imaging (fMRI), tridimensional reconstruction, functional brain imaging},
	Month = may,
	Number = {5},
	Pages = {491--504},
	Shorttitle = {Toward {Noninvasive} 3-{D} {Imaging} of the {Time} {Course} of {Cortical} {Activity}},
	Title = {Toward {Noninvasive} 3-{D} {Imaging} of the {Time} {Course} of {Cortical} {Activity}: {Investigation} of the {Depth} of the {Event}-{Related} {Optical} {Signal}},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811900905652},
	Urldate = {2016-11-26},
	Volume = {11},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811900905652},
	Bdsk-Url-2 = {https://doi.org/10.1006/nimg.2000.0565}}

@article{escabi_naturalistic_2003,
	Abstract = {Statistical analysis of natural sounds and speech reveals logarithmically distributed spectrotemporal modulations that can cover several orders of magnitude. By contrast, most artificial stimuli used to probe auditory function, including pure tones and white noise, have linearly distributed amplitude fluctuations with a limited average dynamic range. Here we explore whether the operating range of the auditory system is physically matched to the statistical structure of natural sounds. We recorded single-unit and multi-unit neuronal activity from the central nucleus of the cat inferior colliculus (ICC) in response to dynamic spectrotemporal sound sequences to determine whether ICC neurons respond preferentially to linear or logarithmic spectrotemporal amplitudes. We varied the intensity, dynamic range, and contrast statistics of these sounds to mimic those of natural and artificial stimuli. ICC neurons exhibited monotonic and nonmonotonic contrast dependencies with increasing dynamic range that were independent of the stimulus intensity. Midbrain neurons had higher firing rates and higher receptive field energies and showed a net improvement in spectrotemporal encoding ability for logarithmic stimuli, with an increase in the mutual information rate of approximately 50\% over linear amplitude sounds. This efficient use of logarithmic spectrotemporal modulations by auditory midbrain neurons reflects a neural adaptation to structural regularities in natural sounds and likely underlies human perceptual abilities.},
	Author = {Escab{\'\i}, Monty A and Miller, Lee M and Read, Heather L and Schreiner, Christoph E},
	Issn = {1529-2401},
	Journal = {The Journal of neuroscience: the official journal of the Society for Neuroscience},
	Keywords = {Animals, Auditory Perception, Cats, Data Interpretation, Statistical, Inferior Colliculi, Kinetics, Loudness Perception, Neurons, Action potentials},
	Language = {eng},
	Month = dec,
	Number = {37},
	Pages = {11489--11504},
	Pmid = {14684853},
	Title = {Naturalistic auditory contrast improves spectrotemporal coding in the cat inferior colliculus},
	Volume = {23},
	Year = {2003}}

@article{sato_development_2010,
	Abstract = {Infants' speech perception abilities change through the first year of life, from broad sensitivity to a wide range of speech contrasts to becoming more finely attuned to their native language. What remains unclear, however, is how this perceptual change relates to brain responses to native language contrasts in terms of the functional specialization of the left and right hemispheres. Here, to elucidate the developmental changes in functional lateralization accompanying this perceptual change, we conducted two experiments on Japanese infants using Japanese lexical pitch-accent, which changes word meanings with the pitch pattern within words. In the first behavioral experiment, using visual habituation, we confirmed that infants at both 4 and 10 months have sensitivities to the lexical pitch- accent pattern change embedded in disyllabic words. In the second experiment, near-infrared spectroscopy was used to measure cortical hemodynamic responses in the left and right hemispheres to the same lexical pitch-accent pattern changes and their pure tone counterparts. We found that brain responses to the pitch change within words differed between 4- and 10-month-old infants in terms of functional lateralization: Left hemisphere dominance for the perception of the pitch change embedded in words was seen only in the 10-month-olds. These results suggest that the perceptual change in Japanese lexical pitch-accent may be related to a shift in functional lateralization from bilateral to left hemisphere dominance.},
	Author = {Sato, Yutaka and Sogabe, Yuko and Mazuka, Reiko},
	File = {Satoetal2010.pdf:/Users/Cecile/Zotero/storage/IUTX9JB2/Satoetal2010.pdf:application/pdf},
	Issn = {0898929X},
	Journal = {Journal of Cognitive Neuroscience},
	Keywords = {COGNITIVE development, KNOWLEDGE acquisition (Expert systems), CEREBRAL dominance, NEWBORN infants -- Development, JAPAN, Lexical access},
	Month = nov,
	Number = {11},
	Pages = {2503--2513},
	Title = {Development of {Hemispheric} {Specialization} for {Lexical} {Pitch}-{Accent} in {Japanese} {Infants}},
	Url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=52409177&lang=fr&site=eds-live&scope=site},
	Urldate = {2016-09-28},
	Volume = {22},
	Year = {2010},
	Bdsk-Url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=52409177&lang=fr&site=eds-live&scope=site}}

@article{giraud_cortical_2012,
	Abstract = {Neuronal oscillations are ubiquitous in the brain and may contribute to cognition in several ways: for example, by segregating information and organizing spike timing. Recent data show that delta, theta and gamma oscillations are specifically engaged by the multi-timescale, quasi-rhythmic properties of speech and can track its dynamics. We argue that they are foundational in speech and language processing, 'packaging' incoming information into units of the appropriate temporal granularity. Such stimulus-brain alignment arguably results from auditory and motor tuning throughout the evolution of speech and language and constitutes a natural model system allowing auditory research to make a unique contribution to the issue of how neural oscillatory activity affects human cognition.},
	Author = {Giraud, Anne-Lise and Poeppel, David},
	Doi = {10.1038/nn.3063},
	File = {GiraudPoeppel12.pdf:/Users/Cecile/Zotero/storage/QPVWAZ46/GiraudPoeppel12.pdf:application/pdf;GiraudPoeppel2012.pdf:/Users/Cecile/Zotero/storage/GQ8V52UZ/GiraudPoeppel2012.pdf:application/pdf},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Keywords = {Acoustic Stimulation, Brain Mapping, Brain Waves, Computational Biology, Cortical Synchronization, Humans, Nerve Net, Speech, speech perception, Auditory cortex, Speech Perception, Action potentials},
	Language = {eng},
	Month = apr,
	Number = {4},
	Pages = {511--517},
	Pmid = {22426255},
	Shorttitle = {Cortical oscillations and speech processing},
	Title = {Cortical oscillations and speech processing: emerging computational principles and operations},
	Volume = {15},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.3063}}

@article{humphries_response_2005,
	Abstract = {Previous research has implicated a portion of the anterior temporal cortex in sentence-level processing. This region activates more to sentences than to word-lists, sentences in an unfamiliar language, and environmental sound sequences. The current study sought to identify the relative contributions of syntactic and prosodic processing to anterior temporal activation. We presented auditory stimuli where the presence of prosodic and syntactic structure was independently manipulated during functional magnetic resonance imaging (fMRI). Three ``structural'' conditions included normal sentences, sentences with scrambled word order, and lists of content words. These three classes of stimuli were presented either with sentence prosody or with flat supra-lexical (list-like) prosody. Sentence stimuli activated a portion of the left anterior temporal cortex in the superior temporal sulcus (STS) and extending into the middle temporal gyrus, independent of prosody, and to a greater extent than any of the other conditions. An interaction between the structural conditions and prosodic conditions was seen in a more dorsal region of the anterior temporal lobe bilaterally along the superior temporal gyrus (STG). A post-hoc analysis revealed that this region responded either to syntactically structured stimuli or to nonstructured stimuli with sentence-like prosody. The results suggest a parcellation of anterior temporal cortex into 1) an STG region that is sensitive both to the presence of syntactic information and is modulated by prosodic manipulations (in nonsyntactic stimuli); and 2) a more inferior left STS/MTG region that is more selective for syntactic structure. Hum Brain Mapp, 2005. {\copyright} 2005 Wiley-Liss, Inc.},
	Author = {Humphries, Colin and Love, Tracy and Swinney, David and Hickok, Gregory},
	Copyright = {Copyright {\copyright} 2005 Wiley-Liss, Inc.},
	Doi = {10.1002/hbm.20148},
	File = {Snapshot:/Users/Cecile/Zotero/storage/AGPRWVDD/abstract\;jsessionid=811EFF09841FAFD65AC833F89DC6BFEA.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {anterior temporal lobe, fMRI, prosodic processing, sentence processing, syntactic processing},
	Language = {en},
	Month = oct,
	Number = {2},
	Pages = {128--138},
	Title = {Response of anterior temporal cortex to syntactic and prosodic manipulations during sentence processing},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20148/abstract},
	Urldate = {2014-06-02},
	Volume = {26},
	Year = {2005},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20148/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.20148}}

@article{kobayashi_processing_2014,
	Abstract = {Using near-infrared spectroscopy (NIRS), our previous neural adaptation studies found that infants' bilateral temporal regions process facial identity (FiHN 5:153, 2011). In addition, we revealed that size-invariant processing of facial identity develops by 5 months of age (NR 23:984-988, 2012), while view-invariant processing develops around 7 months of age (FiHN 5:153, 2011). The aim in the current study was to examine whether infants' brains process facial identity across the non-rigid transformation of facial features by using the neural adaptation paradigm. We used NIRS to compare hemodynamic changes in the bilateral temporal areas of 5- to 6-month-olds and 7- to 8-month-olds during presentations of an identical face and of different faces.},
	Author = {Kobayashi, Megumi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	Doi = {10.1186/1471-2202-15-81},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DAJEXRSC/art%3A10.1186%2F1471-2202-15-81.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JFZK942J/1471-2202-15-81.html:text/html},
	Issn = {1471-2202},
	Journal = {BMC Neuroscience},
	Pages = {81},
	Shorttitle = {The processing of faces across non-rigid facial transformation develops at 7 month of age},
	Title = {The processing of faces across non-rigid facial transformation develops at 7 month of age: a {fNIRS}-adaptation study},
	Url = {http://dx.doi.org/10.1186/1471-2202-15-81},
	Urldate = {2016-09-28},
	Volume = {15},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1186/1471-2202-15-81}}

@article{carruthers_encoding_2013,
	Abstract = {One of the central tasks of the mammalian auditory system is to represent information about acoustic communicative signals, such as vocalizations. However, the neuronal computations underlying vocalization encoding in the central auditory system are poorly understood. To learn how the rat auditory cortex encodes information about conspecific vocalizations, we presented a library of natural and temporally transformed ultrasonic vocalizations (USVs) to awake rats while recording neural activity in the primary auditory cortex (A1) with chronically implanted multielectrode probes. Many neurons reliably and selectively responded to USVs. The response strength to USVs correlated strongly with the response strength to frequency-modulated (FM) sweeps and the FM rate tuning index, suggesting that related mechanisms generate responses to USVs as to FM sweeps. The response strength further correlated with the neuron's best frequency, with the strongest responses produced by neurons whose best frequency was in the ultrasonic frequency range. For responses of each neuron to each stimulus group, we fitted a novel predictive model: a reduced generalized linear-nonlinear model (GLNM) that takes the frequency modulation and single-tone amplitude as the only two input parameters. The GLNM accurately predicted neuronal responses to previously unheard USVs, and its prediction accuracy was higher than that of an analogous spectrogram-based linear-nonlinear model. The response strength of neurons and the model prediction accuracy were higher for original, rather than temporally transformed, vocalizations. These results indicate that A1 processes original USVs differentially than transformed USVs, indicating preference for temporal statistics of the original vocalizations.},
	Author = {Carruthers, Isaac M. and Natan, Ryan G. and Geffen, Maria N.},
	Copyright = {Copyright {\copyright} 2013 the American Physiological Society. Licensed under Creative Commons Attribution CC-BY 3.0: the American Physiological Society.},
	Doi = {10.1152/jn.00483.2012},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4WR3MD7S/Carruthers et al. - 2013 - Encoding of ultrasonic vocalizations in the audito.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4JQA2274/1912.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = apr,
	Number = {7},
	Pages = {1912--1927},
	Pmid = {23324323},
	Title = {Encoding of ultrasonic vocalizations in the auditory cortex},
	Url = {http://jn.physiology.org.gate1.inist.fr/content/109/7/1912},
	Urldate = {2016-01-15},
	Volume = {109},
	Year = {2013},
	Bdsk-Url-1 = {http://jn.physiology.org.gate1.inist.fr/content/109/7/1912},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00483.2012}}

@article{ichikawa_infant_2010,
	Abstract = {Adult observers can quickly identify specific actions performed by an invisible actor from the points of lights attached to the actor's head and major joints. Infants are also sensitive to biological motion and prefer to see it depicted by a dynamic point-light display [1]. In detecting biological motion such as whole body and facial movements, neuroimaging studies have demonstrated the involvement of the occipitotemporal cortex, including the superior temporal sulcus (STS) [15]. In the present study, we used the point-light display technique and near-infrared spectroscopy (NIRS) to examine infant brain activity while viewing facial biological motion depicted in a point-light display. Dynamic facial point-light displays (PLD) were made from video recordings of three actors making a facial expression of surprise in a dark room. As in Bassili's study [2], about 80 luminous markers were scattered over the surface of the actor's faces. In the experiment, we measured infant's hemodynamic responses to these displays using NIRS. We hypothesized that infants would show different neural activity for upright and inverted PLD. The responses were compared to the baseline activation during the presentation of individual still images, which were frames extracted from the dynamic PLD. We found that the concentration of oxy-Hb increased in the right temporal area during the presentation of the upright PLD compared to that of the baseline period. This is the first study to demonstrate that infant's brain activity in face processing is induced only by the motion cue of facial movement depicted by dynamic PLD.},
	Author = {Ichikawa, Hiroko and Kanazawa, So and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	Doi = {10.1016/j.neulet.2010.06.086},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F59J28HN/Ichikawa et al. - 2010 - Infant brain activity while viewing facial movemen.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/469FWJE7/S0304394010008608.html:text/html},
	Issn = {0304-3940},
	Journal = {Neuroscience Letters},
	Keywords = {Facial movement, Infant brain activity, Point-light display, The right hemispheric dominance, NIRS, Near-infrared spectroscopy},
	Month = sep,
	Number = {2},
	Pages = {90--94},
	Title = {Infant brain activity while viewing facial movement of point-light displays as measured by near-infrared spectroscopy ({NIRS})},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304394010008608},
	Urldate = {2017-12-07},
	Volume = {482},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394010008608},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neulet.2010.06.086}}

@article{vouloumanos_why_2007,
	Author = {Vouloumanos, Athena and Werker, Janet F.},
	Copyright = {{\copyright} 2007 The Authors. Journal compilation {\copyright} 2007 Blackwell Publishing Ltd},
	Doi = {10.1111/j.1467-7687.2007.00551.x},
	File = {Snapshot:/Users/Cecile/Zotero/storage/X36EAV6Q/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Number = {2},
	Pages = {169--171},
	Title = {Why voice melody alone cannot explain neonates' preference for speech},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00551.x/abstract},
	Urldate = {2013-06-17},
	Volume = {10},
	Year = {2007},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00551.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00551.x}}

@article{malach_targeting_2012,
	Author = {Malach, Rafael},
	Doi = {10.1016/j.neuroimage.2012.01.002},
	Issn = {10538119},
	Journal = {NeuroImage},
	Language = {en},
	Month = aug,
	Number = {2},
	Pages = {1163--1169},
	Title = {Targeting the functional properties of cortical neurons using {fMR}-adaptation},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811912000055},
	Urldate = {2016-09-28},
	Volume = {62},
	Year = {2012},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1053811912000055},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.002}}

@article{poremba_processing_2013,
	Abstract = {Abundant evidence from both field and lab studies has established that conspecific vocalizations (CVs) are of critical ecological significance for a wide variety of species, including humans, non-human primates, rodents, and other mammals and birds. Correspondingly, a number of experiments have demonstrated behavioral processing advantages for CVs, such as in discrimination and memory tasks. Further, a wide range of experiments have described brain regions in many species that appear to be specialized for processing CVs. For example, several neural regions have been described in both mammals and birds wherein greater neural responses are elicited by CVs than by comparison stimuli such as heterospecific vocalizations, nonvocal complex sounds, and artificial stimuli. These observations raise the question of whether these regions reflect domain-specific neural mechanisms dedicated to processing CVs, or alternatively, if these regions reflect domain-general neural mechanisms for representing complex sounds of learned significance. Inasmuch as CVs can be viewed as complex combinations of basic spectrotemporal features, the plausibility of the latter position is supported by a large body of literature describing modulated cortical and subcortical representation of a variety of acoustic features that have been experimentally associated with stimuli of natural behavioral significance (such as food rewards). Herein, we review a relatively small body of existing literature describing the roles of experience, learning, and memory in the emergence of species-typical neural representations of CVs and auditory system plasticity. In both songbirds and mammals, manipulations of auditory experience as well as specific learning paradigms are shown to modulate neural responses evoked by CVs, either in terms of overall firing rate or temporal firing patterns. In some cases, CV-sensitive neural regions gradually acquire representation of non-CV stimuli with which subjects have training and experience. These results parallel literature in humans describing modulation of responses in face-sensitive neural regions through learning and experience. Thus, although many questions remain, the available evidence is consistent with the notion that CVs may acquire distinct neural representation through domain-general mechanisms for representing complex auditory objects that are of learned importance to the animal.

This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	Author = {Poremba, Amy and Bigelow, James and Rossi, Breein},
	Doi = {10.1016/j.heares.2013.06.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ED4CGVB9/Poremba et al. - 2013 - Processing of communication sounds Contributions .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9RXRMVM3/S0378595513001482.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Keywords = {oiseau},
	Month = nov,
	Pages = {31--44},
	Series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	Shorttitle = {Processing of communication sounds},
	Title = {Processing of communication sounds: {Contributions} of learning, memory, and experience},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513001482},
	Urldate = {2014-11-03},
	Volume = {305},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001482},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.06.005}}

@article{nourski_auditory_2017,
	Abstract = {Objective

Direct electrophysiological recordings in epilepsy patients offer an opportunity to study human auditory cortical processing with unprecedented spatiotemporal resolution. This review highlights recent intracranial studies of human auditory cortex and focuses on its basic response properties as well as modulation of cortical activity during the performance of active behavioral tasks.
Data Sources: Literature review.
Review Methods: A review of the literature was conducted to summarize the functional organization of human auditory and auditory-related cortex as revealed using intracranial recordings.


Results

The tonotopically organized core auditory cortex within the posteromedial portion of Heschl's gyrus represents spectrotemporal features of sounds with high temporal precision and short response latencies. At this level of processing, high gamma (70--150 Hz) activity is minimally modulated by task demands. Non-core cortex on the lateral surface of the superior temporal gyrus also maintains representation of stimulus acoustic features and, for speech, subserves transformation of acoustic inputs into phonemic representations. High gamma responses in this region are modulated by task requirements. Prefrontal cortex exhibits complex response patterns, related to stimulus intelligibility and task relevance. At this level of auditory processing, activity is strongly modulated by task requirements and reflects behavioral performance.


Conclusions

Direct recordings from the human brain reveal hierarchical organization of sound processing within auditory and auditory-related cortex.


Level of Evidence

Level V},
	Author = {Nourski, Kirill V.},
	Doi = {10.1002/lio2.73},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/B8X6MH5G/Nourski - 2017 - Auditory processing in the human cortex An intrac.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q2UBD7JZ/abstract.html:text/html},
	Issn = {2378-8038},
	Journal = {Laryngoscope Investigative Otolaryngology},
	Keywords = {Superior temporal gyrus, Electrocorticography, Heschl's gyrus, high gamma},
	Language = {en},
	Month = apr,
	Pages = {n/a--n/a},
	Shorttitle = {Auditory processing in the human cortex},
	Title = {Auditory processing in the human cortex: {An} intracranial electrophysiology perspective},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/lio2.73/abstract},
	Urldate = {2017-05-21},
	Year = {2017},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/lio2.73/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/lio2.73}}

@article{mcdermott_summary_2013,
	Abstract = {Sensory signals are transduced at high resolution, but their structure must be stored in a more compact format. Here we provide evidence that the auditory system summarizes the temporal details of sounds using time-averaged statistics. We measured discrimination of 'sound textures' that were characterized by particular statistical properties, as normally result from the superposition of many acoustic features in auditory scenes. When listeners discriminated examples of different textures, performance improved with excerpt duration. In contrast, when listeners discriminated different examples of the same texture, performance declined with duration, a paradoxical result given that the information available for discrimination grows with duration. These results indicate that once these sounds are of moderate length, the brain's representation is limited to time-averaged statistics, which, for different examples of the same texture, converge to the same values with increasing duration. Such statistical representations produce good categorical discrimination, but limit the ability to discern temporal detail.},
	Author = {McDermott, Josh H and Schemitsch, Michael and Simoncelli, Eero P},
	Doi = {10.1038/nn.3347},
	File = {McDermott13SummaryStatisticsInAuditoryPerception.pdf:/Users/Cecile/Zotero/storage/SSQFQ3FS/McDermott13SummaryStatisticsInAuditoryPerception.pdf:application/pdf},
	Issn = {1546-1726},
	Journal = {Nature neuroscience},
	Keywords = {Acoustic Stimulation, Adolescent, Adult, Auditory Perception, Discrimination Learning, Female, Humans, Male, Psychomotor Performance, Young Adult},
	Language = {eng},
	Month = apr,
	Number = {4},
	Pages = {493--498},
	Pmid = {23434915},
	Title = {Summary statistics in auditory perception},
	Volume = {16},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.3347}}

@article{gervain_category-specific_2014,
	Abstract = {Increasing evidence suggests that the natural world has a special status for our sensory and cognitive functioning. The mammalian sensory system is hypothesized to have evolved to encode natural signals in an efficient manner. Exposure to natural stimuli, but not to artificial ones, improves learning and cognitive function. Scale-invariance, the property of exhibiting the same statistical structure at different spatial or temporal scales, is common to naturally occurring sounds. We recently developed a 3-parameter model to capture the essential characteristics of water sounds, and from this generated both scale-invariant and variable-scale sounds. In a previous study, we found that adults perceived a wide range of the artificial scale-invariant, but not the variable-scale, sounds as instances of natural sounds. Here, we explored the ontogenetic origins of these effects by investigating how young infants perceive and categorize scale-invariant acoustic stimuli. Even though they have several months of experience with natural water sounds, infants aged 5 months did not show a preference, in the first experiment, for the instances of the scale-invariant sounds rated as typical water-like sounds by adults over non-prototypical, but still scale-invariant instances. Scale-invariance might thus be a more relevant factor for the perception of natural signals than simple familiarity. In a second experiment, we thus directly compared infants' perception of scale-invariant and variable-scale sounds. When habituated to scale-invariant sounds, infants looked significantly longer to a change in sound category from scale-invariant to variable-scale sounds, whereas infants habituated to variable-scale sounds showed no such difference. These results suggest that infants were able to form a perceptual category of the scale-invariant, but not variable-scale sounds. These findings advance the efficient coding hypothesis, and suggest that the advantage for perceiving and learning about the natural world is evident from the first months of life.},
	Author = {Gervain, Judit and Werker, Janet F. and Geffen, Maria N.},
	Doi = {10.1371/journal.pone.0096278},
	File = {PLoS Snapshot:/Users/Cecile/Zotero/storage/STFX44P8/infodoi10.1371journal.pone.html:text/html},
	Journal = {PLoS ONE},
	Month = may,
	Number = {5},
	Pages = {e96278},
	Title = {Category-{Specific} {Processing} of {Scale}-{Invariant} {Sounds} in {Infancy}},
	Url = {http://dx.doi.org/10.1371/journal.pone.0096278},
	Urldate = {2014-06-01},
	Volume = {9},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pone.0096278}}

@article{bank_regulation_2006,
	Abstract = {The human globin genes are among the most extensively characterized in the human genome, yet the details of the molecular events regulating normal human hemoglobin switching and the potential reactivation of fetal hemoglobin in adult hematopoietic cells remain elusive. Recent discoveries demonstrate physical interactions between the Î² locus control region and the downstream structural Î³- and Î²-globin genes, and with transcription factors and chromatin remodeling complexes. These interactions all play roles in globin gene expression and globin switching at the human Î²-globin locus. If the molecular events in hemoglobin switching were better understood and fetal hemoglobin could be more fully reactivated in adult cells, the insights obtained might lead to new approaches to the therapy of sickle cell disease and Î² thalassemia by identifying specific new targets for molecular therapies.},
	Author = {Bank, Arthur},
	Doi = {10.1182/blood-2005-05-2113},
	Issn = {0006-4971},
	Journal = {Blood},
	Month = jan,
	Number = {2},
	Pages = {435--443},
	Pmcid = {PMC1895603},
	Pmid = {16109777},
	Shorttitle = {Regulation of human fetal hemoglobin},
	Title = {Regulation of human fetal hemoglobin: new players, new complexities},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1895603/},
	Urldate = {2017-02-27},
	Volume = {107},
	Year = {2006},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1895603/},
	Bdsk-Url-2 = {https://doi.org/10.1182/blood-2005-05-2113}}

@article{mehler_precursor_1988,
	Abstract = {Four-day-old French and 2-month-old American infants distinguish utterances in their native languages from those of another language. In contrast, neither group gave evidence of distinguishing utterances from two foreign languages. A series of control experiments confirmed that the ability to distinguish utterances from two different languages appears to depend upon some familiarity with at least one of the two languages. Finally, two experiments with low-pass-filtered versions of the samples replicated the main findings of discrimination of the native language utterances. These latter results suggest that the basis for classifying utterances from the native language may be provided by prosodic cues.},
	Author = {Mehler, Jacques and Jusczyk, Peter and Lambertz, Ghislaine and Halsted, Nilofar and Bertoncini, Josiane and Amiel-Tison, Claudine},
	Doi = {10.1016/0010-0277(88)90035-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/3G4GNBQ9/Mehler et al. - 1988 - A precursor of language acquisition in young infan.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/M5N548DS/0010027788900352.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Month = jul,
	Number = {2},
	Pages = {143--178},
	Title = {A precursor of language acquisition in young infants},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027788900352},
	Urldate = {2016-01-26},
	Volume = {29},
	Year = {1988},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0010027788900352},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(88)90035-2}}

@article{liegeois-chauvel_temporal_2004,
	Abstract = {The goal of this study was to determine the temporal response properties of different auditory cortical areas in humans. This is achieved by recording the phase-locked neural activity to white noises modulated sinusoidally in amplitude (AM) at frequencies between 4 and 128 Hz, in the left and right cortices of 20 subjects. Phase-locked neural responses are recorded in four auditory cortical areas with intracerebral electrodes, and modulation transfer functions (MTFs) are computed from these responses. A number of MTFs are bandpass in shape, demonstrating a selective encoding of AM frequencies below 64 Hz in the auditory cortex. This result provides strong physiological support to the idea that the human auditory system decomposes the temporal envelope of sounds (such as speech) into its constituting AM components. Moreover, the results show a predominant response of cortical auditory areas to the lowest AM frequencies (4--16 Hz). This range matches the range of AM frequencies crucial for speech intelligibility, emphasizing therefore the role played by these initial stations of cortical processing in the analysis of speech. Finally, the results show differences in AM sensitivity across cortical areas and hemispheres, and provide a physiological foundation for claims of functional specialization of auditory areas based on previous population measures.},
	Author = {Li{\'e}geois-Chauvel, Catherine and Lorenzi, Christian and Tr{\'e}buchon, Agn{\`e}s and R{\'e}gis, Jean and Chauvel, Patrick},
	Doi = {10.1093/cercor/bhh033},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/GJ3UI9NA/Li{\'e}geois-Chauvel et al. - 2004 - Temporal Envelope Processing in the Human Left and.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EHE5NS3I/731.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Keywords = {amplitude modulation, auditory cortex, hearing, human, synchronization, temporal envelope},
	Language = {en},
	Month = jan,
	Number = {7},
	Pages = {731--740},
	Pmid = {15054052},
	Title = {Temporal {Envelope} {Processing} in the {Human} {Left} and {Right} {Auditory} {Cortices}},
	Url = {http://cercor.oxfordjournals.org/content/14/7/731},
	Urldate = {2015-02-10},
	Volume = {14},
	Year = {2004},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org/content/14/7/731},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhh033}}

@article{sebastian-galles_adaptation_2000,
	Abstract = {Perceptual adaptation to time-compressed speech was analyzed in two experiments. Previous research has suggested that this adaptation phenomenon is language specific and takes place at the phonological level. Moreover, it has been proposed that adaptation should only be observed for languages that are rhythmically similar. This assumption was explored by studying adaptation to different time-compressed languages in Spanish speakers. In Experiment 1, the performances of Spanish-speaking subjects who adapted to Spanish, Italian, French, English, and Japanese were compared. In Experiment 2, subjects from the same population were tested with Greek sentences compressed to two different rates. The results showed adaptation for Spanish, Italian, and Greek and no adaptation for English and Japanese, with French being an intermediate case. To account for the data, we propose that variables other than just the rhythmic properties of the languages, such as the vowel system and/or the lexical stress pattern, must be considered. The Greek data also support the view that phonological, rather than lexical, information is a determining factor in adaptation to compressed speech.},
	Author = {Sebasti{\'a}n-Gall{\'e}s, N{\'u}ria and Dupoux, Emmanuel and Costa, Albert and Mehler, Jacques},
	Doi = {10.3758/BF03206926},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/B3SS5G8V/Sebasti{\'a}n-Gall{\'e}s et al. - 2000 - Adaptation to time-compressed speech Phonological.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4QNFTNZQ/BF03206926.html:text/html},
	Issn = {0031-5117, 1532-5962},
	Journal = {Perception \& Psychophysics},
	Keywords = {Cognitive Psychology},
	Language = {en},
	Month = jan,
	Number = {4},
	Pages = {834--842},
	Shorttitle = {Adaptation to time-compressed speech},
	Title = {Adaptation to time-compressed speech: {Phonological} determinants},
	Url = {http://link.springer.com/article/10.3758/BF03206926},
	Urldate = {2015-07-15},
	Volume = {62},
	Year = {2000},
	Bdsk-Url-1 = {http://link.springer.com/article/10.3758/BF03206926},
	Bdsk-Url-2 = {https://doi.org/10.3758/BF03206926}}

@article{beasley_childrens_1976,
	Abstract = {Time-compressed versions of the Word Intelligibility by Picture Identification (WIPI) and H. A. Haskins's PB-K 50 speech discrimination measures were presented at 2 sensation levels to 60 children divided into 3 age-groups (3.5-4.5, 5.5-6.5, and 7.5-8.5 yrs) of 20 each. Results show that average intelligibility scores increased as a function of age and sensation level and decreased with increasing amounts of time compression. The PB-K 50 measure was more difficult than the WIPI for each age group under each condition of time compression and sensation level. Several interactions were also found. Results are discussed in terms of open- vs closed-message set response tasks and the implications for audiological diagnoses of children with central auditory processing problems. (22 ref) (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
	Author = {Beasley, Daniel S. and Maki, Jean E. and Orchik, Daniel J.},
	Issn = {0022-4677},
	Journal = {Journal of Speech \& Hearing Disorders},
	Keywords = {Age Differences, Auditory Discrimination, Diagnosis, Speech and Hearing Measures, time compression \& sensation level \& age, speech discrimination measure \& intelligibility scores, 3-8 yr olds with normal speech \& language, implications for audiological diagnosis of central auditory processing problems, speech perception, Speech Perception},
	Month = may,
	Number = {2},
	Pages = {216--225},
	Title = {Children's perception of time-compressed speech on two measures of speech discrimination},
	Volume = {41},
	Year = {1976}}

@article{vouloumanos_detection_2001,
	Author = {Vouloumanos, Athena and Kiehl, Kent A. and Werker, Janet F. and Liddle, Peter F.},
	Date-Modified = {2020-06-16 13:44:49 +0200},
	Doi = {10.1162/089892901753165890},
	File = {Web of Knowledge [v.5.10] - Web of Science Full Record:/Users/Cecile/Zotero/storage/NP5AIE2Q/full_record.html:text/html},
	Issn = {0898-929X, 1530-8898},
	Journal = {Journal of Cognitive Neuroscience},
	Month = oct,
	Number = {7},
	Pages = {994--1005},
	Shorttitle = {Detection of {Sounds} in the {Auditory} {Stream}},
	Title = {Detection of {Sounds} in the {Auditory} {Stream}: {Event}-{Related} {fMRI} {Evidence} for {Differential} {Activation} to {Speech} and {Nonspeech}},
	Url = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=9&SID=P2539gp3JpbfaaifH6k&page=1&doc=1},
	Urldate = {2013-07-17},
	Volume = {13},
	Year = {2001},
	Bdsk-Url-1 = {https://apps-webofknowledge-com.frodon.univ-paris5.fr/full_record.do?product=WOS&search_mode=GeneralSearch&qid=9&SID=P2539gp3JpbfaaifH6k&page=1&doc=1},
	Bdsk-Url-2 = {https://doi.org/10.1162/089892901753165890}}

@article{friederici_neurophysiological_2005,
	Abstract = {Recently, there have been several reports of the neurophysiological correlates of language acquisition. These indicate that the infant's brain is able to discriminate different phonemes within the first 2 months of life, that knowledge about stress patterns and phonotactic rules is established between 5--12 months, and that phonotactic knowledge begins to interact with lexical-semantic processes between 12--14 months. Electrophysiological markers for lexical-semantic processes indicate that semantic processing of words in picture contexts is present at 14 months and for words in sentential contexts around 30 months. At 32 months, children demonstrate an adult-like electrophysiological response pattern to syntactic violations. The similarities between the brain response patterns observed in children and adults support the view that language develops in a continuous manner.},
	Author = {Friederici, Angela D.},
	Doi = {10.1016/j.tics.2005.08.008},
	File = {Friederici05.pdf:/Users/Cecile/Zotero/storage/UCA2CA5E/Friederici05.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DMVTV545/S1364-6613(05)00241-X.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Language = {English},
	Month = oct,
	Number = {10},
	Pages = {481--488},
	Pmid = {16139558},
	Shorttitle = {Neurophysiological markers of early language acquisition},
	Title = {Neurophysiological markers of early language acquisition: from syllables to sentences},
	Url = {http://www.cell.com/article/S136466130500241X/abstract},
	Urldate = {2014-06-01},
	Volume = {9},
	Year = {2005},
	Bdsk-Url-1 = {http://www.cell.com/article/S136466130500241X/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2005.08.008}}

@article{fekete_nirs_2011,
	Abstract = {Near infrared spectroscopy (NIRS) is a non-invasive optical imaging technique that can be used to measure cortical hemodynamic responses to specific stimuli or tasks. While analyses of NIRS data are normally adapted from established fMRI techniques, there are nevertheless substantial differences between the two modalities. Here, we investigate the impact of NIRS-specific noise; e.g., systemic (physiological), motion-related artifacts, and serial autocorrelations, upon the validity of statistical inference within the framework of the general linear model. We present a comprehensive framework for noise reduction and statistical inference, which is custom-tailored to the noise characteristics of NIRS. These methods have been implemented in a public domain Matlab toolbox, the NIRS Analysis Package (NAP). Finally, we validate NAP using both simulated and actual data, showing marked improvement in the detection power and reliability of NIRS.},
	Author = {Fekete, Tomer and Rubin, Denis and Carlson, Joshua M. and Mujica-Parodi, Lilianne R.},
	Doi = {10.1371/journal.pone.0024322},
	File = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/9KB2DP34/Fekete et al. - 2011 - The NIRS Analysis Package Noise Reduction and Sta.pdf:application/pdf;PLoS Snapshot:/Users/Cecile/Zotero/storage/H4S6B36I/infodoi10.1371journal.pone.html:text/html},
	Journal = {PLoS ONE},
	Month = sep,
	Number = {9},
	Pages = {e24322},
	Shorttitle = {The {NIRS} {Analysis} {Package}},
	Title = {The {NIRS} {Analysis} {Package}: {Noise} {Reduction} and {Statistical} {Inference}},
	Url = {http://dx.doi.org/10.1371/journal.pone.0024322},
	Urldate = {2014-09-19},
	Volume = {6},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pone.0024322}}

@book{winer_auditory_2010,
	Abstract = {There has been substantial progress in understanding the contributions of the auditory forebrain to hearing, sound localization, communication, emotive behavior, and cognition.  The Auditory Cortex covers the latest knowledge about the auditory forebrain, including the auditory cortex as well as the medial geniculate body in the thalamus.  This book will cover all important aspects of the auditory forebrain organization and function, integrating the auditory thalamus and cortex into a smooth, coherent whole.  Volume One covers basic auditory neuroscience.  It complements The Auditory Cortex, Volume 2: Integrative Neuroscience, which takes a more applied/clinical perspective.},
	Author = {Winer, Jeffery A. and Schreiner, Christoph E.},
	Isbn = {978-1-4419-0074-6},
	Keywords = {Medical / Neurology, Medical / Neuroscience, Medical / Otorhinolaryngology, Science / Life Sciences / Neuroscience, Science / Life Sciences / Zoology / General},
	Language = {en},
	Month = dec,
	Publisher = {Springer Science \& Business Media},
	Title = {The {Auditory} {Cortex}},
	Year = {2010}}

@article{pallier_perceptual_1998,
	Abstract = {Previous research has shown that, when hearers listen to artificially speeded speech, their performance improves over the course of 10--15 sentences, as if their perceptual system was ``adapting'' to these fast rates of speech. In this paper, we further investigate the mechanisms that are responsible for such effects. In Experiment 1, we report that, for bilingual speakers of Catalan and Spanish, exposure to compressed sentences in either language improves performance on sentences in the other language. Experiment 2 reports that Catalan/Spanish transfer of performance occurs even in monolingual speakers of Spanish who do not understand Catalan. In Experiment 3, we study another pair of languages--- namely, English and French---and report no transfer of adaptation between these two languages for English---French bilinguals. Experiment 4, with monolingual English speakers, assesses transfer of adaptation from French, Dutch, and English toward English. Here we find that there is no adaptation from French and intermediate adaptation from Dutch. We discuss the locus of the adaptation to compressed speech and relate our findings to other cross-linguistic studies in speech perception.},
	Author = {Pallier, Christophe and Sebastian-Gall{\'e}s, Nuria and Dupoux, Emmanuel and Christophe, Anne and Mehler, Jacques},
	Doi = {10.3758/BF03211403},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KZT7BKSC/Pallier et al. - 1998 - Perceptual adjustment to time-compressed speech A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J2HXN82W/BF03211403.html:text/html},
	Issn = {0090-502X, 1532-5946},
	Journal = {Memory \& Cognition},
	Keywords = {Cognitive Psychology},
	Language = {en},
	Month = jul,
	Number = {4},
	Pages = {844--851},
	Shorttitle = {Perceptual adjustment to time-compressed speech},
	Title = {Perceptual adjustment to time-compressed speech: {A} cross-linguistic study},
	Url = {http://link.springer.com/article/10.3758/BF03211403},
	Urldate = {2014-01-20},
	Volume = {26},
	Year = {1998},
	Bdsk-Url-1 = {http://link.springer.com/article/10.3758/BF03211403},
	Bdsk-Url-2 = {https://doi.org/10.3758/BF03211403}}

@article{rieke_naturalistic_1995,
	Abstract = {Natural sounds, especially communication sounds, have highly structured amplitude and phase spectra. We have quantified how structure in the amplitude spectrum of natural sounds affects coding in primary auditory afferents. Auditory afferents encode stimuli with naturalistic amplitude spectra dramatically better than broad-band stimuli (approximating white noise); the rate at which the spike train carries information about the stimulus is 2-6 times higher for naturalistic sounds. Furthermore, the information rates can reach 90\% of the fundamental limit to information transmission set by the statistics of the spike response. These results indicate that the coding strategy of the auditory nerve is matched to the structure of natural sounds; this `tuning' allows afferent spike trains to provide higher processing centres with a more complete description of the sensory world.},
	Author = {Rieke, F. and Bodnar, D. A. and Bialek, W.},
	Doi = {10.1098/rspb.1995.0204},
	File = {Snapshot:/Users/Cecile/Zotero/storage/TU54VMWS/259.html:text/html},
	Issn = {0962-8452, 1471-2954},
	Journal = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
	Language = {en},
	Month = dec,
	Number = {1365},
	Pages = {259--265},
	Pmid = {8587884},
	Title = {Naturalistic {Stimuli} {Increase} the {Rate} and {Efficiency} of {Information} {Transmission} by {Primary} {Auditory} {Afferents}},
	Url = {http://rspb.royalsocietypublishing.org/content/262/1365/259},
	Urldate = {2014-05-24},
	Volume = {262},
	Year = {1995},
	Bdsk-Url-1 = {http://rspb.royalsocietypublishing.org/content/262/1365/259},
	Bdsk-Url-2 = {https://doi.org/10.1098/rspb.1995.0204}}

@article{bortfeld_identifying_2009,
	Abstract = {We investigate the utility of near-infrared spectroscopy (NIRS) as an alternative technique for studying infant speech processing. NIRS is an optical imaging technology that uses relative changes in total hemoglobin concentration and oxygenation as an indicator of neural activation. Procedurally, NIRS has the advantage over more common methods (e.g., fMRI) in that it can be used to study the neural responses of behaviorally active infants. Older infants (aged 6--9 months) were allowed to sit on their caretakers' laps during stimulus presentation to determine relative differences in focal activity in the temporal region of the brain during speech processing. Results revealed a dissociation of sensory-specific processing in two cortical regions, the left and right temporal lobes. These findings are consistent with those obtained using other neurophysiological methods and point to the utility of NIRS as a means of establishing neural correlates of language development in older (and more active) infants.},
	Author = {Bortfeld, Heather and Fava, Eswen and Boas, David A.},
	Doi = {10.1080/87565640802564481},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FEHMUI7Z/Bortfeld et al. - 2009 - Identifying Cortical Lateralization of Speech Proc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AH97PBRP/87565640802564481.html:text/html},
	Issn = {8756-5641},
	Journal = {Developmental Neuropsychology},
	Month = jan,
	Number = {1},
	Pages = {52--65},
	Pmid = {19142766},
	Title = {Identifying {Cortical} {Lateralization} of {Speech} {Processing} in {Infants} {Using} {Near}-{Infrared} {Spectroscopy}},
	Url = {http://dx.doi.org/10.1080/87565640802564481},
	Urldate = {2016-10-10},
	Volume = {34},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/87565640802564481}}

@book{poeppel_human_2012,
	Abstract = {We live in a complex and dynamically changing acoustic environment. To this end, the auditory cortex of humans has developed the ability to process a remarkable amount of diverse acoustic information with apparent ease. In fact, a phylogenetic comparison of auditory systems reveals that human auditory association cortex in particular has undergone extensive changes relative to that of other species, although our knowledge of this remains incomplete. In contrast to other senses, human auditory cortex receives input that is highly pre-processed in a number of sub-cortical structures; this suggests that even primary auditory cortex already performs quite complex analyses. At the same time, much of the functional role of the various sub-areas in human auditory cortex is still relatively unknown, and a more sophisticated understanding is only now emerging through the use of contemporary electrophysiological and neuroimaging techniques. The integration of results across the various techniques signify a new era in our knowledge of how human auditory cortex forms basis for auditory experience. This volume on human auditory cortex will have two major parts. In Part A, the principal methodologies currently used to investigate human auditory cortex will be discussed. Each chapter will first outline how the methodology is used in auditory neuroscience, highlighting the challenges of obtaining data from human auditory cortex; second, each methods chapter will provide two or (at most) three brief examples of how it has been used to generate a major result about auditory processing. In Part B, the central questions for auditory processing in human auditory cortex are covered. Each chapter can draw on all the methods introduced in Part A but will focus on a major computational challenge the system has to solve. This volume will constitute an important contemporary reference work on human auditory cortex. Arguably, this will be the first and most focused book on this critical neurological structure. The combination of different methodological and experimental approaches as well as a diverse range of aspects of human auditory perception ensures that this volume will inspire novel insights and spurn future research.},
	Author = {Poeppel, David and Overath, Tobias and Popper, Arthur N. and Fay, Richard R.},
	Isbn = {978-1-4614-2313-3},
	Keywords = {Medical / Neuroscience, Medical / Otorhinolaryngology, Science / Life Sciences / Ecology, Science / Life Sciences / Neuroscience, Science / Life Sciences / Zoology / General},
	Language = {en},
	Month = apr,
	Publisher = {Springer Science \& Business Media},
	Title = {The {Human} {Auditory} {Cortex}},
	Year = {2012}}

@article{bench_sound_1968,
	Author = {Bench, J.},
	Doi = {10.1080/00221325.1968.10533811},
	Issn = {0022-1325},
	Journal = {The Journal of Genetic Psychology},
	Keywords = {Abdominal Muscles, Female, Fetus, Humans, Pregnancy, Sound},
	Language = {eng},
	Month = sep,
	Number = {1st Half},
	Pages = {85--87},
	Pmid = {4236927},
	Title = {Sound transmission to the human foetus through the maternal abdominal wall},
	Volume = {113},
	Year = {1968},
	Bdsk-Url-1 = {https://doi.org/10.1080/00221325.1968.10533811}}

@article{lakatos_oscillatory_2005,
	Abstract = {EEG oscillations are hypothesized to reflect cyclical variations in the neuronal excitability, with particular frequency bands reflecting differing spatial scales of brain operation. However, despite decades of clinical and scientific investigation, there is no unifying theory of EEG organization, and the role of ongoing activity in sensory processing remains controversial. This study analyzed laminar profiles of synaptic activity [current source density CSD] and multiunit activity (MUA), both spontaneous and stimulus-driven, in primary auditory cortex of awake macaque monkeys. Our results reveal that the EEG is hierarchically organized; delta (1--4 Hz) phase modulates theta (4--10 Hz) amplitude, and theta phase modulates gamma (30--50 Hz) amplitude. This oscillatory hierarchy controls baseline excitability and thus stimulus-related responses in a neuronal ensemble. We propose that the hierarchical organization of ambient oscillatory activity allows auditory cortex to structure its temporal activity pattern so as to optimize the processing of rhythmic inputs.},
	Author = {Lakatos, Peter and Shah, Ankoor S. and Knuth, Kevin H. and Ulbert, Istvan and Karmos, George and Schroeder, Charles E.},
	Copyright = {Copyright {\copyright} 2005 by the American Physiological Society},
	Doi = {10.1152/jn.00263.2005},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/SXF2Z93Z/Lakatos et al. - 2005 - An Oscillatory Hierarchy Controlling Neuronal Exci.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6CJ3326Q/1904.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = sep,
	Number = {3},
	Pages = {1904--1911},
	Title = {An {Oscillatory} {Hierarchy} {Controlling} {Neuronal} {Excitability} and {Stimulus} {Processing} in the {Auditory} {Cortex}},
	Url = {http://jn.physiology.org/content/94/3/1904},
	Urldate = {2014-11-03},
	Volume = {94},
	Year = {2005},
	Bdsk-Url-1 = {http://jn.physiology.org/content/94/3/1904},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00263.2005}}

@article{liberman_motor_1985,
	Author = {Liberman, Alvin M. and Mattingly, Ignatius G.},
	Doi = {10.1016/0010-0277(85)90021-6},
	File = {The motor theory of speech perception revised:/Users/Cecile/Zotero/storage/AXX9JMTD/0010027785900216.html:text/html},
	Issn = {00100277},
	Journal = {Cognition},
	Month = oct,
	Number = {1},
	Pages = {1--36},
	Title = {The motor theory of speech perception revised},
	Url = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/0010027785900216},
	Urldate = {2013-09-16},
	Volume = {21},
	Year = {1985},
	Bdsk-Url-1 = {https://www-sciencedirect-com.frodon.univ-paris5.fr/science/article/pii/0010027785900216},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(85)90021-6}}

@article{gross_speech_2013,
	Abstract = {{\textless}p{\textgreater}A neuroimaging study reveals how coupled brain oscillations at different frequencies align with quasi-rhythmic features of continuous speech such as prosody, syllables, and phonemes.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}},
	Author = {Gross, Joachim and Hoogenboom, Nienke and Thut, Gregor and Schyns, Philippe and Panzeri, Stefano and Belin, Pascal and Garrod, Simon},
	Doi = {10.1371/journal.pbio.1001752},
	File = {PLoS Snapshot:/Users/Cecile/Zotero/storage/WMRNWNPI/infodoi10.1371journal.pbio.html:text/html},
	Journal = {PLoS Biol},
	Month = dec,
	Number = {12},
	Pages = {e1001752},
	Title = {Speech {Rhythms} and {Multiplexed} {Oscillatory} {Sensory} {Coding} in the {Human} {Brain}},
	Url = {http://dx.doi.org/10.1371/journal.pbio.1001752},
	Urldate = {2014-10-31},
	Volume = {11},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pbio.1001752}}

@article{best_stimulus-alternation_1998,
	Author = {Best, CatherineT. and Jones, Cathleen},
	Doi = {10.1016/S0163-6383(98)91508-9},
	Issn = {01636383},
	Journal = {Infant Behavior and Development},
	Language = {en},
	Month = apr,
	Pages = {295},
	Title = {Stimulus-alternation preference procedure to test infant speech discrimination},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0163638398915089},
	Urldate = {2016-10-11},
	Volume = {21},
	Year = {1998},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0163638398915089},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0163-6383(98)91508-9}}

@article{lerner_temporal_2014,
	Abstract = {Different brain areas integrate information over different timescales, and this capacity to accumulate information increases from early sensory areas to higher order perceptual and cognitive areas. It is currently unknown whether the timescale capacity of each brain area is fixed or whether it adaptively rescales depending on the rate at which information arrives from the world. Here, using functional MRI, we measured brain responses to an auditory narrative presented at different rates. We asked whether neural responses to slowed (speeded) versions of the narrative could be compressed (stretched) to match neural responses to the original narrative. Temporal rescaling was observed in early auditory regions (which accumulate information over short timescales) as well as linguistic and extra-linguistic brain areas (which can accumulate information over long timescales). The temporal rescaling phenomenon started to break down for stimuli presented at double speed, and intelligibility was also impaired for these stimuli. These data suggest that 1) the rate of neural information processing can be rescaled according to the rate of incoming information, both in early sensory regions as well as in higher order cortexes, and 2) the rescaling of neural dynamics is confined to a range of rates that match the range of behavioral performance.},
	Author = {Lerner, Y. and Honey, C. J. and Katkov, M. and Hasson, U.},
	Copyright = {Copyright {\copyright} 2014 the American Physiological Society},
	Doi = {10.1152/jn.00497.2013},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/77AAN6D4/Lerner et al. - 2014 - Temporal scaling of neural responses to compressed.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M2VFVHBH/2433.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = jun,
	Number = {12},
	Pages = {2433--2444},
	Pmid = {24647432},
	Title = {Temporal scaling of neural responses to compressed and dilated natural speech},
	Url = {http://jn.physiology.org.gate1.inist.fr/content/111/12/2433},
	Urldate = {2015-08-24},
	Volume = {111},
	Year = {2014},
	Bdsk-Url-1 = {http://jn.physiology.org.gate1.inist.fr/content/111/12/2433},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00497.2013}}

@article{ding_robust_2014,
	Abstract = {Speech recognition is robust to background noise. One underlying neural mechanism is that the auditory system segregates speech from the listening background and encodes it reliably. Such robust internal representation has been demonstrated in auditory cortex by neural activity entrained to the temporal envelope of speech. A paradox, however, then arises, as the spectro-temporal fine structure rather than the temporal envelope is known to be the major cue to segregate target speech from background noise. Does the reliable cortical entrainment in fact reflect a robust internal ``synthesis'' of the attended speech stream rather than direct tracking of the acoustic envelope? Here, we test this hypothesis by degrading the spectro-temporal fine structure while preserving the temporal envelope using vocoders. Magnetoencephalography (MEG) recordings reveal that cortical entrainment to vocoded speech is severely degraded by background noise, in contrast to the robust entrainment to natural speech. Furthermore, cortical entrainment in the delta-band (1--4 Hz) predicts the speech recognition score at the level of individual listeners. These results demonstrate that reliable cortical entrainment to speech relies on the spectro-temporal fine structure, and suggest that cortical entrainment to the speech envelope is not merely a representation of the speech envelope but a coherent representation of multiscale spectro-temporal features that are synchronized to the syllabic and phrasal rhythms of speech.},
	Author = {Ding, Nai and Chatterjee, Monita and Simon, Jonathan Z.},
	Doi = {10.1016/j.neuroimage.2013.10.054},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ZBGZ7WX3/Ding et al. - 2014 - Robust cortical entrainment to the speech envelope.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VUJTSVGD/S105381191301077X.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Auditory scene analysis, Envelope entrainment, MEG, Auditory cortex},
	Month = mar,
	Pages = {41--46},
	Title = {Robust cortical entrainment to the speech envelope relies on the spectro-temporal fine structure},
	Url = {http://www.sciencedirect.com/science/article/pii/S105381191301077X},
	Urldate = {2014-10-31},
	Volume = {88},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191301077X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2013.10.054}}

@article{lin_regional_2013,
	Abstract = {Understanding the evolution of regional and hemispheric asymmetries in the early stages of life is essential to the advancement of developmental neuroscience. By using 2 noninvasive optical methods, frequency-domain near-infrared spectroscopy and diffuse correlation spectroscopy, we measured cerebral hemoglobin oxygenation (SO(2)), blood volume (CBV), an index of cerebral blood flow (CBF(i)), and the metabolic rate of oxygen (CMRO(2i)) in the frontal, temporal, and parietal regions of 70 premature and term newborns. In concordance with results obtained using more invasive imaging modalities, we verified both hemodynamic (CBV, CBF(i), and SO(2)) and metabolic (CMRO(2i)) parameters were greater in the temporal and parietal regions than in the frontal region and that these differences increased with age. In addition, we found that most parameters were significantly greater in the right hemisphere than in the left. Finally, in comparing age-matched males and females, we found that males had higher CBF(i) in most cortical regions, higher CMRO(2i) in the frontal region, and more prominent right-left CBF(i) asymmetry. These results reveal, for the first time, that we can detect regional and hemispheric asymmetries in newborns using noninvasive optical techniques. Such a bedside screening tool may facilitate early detection of abnormalities and delays in maturation of specific cortical areas.},
	Author = {Lin, Pei-Yi and Roche-Labarbe, Nad{\`e}ge and Dehaes, Mathieu and Fenoglio, Angela and Grant, P. Ellen and Franceschini, Maria Angela},
	Doi = {10.1093/cercor/bhs023},
	Issn = {1460-2199},
	Journal = {Cerebral Cortex (New York, N.Y.: 1991)},
	Keywords = {Female, Hemodynamics, Humans, Infant, Newborn, Male, Cerebrovascular Circulation, Infant, Premature, Spectrum Analysis, Oxygen, Brain},
	Language = {eng},
	Month = feb,
	Number = {2},
	Pages = {339--348},
	Pmcid = {PMC3584954},
	Pmid = {22328446},
	Title = {Regional and hemispheric asymmetries of cerebral hemodynamic and oxygen metabolism in newborns},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1093/cercor/bhs023}}

@article{griffiths_planum_nodate,
	Author = {Griffiths, Timothy D. and Warren, Jason D.},
	Journal = {Trends in Cognitive Neurosciences},
	Number = {7},
	Pages = {348--353},
	Title = {The planum temporale as a computational hub},
	Url = {http://www.sciencedirect.com/science/article/pii/S0166223602021914},
	Volume = {25},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223602021914}}

@article{arredondo_bilingualism_2015,
	Abstract = {Bilingualism is a typical linguistic experience, yet relatively little is known about its impact on children's cognitive and brain development. Theories of bilingualism suggest that early dual-language acquisition can improve children's cognitive abilities, specifically those relying on frontal lobe functioning. While behavioral findings present much conflicting evidence, little is known about its effects on children's frontal lobe development. Using functional near-infrared spectroscopy (fNIRS), the findings suggest that Spanish--English bilingual children (n = 13, ages 7--13) had greater activation in left prefrontal cortex during a non-verbal attentional control task relative to age-matched English monolinguals. In contrast, monolinguals (n = 14) showed greater right prefrontal activation than bilinguals. The present findings suggest that early bilingualism yields significant changes to the functional organization of children's prefrontal cortex for attentional control and carry implications for understanding how early life experiences impact cognition and brain development.},
	Author = {Arredondo, Maria M. and Hu, Xiao-Su and Satterfield, Teresa and Kovelman, Ioulia},
	Doi = {10.1111/desc.12377},
	File = {Snapshot:/Users/Cecile/Zotero/storage/4798839E/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = dec,
	Pages = {n/a--n/a},
	Title = {Bilingualism alters children's frontal lobe functioning for attentional control},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12377/abstract},
	Urldate = {2016-11-01},
	Year = {2015},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12377/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12377}}

@article{kobayashi_infants_2011,
	Abstract = {Recent adult functional magnetic resonance imaging (fMRI) studies reported that face-sensitive cortical areas showed attenuated responses to the repeated presentation of an identical facial image compared to the presentation of different facial images (fMRI-adaptation effects: e.g., Andrews and Ewbank, 2004). Building upon this finding, the current study, employing the adaptation paradigm, used near-infrared spectroscopy (NIRS) to explore the neural basis of face processing in infants. In Experiment 1, we compared hemodynamic responses in the bilateral temporal regions during the repeated presentation of the same face (the same-face condition) and the sequential presentation of different faces (the different-face condition). We found that (1) hemodynamic responses in the channels around the T5 and T6 regions increased during the presentation of different faces compared to those during the presentation of different objects; and that (2) these channels showed significantly lower response in the same-face condition than in the different-face condition, demonstrating the neural adaptation effect in 5- to 8-month-olds as measured by NIRS. In Experiment 2, when faces in both the same-face and different-face conditions were changed in viewpoint, lower hemodynamic responses in the same-face condition were found in 7- to 8-month-olds but not in 5- to 6-month-olds. Our results suggest that faces are represented in a viewpoint-invariant manner in 7- and 8-month-old infants.},
	Author = {Kobayashi, Megumi and Otsuka, Yumiko and Nakato, Emi and Kanazawa, So and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	Doi = {10.3389/fnhum.2011.00153},
	File = {fnhum-05-00153.pdf:/Users/Cecile/Zotero/storage/YZ3TUAVV/fnhum-05-00153.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/8TBV7P5W/Kobayashi et al. - 2011 - Do infants represent the face in a viewpoint-invar.pdf:application/pdf},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {adaptation effect, viewpoint-invariant, Face, NIRS, Infants, Near-infrared spectroscopy},
	Pages = {153},
	Shorttitle = {Do infants represent the face in a viewpoint-invariant manner?},
	Title = {Do infants represent the face in a viewpoint-invariant manner? {Neural} adaptation study as measured by near-infrared spectroscopy},
	Url = {http://journal.frontiersin.org/article/10.3389/fnhum.2011.00153/full},
	Urldate = {2016-10-11},
	Volume = {5},
	Year = {2011},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2011.00153/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2011.00153}}

@article{orchik_time-compressed_1977,
	Abstract = {The Word Intelligibility by Picture Identification (WIPI) Test of Speech Discrimination was time compressed at 0, 30, and 60\% and administered to 48 normal-hearing children. The children, all between the ages of 5 years, 6 months and six years, 7 months of age, were equally divided into three groups on the basis of articulation ability. Significant effects were found for test groups and levels of time compression, with differences increasing as time compression increased. The implication is that children with multiple articulation errors demonstrate a developmental lag in the ability to process time-compressed speech. Time-compressed speech may be a useful tool in the study of auditory perception in children.},
	Author = {Orchik, D J and Oelschlaeger, M L},
	Issn = {0360-9294},
	Journal = {Journal of the American Audiology Society},
	Keywords = {Audiometry, Auditory Perception, Child, Child, Preschool, Hearing Disorders, Humans, Speech},
	Language = {eng},
	Month = aug,
	Number = {1},
	Pages = {37--41},
	Pmid = {893199},
	Title = {Time-compressed speech discrimination in children and its relationship to articulation},
	Volume = {3},
	Year = {1977}}

@article{nakato_i_2011,
	Abstract = {Previously, we used near-infrared spectroscopy (NIRS) to measure infant's brain activity during face processing by detecting changes in hemodynamic responses, oxy-Hb, deoxy-Hb, and total-Hb concentrations [1,2]. We found that the right temporal cortex of the brain was activated when infants looked at upright frontal faces rather than inverted faces, and at the frontal view as well as the profile view on 8-month-olds. In the present study, we investigated 7- and 8-month-olds' brain activity related to the perception of mother's and stranger's faces by NIRS. The finding was that oxy-Hb and total-Hb concentrations in the right temporal cortex increased against the baseline during presentation of the mother's face. For strangers' faces, the total-Hb concentration in the right temporal cortex was greater than the baseline. By contrast, oxy- and total-Hb concentrations in the left temporal cortex increased only in the presentation of mother's face. The great activity in the right temporal region for faces irrespective of familiarity was consistent with a predominance of the right temporal cortex found previously in infants [1,2] as well as functional magnetic resonance imaging (fMRI) studies in adults [3,4]. In contrast to the activity in the right temporal cortex, the greater hemodynamic response in the left temporal cortex was observed only in the mother's face condition. These findings suggest that the processing of the mother's face enhances activity in bilateral temporal cortex. This is the first study to clarify the location of brain activity in infants related to the perception of their mother's face.},
	Author = {Nakato, Emi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Honda, Yukiko and Kakigi, Ryusuke},
	Doi = {10.1016/j.earlhumdev.2010.08.030},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/25KHI5JD/Nakato et al. - 2011 - I know this face Neural activity during mother' f.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4TPWUKW3/S0378378210006638.html:text/html},
	Issn = {0378-3782},
	Journal = {Early Human Development},
	Keywords = {Familiarity, Mother's face processing, Infants, Near-infrared spectroscopy},
	Month = jan,
	Number = {1},
	Pages = {1--7},
	Shorttitle = {I know this face},
	Title = {I know this face: {Neural} activity during mother' face perception in 7- to 8-month-old infants as investigated by near-infrared spectroscopy},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378378210006638},
	Urldate = {2017-12-07},
	Volume = {87},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378378210006638},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.earlhumdev.2010.08.030}}

@article{rabinowitz_constructing_2013,
	Abstract = {{\textless}p{\textgreater}Along the auditory pathway from auditory nerve to midbrain to cortex, individual neurons adapt progressively to sound statistics, enabling the discernment of foreground sounds, such as speech, over background noise.{\textless}/p{\textgreater}{\textless}/sec{\textgreater}},
	Author = {Rabinowitz, Neil C. and Willmore, Ben D. B. and King, Andrew J. and Schnupp, Jan W. H.},
	Doi = {10.1371/journal.pbio.1001710},
	File = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/H52XJHNT/Rabinowitz et al. - 2013 - Constructing Noise-Invariant Representations of So.pdf:application/pdf},
	Journal = {PLoS Biol},
	Month = nov,
	Number = {11},
	Pages = {e1001710},
	Title = {Constructing {Noise}-{Invariant} {Representations} of {Sound} in the {Auditory} {Pathway}},
	Url = {http://dx.doi.org/10.1371/journal.pbio.1001710},
	Urldate = {2015-07-15},
	Volume = {11},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pbio.1001710}}

@article{quaresima_brief_2012,
	Abstract = {Upon stimulation, real time maps of cortical hemodynamic responses can be obtained by non-invasive functional near-infrared spectroscopy (fNIRS) which measures changes in oxygenated and deoxygenated hemoglobin after positioning multiple sources and detectors over the human scalp. The current commercially available transportable fNIRS systems have a time resolution of 1-10 Hz, a depth sensitivity of about 1.5 cm, and a spatial resolution of about 1cm. The goal of this brief review is to report infants, children and adults fNIRS language studies. Since 1998, 60 studies have been published on cortical activation in the brain's classic language areas in children/adults as well as newborns using fNIRS instrumentations of different complexity. In addition, the basic principles of fNIRS including features, strengths, advantages, and limitations are summarized in terms that can be understood even by non specialists. Future prospects of fNIRS in the field of language processing imaging are highlighted.},
	Author = {Quaresima, Valentina and Bisconti, Silvia and Ferrari, Marco},
	Doi = {10.1016/j.bandl.2011.03.009},
	Issn = {1090-2155},
	Journal = {Brain and Language},
	Keywords = {Adult, Brain Mapping, Child, Humans, Infant, Newborn, Spectroscopy, Near-Infrared, language, Brain},
	Language = {eng},
	Month = may,
	Number = {2},
	Pages = {79--89},
	Pmid = {21507474},
	Title = {A brief review on the use of functional near-infrared spectroscopy ({fNIRS}) for language imaging studies in human newborns and adults},
	Volume = {121},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.bandl.2011.03.009}}

@article{aslin_hemodynamic_2015,
	Abstract = {Over the past 20 years, the field of cognitive neuroscience has relied heavily on hemodynamic measures of blood oxygenation in local regions of the brain to make inferences about underlying cognitive processes. These same functional magnetic resonance imaging (fMRI) and functional near-infrared spectroscopy (fNIRS) techniques have recently been adapted for use with human infants. We review the advantages and disadvantages of these two neuroimaging methods for studies of infant cognition, with a particular emphasis on their technical limitations and the linking hypotheses that are used to draw conclusions from correlational data. In addition to summarizing key findings in several domains of infant cognition, we highlight the prospects of improving the quality of fNIRS data from infants to address in a more sophisticated way how cognitive development is mediated by changes in underlying neural mechanisms.},
	Author = {Aslin, Richard N. and Shukla, Mohinish and Emberson, Lauren L.},
	Doi = {10.1146/annurev-psych-010213-115108},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/I525QRDE/Aslin et al. - 2015 - Hemodynamic Correlates of Cognition in Human Infan.pdf:application/pdf},
	Issn = {0066-4308},
	Journal = {Annual review of psychology},
	Month = jan,
	Pages = {349--379},
	Pmcid = {PMC4429889},
	Pmid = {25251480},
	Title = {Hemodynamic {Correlates} of {Cognition} in {Human} {Infants}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4429889/},
	Urldate = {2016-11-02},
	Volume = {66},
	Year = {2015},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4429889/},
	Bdsk-Url-2 = {https://doi.org/10.1146/annurev-psych-010213-115108}}

@article{dehaene-lambertz_infancy_2015,
	Author = {Dehaene-Lambertz, G. and Spelke, E.S.},
	Doi = {10.1016/j.neuron.2015.09.026},
	File = {DehaeneLambertz-Spelke_TheinfancyoftheHumanBrain_Neuron2015.pdf:/Users/Cecile/Zotero/storage/DWZEX2JN/DehaeneLambertz-Spelke_TheinfancyoftheHumanBrain_Neuron2015.pdf:application/pdf},
	Issn = {08966273},
	Journal = {Neuron},
	Language = {en},
	Month = oct,
	Number = {1},
	Pages = {93--109},
	Title = {The {Infancy} of the {Human} {Brain}},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008156},
	Urldate = {2015-10-12},
	Volume = {88},
	Year = {2015},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008156},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2015.09.026}}

@article{banai_perceptual_2012,
	Abstract = {BackgroundTime-compressed speech, a form of rapidly presented speech, is harder to comprehend than natural speech, especially for non-native speakers. Although it is possible to adapt to time-compressed speech after a brief exposure, it is not known whether additional perceptual learning occurs with further practice. Here, we ask whether multiday training on time-compressed speech yields more learning than that observed during the initial adaptation phase and whether the pattern of generalization following successful learning is different than that observed with initial adaptation only.Methodology/Principal FindingsTwo groups of non-native Hebrew speakers were tested on five different conditions of time-compressed speech identification in two assessments conducted 10--14 days apart. Between those assessments, one group of listeners received five practice sessions on one of the time-compressed conditions. Between the two assessments, trained listeners improved significantly more than untrained listeners on the trained condition. Furthermore, the trained group generalized its learning to two untrained conditions in which different talkers presented the trained speech materials. In addition, when the performance of the non-native speakers was compared to that of a group of na{\"\i}ve native Hebrew speakers, performance of the trained group was equivalent to that of the native speakers on all conditions on which learning occurred, whereas performance of the untrained non-native listeners was substantially poorer.Conclusions/SignificanceMultiday training on time-compressed speech results in significantly more perceptual learning than brief adaptation. Compared to previous studies of adaptation, the training induced learning is more stimulus specific. Taken together, the perceptual learning of time-compressed speech appears to progress from an initial, rapid adaptation phase to a subsequent prolonged and more stimulus specific phase. These findings are consistent with the predictions of the Reverse Hierarchy Theory of perceptual learning and suggest constraints on the use of perceptual-learning regimens during second language acquisition.},
	Author = {Banai, Karen and Lavner, Yizhar},
	Doi = {10.1371/journal.pone.0047099},
	File = {BanaiLavner12.pdf:/Users/Cecile/Zotero/storage/6H64DJVB/BanaiLavner12.pdf:application/pdf;PLoS Full Text PDF:/Users/Cecile/Zotero/storage/JT67DSA2/Banai et Lavner - 2012 - Perceptual Learning of Time-Compressed Speech Mor.pdf:application/pdf;PLoS Snapshot:/Users/Cecile/Zotero/storage/W74N79WQ/infodoi10.1371journal.pone.html:text/html},
	Journal = {PLoS ONE},
	Month = oct,
	Number = {10},
	Pages = {e47099},
	Shorttitle = {Perceptual {Learning} of {Time}-{Compressed} {Speech}},
	Title = {Perceptual {Learning} of {Time}-{Compressed} {Speech}: {More} than {Rapid} {Adaptation}},
	Url = {http://dx.doi.org/10.1371/journal.pone.0047099},
	Urldate = {2014-04-02},
	Volume = {7},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pone.0047099}}

@article{remez_bistability_2001,
	Abstract = {Our studies revealed two stable modes of perceptual organization, one based on attributes of auditory sensory elements and another based on attributes of patterned sensory variation composed by the aggregation of sensory elements. In a dual-task method, listeners attended concurrently to both aspects, component and pattern, of a sine wave analogue of a word. Organization of elements was indexed by several single-mode tests of auditory form perception to verify the perceptual segregation of either an individual formant of a synthetic word or a tonal component of a sinusoidal word analogue. Organization of patterned variation was indexed by a test of lexical identification. The results show the independence of the perception of auditory and phonetic form, which appear to be differently organized concurrent effects of the same acoustic cause.},
	Author = {Remez, Robert E. and Pardo, Jennifer S. and Piorkowski, Rebecca L. and Rubin, Philip E.},
	Doi = {10.1111/1467-9280.00305},
	File = {Snapshot:/Users/Cecile/Zotero/storage/NUSTFC2Z/24.html:text/html},
	Issn = {0956-7976, 1467-9280},
	Journal = {Psychological Science},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {24--29},
	Pmid = {11294224},
	Title = {On the {Bistability} of {Sine} {Wave} {Analogues} of {Speech}},
	Url = {http://pss.sagepub.com/content/12/1/24},
	Urldate = {2014-05-28},
	Volume = {12},
	Year = {2001},
	Bdsk-Url-1 = {http://pss.sagepub.com/content/12/1/24},
	Bdsk-Url-2 = {https://doi.org/10.1111/1467-9280.00305}}

@article{wang_neurophysiological_2010,
	Abstract = {Synchronous rhythms represent a core mechanism for sculpting temporal coordination of neural activity in the brain-wide network. This review focuses on oscillations in the cerebral cortex that occur during cognition, in alert behaving conditions. Over the last two decades, experimental and modeling work has made great strides in elucidating the detailed cellular and circuit basis of these rhythms, particularly gamma and theta rhythms. The underlying physiological mechanisms are diverse (ranging from resonance and pacemaker properties of single cells to multiple scenarios for population synchronization and wave propagation), but also exhibit unifying principles. A major conceptual advance was the realization that synaptic inhibition plays a fundamental role in rhythmogenesis, either in an interneuronal network or in a reciprocal excitatory-inhibitory loop. Computational functions of synchronous oscillations in cognition are still a matter of debate among systems neuroscientists, in part because the notion of regular oscillation seems to contradict the common observation that spiking discharges of individual neurons in the cortex are highly stochastic and far from being clocklike. However, recent findings have led to a framework that goes beyond the conventional theory of coupled oscillators and reconciles the apparent dichotomy between irregular single neuron activity and field potential oscillations. From this perspective, a plethora of studies will be reviewed on the involvement of long-distance neuronal coherence in cognitive functions such as multisensory integration, working memory, and selective attention. Finally, implications of abnormal neural synchronization are discussed as they relate to mental disorders like schizophrenia and autism.},
	Author = {Wang, Xiao-Jing},
	Copyright = {Copyright {\copyright} 2010 the American Physiological Society},
	Doi = {10.1152/physrev.00035.2008},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NV2D4RDB/Wang - 2010 - Neurophysiological and Computational Principles of.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/996TUASI/1195.html:text/html},
	Issn = {0031-9333, 1522-1210},
	Journal = {Physiological Reviews},
	Language = {en},
	Month = jul,
	Number = {3},
	Pages = {1195--1268},
	Title = {Neurophysiological and {Computational} {Principles} of {Cortical} {Rhythms} in {Cognition}},
	Url = {http://physrev.physiology.org/content/90/3/1195},
	Urldate = {2014-10-21},
	Volume = {90},
	Year = {2010},
	Bdsk-Url-1 = {http://physrev.physiology.org/content/90/3/1195},
	Bdsk-Url-2 = {https://doi.org/10.1152/physrev.00035.2008}}

@article{hill_surface-based_2010,
	Abstract = {We have established a population average surface-based atlas of human cerebral cortex at term gestation and used it to compare infant and adult cortical shape characteristics. Accurate cortical surface reconstructions for each hemisphere of 12 healthy term gestation infants were generated from structural magnetic resonance imaging data using a novel segmentation algorithm. Each surface was inflated, flattened, mapped to a standard spherical configuration, and registered to a target atlas sphere that reflected shape characteristics of all 24 contributing hemispheres using landmark constrained surface registration. Population average maps of sulcal depth, depth variability, three-dimensional positional variability, and hemispheric depth asymmetry were generated and compared with previously established maps of adult cortex. We found that cortical structure in term infants is similar to the adult in many respects, including the pattern of individual variability and the presence of statistically significant structural asymmetries in lateral temporal cortex, including the planum temporale and superior temporal sulcus. These results indicate that several features of cortical shape are minimally influenced by the postnatal environment.},
	Author = {Hill, Jason and Dierker, Donna and Neil, Jeffrey and Inder, Terrie and Knutsen, Andrew and Harwell, John and Coalson, Timothy and Essen, David Van},
	Doi = {10.1523/JNEUROSCI.4682-09.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IMRT5DT3/Hill et al. - 2010 - A Surface-Based Analysis of Hemispheric Asymmetrie.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DMFUUHCT/2268.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = oct,
	Number = {6},
	Pages = {2268--2276},
	Pmid = {20147553},
	Title = {A {Surface}-{Based} {Analysis} of {Hemispheric} {Asymmetries} and {Folding} of {Cerebral} {Cortex} in {Term}-{Born} {Human} {Infants}},
	Url = {http://www.jneurosci.org/content/30/6/2268},
	Urldate = {2014-09-16},
	Volume = {30},
	Year = {2010},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/30/6/2268},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.4682-09.2010}}

@article{bertoncini_morae_1995,
	Abstract = {Are neonates sensitive to the different rhythmical units that are used in different spoken languages? And do they use these units to represent and discriminate multisyllabic words? In the present study, we used the High-Amplitude Sucking procedure to test whether 3-day-old French infants discriminate lists of Japanese words. The lists of words differed either in the number of syllabic units or in the number of sub-syllabic units such as morae. In Experiment 1, infants heard bisyllabic versus trisyllabic words (e.g.: iga vs. hekiga); in Experiment 2, they were presented with bimoraic versus trimoraic bisyllabic words (e.g.: iga vs. iNga). The results corroborate those obtained by Bijeljac-Babic, Bertoncini, and Mehler (1993), providing further evidence that neonates discriminate bisyllabic from trisyllabic words. In contrast, neonates do not appear to discriminate bisyllabic words that vary in number of sub-syllabic units. It is proposed that syllables are particularly salient units during the initial stage of speech processing, irrespective of which language and rhythmical structure is heard.},
	Author = {Bertoncini, Josiane and Floccia, Caroline and Nazzi, Thierry and Mehler, Jacques},
	Doi = {10.1177/002383099503800401},
	File = {Snapshot:/Users/Cecile/Zotero/storage/38GN29CQ/311.html:text/html},
	Issn = {0023-8309, 1756-6053},
	Journal = {Language and Speech},
	Keywords = {Rhythm, cue transparency, infant speech perception, speech units},
	Language = {en},
	Month = jan,
	Number = {4},
	Pages = {311--329},
	Shorttitle = {Morae and {Syllables}},
	Title = {Morae and {Syllables}: {Rhythmical} {Basis} of {Speech} {Representations} in {Neonates}},
	Url = {http://las.sagepub.com/content/38/4/311},
	Urldate = {2014-06-01},
	Volume = {38},
	Year = {1995},
	Bdsk-Url-1 = {http://las.sagepub.com/content/38/4/311},
	Bdsk-Url-2 = {https://doi.org/10.1177/002383099503800401}}

@article{dehaene-lambertz_cerebral_2000,
	Abstract = {Early cerebral specialization and lateralization for auditory processing in 4-month-old infants was studied by recording high-density evoked potentials to acoustical and phonetic changes in a series of repeated stimuli (either tones or syllables). Mismatch responses to these stimuli exhibit a distinct topography suggesting that different neural networks within the temporal lobe are involved in the perception and representation of the different features of an auditory stimulus. These data confirm that specialized modules are present within the auditory cortex very early in development. However, both for syllables and continuous tones, higher voltages were recorded over the left hemisphere than over the right with no significant interaction of hemisphere by type of stimuli. This suggests that there is no greater left hemisphere involvement in phonetic processing than in acoustic processing during the first months of life.},
	Author = {Dehaene-Lambertz, G.},
	Doi = {10.1162/089892900562264},
	File = {Citeseer - Full Text PDF:/Users/Cecile/Zotero/storage/RKPVLGLJ/In et al. - 2000 - Cerebral Specialization for Speech and.pdf:application/pdf;Journal of Cognitive Neuroscience Snapshot:/Users/Cecile/Zotero/storage/AAUBA23W/089892900562264.html:text/html},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = may,
	Number = {3},
	Pages = {449--460},
	Title = {Cerebral {Specialization} for {Speech} and {Non}-{Speech} {Stimuli} in {Infants}},
	Url = {http://dx.doi.org/10.1162/089892900562264},
	Urldate = {2014-05-29},
	Volume = {12},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1162/089892900562264}}

@article{lloyd-fox_cortical_2015,
	Abstract = {The extent to which perception and action share common neural processes is much debated in cognitive neuroscience. Taking a developmental approach to this issue allows us to assess whether perceptual processing develops in close association with the emergence of related action skills within the same individual. The current study used functional near-infrared spectroscopy (fNIRS) to investigate the perception of human action in 4- to 6-month-old human infants. In addition, the infants' manual dexterity was assessed using the fine motor component of The Mullen Scales of Early Learning and an in-house developed Manual Dexterity task. Results show that the degree of cortical activation, within the posterior superior temporal sulcus---temporoparietal junction (pSTS-TPJ) region, to the perception of manual actions in individual infants correlates with their own level of fine motor skills. This association was not fully explained by either measures of global attention (i.e., looking time) or general developmental stage. This striking concordance between the emergence of motor skills and related perceptual processing within individuals is consistent with experience-related cortical specialization in the developing brain.},
	Author = {Lloyd-Fox, Sarah and Wu, Rachel and Richards, John E. and Elwell, Clare E. and Johnson, Mark H.},
	Doi = {10.1093/cercor/bht207},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/44UQQ83D/Lloyd-Fox et al. - 2015 - Cortical Activation to Action Perception is Associ.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EPVQP96C/296958.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = feb,
	Number = {2},
	Pages = {289--297},
	Title = {Cortical {Activation} to {Action} {Perception} is {Associated} with {Action} {Production} {Abilities} in {Young} {Infants}},
	Url = {https://academic.oup.com/cercor/article/25/2/289/296958},
	Urldate = {2017-12-08},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/25/2/289/296958},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bht207}}

@article{ferry_nonhuman_2013,
	Abstract = {Language is a signature of our species and our primary conduit for conveying the contents of our minds. The power of language derives not only from the exquisite detail of the signal itself but also from its intricate link to human cognition. To acquire a language, infants must identify which signals are part of their language and discover how these signals are linked to meaning. At birth, infants prefer listening to vocalizations of human and nonhuman primates; within 3 mo, this initially broad listening preference is tuned specifically to human vocalizations. Moreover, even at this early developmental point, human vocalizations evoke more than listening preferences alone: they engender in infants a heightened focus on the objects in their visual environment and promote the formation of object categories, a fundamental cognitive capacity. Here, we illuminate the developmental origin of this early link between human vocalizations and cognition. We document that this link emerges from a broad biological template that initially encompasses vocalizations of human and nonhuman primates (but not backward speech) and that within 6 mo this link to cognition is tuned specifically to human vocalizations. At 3 and 4 mo, nonhuman primate vocalizations promote object categorization, mirroring precisely the advantages conferred by human vocalizations, but by 6 mo, nonhuman primate vocalizations no longer exert this advantageous effect. This striking developmental shift illuminates a path of specialization that supports infants as they forge the foundational links between human language and the core cognitive processes that will serve as the foundations of meaning.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1073/pnas.1221166110},
	Issn = {1091-6490},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Age Factors, Animals, Attention, Child Development, Cognition, Humans, Infant, Language Development, Lemur, Species Specificity, Speech, Vocalization, Animal},
	Language = {eng},
	Month = sep,
	Number = {38},
	Pages = {15231--15235},
	Pmcid = {PMC3780887},
	Pmid = {24003164},
	Title = {Nonhuman primate vocalizations support categorization in very young human infants},
	Volume = {110},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1073/pnas.1221166110}}

@article{partanen_learning-induced_2013,
	Abstract = {Learning, the foundation of adaptive and intelligent behavior, is based on plastic changes in neural assemblies, reflected by the modulation of electric brain responses. In infancy, auditory learning implicates the formation and strengthening of neural long-term memory traces, improving discrimination skills, in particular those forming the prerequisites for speech perception and understanding. Although previous behavioral observations show that newborns react differentially to unfamiliar sounds vs. familiar sound material that they were exposed to as fetuses, the neural basis of fetal learning has not thus far been investigated. Here we demonstrate direct neural correlates of human fetal learning of speech-like auditory stimuli. We presented variants of words to fetuses; unlike infants with no exposure to these stimuli, the exposed fetuses showed enhanced brain activity (mismatch responses) in response to pitch changes for the trained variants after birth. Furthermore, a significant correlation existed between the amount of prenatal exposure and brain activity, with greater activity being associated with a higher amount of prenatal speech exposure. Moreover, the learning effect was generalized to other types of similar speech sounds not included in the training material. Consequently, our results indicate neural commitment specifically tuned to the speech features heard before birth and their memory representations.},
	Author = {Partanen, Eino and Kujala, Teija and N{\"a}{\"a}t{\"a}nen, Risto and Liitola, Auli and Sambeth, Anke and Huotilainen, Minna},
	Doi = {10.1073/pnas.1302159110},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CINW4T3X/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/MKQW4IT9/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BG833BUU/15145.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/V7NZKAB5/15145.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {event-related potentials, Mismatch negativity},
	Language = {en},
	Month = oct,
	Number = {37},
	Pages = {15145--15150},
	Pmid = {23980148},
	Title = {Learning-induced neural plasticity of speech processing before birth},
	Url = {http://www.pnas.org/content/110/37/15145},
	Urldate = {2015-04-01},
	Volume = {110},
	Year = {2013},
	Bdsk-Url-1 = {http://www.pnas.org/content/110/37/15145},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1302159110}}

@article{shultz_neural_2014,
	Abstract = {How does the brain's response to speech change over the first months of life? Although behavioral findings indicate that neonates' listening biases are sharpened over the first months of life, with a species-specific preference for speech emerging by 3 months, the neural substrates underlying this developmental change are unknown. We examined neural responses to speech compared with biological non-speech sounds in 1- to 4-month-old infants using fMRI. Infants heard speech and biological non-speech sounds, including heterospecific vocalizations and human non-speech. We observed a left-lateralized response in temporal cortex for speech compared to biological non-speech sounds, indicating that this region is highly selective for speech by the first month of life. Specifically, this brain region becomes increasingly selective for speech over the next 3 months as neural substrates become less responsive to non-speech sounds. These results reveal specific changes in neural responses during a developmental period characterized by rapid behavioral changes.},
	Author = {Shultz, Sarah and Vouloumanos, Athena and Bennett, Randi H. and Pelphrey, Kevin},
	Copyright = {{\copyright} 2014 The Authors. Developmental Science Published by John Wiley \& Sons Ltd., This is an open access article under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in any medium, provided the original work is properly cited.},
	Doi = {10.1111/desc.12151},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/EVKNDHCV/Shultz et al. - 2014 - Neural specialization for speech in the first mont.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MIQH32U4/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = feb,
	Pages = {n/a--n/a},
	Title = {Neural specialization for speech in the first months of life},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12151/abstract},
	Urldate = {2014-05-22},
	Year = {2014},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12151/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12151}}

@article{geffen_auditory_2011,
	Abstract = {Many natural signals, including environmental sounds, exhibit scale-invariant statistics: their structure is repeated at multiple scales. Such scale-invariance has been identified separately across spectral and temporal correlations of natural sounds (Clarke and Voss, 1975; Attias and Schreiner, 1997; Escabi et al., 2003; Singh and Theunissen, 2003). Yet the role of scale-invariance across overall spectro-temporal structure of the sound has not been explored directly in auditory perception. Here, we identify that the acoustic waveform from the recording of running water is a self-similar fractal, exhibiting scale-invariance not only within spectral channels, but also across the full spectral bandwidth. The auditory perception of the water sound did not change with its scale. We tested the role of scale-invariance in perception by using an artificial sound, which could be rendered scale-invariant. We generated a random chirp stimulus: an auditory signal controlled by two parameters, Q, controlling the relative, and r, controlling the absolute, temporal structure of the sound. Imposing scale-invariant statistics on the artificial sound was required for its perception as natural and water-like. Further, Q had to be restricted to a specific range for the sound to be perceived as natural. To detect self-similarity in the water sound, and identify Q, the auditory system needs to process the temporal dynamics of the waveform across spectral bands in terms of the number of cycles, rather than absolute timing. We propose a two-stage neural model implementing this computation. This computation may be carried out by circuits of neurons in the auditory cortex. The set of auditory stimuli developed in this study are particularly suitable for measurements of response properties of neurons in the auditory pathway, allowing for quantification of the effects of varying the statistics of the spectro-temporal statistical structure of the stimulus.},
	Author = {Geffen, Maria N. and Gervain, Judit and Werker, Janet F. and Magnasco, Marcelo O.},
	Doi = {10.3389/fnint.2011.00015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7RVX7JAK/Geffen et al. - 2011 - Auditory perception of self-similarity in water so.pdf:application/pdf},
	Journal = {Frontiers in Integrative Neuroscience},
	Keywords = {Perception, Psychophysics, auditory, coherence, receptive field, scale-invariance, temporal adaptation},
	Pages = {15},
	Title = {Auditory perception of self-similarity in water sounds},
	Url = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2011.00015/abstract},
	Urldate = {2013-06-17},
	Volume = {5},
	Year = {2011},
	Bdsk-Url-1 = {http://www.frontiersin.org/Integrative_Neuroscience/10.3389/fnint.2011.00015/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnint.2011.00015}}

@article{kida_gentle_2013,
	Abstract = {Previous studies have demonstrated that pleasant touch activates reward-related cortical regions including the anterior prefrontal cortex (APFC) in adults, but the developmental change is still unknown in infancy. The present study used near infrared spectroscopy (NIRS) to investigate activation of the APFC by gentle touching of the hand of infants 2--16 months after birth, who were classified into three groups (3, 6 and 10 months old). Results showed that 10-month-olds, but not 3- and 6-month-olds, showed bilateral activation of the APFC by gentle touching of the palm with a sensuous velvet fabric compared to touch with rounded wood. The present finding suggests that developmental changes in the tactile affective system are associated with the activation of the APFC and that the critical point is between 6 and 10 months after birth.},
	Author = {Kida, Tetsuo and Shinohara, Kazuyuki},
	Doi = {10.1016/j.neulet.2013.01.048},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GSQH3T77/Kida et Shinohara - 2013 - Gentle touch activates the prefrontal cortex in in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/384TPWAD/S0304394013001055.html:text/html},
	Issn = {0304-3940},
	Journal = {Neuroscience Letters},
	Keywords = {Hemodynamics, Plasticity, Pleasant touch, Development},
	Month = apr,
	Pages = {63--66},
	Shorttitle = {Gentle touch activates the prefrontal cortex in infancy},
	Title = {Gentle touch activates the prefrontal cortex in infancy: {An} {NIRS} study},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304394013001055},
	Urldate = {2016-10-24},
	Volume = {541},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394013001055},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neulet.2013.01.048}}

@article{dubois_assessment_2006,
	Abstract = {The human infant is particularly immature at birth and brain maturation, with the myelination of white matter fibers, is protracted until adulthood. Diffusion tensor imaging offers the possibility to describe non invasively the fascicles spatial organization at an early stage and to follow the cerebral maturation with quantitative parameters that might be correlated with behavioral development. Here, we assessed the feasibility to study the organization and maturation of major white matter bundles in eighteen 1- to 4-month-old healthy infants, using a specific acquisition protocol customized to the immature brain (with 15 orientations of the diffusion gradients and a 700 s mmâ2 b factor). We were able to track most of the main fascicles described at later ages despite the low anisotropy of the infant white matter, using the FACT algorithm. This mapping allows us to propose a new method of quantification based on reconstructed tracts, split between specific regions, which should be more sensitive to specific changes in a bundle than the conventional approach, based on regions-of-interest. We observed variations in fractional anisotropy and mean diffusivity over the considered developmental period in most bundles (corpus callosum, cerebellar peduncles, cortico-spinal tract, spino-thalamic tract, capsules, radiations, longitudinal and uncinate fascicles, cingulum). The results are in good agreement with the known stages of white matter maturation and myelination, and the proposed approach might provide important insights on brain development.},
	Author = {Dubois, J. and Hertz-Pannier, L. and Dehaene-Lambertz, G. and Cointepas, Y. and Le Bihan, D.},
	Doi = {10.1016/j.neuroimage.2005.11.022},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IUP4MTMA/Dubois et al. - 2006 - Assessment of the early organization and maturatio.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/G7PAGU5F/S1053811905024535.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Diffusion tensor imaging, Myelination, Tractography, Infant, Development, Brain},
	Month = may,
	Number = {4},
	Pages = {1121--1132},
	Shorttitle = {Assessment of the early organization and maturation of infants' cerebral white matter fiber bundles},
	Title = {Assessment of the early organization and maturation of infants' cerebral white matter fiber bundles: {A} feasibility study using quantitative diffusion tensor imaging and tractography},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811905024535},
	Urldate = {2016-10-24},
	Volume = {30},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811905024535},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2005.11.022}}

@article{kusmierek_functional_2009,
	Abstract = {Responses of neural units in two areas of the medial auditory belt (middle medial area [MM] and rostral medial area [RM]) were tested with tones, noise bursts, monkey calls (MC), and environmental sounds (ES) in microelectrode recordings from two alert rhesus monkeys. For comparison, recordings were also performed from two core areas (primary auditory area [A1] and rostral area [R]) of the auditory cortex. All four fields showed cochleotopic organization, with best (center) frequency [BF(c)] gradients running in opposite directions in A1 and MM than in R and RM. The medial belt was characterized by a stronger preference for band-pass noise than for pure tones found medially to the core areas. Response latencies were shorter for the two more posterior (middle) areas MM and A1 than for the two rostral areas R and RM, reaching values as low as 6 ms for high BF(c) in MM and A1, and strongly depended on BF(c). The medial belt areas exhibited a higher selectivity to all stimuli, in particular to noise bursts, than the core areas. An increased selectivity to tones and noise bursts was also found in the anterior fields; the opposite was true for highly temporally modulated ES. Analysis of the structure of neural responses revealed that neurons were driven by low-level acoustic features in all fields. Thus medial belt areas RM and MM have to be considered early stages of auditory cortical processing. The anteroposterior difference in temporal processing indices suggests that R and RM may belong to a different hierarchical level or a different computational network than A1 and MM.},
	Author = {Ku{\'s}mierek, Pawe{\l} and Rauschecker, Josef P.},
	Copyright = {Copyright {\copyright} 2009 the American Physiological Society},
	Doi = {10.1152/jn.00167.2009},
	File = {Snapshot:/Users/Cecile/Zotero/storage/573X54GZ/1606.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = sep,
	Number = {3},
	Pages = {1606--1622},
	Pmid = {19571201},
	Title = {Functional {Specialization} of {Medial} {Auditory} {Belt} {Cortex} in the {Alert} {Rhesus} {Monkey}},
	Url = {http://jn.physiology.org/content/102/3/1606},
	Urldate = {2015-05-22},
	Volume = {102},
	Year = {2009},
	Bdsk-Url-1 = {http://jn.physiology.org/content/102/3/1606},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00167.2009}}

@article{watanabe_functional_2008,
	Abstract = {To understand the functional organization of the human cortex during the early postnatal period, we performed neuroimaging studies for visual perception in awake 3-month-old infants. Cortical hemodynamic responses to 2 different video images, moving mobile objects and black-and-white checkerboard pattern reversals, were observed using multichannel near-infrared spectroscopy (NIRS). Although a focal region of the occipital cortex was equally activated by both stimuli, the occipitotemporal region was activated only by the mobile objects. A possible explanation of the result is that the former and the latter regions are involved in the primary processing of visual stimuli and perception of objects with complex visual features, respectively. Furthermore, the prefrontal region was distinctly activated by the mobile objects. These results suggest that the early sensory region and the higher sensory/association and prefrontal regions are functionally differentiated by 3 months of age and that diverse regions of the cortex including the prefrontal region function during perception of visual events.},
	Author = {Watanabe, Hama and Homae, Fumitaka and Nakano, Tamami and Taga, Gentaro},
	Doi = {10.1016/j.neuroimage.2008.07.014},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/XTG8F8E3/Watanabe et al. - 2008 - Functional activation in diverse regions of the de.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GP6SGRW6/S1053811908008379.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = nov,
	Number = {2},
	Pages = {346--357},
	Title = {Functional activation in diverse regions of the developing brain of human infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811908008379},
	Urldate = {2016-10-24},
	Volume = {43},
	Year = {2008},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811908008379},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2008.07.014}}

@article{beasley_intelligibility_1980,
	Abstract = {Time-compressed monosyllables have been studied relative to the assessment of central auditory disorders. In certain instances, sentential stimuli may be more useful than word lists in central auditory testing, particularly when results may be contaminated by concomitant peripheral hearing losses. Central Institute for the Deaf (CID) and Revised CID sentence lists and a contrived sentential approximation task were presented to 96 normal hearing young adults at time-compression ratios of 0\%, 40\%, 60\%, and 70\%, under sensation levels of 24 and 40 dB. The CID and RCID stimuli were more intelligible than the sentential approximations. The results are presented and discussed as they pertain to central auditory testing and are compared to earlier data using consonant-nucleus-consonant monosyllabic stimuli.},
	Author = {Beasley, D. S. and Bratt, G. W. and Rintelmann, W. F.},
	Issn = {0022-4685},
	Journal = {Journal of Speech and Hearing Research},
	Keywords = {Adult, Hearing Loss, Central, Humans, Reference Values, Speech Discrimination Tests, Speech Intelligibility},
	Language = {eng},
	Month = dec,
	Number = {4},
	Pages = {722--731},
	Pmid = {7442207},
	Title = {Intelligibility of time-compressed sentential stimuli},
	Volume = {23},
	Year = {1980}}

@article{von_holzen_language_2012,
	Abstract = {We examined how words from bilingual toddlers' second language (L2) primed recognition of related target words in their first language (L1). On critical trials, prime--target word pairs were either (a) phonologically related, with L2 primes overlapped phonologically with L1 target words [e.g., slide (L2 prime)--Kleid (L1 target, ``dress'')], or (b) phonologically related through translation, with L1 translations of L2 primes rhymed with the L1 target words [e.g., leg (L2 prime, L1 translation, ``Bein'')--Stein (L1 target, ``stone''). Evidence of facilitated target recognition in the phonological priming condition suggests language nonselective access but not necessarily lexical access. However, a late interference effect on target recognition in the phonological priming through translation condition provides evidence for language nonselective lexical access: The L2 prime (leg) could influence L1 target recognition (Stein) in this condition only if both the L2 prime (leg) and its L1 translation (``Bein'') were concurrently activated. In addition, age- and gender-matched monolingual toddler controls showed no difference between conditions, providing further evidence that the results with bilingual toddlers were driven by cross-language activation. The current study, therefore, presents the first-ever evidence of cross-talk between the two languages of bilinguals even as they begin to acquire fluency in their second language.},
	Author = {Von Holzen, Katie and Mani, Nivedita},
	Doi = {10.1016/j.jecp.2012.08.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QRBE6BTJ/Von Holzen et Mani - 2012 - Language nonselective lexical access in bilingual .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/Z4N5PVAQ/S0022096512001440.html:text/html},
	Issn = {0022-0965},
	Journal = {Journal of Experimental Child Psychology},
	Keywords = {Cross-language priming, Language Development, Lexical access, Phonological processing, Toddler, bilingualism},
	Month = dec,
	Number = {4},
	Pages = {569--586},
	Title = {Language nonselective lexical access in bilingual toddlers},
	Url = {http://www.sciencedirect.com/science/article/pii/S0022096512001440},
	Urldate = {2015-02-13},
	Volume = {113},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0022096512001440},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jecp.2012.08.001}}

@article{nasi_spontaneous_2011,
	Abstract = {Understanding the interaction between the nervous system and cerebral vasculature is fundamental to forming a complete picture of the neurophysiology of sleep and its role in maintaining physiological homeostasis. However, the intrinsic hemodynamics of slow-wave sleep (SWS) are still poorly known. We carried out 30 all-night sleep measurements with combined near-infrared spectroscopy (NIRS) and polysomnography to investigate spontaneous hemodynamic behavior in SWS compared to light (LS) and rapid-eye-movement sleep (REM). In particular, we concentrated on slow oscillations (3--150 mHz) in oxy- and deoxyhemoglobin concentrations, heart rate, arterial oxygen saturation, and the pulsation amplitude of the photoplethysmographic signal. We also analyzed the behavior of these variables during sleep stage transitions. The results indicate that slow spontaneous cortical and systemic hemodynamic activity is reduced in SWS compared to LS, REM, and wakefulness. This behavior may be explained by neuronal synchronization observed in electrophysiological studies of SWS and a reduction in autonomic nervous system activity. Also, sleep stage transitions are asymmetric, so that the SWS-to-LS and LS-to-REM transitions, which are associated with an increase in the complexity of cortical electrophysiological activity, are characterized by more dramatic hemodynamic changes than the opposite transitions. Thus, it appears that while the onset of SWS and termination of REM occur only as gradual processes over time, the termination of SWS and onset of REM may be triggered more abruptly by a particular physiological event or condition. The results suggest that scalp hemodynamic changes should be considered alongside cortical hemodynamic changes in NIRS sleep studies to assess the interaction between the autonomic and central nervous systems.},
	Author = {N{\"a}si, Tiina and Virtanen, Jaakko and Noponen, Tommi and Toppila, Jussi and Salmi, Tapani and Ilmoniemi, Risto J.},
	Doi = {10.1371/journal.pone.0025415},
	File = {PLoS Full Text PDF:/Users/Cecile/Zotero/storage/GRRE7MAE/N{\"a}si et al. - 2011 - Spontaneous Hemodynamic Oscillations during Human .pdf:application/pdf},
	Journal = {PLoS ONE},
	Month = oct,
	Number = {10},
	Pages = {e25415},
	Title = {Spontaneous {Hemodynamic} {Oscillations} during {Human} {Sleep} and {Sleep} {Stage} {Transitions} {Characterized} with {Near}-{Infrared} {Spectroscopy}},
	Url = {http://dx.doi.org/10.1371/journal.pone.0025415},
	Urldate = {2015-02-13},
	Volume = {6},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1371/journal.pone.0025415}}

@article{holmstrom_efficient_2010,
	Abstract = {An important question in sensory neuroscience is what coding strategies and mechanisms are used by the brain to detect and discriminate among behaviorally relevant stimuli. There is evidence that sensory systems migrate from a distributed and redundant encoding strategy at the periphery to a more heterogeneous encoding in cortical structures. It has been hypothesized that heterogeneity is an efficient encoding strategy that minimizes the redundancy of the neural code and maximizes information throughput. Evidence of this mechanism has been documented in cortical structures. In this study, we examined whether heterogeneous encoding of complex sounds contributes to efficient encoding in the auditory midbrain by characterizing neural responses to behaviorally relevant vocalizations in the mouse inferior colliculus (IC). We independently manipulated the frequency, amplitude, duration, and harmonic structure of the vocalizations to create a suite of modified vocalizations. Based on measures of both spike rate and timing, we characterized the heterogeneity of neural responses to the natural vocalizations and their perturbed variants. Using information theoretic measures, we found that heterogeneous response properties of IC neurons contribute to efficient encoding of behaviorally relevant vocalizations.},
	Author = {Holmstrom, Lars A. and Eeuwes, Lonneke B. M. and Roberts, Patrick D. and Portfors, Christine V.},
	Doi = {10.1523/JNEUROSCI.1964-09.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/MM8B7RCH/Holmstrom et al. - 2010 - Efficient Encoding of Vocalizations in the Auditor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EETQZ3DX/802.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = jan,
	Number = {3},
	Pages = {802--819},
	Pmid = {20089889},
	Title = {Efficient {Encoding} of {Vocalizations} in the {Auditory} {Midbrain}},
	Url = {http://www.jneurosci.org/content/30/3/802},
	Urldate = {2016-03-21},
	Volume = {30},
	Year = {2010},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/30/3/802},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1964-09.2010}}

@article{perani_neural_2011,
	Abstract = {The ability to learn language is a human trait. In adults and children, brain imaging studies have shown that auditory language activates a bilateral frontotemporal network with a left hemispheric dominance. It is an open question whether these activations represent the complete neural basis for language present at birth. Here we demonstrate that in 2-d-old infants, the language-related neural substrate is fully active in both hemispheres with a preponderance in the right auditory cortex. Functional and structural connectivities within this neural network, however, are immature, with strong connectivities only between the two hemispheres, contrasting with the adult pattern of prevalent intrahemispheric connectivities. Thus, although the brain responds to spoken language already at birth, thereby providing a strong biological basis to acquire language, progressive maturation of intrahemispheric functional connectivity is yet to be established with language exposure as the brain develops.},
	Author = {Perani, Daniela and Saccuman, Maria C. and Scifo, Paola and Anwander, Alfred and Spada, Danilo and Baldoli, Cristina and Poloniato, Antonella and Lohmann, Gabriele and Friederici, Angela D.},
	Doi = {10.1073/pnas.1102991108},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T8S43T3A/Perani et al. - 2011 - Neural language networks at birth.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/N7CD9C7K/16056.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {brain activity, dorsal pathway, newborns, ventral pathway},
	Language = {en},
	Month = sep,
	Number = {38},
	Pages = {16056--16061},
	Pmid = {21896765},
	Title = {Neural language networks at birth},
	Url = {http://www.pnas.org/content/108/38/16056},
	Urldate = {2014-05-28},
	Volume = {108},
	Year = {2011},
	Bdsk-Url-1 = {http://www.pnas.org/content/108/38/16056},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1102991108}}

@article{lloyd-fox_are_2015,
	Abstract = {Human interactions are guided by continuous communication among the parties involved, in which verbal communication plays a primary role. However, speech does not necessarily reveal to whom it is addressed, especially for young infants who are unable to decode its semantic content. To overcome such difficulty, adults often explicitly mark their communication as infant-directed. In the present study we investigated whether ostensive signals, which would disambiguate the infant as the addressee of a communicative act, would modulate the brain responses of 6-month-old infants to speech and gestures in an ecologically valid setting. In Experiment 1, we tested whether the gaze direction of the speaker modulates cortical responses to infant-direct speech. To provide a naturalistic environment, two infants and their parents participated at the same time. In Experiment 2, we tested whether a similar modulation of the cortical response would be obtained by varying the intonation (infant versus adult directed speech) of the speech during face-to-face communication, one on one. The results of both experiments indicated that only the combination of ostensive signals (infant directed speech and direct gaze) led to enhanced brain activation. This effect was indicated by responses localized in regions known to be involved in processing auditory and visual aspects of social communication. This study also demonstrated the potential of fNIRS as a tool for studying neural responses in naturalistic scenarios, and for simultaneous measurement of brain function in multiple participants.},
	Author = {Lloyd-Fox, Sarah and Sz{\'e}plaki-K{\"o}ll{\H o}d, Borb{\'a}la and Yin, Jun and Csibra, Gergely},
	Doi = {10.1016/j.cortex.2015.02.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F2FGEJ3X/Lloyd-Fox et al. - 2015 - Are you talking to me Neural activations in 6-mon.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VZ38G8EE/S0010945215000623.html:text/html},
	Issn = {0010-9452},
	Journal = {Cortex},
	Keywords = {Communication, Infant-directed speech, Ostensive signals, Social interactions, fNIRS},
	Month = sep,
	Number = {Supplement C},
	Pages = {35--48},
	Series = {Special issue: {Neuro}-cognitive mechanisms of social interaction},
	Shorttitle = {Are you talking to me?},
	Title = {Are you talking to me? {Neural} activations in 6-month-old infants in response to being addressed during natural interactions},
	Url = {http://www.sciencedirect.com/science/article/pii/S0010945215000623},
	Urldate = {2017-12-08},
	Volume = {70},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0010945215000623},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cortex.2015.02.005}}

@article{leaver_cortical_2010,
	Abstract = {How the brain processes complex sounds, like voices or musical instrument sounds, is currently not well understood. The features comprising the acoustic profiles of such sounds are thought to be represented by neurons responding to increasing degrees of complexity throughout auditory cortex, with complete auditory ``objects'' encoded by neurons (or small networks of neurons) in anterior superior temporal regions. Although specialized voice and speech--sound regions have been proposed, it is unclear how other types of complex natural sounds are processed within this object-processing pathway. Using functional magnetic resonance imaging, we sought to demonstrate spatially distinct patterns of category-selective activity in human auditory cortex, independent of semantic content and low-level acoustic features. Category-selective responses were identified in anterior superior temporal regions, consisting of clusters selective for musical instrument sounds and for human speech. An additional subregion was identified that was particularly selective for the acoustic--phonetic content of speech. In contrast, regions along the superior temporal plane closer to primary auditory cortex were not selective for stimulus category, responding instead to specific acoustic features embedded in natural sounds, such as spectral structure and temporal modulation. Our results support a hierarchical organization of the anteroventral auditory-processing stream, with the most anterior regions representing the complete acoustic signature of auditory objects.},
	Author = {Leaver, Amber M. and Rauschecker, Josef P.},
	Doi = {10.1523/JNEUROSCI.0296-10.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UJFX5IZW/Leaver et Rauschecker - 2010 - Cortical Representation of Natural Complex Sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TX6HCE4I/7604.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = feb,
	Number = {22},
	Pages = {7604--7612},
	Pmid = {20519535},
	Shorttitle = {Cortical {Representation} of {Natural} {Complex} {Sounds}},
	Title = {Cortical {Representation} of {Natural} {Complex} {Sounds}: {Effects} of {Acoustic} {Features} and {Auditory} {Object} {Category}},
	Url = {http://www.jneurosci.org/content/30/22/7604},
	Urldate = {2016-03-17},
	Volume = {30},
	Year = {2010},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/30/22/7604},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.0296-10.2010}}

@article{engineer_cortical_2008,
	Abstract = {Neural activity in the cerebral cortex can explain many aspects of sensory perception. Extensive psychophysical and neurophysiological studies of visual motion and vibrotactile processing show that the firing rate of cortical neurons averaged across 50--500 ms is well correlated with discrimination ability. In this study, we tested the hypothesis that primary auditory cortex (A1) neurons use temporal precision on the order of 1--10 ms to represent speech sounds shifted into the rat hearing range. Neural discrimination was highly correlated with behavioral performance on 11 consonant-discrimination tasks when spike timing was preserved and was not correlated when spike timing was eliminated. This result suggests that spike timing contributes to the auditory cortex representation of consonant sounds.},
	Author = {Engineer, Crystal T. and Perez, Claudia A. and Chen, YeTing H. and Carraway, Ryan S. and Reed, Amanda C. and Shetake, Jai A. and Jakkamsetti, Vikram and Chang, Kevin Q. and Kilgard, Michael P.},
	Copyright = {{\copyright} 2008 Nature Publishing Group},
	Doi = {10.1038/nn.2109},
	File = {Snapshot:/Users/Cecile/Zotero/storage/4BAS8JMD/nn.2109.html:text/html},
	Issn = {1097-6256},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = may,
	Number = {5},
	Pages = {603--608},
	Title = {Cortical activity patterns predict speech discrimination ability},
	Url = {http://www.nature.com/neuro/journal/v11/n5/full/nn.2109.html},
	Urldate = {2015-05-22},
	Volume = {11},
	Year = {2008},
	Bdsk-Url-1 = {http://www.nature.com/neuro/journal/v11/n5/full/nn.2109.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.2109}}

@incollection{werner_morphological_2012-1,
	Address = {New York, NY},
	Author = {Abdala, Carolina and Keefe, Douglas H.},
	Booktitle = {Human {Auditory} {Development}},
	Editor = {Werner, Lynne and Fay, Richard R. and Popper, Arthur N.},
	File = {Chapter 2.pdf:/Users/Cecile/Zotero/storage/HUV3P9V2/Chapter 2.pdf:application/pdf},
	Isbn = {978-1-4614-1420-9 978-1-4614-1421-6},
	Pages = {19--59},
	Publisher = {Springer New York},
	Title = {Morphological and {Functional} {Ear} {Development}},
	Url = {http://link.springer.com/10.1007/978-1-4614-1421-6_2},
	Urldate = {2015-07-30},
	Volume = {42},
	Year = {2012},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/978-1-4614-1421-6_2}}

@article{versfeld_relationship_2002,
	Abstract = {A conventional measure to determine the ability to understand speech in noisy backgrounds is the so-called speech reception threshold (SRT) for sentences. It yields the signal-to-noise ratio (in dB) for which half of the sentences are correctly perceived. The SRT defines to what degree speech must be audible to a listener in order to become just intelligible. There are indications that elderly listeners have greater difficulty in understanding speech in adverse listening conditions than young listeners. This may be partly due to the differences in hearing sensitivity (presbycusis), hence audibility, but other factors, such as temporal acuity, may also play a significant role. A potential measure for the temporal acuity may be the threshold to which speech can be accelerated, or compressed in time. A new test is introduced where the speech rate is varied adaptively. In analogy to the SRT, the time-compression threshold (or TCT) then is defined as the speech rate (expressed in syllables per second) for which half of the sentences are correctly perceived. In experiment I, the TCT test is introduced and normative data are provided. In experiment II, four groups of subjects (young and elderly normal-hearing and hearing-impaired subjects) participated, and the SRT's in stationary and fluctuating speech-shaped noise were determined, as well as the TCT. The results show that the SRT in fluctuating noise and the TCT are highly correlated. All tests indicate that, even after correction for the hearing loss, elderly normal-hearing subjects perform worse than young normal-hearing subjects. The results indicate that the use of the TCT test or the SRT test in fluctuating noise is preferred over the SRT test in stationary noise.},
	Author = {Versfeld, Niek J and Dreschler, Wouter A},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Adult, Age Factors, Aged, Aging, Audiometry, Pure-Tone, Cochlea, Female, Hearing Loss, Sensorineural, Humans, Male, Middle Aged, Noise, Speech, Time Factors, speech perception, Speech Perception},
	Language = {eng},
	Month = jan,
	Number = {1 Pt 1},
	Pages = {401--408},
	Pmid = {11831813},
	Title = {The relationship between the intelligibility of time-compressed speech and speech in noise in young and elderly listeners},
	Volume = {111},
	Year = {2002}}

@article{ip_brain_2016,
	Abstract = {Can bilingual exposure impact children's neural circuitry for learning to read? To answer this question, we investigated the brain bases of morphological awareness, one of the key spoken language abilities for learning to read in English and Chinese. Bilingual Chinese-English and monolingual English children (N = 22, ages 7--12) completed morphological tasks that best characterize each of their languages: compound morphology in Chinese (e.g. basket + ball = basketball) and derivational morphology in English (e.g. re + do = redo). In contrast to monolinguals, bilinguals showed greater activation in the left middle temporal region, suggesting that bilingual exposure to Chinese impacts the functionality of brain regions supporting semantic abilities. Similar to monolinguals, bilinguals showed greater activation in the left inferior frontal region [BA 45] in English than Chinese, suggesting that young bilinguals form language-specific neural representations. The findings offer new insights to inform bilingual and cross-linguistic models of language and literacy acquisition.},
	Author = {Ip, Ka I and Hsu, Lucy Shih-Ju and Arredondo, Maria M. and Tardif, Twila and Kovelman, Ioulia},
	Doi = {10.1111/desc.12449},
	File = {Snapshot:/Users/Cecile/Zotero/storage/QMFMKE5R/abstract\;jsessionid=C832552FBEDF17B8E7D44F65BECAC7B9.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = aug,
	Pages = {n/a--n/a},
	Title = {Brain bases of morphological processing in {Chinese}-{English} bilingual children},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12449/abstract},
	Urldate = {2016-11-01},
	Year = {2016},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12449/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12449}}

@article{turk-browne_babies_2008,
	Abstract = {Many prominent studies of infant cognition over the past two decades have relied on the fact that infants habituate to repeated stimuli -- i.e. that their looking times tend to decline upon repeated stimulus presentations. This phenomenon had been exploited to reveal a great deal about the minds of preverbal infants. Many prominent studies of the neural bases of adult cognition over the past decade have relied on the fact that brain regions habituate to repeated stimuli -- i.e. that the hemodynamic responses observed in fMRI tend to decline upon repeated stimulus presentations. This phenomenon has been exploited to reveal a great deal about the neural mechanisms of perception and cognition. Similarities in the mechanics of these two forms of habituation suggest that it may be useful to relate them to each other. Here we outline this analogy, explore its nuances, and highlight some ways in which the study of habituation in functional neuroimaging could yield novel insights into the nature of habituation in infant cognition -- and vice versa.},
	Author = {Turk-Browne, Nicholas B. and Scholl, Brian J. and Chun, Marvin M.},
	Doi = {10.3389/neuro.09.016.2008},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/EA8CT92D/Turk-Browne et al. - 2008 - Babies and Brains Habituation in Infant Cognition.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = dec,
	Pmcid = {PMC2605404},
	Pmid = {19104669},
	Shorttitle = {Babies and {Brains}},
	Title = {Babies and {Brains}: {Habituation} in {Infant} {Cognition} and {Functional} {Neuroimaging}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605404/},
	Urldate = {2017-08-03},
	Volume = {2},
	Year = {2008},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2605404/},
	Bdsk-Url-2 = {https://doi.org/10.3389/neuro.09.016.2008}}

@article{issa_human_2016,
	Abstract = {Tinnitus is the phantom perception of sound in the absence of an acoustic stimulus. To date, the purported neural correlates of tinnitus from animal models have not been adequately characterized with translational technology in the human brain. The aim of the present study was to measure changes in oxy-hemoglobin concentration from regions of interest (ROI; auditory cortex) and non-ROI (adjacent nonauditory cortices) during auditory stimulation and silence in participants with subjective tinnitus appreciated equally in both ears and in nontinnitus controls using functional near-infrared spectroscopy (fNIRS). Control and tinnitus participants with normal/near-normal hearing were tested during a passive auditory task. Hemodynamic activity was monitored over ROI and non-ROI under episodic periods of auditory stimulation with 750 or 8000âHz tones, broadband noise, and silence. During periods of silence, tinnitus participants maintained increased hemodynamic responses in ROI, while a significant deactivation was seen in controls. Interestingly, non-ROI activity was also increased in the tinnitus group as compared to controls during silence. The present results demonstrate that both auditory and select nonauditory cortices have elevated hemodynamic activity in participants with tinnitus in the absence of an external auditory stimulus, a finding that may reflect basic science neural correlates of tinnitus that ultimately contribute to phantom sound perception.},
	Author = {Issa, Mohamad and Bisconti, Silvia and Kovelman, Ioulia and Kileny, Paul and Basura, Gregory J.},
	Doi = {10.1155/2016/7453149},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/TNXZKFBW/Issa et al. - 2016 - Human Auditory and Adjacent Nonauditory Cerebral C.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WK5SEF2H/abs.html:application/xhtml+xml},
	Issn = {2090-5904},
	Journal = {Neural Plasticity},
	Language = {en},
	Month = mar,
	Pages = {e7453149},
	Title = {Human {Auditory} and {Adjacent} {Nonauditory} {Cerebral} {Cortices} {Are} {Hypermetabolic} in {Tinnitus} as {Measured} by {Functional} {Near}-{Infrared} {Spectroscopy} ({fNIRS})},
	Url = {http://www.hindawi.com/journals/np/2016/7453149/abs/},
	Urldate = {2016-11-01},
	Volume = {2016},
	Year = {2016},
	Bdsk-Url-1 = {http://www.hindawi.com/journals/np/2016/7453149/abs/},
	Bdsk-Url-2 = {https://doi.org/10.1155/2016/7453149}}

@article{obleser_what_2017,
	Author = {Obleser, Jonas and Henry, Molly J. and Lakatos, Peter},
	Doi = {10.1371/journal.pbio.2002794},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DDUKP3PB/Obleser et al. - 2017 - What do we talk about when we talk about rhythm.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5IVCBK97/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Biophysical simulations, Phase determination, Sensory perception, Sequence alignment, Sequence analysis, behavior, event-related potentials, Cognitive Science},
	Month = sep,
	Number = {9},
	Pages = {e2002794},
	Title = {What do we talk about when we talk about rhythm?},
	Url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002794},
	Urldate = {2017-10-17},
	Volume = {15},
	Year = {2017},
	Bdsk-Url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002794},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.2002794}}

@article{sevy_neuroimaging_2010,
	Abstract = {Cochlear implants (CI) are commonly used to treat deafness in young children. While many factors influence the ability of a deaf child who is hearing through a CI to develop speech and language skills, an important factor is that the CI has to stimulate the auditory cortex. Obtaining behavioral measurements from young children with CIs can often be unreliable. While a variety of noninvasive techniques can be used for detecting cortical activity in response to auditory stimuli, many have critical limitations when applied to the pediatric CI population. We tested the ability of near-infrared spectroscopy (NIRS) to detect cortical responses to speech stimuli in pediatric CI users. Neuronal activity leads to changes in blood oxy- and deoxy-hemoglobin concentrations that can be detected by measuring the transmission of near-infrared light through the tissue. To verify the efficacy of NIRS, we first compared auditory cortex responses measured with NIRS and fMRI in normal-hearing adults. We then examined four different participant cohorts with NIRS alone. Speech-evoked cortical activity was observed in 100\% of normal-hearing adults (11 of 11), 82\% of normal-hearing children (9 of 11), 78\% of deaf children who have used a CI \&gt; 4 months (28 of 36), and 78\% of deaf children who completed NIRS testing on the day of CI initial activation (7 of 9). Therefore, NIRS can measure cortical responses in pediatric CI users, and has the potential to be a powerful adjunct to current CI assessment tools.},
	Author = {Sevy, Alexander B. G. and Bortfeld, Heather and Huppert, Theodore J. and Beauchamp, Michael S. and Tonini, Ross E. and Oghalai, John S.},
	Doi = {10.1016/j.heares.2010.09.010},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T49PMQCH/S0378595510003904.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = dec,
	Number = {1--2},
	Pages = {39--47},
	Title = {Neuroimaging with near-infrared spectroscopy demonstrates speech-evoked activity in the auditory cortex of deaf children following cochlear implantation},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595510003904},
	Urldate = {2016-11-01},
	Volume = {270},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595510003904},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2010.09.010}}

@article{pollonini_auditory_2014,
	Abstract = {The primary goal of most cochlear implant procedures is to improve a patient's ability to discriminate speech. To accomplish this, cochlear implants are programmed so as to maximize speech understanding. However, programming a cochlear implant can be an iterative, labor-intensive process that takes place over months. In this study, we sought to determine whether functional near-infrared spectroscopy (fNIRS), a non-invasive neuroimaging method which is safe to use repeatedly and for extended periods of time, can provide an objective measure of whether a subject is hearing normal speech or distorted speech. We used a 140 channel fNIRS system to measure activation within the auditory cortex in 19 normal hearing subjects while they listed to speech with different levels of intelligibility. Custom software was developed to analyze the data and compute topographic maps from the measured changes in oxyhemoglobin and deoxyhemoglobin concentration. Normal speech reliably evoked the strongest responses within the auditory cortex. Distorted speech produced less region-specific cortical activation. Environmental sounds were used as a control, and they produced the least cortical activation. These data collected using fNIRS are consistent with the fMRI literature and thus demonstrate the feasibility of using this technique to objectively detect differences in cortical responses to speech of different intelligibility.},
	Author = {Pollonini, Luca and Olds, Cristen and Abaya, Homer and Bortfeld, Heather and Beauchamp, Michael S. and Oghalai, John S.},
	Doi = {10.1016/j.heares.2013.11.007},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9RMEBB8T/S0378595513002803.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = mar,
	Pages = {84--93},
	Title = {Auditory cortex activation to natural speech and simulated cochlear implant speech measured with functional near-infrared spectroscopy},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513002803},
	Urldate = {2016-11-01},
	Volume = {309},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513002803},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.11.007}}

@article{gratton_shedding_2001,
	Abstract = {One of the basic goals of cognitive psychology is the analysis of the covert processes that occur between stimulus and response. In the past 20--30 years, the tools available to cognitive psychologists have been augmented by a number of imaging techniques for studying the `brain in action' in a non-invasive manner. These techniques have their strength in either temporal or spatial information, but not both. We review here recent advances of a new approach, the event-related optical signal (EROS). This method allows measurements of the time course of neural activity in specific cortical structures, thus combining good spatial and temporal specificity. As an example, we show how EROS can be used to distinguish between serial and parallel models of information processing.},
	Author = {Gratton, Gabriele and Fabiani, Monica},
	Doi = {10.1016/S1364-6613(00)01701-0},
	File = {Snapshot:/Users/Cecile/Zotero/storage/D4HWJEED/S1364-6613(00)01701-0.html:text/html},
	Issn = {1364-6613, 1879-307X},
	Journal = {Trends in Cognitive Sciences},
	Keywords = {brain imaging, Event-Related Optical Signal, serial processing, parallel processing, optical imaging, Cognitive Science, Near-infrared spectroscopy},
	Language = {English},
	Month = aug,
	Number = {8},
	Pages = {357--363},
	Pmid = {11477005},
	Shorttitle = {Shedding light on brain function},
	Title = {Shedding light on brain function: the event-related optical signal},
	Url = {http://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(00)01701-0},
	Urldate = {2016-11-26},
	Volume = {5},
	Year = {2001},
	Bdsk-Url-1 = {http://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(00)01701-0},
	Bdsk-Url-2 = {https://doi.org/10.1016/S1364-6613(00)01701-0}}

@article{wallois_eeg-nirs_2010,
	Author = {Wallois, F. and Patil, A. and H{\'e}berl{\'e}, C. and Grebe, R.},
	Doi = {10.1016/j.neucli.2010.08.004},
	Issn = {09877053},
	Journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
	Language = {en},
	Month = nov,
	Number = {5-6},
	Pages = {281--292},
	Title = {{EEG}-{NIRS} in epilepsy in children and neonates},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0987705310000870},
	Urldate = {2016-11-01},
	Volume = {40},
	Year = {2010},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0987705310000870},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neucli.2010.08.004}}

@article{emberson_isolating_2016,
	Abstract = {Abstract. 
Functional near-infrared spectroscopy (fNIRS) records hemodynamic changes in the cortex arising from neurovascular coupling. However, (noninvasive) fNIRS recordings also record surface vascular signals arising from noncortical sources (e.g., in the skull, skin, dura, and other tissues located between the sensors and the brain). A current and important focus in the fNIRS community is determining how to remove these noncortical vascular signals to reduce noise and to prevent researchers from erroneously attributing responses to cortical sources. The current study is the first to test a popular method for removing signals from the surface vasculature (removing short, 1 cm, channel recordings from long, 3 cm, channel recordings) in human infants, a population frequently studied using fNIRS. We find evidence that this method does remove surface vasculature signals and indicates the presence of both local and global surface vasculature signals. However, we do not find that the removal of this information changes the statistical inferences drawn from the data. This latter result not only questions the importance of removing surface vasculature responses for empiricists employing this method, but also calls for future research using other tasks (e.g., ones with a weaker initial result) with this population and possibly additional methods for removing signals arising from the surface vasculature in infants.},
	Author = {Emberson, Lauren L. and Crosswhite, Stephen L. and Goodwin, James R. and Berger, Andrew J. and Aslin, Richard N.},
	Doi = {10.1117/1.NPh.3.3.031406},
	Issn = {2329-423X},
	Journal = {Neurophotonics},
	Number = {3},
	Pages = {031406--031406},
	Shorttitle = {Isolating the effects of surface vasculature in infant neuroimaging using short-distance optical channels},
	Title = {Isolating the effects of surface vasculature in infant neuroimaging using short-distance optical channels: a combination of local and global effects},
	Url = {http://dx.doi.org/10.1117/1.NPh.3.3.031406},
	Urldate = {2016-11-01},
	Volume = {3},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1117/1.NPh.3.3.031406}}

@article{tanner_how_2015,
	Abstract = {Although it is widely known that high-pass filters can reduce the amplitude of slow ERP components, these filters can also introduce artifactual peaks that lead to incorrect conclusions. To demonstrate this and provide evidence about optimal filter settings, we recorded ERPs in a typical language processing paradigm involving syntactic and semantic violations. Unfiltered results showed standard N400 and P600 effects in the semantic and syntactic violation conditions, respectively. However, high-pass filters with cutoffs at 0.3 Hz and above produced artifactual effects of opposite polarity before the true effect. That is, excessive high-pass filtering introduced a significant N400 effect preceding the P600 in the syntactic condition, and a significant P2 effect preceding the N400 in the semantic condition. Thus, inappropriate use of high-pass filters can lead to false conclusions about which components are influenced by a given manipulation. The present results also lead to practical recommendations for high-pass filter settings that maximize statistical power while minimizing filtering artifacts.},
	Author = {Tanner, Darren and Morgan-Short, Kara and Luck, Steven J.},
	Doi = {10.1111/psyp.12437},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/23X7U5IT/Tanner et al. - 2015 - How inappropriate high-pass filters can produce ar.pdf:application/pdf},
	Issn = {0048-5772},
	Journal = {Psychophysiology},
	Month = aug,
	Number = {8},
	Pages = {997--1009},
	Pmcid = {PMC4506207},
	Pmid = {25903295},
	Title = {How inappropriate high-pass filters can produce artifactual effects and incorrect conclusions in {ERP} studies of language and cognition},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4506207/},
	Urldate = {2016-12-13},
	Volume = {52},
	Year = {2015},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4506207/},
	Bdsk-Url-2 = {https://doi.org/10.1111/psyp.12437}}

@article{osullivan_evidence_2015,
	Abstract = {The human brain has evolved to operate effectively in highly complex acoustic environments, segregating multiple sound sources into perceptually distinct auditory objects. A recent theory seeks to explain this ability by arguing that stream segregation occurs primarily due to the temporal coherence of the neural populations that encode the various features of an individual acoustic source. This theory has received support from both psychoacoustic and functional magnetic resonance imaging (fMRI) studies that use stimuli which model complex acoustic environments. Termed stochastic figure--ground (SFG) stimuli, they are composed of a ``figure'' and background that overlap in spectrotemporal space, such that the only way to segregate the figure is by computing the coherence of its frequency components over time. Here, we extend these psychoacoustic and fMRI findings by using the greater temporal resolution of electroencephalography to investigate the neural computation of temporal coherence. We present subjects with modified SFG stimuli wherein the temporal coherence of the figure is modulated stochastically over time, which allows us to use linear regression methods to extract a signature of the neural processing of this temporal coherence. We do this under both active and passive listening conditions. Our findings show an early effect of coherence during passive listening, lasting from â¼115 to 185 ms post-stimulus. When subjects are actively listening to the stimuli, these responses are larger and last longer, up to â¼265 ms. These findings provide evidence for early and preattentive neural computations of temporal coherence that are enhanced by active analysis of an auditory scene.},
	Author = {O'Sullivan, James A. and Shamma, Shihab A. and Lalor, Edmund C.},
	Doi = {10.1523/JNEUROSCI.4973-14.2015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/MF5364HA/O'Sullivan et al. - 2015 - Evidence for Neural Computations of Temporal Coher.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GK6DXHT3/7256.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Keywords = {Auditory scene analysis, denoising source separation (DSS), electroencephalography (EEG), stream segregation, temporal coherence, temporal response function (TRF)},
	Language = {en},
	Month = jun,
	Number = {18},
	Pages = {7256--7263},
	Pmid = {25948273},
	Title = {Evidence for {Neural} {Computations} of {Temporal} {Coherence} in an {Auditory} {Scene} and {Their} {Enhancement} during {Active} {Listening}},
	Url = {http://www.jneurosci.org/content/35/18/7256},
	Urldate = {2016-05-11},
	Volume = {35},
	Year = {2015},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/35/18/7256},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.4973-14.2015}}

@article{molavi_analyzing_2014,
	Abstract = {We have evaluated the use of phase synchronization to identify resting state functional connectivity (RSFC) in the language system in infants using functional near infrared spectroscopy (fNIRS). We used joint probability distribution of phase between fNIRS channels with a seed channel in the language area to estimate phase relations and to identify the language system network. Our results indicate the feasibility of this method in identifying the language system. The connectivity maps are consistent with anatomical cortical connections and are also comparable to those obtained from functional magnetic resonance imaging (fMRI) functional connectivity studies. The results also indicate left hemisphere lateralization of the language network.},
	Author = {Molavi, Behnam and May, Lillian and Gervain, Judit and Carreiras, Manuel and Werker, Janet F. and Dumont, Guy A.},
	Doi = {10.3389/fnhum.2013.00921},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/87Z2CE4B/Molavi et al. - 2014 - Analyzing the resting state functional connectivit.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = jan,
	Pmcid = {PMC3905209},
	Pmid = {24523685},
	Title = {Analyzing the resting state functional connectivity in the human language system using near infrared spectroscopy},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3905209/},
	Urldate = {2016-12-12},
	Volume = {7},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3905209/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2013.00921}}

@article{wagner_neural_2011,
	Abstract = {An essential aspect of infant language development involves the extraction of meaningful information from a continuous stream of auditory input. Studies have identified early abilities to differentiate auditory input along various dimensions, including the presence or absence of structural regularities. In newborn infants, frontal and temporal regions were found to respond differentially to these regularities (Gervain et al., 2008), and in order to examine the development of this abstract rule-learning we presented 7- and 9-month-old infants with syllables containing an ABB pattern (e.g., ``balolo'') or an ABC pattern (e.g., ``baloti'') and measured activity in left and right lateral brain regions using near-infrared spectroscopy (NIRS). While prior newborn work found increases in oxyhemoglobin (oxyHb) activity in response to ABB blocks as compared to ABC blocks in anterior regions, 7- and 9-month-olds showed no differentiation between grammars in oxyHb. However, changes in deoxyhemoglobin (deoxyHb) pointed to a developmental shift, whereby 7-month-olds showed deoxyHb responding significantly different from zero for ABB blocks, but not ABC blocks, and 9-month-olds showed the opposite pattern, with deoxyHb responding significantly different from zero for the ABC blocks but not the ABB blocks. DeoxyHb responses were more pronounced over anterior regions. A grammar by time interaction also illustrated that during the early blocks, deoxyHb was significantly greater to ABC than in later blocks, but there was no change in ABB activation over time. The shift from stronger activation to ABB in newborns (Gervain et al., 2008) and 7-month-olds in the present study to stronger activation to ABC by 9-month-olds here is discussed in terms of changes in stimulus salience and novelty preference over the first year of life. The present discussion also highlights the importance of future work exploring the coupling between oxyHb and deoxyHb activation in infant NIRS studies.},
	Author = {Wagner, Jennifer B. and Fox, Sharon E. and Tager-Flusberg, Helen and Nelson, Charles A.},
	Doi = {10.3389/fpsyg.2011.00168},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/33RIRFNM/Wagner et al. - 2011 - Neural Processing of Repetition and Non-Repetition.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {NIRS, auditory processing, infancy, optical imaging, language},
	Language = {English},
	Title = {Neural {Processing} of {Repetition} and {Non}-{Repetition} {Grammars} in 7- and 9-{Month}-{Old} {Infants}},
	Url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00168/abstract},
	Urldate = {2017-02-20},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00168/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00168}}

@article{husain_review_2005,
	Abstract = {Neonatal electroencephalography (EEG) presents some of the most difficult challenges in EEG interpretation. It differs significantly in many ways from EEG of older children and adults. Technologically, acquisition of a neonatal EEG is significantly more difficult and different than an adult EEG. There are numerous features that are age-specific and change almost week-to-week in the preterm infant. Some features may be normal at one age and abnormal if they persist for several weeks. Many of these features also have different implications in neonates as compared to older individuals. These issues mandate a different approach to neonatal EEG interpretation. In this article an overview of neonatal EEG is presented. After a brief discussion of relevant technical issues, various normal EEG features encountered in neonates are discussed. This is followed by a discussion of the ontogeny of EEG, starting from the age of viability to the first few months of life. A description of various abnormalities follows. Finally, an approach to analysis of a neonatal EEG is presented.},
	Author = {Husain, Aatif M.},
	File = {Review_of_Neonatal_EEG.pdf:/Users/Cecile/Zotero/storage/5DP4GWZ7/Review_of_Neonatal_EEG.pdf:application/pdf},
	Issn = {1086-508X},
	Journal = {American Journal of Electroneurodiagnostic Technology},
	Keywords = {Brain Mapping, Electroencephalography, Humans, Infant, Newborn, Infant, Newborn, Diseases, Brain Diseases, Diagnosis, Computer-Assisted, Practice Guidelines as Topic, Practice Patterns, Physicians', Sleep, Sleep Wake Disorders},
	Language = {eng},
	Month = mar,
	Number = {1},
	Pages = {12--35},
	Pmid = {15832672},
	Title = {Review of neonatal {EEG}},
	Volume = {45},
	Year = {2005}}

@article{pefkou_theta-_2017,
	Abstract = {Recent psychophysics data suggest that speech perception is not limited by the capacity of the auditory system to encode fast acoustic variations through neural gamma activity, but rather by the time given to the brain to decode them. Whether the decoding process is bounded by the capacity of theta rhythm to follow speech syllabic rhythm, or constrained by a more endogenous top-down mechanism, e.g. involving beta activity, is unknown. We addressed the dynamics of auditory decoding in speech comprehension by challenging syllable tracking and speech decoding using comprehensible and incomprehensible time-compressed auditory sentences. We measured EEG in human participants and found that neural activity in both theta and gamma ranges was sensitive to syllabic rate. Phase patterns of slow neural activity consistently followed the syllabic rate (4---14 Hz), even when this rate went beyond the classical theta range (4---8 Hz). The power of theta activity increased linearly with syllabic rate but showed no sensitivity to comprehension. Conversely, the power of beta (14---21 Hz) activity was insensitive to syllabic rate, yet reflected comprehension on a single trial basis. Consistent with their role in stimulus driven versus endogenous mechanisms, we found different long-range dynamics for theta and beta activity, with beta activity building up in time while more contextual information becomes available. These data show that speech comprehension is constrained by concurrent stimulus-driven theta and low-gamma activity, and by endogenous beta activity, but not primarily by the capacity of theta activity to track the syllabic rhythm.
SIGNIFICANCE STATEMENT
Speech comprehension partly depends on the ability of the auditory cortex to track syllable boundaries with theta-range neural oscillations. The reason comprehension drops when speech is accelerated could hence be because theta oscillations can no longer follow the syllabic rate. Here, we presented subjects with comprehensible and incomprehensible accelerated speech, and show that neural phase patterns in the theta band consistently reflect the syllabic rate, even when speech becomes too fast to be intelligible. The drop in comprehension, however, is signaled by a significant decrease in the power of low-beta oscillations (14---21 Hz). These data suggest that speech comprehension is not limited by the capacity of theta oscillations to adapt to syllabic rate, but by an endogenous decoding process.},
	Author = {Pefkou, Maria and Arnal, Luc H. and Fontolan, Lorenzo and Giraud, Anne-Lise},
	Copyright = {Copyright {\copyright} 2017 the authors},
	Doi = {10.1523/JNEUROSCI.2882-16.2017},
	File = {pefkou2017.pdf:/Users/Cecile/Zotero/storage/BGQZXB8K/pefkou2017.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/F94TET3S/JNEUROSCI.2882-16.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = jul,
	Pages = {2882--16},
	Pmid = {28729443},
	Title = {Theta- and beta-band neural activity reflect independent syllable tracking and comprehension of time-compressed speech},
	Url = {http://www.jneurosci.org/content/early/2017/07/20/JNEUROSCI.2882-16.2017},
	Urldate = {2017-10-24},
	Year = {2017},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/early/2017/07/20/JNEUROSCI.2882-16.2017},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2882-16.2017}}

@article{gliga_development_2007,
	Abstract = {Do infants perceive visual cues as diverse as frontal-view faces, profiles or bodies as being different aspects of the same object, a fellow human? If that is the case, visual exposure to one such cue should facilitate the subsequent processing of the others. To verify this hypothesis, we recorded event-related responses in 4-month-old infants and in adults. Pictures of eyes were interleaved amongst images belonging to three human contexts (frontal-view faces, profiles or bodies) or non-human contexts (houses, cars or pliers). In adults, both profile and frontal-face contexts elicited suppression of the N170 response to eye pictures, indicating an access to a view-invariant representation of faces. In infants, a response suppression of the N290 component was recorded only in the context of frontal faces, while profile context induces a different effect (i.e., a P400 enhancement) on eye processing. This dissociation suggests that the view-invariant representation of faces is learned, as it is for other 3-D objects and needs more than 4 months of exposure to be established. In a follow-up study, where infants were exposed to a short movie showing people rotating their heads, the profile-induced P400 effect was speeded up, indicating that exposure to successive views of the same object is probably a way to build up adult-like face representations.},
	Author = {Gliga, Teodora and Dehaene-Lambertz, Ghislaine},
	Doi = {10.1016/j.cognition.2006.01.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/P55DTJ6W/Gliga et Dehaene-Lambertz - 2007 - Development of a view-invariant representation of .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UNM2ERKD/S0010027706000187.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Keywords = {ERPs, Infant face perception, N170, Response suppression, View invariance},
	Month = feb,
	Number = {2},
	Pages = {261--288},
	Title = {Development of a view-invariant representation of the human head},
	Url = {http://www.sciencedirect.com/science/article/pii/S0010027706000187},
	Urldate = {2017-02-17},
	Volume = {102},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0010027706000187},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cognition.2006.01.004}}

@article{naatanen_mismatch_1995,
	Abstract = {Physically deviant auditory stimuli occurring among frequent ("standard") stimuli (e.g., tones or phonetic stimuli) elicit the mismatch negativity (MMN) of the auditory event-related potential (ERP). The MMN is presumably generated by a mismatch process between the sensory input from a deviant stimulus and a neural sensory-memory trace representing the physical features of the standard stimulus. This process, as well as sensory analysis of auditory input and its encoding into the memory trace, appear to be automatic since the MMN is elicited even by changes in unattended auditory stimuli. Therefore the MMN indirectly provides a unique, objective measure of the central representation of a sound. This opens new possibilities for basic research as well as clinical and other applications.},
	Author = {N{\"a}{\"a}t{\"a}nen, R. and Alho, K.},
	Issn = {0020-7454},
	Journal = {The International Journal of Neuroscience},
	Keywords = {Adolescent, Adult, Age Factors, Aged, Aging, Auditory Perception, Evoked Potentials, Auditory, Humans, Learning, Automatism, Blindness, Memory, Middle Aged, Neural Pathways, Neuronal Plasticity, Brain},
	Language = {eng},
	Number = {1-4},
	Pages = {317--337},
	Pmid = {7775056},
	Title = {Mismatch negativity--a unique measure of sensory processing in audition},
	Volume = {80},
	Year = {1995}}

@article{fishman_mechanisms_2014,
	Abstract = {The mismatch negativity (MMN) is a pre-attentive auditory event-related potential (ERP) component that is elicited by a change in a repetitive acoustic pattern. It is obtained by subtracting responses evoked by frequent 'standard' sounds from responses evoked by infrequent 'deviant' sounds that differ from the standards along some acoustic dimension, e.g., frequency, intensity, or duration, or abstract feature. The MMN has been attributed to neural generators within the temporal and frontal lobes. The mechanisms and meaning of the MMN continue to be debated. Two dominant explanations for the MMN have been proposed. According to the "neural adaptation" hypothesis, repeated presentation of the standards results in adapted (i.e., attenuated) responses of feature-selective neurons in auditory cortex. Rare deviant sounds activate neurons that are less adapted than those stimulated by the frequent standard sounds, and thus elicit a larger 'obligatory' response, which yields the MMN following the subtraction procedure. In contrast, according to the "sensory memory" hypothesis, the MMN is a 'novel' (non-obligatory) ERP component that reflects a deviation between properties of an incoming sound and those of a neural 'memory trace' established by the preceding standard sounds. Here, we provide a selective review of studies which are relevant to the controversy between proponents of these two interpretations of the MMN. We also present preliminary neurophysiological data from monkey auditory cortex with potential implications for the debate. We conclude that the mechanisms and meaning of the MMN are still unresolved and offer remarks on how to make progress on these important issues.},
	Author = {Fishman, Yonatan I.},
	Doi = {10.1007/s10548-013-0337-3},
	Issn = {1573-6792},
	Journal = {Brain Topography},
	Keywords = {Animals, Attention, Auditory Perception, Evoked Potentials, Auditory, Humans, Adaptation, Physiological, Male, Memory, Macaca, Auditory cortex},
	Language = {eng},
	Month = jul,
	Number = {4},
	Pages = {500--526},
	Pmid = {24276221},
	Title = {The mechanisms and meaning of the mismatch negativity},
	Volume = {27},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10548-013-0337-3}}

@article{arichi_development_2012,
	Abstract = {In the rodent brain the hemodynamic response to a brief external stimulus changes significantly during development. Analogous changes in human infants would complicate the determination and use of the hemodynamic response function (HRF) for functional magnetic resonance imaging (fMRI) in developing populations. We aimed to characterize HRF in human infants before and after the normal time of birth using rapid sampling of the Blood Oxygen Level Dependent (BOLD) signal. A somatosensory stimulus and an event related experimental design were used to collect data from 10 healthy adults, 15 sedated infants at term corrected post menstrual age (PMA) (median 41 + 1 weeks), and 10 preterm infants (median PMA 34 + 4 weeks). A positive amplitude HRF waveform was identified across all subject groups, with a systematic maturational trend in terms of decreasing time-to-peak and increasing positive peak amplitude associated with increasing age. Application of the age-appropriate HRF models to fMRI data significantly improved the precision of the fMRI analysis. These findings support the notion of a structured development in the brain's response to stimuli across the last trimester of gestation and beyond., âº First systematic characterization of the BOLD signal HRF in human neonates. âº A maturational trend in HRF morphology was identified. âº Application of empirical HRF models significantly improved neonatal fMRI analysis.},
	Author = {Arichi, Tomoki and Fagiolo, Gianlorenzo and Varela, Marta and Melendez-Calderon, Alejandro and Allievi, Alessandro and Merchant, Nazakat and Tusor, Nora and Counsell, Serena J. and Burdet, Etienne and Beckmann, Christian F. and Edwards, A. David},
	Doi = {10.1016/j.neuroimage.2012.06.054},
	Issn = {1053-8119},
	Journal = {Neuroimage},
	Month = nov,
	Number = {2},
	Pages = {663--673},
	Pmcid = {PMC3459097},
	Pmid = {22776460},
	Title = {Development of {BOLD} signal hemodynamic responses in the human brain},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459097/},
	Urldate = {2016-12-19},
	Volume = {63},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459097/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.06.054}}

@article{lin_non-invasive_2013,
	Abstract = {Perinatal brain injury remains a significant cause of infant mortality and morbidity, but there is not yet an effective bedside tool that can accurately screen for brain injury, monitor injury evolution, or assess response to therapy. The energy used by neurons is derived largely from tissue oxidative metabolism, and neural hyperactivity and cell death are reflected by corresponding changes in cerebral oxygen metabolism (CMROâ). Thus, measures of CMROâ are reflective of neuronal viability and provide critical diagnostic information, making CMROâ an ideal target for bedside measurement of brain health. Brain-imaging techniques such as positron emission tomography (PET) and single-photon emission computed tomography (SPECT) yield measures of cerebral glucose and oxygen metabolism, but these techniques require the administration of radionucleotides, so they are used in only the most acute cases. Continuous-wave near-infrared spectroscopy (CWNIRS) provides non-invasive and non-ionizing radiation measures of hemoglobin oxygen saturation (SOâ) as a surrogate for cerebral oxygen consumption. However, SOâ is less than ideal as a surrogate for cerebral oxygen metabolism as it is influenced by both oxygen delivery and consumption. Furthermore, measurements of SOâ are not sensitive enough to detect brain injury hours after the insult, because oxygen consumption and delivery reach equilibrium after acute transients. We investigated the possibility of using more sophisticated NIRS optical methods to quantify cerebral oxygen metabolism at the bedside in healthy and brain-injured newborns. More specifically, we combined the frequency-domain NIRS (FDNIRS) measure of SO2 with the diffuse correlation spectroscopy (DCS) measure of blood flow index (CBFi) to yield an index of CMROâ (CMROâi). With the combined FDNIRS/DCS system we are able to quantify cerebral metabolism and hemodynamics. This represents an improvement over CWNIRS for detecting brain health, brain development, and response to therapy in neonates. Moreover, this method adheres to all neonatal intensive care unit (NICU) policies on infection control and institutional policies on laser safety. Future work will seek to integrate the two instruments to reduce acquisition time at the bedside and to implement real-time feedback on data quality to reduce the rate of data rejection.},
	Author = {Lin, Pei-Yi and Roche-Labarbe, Nadege and Dehaes, Mathieu and Carp, Stefan and Fenoglio, Angela and Barbieri, Beniamino and Hagan, Katherine and Grant, P. Ellen and Franceschini, Maria Angela},
	Doi = {10.3791/4379},
	Issn = {1940-087X},
	Journal = {Journal of Visualized Experiments: JoVE},
	Keywords = {Hemodynamics, Humans, Infant, Cerebrovascular Circulation, Oxygen Consumption, Spectrum Analysis, Oxygen, Sulfur Dioxide, Spectroscopy, Near-Infrared, optical imaging, Brain},
	Language = {eng},
	Month = mar,
	Number = {73},
	Pages = {e4379},
	Pmcid = {PMC3639513},
	Pmid = {23524854},
	Title = {Non-invasive optical measurement of cerebral metabolism and hemodynamics in infants},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.3791/4379}}

@article{seghier_functional_2006,
	Abstract = {Summary
In order to provide accurate prognosis and developmental intervention to newborns, new methods of assessing cerebral functions are needed. The non-invasive technique of functional magnetic resonance imaging (fMRI) can be considered as the leading technique for functional exploration of the infant's brain. Several studies have previously applied fMRI in both healthy and diseased newborns with different sensory and cognitive tasks. In this chapter, the methodological issues that are proper to the use of fMRI in the newborn are detailed. In addition, an overview of the major findings of previous fMRI studies is provided, with a focus on notable differences from those in adult subjects. More specifically, the functional responses and the localization of cortical activations in healthy and diseased newborns are discussed. We expect a rapid expansion of this field and the establishment of fMRI as a valid clinical diagnostic tool in the newborn.},
	Author = {Seghier, Mohamed L. and Lazeyras, Francois and Huppi, Petra S.},
	Doi = {10.1016/j.siny.2006.07.007},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/U3VHGM8T/Seghier et al. - 2006 - Functional MRI of the newborn.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7KA9Z55Q/S1744165X06000734.html:text/html},
	Issn = {1744-165X},
	Journal = {Seminars in Fetal and Neonatal Medicine},
	Keywords = {BOLD response, Brain activation, Brain plasticity, Functional MRI, Maturation, Newborn},
	Month = dec,
	Number = {6},
	Pages = {479--488},
	Series = {Assessing {Brain} {Function} in the {Perinatal} {Period}},
	Title = {Functional {MRI} of the newborn},
	Url = {http://www.sciencedirect.com/science/article/pii/S1744165X06000734},
	Urldate = {2016-12-19},
	Volume = {11},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1744165X06000734},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.siny.2006.07.007}}

@article{marin-padilla_human_2012,
	Abstract = {The capillary from the meningeal inner pial lamella play a crucial role in the development and structural organization of the cerebral cortex extrinsic and intrinsic microvascular compartments. Only pial capillaries are capable of perforating through the cortex external glial limiting membrane (EGLM) to enter into the nervous tissue, although incapable of perforating the membrane to exit the brain. Circulatory dynamics and functional demands determine which capillaries become arterial and which capillaries become venous. The perforation of the cortex EGLM by pial capillaries is a complex process characterized by three fundamental stages: (1) pial capillary contact with the EGLM with fusion of vascular and glial basal laminae at the contact site, (2) endothelial cell filopodium penetration through the fussed laminae with the formation of a funnel between them that accompanies it into the nervous tissue while remaining open to the meningeal interstitium and, (3) penetration of the whole capillary carrying the open funnel with it and establishing an extravascular Virchow-Robin Compartment (V-RC) that maintains the perforating vessel extrinsic (outside) the nervous tissue through its entire length. The V-RC is walled internally by the vascular basal lamina and externally by the basal lamina of joined glial cells endfeet. The VRC outer glial wall appear as an extension of the cortex superficial EGLM. All the perforating vessels within the V-RCs constitute the cerebral cortex extrinsic microvascular compartment. These perforating vessels are the only one capable of responding to inflammatory insults. The V-RC remains open (for life) to the meningeal interstitium permitting the exchanges of fluid and of cells between brain and meninges. The V-RC function as the brain sole drainage (prelymphatic) system in both physiological as well as pathological situations. During cortical development, capillaries emerge from the perforating vessels, by endothelial cells growing sprouts analogous to their angiogenesis, entering into their corresponding V-RCs. These new capillaries to enter into the nervous tissue must perforate through the V-RC outer glial wall, a process analogous to the original perforation of the cortex EGLM by pial capillaries. These emerging capillaries are incapable of reentering the V-RCs and/or perforating vessels. As the new capillary enters into the nervous tissue, it becomes surrounded by glial endfeet and carries a single basal lamina (possibly glial). Capillaries emerging from contiguous perforators establish an anastomotic plexus between them, by mechanisms still poorly understood. The capillaries of this anastomotic plexus constitute the cerebral cortex intrinsic microvascular compartment and together constitute the so-called blood-brain-barrier. The intrinsic capillaries are changing and readapting continuously, by both active angiogenesis and reabsorption, to the gray matter neurons developmental and functional needs. The brain intrinsic capillaries are among the most active microvessels of the human body. Unresolved developmental and functional aspects concerning the cerebral cortex intrinsic capillary plexus need to be further investigated.},
	Author = {Mar{\'\i}n-Padilla, Miguel},
	Doi = {10.3389/fnana.2012.00038},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/FZKXGCPX/Mar{\'\i}n-Padilla - 2012 - The human brain intracerebral microvascular system.pdf:application/pdf},
	Issn = {1662-5129},
	Journal = {Frontiers in Neuroanatomy},
	Month = sep,
	Pmcid = {PMC3440694},
	Pmid = {22993505},
	Shorttitle = {The human brain intracerebral microvascular system},
	Title = {The human brain intracerebral microvascular system: development and structure},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3440694/},
	Urldate = {2016-12-19},
	Volume = {6},
	Year = {2012},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3440694/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnana.2012.00038}}

@article{lloyd-fox_cortical_2017,
	Abstract = {Brain and nervous system development in human infants during the first 1000 days (conception to two years of age) is critical, and compromised development during this time (such as from under nutrition or poverty) can have life-long effects on physical growth and cognitive function. Cortical mapping of cognitive function during infancy is poorly understood in resource-poor settings due to the lack of transportable and low-cost neuroimaging methods. Having established a signature cortical response to social versus non-social visual and auditory stimuli in infants from 4 to 6 months of age in the UK, here we apply this functional Near Infrared Spectroscopy (fNIRS) paradigm to investigate social responses in infants from the first postnatal days to the second year of life in two contrasting environments: rural Gambian and urban UK. Results reveal robust, localized, socially selective brain responses from 9--24 months of life to both the visual and auditory stimuli. In contrast at 0--2 months of age infants exhibit non-social auditory selectivity, an effect that persists until 4--8 months when we observe a transition to greater social stimulus selectivity. These findings reveal a robust developmental curve of cortical specialization over the first two years of life.},
	Author = {Lloyd-Fox, S. and Begus, K. and Halliday, D. and Pirazzoli, L. and Blasi, A. and Papademetriou, M. and Darboe, M. K. and Prentice, A. M. and Johnson, M. H. and Moore, S. E. and Elwell, C. E.},
	Doi = {10.1016/j.dcn.2016.11.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SPQ4RW59/Lloyd-Fox et al. - Cortical specialisation to social stimuli from the.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H5CVHHBF/S1878929316301840.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {low- and middle-income countries, nutrition, poverty, social cognition, fNIRS, infancy},
	Month = jun,
	Pages = {92--104},
	Shorttitle = {Cortical specialisation to social stimuli from the first days to the second year of life},
	Title = {Cortical specialisation to social stimuli from the first days to the second year of life: {A} rural {Gambian} cohort.},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929316301840},
	Urldate = {2016-12-21},
	Volume = {25},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316301840},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2016.11.005}}

@article{lloyd-fox_fnirs_2016,
	Abstract = {The goal of our work is to establish assessments to evaluate the impact of early risk on cognitive development in infancy and childhood in global health settings. Prior work using functional near-infrared spectroscopy (fNIRS) has shown differential brain responses in infants to social vs. nonsocial stimuli in urban European (Lloyd-Fox et al., 2009; 2013) cohorts. This experimental paradigm has been proposed as an objective measure of social cognition that can be used in many different cohorts with minimal adaptation.
Cortical mapping of the brain during infancy is rarely undertaken in low-income countries due to the lack of transportable neuroimaging methods. Functional near infrared spectroscopy (fNIRS) - which uses the absorption of near infrared light to non-invasively measure changes in oxygen in the blood - is an elegant method for assessing cognitive function in such settings. Participants, ranging in age from 4 -- 8 months (UK: N = 64; The Gambia: N = 24; Bangladesh: N = 23), were tested with a multi-channel NIRS system that recorded brain activity over the frontal and temporal cortices. The experimental stimuli presented were videos of people moving their eyes or hands (i.e. a ``Peek-a-boo'' game), accompanied by vocal sounds (i.e. yawn, laughter), non-vocal sounds (i.e. water running, bell), or silence. Social videos were alternated with control blocks of pictures of local modes of transportation presented with no sounds.
Here we present a comparison of data collected in urban European, rural African and urban Asian cohorts. Participants in The Gambia lived in a rural community of subsistence farmers and participants in Bangladesh lived in an urban slum. Both cohorts were exposed to a broad range of adversity early in life including poverty, under-nourishment, recurrent infections, and lack of maternal education.
Our results indicate specialised social {\textgreater} non-social activation in the superior and middle temporal cortex across all three cohorts and across 4 -- 36 months of life. These results confirm the suitability of fNIRS in this age group in a resource poor setting. Changes in cortical haemoglobin may afford early biomarkers that are more sensitive to nutritional insults and early adversity affecting cognition than current standardised behavioural measures.
Support or Funding Information
Bill and Melinda Gates Foundation, Medical Research Council UK,},
	Author = {Lloyd-Fox, Sarah and Moore, Sophie and Darboe, Momodou and Prentice, Andrew and Papademetriou, Maria and Blasi, Anna and Kumar, Swapna and Westerlund, Alissa and Perdue, Katherine L. and Johnson, Mark H. and Nelson, Charles A. and Elwell, Clare E.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/PIHKKW97/1149.18.html:text/html},
	Issn = {0892-6638, 1530-6860},
	Journal = {The FASEB Journal},
	Language = {en},
	Month = jan,
	Number = {1 Supplement},
	Pages = {1149.18--1149.18},
	Shorttitle = {{fNIRS} in {Africa} \& {Asia}},
	Title = {{fNIRS} in {Africa} \& {Asia}: an {Objective} {Measure} of {Cognitive} {Development} for {Global} {Health} {Settings}},
	Url = {http://www.fasebj.org/content/30/1_Supplement/1149.18},
	Urldate = {2016-12-21},
	Volume = {30},
	Year = {2016},
	Bdsk-Url-1 = {http://www.fasebj.org/content/30/1_Supplement/1149.18}}

@article{henson_neural_2003,
	Abstract = {Repeated stimulus processing is often associated with a reduction in neural activity, as measured by single-cell recording or by haemodynamic imaging techniques like PET and fMRI. These reductions are sometimes linked to the behavioural phenomenon of priming. In this article, we discuss issues relevant to theories that attempt to relate these phenomena, concentrating in particular on the interpretative limitations of current imaging techniques.},
	Author = {Henson, R. N. A and Rugg, M. D},
	Doi = {10.1016/S0028-3932(02)00159-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/8J6GIDR5/Henson et Rugg - 2003 - Neural response suppression, haemodynamic repetiti.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WI9XBIC5/S0028393202001598.html:text/html},
	Issn = {0028-3932},
	Journal = {Neuropsychologia},
	Keywords = {MEG, Faces, Fusiform, Implicit, fMRI, ERP},
	Number = {3},
	Pages = {263--270},
	Series = {Functional {Neuroimaging} of {Memory}},
	Title = {Neural response suppression, haemodynamic repetition effects, and behavioural priming},
	Url = {http://www.sciencedirect.com/science/article/pii/S0028393202001598},
	Urldate = {2017-02-20},
	Volume = {41},
	Year = {2003},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0028393202001598},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0028-3932(02)00159-8}}

@article{homae_large-scale_2011,
	Abstract = {A critical issue in human development is that of whether the language-related areas in the left frontal and temporal regions work as a functional network in preverbal infants. Here, we used 94-channel near-infrared spectroscopy to reveal the functional networks in the brains of sleeping 3-month-old infants with and without presenting speech sounds. During the first 3âmin, we measured spontaneous brain activation (period 1). After period 1, we provided stimuli by playing Japanese sentences for 3âmin (period 2). Finally, we measured brain activation for 3âmin without providing the stimulus (period 3), as in period 1. We found that not only the bilateral temporal and temporoparietal regions but also the prefrontal and occipital regions showed oxygenated hemoglobin signal increases and deoxygenated hemoglobin signal decreases when speech sounds were presented to infants. By calculating time-lagged cross-correlations and coherences of oxy-Hb signals between channels, we tested the functional connectivity for the three periods. The oxy-Hb signals in neighboring channels, as well as their homologous channels in the contralateral hemisphere, showed high correlation coefficients in period 1. Similar correlations were observed in period 2; however, the number of channels showing high correlations was higher in the ipsilateral hemisphere, especially in the anterior--posterior direction. The functional connectivity in period 3 showed a close relationship between the frontal and temporal regions, which was less prominent in period 1, indicating that these regions form the functional networks and work as a hysteresis system that has memory of the previous inputs. We propose a hypothesis that the spatiotemporally large-scale brain networks, including the frontal and temporal regions, underlie speech processing in infants and they might play important roles in language acquisition during infancy.},
	Author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Taga, Gentaro},
	Doi = {10.3389/fpsyg.2011.00093},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/5MTSW9SJ/Homae et al. - 2011 - Large-Scale Brain Networks Underlying Language Acq.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Month = may,
	Pmcid = {PMC3110337},
	Pmid = {21687461},
	Title = {Large-{Scale} {Brain} {Networks} {Underlying} {Language} {Acquisition} in {Early} {Infancy}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110337/},
	Urldate = {2016-12-21},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110337/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00093}}

@article{khakh_diversity_2015,
	Abstract = {Astrocytes tile the entire CNS. They are vital for neural circuit function, but have traditionally been viewed as simple, homogenous cells that serve the same essential supportive roles everywhere. Here, we summarize breakthroughs that instead indicate that astrocytes represent a population of complex and functionally diverse cells. Physiological diversity of astrocytes is apparent between different brain circuits and microcircuits, and individual astrocytes display diverse signaling in subcellular compartments. With respect to injury and disease, astrocytes undergo diverse phenotypic changes that may be protective or causative with regard to pathology in a context-dependent manner. These new insights herald the concept that astrocytes represent a diverse population of genetically tractable cells that mediate neural circuit-specific roles in health and disease.},
	Author = {Khakh, Baljit S and Sofroniew, Michael V},
	Doi = {10.1038/nn.4043},
	File = {KhakhSofroniew15.pdf:/Users/Cecile/Zotero/storage/W9Q965FF/ContentServer.asp.pdf:application/pdf},
	Issn = {10976256},
	Journal = {Nature Neuroscience},
	Keywords = {NEURAL circuitry, BRAIN -- Research, ASTROCYTES, CELLS, CENTRAL NERVOUS SYSTEM},
	Month = jul,
	Number = {7},
	Pages = {942--952},
	Title = {Diversity of astrocyte functions and phenotypes in neural circuits},
	Url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=103427935&lang=fr&site=eds-live&scope=site},
	Urldate = {2016-12-22},
	Volume = {18},
	Year = {2015},
	Bdsk-Url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=103427935&lang=fr&site=eds-live&scope=site},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.4043}}

@article{bouchon_hemispheric_2015,
	Abstract = {Background The repeated presentation of stimuli typically attenuates neural responses (repetition suppression) or, less commonly, increases them (repetition enhancement) when stimuli are highly complex, degraded or presented under noisy conditions. In adult functional neuroimaging research, these repetition effects are considered as neural correlates of habituation. The development and respective functional significance of these effects in infancy remain largely unknown.   Objective This study investigates repetition effects in newborns using functional near-infrared spectroscopy, and specifically the role of stimulus complexity in evoking a repetition enhancement vs. a repetition suppression response, following up on Gervain et al. (2008). In that study, abstract rule-learning was found at birth in cortical areas specific to speech processing, as evidenced by a left-lateralized repetition enhancement of the hemodynamic response to highly variable speech sequences conforming to a repetition-based ABB artificial grammar, but not to a random ABC grammar.   Methods Here, the same paradigm was used to investigate how simpler stimuli (12 different sequences per condition as opposed to 140), and simpler presentation conditions (blocked rather than interleaved) would influence repetition effects at birth.   Results Results revealed that the two grammars elicited different dynamics in the two hemispheres. In left fronto-temporal areas, we reproduce the early perceptual discrimination of the two grammars, with ABB giving rise to a greater response at the beginning of the experiment than ABC. In addition, the ABC grammar evoked a repetition enhancement effect over time, whereas a stable response was found for the ABB grammar. Right fronto-temporal areas showed neither initial discrimination, nor change over time to either pattern.   Conclusion Taken together with Gervain et al. (2008), this is the first evidence that manipulating methodological factors influences the presence or absence of neural repetition enhancement effects in newborns and stimulus variability appears a particularly important factor. Further, this temporal modulation is restricted to the left hemisphere, confirming its specialization for learning linguistic regularities from birth.},
	Author = {Bouchon, Camillia and Nazzi, Thierry and {Judit Gervain}},
	Doi = {10.1371/journal.pone.0140160},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/S9BQ24HP/Bouchon et al. - 2015 - Hemispheric Asymmetries in Repetition Enhancement .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DUCZ4RSA/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Hemodynamics, Learning, Grammar, Left hemisphere, Syllables, neuroimaging, Near-infrared spectroscopy, functional magnetic resonance imaging},
	Month = oct,
	Number = {10},
	Pages = {e0140160},
	Title = {Hemispheric {Asymmetries} in {Repetition} {Enhancement} and {Suppression} {Effects} in the {Newborn} {Brain}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140160},
	Urldate = {2016-12-23},
	Volume = {10},
	Year = {2015},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0140160},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0140160}}

@article{jeschonek_animals_2010,
	Abstract = {One of the earliest categorical distinctions to be made by preverbal infants is the animate--inanimate distinction. To explore the neural basis for this distinction in 7--8-month-olds, an equal number of animal and furniture pictures was presented in an ERP-paradigm. The total of 118 pictures, all looking different from each other, were presented in a semi-randomized order for 1000 ms each. Infants' brain responses to exemplars from both categories differed systematically regarding the negative central component (Nc: 400--600 ms) at anterior channels. More specifically, the Nc was enhanced for animals in one subgroup of infants, and for furniture items in another subgroup of infants. Explorative analyses related to categorical priming further revealed category-specific differences in brain responses in the late time window (650--1550 ms) at right frontal channels: Unprimed stimuli (preceded by a different-category item) elicited a more positive response as compared to primed stimuli (preceded by a same-category item). In sum, these findings suggest that the infant's brain discriminates exemplars from both global domains. Given the design of our task, we conclude that processes of category identification are more likely to account for our findings than processes of on-line category formation during the experimental session.},
	Author = {Jeschonek, Susanna and Marinovic, Vesna and Hoehl, Stefanie and Elsner, Birgit and Pauen, Sabina},
	Doi = {10.1016/j.braindev.2009.11.010},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/26995B5R/Jeschonek et al. - 2010 - Do animals and furniture items elicit different br.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MIDAXDPI/Jeschonek et al. - 2010 - Do animals and furniture items elicit different br.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/FTAHEH23/S0387760409003027.html:text/html;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/URTAH2AM/S0387760409003027.html:text/html},
	Issn = {0387-7604},
	Journal = {Brain and Development},
	Keywords = {Animate--inanmiate distinction, Categorization, Category priming, ERP, Event-related-potentials, Infants, Nc, PSW},
	Month = nov,
	Number = {10},
	Pages = {863--871},
	Title = {Do animals and furniture items elicit different brain responses in human infants?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0387760409003027},
	Urldate = {2017-02-17},
	Volume = {32},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0387760409003027},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.braindev.2009.11.010}}

@article{clarke_emerging_2013,
	Abstract = {Astrocytes are now emerging as key participants in many aspects of brain development, function and disease. In particular, new evidence shows that astrocytes powerfully control the formation, maturation, function and elimination of synapses through various secreted and contact-mediated signals. Astrocytes are also increasingly being implicated in the pathophysiology of many psychiatric and neurological disorders that result from synaptic defects. A better understanding of how astrocytes regulate neural circuit development and function in the healthy and diseased brain might lead to the development of therapeutic agents to treat these diseases.},
	Author = {Clarke, Laura E. and Barres, Ben A.},
	Doi = {10.1038/nrn3484},
	File = {ClarkeBarres13.pdf:/Users/Cecile/Zotero/storage/ZCWRJQJR/ClarkeBarres13.pdf:application/pdf},
	Issn = {1471003X},
	Journal = {Nature Reviews Neuroscience},
	Keywords = {NEURAL circuitry, ASTROCYTES, Neural development, Pathological physiology, Nervous system -- Abnormalities, Synapses},
	Month = may,
	Number = {5},
	Pages = {311--321},
	Title = {Emerging roles of astrocytes in neural circuit development},
	Url = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=87027738&lang=fr&site=eds-live&scope=site},
	Urldate = {2016-12-22},
	Volume = {14},
	Year = {2013},
	Bdsk-Url-1 = {https://frodon.univ-paris5.fr/url?http://search.ebscohost.com/login.aspx?direct=true&db=pbh&AN=87027738&lang=fr&site=eds-live&scope=site},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn3484}}

@article{homae_right_2006,
	Abstract = {Behavioral studies proposed that prosodic information in speech sounds plays important roles for human infants to acquire their native languages. Here, we examined the neural basis of prosodic processing in 3-month-old infants. In order to obtain hemodynamic responses with high signal-to-noise ratio, we used near-infrared optical topography in the infants while they were in quiet sleep. First, we observed bilateral activation under each of the normal and flattened speech conditions. The flattened speech sound was created by eliminating changes in the pitch contours of the original utterance. In a direct comparison between the two conditions, the right temporoparietal region showed more prominent activation to normal speech sounds than to flattened speech sounds. This result demonstrates that the localized region of the right hemisphere in 3-month-old infant is involved in the processing of pitch contours. Our findings suggest that prosodic processing in the right hemisphere may facilitate the acquisition of lexical or syntactic knowledge in the early stages of language development.},
	Author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Asakawa, Kayo and Taga, Gentaro},
	Doi = {10.1016/j.neures.2005.12.006},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GHHRAW4W/Homae et al. - 2006 - The right hemisphere of sleeping infant perceives .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VTZZFQNM/S0168010205003287.html:text/html},
	Issn = {0168-0102},
	Journal = {Neuroscience Research},
	Keywords = {Infant, Near-infrared optical topography, language acquisition, speech perception, Intonation, prosody, Speech Perception},
	Month = apr,
	Number = {4},
	Pages = {276--280},
	Title = {The right hemisphere of sleeping infant perceives sentential prosody},
	Url = {http://www.sciencedirect.com/science/article/pii/S0168010205003287},
	Urldate = {2016-12-23},
	Volume = {54},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010205003287},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neures.2005.12.006}}

@article{reemst_indispensable_2016,
	Abstract = {Glia are essential for brain functioning during development and in the adult brain. Here, we discuss the various roles of both microglia and astrocytes, and their interactions during brain development. Although both cells are fundamentally different in origin and function, they often affect the same developmental processes such as neuro-/gliogenesis, angiogenesis, axonal outgrowth, synaptogenesis and synaptic pruning. Due to their important instructive roles in these processes, dysfunction of microglia or astrocytes during brain development could contribute to neurodevelopmental disorders and potentially even late-onset neuropathology. A better understanding of the origin, differentiation process and developmental functions of microglia and astrocytes will help to fully appreciate their role both in the developing as well as in the adult brain, in health and disease.},
	Author = {Reemst, Kitty and Noctor, Stephen C. and Lucassen, Paul J. and Hol, Elly M.},
	Doi = {10.3389/fnhum.2016.00566},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DWN9UGPQ/Reemst et al. - 2016 - The Indispensable Roles of Microglia and Astrocyte.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {Brain development, ASTROCYTES, Microglia, glial cells, Neurodevelopmental disorders},
	Language = {English},
	Title = {The {Indispensable} {Roles} of {Microglia} and {Astrocytes} during {Brain} {Development}},
	Url = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00566/abstract},
	Urldate = {2016-12-22},
	Volume = {10},
	Year = {2016},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fnhum.2016.00566/abstract},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2016.00566}}

@article{grossmann_early_2008,
	Abstract = {This study examined the brain bases of early human social cognitive abilities. Specifically, we investigated whether cortical regions implicated in adults' perception of facial communication signals are functionally active in early human development. Four-month-old infants watched two kinds of dynamic scenarios in which a face either established mutual gaze or averted its gaze, both of which were followed by an eyebrow raise with accompanying smile. Haemodynamic responses were measured by near-infrared spectroscopy, permitting spatial localization of brain activation (experiment 1), and gamma-band oscillatory brain activity was analysed from electroencephalography to provide temporal information about the underlying cortical processes (experiment 2). The results revealed that perceiving facial communication signals activates areas in the infant temporal and prefrontal cortex that correspond to the brain regions implicated in these processes in adults. In addition, mutual gaze itself, and the eyebrow raise with accompanying smile in the context of mutual gaze, produce similar cortical activations. This pattern of results suggests an early specialization of the cortical network involved in the perception of facial communication cues, which is essential for infants' interactions with, and learning from, others.},
	Author = {Grossmann, Tobias and Johnson, Mark H. and Lloyd-Fox, Sarah and Blasi, Anna and Deligianni, Fani and Elwell, Clare and Csibra, Gergely},
	Copyright = {Copyright {\copyright} 2008 The Royal Society. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
	Doi = {10.1098/rspb.2008.0986},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/HZHE5NZR/Grossmann et al. - 2008 - Early cortical specialization for face-to-face com.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NBARQ28K/2803.html:text/html},
	Issn = {0962-8452, 1471-2954},
	Journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	Language = {en},
	Month = dec,
	Number = {1653},
	Pages = {2803--2811},
	Pmid = {18755668},
	Title = {Early cortical specialization for face-to-face communication in human infants},
	Url = {http://rspb.royalsocietypublishing.org/content/275/1653/2803},
	Urldate = {2016-12-23},
	Volume = {275},
	Year = {2008},
	Bdsk-Url-1 = {http://rspb.royalsocietypublishing.org/content/275/1653/2803},
	Bdsk-Url-2 = {https://doi.org/10.1098/rspb.2008.0986}}

@article{emberson_using_2017,
	Abstract = {How does the developing brain respond to recent experience? Repetition suppression (RS) is a robust and well-characterized response of to recent experience found, predominantly, in the perceptual cortices of the adult brain. We use functional near-infrared spectroscopy (fNIRS) to investigate how perceptual (temporal and occipital) and frontal cortices in the infant brain respond to auditory and visual stimulus repetitions (spoken words and faces). In Experiment 1, we find strong evidence of repetition suppression in the frontal cortex but only for auditory stimuli. In perceptual cortices, we find only suggestive evidence of auditory RS in the temporal cortex and no evidence of visual RS in any ROI. In Experiments 2 and 3, we replicate and extend these findings. Overall, we provide the first evidence that infant and adult brains respond differently to stimulus repetition. We suggest that the frontal lobe may support the development of RS in perceptual cortices.},
	Author = {Emberson, Lauren L. and Cannon, Grace and Palmeri, Holly and Richards, John E. and Aslin, Richard N.},
	Doi = {10.1016/j.dcn.2016.11.002},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/546U34IV/Emberson et al. - 2017 - Using fNIRS to examine occipital and temporal resp.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/F73AV6AU/S1878929316300706.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Speech, Cross-modal, Faces, Frontal cortex, Visual, Words, auditory, fNIRS, repetition suppression},
	Month = feb,
	Pages = {26--38},
	Shorttitle = {Using {fNIRS} to examine occipital and temporal responses to stimulus repetition in young infants},
	Title = {Using {fNIRS} to examine occipital and temporal responses to stimulus repetition in young infants: {Evidence} of selective frontal cortex involvement},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929316300706},
	Urldate = {2016-12-26},
	Volume = {23},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316300706},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2016.11.002}}

@article{harris_physiology_2011,
	Abstract = {BOLD fMRI (blood oxygenation level dependent functional magnetic resonance imaging) is increasingly used to detect developmental changes of human brain function that are hypothesized to underlie the maturation of cognitive processes. BOLD signals depend on neuronal activity increasing cerebral blood flow, and are reduced by neural oxygen consumption. Thus, developmental changes of BOLD signals may not reflect altered information processing if there are concomitant changes in neurovascular coupling (the mechanism by which neuronal activity increases blood flow) or neural energy use (and hence oxygen consumption). We review how BOLD signals are generated, and explain the signalling pathways which convert neuronal activity into increased blood flow. We then summarize in broad terms the developmental changes that the brain's neural circuitry undergoes during growth from childhood through adolescence to adulthood, and present the changes in neurovascular coupling mechanisms and energy use which occur over the same period. This information provides a framework for assessing whether the BOLD changes observed during human development reflect altered cognitive processing or changes in neurovascular coupling and energy use.},
	Author = {Harris, Julia J. and Reynell, Clare and Attwell, David},
	Doi = {10.1016/j.dcn.2011.04.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TT9RVVZH/Harris et al. - 2011 - The physiology of developmental changes in BOLD fu.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RJC63V8H/S1878929311000314.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {BOLD fMRI, Blood flow, Energy, Glutamate, Neurovascular coupling, Development},
	Month = jul,
	Number = {3},
	Pages = {199--216},
	Title = {The physiology of developmental changes in {BOLD} functional imaging signals},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929311000314},
	Urldate = {2016-12-26},
	Volume = {1},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929311000314},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2011.04.001}}

@article{maki_optical_1999,
	Author = {Maki, Atsushi and Yamashita, Yuichi and Watanabe, Eijyu and Yamamoto, Tsuyoshi and Kogure, Kyuya and Kawaguchi, Fumio and Koizumi, Hideaki},
	File = {Snapshot:/Users/Cecile/Zotero/storage/2DMRZGA5/cat.inist.fr.html:text/html},
	Issn = {0277-786X},
	Journal = {Proceedings of SPIE, the International Society for Optical Engineering},
	Language = {eng},
	Pages = {202--212},
	Title = {Optical topography},
	Url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=17451877},
	Urldate = {2017-08-14},
	Volume = {3597},
	Year = {1999},
	Bdsk-Url-1 = {http://cat.inist.fr/?aModele=afficheN&cpsidt=17451877}}

@article{hall_interpreting_2016,
	Abstract = {Cognitive neuroscience depends on the use of blood oxygenation level-dependent (BOLD) functional magnetic resonance imaging (fMRI) to probe brain function. Although commonly used as a surrogate measure of neuronal activity, BOLD signals actually reflect changes in brain blood oxygenation. Understanding the mechanisms linking neuronal activity to vascular perfusion is, therefore, critical in interpreting BOLD. Advances in cellular neuroscience demonstrating differences in this neurovascular relationship in different brain regions, conditions or pathologies are often not accounted for when interpreting BOLD. Meanwhile, within cognitive neuroscience, the increasing use of high magnetic field strengths and the development of model-based tasks and analyses have broadened the capability of BOLD signals to inform us about the underlying neuronal activity, but these methods are less well understood by cellular neuroscientists. In 2016, a Royal Society Theo Murphy Meeting brought scientists from the two communities together to discuss these issues. Here, we consolidate the main conclusions arising from that meeting. We discuss areas of consensus about what BOLD fMRI can tell us about underlying neuronal activity, and how advanced modelling techniques have improved our ability to use and interpret BOLD. We also highlight areas of controversy in understanding BOLD and suggest research directions required to resolve these issues.
This article is part of the themed issue `Interpreting BOLD: a dialogue between cognitive and cellular neuroscience'.},
	Author = {Hall, Catherine N. and Howarth, Clare and Kurth-Nelson, Zebulun and Mishra, Anusha},
	Copyright = {{\copyright} 2016 The Author(s). http://royalsocietypublishing.org/licencePublished by the Royal Society. All rights reserved.},
	Doi = {10.1098/rstb.2015.0348},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/JXK89STX/Hall et al. - 2016 - Interpreting BOLD towards a dialogue between cogn.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2QE76GI7/20150348.html:text/html},
	Issn = {0962-8436, 1471-2970},
	Journal = {Phil. Trans. R. Soc. B},
	Language = {en},
	Month = oct,
	Number = {1705},
	Pages = {20150348},
	Pmid = {27574302},
	Shorttitle = {Interpreting {BOLD}},
	Title = {Interpreting {BOLD}: towards a dialogue between cognitive and cellular neuroscience},
	Url = {http://rstb.royalsocietypublishing.org/content/371/1705/20150348},
	Urldate = {2016-12-26},
	Volume = {371},
	Year = {2016},
	Bdsk-Url-1 = {http://rstb.royalsocietypublishing.org/content/371/1705/20150348},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2015.0348}}

@article{cheour_auditory_2002,
	Abstract = {The present study investigated the temporal dynamics of auditory sensory memory in newborns as reflected by the mismatch negativity (MMN), a preattentive electric change-detection response. MMN was obtained from 24 full-term healthy newborns who were either awake or asleep (quiet or active sleep) during the experiments. Stimuli were 1,000 Hz tones (standards) that were occasionally replaced by 1,100 Hz tones (deviants). The constant stimulus onset asynchrony (SOA) was, in separate blocks, either 450, 800, or 1,500 ms. A prominent MMN was obtained at the 800 ms SOA in all three sleep or waking states, whereas no MMN occurred at 450 and 1,500 ms SOAs. In view of the fact that in adults MMN is elicited even with a 10s SOA, these results imply that the time span of auditory memory is considerably shorter in neonates than in adults and 8-12-year-old children.},
	Author = {Cheour, Marie and {\v C}{\.e}ponien{\'e}, Rita and Lepp{\"a}nen, Paavo and Alho, Kimmo and Kujala, Teija and Renlund, Martin and Fellman, Vineta and N{\"a}{\"a}t{\"a}nen, Risto},
	Doi = {10.1111/1467-9450.00266},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/TJBE7A8E/Cheour et al. - 2002 - The auditory sensory memory trace decays rapidlyin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5EN33MHG/abstract.html:text/html},
	Issn = {1467-9450},
	Journal = {Scandinavian Journal of Psychology},
	Language = {en},
	Month = feb,
	Number = {1},
	Pages = {33--39},
	Title = {The auditory sensory memory trace decays rapidlyin newborns},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00266/abstract},
	Urldate = {2016-12-26},
	Volume = {43},
	Year = {2002},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00266/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/1467-9450.00266}}

@article{haartsen_human_2016,
	Abstract = {Recent studies of the structural and functional development of the human brain over the early years have highlighted the rapid development of brain structures and their interconnectivity. Some regional functional specializations emerge within the first months after birth, while others have a more protracted course of development spanning over the first decade or longer. While some anatomical changes enable the emergence of new functions, evidence also points to the importance of resting state oscillations in sculpting neural architecture during development. In atypical development differences in brain structure, function and task-related activity in infancy often precede the emergence of later diagnostic behavioural symptoms.},
	Author = {Haartsen, Rianne and Jones, Emily JH and Johnson, Mark H},
	Doi = {10.1016/j.cobeha.2016.05.015},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IWI4J3MM/Haartsen et al. - 2016 - Human brain development over the early years.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T3H3JWC5/S2352154616301164.html:text/html},
	Issn = {2352-1546},
	Journal = {Current Opinion in Behavioral Sciences},
	Month = aug,
	Pages = {149--154},
	Series = {Neuroscience of education},
	Title = {Human brain development over the early years},
	Url = {http://www.sciencedirect.com/science/article/pii/S2352154616301164},
	Urldate = {2016-12-26},
	Volume = {10},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S2352154616301164},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cobeha.2016.05.015}}

@incollection{kozberg_chapter_2016,
	Abstract = {In the adult brain, increases in local neural activity are almost always accompanied by increases in local blood flow. However, many functional imaging studies of the newborn and developing human brain have observed patterns of hemodynamic responses that differ from adult responses. Among the proposed mechanisms for the observed variations is that neurovascular coupling itself is still developing in the perinatal brain. Many of the components thought to be involved in actuating and propagating this hemodynamic response are known to still be developing postnatally, including perivascular cells such as astrocytes and pericytes. Both neural and vascular networks expand and are then selectively pruned over the first year of human life. Additionally, the metabolic demands of the newborn brain are still evolving. These changes are highly likely to affect early postnatal neurovascular coupling, and thus may affect functional imaging signals in this age group. This chapter will discuss the literature relating to neurovascular development. Potential effects of normal and aberrant development of neurovascular coupling on the newborn brain will also be explored, as well as ways to effectively utilize imaging techniques that rely on hemodynamic modulation such as fMRI and NIRS in younger populations.},
	Author = {Kozberg, M. and Hillman, E.},
	Booktitle = {Progress in {Brain} {Research}},
	Editor = {Kazuto Masamoto, Hajime Hirase {and} Katsuya Yamada},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UB2XJEXD/S0079612316000376.html:text/html},
	Keywords = {Brain development, Brain metabolism, Neurovascular coupling, fMRI, optical imaging},
	Pages = {213--242},
	Publisher = {Elsevier},
	Series = {New {Horizons} in {Neurovascular} {Coupling}: {A} {Bridge} {Between} {Brain} {Circulation} and {Neural} {Plasticity}},
	Title = {Chapter 10 - {Neurovascular} coupling and energy metabolism in the developing brain},
	Url = {http://www.sciencedirect.com/science/article/pii/S0079612316000376},
	Urldate = {2016-12-26},
	Volume = {225},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0079612316000376}}

@incollection{hoshi_chapter_2016,
	Abstract = {Near-infrared spectroscopy (NIRS) was originally designed for clinical monitoring of tissue oxygenation, and it has also been developed into a useful tool in neuroimaging studies, with the so-called functional NIRS (fNIRS). With NIRS, cerebral activation is detected by measuring the cerebral hemoglobin (Hb), where however, the precise correlation between NIRS signal and neural activity remains to be fully understood. This can in part be attributed to the situation that NIRS signals are inherently subject to contamination by signals arising from extracerebral tissue. In recent years, several approaches have been investigated to distinguish between NIRS signals originating in cerebral tissue and signals originating in extracerebral tissue. Selective measurements of cerebral Hb will enable a further evolution of fNIRS. This chapter is divided into six sections: first a summary of the basic theory of NIRS, NIRS signals arising in the activated areas, correlations between NIRS signals and fMRI signals, correlations between NIRS signals and neural activities, and the influence of a variety of extracerebral tissue on NIRS signals and approaches to this issue are reviewed. Finally, future prospects of fNIRS are described.},
	Author = {Hoshi, Y.},
	Booktitle = {Progress in {Brain} {Research}},
	Editor = {Kazuto Masamoto, Hajime Hirase {and} Katsuya Yamada},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/E4CP5WPW/S007961231600042X.html:text/html},
	Keywords = {EEG, NIRS, DOT, Deoxy-Hb, Extracerebral tissues, Oxy-Hb, Spontaneous fluctuations, t-Hb, fMRI},
	Pages = {153--179},
	Publisher = {Elsevier},
	Series = {New {Horizons} in {Neurovascular} {Coupling}: {A} {Bridge} {Between} {Brain} {Circulation} and {Neural} {Plasticity}},
	Title = {Chapter 7 - {Hemodynamic} signals in {fNIRS}},
	Url = {http://www.sciencedirect.com/science/article/pii/S007961231600042X},
	Urldate = {2016-12-26},
	Volume = {225},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S007961231600042X}}

@article{dukart_cerebral_2017,
	Abstract = {Application of metabolic magnetic resonance imaging measures such as cerebral blood flow in translational medicine is limited by the unknown link of observed alterations to specific neurophysiological processes. Here we address this question by probing cerebral blood flow in healthy volunteers using seven established drugs with known dopaminergic, serotonergic, glutamatergic and GABAergic mechanisms of action in a novel framework aimed at disentangling the observed effects to underlying neurotransmitter systems. We find for all evaluated compounds a reliable spatial link of respective cerebral blood flow changes with underlying activity and/or neurotransmitter receptor densities corresponding to their primary mechanisms of action. The strength of these associations with receptor density is mediated by respective drug affinities. These findings validate cerebral blood flow as a sensitive brain-wide in-vivo assay of metabolic demands across a variety of neurotransmitter systems in humans, with widespread implications for translational medicine and drug discovery alike.},
	Author = {Dukart, Juergen and Holiga, Stefan and Chatham, Christopher and Hawkins, Peter and Forsyth, Anna and McMillan, Rebecca and Myers, Jim and Lingford-Hughes, Anne and Nutt, David and Merlo-Pich, Emilio and Risterucci, Celine and Umbricht, Daniel and Boak, Lauren and Schobel, Scott and Liu, Thomas and Mehta, Mitul and Zelaya, Fernando and Williams, Steve and Brown, Gregory and Paulus, Martin and Honey, Garry and Muthukumaraswamy, Suresh and Hipp, Joerg and Bertolino, Alessandro and Sambataro, Fabio},
	Copyright = {{\copyright} 2017, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	Doi = {10.1101/207407},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/M5M4PMAA/Dukart et al. - 2017 - Cerebral blood flow predicts differential neurotra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4Q97CAFV/207407.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = oct,
	Pages = {207407},
	Title = {Cerebral blood flow predicts differential neurotransmitter activity},
	Url = {https://www.biorxiv.org/content/early/2017/10/24/207407},
	Urldate = {2017-10-25},
	Year = {2017},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2017/10/24/207407},
	Bdsk-Url-2 = {https://doi.org/10.1101/207407}}

@misc{noauthor_proceedings_nodate,
	Abstract = {National Academy of Sciences},
	File = {Snapshot:/Users/Cecile/Zotero/storage/NBGFEGW8/1617589114.html:text/html},
	Journal = {Proceedings of the National Academy of Sciences},
	Title = {Proceedings of the {National} {Academy} of {Sciences}},
	Url = {http://www.pnas.org/content/early/2017/06/26/1617589114.short},
	Urldate = {2017-08-14},
	Bdsk-Url-1 = {http://www.pnas.org/content/early/2017/06/26/1617589114.short}}

@article{ma_resting-state_2016,
	Abstract = {Brain hemodynamics serve as a proxy for neural activity in a range of noninvasive neuroimaging techniques including functional magnetic resonance imaging (fMRI). In resting-state fMRI, hemodynamic fluctuations have been found to exhibit patterns of bilateral synchrony, with correlated regions inferred to have functional connectivity. However, the relationship between resting-state hemodynamics and underlying neural activity has not been well established, making the neural underpinnings of functional connectivity networks unclear. In this study, neural activity and hemodynamics were recorded simultaneously over the bilateral cortex of awake and anesthetized Thy1-GCaMP mice using wide-field optical mapping. Neural activity was visualized via selective expression of the calcium-sensitive fluorophore GCaMP in layer 2/3 and 5 excitatory neurons. Characteristic patterns of resting-state hemodynamics were accompanied by more rapidly changing bilateral patterns of resting-state neural activity. Spatiotemporal hemodynamics could be modeled by convolving this neural activity with hemodynamic response functions derived through both deconvolution and gamma-variate fitting. Simultaneous imaging and electrophysiology confirmed that Thy1-GCaMP signals are well-predicted by multiunit activity. Neurovascular coupling between resting-state neural activity and hemodynamics was robust and fast in awake animals, whereas coupling in urethane-anesthetized animals was slower, and in some cases included lower-frequency ({\textless}0.04 Hz) hemodynamic fluctuations that were not well-predicted by local Thy1-GCaMP recordings. These results support that resting-state hemodynamics in the awake and anesthetized brain are coupled to underlying patterns of excitatory neural activity. The patterns of bilaterally-symmetric spontaneous neural activity revealed by wide-field Thy1-GCaMP imaging may depict the neural foundation of functional connectivity networks detected in resting-state fMRI.},
	Author = {Ma, Ying and Shaik, Mohammed A. and Kozberg, Mariel G. and Kim, Sharon H. and Portes, Jacob P. and Timerman, Dmitriy and Hillman, Elizabeth M. C.},
	Doi = {10.1073/pnas.1525369113},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IK48TQP8/Ma et al. - 2016 - Resting-state hemodynamics are spatiotemporally co.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NXXFUHB8/E8463.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {Neurovascular coupling, resting state, GCaMP, neural network activity, optical imaging},
	Language = {en},
	Month = dec,
	Number = {52},
	Pages = {E8463--E8471},
	Pmid = {27974609},
	Title = {Resting-state hemodynamics are spatiotemporally coupled to synchronized and symmetric neural activity in excitatory neurons},
	Url = {http://www.pnas.org/content/113/52/E8463},
	Urldate = {2016-12-27},
	Volume = {113},
	Year = {2016},
	Bdsk-Url-1 = {http://www.pnas.org/content/113/52/E8463},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1525369113}}

@article{homae_prosodic_2007,
	Abstract = {Speech prosody is considered to be one of the most important sources of information for infants in acquiring their native language. Using multi-channel near-infrared spectroscopy in 10-month-old infants, we examined cortical activation when normal and flattened speech sounds were presented to the infants. The flattened speech sound was generated by eliminating changes in the pitch contours of the original utterance. We found bilateral activation under both speech conditions. In a direct comparison between the two conditions, the right temporal and temporoparietal regions, and bilateral prefrontal regions showed more prominent activation in response to flattened speech than to normal speech. These results demonstrate that the unfamiliar pitch contours of flattened speech induce additional processing in the cortical regions of 10-month-old infants, suggesting that 10-month-old infants already have neural mechanisms for the processing of at least a part of the prosodic structures in their native language. To investigate developmental changes in cortical activation patterns, we compared the present results with those of our previous study using the same paradigm with 3-month-old infants. We propose that speech processing in the infant brain develops from analyzing pitch information per se, to comparing and integrating information in input speech sounds with acquired prosodic structures.},
	Author = {Homae, Fumitaka and Watanabe, Hama and Nakano, Tamami and Taga, Gentaro},
	Doi = {10.1016/j.neures.2007.05.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PCID57AM/Homae et al. - 2007 - Prosodic processing in the developing brain.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C57R83K5/S0168010207001812.html:text/html},
	Issn = {0168-0102},
	Journal = {Neuroscience Research},
	Keywords = {Infant, NIRS, Pitch, language acquisition, speech perception, prosody, Speech Perception},
	Month = sep,
	Number = {1},
	Pages = {29--39},
	Title = {Prosodic processing in the developing brain},
	Url = {http://www.sciencedirect.com/science/article/pii/S0168010207001812},
	Urldate = {2017-12-11},
	Volume = {59},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0168010207001812},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neures.2007.05.005}}

@article{gao_functional_2015,
	Abstract = {The first postnatal year is characterized by the most dramatic functional network development of the human lifespan. Yet, the relative sequence of the maturation of different networks and the impact of socioeconomic status (SES) on their development during this critical period remains poorly characterized. Leveraging a large, normally developing infant sample with multiple longitudinal resting-state functional magnetic resonance imaging scans during the first year (N = 65, scanned every 3 months), we aimed to delineate the relative maturation sequence of 9 key brain functional networks and examine their SES correlations. Our results revealed a maturation sequence from primary sensorimotor/auditory to visual to attention/default-mode, and finally to executive control networks. Network-specific critical growth periods were also identified. Finally, marginally significant positive SES--brain correlations were observed at 6 months of age for both the sensorimotor and default-mode networks, indicating interesting SES effects on functional brain maturation. To the best of our knowledge, this is the first study delineating detailed longitudinal growth trajectories of all major functional networks during the first year of life and their SES correlations. Insights from this study not only improve our understanding of early brain development, but may also inform the critical periods for SES expression during infancy.},
	Author = {Gao, Wei and Alcauter, Sarael and Elton, Amanda and Hernandez-Castillo, Carlos R. and Smith, J. Keith and Ramirez, Juanita and Lin, Weili},
	Doi = {10.1093/cercor/bhu088},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/CNARM5PF/Gao et al. - 2015 - Functional Network Development During the First Ye.pdf:application/pdf},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex (New York, NY)},
	Month = sep,
	Number = {9},
	Pages = {2919--2928},
	Pmcid = {PMC4537436},
	Pmid = {24812084},
	Shorttitle = {Functional {Network} {Development} {During} the {First} {Year}},
	Title = {Functional {Network} {Development} {During} the {First} {Year}: {Relative} {Sequence} and {Socioeconomic} {Correlations}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4537436/},
	Urldate = {2016-12-27},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4537436/},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhu088}}

@article{kidd_goldilocks_2012,
	Abstract = {Human infants, like immature members of any species, must be highly selective in sampling information from their environment to learn efficiently. Failure to be selective would waste precious computational resources on material that is already known (too simple) or unknowable (too complex). In two experiments with 7- and 8-month-olds, we measure infants' visual attention to sequences of events varying in complexity, as determined by an ideal learner model. Infants' probability of looking away was greatest on stimulus items whose complexity (negative log probability) according to the model was either very low or very high. These results suggest a principle of infant attention that may have broad applicability: infants implicitly seek to maintain intermediate rates of information absorption and avoid wasting cognitive resources on overly simple or overly complex events.},
	Author = {Kidd, Celeste and Piantadosi, Steven T. and Aslin, Richard N.},
	Doi = {10.1371/journal.pone.0036399},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BNUJW34K/Kidd et al. - 2012 - The Goldilocks Effect Human Infants Allocate Atte.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VZDQ8KZM/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Attention, Learning, Human learning, Curve fitting, Eyes, Sequence analysis, Vision, Infants},
	Month = may,
	Number = {5},
	Pages = {e36399},
	Shorttitle = {The {Goldilocks} {Effect}},
	Title = {The {Goldilocks} {Effect}: {Human} {Infants} {Allocate} {Attention} to {Visual} {Sequences} {That} {Are} {Neither} {Too} {Simple} {Nor} {Too} {Complex}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036399},
	Urldate = {2017-01-05},
	Volume = {7},
	Year = {2012},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036399},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0036399}}

@article{minagawa-kawai_neural_2007,
	Abstract = {To elucidate the developmental neural attunement process in the language-specific phonemic repertoire, cerebral hemodynamic responses to a Japanese durational vowel contrast were measured in Japanese infants using near-infrared spectroscopy. Because only relative durational information distinguishes this particular vowel contrast, both first and second language learners have difficulties in acquiring this phonemically crucial durational difference. Previous cross-linguistic studies conducted on adults showed that phoneme-specific, left-dominant neural responses were observed only for native Japanese listeners. Using the same stimuli, we show that a larger response to the across-category changes than to the within-category changes occurred transiently in the 6- to 7-month-old group before stabilizing in the groups older than 12 months. However, the left dominance of the phoneme-specific response in the auditory area was observed only in the groups of 13 months and above. Thus, the durational phonemic contrast is most likely processed first by a generic auditory circuit at 6--7 months as a result of early auditory experience. The neural processing of the contrast is then switched over to a more linguistic circuit after 12 months, this time with a left dominance similar to native adult listeners.},
	Author = {Minagawa-Kawai, Yasuyo and Mori, Koichi and Naoi, Nozomi and Kojima, Shozo},
	Copyright = {Copyright {\copyright} 2007 Society for Neuroscience 0270-6474/07/270315-07\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1984-06.2007},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/EW779KTX/Minagawa-Kawai et al. - 2007 - Neural Attunement Processes in Infants during the .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5BC9QHM2/315.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {NIRS, auditory area, cerebral lateralization, phonemic acquisition, speech perception, Development, Speech Perception},
	Language = {en},
	Month = jan,
	Number = {2},
	Pages = {315--321},
	Pmid = {17215392},
	Title = {Neural {Attunement} {Processes} in {Infants} during the {Acquisition} of a {Language}-{Specific} {Phonemic} {Contrast}},
	Url = {http://www.jneurosci.org/content/27/2/315},
	Urldate = {2017-02-20},
	Volume = {27},
	Year = {2007},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/27/2/315},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1984-06.2007}}

@article{kozberg_resolving_2013,
	Abstract = {The adult brain exhibits a local increase in cortical blood flow in response to external stimulus. However, broadly varying hemodynamic responses in the brains of newborn and young infants have been reported. Particular controversy exists over whether the ``true'' neonatal response to stimulation consists of a decrease or an increase in local deoxyhemoglobin, corresponding to a positive (adult-like) or negative blood oxygen level-dependent (BOLD) signal in functional magnetic resonance imaging (fMRI), respectively. A major difficulty with previous studies has been the variability in human subjects and measurement paradigms. Here, we present a systematic study in neonatal rats that charts the evolution of the cortical blood flow response during postnatal development using exposed-cortex multispectral optical imaging. We demonstrate that postnatal-day-12--13 rats (equivalent to human newborns) exhibit an ``inverted'' hemodynamic response (increasing deoxyhemoglobin, negative BOLD) with early signs of oxygen consumption followed by delayed, active constriction of pial arteries. We observed that the hemodynamic response then matures via development of an initial hyperemic (positive BOLD) phase that eventually masks oxygen consumption and balances vasoconstriction toward adulthood. We also observed that neonatal responses are particularly susceptible to stimulus-evoked systemic blood pressure increases, leading to cortical hyperemia that resembles adult positive BOLD responses. We propose that this confound may account for much of the variability in prior studies of neonatal cortical hemodynamics. Our results suggest that functional magnetic resonance imaging studies of infant and child development may be profoundly influenced by the maturing neurovascular and autoregulatory systems of the neonatal brain.},
	Author = {Kozberg, Mariel G. and Chen, Brenda R. and DeLeo, Sarah E. and Bouchard, Matthew B. and Hillman, Elizabeth M. C.},
	Doi = {10.1073/pnas.1212785110},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IESKGP4Z/Kozberg et al. - 2013 - Resolving the transition from negative to positive.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3RDKN3CB/4380.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {Brain development, Neurovascular coupling, autoregulation, somatosensory stimulation, vascular compartments},
	Language = {en},
	Month = dec,
	Number = {11},
	Pages = {4380--4385},
	Pmid = {23426630},
	Title = {Resolving the transition from negative to positive blood oxygen level-dependent responses in the developing brain},
	Url = {http://www.pnas.org/content/110/11/4380},
	Urldate = {2017-02-24},
	Volume = {110},
	Year = {2013},
	Bdsk-Url-1 = {http://www.pnas.org/content/110/11/4380},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1212785110}}

@article{zevin_domain_2010,
	Abstract = {Functional MRI studies of speech sound categorization often compare conditions in which a stimulus is presented repeatedly to conditions in which multiple stimuli are presented. This approach has established that a set of superior temporal and inferior parietal regions respond more strongly to conditions containing stimulus change. Here, we examine whether this contrast is driven by habituation to a repeating condition or by selective responding to change. Experiment 1 directly tests this by comparing the observed response to long trains of stimuli against a constructed hemodynamic response modeling the hypothesis that no habituation occurs. The results are consistent with the view that enhanced response to conditions involving phonemic variability reflect change detection. In a second experiment, the specificity of these responses to linguistically relevant stimulus variability was studied by including a condition in which the talker, rather than phonemic category, was variable from stimulus to stimulus. In this context, strong change detection responses were observed to changes in talker, but not to changes in phoneme category. The results prompt a reconsideration of two assumptions common to fMRI studies of speech sound categorization: they suggest that temporoparietal responses in passive paradigms such as those employed here are better characterized as reflecting change detection than habituation, and that their apparent selectivity to speech sound categories may reflect a more general preference for variability in highly salient or behaviorally relevant stimulus dimensions.},
	Author = {Zevin, Jason D. and Yang, Jianfeng and Skipper, Jeremy I. and McCandliss, Bruce D.},
	Doi = {10.1523/JNEUROSCI.4599-09.2010},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/UA4DQAPV/Zevin et al. - 2010 - Domain general change detection accounts for dish.pdf:application/pdf},
	Issn = {0270-6474},
	Journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	Month = jan,
	Number = {3},
	Pages = {1110--1117},
	Pmcid = {PMC2848500},
	Pmid = {20089919},
	Title = {Domain general change detection accounts for "dishabituation" effects in temporal-parietal regions in {fMRI} studies of speech perception},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2848500/},
	Urldate = {2016-12-29},
	Volume = {30},
	Year = {2010},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2848500/},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.4599-09.2010}}

@article{benavides-varela_studying_2011,
	Abstract = {The measurement of newborns' brain hemodynamic activity has improved our understanding of early cognitive processes, in particular of language acquisition. In this paper, we describe two experimental protocols adapted to study neonates' speech-processing capacities using functional near-infrared spectroscopy (fNIRS): the block design and the familiarization-recognition design. We review some of their benefits and disadvantages, and refer to research issues that can be explored by means of these protocols. We also illustrate the use of the two experimental designs through representative fNIRS studies that reveal specific patterns of activation of the newborn brain during speech perception, learning of repetition structures, and word recognition.},
	Author = {Benavides-Varela, Silvia and G{\'o}mez, David M. and Mehler, Jacques},
	Doi = {10.3389/fpsyg.2011.00064},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/IMEFDNRT/Benavides-Varela et al. - 2011 - Studying Neonates' Language and Memory Capacities .pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Month = apr,
	Pmcid = {PMC3110522},
	Pmid = {21687439},
	Title = {Studying {Neonates}' {Language} and {Memory} {Capacities} with {Functional} {Near}-{Infrared} {Spectroscopy}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110522/},
	Urldate = {2016-12-28},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110522/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00064}}

@article{weissgerber_beyond_2015,
	Abstract = {A systematic review of research articles reveals widespread poor practice in the presentation of continuous data. The authors recommend training for investigators and supply templates for easy use.},
	Author = {Weissgerber, Tracey L. and Milic, Natasa M. and Winham, Stacey J. and Garovic, Vesna D.},
	Doi = {10.1371/journal.pbio.1002128},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8MBE8FAD/Weissgerber et al. - 2015 - Beyond Bar and Line Graphs Time for a New Data Pr.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/V7D6SKMJ/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biol},
	Keywords = {Statistical Distributions, Graphs, Statistical data, Scientists, Systematic reviews, Prisms, Epidemiological statistics, Parametric analysis},
	Month = apr,
	Number = {4},
	Pages = {e1002128},
	Shorttitle = {Beyond {Bar} and {Line} {Graphs}},
	Title = {Beyond {Bar} and {Line} {Graphs}: {Time} for a {New} {Data} {Presentation} {Paradigm}},
	Url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002128},
	Urldate = {2016-04-05},
	Volume = {13},
	Year = {2015},
	Bdsk-Url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002128},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.1002128}}

@article{wood_cortical_2017,
	Abstract = {Inhibitory and excitatory neurons form intricate interconnected circuits in the mammalian sensory cortex. Whereas the function of excitatory neurons is largely to integrate and transmit information within and between brain areas, inhibitory neurons are thought to shape the way excitatory neurons integrate information, and they exhibit context-specific and behavior-specific responses. Over the last few years, work across sensory modalities has begun unraveling the function of distinct types of cortical inhibitory neurons in sensory processing, identifying their contribution to controlling stimulus selectivity of excitatory neurons and modulating information processing based on the behavioral state of the subject. Here, we review results from recent studies and discuss the implications for the contribution of inhibition to cortical circuit activity and information processing.},
	Author = {Wood, Katherine C and Blackwell, Jennifer M and Geffen, Maria Neimark},
	Doi = {10.1016/j.conb.2017.08.018},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/5JHJGSBN/Wood et al. - 2017 - Cortical inhibitory interneurons control sensory p.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TA67XGKE/S0959438817300788.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = oct,
	Number = {Supplement C},
	Pages = {200--207},
	Series = {{SI}: 46 : {Computational} {Neuroscience} (2017)},
	Title = {Cortical inhibitory interneurons control sensory processing},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438817300788},
	Urldate = {2017-11-13},
	Volume = {46},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438817300788},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2017.08.018}}

@article{roche-labarbe_somatosensory_2014,
	Abstract = {The hemodynamic functional response is used as a reliable marker of neuronal activity in countless studies of brain function and cognition. In newborns and infants, however, conflicting results have appeared in the literature concerning the typical response, and there is little information on brain metabolism and functional activation. Measurement of all hemodynamic components and oxygen metabolism is critical for understanding neurovascular coupling in the developing brain., To this end, we combined multiple near infrared spectroscopy techniques to measure oxy- and deoxy-hemoglobin concentrations, cerebral blood volume (CBV), and relative cerebral blood flow (CBF) in the somatosensory cortex of 6 preterm neonates during passive tactile stimulation of the hand. By combining these measures we estimated relative changes in the cerebral metabolic rate of oxygen consumption (rCMRO2)., CBF starts increasing immediately after stimulus onset, and returns to baseline before blood volume. This is consistent with the model of pre-capillary arteriole active dilation driving the CBF response, with a subsequent CBV increase influenced by capillaries and veins dilating passively to accommodate the extra blood. rCMRO2 estimated using the steady-state formulation shows a biphasic pattern: an increase immediately after stimulus onset, followed by a post-stimulus undershoot due to blood flow returning faster to baseline than oxygenation. However, assuming a longer mean transit time from the arterial to the venous compartment, due to the immature vascular system of premature infants, reduces the post-stimulus undershoot and increases the flow/consumption ratio to values closer to adult values reported in the literature., We are the first to report changes in local rCBF and rCMRO2 during functional activation in preterm infants. The ability to measure these variables in addition to hemoglobin concentration changes is critical for understanding neurovascular coupling in the developing brain, and for using this coupling as a reliable functional imaging marker in neonates.},
	Author = {Roche-Labarbe, Nadege and Fenoglio, Angela and Radakrishnan, Harsha and Kocienski-Filip, Marcia and Carp, Stefan A. and Dubb, Jay and Boas, David A. and Grant, P. Ellen and Franceschini, Maria Angela},
	Doi = {10.1016/j.neuroimage.2013.01.035},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/H7G45VNF/Roche-Labarbe et al. - 2014 - Somatosensory evoked changes in cerebral oxygen co.pdf:application/pdf},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = jan,
	Number = {0 1},
	Pmcid = {PMC3686986},
	Pmid = {23370052},
	Title = {Somatosensory evoked changes in cerebral oxygen consumption measured non-invasively in premature neonates},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3686986/},
	Urldate = {2016-12-29},
	Volume = {85},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3686986/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2013.01.035}}

@article{buckner_functional_1998,
	Abstract = {Human functional neuroimaging techniques provide a powerful means of linking neural level descriptions of brain function and cognition. The exploration of the functional anatomy underlying human memory comprises a prime example. Three highly reliable findings linking memory-related cognitive processes to brain activity are discussed. First, priming is accompanied by reductions in the amount of neural activation relative to naive or unprimed task performance. These reductions can be shown to be both anatomically and functionally specific and are found for both perceptual and conceptual task components. Second, verbal encoding, allowing subsequent conscious retrieval, is associated with activation of higher order brain regions including areas within the left inferior and dorsal prefrontal cortex. These areas also are activated by working memory and effortful word generation tasks, suggesting that these tasks, often discussed as separable, might rely on interdependent processes. Finally, explicit (intentional) retrieval shares much of the same functional anatomy as the encoding and word generation tasks but is associated with the recruitment of additional brain areas, including the anterior prefrontal cortex (right {\textgreater} left). These findings illustrate how neuroimaging techniques can be used to study memory processes and can both complement and extend data derived through other means. More recently developed methods, such as event-related functional MRI, will continue this progress and may provide additional new directions for research.},
	Author = {Buckner, Randy L. and Koutstaal, Wilma},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/39STZ7V3/Buckner et Koutstaal - 1998 - Functional neuroimaging studies of encoding, primi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GSPH2T53/891.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {Visual, functional MRI, positron-emission tomography, prefrontal, implicit memory},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {891--898},
	Pmid = {9448256},
	Title = {Functional neuroimaging studies of encoding, priming, and explicit memory retrieval},
	Url = {http://www.pnas.org/content/95/3/891},
	Urldate = {2016-12-28},
	Volume = {95},
	Year = {1998},
	Bdsk-Url-1 = {http://www.pnas.org/content/95/3/891}}

@article{chi_spectro-temporal_1999,
	Abstract = {Detection thresholds for spectral and temporal modulations are measured using broadband spectra with sinusoidally rippled profiles that drift up or down the log-frequency axis at constant velocities. Spectro-temporal modulation transfer functions (MTFs) are derived as a function of ripple peak density (Î© cycles/octave) and drifting velocity (Ï Hz). The MTFs exhibit a low-pass function with respect to both dimensions, with 50\% bandwidths of about 16 Hz and 2 cycles/octave. The data replicate (as special cases) previously measured purely temporal MTFs (Î©=0) [Viemeister, J. Acoust. Soc. Am. 66, 1364--1380 (1979)] and purely spectral MTFs (Ï=0) [Green, in Auditory Frequency Selectivity (Plenum, Cambridge, 1986), pp. 351--359]. A computational auditory model is presented that exhibits spectro-temporal MTFs consistent with the salient trends in the data. The model is used to demonstrate the potential relevance of these MTFs to the assessment of speech intelligibility in noise and reverberant conditions.},
	Author = {Chi, Taishih and Gao, Yujie and Guyton, Matthew C. and Ru, Powen and Shamma, Shihab},
	Doi = {10.1121/1.428100},
	File = {Snapshot:/Users/Cecile/Zotero/storage/3HGHKRJK/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Speech Intelligibility, Time measurement, Acoustical measurements, Auditory system models, Modulation transfer functions},
	Month = nov,
	Number = {5},
	Pages = {2719--2732},
	Title = {Spectro-temporal modulation transfer functions and speech intelligibility},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/106/5/10.1121/1.428100},
	Urldate = {2016-04-08},
	Volume = {106},
	Year = {1999},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/106/5/10.1121/1.428100},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.428100}}

@article{eggermont_between_2001,
	Abstract = {This review investigates the roles of representation, transformation and coding as part of a hierarchical process between sound and perception. This is followed by a survey of how speech sounds and elements thereof are represented in the activity patterns along the auditory pathway. Then the evidence for a place representation of texture features of sound, comprising frequency, periodicity pitch, harmonicity in vowels, and direction and speed of frequency modulation, and for a temporal and synchrony representation of sound contours, comprising onsets, offsets, voice onset time, and low rate amplitude modulation, in auditory cortex is reviewed. Contours mark changes and transitions in sound and auditory cortex appears particularly sensitive to these dynamic aspects of sound. Texture determines which neurons, both cortical and subcortical, are activated by the sound whereas the contours modulate the activity of those neurons. Because contours are temporally represented in the majority of neurons activated by the texture aspects of sound, each of these neurons is part of an ensemble formed by the combination of contour and texture sensitivity. A multiplexed coding of complex sound is proposed whereby the contours set up widespread synchrony across those neurons in all auditory cortical areas that are activated by the texture of sound.},
	Author = {Eggermont, Jos J},
	Doi = {10.1016/S0378-5955(01)00259-3},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/T79787DJ/S0378595501002593.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Keywords = {Speech, auditory system, neural coding, vocalization, Neural representation, Neural transformation, Neural synchrony, Amplitude and frequency modulation, Voice onset time},
	Month = jul,
	Number = {1--2},
	Pages = {1--42},
	Shorttitle = {Between sound and perception},
	Title = {Between sound and perception: reviewing the search for a neural code},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595501002593},
	Urldate = {2016-04-08},
	Volume = {157},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595501002593},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0378-5955(01)00259-3}}

@article{shamma_role_2001,
	Abstract = {Unlike visual and tactile stimuli, auditory signals that allow perception of timbre, pitch and localization are temporal. To process these, the auditory nervous system must either possess specialized neural machinery for analyzing temporal input, or transform the initial responses into patterns that are spatially distributed across its sensory epithelium. The former hypothesis, which postulates the existence of structures that facilitate temporal processing, is most popular. However, I argue that the cochlea transforms sound into spatiotemporal response patterns on the auditory nerve and central auditory stages; and that a unified computational framework exists for central auditory, visual and other sensory processing. Specifically, I explain how four fundamental concepts in visual processing play analogous roles in auditory processing.},
	Author = {Shamma, Shihab},
	Doi = {10.1016/S1364-6613(00)01704-6},
	File = {Snapshot:/Users/Cecile/Zotero/storage/M82PRKVN/S1364-6613(00)01704-6.html:text/html},
	Issn = {1364-6613, 1879-307X},
	Journal = {Trends in Cognitive Sciences},
	Keywords = {Cognitive Science},
	Language = {English},
	Month = aug,
	Number = {8},
	Pages = {340--348},
	Pmid = {11477003, 11477003},
	Title = {On the role of space and time in auditory processing},
	Url = {http://www.cell.com/article/S1364661300017046/abstract},
	Urldate = {2016-04-08},
	Volume = {5},
	Year = {2001},
	Bdsk-Url-1 = {http://www.cell.com/article/S1364661300017046/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/S1364-6613(00)01704-6}}

@article{heckman_determinants_nodate,
	Abstract = {Mouse ultrasonic vocalizations (USV) exhibit a high degree of complexity as demonstrated in recent years. A multitude of factors have been identified to influence USVs on the spectrotemporal as well as structural â e.g. syntactic â level. A synthesis of the various studies that attributes semantics to USV properties or sequences is still lacking. Presently, we address the factors modulating the composition of USVs, specifically age, gender, genetic background (including the targeted FoxP2 mutagenesis), behavioral state and individuality. It emerges that the different factors share a set of common influences, e.g. vocalization rate and frequency range are universally modulated across independent variables described; however, distinct influences exist for sequential structure (different effects for age, behavioral state and genetic background) or vocal repertoire (age). Recently, USV research has seen important advances based on the quantitative maturation of methods on multiple levels of vocalization. Adoption of these methods to address the natural statistics of USV will ultimately benefit several related research areas, e.g. neurolinguistics, neurodevelopmental disorders, multisensory and sensorimotor research.},
	Author = {Heckman, Jesse and McGuinness, Brigit and Celikel, Tansu and Englitz, Bernhard},
	Doi = {10.1016/j.neubiorev.2016.03.029},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/Q33N2PEV/Heckman et al. - Determinants of the Mouse Ultrasonic Vocal Structu.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/P7GZE2S8/S0149763415301457.html:text/html},
	Issn = {0149-7634},
	Journal = {Neuroscience \& Biobehavioral Reviews},
	Keywords = {vocalization, Mouse, USV, behavioral modulation, genetic background, gender, Development},
	Title = {Determinants of the {Mouse} {Ultrasonic} {Vocal} {Structure} and {Repertoire}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0149763415301457},
	Urldate = {2016-04-12},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0149763415301457},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neubiorev.2016.03.029}}

@article{krekelberg_adaptation:_2006,
	Abstract = {Functional magnetic resonance imaging adaptation (fMRIa) is an increasingly popular method that aims to provide insight into the functional properties of subpopulations of neurons within an imaging voxel. The technique relies on the assumption that neural adaptation reduces activity when two successive stimuli activate the same subpopulation but not when they stimulate different subpopulations. Here, we assess the validity of fMRIa by comparing single-cell recordings with functional imaging of orientation, motion and face processing. We find that fMRIa provides novel insight into neural representations in the human brain. However, network responses in general and adaptation in particular are more complex than is often assumed, and an unequivocal interpretation of fMRIa results can be achieved only with great care.},
	Author = {Krekelberg, Bart and Boynton, Geoffrey M. and van Wezel, Richard J. A.},
	Doi = {10.1016/j.tins.2006.02.008},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MZVT8FZM/Krekelberg et al. - 2006 - Adaptation from single cells to BOLD signals.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5DDSMA52/S0166223606000488.html:text/html},
	Issn = {0166-2236},
	Journal = {Trends in Neurosciences},
	Month = may,
	Number = {5},
	Pages = {250--256},
	Shorttitle = {Adaptation},
	Title = {Adaptation: from single cells to {BOLD} signals},
	Url = {http://www.sciencedirect.com/science/article/pii/S0166223606000488},
	Urldate = {2016-12-28},
	Volume = {29},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223606000488},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2006.02.008}}

@article{singh_modulation_2003,
	Author = {Singh, Nandini C. and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1121/1.1624067},
	File = {SinghTheunissen2003.pdf:/Users/Cecile/Zotero/storage/KKKPI84S/SinghTheunissen2003.pdf:application/pdf},
	Issn = {00014966},
	Journal = {The Journal of the Acoustical Society of America},
	Language = {en},
	Number = {6},
	Pages = {3394},
	Title = {Modulation spectra of natural sounds and ethological theories of auditory processing},
	Url = {http://scitation.aip.org/content/asa/journal/jasa/114/6/10.1121/1.1624067},
	Urldate = {2016-04-12},
	Volume = {114},
	Year = {2003},
	Bdsk-Url-1 = {http://scitation.aip.org/content/asa/journal/jasa/114/6/10.1121/1.1624067},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1624067}}

@article{konopka_insights_2016,
	Abstract = {The use of vocalizations to communicate information and elaborate social bonds is an adaptation seen in many vertebrate species. Human speech is an extreme version of this pervasive form of communication. Unlike the vocalizations exhibited by the majority of land vertebrates, speech is a learned behavior requiring early sensory exposure and auditory feedback for its development and maintenance. Studies in humans and a small number of other species have provided insights into the neural and genetic basis for learned vocal communication and are helping to delineate the roles of brain circuits across the cortex, basal ganglia, and cerebellum in generating vocal behaviors. This Review provides an outline of the current knowledge about these circuits and the genes implicated in vocal communication, as well as a perspective on future research directions in this field.},
	Author = {Konopka, Genevieve and Roberts, Todd F.},
	Doi = {10.1016/j.cell.2016.02.039},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/33KNT544/Konopka et Roberts - 2016 - Insights into the Neural and Genetic Basis of Voca.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C9JMDVJ4/S0092867416301891.html:text/html},
	Issn = {0092-8674},
	Journal = {Cell},
	Keywords = {Speech, sensorimotor circuits, human brain, songbird, FOXP2, language},
	Month = mar,
	Number = {6},
	Pages = {1269--1276},
	Title = {Insights into the {Neural} and {Genetic} {Basis} of {Vocal} {Communication}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0092867416301891},
	Urldate = {2016-04-19},
	Volume = {164},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0092867416301891},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cell.2016.02.039}}

@article{blackwell_stable_2016,
	Abstract = {Natural auditory scenes possess highly structured statistical regularities, which are dictated by the physics of sound production in nature, such as scale-invariance. We recently identified that natural water sounds exhibit a particular type of scale invariance, in which the temporal modulation within spectral bands scales with the centre frequency of the band. Here, we tested how neurons in the mammalian primary auditory cortex encode sounds that exhibit this property, but differ in their statistical parameters. The stimuli varied in spectro-temporal density and cyclo-temporal statistics over several orders of magnitude, corresponding to a range of water-like percepts, from pattering of rain to a slow stream. We recorded neuronal activity in the primary auditory cortex of awake rats presented with these stimuli. The responses of the majority of individual neurons were selective for a subset of stimuli with specific statistics. However, as a neuronal population, the responses were remarkably stable over large changes in stimulus statistics, exhibiting a similar range in firing rate, response strength, variability and information rate, and only minor variation in receptive field parameters. This pattern of neuronal responses suggests a potentially general principle for cortical encoding of complex acoustic scenes: while individual cortical neurons exhibit selectivity for specific statistical features, a neuronal population preserves a constant response structure across a broad range of statistical parameters.},
	Author = {Blackwell, Jennifer M. and Taillefumier, Thibaud O. and Natan, Ryan G. and Carruthers, Isaac M. and Magnasco, Marcelo O. and Geffen, Maria N.},
	Doi = {10.1111/ejn.13144},
	Issn = {1460-9568},
	Journal = {The European Journal of Neuroscience},
	Keywords = {Electrophysiology, receptive field, computational neuroscience, natural scene analysis, rat, Auditory cortex},
	Language = {eng},
	Month = mar,
	Number = {6},
	Pages = {751--764},
	Pmid = {26663571},
	Title = {Stable encoding of sounds over a broad range of statistical parameters in the auditory cortex},
	Volume = {43},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1111/ejn.13144}}

@article{oswald_synaptic_2006,
	Abstract = {In vivo voltage clamp recordings have provided new insights into the synaptic mechanisms that underlie processing in the primary auditory cortex. Of particular importance are the discoveries that excitatory and inhibitory inputs have similar frequency and intensity tuning, that excitation is followed by inhibition with a short delay, and that the duration of inhibition is briefer than expected. These findings challenge existing models of auditory processing in which broadly tuned lateral inhibition is used to limit excitatory receptive fields and suggest new mechanisms by which inhibition and short term plasticity shape neural responses.},
	Author = {Oswald, Anne-Marie M. and Schiff, Max L. and Reyes, Alex D.},
	Doi = {10.1016/j.conb.2006.06.015},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TAMR8GQ6/Oswald et al. - 2006 - Synaptic mechanisms underlying auditory processing.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9ZXQ2IIN/S0959438806000882.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = aug,
	Number = {4},
	Pages = {371--376},
	Series = {Sensory systems},
	Title = {Synaptic mechanisms underlying auditory processing},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438806000882},
	Urldate = {2016-04-25},
	Volume = {16},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438806000882},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2006.06.015}}

@article{isaacson_how_2011,
	Abstract = {Cortical processing reflects the interplay of synaptic excitation and synaptic inhibition. Rapidly accumulating evidence is highlighting the crucial role of inhibition in shaping spontaneous and sensory-evoked cortical activity and thus underscores how a better knowledge of inhibitory circuits is necessary for our understanding of cortical function. We discuss current views of how inhibition regulates the function of cortical neurons and point to a number of important open questions.},
	Author = {Isaacson, Jeffry S. and Scanziani, Massimo},
	Doi = {10.1016/j.neuron.2011.09.027},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/IPGQVAHD/Isaacson et Scanziani - 2011 - How Inhibition Shapes Cortical Activity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZR7HMJFK/S0896-6273(11)00879-8.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Language = {English},
	Month = oct,
	Number = {2},
	Pages = {231--243},
	Pmid = {22017986, 22017986},
	Title = {How {Inhibition} {Shapes} {Cortical} {Activity}},
	Url = {http://www.cell.com/article/S0896627311008798/abstract},
	Urldate = {2016-04-25},
	Volume = {72},
	Year = {2011},
	Bdsk-Url-1 = {http://www.cell.com/article/S0896627311008798/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2011.09.027}}

@article{emberson_top-down_2015,
	Abstract = {Recent theoretical work emphasizes the role of expectation in neural processing, shifting the focus from feed-forward cortical hierarchies to models that include extensive feedback (e.g., predictive coding). Empirical support for expectation-related feedback is compelling but restricted to adult humans and nonhuman animals. Given the considerable differences in neural organization, connectivity, and efficiency between infant and adult brains, it is a crucial yet open question whether expectation-related feedback is an inherent property of the cortex (i.e., operational early in development) or whether expectation-related feedback develops with extensive experience and neural maturation. To determine whether infants' expectations about future sensory input modulate their sensory cortices without the confounds of stimulus novelty or repetition suppression, we used a cross-modal (audiovisual) omission paradigm and used functional near-infrared spectroscopy (fNIRS) to record hemodynamic responses in the infant cortex. We show that the occipital cortex of 6-month-old infants exhibits the signature of expectation-based feedback. Crucially, we found that this region does not respond to auditory stimuli if they are not predictive of a visual event. Overall, these findings suggest that the young infant's brain is already capable of some rudimentary form of expectation-based feedback.},
	Author = {Emberson, Lauren L. and Richards, John E. and Aslin, Richard N.},
	Doi = {10.1073/pnas.1510343112},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZCWTPFEA/Emberson et al. - 2015 - Top-down modulation in the infant brain Learning-.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MM7E3BQU/9585.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {Infant, fNIRS, perceptual development, associative learning, multisensory},
	Language = {en},
	Month = apr,
	Number = {31},
	Pages = {9585--9590},
	Pmid = {26195772},
	Shorttitle = {Top-down modulation in the infant brain},
	Title = {Top-down modulation in the infant brain: {Learning}-induced expectations rapidly affect the sensory cortex at 6 months},
	Url = {http://www.pnas.org/content/112/31/9585},
	Urldate = {2016-04-26},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {http://www.pnas.org/content/112/31/9585},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1510343112}}

@article{lloyd-fox_social_2009,
	Author = {Lloyd-Fox, Sarah and Blasi, Anna and Volein, Agnes and Everdell, Nick and Elwell, Claire E. and Johnson, Mark H.},
	Doi = {10.1111/j.1467-8624.2009.01312.x},
	File = {Lloyd-Fox_et_al-2009-Child_Development.pdf:/Users/Cecile/Zotero/storage/FER4JXCN/Lloyd-Fox_et_al-2009-Child_Development.pdf:application/pdf},
	Issn = {00093920, 14678624},
	Journal = {Child Development},
	Language = {en},
	Month = jul,
	Number = {4},
	Pages = {986--999},
	Shorttitle = {Social {Perception} in {Infancy}},
	Title = {Social {Perception} in {Infancy}: {A} {Near} {Infrared} {Spectroscopy} {Study}},
	Url = {http://doi.wiley.com/10.1111/j.1467-8624.2009.01312.x},
	Urldate = {2016-04-26},
	Volume = {80},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.1467-8624.2009.01312.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01312.x}}

@article{huth_natural_2016,
	Author = {Huth, Alexander G. and de Heer, Wendy A. and Griffiths, Thomas L. and Theunissen, Fr{\'e}d{\'e}ric E. and Gallant, Jack L.},
	Doi = {10.1038/nature17637},
	File = {nature17637.pdf:/Users/Cecile/Zotero/storage/6K59JZKX/nature17637.pdf:application/pdf},
	Issn = {0028-0836, 1476-4687},
	Journal = {Nature},
	Month = apr,
	Number = {7600},
	Pages = {453--458},
	Title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	Url = {http://www.nature.com/doifinder/10.1038/nature17637},
	Urldate = {2016-04-30},
	Volume = {532},
	Year = {2016},
	Bdsk-Url-1 = {http://www.nature.com/doifinder/10.1038/nature17637},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature17637}}

@article{lerner_topographic_2011,
	Abstract = {Real-life activities, such as watching a movie or engaging in conversation, unfold over many minutes. In the course of such activities, the brain has to integrate information over multiple time scales. We recently proposed that the brain uses similar strategies for integrating information across space and over time. Drawing a parallel with spatial receptive fields, we defined the temporal receptive window (TRW) of a cortical microcircuit as the length of time before a response during which sensory information may affect that response. Our previous findings in the visual system are consistent with the hypothesis that TRWs become larger when moving from low-level sensory to high-level perceptual and cognitive areas. In this study, we mapped TRWs in auditory and language areas by measuring fMRI activity in subjects listening to a real-life story scrambled at the time scales of words, sentences, and paragraphs. Our results revealed a hierarchical topography of TRWs. In early auditory cortices (A1+), brain responses were driven mainly by the momentary incoming input and were similarly reliable across all scrambling conditions. In areas with an intermediate TRW, coherent information at the sentence time scale or longer was necessary to evoke reliable responses. At the apex of the TRW hierarchy, we found parietal and frontal areas that responded reliably only when intact paragraphs were heard in a meaningful sequence. These results suggest that the time scale of processing is a functional property that may provide a general organizing principle for the human cerebral cortex.},
	Author = {Lerner, Yulia and Honey, Christopher J. and Silbert, Lauren J. and Hasson, Uri},
	Doi = {10.1523/JNEUROSCI.3684-10.2011},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DM4FGEFM/Lerner et al. - 2011 - Topographic Mapping of a Hierarchy of Temporal Rec.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UI7E3FAT/2906.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {The Journal of Neuroscience},
	Language = {en},
	Month = feb,
	Number = {8},
	Pages = {2906--2915},
	Pmid = {21414912},
	Title = {Topographic {Mapping} of a {Hierarchy} of {Temporal} {Receptive} {Windows} {Using} a {Narrated} {Story}},
	Url = {http://www.jneurosci.org/content/31/8/2906},
	Urldate = {2016-05-03},
	Volume = {31},
	Year = {2011},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/31/8/2906},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.3684-10.2011}}

@article{yamada_rapid_1997,
	Abstract = {To determine developmental changes of activity-related metabolism in human visual cortex, we performed functional magnetic resonance imaging (fMRI) from the neonatal period. A rapid metabolic changing pattern accompanying normal human brain maturation was revealed by fMRI with photic stimulation. Infants older than 8 weeks of age showed a stimulus-related signal decrease in the visual cortex, whereas younger neonates showed a signal increase. This inversion of response in infants suggests a change in oxygen consumption during neuronal activation, which is related to rapid synapse formation and accompanying increased metabolism. fMRI can detect dynamic metabolic changes during the brain maturation, and provides a new clue in the detection of abnormal brain development or CNS plasticity.},
	Author = {Yamada, H. and Sadato, N. and Konishi, Y. and Kimura, K. and Tanaka, M. and Yonekura, Y. and Ishii, Y.},
	File = {yamada1997.pdf:/Users/Cecile/Zotero/storage/K7263GSJ/yamada1997.pdf:application/pdf},
	Issn = {0959-4965},
	Journal = {Neuroreport},
	Keywords = {Aging, Female, Gestational Age, Humans, Infant, Infant, Newborn, Male, Brain, Magnetic resonance imaging},
	Language = {eng},
	Month = dec,
	Number = {17},
	Pages = {3775--3778},
	Pmid = {9427369},
	Title = {A rapid brain metabolic change in infants detected by {fMRI}},
	Volume = {8},
	Year = {1997}}

@article{anderson_neonatal_2001,
	Abstract = {The objective of this study was to detect auditory cortical activation in non-sedated neonates employing functional magnetic resonance imaging (fMRI). Using echo-planar functional brain imaging, subjects were presented with a frequency-modulated pure tone; the BOLD signal response was mapped in 5 mm-thick slices running parallel to the superior temporal gyrus. Twenty healthy neonates (13 term, 7 preterm) at term and 4 adult control subjects. Blood oxygen level-dependent (BOLD) signal in response to auditory stimulus was detected in all 4 adults and in 14 of the 20 neonates. FMRI studies of adult subjects demonstrated increased signal in the superior temporal regions during auditory stimulation. In contrast, signal decreases were detected during auditory stimulation in 9 of 14 newborns with BOLD response. fMRI can be used to detect brain activation with auditory stimulation in human infants.},
	Author = {Anderson, Adam W. and Marois, Rene and Colson, Eve R. and Peterson, Bradley S. and Duncan, Charles C. and Ehrenkranz, Richard A. and Schneider, Karen C. and Gore, John C. and Ment, Laura R.},
	Doi = {10.1016/S0730-725X(00)00231-9},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/XNP788XH/Anderson et al. - 2001 - Neonatal auditory activation detected by functiona.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/Q7HVZIIM/S0730725X00002319.html:text/html},
	Issn = {0730-725X},
	Journal = {Magnetic Resonance Imaging},
	Keywords = {Neonate, Term, functional magnetic resonance imaging, Auditory cortex},
	Month = jan,
	Number = {1},
	Pages = {1--5},
	Title = {Neonatal auditory activation detected by functional magnetic resonance imaging},
	Url = {http://www.sciencedirect.com/science/article/pii/S0730725X00002319},
	Urldate = {2017-01-07},
	Volume = {19},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0730725X00002319},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0730-725X(00)00231-9}}

@article{zatorre_spectral_2001,
	Author = {Zatorre, Robert J. and Belin, Pascal},
	Doi = {10.1093/cercor/11.10.946},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UXJAGW7E/Zatorre et Belin - 2001 - Spectral and Temporal Processing in Human Auditory.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8RE62CWW/Spectral-and-Temporal-Processing-in-Human-Auditory.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = oct,
	Number = {10},
	Pages = {946--953},
	Title = {Spectral and {Temporal} {Processing} in {Human} {Auditory} {Cortex}},
	Url = {https://academic.oup.com/cercor/article/11/10/946/280028/Spectral-and-Temporal-Processing-in-Human-Auditory},
	Urldate = {2017-03-10},
	Volume = {11},
	Year = {2001},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/11/10/946/280028/Spectral-and-Temporal-Processing-in-Human-Auditory},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/11.10.946}}

@article{hoshi_hemodynamic_2000,
	Abstract = {A three-channel near-infrared monitoring system was used to evaluate the regional hemodynamic responses to photic stimulation during spontaneous sleep in seven healthy neonates. Three pairs of parallel light guides, separated by 15 mm each, were placed over a 450-mm2 occipital region of the head. Increases in oxygenated and total hemoglobin were observed during photic stimulation only in one channel, and no change or decreases in oxygenated, deoxygenated, and total hemoglobin were observed in the other two channels. The change in the direction of deoxygenated hemoglobin accompanying the increases in oxygenated and total hemoglobin (usually a decrease in adults) differed in each subject and also varied with each measurement even in the same subject. An increase, decrease, and no change were observed. The results imply that an increase in regional cerebral blood flow occurs because of stimulation specific to the visual cortex and that the increase in deoxygenated hemoglobin observed in the visual cortex of the neonatal brain is attributable to venous dilation.},
	Author = {Hoshi, Yoko and Kohri, Shunji and Matsumoto, Yoshinori and Cho, Kazutoshi and Matsuda, Tadashi and Okajima, Satoru and Fujimoto, Seiichiro},
	Doi = {10.1016/S0887-8994(00)00195-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/77RHN535/Hoshi et al. - 2000 - Hemodynamic responses to photic stimulation in neo.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5PI64ABD/S0887899400001958.html:text/html},
	Issn = {0887-8994},
	Journal = {Pediatric Neurology},
	Month = oct,
	Number = {4},
	Pages = {323--327},
	Title = {Hemodynamic responses to photic stimulation in neonates},
	Url = {http://www.sciencedirect.com/science/article/pii/S0887899400001958},
	Urldate = {2017-01-07},
	Volume = {23},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0887899400001958},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0887-8994(00)00195-8}}

@article{kidd_goldilocks_2014,
	Abstract = {Infants must learn about many cognitive domains (e.g., language, music) from auditory statistics, yet capacity limits on their cognitive resources restrict the quantity that they can encode. Previous research has established that infants can attend to only a subset of available acoustic input. Yet few previous studies have directly examined infant auditory attention, and none have directly tested theorized mechanisms of attentional selection based on stimulus complexity. This work utilizes model-based behavioral methods that were recently developed to examine visual attention in infants (e.g., Kidd, Piantadosi, \& Aslin, 2012). The present results demonstrate that 7- to 8-month-old infants selectively attend to nonsocial auditory stimuli that are intermediately predictable/complex with respect to their current implicit beliefs and expectations. These findings provide evidence of a broad principle of infant attention across modalities and suggest that sound-to-sound transitional statistics heavily influence the allocation of auditory attention in human infants.},
	Author = {Kidd, Celeste and Piantadosi, Steven T. and Aslin, Richard N.},
	Doi = {10.1111/cdev.12263},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ARSU9STC/Kidd et al. - 2014 - The Goldilocks Effect in Infant Auditory Attention.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WGCAR2DF/abstract\;jsessionid=F56328E1510356CCB1F8C3719A745321.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Month = sep,
	Number = {5},
	Pages = {1795--1804},
	Title = {The {Goldilocks} {Effect} in {Infant} {Auditory} {Attention}},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/cdev.12263/abstract},
	Urldate = {2017-01-06},
	Volume = {85},
	Year = {2014},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/cdev.12263/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/cdev.12263}}

@article{born_visual_1998,
	Abstract = {The purpose of this study was to determine whether visual stimulation in sleeping infants and young children can be examined by functional magnetic resonance imaging. We studied 17 children, aged 3 d to 48 mo, and three healthy adults. Visual stimulation was performed with 8-Hz flickering light through the sleeping childs' closed eyelids. Functional magnetic resonance imaging was performed with a gradient echoplanar sequence in a 1.5-T magnetic resonance scanner. Six subjects were excluded because of movement artifacts; the youngest infant showed no response. In 10 children, we could demonstrate areas of signal decrease during visual stimulation in the occipital cortex (mean decrease 2.21\%), contrary to the signal increase observed in the adult controls (mean increase 2.82\%). This decrease may be due to a higher proportional increase in oxygen extraction compared with increase in cerebral blood flow during activation. The different response patterns in young children and adults can reflect developmental or behavioral differences. Localization of the activation seemed to be age-dependent. In the older children and the adults, it encompassed the whole length of the calcarine sulcus, whereas it was restricted to the anterior and medial part of the calcarine sulcus in the younger infants. This may reflect a different functional organization of the young child's visual cortex or the on-going retinal development.},
	Author = {Born, Peter and Leth, Helle and Miranda, Maria J. and Rostrup, Egill and Stensgaard, Anders and Peitersen, Birgit and Larsson, Henrik B. W. and Lou, Hans C.},
	Copyright = {{\copyright} 1998 Nature Publishing Group},
	Doi = {10.1203/00006450-199810000-00018},
	File = {Snapshot:/Users/Cecile/Zotero/storage/C7V6CFSD/pr1998504a.html:text/html},
	Issn = {0031-3998},
	Journal = {Pediatric Research},
	Language = {en},
	Month = oct,
	Number = {4},
	Pages = {578--583},
	Title = {Visual {Activation} in {Infants} and {Young} {Children} {Studied} by {Functional} {Magnetic} {Resonance} {Imaging}},
	Url = {http://www.nature.com/pr/journal/v44/n4/full/pr1998504a.html},
	Urldate = {2017-01-07},
	Volume = {44},
	Year = {1998},
	Bdsk-Url-1 = {http://www.nature.com/pr/journal/v44/n4/full/pr1998504a.html},
	Bdsk-Url-2 = {https://doi.org/10.1203/00006450-199810000-00018}}

@article{pernet_human_2015,
	Abstract = {fMRI studies increasingly examine functions and properties of non-primary areas of human auditory cortex. However there is currently no standardized localization procedure to reliably identify specific areas across individuals such as the standard `localizers' available in the visual domain. Here we present an fMRI `voice localizer' scan allowing rapid and reliable localization of the voice-sensitive `temporal voice areas' (TVA) of human auditory cortex. We describe results obtained using this standardized localizer scan in a large cohort of normal adult subjects. Most participants (94\%) showed bilateral patches of significantly greater response to vocal than non-vocal sounds along the superior temporal sulcus/gyrus (STS/STG). Individual activation patterns, although reproducible, showed high inter-individual variability in precise anatomical location. Cluster analysis of individual peaks from the large cohort highlighted three bilateral clusters of voice-sensitivity, or ``voice patches'' along posterior (TVAp), mid (TVAm) and anterior (TVAa) STS/STG, respectively. A series of extra-temporal areas including bilateral inferior prefrontal cortex and amygdalae showed small, but reliable voice-sensitivity as part of a large-scale cerebral voice network. Stimuli for the voice localizer scan and probabilistic maps in MNI space are available for download.},
	Author = {Pernet, Cyril R. and McAleer, Phil and Latinus, Marianne and Gorgolewski, Krzysztof J. and Charest, Ian and Bestelmeyer, Patricia E. G. and Watson, Rebecca H. and Fleming, David and Crabbe, Frances and Valdes-Sosa, Mitchell and Belin, Pascal},
	Doi = {10.1016/j.neuroimage.2015.06.050},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RH9NGGGW/Pernet et al. - 2015 - The human voice areas Spatial organization and in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3ZGEQC3S/S1053811915005558.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Amygdala, Voice, Inferior prefrontal cortex, Superior temporal gyrus, Superior temporal sulcus, functional magnetic resonance imaging, Auditory cortex},
	Month = oct,
	Pages = {164--174},
	Shorttitle = {The human voice areas},
	Title = {The human voice areas: {Spatial} organization and inter-individual variability in temporal and extra-temporal cortices},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811915005558},
	Urldate = {2017-03-09},
	Volume = {119},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811915005558},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2015.06.050}}

@article{meek_regional_1998,
	Abstract = {This study presents the first measurements using near infrared spectroscopy of changes in regional hemodynamics as a response to a visual stimulus in awake infants. Ten infants aged 3 d to 14 wk viewed a checkerboard with a 5-Hz pattern reversal. The emitter and detector (optodes) of a near infrared spectrophotometer were placed over the occipital region of the head. Changes in concentration of oxy- and deoxyhemoglobin (Hbo2 and Hb) were measured and compared during 10-s epochs of stimulus on and off. A control group of 10 infants aged 18 d to 13 wk were examined with the same setup, but with the optodes over the frontoparietal region. In the test group the total hemoglobin concentration (Hbo2 + Hb) increased while the stimulus was on by a mean (+/-SD) of 2.51 (+/-1.48) micromol x L(-1). Nine out of 10 infants showed an Hbo2 increase, and 9 out of 10 an Hb increase related to the stimulus. There was no significant change in any of these parameters in the control group. The results imply that there is increased cerebral blood flow due to stimulation that is specific to the visual cortex and that infants, unlike adults, show increased cerebral oxygen utilization during activation that outstrips this hemodynamic effect. The study demonstrates that near infrared spectroscopy can be used as a practical and noninvasive method of measuring visual functional activation and its hemodynamic correlates in the awake infant.},
	Author = {Meek, J. H. and Firbank, M. and Elwell, C. E. and Atkinson, J. and Braddick, O. and Wyatt, J. S.},
	Doi = {10.1203/00006450-199806000-00019},
	Issn = {0031-3998},
	Journal = {Pediatric Research},
	Keywords = {Adult, Aging, Frontal Lobe, Hemodynamics, Hemoglobins, Humans, Infant, Infant, Newborn, Kinetics, Cerebrovascular Circulation, Photic Stimulation, Time Factors, Occipital Lobe, Oxyhemoglobins},
	Language = {eng},
	Month = jun,
	Number = {6},
	Pages = {840--843},
	Pmid = {9621996},
	Title = {Regional hemodynamic responses to visual stimulation in awake infants},
	Volume = {43},
	Year = {1998},
	Bdsk-Url-1 = {https://doi.org/10.1203/00006450-199806000-00019}}

@article{norman_growth_1986,
	Abstract = {Sections of the occipital cortex from 31 fetuses, infants and children, ranging in age from 15 weeks gestation to ten years postnatal, were stained to demonstrate alkaline phosphatase activity in intracortical vessels. At 15 weeks gestation intracortical positively staining vessels, assumed to be arterial precursors, were radially oriented, originating from leptomeningeal arteries. Most radial vessels coursed through the cerebral cortex without branching to vascularize the subcortical tissue. By 20 weeks gestation horizontal branches arose from radial vessels, most frequently in the lower half of the cortex. Occasionally, recurrent collaterals ascended from these horizontal branches to more superficial cortex. From 20--27 weeks gestation, the number of horizontal branches and recurrent collaterals increased in the lower half of the cortex, horizontal branches appeared in the upper half. From 27 weeks to term, shorter radial vessels, terminating in the more superficial cortical laminae increased in number. After birth a network of fine vessels, presumably precursors of capillaries, increased, particularly vascular layer 3 (neuronal lamina IV and Va). The number of radially oriented vessels per mm2 of pial surface (NA) decreased throughout development, with the most dramatic decrease occurring prenatally. In five cases of trisomy values of NA decreased less rapidly than in the normal},
	Author = {Norman, Margaret G. and O'Kusky, John R.},
	Copyright = {Copyright {\copyright} 1986, by the American Association of Neuropathologists},
	Doi = {10.1097/00005072-198605000-00003},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/VP5BAPEQ/Norman et O'Kusky - 1986 - The Growth and Development of Microvasculature in .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AUIQNCJT/222.html:text/html},
	Issn = {0022-3069, 1554-6578},
	Journal = {Journal of Neuropathology \& Experimental Neurology},
	Language = {en},
	Month = may,
	Number = {3},
	Pages = {222--232},
	Pmid = {3958756},
	Title = {The {Growth} and {Development} of {Microvasculature} in {Human} {Cerebral} {Cortex}},
	Url = {http://jnen.oxfordjournals.org/content/45/3/222},
	Urldate = {2017-01-10},
	Volume = {45},
	Year = {1986},
	Bdsk-Url-1 = {http://jnen.oxfordjournals.org/content/45/3/222},
	Bdsk-Url-2 = {https://doi.org/10.1097/00005072-198605000-00003}}

@article{benes_myelination_1994,
	Abstract = {BACKGROUND: A previous study demonstrated that myelination of the superior medullary lamina along the surface of the parahippocampal gyrus is occurring in human brain during adolescence. To further investigate whether postnatal increases of myelination may continue during the second decade and possibly even longer, the extent of myelination in this region has been analyzed in 164 psychiatrically normal individuals aged newborn to 76 years.
METHODS: Cross sections of the hippocampal formation with adjoining hippocampal gyrus were analyzed on a blinded basis using either a global rating scale or measurements of the area of myelin staining.
RESULTS: A curvilinear increase in the extent of myelination between the first and sixth decades of life (r = .71 and r = .67, respectively) was observed. When the area of myelination was expressed relative to brain weight, there was a twofold increase between the first and second decades and an additional increase of 60\% between the fourth and sixth decades. Female subjects showed a significantly greater degree of myelin staining than did male subjects during the interval of ages 6 to 29 years; however, after the third decade, there were no gender differences in the area of myelin staining.
CONCLUSIONS: The increased staining of myelin during the first and second decades principally occurred in the subicular region and adjacent portions of the presubiculum. During the fourth through sixth decades, however, it extended to progressively more lateral locations along the surface of the presubiculum. The precise origin(s) of the axons showing progressive myelination is unknown; however, the axons in the subiculum may include some perforant path fibers, while those found in the presubiculum may include cingulum bundle projections. Overall, our data are consistent with the idea that both early and late postnatal increases of myelination occur in a key corticolimbic relay area of the human brain and underscore the importance of applying a neurodevelopmental perspective to the study of psychopathology during childhood, adolescence, and even adulthood.},
	Author = {Benes, F. M. and Turtle, M. and Khan, Y. and Farol, P.},
	Issn = {0003-990X},
	Journal = {Archives of General Psychiatry},
	Keywords = {Adolescent, Adult, Age Factors, Aged, Aging, Animals, Child, Child Development, Child, Preschool, Female, Humans, Infant, Infant, Newborn, Male, Middle Aged, Neural Pathways, Hippocampus, Myelin Sheath, Organ Size, Sex Factors, Brain},
	Language = {eng},
	Month = jun,
	Number = {6},
	Pages = {477--484},
	Pmid = {8192550},
	Title = {Myelination of a key relay zone in the hippocampal formation occurs in the human brain during childhood, adolescence, and adulthood},
	Volume = {51},
	Year = {1994}}

@article{mishra_astrocytes_2016,
	Abstract = {Active neurons increase their energy supply by dilating nearby arterioles and capillaries. This neurovascular coupling underlies blood oxygen level-dependent functional imaging signals, but its mechanism is controversial. Canonically, neurons release glutamate to activate metabotropic glutamate receptor 5 (mGluR5) on astrocytes, evoking Ca(2+) release from internal stores, activating phospholipase A2 and generating vasodilatory arachidonic acid derivatives. However, adult astrocytes lack mGluR5, and knockout of the inositol 1,4,5-trisphosphate receptors that release Ca(2+) from stores does not affect neurovascular coupling. We now show that buffering astrocyte Ca(2+) inhibits neuronally evoked capillary dilation, that astrocyte [Ca(2+)]i is raised not by release from stores but by entry through ATP-gated channels, and that Ca(2+) generates arachidonic acid via phospholipase D2 and diacylglycerol kinase rather than phospholipase A2. In contrast, dilation of arterioles depends on NMDA receptor activation and Ca(2+)-dependent NO generation by interneurons. These results reveal that different signaling cascades regulate cerebral blood flow at the capillary and arteriole levels.},
	Author = {Mishra, Anusha and Reynolds, James P. and Chen, Yang and Gourine, Alexander V. and Rusakov, Dmitri A. and Attwell, David},
	Doi = {10.1038/nn.4428},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {eng},
	Month = dec,
	Number = {12},
	Pages = {1619--1627},
	Pmcid = {PMC5131849},
	Pmid = {27775719},
	Title = {Astrocytes mediate neurovascular signaling to capillary pericytes but not to arterioles},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.4428}}

@article{dubois_exploring_2016,
	Abstract = {Linguistic processing is based on a close collaboration between temporal and frontal regions connected by two pathways: the ``dorsal'' and ``ventral pathways'' (assumed to support phonological and semantic processing, respectively, in adults). We investigated here the development of these pathways at the onset of language acquisition, during the first post-natal weeks, using cross-sectional diffusion imaging in 21 healthy infants (6--22 weeks of age) and 17 young adults. We compared the bundle organization and microstructure at these two ages using tractography and original clustering analyses of diffusion tensor imaging parameters. We observed structural similarities between both groups, especially concerning the dorsal/ventral pathway segregation and the arcuate fasciculus asymmetry. We further highlighted the developmental tempos of the linguistic bundles: The ventral pathway maturation was more advanced than the dorsal pathway maturation, but the latter catches up during the first post-natal months. Its fast development during this period might relate to the learning of speech cross-modal representations and to the first combinatorial analyses of the speech input.},
	Author = {Dubois, Jessica and Poupon, Cyril and Thirion, Bertrand and Simonnet, Hina and Kulikova, Sofya and Leroy, Fran{\c c}ois and Hertz-Pannier, Lucie and Dehaene-Lambertz, Ghislaine},
	Doi = {10.1093/cercor/bhv082},
	File = {Snapshot:/Users/Cecile/Zotero/storage/F3RPNUHF/2283.html:text/html},
	Issn = {1047-3211, 1460-2199},
	Journal = {Cerebral Cortex},
	Keywords = {Brain development, language network, diffusion imaging, interhemispheric asymmetry, white matter maturation and myelination},
	Language = {en},
	Month = jan,
	Number = {5},
	Pages = {2283--2298},
	Pmid = {25924951},
	Title = {Exploring the {Early} {Organization} and {Maturation} of {Linguistic} {Pathways} in the {Human} {Infant} {Brain}},
	Url = {http://cercor.oxfordjournals.org/content/26/5/2283},
	Urldate = {2017-01-10},
	Volume = {26},
	Year = {2016},
	Bdsk-Url-1 = {http://cercor.oxfordjournals.org/content/26/5/2283},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhv082}}

@article{kusaka_noninvasive_2004,
	Abstract = {During the developmental stage, the brain undergoes anatomic, functional, and metabolic changes necessary to support the complex adaptive behavior of a mature individual. Estimation of developmental changes occurring in different regions of the brain would provide a means of relating various behavioral phenomena to maturation-specific brain structures, thereby providing useful information on structure-function relationships in both normal and disease states. We used multichannel near-infrared spectroscopy (MNIRS), a new noninvasive imaging technique for revealing the course of neural activity in selected brain regions, to monitor the activities of the visual cortex as mirrored by hemodynamic responses in infants subjected to photostimulation during natural sleep. In the infants, oxyhemoglobin and total hemoglobin decreased and deoxyhemoglobin increased in the visual cortex with photostimulation. This pattern of responses was different from the response pattern in adults reported previously. The different patterns of responses to photostimulation in the visual cortices of infants and adults might reflect developmental and behavioral differences. It may reflect a different functional organization of the visual cortex in infants or ongoing retinal development. Our results demonstrated that regional hemodynamic change could be detected in a small area around the visual cortex. MNIRS offers considerable potential for research and noninvasive clinical applications.},
	Author = {Kusaka, Takashi and Kawada, Kou and Okubo, Kensuke and Nagano, Keiko and Namba, Masanori and Okada, Hitoshi and Imai, Tadashi and Isobe, Kenichi and Itoh, Susumu},
	Doi = {10.1002/hbm.20020},
	Issn = {1065-9471},
	Journal = {Human Brain Mapping},
	Keywords = {Adult, Brain Mapping, Hemoglobins, Humans, Infant, Infant, Newborn, Sleep, Photic Stimulation, Spectroscopy, Near-Infrared, Visual Cortex, Oxyhemoglobins},
	Language = {eng},
	Month = jun,
	Number = {2},
	Pages = {122--132},
	Pmid = {15108300},
	Title = {Noninvasive optical imaging in the visual cortex in young infants},
	Volume = {22},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1002/hbm.20020}}

@article{mahmoudzadeh_functional_2017,
	Author = {Mahmoudzadeh, Mahdi and Wallois, Fabrice and Kongolo, Guy and Goudjil, Sabrina and Dehaene-Lambertz, Ghislaine},
	Doi = {10.1093/cercor/bhw103},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CQKEF2JR/Mahmoudzadeh et al. - 2017 - Functional Maps at the Onset of Auditory Inputs in.pdf:application/pdf;SI_Submit_final.pdf:/Users/Cecile/Zotero/storage/2HMJSJBZ/SI_Submit_final.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/4QAPAJ6Q/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = apr,
	Number = {4},
	Pages = {2500--2512},
	Title = {Functional {Maps} at the {Onset} of {Auditory} {Inputs} in {Very} {Early} {Preterm} {Human} {Neonates}},
	Url = {https://academic.oup.com/cercor/article/27/4/2500/3056357/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in},
	Urldate = {2017-05-15},
	Volume = {27},
	Year = {2017},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/27/4/2500/3056357/Functional-Maps-at-the-Onset-of-Auditory-Inputs-in},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhw103}}

@article{maggioni_investigation_2015,
	Abstract = {Despite negative blood oxygenation level dependent (BOLD) responses to visual stimuli have recently gained considerable interest, the explanation for their underlying neuronal and vascular mechanisms is still controversial. In the present study, a multimodal experimental approach is presented to shed light on the negative BOLD phenomenon in the human brain. In particular, information from functional magnetic resonance imaging (fMRI) and near infrared spectroscopy (NIRS) was integrated to confirm and gain insight into the phenomenon of negative BOLD responses (NBRs) to unpatterned intermittent photic stimulation (IPS) in healthy subjects. Eight healthy subjects participated in the study. Consistent findings emerged from the activation analysis of fMRI and NIRS data and the comparison of BOLD and hemoglobin responses at the single channel level showed that NBRs are related to a decrease in oxyhemoglobin (HbO) combined with a lower increase in deoxyhemoglobin (HHb), corresponding to a decrease in total hemoglobin (THb) and estimated cerebral blood volume (CBV). The HbO and HHb variations were significant in at least one channel in six subjects out of eight (p \&lt; 0.05). The NIRS technique allowed obtaining valuable information on the vascular determinants of the NBRs, since the discrimination between HbO, HHb and THb information provided a more comprehensive view of the negative BOLD phenomenon. The within and between subject heterogeneous BOLD-Hb temporal relations pave the way to further investigations into the neurovascular properties of NBRs.},
	Author = {Maggioni, Eleonora and Molteni, Erika and Zucca, Claudio and Reni, Gianluigi and Cerutti, Sergio and Triulzi, Fabio M. and Arrigoni, Filippo and Bianchi, Anna M.},
	Doi = {10.1016/j.neuroimage.2014.12.074},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BH5I7UAN/Maggioni et al. - 2015 - Investigation of negative BOLD responses in human .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KVJK95HR/S1053811914010805.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = mar,
	Pages = {410--422},
	Title = {Investigation of negative {BOLD} responses in human brain through {NIRS} technique. {A} visual stimulation study},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811914010805},
	Urldate = {2017-06-13},
	Volume = {108},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914010805},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.12.074}}

@article{zhu_mouth_2017,
	Abstract = {Cortex in and around the human posterior superior temporal sulcus (pSTS) is known to be critical for speech perception. The pSTS responds to both the visual modality (especially biological motion) and the auditory modality (especially human voices). Using fMRI in single subjects with no spatial smoothing, we show that visual and auditory selectivity are linked. Regions of the pSTS were identified that preferred visually presented moving mouths (presented in isolation or as part of a whole face) or moving eyes. Mouth-preferring regions responded strongly to voices and showed a significant preference for vocal compared with nonvocal sounds. In contrast, eye-preferring regions did not respond to either vocal or nonvocal sounds. The converse was also true: regions of the pSTS that showed a significant response to speech or preferred vocal to nonvocal sounds responded more strongly to visually presented mouths than eyes. These findings can be explained by environmental statistics. In natural environments, humans see visual mouth movements at the same time as they hear voices, while there is no auditory accompaniment to visual eye movements. The strength of a voxel's preference for visual mouth movements was strongly correlated with the magnitude of its auditory speech response and its preference for vocal sounds, suggesting that visual and auditory speech features are coded together in small populations of neurons within the pSTS.
SIGNIFICANCE STATEMENT Humans interacting face to face make use of auditory cues from the talker's voice and visual cues from the talker's mouth to understand speech. The human posterior superior temporal sulcus (pSTS), a brain region known to be important for speech perception, is complex, with some regions responding to specific visual stimuli and others to specific auditory stimuli. Using BOLD fMRI, we show that the natural statistics of human speech, in which voices co-occur with mouth movements, are reflected in the neural architecture of the pSTS. Different pSTS regions prefer visually presented faces containing either a moving mouth or moving eyes, but only mouth-preferring regions respond strongly to voices.},
	Author = {Zhu, Lin L. and Beauchamp, Michael S.},
	Copyright = {Copyright {\copyright} 2017 the authors 0270-6474/17/372697-12\$15.00/0},
	Doi = {10.1523/JNEUROSCI.2914-16.2017},
	File = {Snapshot:/Users/Cecile/Zotero/storage/4R9DWEQ4/2697.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {Face, audiovisual, multisensory, speech perception, Speech Perception},
	Language = {en},
	Month = mar,
	Number = {10},
	Pages = {2697--2708},
	Pmid = {28179553},
	Shorttitle = {Mouth and {Voice}},
	Title = {Mouth and {Voice}: {A} {Relationship} between {Visual} and {Auditory} {Preference} in the {Human} {Superior} {Temporal} {Sulcus}},
	Url = {http://www.jneurosci.org/content/37/10/2697},
	Urldate = {2017-03-14},
	Volume = {37},
	Year = {2017},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/37/10/2697},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2914-16.2017}}

@article{hall_spectral_2002,
	Author = {Hall, Deborah A. and Johnsrude, Ingrid S. and Haggard, Mark P. and Palmer, Alan R. and Akeroyd, Michael A. and Summerfield, A. Quentin},
	Doi = {10.1093/cercor/12.2.140},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/J4ZB92C3/Hall et al. - 2002 - Spectral and Temporal Processing in Human Auditory.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5FT4TD8S/Spectral-and-Temporal-Processing-in-Human-Auditory.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = feb,
	Number = {2},
	Pages = {140--149},
	Title = {Spectral and {Temporal} {Processing} in {Human} {Auditory} {Cortex}},
	Url = {https://academic.oup.com/cercor/article/12/2/140/301066/Spectral-and-Temporal-Processing-in-Human-Auditory},
	Urldate = {2017-03-10},
	Volume = {12},
	Year = {2002},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/12/2/140/301066/Spectral-and-Temporal-Processing-in-Human-Auditory},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/12.2.140}}

@article{hunter_multifactor_1988,
	Abstract = {Presents a multifactor model for predicting when infants will prefer novel stimuli, when they will prefer familiar stimuli, and when they will show no preference for either is derived. According to this model, preferences for novelty and familiarity are not tied to particular ages, but instead can be found at any age, depending on the duration of previous familiarization and on task difficulty relative to the age and experience of the infant. A selective review is performed to show how the model can be used to provide an alternative explanation for research results supporting the age dependent view of preferences and to review that studies that have directly tested the model. An attempt is made to expand and furbish the model by pointing out additional factors that might be incorporated into it and by interfacing it with several related areas of infant development.},
	Author = {Hunter, Michael A. and Ames, Elinor W.},
	Copyright = {(c) 2016 APA, all rights reserved},
	File = {APA PsycNET Snapshot:/Users/Cecile/Zotero/storage/5PR92QPT/1997-72976-001.html:text/html;Hunter Ames 1988 - A multifactor model of infant preferences for novel.pdf:/Users/Cecile/Zotero/storage/57DP8AF2/Hunter Ames 1988 - A multifactor model of infant preferences for novel.pdf:application/pdf},
	Issn = {0732-9598},
	Journal = {Advances in Infancy Research},
	Keywords = {*Models, *Preferences, Stimulus Novelty},
	Language = {English},
	Pages = {69--95},
	Title = {A multifactor model of infant preferences for novel and familiar stimuli},
	Volume = {5},
	Year = {1988}}

@inproceedings{harding_auditory_2007,
	Abstract = {The idea that the gist of a visual scene is perceived before attention is focused on the details of a particular object is becoming increasingly popular. In the auditory system, on the other hand, it is typically assumed that the sensory signal is first broken down into streams and then attention is applied to select one of the streams. We consider evidence for an alternative: that, in close analogy with the visual system, the gist of an auditory scene is perceived and only afterwards attention is paid to relevant constituents. We find that much experimental evidence is consistent with such a proposal, and we suggest some possibilities for gist representations.},
	Author = {Harding, Sue and Cooke, Martin and K{\"o}nig, Peter},
	Booktitle = {Attention in {Cognitive} {Systems}. {Theories} and {Systems} from an {Interdisciplinary} {Viewpoint}},
	Doi = {10.1007/978-3-540-77343-6_26},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3R2J3BBS/Harding et al. - 2007 - Auditory Gist Perception An Alternative to Attent.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8ZK4NDC9/978-3-540-77343-6_26.html:text/html},
	Language = {en},
	Month = jan,
	Pages = {399--416},
	Publisher = {Springer, Berlin, Heidelberg},
	Shorttitle = {Auditory {Gist} {Perception}},
	Title = {Auditory {Gist} {Perception}: {An} {Alternative} to {Attentional} {Selection} of {Auditory} {Streams}?},
	Url = {https://link.springer.com/chapter/10.1007/978-3-540-77343-6_26},
	Urldate = {2017-03-08},
	Year = {2007},
	Bdsk-Url-1 = {https://link.springer.com/chapter/10.1007/978-3-540-77343-6_26},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-3-540-77343-6_26}}

@article{blasi_investigation_2007,
	Abstract = {Near-infrared spectroscopy has been used to record oxygenation changes in the visual cortex of 4 month old infants. Our in-house topography system, with 30 channels and 3 different source--detector separations, recorded changes in the concentration of oxy-, deoxy- and total haemoglobin (HbO 2 , HHb and HbT) in response to visual stimuli (face, scrambled visual noise and cartoons as rest). The aim of this work was to demonstrate the capability of the system to spatially localize functional activation and study the possibility of depth discrimination in the haemodynamic response. The group data show both face stimulation and visual noise stimulation induced significant increases in HbO 2 from rest, but the increase in HbO 2 with face stimulation was not significantly different from that seen with visual noise stimulation. The face stimuli induced increases in HbO 2 were spread across a greater area across all depths than visual noise induced changes. In results from a single subject there was a significant increase of HbO 2 in the inferior area of the visual cortex in response to both types of stimuli, and a larger number of channels (source--detector pairs) showed HbO 2 increase to face stimuli, especially at the greatest depth. Activation maps were obtained using 3D reconstruction methods on multi source--detector separation optical topography data.},
	Author = {Blasi, A. and Fox, S. and Everdell, N. and Volein, A. and Tucker, L. and Csibra, G. and Gibson, A. P. and Hebden, J. C. and Johnson, M. H. and Elwell, C. E.},
	Doi = {10.1088/0031-9155/52/23/005},
	Issn = {0031-9155},
	Journal = {Physics in Medicine \& Biology},
	Language = {en},
	Number = {23},
	Pages = {6849},
	Title = {Investigation of depth dependent changes in cerebral haemodynamics during face perception in infants},
	Url = {http://stacks.iop.org/0031-9155/52/i=23/a=005},
	Urldate = {2017-08-03},
	Volume = {52},
	Year = {2007},
	Bdsk-Url-1 = {http://stacks.iop.org/0031-9155/52/i=23/a=005},
	Bdsk-Url-2 = {https://doi.org/10.1088/0031-9155/52/23/005}}

@article{peelle_phase-locked_2013,
	Abstract = {A growing body of evidence shows that ongoing oscillations in auditory cortex modulate their phase to match the rhythm of temporally regular acoustic stimuli, increasing sensitivity to relevant environmental cues and improving detection accuracy. In the current study, we test the hypothesis that nonsensory information provided by linguistic content enhances phase-locked responses to intelligible speech in the human brain. Sixteen adults listened to meaningful sentences while we recorded neural activity using magnetoencephalography. Stimuli were processed using a noise-vocoding technique to vary intelligibility while keeping the temporal acoustic envelope consistent. We show that the acoustic envelopes of sentences contain most power between 4 and 7 Hz and that it is in this frequency band that phase locking between neural activity and envelopes is strongest. Bilateral oscillatory neural activity phase-locked to unintelligible speech, but this cerebro-acoustic phase locking was enhanced when speech was intelligible. This enhanced phase locking was left lateralized and localized to left temporal cortex. Together, our results demonstrate that entrainment to connected speech does not only depend on acoustic characteristics, but is also affected by listeners' ability to extract linguistic information. This suggests a biological framework for speech comprehension in which acoustic and linguistic cues reciprocally aid in stimulus prediction.},
	Author = {Peelle, Jonathan E. and Gross, Joachim and Davis, Matthew H.},
	Doi = {10.1093/cercor/bhs118},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/GDCVEHHG/Peelle et al. - 2013 - Phase-Locked Responses to Speech in Human Auditory.pdf:application/pdf},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex (New York, NY)},
	Month = jun,
	Number = {6},
	Pages = {1378--1387},
	Pmcid = {PMC3643716},
	Pmid = {22610394},
	Title = {Phase-{Locked} {Responses} to {Speech} in {Human} {Auditory} {Cortex} are {Enhanced} {During} {Comprehension}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3643716/},
	Urldate = {2017-05-31},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3643716/},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhs118}}

@article{prieto_phonotactic_2012,
	Abstract = {The goal of this study is twofold: first, to examine in greater depth the claimed contribution of differences in syllable structure to measures of speech rhythm for three languages that are reported to belong to different rhythmic classes, namely, English, Spanish, and Catalan; and second, to investigate differences in the durational marking of prosodic heads and final edges of prosodic constituents between the three languages and test whether this distinction correlates in any way with the rhythmic distinctions. Data from a total of 24 speakers reading 720 utterances from these three languages show that differences in the rhythm metrics emerge even when syllable structure is controlled for in the experimental materials, at least between English on the one hand and Spanish/Catalan on the other, suggesting that important differences in durational patterns exist between these languages that cannot simply be attributed to differences in phonotactic properties. In particular, the vocalic variability measures nPVI-V, ÎV, and VarcoV are shown to be robust tools for discrimination above and beyond such phonotactic properties. Further analyses of the data indicate that the rhythmic class distinctions under consideration finely correlate with differences in the way these languages instantiate two prosodic timing processes, namely, the durational marking of prosodic heads, and pre-final lengthening at prosodic boundaries.},
	Author = {Prieto, Pilar and Vanrell, Maria del Mar and Astruc, Llu{\"\i}sa and Payne, Elinor and Post, Brechtje},
	Doi = {10.1016/j.specom.2011.12.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EMK6C5TM/Prieto et al. - 2012 - Phonotactic and phrasal properties of speech rhyth.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/82TZ8VQD/S0167639311001646.html:text/html},
	Issn = {0167-6393},
	Journal = {Speech Communication},
	Keywords = {Rhythm, Accentual lengthening, Catalan language, English language, Final lengthening, Rhythm index measures, Spanish language},
	Month = jul,
	Number = {6},
	Pages = {681--702},
	Title = {Phonotactic and phrasal properties of speech rhythm. {Evidence} from {Catalan}, {English}, and {Spanish}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0167639311001646},
	Urldate = {2017-04-18},
	Volume = {54},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0167639311001646},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.specom.2011.12.001}}

@article{dauer_stress-timing_1983,
	Abstract = {Comparisons of data from continuous texts in English, Thai, Spanish, Italian, and Greek show that interstress intervals in English, a stress-timed language, are no more isochronous than interstress intervals in Spanish, a syllable-timed language, or any of the other languages investigated. A tendency for stresses to recur regularly appears to be a language-universal property. The difference between stress-timed and syllable-timed languages has to do with differences in syllable structure, vowel reduction, and the phonetic realization of stress and its influence on the linguistic system. Languages, language varieties, or historical stages of a language can be considered more or less stress-based, depending on differences in these characteristics. It seems likely that rhythmic grouping takes place even in languages that have been called syllable timed. (55 ref)},
	Author = {Dauer, M. R.},
	Copyright = {(c) 2016 APA, all rights reserved},
	File = {APA PsycNET Snapshot:/Users/Cecile/Zotero/storage/XG2TEPQN/1983-29886-001.html:text/html},
	Issn = {0095-4470},
	Journal = {Journal of Phonetics},
	Keywords = {*Foreign Languages, Syllables, *Language, *Phonology},
	Language = {English},
	Number = {1},
	Pages = {51--62},
	Title = {Stress-timing and syllable-timing reanalyzed},
	Volume = {11},
	Year = {1983}}

@article{cohen_acoustic_2007,
	Abstract = {Communication is one of the fundamental components of both human and nonhuman animal behavior. Auditory communication signals (i.e., vocalizations) are especially important in the socioecology of several species of nonhuman primates such as rhesus monkeys. In rhesus, the ventrolateral prefrontal cortex (vPFC) is thought to be part of a circuit involved in representing vocalizations and other auditory objects. To further our understanding of the role of the vPFC in processing vocalizations, we characterized the spectrotemporal features of rhesus vocalizations, compared these features with other classes of natural stimuli, and then related the rhesus-vocalization acoustic features to neural activity. We found that the range of these spectrotemporal features was similar to that found in other ensembles of natural stimuli, including human speech, and identified the subspace of these features that would be particularly informative to discriminate between different vocalizations. In a first neural study, however, we found that the tuning properties of vPFC neurons did not emphasize these particularly informative spectrotemporal features. In a second neural study, we found that a first-order linear model (the spectrotemporal receptive field) is not a good predictor of vPFC activity. The results of these two neural studies are consistent with the hypothesis that the vPFC is not involved in coding the first-order acoustic properties of a stimulus but is involved in processing the higher-order information needed to form representations of auditory objects.},
	Author = {Cohen, Yale E. and Theunissen, Fr{\'e}d{\'e}ric and Russ, Brian E. and Gill, Patrick},
	Copyright = {Copyright {\copyright} 2007 by the American Physiological Society},
	Doi = {10.1152/jn.00769.2006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2RNC93GG/Cohen et al. - 2007 - Acoustic Features of Rhesus Vocalizations and Thei.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P7996G5R/1470.html:text/html},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {1470--1484},
	Pmid = {17135477},
	Title = {Acoustic {Features} of {Rhesus} {Vocalizations} and {Their} {Representation} in the {Ventrolateral} {Prefrontal} {Cortex}},
	Url = {http://jn.physiology.org/content/97/2/1470},
	Urldate = {2017-04-05},
	Volume = {97},
	Year = {2007},
	Bdsk-Url-1 = {http://jn.physiology.org/content/97/2/1470},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00769.2006}}

@inproceedings{ramus_psychological_2003,
	Abstract = {Linguists have traditionally classified languages into three
rhythm classes, namely stress-timed, syllable-timed and mora-timed languages. However, this classification has remained controversial for various reasons: the search for reliable acoustic cues to the different rhythm types has long remained elusive; some languages are claimed to belong to none of the three classes; and few perceptual studies has bolstered the notion. We have previously proposed an acoustic/phonetic model of the different types of linguistic rhythm, and of their categorisation as such by
listeners. Here, we present perceptual experiments that directly test the notion of rhythm classes, our model's predictions, and the question of intermediate languages. Language discrimination experiments were run using a speech resynthesis technique to ensure that only rhythmic cues were available to the subjects. Languages investigated were English, Dutch, Spanish, Catalan and Polish. Our results are consistent with the idea that English and Dutch are stress-timed, Spanish and Catalan are syllable-timed,
but Polish seems to be different from any other language studied and thus may constitute a new rhythm class. We propose that perceptual studies tapping the ability to discriminate languages' rhythm are the proper way to generate more empirical data relevant to rhythm typology.},
	Author = {Ramus, Franck and Dupoux, Emmanuel and Mehler, Jacques},
	File = {ICPhS03.pdf:/Users/Cecile/Zotero/storage/BCFTZMLG/ICPhS03.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M4UFZPJ6/3079.html:text/html},
	Publisher = {Universitat Aut{\`o}noma de Barcelona},
	Shorttitle = {The psychological reality of rhythm classes},
	Title = {The psychological reality of rhythm classes: {Perceptual} studies},
	Url = {http://cogprints.org/3079/},
	Urldate = {2017-04-18},
	Year = {2003},
	Bdsk-Url-1 = {http://cogprints.org/3079/}}

@article{zimmer_[18f]fdg_2017,
	Abstract = {Contributions of glial cells to neuroenergetics have been the focus of extensive debate. Here we provide positron emission tomography evidence that activation of astrocytic glutamate transport via the excitatory amino acid transporter GLT-1 triggers widespread but graded glucose uptake in the rodent brain. Our results highlight the need for a reevaluation of the interpretation of [18F]FDG positron emission tomography data, whereby astrocytes would be recognized as contributing to the [18F]FDG signal.},
	Author = {Zimmer, Eduardo R. and Parent, Maxime J. and Souza, D{\'e}bora G. and Leuzy, Antoine and Lecrux, Clotilde and Kim, Hyoung-Ihl and Gauthier, Serge and Pellerin, Luc and Hamel, Edith and Rosa-Neto, Pedro},
	Copyright = {{\copyright} 2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/nn.4492},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DRPP25N3/Zimmer et al. - 2017 - [18F]FDG PET signal is driven by astroglial glutam.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Z2KIP3QG/nn.4492.html:text/html},
	Issn = {1097-6256},
	Journal = {Nature Neuroscience},
	Keywords = {positron-emission tomography, Neurochemistry},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {393--395},
	Title = {[{18F}]{FDG} {PET} signal is driven by astroglial glutamate transport},
	Url = {http://www.nature.com/neuro/journal/v20/n3/full/nn.4492.html},
	Urldate = {2017-04-13},
	Volume = {20},
	Year = {2017},
	Bdsk-Url-1 = {http://www.nature.com/neuro/journal/v20/n3/full/nn.4492.html},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.4492}}

@article{arvaniti_usefulness_2012,
	Abstract = {The performance of the rhythm metrics ÎC, \%V, PVIs and Varcos, said to quantify rhythm class distinctions, was tested using English, German, Greek, Italian, Korean and Spanish. Eight participants per language produced speech using three elicitation methods, spontaneous speech, story reading and reading a set of sentences divided into ``uncontrolled'' sentences from original works of each language, and sentences devised to maximize or minimize syllable structure complexity (``stress-timed'' and ``syllable-timed'' sets respectively). Rhythm classifications based on pooled data were inconsistent across metrics, while cross-linguistic differences in scores were often statistically non-significant even for comparisons between prototypical languages like English and Spanish. Metrics showed substantial inter-speaker variation and proved very sensitive to elicitation method and syllable complexity, so that the size of both effects was large and often comparable to that of language. These results suggest that any cross-linguistic differences captured by metrics are not robust; metric scores range substantially within a language and are readily affected by a variety of methodological decisions, making cross-linguistic comparisons and rhythmic classifications based on metrics unsafe at best.},
	Author = {Arvaniti, Amalia},
	Doi = {10.1016/j.wocn.2012.02.003},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/6DM3HWNS/Arvaniti - 2012 - The usefulness of metrics in the quantification of.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/49EEG99U/S0095447012000137.html:text/html},
	Issn = {0095-4470},
	Journal = {Journal of Phonetics},
	Month = may,
	Number = {3},
	Pages = {351--373},
	Title = {The usefulness of metrics in the quantification of speech rhythm},
	Url = {http://www.sciencedirect.com/science/article/pii/S0095447012000137},
	Urldate = {2017-04-18},
	Volume = {40},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0095447012000137},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.wocn.2012.02.003}}

@article{natan_gain_2017,
	Author = {Natan, Ryan G. and Carruthers, Isaac M. and Mwilambwe-Tshilobo, Laetitia and Geffen, Maria N.},
	Doi = {10.1093/cercor/bhw083},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/QEPXL7WZ/Natan et al. - 2017 - Gain Control in the Auditory Cortex Evoked by Chan.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UB9EKX77/Gain-Control-in-the-Auditory-Cortex-Evoked-by.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/H2DFQJZZ/3056262.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = mar,
	Number = {3},
	Pages = {2385--2402},
	Title = {Gain {Control} in the {Auditory} {Cortex} {Evoked} by {Changing} {Temporal} {Correlation} of {Sounds}},
	Url = {https://academic.oup.com/cercor/article-abstract/27/3/2385/3056262/Gain-Control-in-the-Auditory-Cortex-Evoked-by},
	Urldate = {2017-04-05},
	Volume = {27},
	Year = {2017},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article-abstract/27/3/2385/3056262/Gain-Control-in-the-Auditory-Cortex-Evoked-by},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhw083}}

@article{moore_noise-invariant_2013,
	Abstract = {Author Summary Birds and humans excel at the task of detecting important sounds, such as song and speech, in difficult listening environments such as in a large bird colony or in a crowded bar. How our brains achieve such a feat remains a mystery to both neuroscientists and audio engineers. In our research, we found a population of neurons in the brain of songbirds that are able to extract a song signal from a background of noise. We explain how the neurons are able to perform this task and show how a biologically inspired algorithm could outperform the best noise-reduction methods proposed by engineers.},
	Author = {Moore, R. Channing and Lee, Tyler and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1371/journal.pcbi.1002942},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4N4TQTIQ/Moore et al. - 2013 - Noise-invariant Neurons in the Avian Auditory Cort.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/GX8F7CNW/Moore et al. - 2013 - Noise-invariant Neurons in the Avian Auditory Cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/I2PFS8FQ/article.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/T46GS26Z/article.html:text/html},
	Issn = {1553-7358},
	Journal = {PLOS Computational Biology},
	Keywords = {Algorithms, Audio signal processing, Modulation, Neuronal tuning, Neurons, Signal filtering, Signal processing, Speech signal processing},
	Month = mar,
	Number = {3},
	Pages = {e1002942},
	Shorttitle = {Noise-invariant {Neurons} in the {Avian} {Auditory} {Cortex}},
	Title = {Noise-invariant {Neurons} in the {Avian} {Auditory} {Cortex}: {Hearing} the {Song} in {Noise}},
	Url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002942},
	Urldate = {2017-04-05},
	Volume = {9},
	Year = {2013},
	Bdsk-Url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002942},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pcbi.1002942}}

@incollection{grabe_durational_2002,
	Address = {Berlin, Boston},
	Author = {Grabe, Esther and Low, Ee Ling},
	Booktitle = {Laboratory {Phonology} 7},
	Doi = {10.1515/9783110197105.2.515},
	Edition = {Reprint 2013},
	File = {Grabe_Low-reformatted.pdf:/Users/Cecile/Zotero/storage/QRHMEHQD/Grabe_Low-reformatted.pdf:application/pdf},
	Isbn = {978-3-11-019710-5},
	Publisher = {De Gruyter},
	Title = {Durational variability in speech and the {Rhythm} {Class} {Hypothesis}},
	Url = {https://www.degruyter.com/view/books/9783110197105/9783110197105.2.515/9783110197105.2.515.xml},
	Urldate = {2017-04-18},
	Year = {2002},
	Bdsk-Url-1 = {https://www.degruyter.com/view/books/9783110197105/9783110197105.2.515/9783110197105.2.515.xml},
	Bdsk-Url-2 = {https://doi.org/10.1515/9783110197105.2.515}}

@article{ng_eeg_2013,
	Author = {Ng, Benedict Shien Wei and Logothetis, Nikos K. and Kayser, Christoph},
	Doi = {10.1093/cercor/bhs031},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UW5ACM5M/Ng et al. - 2013 - EEG Phase Patterns Reflect the Selectivity of Neur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GDIP4PZA/bhs031.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = feb,
	Number = {2},
	Pages = {389--398},
	Title = {{EEG} {Phase} {Patterns} {Reflect} the {Selectivity} of {Neural} {Firing}},
	Url = {https://academic.oup.com/cercor/article/23/2/389/286373/EEG-Phase-Patterns-Reflect-the-Selectivity-of},
	Urldate = {2017-06-01},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/23/2/389/286373/EEG-Phase-Patterns-Reflect-the-Selectivity-of},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhs031}}

@article{fukui_monte_2003,
	Abstract = {In near-infrared spectroscopy and imaging, the sensitivity of the detected signal to brain activation and the volume of interrogated tissue are clinically important. Light propagation in adult and neonatal heads is strongly affected by the presence of a low-scattering cerebrospinal fluid layer. The effect of the heterogeneous structure of the head on light propagation in the adult brain is likely to be different from that in the neonatal brain because the thickness of the superficial tissues and the optical properties of the brain of the neonatal head are quite different from those of the adult head. In this study, light propagation in the two-dimensional realistic adult and neonatal head models, whose geometries are generated from a magnetic resonance imaging scan of the human heads, is predicted by Monte Carlo simulation. The sandwich structure, which is a low-scattering cerebrospinal fluid layer held between the high-scattering skull and gray matter, strongly affects light propagation in the brain of the adult head. The sensitivity of the absorption change in the gray matter is improved; however, the intensely sensitive region is confined to the shallow region of the gray matter. The high absorption of the neonatal brain causes a similar effect on light propagation in the head. The intensely sensitive region in the neonatal brain is confined to the gray matter; however, the spatial sensitivity profile penetrates into the deeper region of the white matter.},
	Author = {Fukui, Yuich and Ajichi, Yusaku and Okada, Eiji},
	Copyright = {{\copyright} 2003 Optical Society of America},
	Doi = {10.1364/AO.42.002881},
	File = {fukui2003.pdf:/Users/Cecile/Zotero/storage/U6AG9G29/fukui2003.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ICUCZTM2/abstract.html:text/html},
	Issn = {1539-4522},
	Journal = {Applied Optics},
	Keywords = {Light propagation in tissues, Medical optics and biotechnology, Medical optics instrumentation},
	Language = {EN},
	Month = jun,
	Number = {16},
	Pages = {2881--2887},
	Title = {Monte {Carlo} prediction of near-infrared light propagation in realistic adult and neonatal head models},
	Url = {https://www.osapublishing.org/abstract.cfm?uri=ao-42-16-2881},
	Urldate = {2017-06-13},
	Volume = {42},
	Year = {2003},
	Bdsk-Url-1 = {https://www.osapublishing.org/abstract.cfm?uri=ao-42-16-2881},
	Bdsk-Url-2 = {https://doi.org/10.1364/AO.42.002881}}

@article{minagawa-kawai_assessing_2011,
	Abstract = {Past studies have found that in adults that acoustic properties of sound signals (such as fast vs. slow temporal features) differentially activate the left and right hemispheres, and some have hypothesized that left-lateralization for speech processing may follow from left-lateralization to rapidly changing signals. Here, we tested whether newborns' brains show some evidence of signal-specific lateralization responses using near-infrared spectroscopy (NIRS) and auditory stimuli that elicits lateralized responses in adults, composed of segments that vary in duration and spectral diversity. We found significantly greater bilateral responses of oxygenated hemoglobin (oxy-Hb) in the temporal areas for stimuli with a minimum segment duration of 21 ms, than stimuli with a minimum segment duration of 667 ms. However, we found no evidence for hemispheric asymmetries dependent on the stimulus characteristics. We hypothesize that acoustic-based functional brain asymmetries may develop throughout early infancy, and discuss their possible relationship with brain asymmetries for language.},
	Author = {Minagawa-Kawai, Yasuyo and Cristi{\`a}, Alejandrina and Vendelin, Inga and Cabrol, Dominique and Dupoux, Emmanuel},
	Doi = {10.3389/fpsyg.2011.00135},
	File = {Minagawa-Kawai et al. - 2011 - Assessing Signal-Driven Mechanisms in Neonates Br.pdf:/Users/Cecile/Zotero/storage/Y4PM6S9J/Minagawa-Kawai et al. - 2011 - Assessing Signal-Driven Mechanisms in Neonates Br.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {near-infrared spectroscopy (NIRS), functional lateralization, hemispheric specialization, signal-driven system, neonates, Development, Auditory cortex},
	Language = {English},
	Shorttitle = {Assessing {Signal}-{Driven} {Mechanisms} in {Neonates}},
	Title = {Assessing {Signal}-{Driven} {Mechanisms} in {Neonates}: {Brain} {Responses} to {Temporally} and {Spectrally} {Different} {Sounds}},
	Url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00135/full},
	Urldate = {2017-06-13},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fpsyg.2011.00135/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00135}}

@article{strangman_non-invasive_2002,
	Abstract = {This article reviews diffuse optical brain imaging, a technique that employs near-infrared light to non-invasively probe the brain for changes in parameters relating to brain function. We describe the general methodology, including types of measurements and instrumentation (including the tradeoffs inherent in the various instrument components), and the basic theory required to interpret the recorded data. A brief review of diffuse optical applications is included, with an emphasis on research that has been done with psychiatric populations. Finally, we discuss some practical issues and limitations that are relevant when conducting diffuse optical experiments. We find that, while diffuse optics can provide substantial advantages to the psychiatric researcher relative to the alternative brain imaging methods, the method remains substantially underutilized in this field.},
	Author = {Strangman, Gary and Boas, David A and Sutton, Jeffrey P},
	Doi = {10.1016/S0006-3223(02)01550-0},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/6RIK47NK/Strangman et al. - 2002 - Non-invasive neuroimaging using near-infrared ligh.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/HKUJ7XCG/S0006322302015500.html:text/html},
	Issn = {0006-3223},
	Journal = {Biological Psychiatry},
	Keywords = {NIRS, optical imaging, Diffuse optical tomography, functional brain activity, non-invasive},
	Month = oct,
	Number = {7},
	Pages = {679--693},
	Title = {Non-invasive neuroimaging using near-infrared light},
	Url = {http://www.sciencedirect.com/science/article/pii/S0006322302015500},
	Urldate = {2017-06-13},
	Volume = {52},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0006322302015500},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0006-3223(02)01550-0}}

@article{blasi_early_2011,
	Abstract = {Human voices play a fundamental role in social communication, and areas of the adult ``social brain'' show specialization for processing voices and their emotional content (superior temporal sulcus, inferior prefrontal cortex, premotor cortical regions, amygdala, and insula) [1--8]. However, it is unclear when this specialization develops. Functional magnetic resonance (fMRI) studies suggest that the infant temporal cortex does not differentiate speech from music or backward speech [9, 10], but a prior study with functional near-infrared spectroscopy revealed preferential activation for human voices in 7-month-olds, in a more posterior location of the temporal cortex than in adults [11]. However, the brain networks involved in processing nonspeech human vocalizations in early development are still unknown. To address this issue, in the present fMRI study, 3- to 7-month-olds were presented with adult nonspeech vocalizations (emotionally neutral, emotionally positive, and emotionally negative) and nonvocal environmental sounds. Infants displayed significant differential activation in the anterior portion of the temporal cortex, similarly to adults [1]. Moreover, sad vocalizations modulated the activity of brain regions involved in processing affective stimuli such as the orbitofrontal cortex [12] and insula [7, 8]. These results suggest remarkably early functional specialization for processing human voice and negative emotions.},
	Author = {Blasi, Anna and Mercure, Evelyne and Lloyd-Fox, Sarah and Thomson, Alex and Brammer, Michael and Sauter, Disa and Deeley, Quinton and Barker, Gareth J. and Renvall, Ville and Deoni, Sean and Gasston, David and Williams, Steven C. R. and Johnson, Mark H. and Simmons, Andrew and Murphy, Declan G. M.},
	Doi = {10.1016/j.cub.2011.06.009},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AQMGDNJ8/S0960982211006543.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Month = jul,
	Number = {14},
	Pages = {1220--1224},
	Title = {Early {Specialization} for {Voice} and {Emotion} {Processing} in the {Infant} {Brain}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982211006543},
	Urldate = {2017-06-16},
	Volume = {21},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982211006543},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2011.06.009}}

@article{ferradal_functional_2016,
	Author = {Ferradal, Silvina L. and Liao, Steve M. and Eggebrecht, Adam T. and Shimony, Joshua S. and Inder, Terrie E. and Culver, Joseph P. and Smyser, Christopher D.},
	Doi = {10.1093/cercor/bhu320},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6T4K8ZVB/Ferradal et al. - 2016 - Functional Imaging of the Developing Brain at the .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GMVHXXM3/Functional-Imaging-of-the-Developing-Brain-at-the.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = apr,
	Number = {4},
	Pages = {1558--1568},
	Title = {Functional {Imaging} of the {Developing} {Brain} at the {Bedside} {Using} {Diffuse} {Optical} {Tomography}},
	Url = {https://academic.oup.com/cercor/article/26/4/1558/2366869/Functional-Imaging-of-the-Developing-Brain-at-the},
	Urldate = {2017-06-13},
	Volume = {26},
	Year = {2016},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/26/4/1558/2366869/Functional-Imaging-of-the-Developing-Brain-at-the},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhu320}}

@article{lloyd-fox_illuminating_2010,
	Abstract = {A decade has passed since near infrared spectroscopy (NIRS) was first applied to functional brain imaging in infants. As part of the team that published the first functional near infrared spectroscopy (fNIRS) infant study in 1998, we have continued to develop and refine both the technology and methods associated with these measurements. The increasing international interest that this technology is generating among neurodevelopmental researchers and the recent technical developments in biomedical optics have prompted us to compile this review of the challenges that have been overcome in this field, and the practicalities of performing fNIRS in infants. We highlight the increasingly diverse and ambitious studies that have been undertaken and review the technological and methodological advances that have been made in the study design, optical probe development, and interpretation and analyses of the haemodynamic response. A strong emphasis is placed on the potential of the technology and future prospects of fNIRS in the field of developmental neuroscience.},
	Author = {Lloyd-Fox, S. and Blasi, A. and Elwell, C. E.},
	Doi = {10.1016/j.neubiorev.2009.07.008},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QEXN9J5R/Lloyd-Fox et al. - 2010 - Illuminating the developing brain The past, prese.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PPM2HB2P/S0149763409001043.html:text/html},
	Issn = {0149-7634},
	Journal = {Neuroscience \& Biobehavioral Reviews},
	Keywords = {Infant, functional brain imaging, optical imaging, Developmental neuroscience, Near infrared spectroscopy (NIRS)},
	Month = feb,
	Number = {3},
	Pages = {269--284},
	Shorttitle = {Illuminating the developing brain},
	Title = {Illuminating the developing brain: {The} past, present and future of functional near infrared spectroscopy},
	Url = {http://www.sciencedirect.com/science/article/pii/S0149763409001043},
	Urldate = {2017-06-13},
	Volume = {34},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0149763409001043},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neubiorev.2009.07.008}}

@article{plichta_event-related_2006,
	Abstract = {The purpose of the present study was to investigate the retest reliability of event-related functional near-infrared spectroscopy (fNIRS). Therefore, isolated functional activation was evoked in the occipital cortex by a periodic checkerboard stimulation. During a 52-channel fNIRS recording, 12 subjects underwent 60 trials of visual stimulation in two sessions. The retest interval was set to 3 weeks. Linear correlations of the contrast t values supplemented by scatter plots, channel-wise intraclass correlation coefficients (ICC) as well as reproducibility indices for the quantity of activated channels (RQUANTITY) and the location (ROVERLAP) of the detected activation were calculated. The results at the group level showed good reliability in terms of the single measure ICCs (up to 0.84) and excellent reproducibility quantified by RQUANTITY and ROVERLAP (up to 96\% of the quantity and the location were reproducible), whereas the results at the single subjects' level were mediocre. Furthermore, the reliability assessed by single measurement ICCs improved if regarded at a cluster level.},
	Author = {Plichta, M. M. and Herrmann, M. J. and Baehne, C. G. and Ehlis, A. -C. and Richter, M. M. and Pauli, P. and Fallgatter, A. J.},
	Doi = {10.1016/j.neuroimage.2005.12.008},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ASQUF43T/Plichta et al. - 2006 - Event-related functional near-infrared spectroscop.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7BIJ22RQ/S1053811905025425.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {NIRS, Time series analysis, Deoxygenated haemoglobin, Event-related, Functional near-infrared spectroscopy, Oxygenated haemoglobin, Reproducibility, Test--retest reliability, Total haemoglobin},
	Month = may,
	Number = {1},
	Pages = {116--124},
	Shorttitle = {Event-related functional near-infrared spectroscopy ({fNIRS})},
	Title = {Event-related functional near-infrared spectroscopy ({fNIRS}): {Are} the measurements reliable?},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811905025425},
	Urldate = {2017-06-13},
	Volume = {31},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811905025425},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2005.12.008}}

@article{taga_brain_2003,
	Abstract = {Studies of young infants are critical to understand perceptual, motor, and cognitive processing in humans. However, brain mechanisms involved are poorly understood, because the use of brain-imaging methods such as functional magnetic resonance imaging in awake infants is difficult. In the present study we show functional brain imaging of awake infants viewing visual stimuli by means of multichannel near-infrared spectroscopy, a technique that permits a measurement of cerebral hemoglobin oxygenation in response to brain activation through the intact skull without subject constraint. We found that event-related increases in oxyhemoglobin were evident in localized areas of the occipital cortex of infants aged 2--4 months in response to a brief presentation of a checkerboard pattern reversal while they maintained fixation to attention-grabbing stimuli. The dynamic change in cerebral blood oxygenation was qualitatively similar to that observed in the adult brain. This result introduces near-infrared optical topography as a method for investigating the functional development of the brain in early infancy.},
	Author = {Taga, Gentaro and Asakawa, Kayo and Maki, Atsushi and Konishi, Yukuo and Koizumi, Hideaki},
	Doi = {10.1073/pnas.1932552100},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KTFIZDDT/Taga et al. - 2003 - Brain imaging in awake infants by near-infrared op.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KMIXH65V/10722.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Language = {en},
	Month = sep,
	Number = {19},
	Pages = {10722--10727},
	Pmid = {12960368},
	Title = {Brain imaging in awake infants by near-infrared optical topography},
	Url = {http://www.pnas.org/content/100/19/10722},
	Urldate = {2017-06-14},
	Volume = {100},
	Year = {2003},
	Bdsk-Url-1 = {http://www.pnas.org/content/100/19/10722},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1932552100}}

@article{brigadoi_how_2015,
	Abstract = {In recent years, it has been demonstrated that using functional near-infrared spectroscopy (fNIRS) channels with short separations to explicitly sample extra-cerebral tissues can provide a significant improvement in the accuracy and reliability of fNIRS measurements. The aim of these short-separation channels is to measure the same superficial hemodynamics observed by standard fNIRS channels while also being insensitive to the brain. We use Monte Carlo simulations of photon transport in anatomically informed multilayer models to determine the optimum source-detector distance for short-separation channels in adult and newborn populations. We present a look-up plot that provides (for an acceptable value of short-separation channel brain sensitivity relative to standard channel brain sensitivity) the optimum short-separation distance. Though values vary across the scalp, when the acceptable ratio of the short-separation channel brain sensitivity to standard channel brain sensitivity is set at 5\%, the optimum short-separation distance is 8.4 mm in the typical adult and 2.15 mm in the term-age infant.},
	Author = {Brigadoi, Sabrina and Cooper, Robert J.},
	Doi = {10.1117/1.NPh.2.2.025005},
	Issn = {2329-423X},
	Journal = {Neurophotonics},
	Keywords = {Functional near-infrared spectroscopy, Monte Carlo simulations, short-separation channel, source--detector distance},
	Language = {eng},
	Month = apr,
	Number = {2},
	Pages = {025005},
	Pmcid = {PMC4478880},
	Pmid = {26158009},
	Shorttitle = {How short is short?},
	Title = {How short is short? {Optimum} source-detector distance for short-separation channels in functional near-infrared spectroscopy},
	Volume = {2},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1117/1.NPh.2.2.025005}}

@article{taga_effects_2007,
	Abstract = {One of the practical problems in neuroimaging using near infrared spectroscopy (NIRS) is to choose an appropriate source-detector distance to maximize the sensitivity to cerebral blood oxygenation and to improve the spatial resolution for mapping cortical activation. While NIRS has attracted increasing attention in neuroimaging in infants, there has been no report of comparative data regarding source-detector distance for the infant brain. In the present study, 9 quietly sleeping 3-month-old infants were exposed to 3-s speech sounds, and hemodynamic responses over the bilateral temporal cortices were assessed by using multiple pairs of source and detector of NIR light with varying distances (1, 2, 3 and 4 cm) and varying intensities (0.6 and 1.2 mW). The statistical analyses of the group-averaged hemodynamic responses and the frequency analyses of the signal-to-noise ratios revealed that a 2-cm source-detector distance with 0.6-mW NIR light provided the highest sensitivity to cortical responses. This indicates that NIRS can be used to detect the activation of the cortical regions, in the infant brain, by using the source-detector distance scaled to the smaller head size of infants and a relatively low intensity of NIR light compared to the ones that have been routinely used in adult studies.},
	Author = {Taga, Gentaro and Homae, Fumitaka and Watanabe, Hama},
	Doi = {10.1016/j.neuroimage.2007.07.050},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4K7U2K3C/Taga et al. - 2007 - Effects of source-detector distance of near infrar.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/U5JU4GV6/S105381190700660X.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = nov,
	Number = {3},
	Pages = {452--460},
	Title = {Effects of source-detector distance of near infrared spectroscopy on the measurement of the cortical hemodynamic response in infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S105381190700660X},
	Urldate = {2017-06-13},
	Volume = {38},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S105381190700660X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2007.07.050}}

@article{brigadoi_4d_2014,
	Abstract = {Diffuse optical tomography is most accurate when an individual's MRI data can be used as a spatial prior for image reconstruction and for visualization of the resulting images of changes in oxy- and deoxy-hemoglobin concentration. As this necessitates an MRI scan to be performed for each study, which undermines many of the advantages of diffuse optical methods, the use of registered atlases to model the individual's anatomy is becoming commonplace. Infant studies require carefully age-matched atlases because of the rapid growth and maturation of the infant brain. In this paper, we present a 4D neonatal head model which, for each week from 29 to 44 weeks post-menstrual age, includes: 1) a multi-layered tissue mask which identifies extra-cerebral layers, cerebrospinal fluid, gray matter, white matter, cerebellum and brainstem, 2) a high-density tetrahedral head mesh, 3) surface meshes for the scalp, gray-matter and white matter layers and 4) cranial landmarks and 10-5 locations on the scalp surface. This package, freely available online at www.ucl.ac.uk/medphys/research/4dneonatalmodel can be applied by users of near-infrared spectroscopy and diffuse optical tomography to optimize probe locations, optimize image reconstruction, register data to cortical locations and ultimately improve the accuracy and interpretation of diffuse optical techniques in newborn populations.},
	Author = {Brigadoi, Sabrina and Aljabar, Paul and Kuklisova-Murgasova, Maria and Arridge, Simon R. and Cooper, Robert J.},
	Doi = {10.1016/j.neuroimage.2014.06.028},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/9DQK95W9/Brigadoi et al. - 2014 - A 4D neonatal head model for diffuse optical imagi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JNPJB8GG/S1053811914005059.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {NIRS, Diffuse optical imaging, Diffuse optical tomography, Mesh, Neonatal head models, Preterm infants},
	Month = oct,
	Pages = {385--394},
	Title = {A {4D} neonatal head model for diffuse optical imaging of pre-term to term infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811914005059},
	Urldate = {2017-06-13},
	Volume = {100},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914005059},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.06.028}}

@article{cristia_online_2013,
	Abstract = {Until recently, imaging the infant brain was very challenging. Functional Near InfraRed Spectroscopy (fNIRS) is a promising, relatively novel technique, whose use is rapidly expanding. As an emergent field, it is particularly important to share methodological knowledge to ensure replicable and robust results. In this paper, we present a community-augmented database which will facilitate precisely this exchange. We tabulated articles and theses reporting empirical fNIRS research carried out on infants below three years of age along several methodological variables. The resulting spreadsheet has been uploaded in a format allowing individuals to continue adding new results, and download the most recent version of the table. Thus, this database is ideal to carry out systematic reviews. We illustrate its academic utility by focusing on the factors affecting three key variables: infant attrition, the reliability of oxygenated and deoxygenated responses, and signal-to-noise ratios. We then discuss strengths and weaknesses of the DBIfNIRS, and conclude by suggesting a set of simple guidelines aimed to facilitate methodological convergence through the standardization of reports.},
	Author = {Cristia, Alejandrina and Dupoux, Emmanuel and Hakuno, Yoko and Lloyd-Fox, Sarah and Schuetze, Manuela and Kivits, Jos{\'e} and Bergvelt, Tomas and Gelder, Marjolijn van and Filippin, Luca and Charron, Sylvain and Minagawa-Kawai, Yasuyo},
	Doi = {10.1371/journal.pone.0058906},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KWHKW8ZJ/Cristia et al. - 2013 - An Online Database of Infant Functional Near Infra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VHXTII3Z/article.pdf:application/pdf},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Age groups, Hemodynamics, neuroimaging, Signal to noise ratio, Supervisors, Infants, Near-infrared spectroscopy, HEMOGLOBIN},
	Month = mar,
	Number = {3},
	Pages = {e58906},
	Shorttitle = {An {Online} {Database} of {Infant} {Functional} {Near} {InfraRed} {Spectroscopy} {Studies}},
	Title = {An {Online} {Database} of {Infant} {Functional} {Near} {InfraRed} {Spectroscopy} {Studies}: {A} {Community}-{Augmented} {Systematic} {Review}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0058906},
	Urldate = {2017-06-13},
	Volume = {8},
	Year = {2013},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0058906},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0058906}}

@article{lloyd-fox_coregistering_2014,
	Abstract = {Abstract. 
Functional near-infrared spectroscopy (fNIRS) is becoming a popular tool in developmental neuroscience for mapping functional localized brain responses. However, as it cannot provide information about underlying anatomy, researchers have begun to conduct spatial registration of fNIRS channels to cortical anatomy in adults. The current work investigated this issue with infants by coregistering fNIRS and magnetic resonance imaging (MRI) data from 55 individuals. Our findings suggest that fNIRS channels can be reliably registered with regions in the frontal and temporal cortex of infants from 4 to 7 months of age. Although some macro-anatomical regions are difficult to consistently define, others are more stable and fNIRS channels on an age-appropriate MRI template are often consistent with individual infant MRIs. We have generated a standardized scalp surface map of fNIRS channel locators to reliably locate cortical regions for fNIRS developmental researchers. This new map can be used to identify the inferior frontal gyrus, superior temporal sulcus (STS) region [which includes the superior and middle temporal gyri (MTG) nearest to the STS], and MTG and temporal-parietal regions in 4- to 7-month-old infants. Future work will model data for the whole head, taking into account the properties of light transport in tissue, and expanding to different ages across development.},
	Author = {Lloyd-Fox, Sarah and Richards, John E. and Blasi, Anna and Murphy, Declan G. M. and Elwell, Clare E. and Johnson, Mark H.},
	Doi = {10.1117/1.NPh.1.2.025006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ITPUKZ7U/Lloyd-Fox et al. - 2014 - Coregistering functional near-infrared spectroscop.pdf:application/pdf},
	Issn = {2329-423X},
	Journal = {Neurophotonics},
	Number = {2},
	Pages = {025006--025006},
	Title = {Coregistering functional near-infrared spectroscopy with underlying cortical areas in infants},
	Url = {http://dx.doi.org/10.1117/1.NPh.1.2.025006},
	Urldate = {2017-06-16},
	Volume = {1},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1117/1.NPh.1.2.025006}}

@article{singh_mapping_2014,
	Abstract = {Seizures in the newborn brain represent a major challenge to neonatal medicine. Neonatal seizures are poorly classified, under-diagnosed, difficult to treat and are associated with poor neurodevelopmental outcome. Video-EEG is the current gold-standard approach for seizure detection and monitoring. Interpreting neonatal EEG requires expertise and the impact of seizures on the developing brain remains poorly understood. In this case study we present the first ever images of the haemodynamic impact of seizures on the human infant brain, obtained using simultaneous diffuse optical tomography (DOT) and video-EEG with whole-scalp coverage. Seven discrete periods of ictal electrographic activity were observed during a 60 minute recording of an infant with hypoxic--ischaemic encephalopathy. The resulting DOT images show a remarkably consistent, high-amplitude, biphasic pattern of changes in cortical blood volume and oxygenation in response to each electrographic event. While there is spatial variation across the cortex, the dominant haemodynamic response to seizure activity consists of an initial increase in cortical blood volume prior to a large and extended decrease typically lasting several minutes. This case study demonstrates the wealth of physiologically and clinically relevant information that DOT--EEG techniques can yield. The consistency and scale of the haemodynamic responses observed here also suggest that DOT--EEG has the potential to provide improved detection of neonatal seizures.},
	Author = {Singh, Harsimrat and Cooper, Robert J. and Wai Lee, Chuen and Dempsey, Laura and Edwards, Andrea and Brigadoi, Sabrina and Airantzis, Dimitrios and Everdell, Nick and Michell, Andrew and Holder, David and Hebden, Jeremy C. and Austin, Topun},
	Doi = {10.1016/j.nicl.2014.06.012},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/EGIPUAEH/Singh et al. - 2014 - Mapping cortical haemodynamics during neonatal sei.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/J6FC2KUT/S2213158214000886.html:text/html},
	Issn = {2213-1582},
	Journal = {NeuroImage: Clinical},
	Keywords = {Diffuse optical tomography (DOT), Functional near infrared spectroscopy (fNIRS), Hypoxic--ischaemic encephalopathy (HIE), Neonatal seizures},
	Pages = {256--265},
	Shorttitle = {Mapping cortical haemodynamics during neonatal seizures using diffuse optical tomography},
	Title = {Mapping cortical haemodynamics during neonatal seizures using diffuse optical tomography: {A} case study},
	Url = {http://www.sciencedirect.com/science/article/pii/S2213158214000886},
	Urldate = {2017-06-13},
	Volume = {5},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S2213158214000886},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.nicl.2014.06.012}}

@article{plichta_model-based_2007,
	Abstract = {To validate the usefulness of a model-based analysis approach according to the general linear model (GLM) for functional near-infrared spectroscopy (fNIRS) data, a rapid event-related paradigm with an unpredictable stimulus sequence was applied to 15 healthy subjects. A parametric design was chosen wherein four differently graded contrasts of a flickering checkerboard were presented, allowing directed hypotheses about the rank order of the evoked hemodynamic response amplitudes. The results indicate the validity of amplitude estimation by three main findings (a) the GLM approach for fNIRS data is capable to identify human brain activation in the visual cortex with inter-stimulus intervals of 4--9 s (6.5 s average) whereas in non-visual areas no systematic activation was detectable; (b) the different contrast level intensities lead to the hypothesized rank order of the GLM amplitude parameters: visual cortex activation evoked by highest contrast \&gt; moderate contrast \&gt; lowest contrast \&gt; no stimulation; (c) analysis of null-events (no stimulation) did not produce any significant activation in the visual cortex or in other brain areas.
We conclude that a model-based GLM approach delivers valid fNIRS amplitude estimations and enables the analysis of rapid event-related fNIRS data series, which is highly relevant in particular for cognitive fNIRS studies.},
	Author = {Plichta, M. M. and Heinzel, S. and Ehlis, A. -C. and Pauli, P. and Fallgatter, A. J.},
	Doi = {10.1016/j.neuroimage.2006.11.028},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/G8BZMHTJ/Plichta et al. - 2007 - Model-based analysis of rapid event-related functi.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/47CCUQ29/S1053811906011657.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {GLM, Methods, NIRS, Event-related, Functional near-infrared spectroscopy, Model-based approach, OLS, Parametric design, Two-stage ordinary least square},
	Month = apr,
	Number = {2},
	Pages = {625--634},
	Shorttitle = {Model-based analysis of rapid event-related functional near-infrared spectroscopy ({NIRS}) data},
	Title = {Model-based analysis of rapid event-related functional near-infrared spectroscopy ({NIRS}) data: {A} parametric validation study},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811906011657},
	Urldate = {2017-06-13},
	Volume = {35},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811906011657},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2006.11.028}}

@article{perdue_effects_2013,
	Abstract = {The objective of this work is to quantify how patterns of cortical activity at different spatial scales are measured by noninvasive functional neuroimaging sensors. We simulated cortical activation patterns at nine different spatial scales in a realistic head model and propagated this activity to magnetoencephalography (MEG), electroencephalography (EEG), diffuse optical tomography (DOT), and functional magnetic resonance imaging (fMRI) sensors in arrangements that are typically used in functional neuroimaging studies. We estimated contrast transfer functions (CTF), correlation distances in sensor space, and the minimum resolvable spatial scale of cortical activity for each modality. We found that CTF decreases as the spatial extent of cortical activity decreases, and that correlations between nearby sensors depend on the spatial extent of cortical activity. For cortical activity on the intermediate spatial scale of 6.7 cm2, the correlation distances (r{\textgreater}0.5) were 1.0 cm for fMRI, 2.0 cm for DOT, 12.8 for EEG, 9.5 cm for MEG magnetometers and 9.7 cm for MEG gradiometers. The resolvable spatial pattern scale was found to be 1.43 cm2 for MEG magnetometers, 0.88 cm2 for MEG gradiometers, 376 cm2 for EEG, 0.75 cm2 for DOT, and 0.072 cm2 for fMRI. These findings show that sensitivity to cortical activity varies substantially as a function of spatial scale within and between the different imaging modalities. This information should be taken into account when interpreting neuroimaging data and when choosing the number of nodes for network analyses in sensor space.},
	Author = {Perdue, Katherine L. and Diamond, Solomon Gilbert},
	Doi = {10.1371/journal.pone.0083299},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CV8FJ99M/Perdue et Diamond - 2013 - Effects of Spatial Pattern Scale of Brain Activity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DZXRUZQX/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Imaging techniques, Electroencephalography, Head, neuroimaging, Magnetometers, Network analysis, functional magnetic resonance imaging, magnetoencephalography},
	Month = dec,
	Number = {12},
	Pages = {e83299},
	Title = {Effects of {Spatial} {Pattern} {Scale} of {Brain} {Activity} on the {Sensitivity} of {DOT}, {fMRI}, {EEG} and {MEG}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083299},
	Urldate = {2017-06-15},
	Volume = {8},
	Year = {2013},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0083299},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0083299}}

@article{duncan_measurement_1996,
	Abstract = {Near infrared spectroscopy (NIRS) has been used to measure concentration changes of cerebral hemoglobin and cytochrome in neonates, children, and adults, to study cerebral oxygenation and hemodynamics. To derive quantitative concentration changes from measurements of light attenuation, the optical path length must be known. This is obtained by multiplying the source/detector separation by a laboratory measured differential path length factor (DPF) which accounts for the increased distance traveled by light due to scattering. DPF has been measured by time of flight techniques on small populations of adults and postmortem infants. The values for adults are greater than those for newborns, and it is not clear how to interpolate the present data for studies on children. Recent developments in instrumentation using phase resolved spectroscopy techniques have produced a bedside unit which can measure optical path length on any subject. We have developed an intensity modulated optical spectrometer which measures path length at four wavelengths. Two hundred and eighty three subjects from 1 d of age to 50 y were studied. Measurements were made at a fixed frequency of 200 MHz and a source detector separation of 4.5 cm. Results suggest a slowly varying age dependence of DPF, following the relation DPF690 = 5.38 + 0.049A0.877, DPF744 = 5.11 + 0.106A0.723, DPF807 = 4.99 + 0.067A0.814, and DPF832 = 4.67 + 0.062A0.819, where DPF690 is the DPF measured at 690 nm and A is age is expressed in years from full term. There was a wide scatter of values, however, implying that ideally DPF should be measured at the time of each study.},
	Author = {Duncan, Arlene and Meek, Judith H. and Clemence, Matthew and Elwell, Clare E. and Fallon, Penny and Tyszczuk, Lidia and Cope, Mark and Delpy, David T.},
	Copyright = {{\copyright} 1996 Nature Publishing Group},
	Doi = {10.1203/00006450-199605000-00025},
	File = {Snapshot:/Users/Cecile/Zotero/storage/HGHQR7R2/pr19962544a.html:text/html},
	Issn = {0031-3998},
	Journal = {Pediatric Research},
	Language = {en},
	Month = may,
	Number = {5},
	Pages = {889--894},
	Title = {Measurement of {Cranial} {Optical} {Path} {Length} as a {Function} of {Age} {Using} {Phase} {Resolved} {Near} {Infrared} {Spectroscopy}},
	Url = {https://www.nature.com/pr/journal/v39/n5/full/pr19962544a.html},
	Urldate = {2017-06-16},
	Volume = {39},
	Year = {1996},
	Bdsk-Url-1 = {https://www.nature.com/pr/journal/v39/n5/full/pr19962544a.html},
	Bdsk-Url-2 = {https://doi.org/10.1203/00006450-199605000-00025}}

@article{plichta_event-related_2006-1,
	Abstract = {The purpose of this study was to investigate the regional specificity of multi-channel functional near-infrared spectroscopy (fNIRS) in the detection of cortical activation in humans. Therefore, brain},
	Author = {Plichta, M. M. and Herrmann, M. J. and Ehlis, A.-C. and Baehne, C. G. and Richter, M. M. and Fallgatter, A. J.},
	Doi = {10.1159/000091723},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/C9BEFBAE/Plichta et al. - 2006 - Event-Related Visual versus Blocked Motor Task De.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/423VVGHJ/91723.html:text/html},
	Issn = {0302-282X, 1423-0224},
	Journal = {Neuropsychobiology},
	Language = {english},
	Number = {2},
	Pages = {77--82},
	Pmid = {16511338},
	Shorttitle = {Event-{Related} {Visual} versus {Blocked} {Motor} {Task}},
	Title = {Event-{Related} {Visual} versus {Blocked} {Motor} {Task}: {Detection} of {Specific} {Cortical} {Activation} {Patterns} with {Functional} {Near}-{Infrared} {Spectroscopy}},
	Url = {http://www.karger.com/Article/Abstract/91723},
	Urldate = {2017-06-15},
	Volume = {53},
	Year = {2006},
	Bdsk-Url-1 = {http://www.karger.com/Article/Abstract/91723},
	Bdsk-Url-2 = {https://doi.org/10.1159/000091723}}

@article{emberson_lateral_2017,
	Abstract = {Understanding how the human visual system develops is crucial to understanding the nature and organization of our complex and varied visual representations. However, previous investigations of the development of the visual system using fMRI are primarily confined to a subset of the visual system (high-level vision: faces, scenes) and relatively late in visual development (starting at 4--5 years of age). The current study extends our understanding of human visual development by presenting the first systematic investigation of a mid-level visual region [the lateral occipital cortex (LOC)] in a population much younger than has been investigated in the past: 6 month olds. We use functional near-infrared spectroscopy (fNIRS), an emerging optical method for recording cortical hemodynamics, to perform neuroimaging with this very young population. Whereas previous fNIRS studies have suffered from imprecise neuroanatomical localization, we rely on the most rigorous MR coregistration of fNIRS data to date to image the infant LOC. We find surprising evidence that at 6 months the LOC has functional specialization that is highly similar to adults. Following Cant and Goodale (2007), we investigate whether the LOC tracks shape information and not other cues to object identity (e.g., texture/material). This finding extends evidence of LOC specialization from early childhood into infancy and earlier than developmental trajectories of high-level visual regions.
SIGNIFICANCE STATEMENT Understanding visual development is crucial to understanding the nature of visual representations in the human brain. Previous studies of visual development have investigated children (4 years and older) and high-level visual areas. This study expands our knowledge of visual development by investigating the functional development of mid-level vision [lateral occipital cortex (LOC)] early in infancy. We find surprisingly adult-like functional specialization of the LOC by 6 months of age: infants exhibit shape selectivity, but not object selectivity, in this region.},
	Author = {Emberson, Lauren L. and Crosswhite, Stephen L. and Richards, John E. and Aslin, Richard N.},
	Copyright = {Copyright {\copyright} 2017 the authors 0270-6474/17/373698-06\$15.00/0},
	Doi = {10.1523/JNEUROSCI.3300-16.2017},
	File = {Snapshot:/Users/Cecile/Zotero/storage/VNVGEF5V/3698.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {Vision, fNIRS, infancy, LOC, representation, visual development},
	Language = {en},
	Month = mar,
	Number = {13},
	Pages = {3698--3703},
	Pmid = {28264984},
	Title = {The {Lateral} {Occipital} {Cortex} {Is} {Selective} for {Object} {Shape}, {Not} {Texture}/{Color}, at {Six} {Months}},
	Url = {http://www.jneurosci.org/content/37/13/3698},
	Urldate = {2017-06-15},
	Volume = {37},
	Year = {2017},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/37/13/3698},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.3300-16.2017}}

@article{watanabe_general_2010,
	Abstract = {A critical issue in the functional development of the cerebral cortex is whether cortical regions are functionally differentiated in early infancy. Although a growing number of neuroimaging studies have revealed that functional differentiation between early sensory and association regions of the cortex is already present at 3 months of age, it is unclear how functional regions per se emerge in the earlier developmental period. Here, we present 3 possible hypotheses regarding the functional development of the cerebral cortex as follows: (1) functionally differentiated regions are prespecified in the early developmental period; (2) functional activations appear in a hierarchical order from early sensory regions to the association regions; and (3) functional activation patterns change in a general-to-specific manner, thereby increasing the localization of regions activated by a particular stimulus and increasing the exclusivity of the response to specific stimuli within a particular cortical region. In the present study, we used multichannel near-infrared spectroscopy (NIRS) to measure cortical hemodynamic responses to 2 different video images of colorful mobile objects and black-and-white checkerboard pattern reversals over the occipital and prefrontal regions in awake 2-month-old infants. Both visual stimuli produced comparative activations over broad regions of the cortex including the early sensory and association regions, supporting the general-to-specific development (Hypothesis 3). This result suggests that functional cortical regions emerge between 2 and 3 months of age for visual perception.},
	Author = {Watanabe, Hama and Homae, Fumitaka and Taga, Gentaro},
	Doi = {10.1016/j.neuroimage.2010.01.068},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UH33P3VI/Watanabe et al. - 2010 - General to specific development of functional acti.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/I2ABAPP6/S105381191000090X.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Infant, functional differentiation, near-infrared spectroscopy (NIRS), Cortical development, Visual object processing},
	Month = may,
	Number = {4},
	Pages = {1536--1544},
	Title = {General to specific development of functional activation in the cerebral cortexes of 2- to 3-month-old infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S105381191000090X},
	Urldate = {2017-06-20},
	Volume = {50},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191000090X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2010.01.068}}

@article{karen_hemodynamic_2008,
	Abstract = {Brain activity is associated with physiological changes, which alter the optical properties of tissue. These changes can be detected by near-infrared spectroscopy (NIRS). Aim of the study was to determine changes in cerebral oxygenation in response to stimulation in the visual cortex in newborn infants during spontaneous sleep in the first days of life. We used an in-house developed multichannel NIRS imaging instrument, the MCP-II, to measure changes in concentration of oxyhemoglobin (O2Hb) and deoxyhemoglobin (HHb) in specific brain areas. In 10 out of 15 subjects, a significant increase in O2Hb and/or a significant decrease in HHb were found in one or more channels over the occipital cortex. During stimulation, O2Hb increased by a mean of 0.98 Î¼mol/l, HHb decreased by a mean 0.17 Î¼mol/l, and total-Hb increased by a mean of 0.81 Î¼mol/l. The hemodynamic response to visual stimulation in the occipital cortex in newborn infants is similar to adults. The increase in O2Hb and the simultaneous decrease in HHb during stimulation suggest an increase in cerebral blood flow (CBF) that overcompensates for the increased oxygen consumption (CMRO2) in the activated cortical area. Hum Brain Mapp, 2008. {\copyright} 2007 Wiley-Liss, Inc.},
	Author = {Karen, Tanja and Morren, Geert and Haensse, Daniel and Bauschatz, Andrea S. and Bucher, Hans Ulrich and Wolf, Martin},
	Doi = {10.1002/hbm.20411},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8SI4NIBB/Karen et al. - 2008 - Hemodynamic response to visual stimulation in newb.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZTT3J92I/abstract.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {Functional near-infrared spectroscopy, age dependence, behavioral state, visual stimulation, hemodynamic response, Infants},
	Language = {en},
	Month = apr,
	Number = {4},
	Pages = {453--460},
	Title = {Hemodynamic response to visual stimulation in newborn infants using functional near-infrared spectroscopy},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20411/abstract},
	Urldate = {2017-06-20},
	Volume = {29},
	Year = {2008},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20411/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.20411}}

@article{zeff_retinotopic_2007,
	Abstract = {Functional neuroimaging is a vital element of neuroscience and cognitive research and, increasingly, is an important clinical tool. Diffuse optical imaging is an emerging, noninvasive technique with unique portability and hemodynamic contrast capabilities for mapping brain function in young subjects and subjects in enriched or clinical environments. We have developed a high-performance, high-density diffuse optical tomography (DOT) system that overcomes previous limitations and enables superior image quality. We show herein the utility of the DOT system by presenting functional hemodynamic maps of the adult human visual cortex. The functional brain images have a high contrast-to-noise ratio, allowing visualization of individual activations and highly repeatable mapping within and across subjects. With the improved spatial resolution and localization, we were able to image functional responses of 1.7 cm in extent and shifts of {\textless}1 cm. Cortical maps of angle and eccentricity in the visual field are consistent with retinotopic studies using functional MRI and positron-emission tomography. These results demonstrate that high-density DOT is a practical and powerful tool for mapping function in the human cortex.},
	Author = {Zeff, Benjamin W. and White, Brian R. and Dehghani, Hamid and Schlaggar, Bradley L. and Culver, Joseph P.},
	Doi = {10.1073/pnas.0611266104},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8RSWWVMR/Zeff et al. - 2007 - Retinotopic mapping of adult human visual cortex w.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6JN6INU9/12169.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {neuroimaging, functional brain mapping, retinotopy, Near-infrared spectroscopy},
	Language = {en},
	Month = jul,
	Number = {29},
	Pages = {12169--12174},
	Pmid = {17616584},
	Title = {Retinotopic mapping of adult human visual cortex with high-density diffuse optical tomography},
	Url = {http://www.pnas.org/content/104/29/12169},
	Urldate = {2017-06-20},
	Volume = {104},
	Year = {2007},
	Bdsk-Url-1 = {http://www.pnas.org/content/104/29/12169},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0611266104}}

@inproceedings{goldowsky_modeling_1993,
	Abstract = {This volume presents research in the field of first language acquisition discussed at the 1992 meeting of the Child Language Research Forum. The contributors are Shanley E. M. Allen, Heike Behrens, Paul Bloom, Anne Christophe, Martha B. Crago, Lisa Dasinger, Kenneth F. Drozd, Emmanuel Dupoux, Boris N. Goldowsky, Jiansheng Guo, Aylin Kuntay, Barbara Landau, Elizabeth Lanza, Ping Li, Michael Maratsos, Jacques Mehler, Elissa L. Newport, Raquel S. Olguin, William Philip, Dan I. Slobin, Trisha Svaib, Michael Tomasello, Cecile Toupin, Jill de Villiers, and Amanda Woodward.},
	Author = {Goldowsky, Boris N. and Newport, Elissa L},
	Booktitle = {The {Proceedings} of the 24th {Annual} {Child} {Language} {Research} {Forum}},
	Isbn = {978-1-881526-04-9},
	Keywords = {Language Arts \& Disciplines / Linguistics / General, Language Arts \& Disciplines / Linguistics / Psycholinguistics, Language Arts \& Disciplines / Linguistics / Semantics},
	Language = {en},
	Month = mar,
	Note = {Google-Books-ID: x4FCUNpgPRQC},
	Publisher = {Center for the Study of Language (CSLI)},
	Title = {Modeling the {Effects} of {Processing} {Limitations} on the {Acquisition} of {Morphology}: {The} {Less} {Is} {More} {Hypothesis}},
	Year = {1993}}

@article{nakano_prefrontal_2009,
	Author = {Nakano, Tamami and Watanabe, Hama and Homae, Fumitaka and Taga, Gentaro},
	Doi = {10.1093/cercor/bhn096},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RVCT9FBI/Nakano et al. - 2009 - Prefrontal Cortical Involvement in Young Infants' .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S9Q7PJ7V/bhn096.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = feb,
	Number = {2},
	Pages = {455--463},
	Title = {Prefrontal {Cortical} {Involvement} in {Young} {Infants}' {Analysis} of {Novelty}},
	Url = {https://academic.oup.com/cercor/article/19/2/455/345396/Prefrontal-Cortical-Involvement-in-Young-Infants},
	Urldate = {2017-07-04},
	Volume = {19},
	Year = {2009},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/19/2/455/345396/Prefrontal-Cortical-Involvement-in-Young-Infants},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhn096}}

@article{issard_adult-like_2017,
	Abstract = {Humans can adapt to a wide range of variations in the speech signal, maintaining an invariant representation of the linguistic information it contains. Among them, adaptation to rapid or time-compressed speech has been well studied in adults, but the developmental origin of this capacity remains unknown. Does this ability depend on experience with speech (if yes, as heard in utero or as heard postnatally), with sounds in general or is it experience-independent? Using near-infrared spectroscopy, we show that the newborn brain can discriminate between three different compression rates: normal, i.e. 100\% of the original duration, moderately compressed, i.e. 60\% of original duration and highly compressed, i.e. 30\% of original duration. Even more interestingly, responses to normal and moderately compressed speech are similar, showing a canonical hemodynamic response in the left temporoparietal, right frontal and right temporal cortex, while responses to highly compressed speech are inverted, showing a decrease in oxyhemoglobin concentration. These results mirror those found in adults, who readily adapt to moderately compressed, but not to highly compressed speech, showing that adaptation to time-compressed speech requires little or no experience with speech, and happens at an auditory, and not at a more abstract linguistic level.},
	Author = {Issard, C{\'e}cile and Gervain, Judit},
	Copyright = {All rights reserved},
	Doi = {10.1016/j.dcn.2016.10.006},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GH273QGZ/IssardGervain16.pdf:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Newborn infants, Temporal envelope, Time-compressed speech, near-infrared spectroscopy (NIRS), prosody},
	Month = jun,
	Pages = {176--184},
	Series = {Sensitive periods across development},
	Shorttitle = {Adult-like processing of time-compressed speech by newborns},
	Title = {Adult-like processing of time-compressed speech by newborns: {A} {NIRS} study},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929316300469},
	Urldate = {2017-07-04},
	Volume = {25},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316300469},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2016.10.006}}

@article{bartocci_cerebral_2001,
	Abstract = {Newborn infants in intensive care units are exposed to several unfamiliar smells, mostly related to the nosocomial environment. How the preterm baby perceives these olfactory stimulations remains unclear. Near-infrared spectroscopy can be performed noninvasively above the olfactory cortex to monitor changes of cerebral blood flow as an indicator of cortical activation. The aim of this study was to explore by near-infrared spectroscopy how odorous substances routinely used in the neonatal intensive care unit influence bilateral cortical hemodynamics in the olfactory region of the brains of preterm infants. Specifically, a detergent (Neomidil) and an adhesive remover (Remove) have been tested. Twenty preterm neonates of gestational age 30--37 wk (mean 33.7 $\pm$ 2.3 SD) and postconceptional age 32--37.3 wk (mean 35.5 $\pm$ 2.75 SD) were monitored by near-infrared spectroscopy. Two optode pairs were placed above the anterior orbitofrontal gyri, which is involved in olfactory processing, on each side of the skull. Fifteen babies were exposed to the smell of a disinfectant and five babies to that of a detergent, both applied to small cotton pads. Changes of oxygenated Hb and deoxygenated Hb were recorded before, during, and after a 10-s stimulus. In 17 out of 20 babies, there was a decrease in oxygenated Hb and total Hb after the exposure to the substances. The decrease was significantly greater in the right side than in the left side. This change was different from that observed in our previous study after exposure to colostrum and the pleasant smell of vanilla, which elicited an increase in blood oxygenation in the same region. The biologic significance of this finding is unknown. We conclude that cortical hemodynamic modifications occur in the preterm newborn after exposure to preparations commonly used in the neonatal intensive care unit. A lateralization seems to occur in processing unpleasant olfactory cues.},
	Author = {Bartocci, Marco and Winberg, Jan and Papendieck, Gesa and Mustica, Teresa and Serra, Giovanni and Lagercrantz, Hugo},
	Copyright = {{\copyright} 2001 Nature Publishing Group},
	Doi = {10.1203/00006450-200109000-00006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3R8F58IQ/Bartocci et al. - 2001 - Cerebral Hemodynamic Response to Unpleasant Odors .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RGCAIXIE/pr2001182a.html:text/html},
	Issn = {0031-3998},
	Journal = {Pediatric Research},
	Language = {en},
	Month = sep,
	Number = {3},
	Pages = {324--330},
	Title = {Cerebral {Hemodynamic} {Response} to {Unpleasant} {Odors} in the {Preterm} {Newborn} {Measured} by {Near}-{Infrared} {Spectroscopy}},
	Url = {http://www.nature.com/pr/journal/v50/n3/full/pr2001182a.html},
	Urldate = {2017-06-20},
	Volume = {50},
	Year = {2001},
	Bdsk-Url-1 = {http://www.nature.com/pr/journal/v50/n3/full/pr2001182a.html},
	Bdsk-Url-2 = {https://doi.org/10.1203/00006450-200109000-00006}}

@article{bartocci_activation_2000,
	Abstract = {In mammals, perception of smells during the first hours of life is an essential prerequisite for adaptation of the newborn to the new extrauterine world. Functional magnetic resonance studies have shown that olfactory impression is processed in the lateral and anterior orbito-frontal gyri of the frontal lobe. Near-infrared spectroscopy (NIRS) can detect changes in oxygenated [Hb O2], and deoxygenated [Hb H] Hb during cortical activation. The aim of this study was to assess by NIRS olfactory cortex activity in newborn infants receiving olfactory stimuli. Twelve males and 11 females were studied when awake at 6 h to 8 d after birth. NIRS monitoring was carried out using two optodes placed above the left anterior orbito-frontal gyri. Each newborn was exposed for 30 s to two different smell stimuli---mother's colostrum and vanilla---and to a negative control, distilled water. Changes in Hb concentration were measured over the orbito-frontal region. During exposure to vanilla, [Hb O2] increased significantly over the left orbito-frontal area in all babies. The magnitude of the [Hb O2] increase over the illuminated region during colostrum exposure was inversely related to postnatal age. We conclude that monitoring Hb changes by NIRS can be valuable in assessing olfactory responsiveness in infants.},
	Author = {Bartocci, Marco and Winberg, Jan and Ruggiero, Carmelina and Bergqvist, Lena L. and Serra, Giovanni and Lagercrantz, Hugo},
	Copyright = {{\copyright} 2000 Nature Publishing Group},
	Doi = {10.1203/00006450-200007000-00006},
	File = {Snapshot:/Users/Cecile/Zotero/storage/TQ79H7XQ/pr2000148a.html:text/html},
	Issn = {0031-3998},
	Journal = {Pediatric Research},
	Language = {en},
	Month = jul,
	Number = {1},
	Pages = {18--23},
	Shorttitle = {Activation of {Olfactory} {Cortex} in {Newborn} {Infants} {After} {Odor} {Stimulation}},
	Title = {Activation of {Olfactory} {Cortex} in {Newborn} {Infants} {After} {Odor} {Stimulation}: {A} {Functional} {Near}-{Infrared} {Spectroscopy} {Study}},
	Url = {http://www.nature.com/pr/journal/v48/n1/full/pr2000148a.html},
	Urldate = {2017-06-20},
	Volume = {48},
	Year = {2000},
	Bdsk-Url-1 = {http://www.nature.com/pr/journal/v48/n1/full/pr2000148a.html},
	Bdsk-Url-2 = {https://doi.org/10.1203/00006450-200007000-00006}}

@article{kozberg_rapid_2016,
	Abstract = {In the adult brain, increases in neural activity lead to increases in local blood flow. However, many prior measurements of functional hemodynamics in the neonatal brain, including functional magnetic resonance imaging (fMRI) in human infants, have noted altered and even inverted hemodynamic responses to stimuli. Here, we demonstrate that localized neural activity in early postnatal mice does not evoke blood flow increases as in the adult brain, and elucidate the neural and metabolic correlates of these altered functional hemodynamics as a function of developmental age. Using wide-field GCaMP imaging, the development of neural responses to somatosensory stimulus is visualized over the entire bilaterally exposed cortex. Neural responses are observed to progress from tightly localized, unilateral maps to bilateral responses as interhemispheric connectivity becomes established. Simultaneous hemodynamic imaging confirms that spatiotemporally coupled functional hyperemia is not present during these early stages of postnatal brain development, and develops gradually as cortical connectivity is established. Exploring the consequences of this lack of functional hyperemia, measurements of oxidative metabolism via flavoprotein fluorescence suggest that neural activity depletes local oxygen to below baseline levels at early developmental stages. Analysis of hemoglobin oxygenation dynamics at the same age confirms oxygen depletion for both stimulus-evoked and resting-state neural activity. This state of unmet metabolic demand during neural network development poses new questions about the mechanisms of neurovascular development and its role in both normal and abnormal brain development. These results also provide important insights for the interpretation of fMRI studies of the developing brain.
SIGNIFICANCE STATEMENT This work demonstrates that the postnatal development of neuronal connectivity is accompanied by development of the mechanisms that regulate local blood flow in response to neural activity. Novel in vivo imaging reveals that, in the developing mouse brain, strong and localized GCaMP neural responses to stimulus fail to evoke local blood flow increases, leading to a state in which oxygen levels become locally depleted. These results demonstrate that the development of cortical connectivity occurs in an environment of altered energy availability that itself may play a role in shaping normal brain development. These findings have important implications for understanding the pathophysiology of abnormal developmental trajectories, and for the interpretation of functional magnetic resonance imaging data acquired in the developing brain.},
	Author = {Kozberg, Mariel G. and Ma, Ying and Shaik, Mohammed A. and Kim, Sharon H. and Hillman, Elizabeth M. C.},
	Copyright = {Copyright {\copyright} 2016 the authors 0270-6474/16/366704-14\$15.00/0},
	Doi = {10.1523/JNEUROSCI.2363-15.2016},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/U2VV839R/Kozberg et al. - 2016 - Rapid Postnatal Expansion of Neural Networks Occur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MW8K2PUE/6704.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {Oxygen Consumption, Neurovascular coupling, fMRI, GCaMP imaging, flavoprotein fluorescence, functional hyperemia, postnatal neural development},
	Language = {en},
	Month = jun,
	Number = {25},
	Pages = {6704--6717},
	Pmid = {27335402},
	Title = {Rapid {Postnatal} {Expansion} of {Neural} {Networks} {Occurs} in an {Environment} of {Altered} {Neurovascular} and {Neurometabolic} {Coupling}},
	Url = {http://www.jneurosci.org/content/36/25/6704},
	Urldate = {2017-06-30},
	Volume = {36},
	Year = {2016},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/36/25/6704},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2363-15.2016}}

@article{csibra_near_2004,
	Abstract = {{\textless}p{\textgreater}We used near infrared spectroscopy to measure changes in cerebral oxygenation in both human infants and adults as they viewed images of faces or control "visual noise" stimuli. At an occipital site, adults showed a significant increase in oxyhaemoglobin and a contrasting pattern of results was observed in infants. While the same general difference between the processing of the two stimuli was observed, a larger decrease in oxyhemoglobin concentration in response to faces than to visual noise was found in infants. These results demonstrate that near infrared spectroscopy can detect differences in stimulus processing induced by a complex visual stimulus in both infants and adults. (J Pediatr Neurol 2004; 2(2): 85--89).{\textless}/p{\textgreater}},
	Author = {Csibra, Gergely and Henty, Julian and Volein, {\'A}gnes and Elwell, Clare and Tucker, Leslie and Meek, Judith and Johnson, Mark H.},
	Copyright = {Georg Thieme Verlag KG Stuttgart -- New York},
	Doi = {10.1055/s-0035-1557198},
	File = {pn04017.pdf:/Users/Cecile/Zotero/storage/3EG2BJHS/pn04017.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XGHXDPGF/s-0035-1557198.html:text/html},
	Issn = {1304-2580, 1875-9041},
	Journal = {Journal of Pediatric Neurology},
	Language = {en},
	Month = jun,
	Number = {02},
	Pages = {085--089},
	Title = {Near infrared spectroscopy reveals neural activation during face perception in infants and adults},
	Url = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0035-1557198},
	Urldate = {2017-06-20},
	Volume = {02},
	Year = {2004},
	Bdsk-Url-1 = {http://www.thieme-connect.de/DOI/DOI?10.1055/s-0035-1557198},
	Bdsk-Url-2 = {https://doi.org/10.1055/s-0035-1557198}}

@article{schacter_reductions_2007,
	Abstract = {Priming is a nonconscious form of memory in which an encounter with a stimulus influences the subsequent identification, production or classification of the same or a related stimulus. Neuroimaging studies have revealed that behavioral priming is typically accompanied by reduced activity in several cortical regions. We review recent studies that have concerned two key issues. First, specificity effects produced by changes between study and test in either the physical features of stimuli or the behavioral response reveal cortical sensitivity to the perceptual, conceptual and stimulus-to-decision mapping properties of primed items. Second, correlations between behavioral priming and activity reductions are robust across a range of tasks and procedures in prefrontal regions but not in posterior regions. On the basis of these recent studies, we suggest that the reduction in cortical activity during priming involves at least two different mechanisms.},
	Author = {Schacter, Daniel L and Wig, Gagan S and Stevens, W Dale},
	Doi = {10.1016/j.conb.2007.02.001},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3WP5RX4C/S0959438807000256.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = apr,
	Number = {2},
	Pages = {171--176},
	Series = {Cognitive neuroscience},
	Title = {Reductions in cortical activity during priming},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438807000256},
	Urldate = {2017-07-04},
	Volume = {17},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438807000256},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2007.02.001}}

@article{hillman_coupling_2014,
	Abstract = {Functional magnetic resonance imaging (fMRI) provides a unique view of the working human mind. The blood-oxygen-level-dependent (BOLD) signal, detected in fMRI, reflects changes in deoxyhemoglobin driven by localized changes in brain blood flow and blood oxygenation, which are coupled to underlying neuronal activity by a process termed neurovascular coupling. Over the past 10 years, a range of cellular mechanisms, including astrocytes, pericytes, and interneurons, have been proposed to play a role in functional neurovascular coupling. However, the field remains conflicted over the relative importance of each process, while key spatiotemporal features of BOLD response remain unexplained. Here, we review current candidate neurovascular coupling mechanisms and propose that previously overlooked involvement of the vascular endothelium may provide a more complete picture of how blood flow is controlled in the brain. We also explore the possibility and consequences of conditions in which neurovascular coupling may be altered, including during postnatal development, pathological states, and aging, noting relevance to both stimulus-evoked and resting-state fMRI studies.},
	Author = {Hillman, Elizabeth M.C.},
	Doi = {10.1146/annurev-neuro-071013-014111},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/NV22DKCJ/Hillman - 2014 - Coupling Mechanism and Significance of the BOLD Si.pdf:application/pdf},
	Issn = {0147-006X},
	Journal = {Annual review of neuroscience},
	Month = jul,
	Pages = {161--181},
	Pmcid = {PMC4147398},
	Pmid = {25032494},
	Shorttitle = {Coupling {Mechanism} and {Significance} of the {BOLD} {Signal}},
	Title = {Coupling {Mechanism} and {Significance} of the {BOLD} {Signal}: {A} {Status} {Report}},
	Url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147398/},
	Urldate = {2017-06-30},
	Volume = {37},
	Year = {2014},
	Bdsk-Url-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147398/},
	Bdsk-Url-2 = {https://doi.org/10.1146/annurev-neuro-071013-014111}}

@article{liao_neonatal_2010,
	Abstract = {The neurodevelopmental outcome of neonatal intensive care unit (NICU) infants is a major clinical concern with many infants displaying neurobehavioral deficits in childhood. Functional neuroimaging may provide early recognition of neural deficits in high-risk infants. Near-infrared spectroscopy (NIRS) has the advantage of providing functional neuroimaging in infants at the bedside. However, limitations in traditional NIRS have included contamination from superficial vascular dynamics in the scalp. Furthermore, controversy exists over the nature of normal vascular, responses in infants. To address these issues, we extend the use of novel high-density NIRS arrays with multiple source-detector distances and a superficial signal regression technique to infants. Evaluations of healthy term-born infants within the first three days of life are performed without sedation using a visual stimulus. We find that the regression technique significantly improves brain activation signal quality. Furthermore, in six out of eight infants, both oxy- and total hemoglobin increases while deoxyhemoglobin decreases, suggesting that, at term, the neurovascular coupling in the visual cortex is similar to that found in healthy adults. These results demonstrate the feasibility of using high-density NIRS arrays in infants to improve signal quality through superficial signal regression, and provide a foundation for further development of high-density NIRS as a clinical tool.},
	Author = {Liao, Steve M. and Gregg, Nick M. and White, Brian R. and Zeff, Benjamin W. and Bjerkaas, Katelin A. and Inder, Terrie E. and Culver, Joseph P.},
	Doi = {10.1117/1.3369809},
	Issn = {1083-3668},
	Journal = {Journal of Biomedical Optics},
	Number = {2},
	Pages = {026010--026010--9},
	Shorttitle = {Neonatal hemodynamic response to visual cortex activity},
	Title = {Neonatal hemodynamic response to visual cortex activity: high-density near-infrared spectroscopy study},
	Url = {http://dx.doi.org/10.1117/1.3369809},
	Urldate = {2017-06-20},
	Volume = {15},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1117/1.3369809}}

@article{watanabe_activation_2012,
	Abstract = {In an infant's developing cortex, the explanation for the mechanisms underlying the activations and deactivations in response to visual stimuli remains controversial. While previous near-infrared spectroscopy (NIRS) studies in awake infants have demonstrated cortical activations in response to meaningful/attractive visual stimuli, functional magnetic resonance imaging (fMRI) studies performed on sleeping infants showed negative blood oxygenation level-dependent (BOLD) responses to high-luminance unpatterned stimulations, such as a photic stimulation. To examine the effect of the characteristics of visual stimuli on cortical processing in awake infants, we measured cortical hemodynamic responses in 6-month-old infants during the presentation of a high-luminance unpatterned stimulus by using a NIRS system with 94 measurement channels. Results from 35 infants showed dissociated cortical responses between the occipital region and the other parts of the cortex, including the temporal and prefrontal regions. Although the visual stimulus produced sustained increases in oxygenated hemoglobin (oxy-Hb) signals in the temporal and prefrontal regions, it produced a transient increase in oxy-Hb signals followed by a salient decrease in oxy-Hb signals during a trial in a focal region of the occipital visual region. This suggests that the deactivation of the occipital visual region in response to visual stimulation is not a phenomenon that occurs only in the sleeping state, but that a high-luminance unpatterned stimulus can induce deactivation even in the awake infants. {\copyright} 2011 Wiley Periodicals, Inc. Dev Psychobiol 54:1--15, 2012.},
	Author = {Watanabe, Hama and Homae, Fumitaka and Taga, Gentaro},
	Doi = {10.1002/dev.20569},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/S9E9GRKK/Watanabe et al. - 2012 - Activation and deactivation in response to visual .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3EMACHE9/abstract.html:text/html},
	Issn = {1098-2302},
	Journal = {Developmental Psychobiology},
	Keywords = {Infant, near-infrared spectroscopy (NIRS), activation, cortical response, deactivation, visual processing},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {1--15},
	Title = {Activation and deactivation in response to visual stimulation in the occipital cortex of 6-month-old human infants},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/dev.20569/abstract},
	Urldate = {2017-06-20},
	Volume = {54},
	Year = {2012},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/dev.20569/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/dev.20569}}

@article{guo_corticothalamic_nodate,
	Abstract = {Summary
Sensory processing must be sensitive enough to encode faint signals near the noise floor but selective enough to differentiate between similar stimuli. Here we describe a layer 6 corticothalamic (L6 CT) circuit in the mouse auditory forebrain that alternately biases sound processing toward hypersensitivity and improved behavioral sound detection or dampened excitability and enhanced sound discrimination. Optogenetic activation of L6 CT neurons could increase or decrease the gain and tuning precision in the thalamus and all layers of the cortical column, depending on the timing between L6 CT activation and sensory stimulation. The direction of neural and perceptual modulation -- enhanced detection at the expense of discrimination or vice versa -- arose from the interaction of L6 CT neurons and subnetworks of fast-spiking inhibitory neurons that reset the phase of low-frequency cortical rhythms. These findings suggest that L6 CT neurons contribute to the resolution of the competing demands of detection and discrimination.},
	Author = {Guo, Wei and Clause, Amanda R. and Barth-Maron, Asa and Polley, Daniel B.},
	Doi = {10.1016/j.neuron.2017.05.019},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/5N6DVQE2/Guo et al. - A Corticothalamic Circuit for Dynamic Switching be.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/HWCD5TWA/S0896627317304579.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {Plasticity, auditory thalamus, layer 6, medial geniculate body, oscillation, phase reset, Modulation, Auditory cortex, Delta Rhythm, Theta Rhythm},
	Title = {A {Corticothalamic} {Circuit} for {Dynamic} {Switching} between {Feature} {Detection} and {Discrimination}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627317304579},
	Urldate = {2017-06-20},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627317304579},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2017.05.019}}

@article{taga_hemodynamic_2003,
	Abstract = {A near-infrared optical topography (OT) was used to reveal spatio-temporal changes in the cerebral oxygenation of newborn infants in response to brief visual stimulation. Newborn infants were presented 3-s stroboscopic light flashing at 14 Hz during spontaneous sleep. Event-related changes in oxy- and deoxyhemoglobin ([oxy-Hb] and [deoxy-Hb]) were observed over the occipital and frontal cortex. The visual stimulus produced statistically significant increases in oxyhemoglobin not only in the occipital cortex but also in the prefrontal cortex. These results suggest that the cerebrovascular coupling is already functioning in newborn's brain. The prefrontal activation implies that it may contribute to early processing of sensory signals.},
	Author = {Taga, Gentaro and Asakawa, Kayo and Hirasawa, Kyoko and Konishi, Yukuo},
	Doi = {10.1016/j.earlhumdev.2003.08.023},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KX8C47BM/S0378378203001324.html:text/html},
	Issn = {0378-3782},
	Journal = {Early Human Development},
	Keywords = {Hemodynamics, brain imaging, Optical topography, Near-infrared spectroscopy, Newborn},
	Month = dec,
	Pages = {203--210},
	Shorttitle = {Hemodynamic responses to visual stimulation in occipital and frontal cortex of newborn infants},
	Title = {Hemodynamic responses to visual stimulation in occipital and frontal cortex of newborn infants: a near-infrared optical topography study},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378378203001324},
	Urldate = {2017-06-20},
	Volume = {75},
	Year = {2003},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378378203001324},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.earlhumdev.2003.08.023}}

@article{watanabe_effect_2013,
	Abstract = {A fundamental question with regard to perceptual development is how multisensory information is processed in the brain during the early stages of development. Although a growing body of evidence has shown the early emergence of modality-specific functional differentiation of the cortical regions, the interplay between sensory inputs from different modalities in the developing brain is not well understood. To study the effects of auditory input during audio-visual processing in 3-month-old infants, we evaluated the spatiotemporal cortical hemodynamic responses of 50 infants while they perceived visual objects with or without accompanying sounds. The responses were measured using 94-channel near-infrared spectroscopy over the occipital, temporal, and frontal cortices. The effects of sound manipulation were pervasive throughout the diverse cortical regions and were specific to each cortical region. Visual stimuli co-occurring with sound induced the early-onset activation of the early auditory region, followed by activation of the other regions. Removal of the sound stimulus resulted in focal deactivation in the auditory regions and reduced activation in the early visual region, the association region of the temporal and parietal cortices, and the anterior prefrontal regions, suggesting multisensory interplay. In contrast, equivalent activations were observed in the lateral occipital and lateral prefrontal regions, regardless of sound manipulation. Our findings indicate that auditory input did not generally enhance overall activation in relation to visual perception, but rather induced specific changes in each cortical region. The present study implies that 3-month-old infants may perceive audio-visual multisensory inputs by using the global network of functionally differentiated cortical regions. Hum Brain Mapp, 2013. {\copyright} 2011 Wiley Periodicals, Inc.},
	Author = {Watanabe, Hama and Homae, Fumitaka and Nakano, Tamami and Tsuzuki, Daisuke and Enkhtur, Lkhamsuren and Nemoto, Kiyotaka and Dan, Ippeita and Taga, Gentaro},
	Doi = {10.1002/hbm.21453},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/G5QAWNF9/Watanabe et al. - 2013 - Effect of auditory input on activations in infant .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7PWP2J7H/abstract.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {Hemodynamics, Cortical development, activation, audio-visual processing, deactivation, multisensory perception, Near-infrared spectroscopy},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {543--565},
	Title = {Effect of auditory input on activations in infant diverse cortical regions during audiovisual processing},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21453/abstract},
	Urldate = {2017-06-20},
	Volume = {34},
	Year = {2013},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21453/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.21453}}

@article{novitski_neonatal_2007,
	Abstract = {The precision of sound frequency discrimination in newborn infants in the 250--4000-Hz frequency range was determined using the neonatal electrophysiological mismatch response (MMR), the infant equivalent of adult mismatch negativity (MMN). The electroencephalogram (EEG) was recorded in 11 full-term sleeping newborn infants mostly in active sleep (67\% of the time). Pure tones were presented through loudspeakers in an oddball paradigm with a 800-ms stimulus onset asynchrony (SOA). Each stimulus block contained a standard (p=0.76) of 250, 1000, or 4000Hz in frequency (in separate blocks) and deviants with a frequency change of either 5\% or 20\% of the standard (p=0.12 of each). A positive ERP deflection was found at 200--300ms from stimulus onset in response to the 20\% deviation from the 250, 1000, and 4000Hz standard frequencies. The amplitude of the response in the 200--300ms time window was significantly larger for the 20\% than 5\% deviation. We observed in newborn infants automatic frequency discrimination as reflected by a positive MMR. The newborns were able to discriminate frequency change of 20\% in the 250--4000-Hz frequency range, whereas the discrimination of the 5\% frequency change was not statistically confirmed. The present data hence suggest that the neonatal frequency discrimination has lower resolution than that in adult and older children data.},
	Author = {Novitski, Nikolai and Huotilainen, Minna and Tervaniemi, Mari and N{\"a}{\"a}t{\"a}nen, Risto and Fellman, Vineta},
	Doi = {10.1016/j.clinph.2006.10.008},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EAWBIRKC/S1388245706014787.html:text/html},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology},
	Keywords = {Newborn infants, Frequency discrimination, MMN},
	Month = feb,
	Number = {2},
	Pages = {412--419},
	Shorttitle = {Neonatal frequency discrimination in 250--4000-{Hz} range},
	Title = {Neonatal frequency discrimination in 250--4000-{Hz} range: {Electrophysiological} evidence},
	Url = {http://www.sciencedirect.com/science/article/pii/S1388245706014787},
	Urldate = {2017-06-27},
	Volume = {118},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245706014787},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2006.10.008}}

@article{nakato_when_2009,
	Abstract = {The objective of the present study was to determine whether a developmental difference occurs in brain activity when infants look at frontal and profile views using near-infrared spectroscopy (NIRS), which is an optical imaging technique used to measure changes in the concentrations of oxyhemoglobin (oxy-Hb), deoxyhemoglobin (deoxy-Hb), and total hemoglobin (total-Hb). For this objective, we compared NIRS results in two age groups, 5- and 8-month-old infants, while they were looking at frontal views, profile views, and objects. We found that the concentration of oxy-Hb and total-Hb in the 5-month-old group increased for only frontal views in the right temporal regions. In contrast, the concentration of oxy-Hb and total-Hb in the 8-month-old group increased for both frontal and profile views in the right temporal regions. Therefore, the present study indicated that the right hemisphere was dominant for the perception of profile views as well as frontal views. In addition, the most important and interesting finding was that the infants' brain activity of the face area would become view-invariant at the age of 8 months but not at 5 months. The developmental period for view-invariant face recognition has been discussed in previous psychological studies, but this is the first objective study to confirm that the period is between 5- and 8-months by measuring the blood flow in the brain using NIRS. Hum Brain Mapp, 2009. {\copyright} 2007 Wiley-Liss, Inc.},
	Author = {Nakato, Emi and Otsuka, Yumiko and Kanazawa, So and Yamaguchi, Masami K. and Watanabe, Shoko and Kakigi, Ryusuke},
	Doi = {10.1002/hbm.20516},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KV8ITRPD/Nakato et al. - 2009 - When do infants differentiate profile face from fr.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DR4WVQBD/abstract.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {near infrared spectroscopy, developmental changes, face perception, right hemisphere, Infants},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {462--472},
	Shorttitle = {When do infants differentiate profile face from frontal face?},
	Title = {When do infants differentiate profile face from frontal face? {A} near-infrared spectroscopic study},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20516/abstract},
	Urldate = {2017-06-20},
	Volume = {30},
	Year = {2009},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20516/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.20516}}

@article{taga_selectivity_2007,
	Abstract = {To better understand the development of multimodal perception, we examined selectivity and localization of cortical responses to auditory and visual stimuli in young infants. Near-infrared optical topography with 24 channels was used to measure event-related cerebral oxygenation changes of the bilateral temporal cortex in 15 infants aged 2 to 4 months, when they were exposed to speech sounds lasting 3 s and checkerboard pattern reversals lasting 3 s, which were asynchronously presented with different alternating intervals. Group analysis revealed focal increases in oxy-hemoglobin and decreases in deoxy-hemoglobin in both hemispheres in response to auditory, but not to visual, stimulation. These results indicate that localized areas of the primary auditory cortex and the auditory association cortex are involved in auditory perception in infants as young as 2 months of age. In contrast to the hypothesis that perception of distinct sensory modalities may not be separated due to cross talk over the immature cortex in young infants, the present study suggests that unrelated visual events do not influence on the auditory perception of awake infants.},
	Author = {Taga, Gentaro and Asakawa, Kayo},
	Doi = {10.1016/j.neuroimage.2007.04.037},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JK7Z68FP/S1053811907002832.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = jul,
	Number = {4},
	Pages = {1246--1252},
	Title = {Selectivity and localization of cortical response to auditory and visual stimulation in awake infants aged 2 to 4 months},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811907002832},
	Urldate = {2017-06-23},
	Volume = {36},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811907002832},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2007.04.037}}

@article{allievi_maturation_2016,
	Author = {Allievi, Alessandro G. and Arichi, Tomoki and Tusor, Nora and Kimpton, Jessica and Arulkumaran, Sophie and Counsell, Serena J. and Edwards, A. David and Burdet, Etienne},
	Doi = {10.1093/cercor/bhv203},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9SDFXH77/Allievi et al. - 2016 - Maturation of Sensori-Motor Functional Responses i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/M5R3EUKW/Maturation-of-Sensori-Motor-Functional-Responses.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = jan,
	Number = {1},
	Pages = {402--413},
	Title = {Maturation of {Sensori}-{Motor} {Functional} {Responses} in the {Preterm} {Brain}},
	Url = {https://academic.oup.com/cercor/article/26/1/402/2367359/Maturation-of-Sensori-Motor-Functional-Responses},
	Urldate = {2017-06-27},
	Volume = {26},
	Year = {2016},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/26/1/402/2367359/Maturation-of-Sensori-Motor-Functional-Responses},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhv203}}

@article{eggebrecht_quantitative_2012,
	Abstract = {Functional neuroimaging commands a dominant role in current neuroscience research. However its use in bedside clinical and certain neuro-scientific studies has been limited because the current tools lack the combination of being non-invasive, non-ionizing and portable while maintaining moderate resolution and localization accuracy. Optical neuroimaging satisfies many of these requirements, but, until recent advances in high-density diffuse optical tomography (HD-DOT), has been hampered by limited resolution. While early results of HD-DOT have been promising, a quantitative voxel-wise comparison and validation of HD-DOT against the gold standard of functional magnetic resonance imaging (fMRI) has been lacking. Herein, we provide such an analysis within the visual cortex using matched visual stimulation protocols in a single group of subjects (n = 5) during separate HD-DOT and fMRI scanning sessions. To attain the needed voxel-to-voxel co-registration between HD-DOT and fMRI image spaces, we implemented subject-specific head modeling that incorporated MRI anatomy, detailed segmentation, and alignment of source and detector positions. Comparisons of the visual responses found an average localization error between HD-DOT and fMRI of 4.4 +/â 1 mm, significantly less than the average distance between cortical gyri. This specificity demonstrates that HD-DOT has sufficient image quality to be useful as a surrogate for fMRI.},
	Author = {Eggebrecht, Adam T. and White, Brian R. and Ferradal, Silvina L. and Chen, Chunxiao and Zhan, Yuxuan and Snyder, Abraham Z. and Dehghani, Hamid and Culver, Joseph P.},
	Doi = {10.1016/j.neuroimage.2012.01.124},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/K8GXGZHE/Eggebrecht et al. - 2012 - A quantitative spatial comparison of high-density .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3E6CW7FI/S1053811912001516.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Functional Neuroimaging, Cortex, Human, Mapping, Optical tomography},
	Month = jul,
	Number = {4},
	Pages = {1120--1128},
	Title = {A quantitative spatial comparison of high-density diffuse optical tomography and {fMRI} cortical mapping},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811912001516},
	Urldate = {2017-06-20},
	Volume = {61},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912001516},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.124}}

@article{okubo_hemodynamic_2002,
	Abstract = {This is the first report on the use of near-infrared topography (NIRT) for functional imaging of the visual cortex of newborn infants during photic stimulation (PS) under the condition of natural sleep. Measurements were conducted in four healthy term neonates within 1 week after birth. NIRT was performed on the occipital region of the head using a device consisting of 16 optical fibers, 8 for transmission and 8 for detection, and 24-measuring points were determined. Baseline data were collected over a period of 10 s. PS was produced by flashing lights (laser-emitting diodes) at 8 Hz and lasting for 15 s, followed by a 45-s rest period. Data were collected every 0.1 s, averaged over 10 cycles, and smoothed. As control data, hemodynamic changes in all neonates without stimulation were measured by the same method. PS caused marked increases from the baseline values in oxyhemoglobin ([HbO2]) and total hemoglobin ([T-Hb]) and a decrease in deoxyhemoglobin ([Hb]) in the primary visual areas of all neonates. We conclude that our method is useful for imaging and evaluating the primary visual area function in response to PS even in newborn infants during natural sleep.},
	Author = {Okubo, Kensuke and Kusaka, Takashi and Isobe, Kenichi and Nagano, Keiko and Kawada, Kou and Namba, Masanori and Imai, Tadashi and Itoh, Susumu and Onishi, Shoju},
	Doi = {10.1016/S0531-5131(01)00813-5},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/K85GIEPM/S0531513101008135.html:text/html},
	Issn = {0531-5131},
	Journal = {International Congress Series},
	Keywords = {Newborn infants, Photic Stimulation, Multichannel near-infrared spectroscopy, Primary visual cortex},
	Month = apr,
	Pages = {593--597},
	Series = {Recent advances in human brain mapping},
	Title = {Hemodynamic changes in the neonatal visual cortex by using near-infrared topography},
	Url = {http://www.sciencedirect.com/science/article/pii/S0531513101008135},
	Urldate = {2017-06-20},
	Volume = {1232},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0531513101008135},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0531-5131(01)00813-5}}

@article{wiggs_properties_1998,
	Abstract = {Recent evidence suggests that the behavioral phenomenon of perceptual priming and the physiological finding of decreased neural responses with item repetition have similar properties. Both the behavioral and neurophysiological effects show graded changes with multiple repetitions, are resistant to manipulations of particular stimulus attributes (e.g. size and location), and occur independently of awareness. These and other recent findings (e.g. from functional brain imaging in humans) suggest that perceptual priming may be mediated by decreased neural responses associated with perceptual learning.},
	Author = {Wiggs, Cheri L and Martin, Alex},
	Doi = {10.1016/S0959-4388(98)80144-X},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/FPMWK8GQ/Wiggs et Martin - 1998 - Properties and mechanisms of perceptual priming.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/A93TKRVJ/S095943889880144X.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = apr,
	Number = {2},
	Pages = {227--233},
	Title = {Properties and mechanisms of perceptual priming},
	Url = {http://www.sciencedirect.com/science/article/pii/S095943889880144X},
	Urldate = {2017-07-04},
	Volume = {8},
	Year = {1998},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S095943889880144X},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0959-4388(98)80144-X}}

@article{emberson_deficits_2017,
	Abstract = {A prominent theoretical view is that the brain is inherently predictive [ 1, 2 ] and that prediction helps drive the engine of development [ 3, 4 ]. Although infants exhibit neural signatures of top-down sensory prediction [ 5, 6 ], in order to establish that prediction supports development, it must be established that deficits in early prediction abilities alter trajectories. We investigated prediction in infants born prematurely, a leading cause of neuro-cognitive impairment worldwide [ 7 ]. Prematurity, independent of medical complications, leads to developmental disturbances [ 8--12 ] and a broad range of developmental delays [ 13--17 ]. Is an alteration in early prediction abilities the common cause? Using functional near-infrared spectroscopy (fNIRS), we measured top-down sensory prediction in preterm infants (born {\textless}33 weeks gestation) before infants exhibited clinically identifiable developmental delays (6 months corrected age). Whereas preterm infants had typical neural responses to presented visual stimuli, they exhibited altered neural responses to predicted visual stimuli. Importantly, a separate behavioral control confirmed that preterm infants detect pattern violations at the same rate as full-terms, establishing selectivity of this response to top-down predictions (e.g., not in learning an audiovisual association). These findings suggest that top-down sensory prediction plays a crucial role in development and that deficits in this ability may be the reason why preterm infants experience altered developmental trajectories and are at risk for poor developmental outcomes. Moreover, this work presents an opportunity for establishing a neuro-biomarker for early identification of infants at risk and could guide early intervention regimens.},
	Author = {Emberson, Lauren L. and Boldin, Alex M. and Riccio, Julie E. and Guillet, Ronnie and Aslin, Richard N.},
	Doi = {10.1016/j.cub.2016.12.028},
	File = {Embersonetal_2017_CurrentBiology_premieTopDownPrediction.pdf:/Users/Cecile/Zotero/storage/N2PZVEBP/Embersonetal_2017_CurrentBiology_premieTopDownPrediction.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q76HGECS/S0960-9822(16)31508-1.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Keywords = {Infant, Learning, Perception, fNIRS, audiovisual, multisensory, prediction, prematurity, Development},
	Language = {English},
	Month = feb,
	Number = {3},
	Pages = {431--436},
	Pmid = {28132814},
	Title = {Deficits in {Top}-{Down} {Sensory} {Prediction} in {Infants} {At} {Risk} due to {Premature} {Birth}},
	Url = {http://www.cell.com/current-biology/abstract/S0960-9822(16)31508-1},
	Urldate = {2017-06-20},
	Volume = {27},
	Year = {2017},
	Bdsk-Url-1 = {http://www.cell.com/current-biology/abstract/S0960-9822(16)31508-1},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2016.12.028}}

@article{boas_improving_2004,
	Abstract = {We compare two geometries of sources and detectors for optimizing the diffuse optical imaging resolution of brain activation in humans. Because of limitations in the instruments' dynamic range, most diffuse optical brain activation images have used only nonoverlapping measurements. We demonstrate theoretically and with a human experiment that a simple geometry of sources and detectors can provide overlapping measurements within the limitation of instrumentation dynamic range and produce an image resolution and localization accuracy that is twofold better.},
	Author = {Boas, D. A. and Chen, K. and Grebert, D. and Franceschini, M. A.},
	Copyright = {{\copyright} 2004 Optical Society of America},
	Doi = {10.1364/OL.29.001506},
	File = {Boas_OptLett_29_1506_2004.pdf:/Users/Cecile/Zotero/storage/97NXQK4V/Boas_OptLett_29_1506_2004.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TWG78HXV/abstract.html:text/html},
	Issn = {1539-4794},
	Journal = {Optics Letters},
	Keywords = {Image reconstruction techniques, Photon migration, Tomography},
	Language = {EN},
	Month = jul,
	Number = {13},
	Pages = {1506--1508},
	Title = {Improving the diffuse optical imaging spatial resolution of the cerebral hemodynamic response to brain activation in humans},
	Url = {https://www.osapublishing.org/abstract.cfm?uri=ol-29-13-1506},
	Urldate = {2017-06-20},
	Volume = {29},
	Year = {2004},
	Bdsk-Url-1 = {https://www.osapublishing.org/abstract.cfm?uri=ol-29-13-1506},
	Bdsk-Url-2 = {https://doi.org/10.1364/OL.29.001506}}

@article{sato_cerebral_2012,
	Abstract = {Considerable knowledge on neural development related to speech perception has been obtained by functional imaging studies using near-infrared spectroscopy (optical topography). In particular, a pioneering study showed stronger left-dominant activation in the temporal lobe for (normal) forward speech (FW) than for (reversed) backward speech (BW) in neonates. However, it is unclear whether this stronger left-dominant activation for FW is equally observed for any language or is clearer for the mother tongue. We hypothesized that the maternal language elicits clearer activation than a foreign language in newborns because of their prenatal and/or few-day postnatal exposure to the maternal language. To test this hypothesis, we developed a whole-head optode cap for 72-channel optical topography and visualized the spatiotemporal hemodynamics in the brains of 17 Japanese newborns when they were exposed to FW and BW in their maternal language (Japanese) and in a foreign language (English). Statistical analysis showed that all sound stimuli together induced significant activation in the bilateral temporal regions and the frontal region. They also showed that the left temporal-parietal region was significantly more active for Japanese FW than Japanese BW or English FW, while no significant difference between FW and BW was shown for English. This supports our hypothesis and suggests that the few-day-old brain begins to become attuned to the maternal language. Together with a finding of equivalent activation for all sound stimuli in the adjacent measurement positions in the temporal region, these findings further clarify the functional organization of the neonatal brain. Hum Brain Mapp 33:2092--2103, 2012. {\copyright} 2011 Wiley Periodicals, Inc.},
	Author = {Sato, Hiroki and Hirabayashi, Yukiko and Tsubokura, Hifumi and Kanai, Makoto and Ashida, Takashi and Konishi, Ikuo and Uchida-Ota, Mariko and Konishi, Yukuo and Maki, Atsushi},
	Doi = {10.1002/hbm.21350},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZQQC2H2S/Sato et al. - 2012 - Cerebral hemodynamics in newborn infants exposed t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CJVRI8Q8/abstract.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {language acquisition, near-infrared spectroscopy (NIRS), neonates, speech perception, Auditory cortex, Speech Perception},
	Language = {en},
	Month = sep,
	Number = {9},
	Pages = {2092--2103},
	Shorttitle = {Cerebral hemodynamics in newborn infants exposed to speech sounds},
	Title = {Cerebral hemodynamics in newborn infants exposed to speech sounds: {A} whole-head optical topography study},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21350/abstract},
	Urldate = {2017-07-18},
	Volume = {33},
	Year = {2012},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.21350/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.21350}}

@article{cristia_neural_2014,
	Abstract = {The present study investigated the neural correlates of infant discrimination of very similar linguistic varieties (Quebecois and Parisian French) using functional Near InfraRed Spectroscopy. In line with previous behavioral and electrophysiological data, there was no evidence that 3-month-olds discriminated the two regional accents, whereas 5-month-olds did, with the locus of discrimination in left anterior perisylvian regions. These neuroimaging results suggest that a developing language network relying crucially on left perisylvian cortices sustains infants' discrimination of similar linguistic varieties within this early period of infancy.},
	Author = {Cristia, Alejandrina and Minagawa-Kawai, Yasuyo and Egorova, Natalia and Gervain, Judit and Filippin, Luca and Cabrol, Dominique and Dupoux, Emmanuel},
	Doi = {10.1111/desc.12160},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PWTUQCGG/Cristia et al. - 2014 - Neural correlates of infant accent discrimination.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/97UZ5WCD/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = jul,
	Number = {4},
	Pages = {628--635},
	Shorttitle = {Neural correlates of infant accent discrimination},
	Title = {Neural correlates of infant accent discrimination: an {fNIRS} study},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12160/abstract},
	Urldate = {2017-07-24},
	Volume = {17},
	Year = {2014},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12160/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12160}}

@article{naccache_priming_2001,
	Abstract = {Most of the current brain imaging methods are limited by the low spatial resolution of neuroimaging techniques and remain unable to measure activity at the scale of single neurons or small columns of neurons, which are the coding elements of the nervous system. In this work we have adapted the priming method, an emerging research strategy that can overcome some of these spatial limitations, to investigate the coding of numerical quantities in the human brain. This approach combines the logic of psychological priming experiments with the recently discovered neurophysiological phenomenon called repetition suppression (RS). In each trial, while subjects perform a constant task, a subliminal prime is presented prior to each target. By varying the relationship between prime and target, one can detect which brain areas present RS specifically for any given level of prime--target repetition. We first expose the general logic, potential and limitations of the priming method and then illustrate it by demonstrating that a region of parietal cortex is coding for numbers at the quantity level, independently of other stimulus attributes, and that this region processes both consciously and unconsciously perceived stimuli.},
	Author = {Naccache, Lionel and Dehaene, Stanislas},
	Doi = {10.1093/cercor/11.10.966},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UPC2WFQ6/Naccache et Dehaene - 2001 - The Priming Method Imaging Unconscious Repetition.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DDSEDPSM/The-Priming-Method-Imaging-Unconscious-Repetition.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = oct,
	Number = {10},
	Pages = {966--974},
	Shorttitle = {The {Priming} {Method}},
	Title = {The {Priming} {Method}: {Imaging} {Unconscious} {Repetition} {Priming} {Reveals} an {Abstract} {Representation} of {Number} in the {Parietal} {Lobes}},
	Url = {https://academic.oup.com/cercor/article/11/10/966/280031/The-Priming-Method-Imaging-Unconscious-Repetition},
	Urldate = {2017-07-19},
	Volume = {11},
	Year = {2001},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/11/10/966/280031/The-Priming-Method-Imaging-Unconscious-Repetition},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/11.10.966}}

@article{kotilahti_hemodynamic_2010,
	Abstract = {We used near-infrared spectroscopy (NIRS) to study responses to speech and music on the auditory cortices of 13 healthy full-term newborn infants during natural sleep. The purpose of the study was to investigate the lateralization of speech and music responses at this stage of development. NIRS data was recorded from eight positions on both hemispheres simultaneously with electroencephalography, electrooculography, electrocardiography, pulse oximetry, and inclinometry. In 11 subjects, statistically significant (P {\textless} 0.02) oxygenated (HbO2) and total hemoglobin (HbT) responses were recorded. Both stimulus types elicited significant HbO2 and HbT responses on both hemispheres in five subjects. Six of the 11 subjects had positive HbO2 and HbT responses to both stimulus types, whereas one subject had negative responses. Mixed positive and negative responses were observed in four neonates. On both hemispheres, speech and music responses were significantly correlated (r = 0.64; P = 0.018 on the left hemisphere (LH) and r = 0.60; P = 0.029 on the right hemisphere (RH)). On the group level, the average response to the speech stimuli was statistically significantly greater than zero in the LH, whereas responses on the RH or to the music stimuli did not differ significantly from zero. This suggests a more coherent response to speech on the LH. However, significant differences in lateralization of the responses or mean response amplitudes of the two stimulus types were not observed on the group level. Hum Brain Mapp, 2010. {\copyright} 2009 Wiley-Liss, Inc.},
	Author = {Kotilahti, Kalle and Nissil{\"a}, Ilkka and N{\"a}si, Tiina and Lipi{\"a}inen, Lauri and Noponen, Tommi and Meril{\"a}inen, Pekka and Huotilainen, Minna and Fellman, Vineta},
	Doi = {10.1002/hbm.20890},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PSAF5ZZG/Kotilahti et al. - 2010 - Hemodynamic responses to speech and music in newbo.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/C56763FG/abstract.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {Functional Laterality, brain imaging, Neonate, auditory responses, Near-infrared spectroscopy},
	Language = {en},
	Month = apr,
	Number = {4},
	Pages = {595--603},
	Title = {Hemodynamic responses to speech and music in newborn infants},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20890/abstract},
	Urldate = {2017-07-24},
	Volume = {31},
	Year = {2010},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/hbm.20890/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.20890}}

@article{henson_neuroimaging_2000,
	Abstract = {Repetition priming has been characterized neurophysiologically as a decreased response following stimulus repetition. The present study used event-related functional magnetic resonance imaging to investigate whether this repetition-related response is sensitive to stimulus familiarity. A right fusiform region exhibited an attenuated response to the repetition of familiar stimuli, both faces and symbols, but exhibited an enhanced response to the repetition of unfamiliar stimuli. Moreover, both repetition effects were modulated by lag between successive presentations. Further experiments replicated the interactions between repetition, familiarity, and lag and demonstrated the persistence of these effects over multiple repetitions. Priming-related responses are therefore not unitary but depend on the presence or absence of preexisting stimulus representations.},
	Author = {Henson, R. and Shallice, T. and Dolan, R.},
	Doi = {10.1126/science.287.5456.1269},
	File = {Snapshot:/Users/Cecile/Zotero/storage/DBEVAUGK/1269.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = feb,
	Number = {5456},
	Pages = {1269--1272},
	Pmid = {10678834},
	Title = {Neuroimaging {Evidence} for {Dissociable} {Forms} of {Repetition} {Priming}},
	Url = {http://science.sciencemag.org/content/287/5456/1269},
	Urldate = {2017-07-19},
	Volume = {287},
	Year = {2000},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/287/5456/1269},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.287.5456.1269}}

@article{henson_face_2002,
	Abstract = {Recent parallels between neurophysiological and neuroimaging findings suggest that repeated stimulus processing produces decreased responses in brain regions associated with that processingâ---âa `repetition suppression' effect. In the present study, volunteers performed two tasks on repeated presentation of famous and unfamiliar faces during functional magnetic resonance imaging (fMRI). In the implicit task, they made fame-judgements (regardless of repetition); in the explicit task, they made episodic recognition judgements (regardless of familiarity). Only in the implicit task was repetition suppression observed: for famous faces in a right lateral fusiform region, and for both famous and unfamiliar faces in a left inferior occipital region. Repetition suppression is therefore not an automatic consequence of repeated perceptual processing of stimuli.},
	Author = {Henson, R. N. A. and Shallice, T. and Gorno-Tempini, M. L. and Dolan, R. J.},
	Doi = {10.1093/cercor/12.2.178},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2ZTNGSKG/Henson et al. - 2002 - Face Repetition Effects in Implicit and Explicit M.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/TQFT6TM5/Henson et al. - 2002 - Face Repetition Effects in Implicit and Explicit M.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/R43HGBEQ/301071.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/WT8M3ZBK/301071.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Month = feb,
	Number = {2},
	Pages = {178--186},
	Title = {Face {Repetition} {Effects} in {Implicit} and {Explicit} {Memory} {Tests} as {Measured} by {fMRI}},
	Url = {https://academic.oup.com/cercor/article/12/2/178/301071/Face-Repetition-Effects-in-Implicit-and-Explicit},
	Urldate = {2017-07-19},
	Volume = {12},
	Year = {2002},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/12/2/178/301071/Face-Repetition-Effects-in-Implicit-and-Explicit},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/12.2.178}}

@article{okada_near-infrared_2003,
	Abstract = {It is important for near-infrared spectroscopy (NIRS) and imaging to estimate the sensitivity of the detected signal to the change in hemoglobin that results from brain activation and the volume of tissue interrogated for a specific source-detector fiber spacing. In this study light propagation in adult head models is predicted by Monte Carlo simulation to investigate the effect of the superficial tissue thickness on the partial optical path length in the brain and on the spatial sensitivity profile. In the case of source-detector spacing of 30 mm, the partial optical path length depends mainly on the depth of the inner skull surface whereas the spatial sensitivity profile is significantly affected by the thickness of the cerebrospinal fluid layer. The mean optical path length that can be measured by time-resolved experiments increases when the skull thickness increases whereas the partial mean optical path length in the brain decreases when the skull thickness increases. These results indicate that it is not appropriate to use the mean optical path length as an alternative to the partial optical path length to compensate the NIRS signal for the difference in sensitivity caused by variation of the superficial tissue thickness.},
	Author = {Okada, Eiji and Delpy, David T.},
	Issn = {0003-6935},
	Journal = {Applied Optics},
	Keywords = {Adult, Head, Humans, Spectroscopy, Near-Infrared, Cerebrospinal Fluid, Models, Anatomic, Monte Carlo Method, Sensitivity and Specificity, Skull},
	Language = {eng},
	Month = jun,
	Number = {16},
	Pages = {2915--2922},
	Pmid = {12790440},
	Title = {Near-infrared light propagation in an adult head model. {II}. {Effect} of superficial tissue thickness on the sensitivity of the near-infrared spectroscopy signal},
	Volume = {42},
	Year = {2003}}

@article{okada_near-infrared_2003-1,
	Abstract = {Adequate modeling of light propagation in a human head is important for quantitative near-infrared spectroscopy and optical imaging. The presence of a nonscattering cerebrospinal fluid (CSF) that surrounds the brain has been previously shown to have a strong effect on light propagation in the head. However, in reality, a small amount of scattering is caused by the arachnoid trabeculae in the CSF layer. In this study, light propagation in an adult head model with discrete scatterers distributed within the CSF layer has been predicted by Monte Carlo simulation to investigate the effect of the small amount of scattering caused by the arachnoid trabeculae in the CSF layer. This low scattering in the CSF layer is found to have little effect on the mean optical path length, a parameter that can be directly measured by a time-resolved experiment. However, the partial optical path length in brain tissue that relates the sensitivity of the detected signal to absorption changes in the brain is strongly affected by the presence of scattering within the CSF layer. The sensitivity of the near-infrared signal to hemoglobin changes induced by brain activation is improved by the effect of a low-scattering CSF layer.},
	Author = {Okada, Eiji and Delpy, David T.},
	Issn = {0003-6935},
	Journal = {Applied Optics},
	Keywords = {Adult, Head, Humans, Spectroscopy, Near-Infrared, Cerebrospinal Fluid, Models, Anatomic, Monte Carlo Method, Models, Theoretical, Scattering, Radiation, Brain},
	Language = {eng},
	Month = jun,
	Number = {16},
	Pages = {2906--2914},
	Pmid = {12790439},
	Title = {Near-infrared light propagation in an adult head model. {I}. {Modeling} of low-level scattering in the cerebrospinal fluid layer},
	Volume = {42},
	Year = {2003}}

@article{benavides-varela_brain_2017,
	Abstract = {Perception and cognition in infants have been traditionally investigated using habituation paradigms, assuming that babies' memories in laboratory contexts are best constructed after numerous repetitions of the very same stimulus in the absence of interference. A crucial, yet open, question regards how babies deal with stimuli experienced in a fashion similar to everyday learning situations-namely, in the presence of interfering stimuli. To address this question, we used functional near-infrared spectroscopy to test 40 healthy newborns on their ability to encode words presented in concomitance with other words. The results evidenced a habituation-like hemodynamic response during encoding in the left-frontal region, which was associated with a progressive decrement of the functional connections between this region and the left-temporal, right-temporal, and right-parietal regions. In a recognition test phase, a characteristic neural signature of recognition recruited first the right-frontal region and subsequently the right-parietal ones. Connections originating from the right-temporal regions to these areas emerged when newborns listened to the familiar word in the test phase. These findings suggest a neural specialization at birth characterized by the lateralization of memory functions: the interplay between temporal and left-frontal regions during encoding and between temporo-parietal and right-frontal regions during recognition of speech sounds. Most critically, the results show that newborns are capable of retaining the sound of specific words despite hearing other stimuli during encoding. Thus, habituation designs that include various items may be as effective for studying early memory as repeated presentation of a single word.},
	Author = {Benavides-Varela, Silvia and Siugzdaite, Roma and G{\'o}mez, David Maximiliano and Macagno, Francesco and Cattarossi, Luigi and Mehler, Jacques},
	Doi = {10.1073/pnas.1617589114},
	Issn = {1091-6490},
	Journal = {Proceedings of the National Academy of Sciences of the United States of America},
	Keywords = {Habituation, Memory, newborns, fNIRS effective connectivity, language},
	Language = {eng},
	Month = jul,
	Number = {29},
	Pages = {7588--7593},
	Pmcid = {PMC5530644},
	Pmid = {28674020},
	Title = {Brain regions and functional interactions supporting early word recognition in the face of input variability},
	Volume = {114},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1073/pnas.1617589114}}

@article{sakatani_cerebral_1999,
	Abstract = {Recent neuronal activation studies on newborns using functional MRI or near infrared spectroscopy (NIRS) have suggested that the increase in O2 consumption accompanying neuronal activation exceeds the increase in O2 delivery in the visual cortex during photic stimulation. In the present study, we evaluated the cerebral blood oxygenation (CBO) changes induced by auditory stimulation in the frontal lobe of newborns using NIRS. We studied 28 newborns; the postnatal age at CBO measurements was 3.1+/-0.3 days (mean+/-S.E.M.). We measured concentration changes of deoxyhemoglobin (Deoxy-Hb), oxyhemoglobin (Oxy-Hb), and total hemoglobin (Total-Hb) induced by auditory (music) stimulation in the bilateral frontal lobes of the newborns. Twenty-six (92.9\%) out of 28 subjects showed increases of Oxy-Hb and Total-Hb during the stimulation. In these subjects, 17 (60.7\%) subjects showed an increase of Deoxy-Hb associated with increases of Oxy-Hb and Total-Hb, while nine (32.1\%) subjects showed a decrease of Deoxy-Hb. Although the direction of the Deoxy-Hb differed, these two groups did not differ for Oxy-Hb and Total-Hb (P {\textgreater} 0.05). Two (7.1\%) subjects showed other changes. The frontal lobe of newborns shows CBO responses similar to those observed in the visual cortex, specifically neuronal activation causes an increase of Deoxy-Hb associated with increases of Oxy-Hb and Total-Hb. These results support the hypothesis that increments in O2 consumption exceed increments in O2 delivery during neuronal activity in newborns.},
	Author = {Sakatani, K. and Chen, S. and Lichty, W. and Zuo, H. and Wang, Y. P.},
	Issn = {0378-3782},
	Journal = {Early Human Development},
	Keywords = {Acoustic Stimulation, Female, Frontal Lobe, Hemoglobins, Humans, Infant, Newborn, Male, Oxygen, Spectroscopy, Near-Infrared, Oxyhemoglobins, Brain},
	Language = {eng},
	Month = jul,
	Number = {3},
	Pages = {229--236},
	Pmid = {10463787},
	Title = {Cerebral blood oxygenation changes induced by auditory stimulation in newborn infants measured by near infrared spectroscopy},
	Volume = {55},
	Year = {1999}}

@article{spelke_core_2000,
	Abstract = {Complex cognitive skills such as reading and calculation and complex cognitive achievements such as formal science and mathematics may depend on a set of building block systems that emerge early in human ontogeny and phylogeny. These core knowledge systems show characteristic limits of domain and task specificity: Each serves to represent a particular class of entities for a particular set of purposes. By combining representations from these systems, however human cognition may achieve extraordinary flexibility. Studies of cognition in human infants and in nonhuman primates therefore may contribute to understanding unique features of human knowledge. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Author = {Spelke, Elizabeth S.},
	Doi = {10.1037/0003-066X.55.11.1233},
	File = {EBSCO Full Text:/Users/Cecile/Zotero/storage/USRT79TN/Spelke - 2000 - Core knowledge.pdf:application/pdf},
	Issn = {0003-066X},
	Journal = {American Psychologist},
	Keywords = {Animals, Cognition, COGNITIVE development, Humans, Primates, Human Development, Mathematical Ability, Phylogeny, Problem Solving, Psychology, Child, Reading, Science Achievement, development of cognitive skills such as reading \& calculation \& cognitive achievements such as formal science \& mathematics},
	Month = nov,
	Number = {11},
	Pages = {1233--1243},
	Title = {Core knowledge},
	Url = {http://frodon.univ-paris5.fr/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2000-14050-006&lang=fr&site=ehost-live},
	Urldate = {2017-09-14},
	Volume = {55},
	Year = {2000},
	Bdsk-Url-1 = {http://frodon.univ-paris5.fr/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=pdh&AN=2000-14050-006&lang=fr&site=ehost-live},
	Bdsk-Url-2 = {https://doi.org/10.1037/0003-066X.55.11.1233}}

@article{weisz_amplitude_nodate,
	Abstract = {Periodic modulations of an acoustic feature, such as amplitude over a certain frequency range, leads to phase locking of neural responses to the envelope of the modulation. Using electrophysiological methods this neural activity pattern, also called the auditory steady-state response (aSSR), is visible following frequency transformation of the evoked response as a clear spectral peak at the modulation frequency. Despite several studies employing the aSSR that show, for example, strongest responses for â¼40 Hz and an overall right-hemispheric dominance, it has not been investigated so far to what extent within auditory cortex different modulation frequencies elicit aSSRs at a homogenous source or whether the localization of the aSSR is topographically organized in a systematic manner. The latter would be suggested by previous neuroimaging works in monkeys and humans showing a periodotopic organization within and across distinct auditory fields. However, the sluggishness of the signal from these neuroimaging works prohibit inferences with regards to the fine-temporal features of the neural response. In the present study, we employed amplitude-modulated (AM) sounds over a range between 4 and 85 Hz to elicit aSSRs while recording brain activity via magnetoencephalography (MEG). Using beamforming and a fine spatially resolved grid restricted to auditory cortical processing regions, our study revealed a topographic representation of the aSSR that depends on AM rate, in particular in the medial-lateral (bilateral) and posterior-anterior (right auditory cortex) direction. In summary, our findings confirm previous studies that showing different AM rates to elicit maximal response in distinct neural populations. They extend these findings however by also showing that these respective neural ensembles in auditory cortex actually phase lock their activity over a wide modulation frequency range.},
	Author = {Weisz, Nathan and Lithari, Chrysoula},
	Doi = {10.1016/j.heares.2017.09.003},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F5NPE2XJ/Weisz et Lithari - Amplitude modulation rate dependent topographic or.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9JJPQMAV/S0378595517301697.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Keywords = {Amplitude modulation, Auditory steady-state response, Beamforming, Auditory cortex, magnetoencephalography},
	Title = {Amplitude modulation rate dependent topographic organization of the auditory steady-state response in human auditory cortex},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595517301697},
	Urldate = {2017-09-19},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595517301697},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2017.09.003}}

@article{chi_multiresolution_2005,
	Author = {Chi, Taishih and Ru, Powen and Shamma, Shihab A.},
	File = {chi_ru_shamma_2005.pdf:/Users/Cecile/Zotero/storage/6NZDJJ26/chi_ru_shamma_2005.pdf:application/pdf},
	Journal = {The Journal of the Acoustical Society of America},
	Number = {2},
	Pages = {887--906},
	Title = {Multiresolution spectrotemporal analysis of complex sounds},
	Url = {http://asa.scitation.org/doi/abs/10.1121/1.1945807},
	Urldate = {2017-09-25},
	Volume = {118},
	Year = {2005},
	Bdsk-Url-1 = {http://asa.scitation.org/doi/abs/10.1121/1.1945807}}

@article{jun_fully_2017,
	Abstract = {{\textless}p{\textgreater}Sensory, motor and cognitive operations involve the coordinated action of large neuronal populations across multiple brain regions. Existing technologies reliably measure activity from a relatively small number of neurons with high spatial and temporal resolution, or from a large volume of neurons with low resolution. Timothy Harris and colleagues describe the design, fabrication and performance of Neuropixels, a silicon probe that can measure well-isolated neural activity from hundreds of neurons. They integrated these probes into a lightweight system that could record activity simultaneously and with high fidelity from hundreds of neurons in awake and freely moving rodents.{\textless}/p{\textgreater}},
	Author = {Jun, James J. and Steinmetz, Nicholas A. and Siegle, Joshua H. and Denman, Daniel J. and Bauza, Marius and Barbarits, Brian and Lee, Albert K. and Anastassiou, Costas A. and Andrei, Alexandru and AydÄ±n, {\c C}a{\u g}atay and Barbic, Mladen and Blanche, Timothy J. and Bonin, Vincent and Couto, Jo{\~a}o and Dutta, Barundeb and Gratiy, Sergey L. and Gutnisky, Diego A. and H{\"a}usser, Michael and Karsh, Bill and Ledochowitsch, Peter and Lopez, Carolina Mora and Mitelut, Catalin and Musa, Silke and Okun, Michael and Pachitariu, Marius and Putzeys, Jan and Rich, P. Dylan and Rossant, Cyrille and Sun, Wei-lung and Svoboda, Karel and Carandini, Matteo and Harris, Kenneth D. and Koch, Christof and O'Keefe, John and Harris, Timothy D.},
	Copyright = {2017 Nature Publishing Group},
	Doi = {10.1038/nature24636},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CQ4V9G8G/Jun et al. - 2017 - Fully integrated silicon probes for high-density r.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EX7E46QA/nature24636.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = nov,
	Number = {7679},
	Pages = {nature24636},
	Title = {Fully integrated silicon probes for high-density recording of neural activity},
	Url = {https://www.nature.com/articles/nature24636},
	Urldate = {2017-11-13},
	Volume = {551},
	Year = {2017},
	Bdsk-Url-1 = {https://www.nature.com/articles/nature24636},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature24636}}

@phdthesis{cabrera_developpement_2013,
	Author = {Cabrera, Laurianne},
	File = {Doctorale et al. - 2013 - spectro-te mporal modulation processing Behavioral studies in infants Th{\`e}se de Doctorat Laurianne Cabrera-annotated.pdf:/Users/Cecile/Zotero/storage/U6B4IM5N/Doctorale et al. - 2013 - spectro-te mporal modulation processing Behavioral studies in infants Th{\`e}Ìse de Doctorat Laurianne Cabrera-annota.pdf:application/pdf},
	School = {Paris 5},
	Shorttitle = {D{\'e}veloppement de la perception de la parole et du traitement auditif des modulations spectro-temporelles},
	Title = {D{\'e}veloppement de la perception de la parole et du traitement auditif des modulations spectro-temporelles: {\'e}tudes comportementales chez le nourrisson},
	Url = {http://www.theses.fr/2013PA05H112},
	Urldate = {2017-09-25},
	Year = {2013},
	Bdsk-Url-1 = {http://www.theses.fr/2013PA05H112}}

@incollection{saffran_infants_2007,
	Abstract = {The focus of this chapter is on how infants perceive, process, and learn from their auditory environments. We focus on mechanism of hearing, speech perception, and early language learning, with the goal of elucidating recent progress in this field and its historical context. The literature reviewed includes studies of hearing development in young infants, the beginnings of speech perception and tuning to the native language, word segmentation, word learning, phonological acquisition, and the early stages of language acquisition. Throughout, we focus on current controversies along with theoretical and methodological innovations.},
	Author = {Saffran, Jenny R. and Werker, Janet F. and Werner, Lynne A.},
	Booktitle = {Handbook of {Child} {Psychology}},
	Copyright = {Copyright {\copyright} 2006 John Wiley \& Sons, Inc. All rights reserved.},
	Doi = {10.1002/9780470147658.chpsy0202},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/N2E3R49C/Saffran et al. - 2007 - The Infant's Auditory World Hearing, Speech, and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CWFUDADS/abstract.html:text/html},
	Isbn = {978-0-470-14765-8},
	Keywords = {Hearing, Speech, Words, Infants, language},
	Language = {en},
	Publisher = {John Wiley \& Sons, Inc.},
	Shorttitle = {The {Infant}'s {Auditory} {World}},
	Title = {The {Infant}'s {Auditory} {World}: {Hearing}, {Speech}, and the {Beginnings} of {Language}},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470147658.chpsy0202/abstract},
	Urldate = {2017-09-25},
	Year = {2007},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/9780470147658.chpsy0202/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/9780470147658.chpsy0202}}

@article{coffey_neural_2017,
	Abstract = {Speech-in-noise (SIN) perception is a complex cognitive skill that affects social, vocational, and educational activities. Poor SIN ability particularly affects young and elderly populations, yet varies considerably even among healthy young adults with normal hearing. Although SIN skills are known to be influenced by top-down processes that can selectively enhance lower-level sound representations, the complementary role and of feed-forward mechanisms and their relationship to musical training is poorly understood. Using a paradigm that minimizes the main top-down factors that have been implicated in SIN performance such as working memory, we aimed to better understand how robust encoding of periodicity in the auditory system (as measured by the frequency-following response) contributes to SIN perception. Using magnetoencephalograpy, we found that the strength of encoding at the fundamental frequency in the brainstem, thalamus, and cortex is correlated with SIN accuracy. The amplitude of the slower cortical P2 wave was previously also shown to be related to SIN accuracy and FFR strength; we use MEG source localization to show that the P2 wave originates in a temporal region anterior to that of the cortical FFR. We also confirm that the observed enhancements were related to the extent and timing of musicianship. These results are consistent with the hypothesis that basic feed-forward sound encoding affects SIN perception by providing better information to later processing stages, and that modifying this process may be one mechanism through which musical training might enhance the auditory networks that subserve both musical and language functions.},
	Author = {Coffey, Emily B. J. and Chepesiuk, Alexander M. P. and Herholz, Sibylle C. and Baillet, Sylvain and Zatorre, Robert J.},
	Doi = {10.3389/fnins.2017.00479},
	Issn = {1662-453X},
	Journal = {Frontiers in Neuroscience},
	Keywords = {Auditory Perception, electroencephalography (EEG), Training-related enhancement, frequency-following response (FFR), inter-individual variability, source localization, speech-in-noise perception, magnetoencephalography (MEG)},
	Language = {English},
	Title = {Neural {Correlates} of {Early} {Sound} {Encoding} and their {Relationship} to {Speech}-in-{Noise} {Perception}},
	Url = {http://journal.frontiersin.org/article/10.3389/fnins.2017.00479/full?utm_source=S-TWT&utm_medium=SNET&utm_campaign=ECO_FNINS_XXXXXXXX_auto-dlvrit},
	Urldate = {2017-09-01},
	Volume = {11},
	Year = {2017},
	Bdsk-Url-1 = {http://journal.frontiersin.org/article/10.3389/fnins.2017.00479/full?utm_source=S-TWT&utm_medium=SNET&utm_campaign=ECO_FNINS_XXXXXXXX_auto-dlvrit},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2017.00479}}

@book{fant_acoustic_1971,
	Author = {Fant, Gunnar},
	Isbn = {978-3-11-087342-9},
	Keywords = {Language Arts \& Disciplines / Linguistics / General, Language Arts \& Disciplines / Linguistics / Historical \& Comparative, Language Arts \& Disciplines / Linguistics / Phonetics \& Phonology},
	Language = {en},
	Month = jan,
	Note = {Google-Books-ID: UY0iAAAAQBAJ},
	Publisher = {Walter de Gruyter},
	Shorttitle = {Acoustic {Theory} of {Speech} {Production}},
	Title = {Acoustic {Theory} of {Speech} {Production}: {With} {Calculations} based on {X}-{Ray} {Studies} of {Russian} {Articulations}},
	Year = {1971}}

@article{friederici_language_2017,
	Abstract = {Language serves as a cornerstone of human cognition. However, our knowledge about its neural basis is still a matter of debate, partly because `language' is often ill-defined. Rather than equating language with `speech' or `communication', we propose that language is best described as a biologically determined computational cognitive mechanism that yields an unbounded array of hierarchically structured expressions. The results of recent brain imaging studies are consistent with this view of language as an autonomous cognitive mechanism, leading to a view of its neural organization, whereby language involves dynamic interactions of syntactic and semantic aspects represented in neural networks that connect the inferior frontal and superior temporal cortices functionally and structurally. Friederici et al. outline a view of the neural organization of language that is compatible with a description of language as a biologically determined computational mechanism that yields an infinite number of hierarchically structured expressions.},
	Author = {Friederici, Angela D. and Chomsky, Noam and Berwick, Robert C. and Moro, Andrea and Bolhuis, Johan J.},
	Copyright = {2017 The Publisher},
	Doi = {10.1038/s41562-017-0184-4},
	File = {Snapshot:/Users/Cecile/Zotero/storage/ZX44R2I5/s41562-017-0184-4.html:text/html},
	Issn = {2397-3374},
	Journal = {Nature Human Behaviour},
	Language = {En},
	Month = sep,
	Pages = {1},
	Title = {Language, mind and brain},
	Url = {https://www.nature.com/articles/s41562-017-0184-4},
	Urldate = {2017-09-20},
	Year = {2017},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41562-017-0184-4},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41562-017-0184-4}}

@article{spelke_initial_1994,
	Abstract = {Although debates continue, studies of cognition in infancy suggest that knowledge begins to emerge early in life and constitutes part of humans' innate endowment. Early-developing knowledge appears to be both domain-specific and task-specific, it appears to capture fundamental constraints on ecologically important classes of entities in the child's environment, and it appears to remain central to the commonsense knowledge systems of adults.},
	Author = {Spelke, Elizabeth S.},
	Doi = {10.1016/0010-0277(94)90039-6},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/K2VCZBGA/0010027794900396.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Month = apr,
	Number = {1},
	Pages = {431--445},
	Shorttitle = {Initial knowledge},
	Title = {Initial knowledge: six suggestions},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027794900396},
	Volume = {50},
	Year = {1994},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0010027794900396},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0277(94)90039-6}}

@article{birnholz_development_1983,
	Abstract = {Blink-startle responses to vibroacoustic stimulation were monitored ultrasonically in human fetuses of known gestational age. Responses were first elicited between 24 and 25 weeks of gestational age and were present consistently after 28 weeks. Defining the developmental sequence for audition provides a foundation for diagnosing deafness and recognizing aberrant responses antenatally.},
	Author = {Birnholz, J. C. and Benacerraf, B. R.},
	Copyright = {{\copyright} 1983},
	Doi = {10.1126/science.6623091},
	File = {Snapshot:/Users/Cecile/Zotero/storage/R3UNFG9R/516.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = nov,
	Number = {4623},
	Pages = {516--518},
	Pmid = {6623091},
	Title = {The development of human fetal hearing},
	Url = {http://science.sciencemag.org/content/222/4623/516},
	Urldate = {2017-10-06},
	Volume = {222},
	Year = {1983},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/222/4623/516},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.6623091}}

@article{lecanuet_fetal_1988,
	Abstract = {Accelerative and decelerative cardiac responses and motor responses (leg movements) of 37--40 weeks (G.A.) fetuses are analyzed as a function of the frequency of three octave-band noises (respectively centered at 500 Hz, 2000 Hz and 5000 Hz) and of their intensity level (100, 105, 110 dB SPL, ex utero), during high (HV) and low (LV) heart rate (HR) variability pattern states. In both states, increasing the frequency and/or the intensity of the acoustic stimulation: (i) increases the ratios and amplitudes of accelerations, and the motor response ratios, (ii) reduces deceleration ratios and motor response latencies. Cardiac and motor reactiveness are higher in HV than in LV with acceleration ratios always greater than motor ones. However, when a high intensity and/or frequency is used, the reactiveness differences between states disappears. Low intensity and/or frequency stimulation levels induce a majority of decelerations.},
	Author = {Lecanuet, J-P. and Granier-Deferre, C. and Busnel, M-C.},
	Doi = {10.1016/0378-3782(88)90045-X},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/WS35G56Z/Lecanuet et al. - 1988 - Fetal cardiac and motor responses to octave-band n.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/N2R394A2/037837828890045X.html:text/html},
	Issn = {0378-3782},
	Journal = {Early Human Development},
	Keywords = {Fetus, acoustical stimulation, cardiac acceleration, cardiac deceleration, frequency, heart rate variability pattern, intensity, motor response},
	Month = dec,
	Number = {2},
	Pages = {81--93},
	Title = {Fetal cardiac and motor responses to octave-band noises as a function of central frequency, intensity and heart rate variability},
	Url = {http://www.sciencedirect.com/science/article/pii/037837828890045X},
	Urldate = {2017-10-06},
	Volume = {18},
	Year = {1988},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/037837828890045X},
	Bdsk-Url-2 = {https://doi.org/10.1016/0378-3782(88)90045-X}}

@article{marler_innate_1990,
	Abstract = {Research on the ways in which different species of birds learn to sing is used to illustrate the necessity of taking innate factors into account in studies of behavioral development. Experiments on two species of songbirds are described that reveal innate species differences in responsiveness to taperecorded songs. Conspecific songs are favored over those of other species. These patterns of innately varying responsiveness provide a basis for the development, not of stereotyped behavior, but of variable, individually learned behavior. The viewpoint is presented that mechanisms that differ innately from species to species, some with general functions, others specialized for particular ontogenetic assignments, provide the necessary substrates with which experience interacts.},
	Author = {Marler, Peter},
	Doi = {10.1002/dev.420230703},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KIWNEMWA/Marler - 1990 - Innate learning preferences Signals for communica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XUIWVDDZ/abstract.html:text/html},
	Issn = {1098-2302},
	Journal = {Developmental Psychobiology},
	Keywords = {oiseau},
	Language = {en},
	Month = nov,
	Number = {7},
	Pages = {557--568},
	Shorttitle = {Innate learning preferences},
	Title = {Innate learning preferences: {Signals} for communication},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/dev.420230703/abstract},
	Urldate = {2017-10-05},
	Volume = {23},
	Year = {1990},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/dev.420230703/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/dev.420230703}}

@article{spelke_core_2007,
	Abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a fifth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
	Author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
	Doi = {10.1111/j.1467-7687.2007.00569.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9G7E6DZW/Spelke et Kinzler - 2007 - Core knowledge.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QBWB9XFX/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {89--96},
	Title = {Core knowledge},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x/abstract},
	Urldate = {2017-10-03},
	Volume = {10},
	Year = {2007},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00569.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00569.x}}

@article{moore_human_2007,
	Abstract = {This review traces the structural maturation of the human auditory system, and compares the timeline of anatomical development with cotemporaneous physiological and behavioral events. During the embryonic period, there is formation of basic structure at all levels of the system, i.e. the inner ear, the brainstem pathway, and the cortex. The second trimester is a time of rapid growth and development, and by the end of this period, the cochlea has acquired a very adult-like configuration. During the perinatal period, the brainstem reaches a mature state, and brainstem activity is reflected in behavioral responses to sound, including phonetic discrimination, and in evoked brainstem and early middle latency responses. The perinatal period is also the time of peak development of brainstem input to the cortex through the marginal layer, and of the long latency cortical potentials, the N2 and mismatch negativity. In early childhood, from the sixth post-natal month to age five, there is progressive maturation of the thalamic projections to the cortex and of the longer latency Pa and P1 evoked potentials. Later childhood, from six to twelve years, is the time of maturation of the superficial cortical layers and their intracortical connections, accompanied by appearance of the N1 potential and improved linguistic discriminative abilities. Some consideration is given to the potential negative effects of deafness-induced sound deprivation during the perinatal period and childhood.},
	Author = {Moore, Jean K. and Linthicum, Fred H. Jr},
	Doi = {10.1080/14992020701383019},
	File = {moore2007.pdf:/Users/Cecile/Zotero/storage/Q7JBM2TK/moore2007.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/894VP7I5/14992020701383019.html:text/html},
	Issn = {1499-2027},
	Journal = {International Journal of Audiology},
	Keywords = {Cochlea, MMN, ABR, Brainstem, MLR, Auditory cortex},
	Month = jan,
	Number = {9},
	Pages = {460--478},
	Shorttitle = {The human auditory system},
	Title = {The human auditory system: {A} timeline of development},
	Url = {http://dx.doi.org/10.1080/14992020701383019},
	Urldate = {2017-10-06},
	Volume = {46},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/14992020701383019}}

@article{granier-deferre_near-term_2011,
	Abstract = {The perception of speech and music requires processing of variations in spectra and amplitude over different time intervals. Near-term fetuses can discriminate acoustic features, such as frequencies and spectra, but whether they can process complex auditory streams, such as speech sequences and more specifically their temporal variations, fast or relatively slow acoustic variations, is unclear. We recorded the cardiac activity of 82 near-term fetuses (38 weeks GA) in quiet sleep during a silent control condition and four 15 s streams presented at 90 dB SPL Leq: two piano melodies with opposite contours, a natural Icelandic sentence and a chimera of the sentence -- all its spectral information was replaced with broadband noise, leaving its specific temporal variations in amplitude intact without any phonological information. All stimuli elicited a heart rate deceleration. The response patterns to the melodies were the same and differed significantly from those observed with the Icelandic sentence and its chimera, which did not differ. The melodies elicited a monophasic heart rate deceleration, indicating a stimulus orienting reflex while the Icelandic and its chimera evoked a sustained lower magnitude response, indicating a sustained attentional response or more focused information processing. A conservative interpretation of the data is that near-term fetuses can perceive sound streams and the rapid temporal variations in amplitude that are specific to speech sounds with no spectral variations at all.},
	Author = {Granier-Deferre, Carolyn and Ribeiro, Aur{\'e}lie and Jacquet, Anne-Yvonne and Bassereau, Sophie},
	Doi = {10.1111/j.1467-7687.2010.00978.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T8C2BTE7/Granier-Deferre et al. - 2011 - Near-term fetuses process temporal features of spe.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ETF8276M/abstract\;jsessionid=65A2DA716F95867A8D20547AF93BBECD.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = mar,
	Number = {2},
	Pages = {336--352},
	Title = {Near-term fetuses process temporal features of speech},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2010.00978.x/abstract},
	Urldate = {2017-10-06},
	Volume = {14},
	Year = {2011},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2010.00978.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2010.00978.x}}

@article{magnuson_acoustic_2007,
	Abstract = {Two talkers' productions of the same phoneme may be quite different acoustically, whereas their productions of different speech sounds may be virtually identical. Despite this lack of invariance in the relationship between the speech signal and linguistic categories, listeners experience phonetic constancy across a wide range of talkers, speaking styles, linguistic contexts, and acoustic environments. The authors present evidence that perceptual sensitivity to talker variability involves an active cognitive mechanism: Listeners expecting to hear 2 different talkers differing only slightly in average pitch showed performance costs typical of adjusting to talker variability, whereas listeners hearing the same materials but expecting a single talker or given no special instructions did not show these performance costs. The authors discuss the implications for understanding phonetic constancy despite variability between talkers (and other sources of variability) and for theories of speech perception. The results provide further evidence for active, controlled processing in real-time speech perception and are consistent with a model of talker normalization that involves contextual tuning.},
	Author = {Magnuson, James S. and Nusbaum, Howard C.},
	Doi = {10.1037/0096-1523.33.2.391},
	File = {magnuson_nusbaum_JEPHPP2007.pdf:/Users/Cecile/Zotero/storage/THRKQ284/magnuson_nusbaum_JEPHPP2007.pdf:application/pdf},
	Issn = {0096-1523},
	Journal = {Journal of Experimental Psychology. Human Perception and Performance},
	Keywords = {Acoustics, Female, Humans, Male, Phonetics, Verbal Behavior, speech perception, Speech Perception},
	Language = {eng},
	Month = apr,
	Number = {2},
	Pages = {391--409},
	Pmid = {17469975},
	Title = {Acoustic differences, listener expectations, and the perceptual accommodation of talker variability},
	Volume = {33},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1037/0096-1523.33.2.391}}

@article{heald_perceptual_2017,
	Abstract = {In our auditory environment, we rarely experience the exact acoustic waveform twice. This is especially true for communicative signals that have meaning for listeners. In speech and music, the acoustic signal changes as a function of the talker (or instrument), speaking (or playing) rate, and room acoustics, to name a few factors. Yet, despite this acoustic variability, we are able to recognize a sentence or melody as the same across various kinds of acoustic inputs and determine meaning based on listening goals, expectations, context, and experience. The recognition process relates acoustic signals to prior experience despite variability in signal-relevant and signal-irrelevant acoustic properties, some of which could be considered as "noise" in service of a recognition goal. However, some acoustic variability, if systematic, is lawful and can be exploited by listeners to aid in recognition. Perceivable changes in systematic variability can herald a need for listeners to reorganize perception and reorient their attention to more immediately signal-relevant cues. This view is not incorporated currently in many extant theories of auditory perception, which traditionally reduce psychological or neural representations of perceptual objects and the processes that act on them to static entities. While this reduction is likely done for the sake of empirical tractability, such a reduction may seriously distort the perceptual process to be modeled. We argue that perceptual representations, as well as the processes underlying perception, are dynamically determined by an interaction between the uncertainty of the auditory signal and constraints of context. This suggests that the process of auditory recognition is highly context-dependent in that the identity of a given auditory object may be intrinsically tied to its preceding context. To argue for the flexible neural and psychological updating of sound-to-meaning mappings across speech and music, we draw upon examples of perceptual categories that are thought to be highly stable. This framework suggests that the process of auditory recognition cannot be divorced from the short-term context in which an auditory object is presented. Implications for auditory category acquisition and extant models of auditory perception, both cognitive and neural, are discussed.},
	Author = {Heald, Shannon L. M. and Van Hedger, Stephen C. and Nusbaum, Howard C.},
	Doi = {10.3389/fpsyg.2017.00781},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {Auditory Perception, dynamical systems, lack of invariance, music perception, perceptual constancy, short-term plasticity, Categorization, speech perception, Speech Perception},
	Language = {eng},
	Pages = {781},
	Pmcid = {PMC5440584},
	Pmid = {28588524},
	Title = {Perceptual {Plasticity} for {Auditory} {Object} {Recognition}},
	Volume = {8},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.3389/fpsyg.2017.00781}}

@article{dorman_stop-consonant_1977,
	Abstract = {Three experiments assessed the roles of release bursts and formant transitions as acoustic cues to place of articulation in syllable-initial voiced stop consonants by systematically removing them from American English /b,d,g/, spoken before nine different vowels by two speakers, and by transposing the bursts across all vowels for each class of stop consonant. The results showed that bursts were largely invariant in their effect, but carried significant perceptual weight in only one syllable out of 27 for Speaker 1, in only 13 syllables out of 27 for Speaker 2. Furthermore, bursts and transitions tended to be reciprocally related: Where the perceptual weight of one increased, the weight of the other declined. They were thus shown to be functionally equivalent, context-dependent cues, each contributing to the rapid spectral changes that follow consonantal release. The results are interpreted as pointing to the possible role of the front-cavity resonance in signaling place of articulation.},
	Author = {Dorman, M. F. and Studdert-Kennedy, M. and Raphael, L. J.},
	Doi = {10.3758/BF03198744},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/M9DS5ZQG/Dorman et al. - 1977 - Stop-consonant recognition Release bursts and for.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RCH6848K/BF03198744.html:text/html},
	Issn = {0031-5117, 1532-5962},
	Journal = {Perception \& Psychophysics},
	Language = {en},
	Month = mar,
	Number = {2},
	Pages = {109--122},
	Shorttitle = {Stop-consonant recognition},
	Title = {Stop-consonant recognition: {Release} bursts and formant transitions as functionally equivalent, context-dependent cues},
	Url = {https://link.springer.com/article/10.3758/BF03198744},
	Urldate = {2017-12-03},
	Volume = {22},
	Year = {1977},
	Bdsk-Url-1 = {https://link.springer.com/article/10.3758/BF03198744},
	Bdsk-Url-2 = {https://doi.org/10.3758/BF03198744}}

@article{anderson_information-processing_2003,
	Abstract = {Two imaging experiments were performed--one involving an algebraic transformation task studied by Anderson, Reder, and Lebiere (1996) and the other an abstraction symbol manipulation task studied by Blessing and Anderson (1996). ACT-R models exist that predict the latency patterns in these tasks. These models require activity in an imaginal buffer to represent changes to the problem representation, in a retrieval buffer to hold information from declarative memory, and in a manual buffer to hold information about motor behavior. A general theory is described about how to map activity in these buffers onto the fMRI blood oxygen level dependent (BOLD) response. This theory claims that the BOLD response is integrated over the duration that a buffer is active and can be used to predict the observed BOLD function. Activity in the imaginal buffer is shown to predict the BOLD response in a left posterior parietal region; activity in the retrieval buffer is shown to predict the BOLD response in a left prefrontal region; and activity in the manual buffer is shown to predict activity in a motor region. More generally, this article shows how to map a large class of information-processing theories (not just ACT-R) onto the BOLD response and provides a precise interpretation of the cognitive significance of the BOLD response.},
	Author = {Anderson, John R. and Qin, Yulin and Sohn, Myeong-Ho and Stenger, V. Andrew and Carter, Cameron S.},
	File = {Anderson2003.pdf:/Users/Cecile/Zotero/storage/RUB47XRV/Anderson2003.pdf:application/pdf},
	Issn = {1069-9384},
	Journal = {Psychonomic Bulletin \& Review},
	Keywords = {Cognition, Humans, Memory, Models, Biological, Oxygen, Parietal Lobe, Symbolism, Brain, Magnetic resonance imaging},
	Language = {eng},
	Month = jun,
	Number = {2},
	Pages = {241--261},
	Pmid = {12921408},
	Title = {An information-processing model of the {BOLD} response in symbol manipulation tasks},
	Volume = {10},
	Year = {2003}}

@article{mayhew_global_2016,
	Abstract = {In functional magnetic resonance imaging (fMRI), the relationship between positive BOLD responses (PBRs) and negative BOLD responses (NBRs) to stimulation is potentially informative about the balance of excitatory and inhibitory brain responses in sensory cortex. In this study, we performed three separate experiments delivering visual, motor or somatosensory stimulation unilaterally, to one side of the sensory field, to induce PBR and NBR in opposite brain hemispheres. We then assessed the relationship between the evoked amplitudes of contralateral PBR and ipsilateral NBR at the level of both single-trial and average responses. We measure single-trial PBR and NBR peak amplitudes from individual time-courses, and show that they were positively correlated in all experiments. In contrast, in the average response across trials the absolute magnitudes of both PBR and NBR increased with increasing stimulus intensity, resulting in a negative correlation between mean response amplitudes. Subsequent analysis showed that the amplitude of single-trial PBR was positively correlated with the BOLD response across all grey-matter voxels and was not specifically related to the ipsilateral sensory cortical response. We demonstrate that the global component of this single-trial response modulation could be fully explained by voxel-wise vascular reactivity, the BOLD signal standard deviation measured in a separate resting-state scan (resting state fluctuation amplitude, RSFA). However, bilateral positive correlation between PBR and NBR regions remained. We further report that modulations in the global brain fMRI signal cannot fully account for this positive PBR--NBR coupling and conclude that the local sensory network response reflects a combination of superimposed vascular and neuronal signals. More detailed quantification of physiological and noise contributions to the BOLD signal is required to fully understand the trial-by-trial PBR and NBR relationship compared with that of average responses.},
	Author = {Mayhew, S. D. and Mullinger, K. J. and Ostwald, D. and Porcaro, C. and Bowtell, R. and Bagshaw, A. P. and Francis, S. T.},
	Doi = {10.1016/j.neuroimage.2016.02.077},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/FZPHIVHW/Mayhew et al. - 2016 - Global signal modulation of single-trial fMRI resp.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/D3J9Q6VE/S1053811916001956.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Global signal, Negative BOLD response, deactivation, RSFA},
	Month = jun,
	Number = {Supplement C},
	Pages = {62--74},
	Shorttitle = {Global signal modulation of single-trial {fMRI} response variability},
	Title = {Global signal modulation of single-trial {fMRI} response variability: {Effect} on positive vs negative {BOLD} response relationship},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811916001956},
	Urldate = {2017-12-12},
	Volume = {133},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811916001956},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2016.02.077}}

@article{mullinger_evidence_2014,
	Abstract = {Unambiguous interpretation of changes in the BOLD signal is challenging because of the complex neurovascular coupling that translates changes in neuronal activity into the subsequent haemodynamic response. In particular, the neurophysiological origin of the negative BOLD response (NBR) remains incompletely understood. Here, we simultaneously recorded BOLD, EEG and cerebral blood flow (CBF) responses to 10s blocks of unilateral median nerve stimulation (MNS) in order to interrogate the NBR. Both negative BOLD and negative CBF responses to MNS were observed in the same region of the ipsilateral primary sensorimotor cortex (S1/M1) and calculations showed that MNS induced a decrease in the cerebral metabolic rate of oxygen consumption (CMRO2) in this NBR region. The âCMRO2/âCBF coupling ratio (n) was found to be significantly larger in this ipsilateral S1/M1 region (n=0.91$\pm$0.04, M=10.45\%) than in the contralateral S1/M1 (n=0.65$\pm$0.03, M=10.45\%) region that exhibited a positive BOLD response (PBR) and positive CBF response, and a consequent increase in CMRO2 during MNS. The fMRI response amplitude in ipsilateral S1/M1 was negatively correlated with both the power of the 8--13Hz EEG mu oscillation and somatosensory evoked potential amplitude. Blocks in which the largest magnitude of negative BOLD and CBF responses occurred therefore showed greatest mu power, an electrophysiological index of cortical inhibition, and largest somatosensory evoked potentials. Taken together, our results suggest that a neuronal mechanism underlies the NBR, but that the NBR may originate from a different neurovascular coupling mechanism to the PBR, suggesting that caution should be taken in assuming the NBR simply represents the neurophysiological inverse of the PBR.},
	Author = {Mullinger, K. J. and Mayhew, S. D. and Bagshaw, A. P. and Bowtell, R. and Francis, S. T.},
	Doi = {10.1016/j.neuroimage.2014.02.029},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RCANGMJW/Mullinger et al. - 2014 - Evidence that the negative BOLD response is neuron.pdf:application/pdf;ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KIUJT7CC/Mullinger et al. - 2014 - Evidence that the negative BOLD response is neuron.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9GUIE4CH/S1053811914001426.html:text/html;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WP2MNJM9/S1053811914001426.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = jul,
	Number = {Supplement C},
	Pages = {263--274},
	Shorttitle = {Evidence that the negative {BOLD} response is neuronal in origin},
	Title = {Evidence that the negative {BOLD} response is neuronal in origin: {A} simultaneous {EEG}--{BOLD}--{CBF} study in humans},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811914001426},
	Urldate = {2017-12-12},
	Volume = {94},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914001426},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.02.029}}

@article{obrig_impact_2017,
	Abstract = {During early language development native phonotactics are acquired in a `bottom-up' fashion, relying on exquisite auditory differentiation skills operational from birth. Since basic lexico-semantic abilities have been demonstrated from 6 months onwards, `top-down' influences on phonotactic learning may complement the extraction of transitional probabilities in phonotactic learning. Such a bidirectional acquisition strategy predicts, that familiarization with (proto)words should affect processing of untrained word-forms of similar phonological structure. We investigated 6-month-old infants undergoing an associative training to establish a pseudoword-pseudoobject link. Comparison between pre- and post-training responses to trained and untrained items allowed investigating training effects. Additionally phonotactic status (50\% legal, 50\% illegal with regard to German) allowed investigating influences of previous language experience. EEG and functional near-infrared spectroscopy (fNIRS) provided measures of electrophysiological and hemodynamic responses. We find evidence for a robust effect of associative training on pseudoword processing when presented in isolation. This transferred to untrained items. Previous linguistic experience showed a much weaker effect. Taken together the results suggest that sensitivity to phonotactic contrasts is present at 6 months, but that acceptance as lexical candidates is rapidly modulated when word forms following non-native phonotactics become potentially meaningful due to repeated exposure in a semantic context.},
	Author = {Obrig, Hellmuth and Mock, Julia and Stephan, Franziska and Richter, Maria and Vignotto, Micol and Rossi, Sonja},
	Doi = {10.1016/j.dcn.2016.09.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UGUCKWJ3/Obrig et al. - 2017 - Impact of associative word learning on phonotactic.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8XW9SV6D/S1878929316300603.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Language Development, Associative training, fNIRS, phonotactics},
	Month = jun,
	Number = {Supplement C},
	Pages = {185--197},
	Series = {Sensitive periods across development},
	Shorttitle = {Impact of associative word learning on phonotactic processing in 6-month-old infants},
	Title = {Impact of associative word learning on phonotactic processing in 6-month-old infants: {A} combined {EEG} and {fNIRS} study},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929316300603},
	Urldate = {2017-12-12},
	Volume = {25},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316300603},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2016.09.001}}

@article{steinbrink_illuminating_2006,
	Abstract = {Functional magnetic resonance imaging (fMRI) is currently combined with electrophysiological methods to identify the relationship between neuronal activity and the blood oxygenation level-dependent (BOLD) signal. Several processes like neuronal activity, synaptic activity, vascular dilation, blood volume and oxygenation changes underlie both response modalities, that is, the electrophysiological signal and the vascular response. However, accessing single process relationships is absolutely mandatory when aiming at a deeper understanding of neurovascular coupling and necessitates studies on the individual building blocks of the vascular response. Combined fMRI and functional near-infrared spectroscopy studies have been performed to validate the correlation of the BOLD signal to the hemodynamic changes in the brain. Here we review the current status of the integration of both technologies and judge these studies in the light of recent findings on neurovascular coupling.},
	Author = {Steinbrink, Jens and Villringer, Arno and Kempf, Florian and Haux, Daniel and Boden, Stefanie and Obrig, Hellmuth},
	Doi = {10.1016/j.mri.2005.12.034},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/2PQIMXF6/Steinbrink et al. - 2006 - Illuminating the BOLD signal combined fMRI--fNIRS .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GKEK29C6/S0730725X06000531.html:text/html},
	Issn = {0730-725X},
	Journal = {Magnetic Resonance Imaging},
	Keywords = {BOLD, Hemodynamic response function (HRF), fMRI, fNIRS},
	Month = may,
	Number = {4},
	Pages = {495--505},
	Shorttitle = {Illuminating the {BOLD} signal},
	Title = {Illuminating the {BOLD} signal: combined {fMRI}--{fNIRS} studies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0730725X06000531},
	Urldate = {2017-12-12},
	Volume = {24},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0730725X06000531},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.mri.2005.12.034}}

@article{honda_how_2010,
	Abstract = {Using near-infrared spectroscopy (NIRS), we recorded changes of oxy-Hb, deoxy-Hb, and total-Hb in 7- to 8-month-old infants' and adults' brains in response to canonical face and scrambled face stimuli. Using a newly developed probe for NIRS recording, which was light and soft enough to be tolerated by infants, we were able to acquire data from the very young even in the awake state. Total-Hb in response to a canonical face stimulus was greater than for scrambled face stimuli only in the right hemisphere in infants. This indicates the presence of right hemisphere dominance of brain activity in response to face images in 7- to 8-month-old infants. In adults, oxy-Hb and total-Hb were significantly increased from baseline only for the canonical face in the right hemisphere. There were greater numbers of channels showing significantly increased activity for the canonical face in the right than in the left hemisphere. These data indicate that the right hemisphere is more dominant for canonical face perception in both infants and adults. However, overall, the increase of total-Hb and oxy-Hb in adults was modest compared to infants. Although the reason for the difference between infants and adults is unclear, in addition to developmental changes influencing face perception, some methodological problems may be present. Thus, because we recorded NIRS signals in infants and adults using the same method, anatomical and physiological problems might affect the results to some degree. Although comparing the results between infants and adults is not simple, the present study is the first to indicate how 7- to 8-month-old infants perceive scrambled face stimuli and to compare such results with those of adults in order to understand developmental changes in face perception.},
	Author = {Honda, Yukiko and Nakato, Emi and Otsuka, Yumiko and Kanazawa, So and Kojima, Shozo and Yamaguchi, Masami K. and Kakigi, Ryusuke},
	Doi = {10.1016/j.brainres.2009.10.046},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/UT2595BB/Honda et al. - 2010 - How do infants perceive scrambled face A near-in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/PXMCKIKI/S0006899309022240.html:text/html},
	Issn = {0006-8993},
	Journal = {Brain Research},
	Keywords = {Infant, Near infrared spectroscopy (NIRS), face perception, Developmental change, Scrambled face},
	Month = jan,
	Number = {Supplement C},
	Pages = {137--146},
	Shorttitle = {How do infants perceive scrambled face?},
	Title = {How do infants perceive scrambled face?: {A} near-infrared spectroscopic study},
	Url = {http://www.sciencedirect.com/science/article/pii/S0006899309022240},
	Urldate = {2017-12-14},
	Volume = {1308},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0006899309022240},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.brainres.2009.10.046}}

@article{buxton_dynamics_1998,
	Abstract = {A biomechanical model is presented for the dynamic changes in deoxyhemoglobin content during brain activation. The model incorporates the conflicting effects of dynamic changes in both blood oxygenation and blood volume. Calculations based on the model show pronounced transients in the deoxyhemoglobin content and the blood oxygenation level dependent (BOLD) signal measured with functional MRI, including initial dips and overshoots and a prolonged post-stimulus undershoot of the BOLD signal. Furthermore, these transient effects can occur in the presence of tight coupling of cerebral blood flow and oxygen metabolism throughout the activation period. An initial test of the model against experimental measurements of flow and BOLD changes during a finger-tapping task showed good agreement.},
	Author = {Buxton, Richard B. and Wong, Eric C. and Frank, Lawrence R.},
	Doi = {10.1002/mrm.1910390602},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FEPHMQ5D/Buxton et al. - 1998 - Dynamics of blood flow and oxygenation changes dur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMCBUTCM/abstract\;jsessionid=574B21C633AFB659AF923D355EC813B9.html:text/html},
	Issn = {1522-2594},
	Journal = {Magnetic Resonance in Medicine},
	Keywords = {cerebral blood flow, cerebral blood volume, cerebral oxygen metabolism, functional magnetic resonance imaging},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {855--864},
	Shorttitle = {Dynamics of blood flow and oxygenation changes during brain activation},
	Title = {Dynamics of blood flow and oxygenation changes during brain activation: {The} balloon model},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1910390602/abstract},
	Urldate = {2017-12-18},
	Volume = {39},
	Year = {1998},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/mrm.1910390602/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1002/mrm.1910390602}}

@book{macwhinney_childes_2000,
	Author = {MacWhinney, B.},
	Publisher = {Mahwah, NJ: Lawrence Erlbaum Associates.},
	Title = {The {CHILDES} {Project}: {Tools} for analyzing talk. {Third} {Edition}.},
	Year = {2000}}

@article{telkemeyer_acoustic_2011,
	Abstract = {Speech perception requires rapid extraction of the linguistic content from the acoustic signal. The ability to efficiently process rapid changes in auditory information is important for decoding speech and thereby crucial during language acquisition. Investigating functional networks of speech perception in infancy might elucidate neuronal ensembles supporting perceptual abilities that gate language acquisition. Interhemispheric specializations for language have been demonstrated in infants. How these asymmetries are shaped by basic temporal acoustic properties is under debate. We recently provided evidence that newborns process non-linguistic sounds sharing temporal features with language in a differential and lateralized fashion. The present study used the same material while measuring brain responses of 6 and 3âmonth old infants using simultaneous recordings of electroencephalography (EEG) and near-infrared spectroscopy (NIRS). NIRS reveals that the lateralization observed in newborns remains constant over the first months of life. While fast acoustic modulations elicit bilateral neuronal activations, slow modulations lead to right-lateralized responses. Additionally, auditory-evoked potentials and oscillatory EEG responses show differential responses for fast and slow modulations indicating a sensitivity for temporal acoustic variations. Oscillatory responses reveal an effect of development, that is, 6 but not 3âmonth old infants show stronger theta-band desynchronization for slowly modulated sounds. Whether this developmental effect is due to increasing fine-grained perception for spectrotemporal sounds in general remains speculative. Our findings support the notion that a more general specialization for acoustic properties can be considered the basis for lateralization of speech perception. The results show that concurrent assessment of vascular based imaging and electrophysiological responses have great potential in the research on language acquisition.},
	Author = {Telkemeyer, Silke and Rossi, Sonja and Nierhaus, Till and Steinbrink, Jens and Obrig, Hellmuth and Wartenburger, Isabell},
	Doi = {10.3389/fpsyg.2011.00062},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/BIE3D8SB/Telkemeyer et al. - 2011 - Acoustic Processing of Temporally Modulated Sounds.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Month = apr,
	Pmcid = {PMC3110620},
	Pmid = {21716574},
	Shorttitle = {Acoustic {Processing} of {Temporally} {Modulated} {Sounds} in {Infants}},
	Title = {Acoustic {Processing} of {Temporally} {Modulated} {Sounds} in {Infants}: {Evidence} from a {Combined} {Near}-{Infrared} {Spectroscopy} and {EEG} {Study}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110620/},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110620/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00062}}

@article{rosen_constructing_2007,
	Abstract = {Vouloumanos and Werker (2007) claim that human neonates have a (possibly innate) bias to listen to speech based on a preference for natural speech utterances over sine-wave analogues. We argue that this bias more likely arises from the strikingly different saliency of voice melody in the two kinds of sounds, a bias that has already been shown to be learned pre-natally. Possible avenues of research to address this crucial issue are proposed, based on a consideration of the distinctive acoustic properties of speech.},
	Author = {Rosen, Stuart and Iverson, Paul},
	Doi = {10.1111/j.1467-7687.2007.00550.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/87GQ9ITT/Rosen et Iverson - 2007 - Constructing adequate non-speech analogues what i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PCKI4EUH/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = mar,
	Number = {2},
	Pages = {165--168},
	Shorttitle = {Constructing adequate non-speech analogues},
	Title = {Constructing adequate non-speech analogues: what is special about speech anyway?},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00550.x/abstract},
	Urldate = {2017-12-30},
	Volume = {10},
	Year = {2007},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2007.00550.x/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2007.00550.x}}

@book{lloyd_james_speech_1940,
	Address = {London},
	Author = {Lloyd James, Arthur},
	Keywords = {Signals and signaling., Speech., Telephone.},
	Language = {eng},
	Note = {Open Library ID: OL6442817M},
	Publisher = {Sir I. Pitman \& sons, ltd.},
	Title = {Speech signals in telephony},
	Year = {1940}}

@article{david_incorporating_nodate,
	Abstract = {For several decades, auditory neuroscientists have used spectro-temporal encoding models to understand how neurons in the auditory system represent sound. Derived from early applications of systems identification tools to the auditory periphery, the spectro-temporal receptive field (STRF) and more sophisticated variants have emerged as an efficient means of characterizing representation throughout the auditory system. Most of these encoding models describe neurons as static sensory filters. However, auditory neural coding is not static. Sensory context, reflecting the acoustic environment, and behavioral context, reflecting the internal state of the listener, can both influence sound-evoked activity, particularly in central auditory areas. This review explores recent efforts to integrate context into spectro-temporal encoding models. It begins with a brief tutorial on the basics of estimating and interpreting STRFs. Then it describes three recent studies that have characterized contextual effects on STRFs, emerging over a range of timescales, from many minutes to tens of milliseconds. An important theme of this work is not simply that context influences auditory coding, but also that contextual effects span a large continuum of internal states. The added complexity of these context-dependent models introduces new experimental and theoretical challenges that must be addressed in order to be used effectively. Several new methodological advances promise to address these limitations and allow the development of more comprehensive context-dependent models in the future.},
	Author = {David, Stephen V.},
	Doi = {10.1016/j.heares.2017.12.021},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KH5U4ER6/David - Incorporating behavioral and sensory context into .pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RJZ6EUVE/S0378595517303611.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Title = {Incorporating behavioral and sensory context into spectro-temporal models of auditory encoding},
	Url = {https://www.sciencedirect.com/science/article/pii/S0378595517303611},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0378595517303611},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2017.12.021}}

@article{sussman_can_2017,
	Author = {Sussman, Harvey Martin},
	File = {379.pdf:/Users/Cecile/Zotero/storage/2SXKUCE2/379.pdf:application/pdf},
	Journal = {BIOLINGUISTICS},
	Title = {Can a {Morphological} {Feature} of {Dendritic} {Structure} be {Linked} to {Language} {Acquisition}?},
	Volume = {11},
	Year = {2017}}

@article{borges_scale-free_2018,
	Abstract = {Speech comprehension is preserved up to a threefold acceleration, but deteriorates rapidly at higher speeds. Current models posit that perceptual resilience to accelerated speech is limited by the brain's ability to parse speech into syllabic units using Î´/Î¸ oscillations. Here, we investigated whether the involvement of neuronal oscillations in processing accelerated speech also relates to their scale-free amplitude modulation as indexed by the strength of long-range temporal correlations (LRTC). We recorded MEG while 24 human subjects (12 females) listened to radio news uttered at different comprehensible rates, at a mostly unintelligible rate and at this same speed interleaved with silence gaps. Î´, Î¸, and low-Î³ oscillations followed the nonlinear variation of comprehension, with LRTC rising only at the highest speed. In contrast, increasing the rate was associated with a monotonic increase in LRTC in high-Î³ activity. When intelligibility was restored with the insertion of silence gaps, LRTC in the Î´, Î¸, and low-Î³ oscillations resumed the low levels observed for intelligible speech. Remarkably, the lower the individual subject scaling exponents of Î´/Î¸ oscillations, the greater the comprehension of the fastest speech rate. Moreover, the strength of LRTC of the speech envelope decreased at the maximal rate, suggesting an inverse relationship with the LRTC of brain dynamics when comprehension halts. Our findings show that scale-free amplitude modulation of cortical oscillations and speech signals are tightly coupled to speech uptake capacity.
SIGNIFICANCE STATEMENT One may read this statement in 20--30 s, but reading it in less than five leaves us clueless. Our minds limit how much information we grasp in an instant. Understanding the neural constraints on our capacity for sensory uptake is a fundamental question in neuroscience. Here, MEG was used to investigate neuronal activity while subjects listened to radio news played faster and faster until becoming unintelligible. We found that speech comprehension is related to the scale-free dynamics of Î´ and Î¸ bands, whereas this property in high-Î³ fluctuations mirrors speech rate. We propose that successful speech processing imposes constraints on the self-organization of synchronous cell assemblies and their scale-free dynamics adjusts to the temporal properties of spoken language.},
	Author = {Borges, Ana Filipa Teixeira and Giraud, Anne-Lise and Mansvelder, Huibert D. and Linkenkaer-Hansen, Klaus},
	Copyright = {Copyright {\copyright} 2018 the authors 0270-6474/18/380710-13\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1515-17.2017},
	File = {Snapshot:/Users/Cecile/Zotero/storage/NKZV2JBD/710.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {accelerated speech, language comprehension, long-range temporal correlations, magnetoencephalography (MEG), principle of complexity management (PCM), scale-free dynamics},
	Language = {en},
	Month = jan,
	Number = {3},
	Pages = {710--722},
	Pmid = {29217685},
	Title = {Scale-{Free} {Amplitude} {Modulation} of {Neuronal} {Oscillations} {Tracks} {Comprehension} of {Accelerated} {Speech}},
	Url = {http://www.jneurosci.org/content/38/3/710},
	Urldate = {2018-01-23},
	Volume = {38},
	Year = {2018},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/38/3/710},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1515-17.2017}}

@article{wade_negative_2002,
	Abstract = {Many fMRI experiments show regions of cortex that seem to respond in antiphase with the primary stimulus. In this issue of Neuron, Shmuel et al. show that this ``negative BOLD response'' is spatially and temporally linked to reductions in blood flow. By combining BOLD and blood flow data to model the energy consumption in cortex, they conclude that the NBR is primarily due to active neuronal inhibition.},
	Author = {Wade, Alex R.},
	Doi = {10.1016/S0896-6273(02)01138-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SHX27LC5/Wade - 2002 - The Negative BOLD Signal Unmasked.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/B4CQ22FW/S0896627302011388.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = dec,
	Number = {6},
	Pages = {993--995},
	Title = {The {Negative} {BOLD} {Signal} {Unmasked}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627302011388},
	Urldate = {2018-01-08},
	Volume = {36},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627302011388},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0896-6273(02)01138-8}}

@article{fischer_ultrasonic_2011,
	Abstract = {Comparative analyses used to reconstruct the evolution of traits associated with the human language faculty, including its socio-cognitive underpinnings, highlight the importance of evolutionary constraints limiting vocal learning in non-human primates. After a brief overview of this field of research and the neural basis of primate vocalizations, we review studies that have addressed the genetic basis of usage and structure of ultrasonic communication in mice, with a focus on the gene FOXP2 involved in specific language impairments and neuroligin genes (NL-3 and NL-4) involved in autism spectrum disorders. Knockout of FoxP2 leads to reduced vocal behavior and eventually premature death. Introducing the human variant of FoxP2 protein into mice, in contrast, results in shifts in frequency and modulation of pup ultrasonic vocalizations. Knockout of NL-3 and NL-4 in mice diminishes social behavior and vocalizations. Although such studies may provide insights into the molecular and neural basis of social and communicative behavior, the structure of mouse vocalizations is largely innate, limiting the suitability of the mouse model to study human speech, a learned mode of production. Although knockout or replacement of single genes has perceptible effects on behavior, these genes are part of larger networks whose functions remain poorly understood. In humans, for instance, deficiencies in NL-4 can lead to a broad spectrum of disorders, suggesting that further factors (experiential and/or genetic) contribute to the variation in clinical symptoms. The precise nature as well as the interaction of these factors is yet to be determined.},
	Author = {Fischer, J and Hammerschmidt, K},
	Doi = {10.1111/j.1601-183X.2010.00610.x},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/WF9X4S9B/Fischer et Hammerschmidt - 2011 - Ultrasonic vocalizations in mouse models for speec.pdf:application/pdf},
	Issn = {1601-1848},
	Journal = {Genes, Brain, and Behavior},
	Month = feb,
	Number = {1},
	Pages = {17--27},
	Pmcid = {PMC3047712},
	Pmid = {20579107},
	Shorttitle = {Ultrasonic vocalizations in mouse models for speech and socio-cognitive disorders},
	Title = {Ultrasonic vocalizations in mouse models for speech and socio-cognitive disorders: insights into the evolution of vocal communication},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3047712/},
	Volume = {10},
	Year = {2011},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3047712/},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1601-183X.2010.00610.x}}

@article{gargiulo_effect_2015,
	Author = {Gargiulo, P. and Belfiore, P. and FriÃ°geirsson, E.A. and Vanhatalo, S. and Ramon, C.},
	Doi = {10.1016/j.clinph.2014.12.002},
	File = {Gargiulo 2015.pdf:/Users/Cecile/Zotero/storage/4XCLIWTP/Gargiulo 2015.pdf:application/pdf},
	Issn = {13882457},
	Journal = {Clinical Neurophysiology},
	Language = {en},
	Month = sep,
	Number = {9},
	Pages = {1703--1710},
	Title = {The effect of fontanel on scalp {EEG} potentials in the neonate},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S138824571400844X},
	Urldate = {2018-02-01},
	Volume = {126},
	Year = {2015},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S138824571400844X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2014.12.002}}

@phdthesis{diallo_probleme_2017,
	Author = {Diallo, Mohamadou Malal},
	File = {theseDiallo.pdf:/Users/Cecile/Zotero/storage/TC3IZX7F/theseDiallo.pdf:application/pdf},
	School = {Universit{\'e} de Picardie-Jules Verne},
	Title = {Probl{\`e}me inverse de sources en {Electro}-{Enc{\'e}phalo}-{Graphie} chez le nouveau-n{\'e}},
	Type = {{PhD} {Thesis}},
	Year = {2017}}

@article{alho_stimulus-dependent_2014,
	Author = {Alho, Kimmo and Rinne, Teemu and Herron, Timothy J. and Woods, David L.},
	Doi = {10.1016/j.heares.2013.08.001},
	File = {Alho_et_al_2014_Hear_Res_Auditory_fMRI_meta-analysis.pdf:/Users/Cecile/Zotero/storage/7ZI7355U/Alho_et_al_2014_Hear_Res_Auditory_fMRI_meta-analysis.pdf:application/pdf},
	Issn = {03785955},
	Journal = {Hearing Research},
	Language = {en},
	Month = jan,
	Pages = {29--41},
	Shorttitle = {Stimulus-dependent activations and attention-related modulations in the auditory cortex},
	Title = {Stimulus-dependent activations and attention-related modulations in the auditory cortex: {A} meta-analysis of {fMRI} studies},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0378595513001913},
	Urldate = {2018-02-01},
	Volume = {307},
	Year = {2014},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0378595513001913},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.08.001}}

@article{alho_attention-related_2012,
	Author = {Alho, Kimmo and Salonen, Johanna and Rinne, Teemu and Medvedev, Svyatoslav V. and Hugdahl, Kenneth and H{\"a}m{\"a}l{\"a}inen, Heikki},
	Doi = {10.1016/j.brainres.2012.01.007},
	File = {Alho_et_al_2012_Brain_Res_dichotic_listening_aud_attn_MEG.pdf:/Users/Cecile/Zotero/storage/HPENSBIC/Alho_et_al_2012_Brain_Res_dichotic_listening_aud_attn_MEG.pdf:application/pdf},
	Issn = {00068993},
	Journal = {Brain Research},
	Language = {en},
	Month = mar,
	Pages = {47--54},
	Title = {Attention-related modulation of auditory-cortex responses to speech sounds during dichotic listening},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S0006899312000455},
	Urldate = {2018-02-01},
	Volume = {1442},
	Year = {2012},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0006899312000455},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.brainres.2012.01.007}}

@article{flemming_evaluation_2005,
	Author = {Flemming, Lars and Wang, Yaozhi and Caprihan, Arvind and Eiselt, Michael and Haueisen, Jens and Okada, Yoshio},
	Doi = {10.1016/j.clinph.2005.01.007},
	File = {Flemming 2005.pdf:/Users/Cecile/Zotero/storage/JQPPZTAF/Flemming 2005.pdf:application/pdf},
	Issn = {13882457},
	Journal = {Clinical Neurophysiology},
	Language = {en},
	Month = may,
	Number = {5},
	Pages = {1141--1152},
	Title = {Evaluation of the distortion of {EEG} signals caused by a hole in the skull mimicking the fontanel in the skull of human neonates},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S1388245705000295},
	Urldate = {2018-02-01},
	Volume = {116},
	Year = {2005},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1388245705000295},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2005.01.007}}

@article{moerel_processing_2012,
	Abstract = {Auditory cortical processing of complex meaningful sounds entails the transformation of sensory (tonotopic) representations of incoming acoustic waveforms into higher-level sound representations (e.g., their category). However, the precise neural mechanisms enabling such transformations remain largely unknown. In the present study, we use functional magnetic resonance imaging (fMRI) and natural sounds stimulation to examine these two levels of sound representation (and their relation) in the human auditory cortex. In a first experiment, we derive cortical maps of frequency preference (tonotopy) and selectivity (tuning width) by mathematical modeling of fMRI responses to natural sounds. The tuning width maps highlight a region of narrow tuning that follows the main axis of Heschl's gyrus and is flanked by regions of broader tuning. The narrowly tuned portion on Heschl's gyrus contains two mirror-symmetric frequency gradients, presumably defining two distinct primary auditory areas. In addition, our analysis indicates that spectral preference and selectivity (and their topographical organization) extend well beyond the primary regions and also cover higher-order and category-selective auditory regions. In particular, regions with preferential responses to human voice and speech occupy the low-frequency portions of the tonotopic map. We confirm this observation in a second experiment, where we find that speech/voice selective regions exhibit a response bias toward the low frequencies characteristic of human voice and speech, even when responding to simple tones. We propose that this frequency bias reflects the selective amplification of relevant and category-characteristic spectral bands, a useful processing step for transforming a sensory (tonotopic) sound image into higher level neural representations.},
	Author = {Moerel, Michelle and Martino, Federico De and Formisano, Elia},
	Copyright = {Copyright {\copyright} 2012 the authors 0270-6474/12/3214205-12\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1388-12.2012},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FQA7XPVX/Moerel et al. - 2012 - Processing of Natural Sounds in Human Auditory Cor.pdf:application/pdf},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = oct,
	Number = {41},
	Pages = {14205--14216},
	Pmid = {23055490},
	Shorttitle = {Processing of {Natural} {Sounds} in {Human} {Auditory} {Cortex}},
	Title = {Processing of {Natural} {Sounds} in {Human} {Auditory} {Cortex}: {Tonotopy}, {Spectral} {Tuning}, and {Relation} to {Voice} {Sensitivity}},
	Url = {http://www.jneurosci.org/content/32/41/14205},
	Urldate = {2018-02-04},
	Volume = {32},
	Year = {2012},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/32/41/14205},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1388-12.2012}}

@article{friederici_towards_2002,
	Abstract = {Functional dissociations within the neural basis of auditory sentence processing are difficult to specify because phonological, syntactic and semantic information are all involved when sentences are perceived. In this review I argue that sentence processing is supported by a temporo--frontal network. Within this network, temporal regions subserve aspects of identification and frontal regions the building of syntactic and semantic relations. Temporal analyses of brain activation within this network support syntax-first models because they reveal that building of syntactic structure precedes semantic processes and that these interact only during a later stage.},
	Author = {Friederici, Angela D.},
	Doi = {10.1016/S1364-6613(00)01839-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/RTSTV3LU/Friederici - 2002 - Towards a neural basis of auditory sentence proces.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GB7Z8WES/S1364661300018398.html:text/html},
	Issn = {1364-6613},
	Journal = {Trends in Cognitive Sciences},
	Keywords = {neuroimaging, Broca's area, prosody, semantics, Syntax},
	Month = feb,
	Number = {2},
	Pages = {78--84},
	Title = {Towards a neural basis of auditory sentence processing},
	Url = {http://www.sciencedirect.com/science/article/pii/S1364661300018398},
	Urldate = {2018-02-04},
	Volume = {6},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1364661300018398},
	Bdsk-Url-2 = {https://doi.org/10.1016/S1364-6613(00)01839-8}}

@article{schridde_negative_2008,
	Abstract = {Blood oxygen level--dependent (BOLD) functional magnetic resonance imaging (fMRI) is widely used in neuroscience to study brain activity. However, BOLD fMRI does not measure neuronal activity directly but depends on cerebral blood flow (CBF), cerebral blood volume (CBV), and cerebral metabolic rate of oxygen (CMRO2) consumption. Using fMRI, CBV, CBF, neuronal recordings, and CMRO2 modeling, we investigated how the signals are related during seizures in rats. We found that increases in hemodynamic, neuronal, and metabolic activity were associated with positive BOLD signals in the cortex, but with negative BOLD signals in hippocampus. Our data show that negative BOLD signals do not necessarily imply decreased neuronal activity or CBF, but can result from increased neuronal activity, depending on the interplay between hemodynamics and metabolism. Caution should be used in interpreting fMRI signals because the relationship between neuronal activity and BOLD signals may depend on brain region and state and can be different during normal and pathological conditions.},
	Author = {Schridde, Ulrich and Khubchandani, Manjula and Motelow, Joshua E. and Sanganahalli, Basavaraju G. and Hyder, Fahmeed and Blumenfeld, Hal},
	Doi = {10.1093/cercor/bhm208},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/B3836W7J/Schridde et al. - 2008 - Negative BOLD with Large Increases in Neuronal Act.pdf:application/pdf},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Language = {en},
	Month = aug,
	Number = {8},
	Pages = {1814--1827},
	Title = {Negative {BOLD} with {Large} {Increases} in {Neuronal} {Activity}},
	Url = {https://academic.oup.com/cercor/article/18/8/1814/284529},
	Urldate = {2018-01-25},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/18/8/1814/284529},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhm208}}

@article{shmuel_sustained_2002,
	Abstract = {Most fMRI studies are based on the detection of a positive BOLD response (PBR). Here, we demonstrate and characterize a robust sustained negative BOLD response (NBR) in the human occipital cortex, triggered by stimulating part of the visual field. The NBR was spatially adjacent to but segregated from the PBR. It depended on the stimulus and thus on the pattern of neuronal activity. The time courses of the NBR and PBR were similar, and their amplitudes covaried both with increasing stimulus duration and increasing stimulus contrast. The NBR was associated with reductions in blood flow and with decreases in oxygen consumption. Our findings support the contribution to the NBR of (1) a significant component of reduction in neuronal activity and (2) possibly a component of hemodynamic changes independent of the local changes in neuronal activity.},
	Author = {Shmuel, Amir and Yacoub, Essa and Pfeuffer, Josef and Van de Moortele, Pierre-Francois and Adriany, Gregor and Hu, Xiaoping and Ugurbil, Kamil},
	Doi = {10.1016/S0896-6273(02)01061-9},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/M3C7GTB5/Shmuel et al. - 2002 - Sustained Negative BOLD, Blood Flow and Oxygen Con.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WK37DMSQ/S0896627302010619.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = dec,
	Number = {6},
	Pages = {1195--1210},
	Title = {Sustained {Negative} {BOLD}, {Blood} {Flow} and {Oxygen} {Consumption} {Response} and {Its} {Coupling} to the {Positive} {Response} in the {Human} {Brain}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627302010619},
	Urldate = {2018-01-25},
	Volume = {36},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627302010619},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0896-6273(02)01061-9}}

@article{hari_auditory_1980,
	Abstract = {SummaryA long auditory stimulus elicits a magnetic evoked response in the human brain, consisting of transient deflections followed by a sustained response. The distributions of the magnetic fields indicate that the auditory evoked transient response at a latency of 100 ms as well as the auditory sustained response are generated at and around the primary auditory cortex.},
	Author = {Hari, R. and Aittoniemi, K. and J{\"a}rvinen, M.-L. and Katila, T. and Varpula, T.},
	Doi = {10.1007/BF00237543},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/WJ8TAWVT/Hari et al. - 1980 - Auditory evoked transient and sustained magnetic f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7LDMLREP/BF00237543.html:text/html},
	Issn = {0014-4819, 1432-1106},
	Journal = {Experimental Brain Research},
	Language = {en},
	Month = sep,
	Number = {2},
	Pages = {237--240},
	Title = {Auditory evoked transient and sustained magnetic fields of the human brain localization of neural generators},
	Url = {https://link.springer.com/article/10.1007/BF00237543},
	Urldate = {2018-02-01},
	Volume = {40},
	Year = {1980},
	Bdsk-Url-1 = {https://link.springer.com/article/10.1007/BF00237543},
	Bdsk-Url-2 = {https://doi.org/10.1007/BF00237543}}

@article{ferry_edge_2016,
	Abstract = {To understand language, humans must encode information from rapid, sequential streams of syllables -- tracking their order and organizing them into words, phrases, and sentences. We used Near-Infrared Spectroscopy (NIRS) to determine whether human neonates are born with the capacity to track the positions of syllables in multisyllabic sequences. After familiarization with a six-syllable sequence, the neonate brain responded to the change (as shown by an increase in oxy-hemoglobin) when the two edge syllables switched positions but not when two middle syllables switched positions (Experiment 1), indicating that they encoded the syllables at the edges of sequences better than those in the middle. Moreover, when a 25 ms pause was inserted between the middle syllables as a segmentation cue, neonates' brains were sensitive to the change (Experiment 2), indicating that subtle cues in speech can signal a boundary, with enhanced encoding of the syllables located at the edges of that boundary. These findings suggest that neonates' brains can encode information from multisyllabic sequences and that this encoding is constrained. Moreover, subtle segmentation cues in a sequence of syllables provide a mechanism with which to accurately encode positional information from longer sequences. Tracking the order of syllables is necessary to understand language and our results suggest that the foundations for this encoding are present at birth.},
	Author = {Ferry, Alissa L. and Fl{\'o}, Ana and Brusini, Perrine and Cattarossi, Luigi and Macagno, Francesco and Nespor, Marina and Mehler, Jacques},
	Doi = {10.1111/desc.12323},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LIKKBV6S/Ferry et al. - 2016 - On the edge of language acquisition inherent cons.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7H7FCR32/abstract.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = may,
	Number = {3},
	Pages = {488--503},
	Shorttitle = {On the edge of language acquisition},
	Title = {On the edge of language acquisition: inherent constraints on encoding multisyllabic sequences in the neonate brain},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12323/abstract},
	Urldate = {2018-01-30},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12323/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12323}}

@article{issard_variability_2018,
	Abstract = {Measuring brain activity in developmental populations remains a major challenge despite great technological advances. Among the numerous available methods, functional near-infrared spectroscopy (fNIRS), an imaging modality that probes the hemodynamic response, is a powerful tool for recording brain activity in a great variety of situations and populations. Neurocognitive studies with infants have often reported inverted hemodynamic responses, i.e. a decrease instead of an increase in regional blood oxygenation, but the exact physiological explanation and cognitive interpretation of this response remain unclear. Here, we first provide an overview of the basic principles of NIRS and its use in cognitive developmental neuroscience. We then review the infant fNIRS literature to show that the hemodynamic response is modulated by experimental design and stimulus complexity, sometimes leading to hemodynamic responses with non-canonical shapes. We also argue that this effect is further modulated by the age of participants, the cortical regions involved, and the developmental stage of the tested cognitive process. We argue that this variability needs to be taken into account when designing and interpreting developmental studies measuring the hemodynamic response.},
	Author = {Issard, C{\'e}cile and Gervain, Judit},
	Doi = {10.1016/j.dcn.2018.01.009},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EVPQC8ZG/S187892931730049X.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {fNIRS, Infants, Development, Experimental complexity, Inverted Hemodynamic Response},
	Shorttitle = {Variability of the hemodynamic response in infants},
	Title = {Variability of the hemodynamic response in infants: {Influence} of experimental design and stimulus complexity},
	Url = {https://www.sciencedirect.com/science/article/pii/S187892931730049X},
	Urldate = {2018-02-05},
	Year = {2018},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S187892931730049X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2018.01.009}}

@article{may_specificity_2018,
	Abstract = {In this work we ask whether at birth, the human brain responds uniquely to speech, or if similar activation also occurs to a non-speech surrogate `language'. We compare neural activation in newborn infants to the language heard in utero (English), to an unfamiliar language (Spanish), and to a whistled surrogate language (Silbo Gomero) that, while used by humans to communicate, is not speech. Anterior temporal areas of the neonate cortex are activated in response to both familiar and unfamiliar spoken language, but these classic language areas are not activated to the whistled surrogate form. These results suggest that at the time human infants emerge from the womb, the neural preparation for language is specialized to speech.},
	Author = {May, Lillian and Gervain, Judit and Carreiras, Manuel and Werker, Janet F.},
	Doi = {10.1111/desc.12564},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/K3L3Y9BB/May et al. - The specificity of the neural response to speech a.pdf:application/pdf;may2017.pdf:/Users/Cecile/Zotero/storage/ISW8AKFJ/may2017.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6S3I6S8J/abstract\;jsessionid=467B234A42F2B0A6454F7393E93C39B2.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Number = {3},
	Pages = {n/a--n/a},
	Title = {The specificity of the neural response to speech at birth},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12564/abstract},
	Urldate = {2018-01-30},
	Volume = {21},
	Year = {2018},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12564/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12564}}

@article{lew_effects_2013,
	Author = {Lew, Seok and Sliva, Danielle D. and Choe, Myong-sun and Grant, P. Ellen and Okada, Yoshio and Wolters, Carsten H. and H{\"a}m{\"a}l{\"a}inen, Matti S.},
	Doi = {10.1016/j.neuroimage.2013.03.017},
	File = {Lew 2013.pdf:/Users/Cecile/Zotero/storage/96MBK8GV/Lew 2013.pdf:application/pdf},
	Issn = {10538119},
	Journal = {NeuroImage},
	Language = {en},
	Month = aug,
	Pages = {282--293},
	Title = {Effects of sutures and fontanels on {MEG} and {EEG} source analysis in a realistic infant head model},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913002590},
	Urldate = {2018-02-01},
	Volume = {76},
	Year = {2013},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1053811913002590},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2013.03.017}}

@article{alho_event-related_1990,
	Abstract = {We report here event-related potentials (ERPs) of human newborns to occasional pitch changes in a repetitive sequence of tone pips. These pitch changes elicited a large slow negative ERP component which resembles the mismatch negativity (MMN) generated by the adult brain under similar conditions. This MMN-type of negativity in newborns suggests that already at this early ontogenetic stage the brain monitors the acoustic environment for a possible change in any of its repetitive aspects. Apart from its theoretical interest, this finding might provide a new way to test the development of the central nervous system and to diagnose cerebral dysfunction at a very early stage.},
	Author = {Alho, K. and Sainio, K. and Sajaniemi, N. and Reinikainen, K. and N{\"a}{\"a}t{\"a}nen, R.},
	Doi = {10.1016/0168-5597(90)90031-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/BEGX3HKY/Alho et al. - 1990 - Event-related brain potential of human newborns to.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/GWY8L6XT/0168559790900318.html:text/html},
	Issn = {0168-5597},
	Journal = {Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section},
	Keywords = {Audition, Event-related brain potential, Mismatch negativity, Newborn},
	Month = mar,
	Number = {2},
	Pages = {151--155},
	Title = {Event-related brain potential of human newborns to pitch change of an acoustic stimulus},
	Url = {http://www.sciencedirect.com/science/article/pii/0168559790900318},
	Urldate = {2018-02-01},
	Volume = {77},
	Year = {1990},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0168559790900318},
	Bdsk-Url-2 = {https://doi.org/10.1016/0168-5597(90)90031-8}}

@article{moore_maturation_2002,
	Abstract = {This project traced the maturation of the human auditory cortex from midgestation to young adulthood, using immunostaining of axonal neurofilaments to determine the time of onset of rapid conduction. The study identified 3 developmental periods, each characterized by maturation of a different axonal system. During the perinatal period (3rd trimester to 4th postnatal month), neurofilament expression occurs only in axons of the marginal layer. These axons drive the structural and functional development of cells in the deeper cortical layers, but do not relay external stimuli. In early childhood (6 months to 5 years), maturing thalamocortical afferents to the deeper cortical layers are the first source of input to the auditory cortex from lower levels of the auditory system. During later childhood (5 to 12 years), maturation of commissural and association axons in the superficial cortical layers allows communication between different subdivisions of the auditory cortex, thus forming a basis for more complex cortical processing of auditory stimuli.},
	Author = {Moore, Jean K.},
	Doi = {10.1177/00034894021110S502},
	Issn = {0003-4894},
	Journal = {Annals of Otology, Rhinology \& Laryngology},
	Language = {en},
	Month = may,
	Number = {5\_suppl},
	Pages = {7--10},
	Shorttitle = {Maturation of {Human} {Auditory} {Cortex}},
	Title = {Maturation of {Human} {Auditory} {Cortex}: {Implications} for {Speech} {Perception}},
	Url = {https://doi.org/10.1177/00034894021110S502},
	Urldate = {2018-02-02},
	Volume = {111},
	Year = {2002},
	Bdsk-Url-1 = {https://doi.org/10.1177/00034894021110S502}}

@article{may_auditory_2004,
	Author = {May, P. J. and Tiitinen, H.},
	File = {May_Tiitinen_2004_Neurol_Clin_Neurophysiol_Auditory_scene_analysis_and_sensory_memory_Sustained_transient_MEG.pdf:/Users/Cecile/Zotero/storage/SRGSSRK4/May_Tiitinen_2004_Neurol_Clin_Neurophysiol_Auditory_scene_analysis_and_sensory_memory_Sustained_transient_MEG.pdf:application/pdf},
	Journal = {Neurology and Clinical Neurophysiology},
	Shorttitle = {Auditory scene analysis and sensory memory},
	Title = {Auditory scene analysis and sensory memory: the role of the auditory {N100m}},
	Volume = {19},
	Year = {2004}}

@article{edwards_functional_2016,
	Abstract = {Humans are born with the ability to mentally represent the approximate numerosity of a set of objects, but little is known about the brain systems that sub-serve this ability early in life and their relation to the brain systems underlying symbolic number and mathematics later in development. Here we investigate processing of numerical magnitudes before the acquisition of a symbolic numerical system or even spoken language, by measuring the brain response to numerosity changes in pre-verbal infants using functional near-infrared spectroscopy (fNIRS). To do this, we presented infants with two types of numerical stimulus blocks: number change blocks that presented dot arrays alternating in numerosity and no change blocks that presented dot arrays all with the same number. Images were carefully constructed to rule out the possibility that responses to number changes could be due to non-numerical stimulus properties that tend to co-vary with number. Interleaved with the two types of numerical blocks were audio-visual animations designed to increase attention. We observed that number change blocks evoked an increase in oxygenated hemoglobin over a focal right parietal region that was greater than that observed during no change blocks and during audio-visual attention blocks. The location of this effect was consistent with intra-parietal activity seen in older children and adults for both symbolic and non-symbolic numerical tasks. A distinct set of bilateral occipital and middle parietal channels responded more to the attention-grabbing animations than to either of the types of numerical stimuli, further dissociating the specific right parietal response to number from a more general bilateral visual or attentional response. These results provide the strongest evidence to date that the right parietal cortex is specialized for numerical processing in infancy, as the response to number is dissociated from visual change processing and general attentional processing.},
	Author = {Edwards, Laura A. and Wagner, Jennifer B. and Simon, Charline E. and Hyde, Daniel C.},
	Doi = {10.1111/desc.12333},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PUQ9SHN2/Edwards et al. - 2016 - Functional brain organization for number processin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T5W6P89L/abstract\;jsessionid=EB934C5ED2D842EE09A96E2D53D47898.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = sep,
	Number = {5},
	Pages = {757--769},
	Title = {Functional brain organization for number processing in pre-verbal infants},
	Url = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12333/abstract},
	Urldate = {2018-01-30},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1111/desc.12333/abstract},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12333}}

@article{hari_selective_1989,
	Author = {Hari, R. and H{\"a}m{\"a}l{\"a}inen, M. and Kaukoranta, E. and M{\"a}kel{\"a}, J. and Joutsiniemi, S. L. and Tiihonen, J.},
	File = {Hari_et_al_1989_Exp_Brain_Res_aud_attn_speech_tones_MEG_ERF.pdf:/Users/Cecile/Zotero/storage/BN7XYC2U/Hari_et_al_1989_Exp_Brain_Res_aud_attn_speech_tones_MEG_ERF.pdf:application/pdf},
	Journal = {Experimental Brain Research},
	Number = {3},
	Pages = {463--470},
	Title = {Selective listening modifies activity of the human auditory cortex},
	Volume = {74},
	Year = {1989}}

@article{vasile_human_2017,
	Abstract = {Data collected on astrocytes' physiology in the rodent have placed them as key regulators of synaptic, neuronal, network, and cognitive functions. While these findings proved highly valuable for our awareness and appreciation of non-neuronal cell significance in brain physiology, early structural and phylogenic investigations of human astrocytes hinted at potentially different astrocytic properties. This idea sparked interest to replicate rodent-based studies on human samples, which have revealed an analogous but enhanced involvement of astrocytes in neuronal function of the human brain. Such evidence pointed to a central role of human astrocytes in sustaining more complex information processing. Here, we review the current state of our knowledge of human astrocytes regarding their structure, gene profile, and functions, highlighting the differences with rodent astrocytes. This recent insight is essential for assessment of the relevance of findings using animal models and for comprehending the functional significance of species-specific properties of astrocytes. Moreover, since dysfunctional astrocytes have been described in many brain disorders, a more thorough understanding of human-specific astrocytic properties is crucial for better-adapted translational applications.},
	Author = {Vasile, Flora and Dossi, Elena and Rouach, Nathalie},
	Doi = {10.1007/s00429-017-1383-5},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/K8UFUF4H/Vasile et al. - 2017 - Human astrocytes structure and functions in the h.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/N8QZU4VF/s00429-017-1383-5.html:text/html},
	Issn = {1863-2653, 1863-2661},
	Journal = {Brain Structure and Function},
	Language = {en},
	Month = jul,
	Number = {5},
	Pages = {2017--2029},
	Shorttitle = {Human astrocytes},
	Title = {Human astrocytes: structure and functions in the healthy brain},
	Url = {https://link.springer.com/article/10.1007/s00429-017-1383-5},
	Urldate = {2018-02-07},
	Volume = {222},
	Year = {2017},
	Bdsk-Url-1 = {https://link.springer.com/article/10.1007/s00429-017-1383-5},
	Bdsk-Url-2 = {https://doi.org/10.1007/s00429-017-1383-5}}

@article{aizenberg_bidirectional_2015,
	Abstract = {Modulating the activity of a specific type of cortical neuron can either improve or impair the ability to discriminate between tones of different frequencies and to associate danger with specific sounds.},
	Author = {Aizenberg, Mark and Mwilambwe-Tshilobo, Laetitia and Briguglio, John J. and Natan, Ryan G. and Geffen, Maria N.},
	Doi = {10.1371/journal.pbio.1002308},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BZGH5TPF/Aizenberg et al. - 2015 - Bidirectional Regulation of Innate and Learned Beh.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DDPGRWGQ/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Cognition, Learning, Neuronal tuning, Neurons, Conditioned response, Interneurons, Lasers, Mice},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e1002308},
	Title = {Bidirectional {Regulation} of {Innate} and {Learned} {Behaviors} {That} {Rely} on {Frequency} {Discrimination} by {Cortical} {Inhibitory} {Neurons}},
	Url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002308},
	Urldate = {2018-02-14},
	Volume = {13},
	Year = {2015},
	Bdsk-Url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002308},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.1002308}}

@article{aizenberg_bidirectional_2013,
	Abstract = {Although emotional learning affects sensory acuity, little is known about how these changes are facilitated in the brain. We found that auditory fear conditioning in mice elicited either an increase or a decrease in frequency discrimination acuity depending on how specific the learned response was to the conditioned tone. Using reversible pharmacological inactivation, we found that the auditory cortex mediated learning-evoked changes in acuity in both directions.},
	Author = {Aizenberg, Mark and Geffen, Maria Neimark},
	Copyright = {2013 Nature Publishing Group},
	Doi = {10.1038/nn.3443},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BU9LQ5BQ/Aizenberg et Geffen - 2013 - Bidirectional effects of aversive learning on perc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WBDBLE6U/nn.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = aug,
	Number = {8},
	Pages = {994--996},
	Title = {Bidirectional effects of aversive learning on perceptual acuity are mediated by the sensory cortex},
	Url = {https://www.nature.com/articles/nn.3443},
	Urldate = {2018-02-14},
	Volume = {16},
	Year = {2013},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn.3443},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.3443}}

@article{osten_mapping_2013,
	Abstract = {The beginning of the 21st century has seen a renaissance in light microscopy and anatomical tract tracing that together are rapidly advancing our understanding of the form and function of neuronal circuits. The introduction of instruments for automated imaging of whole mouse brains, new cell type--specific and trans-synaptic tracers, and computational methods for handling the whole-brain data sets has opened the door to neuroanatomical studies at an unprecedented scale. We present an overview of the present state and future opportunities in charting long-range and local connectivity in the entire mouse brain and in linking brain circuits to function.},
	Author = {Osten, Pavel and Margrie, Troy W.},
	Copyright = {2013 Nature Publishing Group},
	Doi = {10.1038/nmeth.2477},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/5PE7CGG7/Osten et Margrie - 2013 - Mapping brain circuitry with a light microscope.pdf:application/pdf},
	Issn = {1548-7105},
	Journal = {Nature Methods},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {515--523},
	Title = {Mapping brain circuitry with a light microscope},
	Url = {https://www.nature.com/articles/nmeth.2477},
	Urldate = {2018-02-09},
	Volume = {10},
	Year = {2013},
	Bdsk-Url-1 = {https://www.nature.com/articles/nmeth.2477},
	Bdsk-Url-2 = {https://doi.org/10.1038/nmeth.2477}}

@article{blackwell_progress_2017,
	Abstract = {Advances in multi-neuron recordings and optogenetic manipulation have resulted in an interrogation of the function of specific cortical cell types in auditory cortex during sound processing. Here, the authors review this literature and discuss the merits of integrating computational approaches from dynamic network science.},
	Author = {Blackwell, Jennifer M. and Geffen, Maria N.},
	Copyright = {2017 The Author(s)},
	Doi = {10.1038/s41467-017-01755-2},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Z99HWLX6/Blackwell et Geffen - 2017 - Progress and challenges for understanding the func.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XJFIEKCP/s41467-017-01755-2.html:text/html},
	Issn = {2041-1723},
	Journal = {Nature Communications},
	Language = {en},
	Month = dec,
	Number = {1},
	Pages = {2165},
	Title = {Progress and challenges for understanding the function of cortical microcircuits in auditory processing},
	Url = {https://www.nature.com/articles/s41467-017-01755-2},
	Urldate = {2018-02-12},
	Volume = {8},
	Year = {2017},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41467-017-01755-2},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41467-017-01755-2}}

@article{kang_astrocyte-mediated_1998,
	Abstract = {We investigated the role of astrocytes in activity-dependent modulation of inhibitory synaptic transmission in hippocampal slices. Repetitive firing of an interneuron decreased the probability of synaptic failures in spike-evoked inhibitory postsynaptic currents (unitary IPSCs) in CA1 pyramidal neurons. The GABAB-receptor antagonist CGP55845A abolished this effect. Direct stimulation of astrocytes, or application of the GABAB-receptor agonist baclofen, potentiated miniature inhibitory postsynaptic currents (mIPSCs) in pyramidal neurons. These effects were blocked by inhibition of astrocytic calcium signaling with the calcium chelator BAPTA or by antagonists of the ionotropic glutamate receptors. These observations suggest that interneuronal firing elicits a GABAB-receptor-mediated elevation of calcium in surrounding astrocytes, which in turn potentiates inhibitory transmission. Astrocytes may therefore be a necessary intermediary in activity-dependent modulation of inhibitory synapses in the hippocampus.},
	Author = {Kang, J. and Jiang, L. and Goldman, S. A. and Nedergaard, M.},
	Doi = {10.1038/3684},
	Issn = {1097-6256},
	Journal = {Nature Neuroscience},
	Keywords = {Animals, Female, Male, ASTROCYTES, Synapses, Hippocampus, Neurons, Calcium Signaling, In Vitro Techniques, Neural Inhibition, Neuroglia, Rats, Rats, Sprague-Dawley, Receptors, AMPA, Receptors, N-Methyl-D-Aspartate, Synaptic Transmission},
	Language = {eng},
	Month = dec,
	Number = {8},
	Pages = {683--692},
	Pmid = {10196584},
	Title = {Astrocyte-mediated potentiation of inhibitory synaptic transmission},
	Volume = {1},
	Year = {1998},
	Bdsk-Url-1 = {https://doi.org/10.1038/3684}}

@article{dallerac_astrocytes_2016,
	Abstract = {Astrocytes are now viewed as key elements of brain wiring as well as neuronal communication. Indeed, they not only bridge the gap between metabolic supplies by blood vessels and neurons, but also allow fine control of neurotransmission by providing appropriate signaling molecules and insulation through a tight enwrapping of synapses. Recognition that astroglia is essential to neuronal communication is nevertheless fairly recent and the large body of evidence dissecting such role has focused on the synaptic level by identifying neuro- and gliotransmitters uptaken and released at synaptic or extrasynaptic sites. Yet, more integrated research deciphering the impact of astroglial functions on neuronal network activity have led to the reasonable assumption that the role of astrocytes in supervising synaptic activity translates in influencing neuronal processing and cognitive functions. Several investigations using recent genetic tools now support this notion by showing that inactivating or boosting astroglial function directly affects cognitive abilities. Accordingly, brain diseases resulting in impaired cognitive functions have seen their physiopathological mechanisms revisited in light of this primary protagonist of brain processing. We here provide a review of the current knowledge on the role of astrocytes in cognition and in several brain diseases including neurodegenerative disorders, psychiatric illnesses, as well as other conditions such as epilepsy. Potential astroglial therapeutic targets are also discussed.},
	Author = {Dall{\'e}rac, Glenn and Rouach, Nathalie},
	Doi = {10.1016/j.pneurobio.2016.01.003},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XN6786SE/S0301008215300769.html:text/html},
	Issn = {0301-0082},
	Journal = {Progress in Neurobiology},
	Keywords = {Epilepsy, Memory, Astroglial network, Neuroglial interactions, Neurodegenerative diseases, Psychiatric diseases, Alzheimer, Huntington, Parkinson, Depression, Schizophrenia, Bipolar disorder, Autism spectrum disorder, Fragile X, Rett syndrome},
	Month = sep,
	Pages = {48--67},
	Series = {Targeting {Astrocytes} in {Brain} {Injuries}: {A} {Translational} {Research} {Approach}},
	Title = {Astrocytes as new targets to improve cognitive functions},
	Url = {http://www.sciencedirect.com/science/article/pii/S0301008215300769},
	Volume = {144},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0301008215300769},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.pneurobio.2016.01.003}}

@article{bazargani_astrocyte_2016,
	Abstract = {The discovery that transient elevations of calcium concentration occur in astrocytes, and release 'gliotransmitters' which act on neurons and vascular smooth muscle, led to the idea that astrocytes are powerful regulators of neuronal spiking, synaptic plasticity and brain blood flow. These findings were challenged by a second wave of reports that astrocyte calcium transients did not mediate functions attributed to gliotransmitters and were too slow to generate blood flow increases. Remarkably, the tide has now turned again: the most important calcium transients occur in fine astrocyte processes not resolved in earlier studies, and new mechanisms have been discovered by which astrocyte [Ca2+]i is raised and exerts its effects. Here we review how this third wave of discoveries has changed our understanding of astrocyte calcium signaling and its consequences for neuronal function.},
	Author = {Bazargani, Narges and Attwell, David},
	Copyright = {2016 Nature Publishing Group},
	Doi = {10.1038/nn.4201},
	File = {Snapshot:/Users/Cecile/Zotero/storage/26F3QRBS/nn.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {182--189},
	Shorttitle = {Astrocyte calcium signaling},
	Title = {Astrocyte calcium signaling: the third wave},
	Url = {https://www.nature.com/articles/nn.4201},
	Urldate = {2018-02-22},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn.4201},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.4201}}

@article{bindocci_three-dimensional_2017,
	Abstract = {Glial calcium dynamics in space and time
Astrocytes use calcium signals to process information received from neighboring brain cells and thus generate modulatory responses at the local or network level. Previous studies have relied on calcium imaging in line scans or in a single focal plane mostly focusing on the cell bodies of astrocytes. Bindocci et al. used more powerful scanners that can rapidly scan many focal planes. They combined this technique with advanced genetic tools for monitoring calcium gradients with high sensitivity, which allowed three-dimensional calcium imaging of a whole astrocyte. Most of the basal calcium activity occurred in the astrocyte processes, some in the endfeet, and only a small fraction actually in the cell bodies of astrocytes.
Science, this issue p. eaai8185
Structured Abstract
INTRODUCTIONAstrocytes translate incoming information and generate functional outputs via Ca2+ signaling. Thereby, they respond to neuronal activity, producing downstream modulation of synaptic functions, and may participate in hemodynamics regulation. Deciphering the ``Ca2+ language'' of astrocytes is therefore essential for defining their roles in brain physiology and pathology. However, the specifics of astrocytic Ca2+ signaling are still poorly understood, and recent studies producing inconsistent or contradictory results have fostered debate on the actual role of astrocytes in synaptic and vascular functions.
RATIONALEA neglected potential source of inconsistencies lies in the way astrocytic Ca2+ signaling has been studied to date, mostly by conventional two-dimensional (2D) imaging, which assumes that sampling a single ({\textasciitilde}1 Î¼m) focal plane is representative of the entire astrocytic cell. This is, however, dubious given that astrocytes are highly 3D cells, entertain heterogeneous 3D relations with neighboring structures, and display Ca2+ signals on a local scale. Therefore, we developed a new method to three-dimensionally scan entire astrocytes and observe full-cell Ca2+ dynamics.
RESULTSWith our 3D approach, we sampled astrocytes at a sufficient rate to detect events with durations of {\textgreater}1.5 s throughout the cell, and faster ones in selected substructures. We found that Ca2+ activity in an individual astrocyte is heterogeneously scattered throughout the cell, largely compartmented within each region, and preponderantly local. The majority resides in the ``gliapil,'' the peripheral region composed of fine (optically subresolved) structures occupying â¼75\% of the astrocyte volume. Within the central (resolvable) ``core,'' the soma is mostly inactive, whereas processes are frequently active yet show widely different activity between them. Even in individual processes, activity distributes heterogeneously, with alternating ``hot'' and ``cold'' spots.We performed 3D imaging in awake mice and in adult brain slices. Activity in vivo was faster and more frequent, particularly in endfeet, yet similar in properties and cellular distribution to slices, except for the presence of cell-wide ``global'' Ca2+ events mainly associated with mouse movement. Contrary to current beliefs, global events were not sweeping waves, but rather consisted of multifocal Ca2+ elevations that started at multiple gliapil loci and then spread to the core.At the vascular interface, astrocytic Ca2+ activity was mostly restricted to individual endfeet, even to their fractions, and only occasionally coordinated with the endfoot process or the rest of the astrocyte. Two or more endfeet were mainly asynchronous, even when enwrapping the same vessel. Astrocytic structures and axons intersected three-dimensionally, and minimal axonal activity (individual action potentials) produced time-correlated astrocytic Ca2+ elevations in small spots ({\textless}1\% of the volume), which demonstrates that astrocytes can sense even the lowest levels of neuronal activity.
CONCLUSIONWe provide the first comprehensive 3D map of Ca2+ activity in an individual astrocyte. Its widespread, heterogeneous, local, and mostly 3D nature confirms the appropriateness of our whole-cell imaging approach. Past 2D studies, often focusing on somatic Ca2+ dynamics, inadequately described the emerging richness and complexity of the astrocyte activity, notably at astrocyte-synapse and astrocyte-vascular interfaces, where activity is small, fast, and frequent. In this context, we can foresee future challenges in extending studies to the gliapil, whose structures fall below current optical resolution, and in reporting the complete gamut of astrocyte Ca2+ signals at the whole-cell scale, both requiring technical advances. Nonetheless, the technique demonstrated here promises to make 3D Ca2+ imaging the state-of-the-art approach for Ca2+ studies addressing the role of astrocytes in brain function. {\textless}img class="fragment-image" src="https://d2ufo47lrtsv5s.cloudfront.net/content/sci/356/6339/eaai8185/F1.medium.gif"/{\textgreater} Download high-res image Open in new tab Download Powerpoint 3D Ca2+ imaging reveals the complex activity of astrocytes.(1) Representation of the 3D structural interactions among astrocyte, axons, and blood vessels. The astrocyte contains optically resolved (c, core) and unresolved (g, gliapil) regions. (2) 3D Ca2+ imaging reveals different activity (intensity color scale) in different astrocytic regions (P, processes; S, soma; EF, endfoot); (3) in different processes; and (4) in different loci of individual processes. (5) It also reveals asynchronous activity in endfeet, (6) often restricted to endfoot subdomains, and (7) local astrocyte responses to minimal axonal firing, or (8) global responses to in vivo locomotion (time color scale).
Astrocyte communication is typically studied by two-dimensional calcium ion (Ca2+) imaging, but this method has not yielded conclusive data on the role of astrocytes in synaptic and vascular function. We developed a three-dimensional two-photon imaging approach and studied Ca2+ dynamics in entire astrocyte volumes, including during axon-astrocyte interactions. In both awake mice and brain slices, we found that Ca2+ activity in an individual astrocyte is scattered throughout the cell, largely compartmented between regions, preponderantly local within regions, and heterogeneously distributed regionally and locally. Processes and endfeet displayed frequent fast activity, whereas the soma was infrequently active. In awake mice, activity was higher than in brain slices, particularly in endfeet and processes, and displayed occasional multifocal cellwide events. Astrocytes responded locally to minimal axonal firing with time-correlated Ca2+ spots.
A two-photon imaging technique allows the measurement of calcium dynamics in neuronal glial cells in three dimensions.
A two-photon imaging technique allows the measurement of calcium dynamics in neuronal glial cells in three dimensions.},
	Author = {Bindocci, Erika and Savtchouk, Iaroslav and Liaudet, Nicolas and Becker, Denise and Carriero, Giovanni and Volterra, Andrea},
	Copyright = {Copyright {\copyright} 2017, American Association for the Advancement of Science},
	Doi = {10.1126/science.aai8185},
	File = {Snapshot:/Users/Cecile/Zotero/storage/VVZIXMGJ/eaai8185.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = may,
	Number = {6339},
	Pages = {eaai8185},
	Pmid = {28522470},
	Title = {Three-dimensional {Ca2}+ imaging advances understanding of astrocyte biology},
	Url = {http://science.sciencemag.org/content/356/6339/eaai8185},
	Urldate = {2018-02-24},
	Volume = {356},
	Year = {2017},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/356/6339/eaai8185},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.aai8185}}

@article{wild_effortful_2012,
	Abstract = {The conditions of everyday life are such that people often hear speech that has been degraded (e.g., by background noise or electronic transmission) or when they are distracted by other tasks. However, it remains unclear what role attention plays in processing speech that is difficult to understand. In the current study, we used functional magnetic resonance imaging to assess the degree to which spoken sentences were processed under distraction, and whether this depended on the acoustic quality (intelligibility) of the speech. On every trial, adult human participants attended to one of three simultaneously presented stimuli: a sentence (at one of four acoustic clarity levels), an auditory distracter, or a visual distracter. A postscan recognition test showed that clear speech was processed even when not attended, but that attention greatly enhanced the processing of degraded speech. Furthermore, speech-sensitive cortex could be parcellated according to how speech-evoked responses were modulated by attention. Responses in auditory cortex and areas along the superior temporal sulcus (STS) took the same form regardless of attention, although responses to distorted speech in portions of both posterior and anterior STS were enhanced under directed attention. In contrast, frontal regions, including left inferior frontal gyrus, were only engaged when listeners were attending to speech and these regions exhibited elevated responses to degraded, compared with clear, speech. We suggest this response is a neural marker of effortful listening. Together, our results suggest that attention enhances the processing of degraded speech by engaging higher-order mechanisms that modulate perceptual auditory processing.},
	Author = {Wild, Conor J. and Yusuf, Afiqah and Wilson, Daryl E. and Peelle, Jonathan E. and Davis, Matthew H. and Johnsrude, Ingrid S.},
	Copyright = {Copyright {\copyright} 2012 the authors 0270-6474/12/3214010-12\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1528-12.2012},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/HRZ5WMUN/Wild et al. - 2012 - Effortful Listening The Processing of Degraded Sp.pdf:application/pdf},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = oct,
	Number = {40},
	Pages = {14010--14021},
	Pmid = {23035108},
	Shorttitle = {Effortful {Listening}},
	Title = {Effortful {Listening}: {The} {Processing} of {Degraded} {Speech} {Depends} {Critically} on {Attention}},
	Url = {http://www.jneurosci.org/content/32/40/14010},
	Urldate = {2018-03-02},
	Volume = {32},
	Year = {2012},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/32/40/14010},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1528-12.2012}}

@article{hedwig_song_2017,
	Abstract = {Acoustic communication requires filter mechanisms to process and recognize key features of the perceived signals. We analysed such a filter mechanism in field crickets (Gryllus bimaculatus), which communicate with species-specific repetitive patterns of sound pulses and chirps. A delay-line and coincidence-detection mechanism, in which each sound pulse has an impact on the processing of the following pulse, is implicated to underlie the recognition of the species-specific pulse pattern. Based on this concept, we hypothesized that altering the duration of a single pulse or inter-pulse interval in three-pulse chirps will lead to different behavioural responses. Phonotaxis was tested in female crickets walking on a trackball exposed to different sound paradigms. Changing the duration of either the first, second or third pulse of the chirps led to three different characteristic tuning curves. Long first pulses decreased the phonotactic response whereas phonotaxis remained strong when the third pulse was long. Chirps with three pulses of increasing duration of 5, 20 and 50 ms elicited phonotaxis, but the chirps were not attractive when played in reverse order. This demonstrates specific, pulse duration-dependent effects while sequences of pulses are processed. The data are in agreement with a mechanism in which processing of a sound pulse has an effect on the processing of the subsequent pulse, as outlined in the flow of activity in a delay-line and coincidence-detector circuit. Additionally our data reveal a substantial increase in the gain of phonotaxis, when the number of pulses of a chirp is increased from two to three.},
	Author = {Hedwig, Berthold and Sarmiento-Ponce, Edith Julieta},
	Copyright = {{\copyright} 2017 The Authors.. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited.},
	Doi = {10.1098/rspb.2017.0745},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KXE8FQH8/Hedwig et Sarmiento-Ponce - 2017 - Song pattern recognition in crickets based on a de.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U3SCQ3TJ/20170745.html:text/html},
	Issn = {0962-8452, 1471-2954},
	Journal = {Proc. R. Soc. B},
	Language = {en},
	Month = may,
	Number = {1855},
	Pages = {20170745},
	Pmid = {28539524},
	Title = {Song pattern recognition in crickets based on a delay-line and coincidence-detector mechanism},
	Url = {http://rspb.royalsocietypublishing.org/content/284/1855/20170745},
	Urldate = {2018-03-12},
	Volume = {284},
	Year = {2017},
	Bdsk-Url-1 = {http://rspb.royalsocietypublishing.org/content/284/1855/20170745},
	Bdsk-Url-2 = {https://doi.org/10.1098/rspb.2017.0745}}

@article{lenard_acoustic_1969,
	Author = {Lenard, H. G. and Bernuth, H. von and Hutt, S. J.},
	Doi = {10.1016/0013-4694(69)90164-3},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/V4P4XLIJ/Lenard et al. - 1969 - Acoustic evoked responses in newborn infants the .pdf:application/pdf},
	Issn = {0013-4694},
	Journal = {Electroencephalography and Clinical Neurophysiology},
	Language = {English},
	Month = aug,
	Number = {2},
	Pages = {121--127},
	Shorttitle = {Acoustic evoked responses in newborn infants},
	Title = {Acoustic evoked responses in newborn infants: the influence of pitch and complexity of the stimulus},
	Url = {http://www.clinph-journal.com/article/0013-4694(69)90164-3/fulltext},
	Urldate = {2018-03-09},
	Volume = {27},
	Year = {1969},
	Bdsk-Url-1 = {http://www.clinph-journal.com/article/0013-4694(69)90164-3/fulltext},
	Bdsk-Url-2 = {https://doi.org/10.1016/0013-4694(69)90164-3}}

@article{klatt_analysis_1990,
	Author = {Klatt, Dennis H. and Klatt, Laura C.},
	Doi = {10.1121/1.398894},
	File = {Snapshot:/Users/Cecile/Zotero/storage/525HH6FL/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = feb,
	Number = {2},
	Pages = {820--857},
	Title = {Analysis, synthesis, and perception of voice quality variations among female and male talkers},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.398894},
	Urldate = {2018-03-08},
	Volume = {87},
	Year = {1990},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.398894},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.398894}}

@article{johnson_individual_1993,
	Author = {Johnson, Keith and Ladefoged, Peter and Lindau, Mona},
	Doi = {10.1121/1.406887},
	File = {Snapshot:/Users/Cecile/Zotero/storage/5EWTE89S/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = aug,
	Number = {2},
	Pages = {701--714},
	Title = {Individual differences in vowel production},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.406887},
	Volume = {94},
	Year = {1993},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.406887},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.406887}}

@article{hagiwara_acoustic_1995,
	Author = {Hagiwara, Robert},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/N4MSR4N4/Hagiwara - 1995 - WPP, No. 90 Acoustic Realizations of American r.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GID5SAZE/8779b7gq.pdf:application/pdf},
	Journal = {UCLA Working Papers in Phonetics},
	Language = {en},
	Month = aug,
	Pages = {1--187},
	Shorttitle = {{WPP}, {No}. 90},
	Title = {Acoustic {Realizations} of {American} /r/ as {Produced} by {Women} and {Men}},
	Url = {https://escholarship.org/uc/item/8779b7gq},
	Urldate = {2018-03-12},
	Volume = {90},
	Year = {1995},
	Bdsk-Url-1 = {https://escholarship.org/uc/item/8779b7gq}}

@incollection{lindblom_explaining_1990,
	Abstract = {The H\&H theory is developed from evidence showing that speaking and listening are shaped by biologically general processes. Speech production is adaptive. Speakers can, and typically do, tune their performance according to communicative and situational demands, controlling the interplay between production-oriented factors on the one hand, and output-oriented constraints on the other. For the ideal speaker, H\&H claims that such adaptations reflect his tacit awareness of the listener's access to sources of information independent of the signal and his judgement of the short-term demands for explicit signal information. Hence speakers are expected to vary their output along a continuum of hyper- and hypospeech. The theory suggests that the lack of invariance that speech signals commonly exhibit (Perkell and Klatt 1986) is a direct consequence of this adaptive organization (cf MacNeilage 1970). Accordingly, in the H\&H program the quest for phonetic invariance is replaced by another research task: Explicating the notion of sufficient discriminability and defining the class of speech signals that meet that criterion.},
	Author = {Lindblom, B.},
	Booktitle = {Speech {Production} and {Speech} {Modelling}},
	Doi = {10.1007/978-94-009-2037-8_16},
	File = {Snapshot:/Users/Cecile/Zotero/storage/SC6FQI8W/978-94-009-2037-8_16.html:text/html},
	Isbn = {978-94-010-7414-8 978-94-009-2037-8},
	Language = {en},
	Pages = {403--439},
	Publisher = {Springer, Dordrecht},
	Series = {{NATO} {ASI} {Series}},
	Shorttitle = {Explaining {Phonetic} {Variation}},
	Title = {Explaining {Phonetic} {Variation}: {A} {Sketch} of the {H}\&amp;{H} {Theory}},
	Url = {https://link.springer.com/chapter/10.1007/978-94-009-2037-8_16},
	Urldate = {2018-03-12},
	Year = {1990},
	Bdsk-Url-1 = {https://link.springer.com/chapter/10.1007/978-94-009-2037-8_16},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-94-009-2037-8_16}}

@book{perkell_invariance_2014,
	Abstract = {First published in 1986. Routledge is an imprint of Taylor \& Francis, an informa company.},
	Author = {Perkell, J. S. and Klatt, D. H.},
	Isbn = {978-1-317-76829-6},
	Keywords = {Medical / Audiology \& Speech Pathology, Psychology / General, Psychology / Cognitive Psychology \& Cognition, Psychology / Experimental Psychology},
	Language = {en},
	Month = jan,
	Note = {Google-Books-ID: HsmYAgAAQBAJ},
	Publisher = {Psychology Press},
	Title = {Invariance and {Variability} in {Speech} {Processes}},
	Year = {2014}}

@article{gervain_role_2018,
	Abstract = {Human infants are born linguistic citizens of the world, possessing broad-based, universal perceptual and learning abilities that allow them to start {\ldots}},
	Author = {Gervain, Judit},
	Doi = {10.1016/j.cobeha.2018.02.004},
	File = {Snapshot:/Users/Cecile/Zotero/storage/JKJHVBX4/S2352154617301365.html:text/html},
	Issn = {2352-1546},
	Journal = {Current Opinion in Behavioral Sciences},
	Language = {en},
	Month = jun,
	Pages = {62--67},
	Title = {The role of prenatal experience in language development},
	Url = {https://www.sciencedirect.com/science/article/pii/S2352154617301365},
	Urldate = {2018-03-18},
	Volume = {21},
	Year = {2018},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S2352154617301365},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cobeha.2018.02.004}}

@article{perani_bilingual_1998,
	Abstract = {Functional imaging methods show differences in the pattern of cerebral activation associated with the subject's native language (L1) compared with a second language (L2). In a recent PET investigation on bilingualism we showed that auditory processing of stories in L1 (Italian) engages the temporal lobes and temporoparietal cortex more extensively than L2 (English). However, in that study the Italian subjects learned L2 late and attained a fair, but not an excellent command of this language (low proficiency, late acquisition bilinguals). Thus, the different patterns of activation could be ascribed either to age of acquisition or to proficiency level. In the current study we use a similar paradigm to evaluate the effect of early and late acquisition of L2 in highly proficient bilinguals. We studied a group of Italian-English bilinguals who acquired L2 after the age of 10 years (high proficiency, late acquisition bilinguals) and a group of Spanish-Catalan bilinguals who acquired L2 before the age of 4 years (high proficiency, early acquisition bilinguals). The differing cortical responses we had observed when low proficiency volunteers listened to stories in L1 and L2 were not found in either of the high proficiency groups in this study. Several brain areas, similar to those observed for L1 in low proficiency bilinguals, were activated by L2. These findings suggest that, at least for pairs of L1 and L2 languages that are fairly close, attained proficiency is more important than age of acquisition as a determinant of the cortical representation of L2.},
	Author = {Perani, D. and Paulesu, E. and Galles, N. S. and Dupoux, E. and Dehaene, S. and Bettinardi, V. and Cappa, S. F. and Fazio, F. and Mehler, J.},
	Doi = {10.1093/brain/121.10.1841},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9CDR2SII/Perani et al. - 1998 - The bilingual brain. Proficiency and age of acquis.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/6ZDUQDDE/Perani et al. - 1998 - The bilingual brain. Proficiency and age of acquis.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MMX2UAPP/265619.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/MM8HECCI/265619.html:text/html},
	Issn = {0006-8950},
	Journal = {Brain},
	Language = {en},
	Month = oct,
	Number = {10},
	Pages = {1841--1852},
	Title = {The bilingual brain. {Proficiency} and age of acquisition of the second language.},
	Url = {https://academic.oup.com/brain/article/121/10/1841/265619},
	Urldate = {2018-03-20},
	Volume = {121},
	Year = {1998},
	Bdsk-Url-1 = {https://academic.oup.com/brain/article/121/10/1841/265619},
	Bdsk-Url-2 = {https://doi.org/10.1093/brain/121.10.1841}}

@article{dehaene_anatomical_1997,
	Abstract = {FUNCTIONAL magnetic resonance imaging was used to assess inter-subject variability in the cortical representation of language comprehension processes. Moderately fluent French-English bilinguals were scanned while they listened to stories in their first language (L1 = French) or in a second language (L2 = English) acquired at school after the age of seven. In all subjects, listening to L1 always activated a similar set of areas in the left temporal lobe, clustered along the left superior temporal sulcus. Listening to L2, however, activated a highly variable network of left and right temporal and frontal areas, sometimes restricted only to right-hemispheric regions. These results support the hypothesis that first language acquisition relies on a dedicated left-hemispheric cerebral network, while late second language acquisition is not necessarily associated with a reproducible biological substrate. The postulated contribution of the right hemisphere to L2 comprehension1 is found to hold only on average, individual subjects varying from complete right lateralization to standard left lateralization for L2.},
	Author = {Dehaene, Stanislas and Dupoux, Emmanuel and Mehler, Jacques and Cohen, Laurent and Paulesu, Eraldo and Perani, Daniela and van de Moortele, Pierre-Francois and Leh{\'e}ricy, St{\'e}phane and Le Bihan, Denis},
	File = {Snapshot:/Users/Cecile/Zotero/storage/JBSICM78/Anatomical_variability_in_the_cortical.30.html:text/html;Snapshot:/Users/Cecile/Zotero/storage/IJVZVG6U/Anatomical_variability_in_the_cortical.30.html:text/html},
	Issn = {0959-4965},
	Journal = {NeuroReport},
	Language = {en-US},
	Month = dec,
	Number = {17},
	Pages = {3809},
	Title = {Anatomical variability in the cortical representation of first and second language},
	Url = {https://journals.lww.com/neuroreport/Abstract/1997/12010/Anatomical_variability_in_the_cortical.30.aspx},
	Urldate = {2018-03-20},
	Volume = {8},
	Year = {1997},
	Bdsk-Url-1 = {https://journals.lww.com/neuroreport/Abstract/1997/12010/Anatomical_variability_in_the_cortical.30.aspx}}

@phdthesis{khatami_firoozabadi_neural_2017,
	Author = {Khatami Firoozabadi, Seyedeh Fatemeh},
	File = {Firoozabadi - Neural Coding and Models for Natural Sounds Recogn.pdf:/Users/Cecile/Zotero/storage/5NSHW724/Firoozabadi - Neural Coding and Models for Natural Sounds Recogn.pdf:application/pdf},
	Month = jul,
	School = {University of Connecticut},
	Title = {Neural {Coding} and {Models} for {Natural} {Sounds} {Recognition}: {Effects} of {Temporal} and {Spectral} {Features}},
	Url = {http://digitalcommons.uconn.edu/dissertations/1520},
	Year = {2017},
	Bdsk-Url-1 = {http://digitalcommons.uconn.edu/dissertations/1520}}

@article{gobl_role_2003,
	Abstract = {This paper explores the role of voice quality in the communication of emotions, moods and attitudes. Listeners' reactions to an utterance synthesised {\ldots}},
	Author = {Gobl, Christer and Chasaide, Ailbhe N.},
	Doi = {10.1016/S0167-6393(02)00082-1},
	File = {Snapshot:/Users/Cecile/Zotero/storage/SGRD8K32/S0167639302000821.html:text/html},
	Issn = {0167-6393},
	Journal = {Speech Communication},
	Language = {en},
	Month = apr,
	Number = {1-2},
	Pages = {189--212},
	Title = {The role of voice quality in communicating emotion, mood and attitude},
	Url = {https://www.sciencedirect.com/science/article/pii/S0167639302000821},
	Urldate = {2018-03-29},
	Volume = {40},
	Year = {2003},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0167639302000821},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0167-6393(02)00082-1}}

@article{maryn_acoustic_2009,
	Author = {Maryn, Youri and Roy, Nelson and De Bodt, Marc and Van Cauwenberge, Paul and Corthals, Paul},
	Doi = {10.1121/1.3224706},
	File = {Snapshot:/Users/Cecile/Zotero/storage/VNC3FDFX/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = nov,
	Number = {5},
	Pages = {2619--2634},
	Shorttitle = {Acoustic measurement of overall voice quality},
	Title = {Acoustic measurement of overall voice quality: {A} meta-analysis},
	Url = {https://asa.scitation.org/doi/10.1121/1.3224706},
	Volume = {126},
	Year = {2009},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.3224706},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.3224706}}

@article{mcgettigan_social_2015,
	Abstract = {The social life of voices: studying the neural bases for the expression and perception of the self and others during spoken communication},
	Author = {McGettigan, Carolyn},
	Doi = {10.3389/fnhum.2015.00129},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CVH6C4JS/McGettigan - 2015 - The social life of voices studying the neural bas.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {Functional Neuroimaging, Voice, speech perception, social neuroscience, speech production, Identity, Speech Perception},
	Language = {English},
	Shorttitle = {The social life of voices},
	Title = {The social life of voices: studying the neural bases for the expression and perception of the self and others during spoken communication},
	Url = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00129/full#B22},
	Urldate = {2018-03-29},
	Volume = {9},
	Year = {2015},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00129/full#B22},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2015.00129}}

@article{rosen_adaptation_1999,
	Author = {Rosen, Stuart and Faulkner, Andrew and Wilkinson, Lucy},
	Doi = {10.1121/1.428215},
	File = {Snapshot:/Users/Cecile/Zotero/storage/AX4TZX9X/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = nov,
	Number = {6},
	Pages = {3629--3636},
	Shorttitle = {Adaptation by normal listeners to upward spectral shifts of speech},
	Title = {Adaptation by normal listeners to upward spectral shifts of speech: {Implications} for cochlear implants},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.428215},
	Volume = {106},
	Year = {1999},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.428215},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.428215}}

@article{dana_thy1_2018,
	Abstract = {Calcium imaging is commonly used to measure the neural activity of large groups of neurons in mice. Genetically encoded calcium indicators (GECIs) can be delivered for this purpose using non-invasive genetic methods. Compared to viral gene transfer, transgenic targeting of GECIs provides stable long-term expression and obviates the need for invasive viral injections. Transgenic mice expressing the green GECI GCaMP6 are already widely used. Here we present the generation and characterizarion of transgenic mice expressing the sensitive red GECI jRGECO1a, driven by the Thy1 promoter. Four transgenic lines with different expression patterns showed sufficiently high expression for cellular in vivo imaging. We used two-photon microscopy to characterize visual responses of individual neurons in the visual cortex in vivo. The signal-to-noise ratio in transgenic mice was comparable to, or better than, for mice transduced with adeno-associated virus.We also show that Thy1-jRGECO1a transgenic mice are useful for transcranial population imaging and functional mapping using widefield fluorescecnce microscopy. We also demonstrate imaging of visual responses in retinal ganglion cells. Thy1-jRGECO1a transgenic mice are therefore a useful addition to the toolbox for imaging activity in intact neural networks.},
	Author = {Dana, Hod and Novak, Ondrej and Guardado-Montesino, Michael and Fransen, James W. and Hu, Amy and Borghuis, Bart G. and Guo, Caiying and Kim, Douglas S. and Svoboda, Karel},
	Copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	Doi = {10.1101/284497},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/J2HDLINK/Dana et al. - 2018 - Thy1 transgenic mice expressing the red fluorescen.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EASLGZEM/284497.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = mar,
	Pages = {284497},
	Title = {Thy1 transgenic mice expressing the red fluorescent calcium indicator {jRGECO1a} for neuronal population imaging in vivo},
	Url = {https://www.biorxiv.org/content/early/2018/03/18/284497},
	Urldate = {2018-04-03},
	Year = {2018},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2018/03/18/284497},
	Bdsk-Url-2 = {https://doi.org/10.1101/284497}}

@article{belin_voice-selective_2000,
	Abstract = {The human voice contains in its acoustic structure a wealth of information on the speaker's identity and emotional state which we perceive with remarkable ease and accuracy1,2,3. Although the perception of speaker-related features of voice plays a major role in human communication, little is known about its neural basis4,5,6,7. Here we show, using functional magnetic resonance imaging in human volunteers, that voice-selective regions can be found bilaterally along the upper bank of the superior temporal sulcus (STS). These regions showed greater neuronal activity when subjects listened passively to vocal sounds, whether speech or non-speech, than to non-vocal environmental sounds. Central STS regions also displayed a high degree of selectivity by responding significantly more to vocal sounds than to matched control stimuli, including scrambled voices and amplitude-modulated noise. Moreover, their response to stimuli degraded by frequency filtering paralleled the subjects' behavioural performance in voice-perception tasks that used these stimuli. The voice-selective areas in the STS may represent the counterpart of the face-selective areas in human visual cortex8,9; their existence sheds new light on the functional architecture of the human auditory cortex.},
	Author = {Belin, Pascal and Zatorre, Robert J. and Lafaille, Philippe and Ahad, Pierre and Pike, Bruce},
	Copyright = {2000 Nature Publishing Group},
	Doi = {10.1038/35002078},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/YJBYBB34/Belin et al. - 2000 - Voice-selective areas in human auditory cortex.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/FXWXUKTB/35002078.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = jan,
	Number = {6767},
	Pages = {309--312},
	Title = {Voice-selective areas in human auditory cortex},
	Url = {https://www.nature.com/articles/35002078},
	Urldate = {2018-03-30},
	Volume = {403},
	Year = {2000},
	Bdsk-Url-1 = {https://www.nature.com/articles/35002078},
	Bdsk-Url-2 = {https://doi.org/10.1038/35002078}}

@article{black_quantifying_nodate,
	Abstract = {Theories of language acquisition and perceptual learning increasingly rely on statistical learning mechanisms. The current meta-analysis aims to clarify the robustness of this capacity in infancy within the word segmentation literature. Our analysis reveals a significant, small effect size for conceptual replications of Saffran, Aslin, \& Newport (1996), and a nonsignificant effect across all studies that incorporate transitional probabilities to segment words. In both conceptual replications and the broader literature, however, statistical learning is moderated by whether stimuli are naturally produced or synthesized. These findings invite deeper questions about the complex factors that influence statistical learning, and the role of statistical learning in language acquisition.},
	Author = {Black, Alexis and Bergmann, Christina},
	File = {Black - Quantifying Infants' Statistical Word Segmentation.pdf:/Users/Cecile/Zotero/storage/8BGPXICN/Black - Quantifying Infants' Statistical Word Segmentation.pdf:application/pdf},
	Language = {en},
	Pages = {6},
	Title = {Quantifying {Infants}' {Statistical} {Word} {Segmentation}: {A} {Meta}-{Analysis}}}

@article{haller_parameterizing_2018,
	Abstract = {Electrophysiological signals across species and recording scales exhibit both periodic and aperiodic features. Periodic oscillations have been widely studied and linked to numerous physiological, cognitive, behavioral, and disease states, while the aperiodic "background" 1/f component of neural power spectra has received far less attention. Most analyses of oscillations are conducted on a priori, canonically-defined frequency bands without consideration of the underlying aperiodic structure, or verification that a periodic signal even exists in addition to the aperiodic signal. This is problematic, as recent evidence shows that the aperiodic signal is dynamic, changing with age, task demands, and cognitive state. It has also been linked to the relative excitation/inhibition of the underlying neuronal population. This means that standard analytic approaches easily conflate changes in the periodic and aperiodic signals with one another because the aperiodic parameters--along with oscillation center frequency, power, and bandwidth--are all dynamic in physiologically meaningful, but likely different, ways. In order to overcome the limitations of traditional narrowband analyses and to reduce the potentially deleterious effects of conflating these features, we introduce a novel algorithm for automatic parameterization of neural power spectral densities (PSDs) as a combination of the aperiodic signal and putative periodic oscillations. Notably, this algorithm requires no a priori specification of band limits and accounts for potentially-overlapping oscillations while minimizing the degree to which they are confounded with one another. This algorithm is amenable to large-scale data exploration and analysis, providing researchers with a tool to quickly and accurately parameterize neural power spectra.},
	Author = {Haller, Matar and Donoghue, Thomas and Peterson, Erik and Varma, Paroma and Sebastian, Priyadarshini and Gao, Richard and Noto, Torben and Knight, Robert T. and Shestyuk, Avgusta and Voytek, Bradley},
	Copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	Doi = {10.1101/299859},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Z9GT9VNX/Haller et al. - 2018 - Parameterizing neural power spectra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TSDZX8BP/299859.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = apr,
	Pages = {299859},
	Title = {Parameterizing neural power spectra},
	Url = {https://www.biorxiv.org/content/early/2018/04/11/299859},
	Urldate = {2018-04-12},
	Year = {2018},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2018/04/11/299859},
	Bdsk-Url-2 = {https://doi.org/10.1101/299859}}

@article{harris_organization_2018,
	Abstract = {The mammalian cortex is a laminar structure composed of many cell types densely interconnected in complex ways. Recent systematic efforts to map the mouse mesoscale connectome provide comprehensive projection data on inter-areal connections, but not at the level of specific cell classes or layers within cortical areas. We present here a significant expansion of the Allen Mouse Brain Connectivity Atlas, with {\textasciitilde}1000 new axonal projection mapping experiments across nearly all isocortical areas in 50 Cre driver lines. Using 13 lines most selective for cortical layer and/or projection neuron class we identify the differential contribution of each layer/class to the overall intracortical connectivity patterns. We find that layer 5 (L5) projection neurons account for essentially all intracortical outputs. L2/3, L4, and L6 neurons contact a subset of the L5 cortical targets. We describe the most common axon lamination patterns in target regions, and their relationships to source layer/class. Most patterns were consistent with previous anatomical rules used to determine hierarchical position between cortical areas (feedforward, feedback), with notable exceptions. We observe a diversity of target patterns arising from every source layer/class, but supragranular (L2/3 and upper L4) neurons are most associated with feedforward type patterns, whereas infragranular (L5 and L6) neurons have both feedforward and feedback. Network analyses revealed a modular organization of the intracortical connectome. Using the cell class-based target lamination patterns, we labeled all connections and intermodule connections as feed-forward or -back, and finally present an integrated view of the intracortical connectome as a hierarchical network.},
	Author = {Harris, Julie A. and Mihalas, Stefan and Hirokawa, Karla E. and Whitesell, Jennifer D. and Knox, Joseph and Bernard, Amy and Bohn, Philip and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Feng, David and Gaudreault, Nathalie and Graddis, Nile and Groblewski, Peter A. and Henry, Alex and Ho, Anh and Howard, Robert and Kuan, Leonard and Lecoq, Jerome and Luviano, Jennifer and McConoghy, Stephen and Mortrud, Marty and Naeemi, Maitham and Ng, Lydia and Oh, Seung W. and Ouellette, Benjamin and Sorensen, Staci and Wakeman, Wayne and Wang, Quanxin and Williford, Ali and Phillips, John and Koch, Christof and Zeng, Hongkui},
	Copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	Doi = {10.1101/292961},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8NM7GM82/Harris et al. - 2018 - The organization of intracortical connections by l.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HB5V84RB/292961.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = apr,
	Pages = {292961},
	Title = {The organization of intracortical connections by layer and cell class in the mouse brain},
	Url = {https://www.biorxiv.org/content/early/2018/04/01/292961},
	Urldate = {2018-04-03},
	Year = {2018},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2018/04/01/292961},
	Bdsk-Url-2 = {https://doi.org/10.1101/292961}}

@article{keitel_perceptually_2018,
	Abstract = {During online speech processing, our brain tracks the acoustic fluctuations in speech at different timescales. Previous research has focused on generic timescales (for example, delta or theta bands) that are assumed to map onto linguistic features such as prosody or syllables. However, given the high intersubject variability in speaking patterns, such a generic association between the timescales of brain activity and speech properties can be ambiguous. Here, we analyse speech tracking in source-localised magnetoencephalographic data by directly focusing on timescales extracted from statistical regularities in our speech material. This revealed widespread significant tracking at the timescales of phrases (0.6--1.3 Hz), words (1.8--3 Hz), syllables (2.8--4.8 Hz), and phonemes (8--12.4 Hz). Importantly, when examining its perceptual relevance, we found stronger tracking for correctly comprehended trials in the left premotor (PM) cortex at the phrasal scale as well as in left middle temporal cortex at the word scale. Control analyses using generic bands confirmed that these effects were specific to the speech regularities in our stimuli. Furthermore, we found that the phase at the phrasal timescale coupled to power at beta frequency (13--30 Hz) in motor areas. This cross-frequency coupling presumably reflects top-down temporal prediction in ongoing speech perception. Together, our results reveal specific functional and perceptually relevant roles of distinct tracking and cross-frequency processes along the auditory--motor pathway.},
	Author = {Keitel, Anne and Gross, Joachim and Kayser, Christoph},
	Doi = {10.1371/journal.pbio.2004473},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/GY7JVKUV/Keitel et al. - 2018 - Perceptually relevant speech tracking in auditory .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/F43YRDUX/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Syllables, Speech, Speech signal processing, Linguistics, Motor system, Phonemes, Syntax, magnetoencephalography},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {e2004473},
	Title = {Perceptually relevant speech tracking in auditory and motor cortex reflects distinct linguistic features},
	Url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2004473},
	Urldate = {2018-04-03},
	Volume = {16},
	Year = {2018},
	Bdsk-Url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2004473},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.2004473}}

@article{ghazanfar_evolution_2008,
	Author = {Ghazanfar, Asif A. and Rendall, Drew},
	Doi = {10.1016/j.cub.2008.03.030},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KNQG5XX4/Ghazanfar et Rendall - 2008 - Evolution of human vocal production.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K3GR7LLF/S0960-9822(08)00371-0.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Language = {English},
	Month = jun,
	Number = {11},
	Pages = {R457--R460},
	Pmid = {18522811},
	Title = {Evolution of human vocal production},
	Url = {http://www.cell.com/current-biology/abstract/S0960-9822(08)00371-0},
	Urldate = {2018-03-30},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {http://www.cell.com/current-biology/abstract/S0960-9822(08)00371-0},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2008.03.030}}

@article{kello_hierarchical_2017,
	Abstract = {Humans talk, sing and play music. Some species of birds and whales sing long and complex songs. All these behaviours and sounds exhibit hierarchical structure---syllables and notes are positioned within words and musical phrases, words and motives in sentences and musical phrases, and so on. We developed a new method to measure and compare hierarchical temporal structures in speech, song and music. The method identifies temporal events as peaks in the sound amplitude envelope, and quantifies event clustering across a range of timescales using Allan factor (AF) variance. AF variances were analysed and compared for over 200 different recordings from more than 16 different categories of signals, including recordings of speech in different contexts and languages, musical compositions and performances from different genres. Non-human vocalizations from two bird species and two types of marine mammals were also analysed for comparison. The resulting patterns of AF variance across timescales were distinct to each of four natural categories of complex sound: speech, popular music, classical music and complex animal vocalizations. Comparisons within and across categories indicated that nested clustering in longer timescales was more prominent when prosodic variation was greater, and when sounds came from interactions among individuals, including interactions between speakers, musicians, and even killer whales. Nested clustering also was more prominent for music compared with speech, and reflected beat structure for popular music and self-similarity across timescales for classical music. In summary, hierarchical temporal structures reflect the behavioural and social processes underlying complex vocalizations and musical performances.},
	Author = {Kello, Christopher T. and Bella, Simone Dalla and M{\'e}d{\'e}, Butovens and Balasubramaniam, Ramesh},
	Copyright = {{\copyright} 2017 The Author(s). http://royalsocietypublishing.org/licencePublished by the Royal Society. All rights reserved.},
	Doi = {10.1098/rsif.2017.0231},
	File = {Kello et al. - 2017 - Hierarchical temporal structure in music, speech a.pdf:/Users/Cecile/Zotero/storage/U8ZLEEX8/Kello et al. - 2017 - Hierarchical temporal structure in music, speech a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3EF9K9DQ/20170231.html:text/html},
	Issn = {1742-5689, 1742-5662},
	Journal = {Journal of The Royal Society Interface},
	Language = {en},
	Month = oct,
	Number = {135},
	Pages = {20170231},
	Pmid = {29021158},
	Shorttitle = {Hierarchical temporal structure in music, speech and animal vocalizations},
	Title = {Hierarchical temporal structure in music, speech and animal vocalizations: jazz is like a conversation, humpbacks sing like hermit thrushes},
	Url = {http://rsif.royalsocietypublishing.org/content/14/135/20170231},
	Urldate = {2018-04-03},
	Volume = {14},
	Year = {2017},
	Bdsk-Url-1 = {http://rsif.royalsocietypublishing.org/content/14/135/20170231},
	Bdsk-Url-2 = {https://doi.org/10.1098/rsif.2017.0231}}

@book{mehler_neonate_1985,
	Author = {Mehler, Jacques A. and Fox, Robin},
	Isbn = {978-0-89859-345-7},
	Keywords = {Psychology / General},
	Language = {en},
	Publisher = {L. Erlbaum Associates},
	Shorttitle = {Neonate {Cognition}},
	Title = {Neonate {Cognition}: {Beyond} the {Blooming} {Buzzing} {Confusion}},
	Year = {1985}}

@article{dehaene-lambertz_electrophysiological_2001,
	Abstract = {At least two fundamental properties should be present in a network computing a phonetic representation: categorical perception and normalization across different utterances. Normalization processes were studied at birth by recording high density evoked potentials to strings of syllables in sleeping neonates. We compared the response to a change of phoneme when irrelevant speaker variation was present or absent. A mismatch response was recorded at the same latency in both cases, suggesting that relevant phonetic information was extracted from the irrelevant variation. Combined with our previous work showing that the mismatch response is sensitive to categorical perception in infants, this result suggests that a phonetic network like that of adults, is already present in the infant brain. Furthermore, efficient phonetic processing does not require attention.},
	Author = {Dehaene-Lambertz, G. and Pena, M.},
	File = {Dehaene-Lambertz et Pena - 2001 - Electrophysiological evidence for automatic phonet.pdf:/Users/Cecile/Zotero/storage/XMI8JNLP/Dehaene-Lambertz et Pena - 2001 - Electrophysiological evidence for automatic phonet.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/R74MVQJM/articleviewer.html:text/html},
	Issn = {0959-4965},
	Journal = {NeuroReport},
	Language = {en-US},
	Month = oct,
	Number = {14},
	Pages = {3155},
	Title = {Electrophysiological evidence for automatic phonetic processing in neonates},
	Url = {https://journals.lww.com/neuroreport/pages/articleviewer.aspx?year=2001&issue=10080&article=00034&type=abstract},
	Urldate = {2018-04-23},
	Volume = {12},
	Year = {2001},
	Bdsk-Url-1 = {https://journals.lww.com/neuroreport/pages/articleviewer.aspx?year=2001&issue=10080&article=00034&type=abstract}}

@article{ecklund-flores_asymmetric_1996,
	Abstract = {Functional asymmetries were examined in 59 newborns by recording headturns from midline to bin-aurally equivalent sounds. Results showed that robust, asymmetric pattern of headturning occurred in most newborns' responses to binaurally presented unfiltered female speech sounds, with increased rightward orientation demonstrated in five replications. Female speech that was modified by attenuation of frequencies above 500 Hz, as well as speech attenuated below 1500 Hz and above 3000 Hz, resulted in a significant rightward bias in headturning. In contrast, female speech attenuated below 3500 Hz, and continuous, repetitive stimuli such as heartbeat sounds and phrases of speech repeated at the rate of heartbeat (termed heartspeech), failed to generate the rightward orientation bias. These results suggest that female speech sounds, particularly low-frequency sounds related to the naturally occurring prosodic characteristics of speech, are a salient class of stimuli for the organization of lateral biases in orienting in newborns. {\copyright} 1996 John Wiley \& Sons, Inc.},
	Annote = {meta-analysis},
	Author = {Ecklund-Flores, Lisa and Turkewitz, Gerald},
	Copyright = {Copyright {\copyright} 1996 John Wiley \& Sons, Inc.},
	Date-Modified = {2020-06-16 13:49:22 +0200},
	Doi = {10.1002/(SICI)1098-2302(199604)29:3<205::AID-DEV2>3.0.CO;2-V},
	File = {Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:/Users/Cecile/Zotero/storage/ME9WP2MY/Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:application/pdf;Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:/Users/Cecile/Zotero/storage/KS3CEAUV/Ecklund-Flores et Turkewitz - 1996 - Asymmetric headturning to speech and nonspeech in .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UPCVM56Y/(SICI)1098-2302(199604)293205AID-DEV23.0.html:text/html},
	Issn = {1098-2302},
	Journal = {Developmental Psychobiology},
	Language = {en},
	Month = apr,
	Number = {3},
	Pages = {205--217},
	Title = {Asymmetric headturning to speech and nonspeech in human newborns},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2302%28199604%2929%3A3%3C205%3A%3AAID-DEV2%3E3.0.CO%3B2-V},
	Urldate = {2018-04-24},
	Volume = {29},
	Year = {1996},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291098-2302%28199604%2929%3A3%3C205%3A%3AAID-DEV2%3E3.0.CO%3B2-V},
	Bdsk-Url-2 = {https://doi.org/10.1002/(SICI)1098-2302(199604)29:3%3C205::AID-DEV2%3E3.0.CO;2-V}}

@article{liberman_perception_1967,
	Author = {Liberman, A. M. and Cooper, F. S. and Shankweiler, D. P. and Studdert-Kennedy, M.},
	Doi = {10.1037/h0020279},
	File = {Liberman et al. - 1967 - Perception of the speech code..pdf:/Users/Cecile/Zotero/storage/UYB9ULJZ/Liberman et al. - 1967 - Perception of the speech code..pdf:application/pdf},
	Issn = {1939-1471, 0033-295X},
	Journal = {Psychological Review},
	Language = {en},
	Number = {6},
	Pages = {431--461},
	Title = {Perception of the speech code.},
	Url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0020279},
	Urldate = {2018-04-21},
	Volume = {74},
	Year = {1967},
	Bdsk-Url-1 = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0020279},
	Bdsk-Url-2 = {https://doi.org/10.1037/h0020279}}

@incollection{silva_eeg:_2009,
	Abstract = {The existence of the electrical activity of the brain (i.e. the electroencephalogram or EEG) was discovered more than a century ago by Caton. After the demonstration that the EEG could be recorded from the human scalp by Berger in the 1920s, it made a slow start before it became accepted as a method of analysis of brain functions in health and disease. It is interesting to note that this acceptance came only after the demonstration by Adrian and Mathews (1934) that the EEG, namely the alpha rhythm, was likely generated in the occipital lobes in man, and was not artefactual. However, the neuronal sources of the alpha rhythm remained undefined until the 1970s, when we demonstrated, in dog, that the alpha rhythm is generated by a dipole layer cantered at layers IV and V of the visual cortex (Lopes da Silva and Storm van Leeuwen 1977). It may be not surprising that the mechanisms of generation and the functional significance of the EEG remained controversial for a relatively long time considering the complexity of the underlying systems of neuronal generators on the one hand and the rather involved transfer of signals from the cortical surface to the scalp due to the topological and electrical properties of the volume conductor (brain, cerebrospinal fluid, skull, scalp) on the other. The EEG consists of the summed electrical activities of populations of neurons, with a modest contribution from glial cells. The neurons are excitable cells with characteristic intrinsic electrical properties, and their activity produces electrical and magnetic fields. These fields may be recorded by means of electrodes at a short distance from the sources (the local EEG or local field potentials, LFPs), or from the cortical surface (the electrocorticogram or ECoG), or at longer distances, even from the scalp (i.e. the EEG, in the most common sense). The associated MEG is usually recorded via sensors that are highly sensitive to changes in the very weak neuronal magnetic fields, which are placed at short distances around the scalp.},
	Author = {Silva, Fernando Lopes da},
	Booktitle = {{EEG} - {fMRI}},
	Doi = {10.1007/978-3-540-87919-0_2},
	File = {Snapshot:/Users/Cecile/Zotero/storage/I4QFN232/10.html:text/html},
	Isbn = {978-3-540-87918-3 978-3-540-87919-0},
	Language = {en},
	Pages = {19--38},
	Publisher = {Springer, Berlin, Heidelberg},
	Shorttitle = {{EEG}},
	Title = {{EEG}: {Origin} and {Measurement}},
	Url = {https://link.springer.com/chapter/10.1007/978-3-540-87919-0_2},
	Urldate = {2018-05-06},
	Year = {2009},
	Bdsk-Url-1 = {https://link.springer.com/chapter/10.1007/978-3-540-87919-0_2},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-3-540-87919-0_2}}

@incollection{johnson_speaker_2008,
	Abstract = {This chapter contains sections titled: Perceiving Vowels in Isolated Syllables Formant Ratio Theories From Auditory Gestalts to Vocal Tract Actions Vocal Tract Normalization Talkers or Vocal Tractsquest; Talker Normalization},
	Author = {Johnson, Keith},
	Booktitle = {The {Handbook} of {Speech} {Perception}},
	Copyright = {Copyright {\copyright} 2005 Blackwell Publishing Ltd},
	Doi = {10.1002/9780470757024.ch15},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4I8EEAU7/Johnson - 2008 - Speaker Normalization in Speech Perception.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JPT7AV44/9780470757024.html:text/html},
	Isbn = {978-0-470-75702-4},
	Keywords = {speech perception, isolated syllables, phonological identity, speaker normalization, vowel perception},
	Language = {en},
	Pages = {363--389},
	Publisher = {Wiley-Blackwell},
	Title = {Speaker {Normalization} in {Speech} {Perception}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470757024.ch15},
	Urldate = {2018-05-12},
	Year = {2008},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470757024.ch15},
	Bdsk-Url-2 = {https://doi.org/10.1002/9780470757024.ch15}}

@article{leong_acoustic-emergent_2015,
	Abstract = {When acquiring language, young children may use acoustic spectro-temporal patterns in speech to derive phonological units in spoken language (e.g., prosodic stress patterns, syllables, phonemes). Children appear to learn acoustic-phonological mappings rapidly, without direct instruction, yet the underlying developmental mechanisms remain unclear. Across different languages, a relationship between amplitude envelope sensitivity and phonological development has been found, suggesting that children may make use of amplitude modulation (AM) patterns within the envelope to develop a phonological system. Here we present the Spectral Amplitude Modulation Phase Hierarchy (S-AMPH) model, a set of algorithms for deriving the dominant AM patterns in child-directed speech (CDS). Using Principal Components Analysis, we show that rhythmic CDS contains an AM hierarchy comprising 3 core modulation timescales. These timescales correspond to key phonological units: prosodic stress (Stress AM, {\textasciitilde}2 Hz), syllables (Syllable AM, {\textasciitilde}5 Hz) and onset-rime units (Phoneme AM, {\textasciitilde}20 Hz). We argue that these AM patterns could in principle be used by na{\"\i}ve listeners to compute acoustic-phonological mappings without lexical knowledge. We then demonstrate that the modulation statistics within this AM hierarchy indeed parse the speech signal into a primitive hierarchically-organised phonological system comprising stress feet (proto-words), syllables and onset-rime units. We apply the S-AMPH model to two other CDS corpora, one spontaneous and one deliberately-timed. The model accurately identified 72--82\% (freely-read CDS) and 90--98\% (rhythmically-regular CDS) stress patterns, syllables and onset-rime units. This in-principle demonstration that primitive phonology can be extracted from speech AMs is termed Acoustic-Emergent Phonology (AEP) theory. AEP theory provides a set of methods for examining how early phonological development is shaped by the temporal modulation structure of speech across languages. The S-AMPH model reveals a crucial developmental role for stress feet (AMs {\textasciitilde}2 Hz). Stress feet underpin different linguistic rhythm typologies, and speech rhythm underpins language acquisition by infants in all languages.},
	Author = {Leong, Victoria and Goswami, Usha},
	Doi = {10.1371/journal.pone.0144411},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6Y236JXW/Leong et Goswami - 2015 - Acoustic-Emergent Phonology in the Amplitude Envel.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P7GTPNPX/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Acoustics, Phonology, Syllables, Speech, Speech signal processing, Linguistics, Principal component analysis, Vowels},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e0144411},
	Title = {Acoustic-{Emergent} {Phonology} in the {Amplitude} {Envelope} of {Child}-{Directed} {Speech}},
	Url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144411},
	Urldate = {2018-06-05},
	Volume = {10},
	Year = {2015},
	Bdsk-Url-1 = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144411},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0144411}}

@article{fujimura_analysis_1962,
	Author = {Fujimura, Osamu},
	Doi = {10.1121/1.1909142},
	File = {Fujimura - 1962 - Analysis of Nasal Consonants.pdf:/Users/Cecile/Zotero/storage/U2P6VLP8/Fujimura - 1962 - Analysis of Nasal Consonants.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BXZPE6G4/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = dec,
	Number = {12},
	Pages = {1865--1875},
	Title = {Analysis of {Nasal} {Consonants}},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.1909142},
	Urldate = {2018-06-15},
	Volume = {34},
	Year = {1962},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1909142},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1909142}}

@article{houtgast_review_1985,
	Author = {Houtgast, T. and Steeneken, H. J. M.},
	Doi = {10.1121/1.392224},
	File = {Houtgast et Steeneken - 1985 - A review of the MTF concept in room acoustics and .pdf:/Users/Cecile/Zotero/storage/WTVM4QQ3/Houtgast et Steeneken - 1985 - A review of the MTF concept in room acoustics and .pdf:application/pdf},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {1069--1077},
	Title = {A review of the {MTF} concept in room acoustics and its use for estimating speech intelligibility in auditoria},
	Url = {http://asa.scitation.org/doi/10.1121/1.392224},
	Urldate = {2018-06-05},
	Volume = {77},
	Year = {1985},
	Bdsk-Url-1 = {http://asa.scitation.org/doi/10.1121/1.392224},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.392224}}

@inproceedings{guiraud_perception_2018,
	Abstract = {According to the "prosodic phrasing" hypothesis (Cumming et al., 2015), children with Developmental Language Disorder (DLD) show difficulty extracting low-frequency rhythmic information from the speech signal, hindering syllabic segmentation and leading to phonological and morpho-syntactic impairments. We tested this hypothesis by measuring, using magnetoencephalography, the synchronization between cortical oscillations and speech amplitude envelope in children with DLD paired to typically-developing children when listening to sentences naturally produced at a normal or rapid rate. Our results in the theta frequency band (4-7 Hz) show reduced brain-to-speech coupling in children with DLD, as compared with typically-developing children, 1) in the right auditory cortex at normal rate and 2) left (pre)motor regions at fast rate. To our knowledge, this study brings the first piece of evidence for atypical cortical alignment to speech syllabic rhythm in children with DLD.},
	Address = {Aix-en-Provence, France},
	Author = {Guiraud, H{\'e}l{\`e}ne and Hincapi{\'e}, Ana-Sofia and Jerbi, Karim and Boulenger, V{\'e}ronique},
	Booktitle = {Proc. {XXXIIe} {Journ{\'e}es} d'{\'E}tudes sur la {Parole}},
	Doi = {10.21437/JEP.2018-26},
	File = {H{\'e}l{\`e}ne et al. - 2018 - Perception de la parole et oscillations c{\'e}r{\'e}brales.pdf:/Users/Cecile/Zotero/storage/HJHYQMBR/H{\'e}l{\`e}ne et al. - 2018 - Perception de la parole et oscillations c{\'e}r{\'e}brales.pdf:application/pdf},
	Language = {fr},
	Month = jun,
	Pages = {222--230},
	Publisher = {ISCA},
	Title = {Perception de la parole et oscillations c{\'e}r{\'e}brales chez les enfants neurotypiques et dysphasiques.},
	Url = {http://www.isca-speech.org/archive/JEP_2018/abstracts/189775.html},
	Urldate = {2018-06-14},
	Year = {2018},
	Bdsk-Url-1 = {http://www.isca-speech.org/archive/JEP_2018/abstracts/189775.html},
	Bdsk-Url-2 = {https://doi.org/10.21437/JEP.2018-26}}

@article{dudley_carrier_1940,
	Abstract = {Speech synthesizing is here discussed in the terminology of carrier circuits. The speaker is pictured as a sort of radio broadcast transmitter with the message to be sent out originating in the studio of the talker's brain and manifesting itself in muscular wave motions in the vocal tract. Although these motions contain the message, they are inaudible because they occur at syllabic rates. An audible sound is needed to pass the message into the listener's ear. This is provided by the carrier in the form of a group of higher frequency waves in the audible range set up by oscillatory action at the vocal cords or elsewhere in the vocal tract. These carrier waves either in their generation or their transmission are modulated by the message waves to form the speech waves. As the speech waves contain the message information on an audible carrier they are adapted to broadcast reception by receiving sets in the form of listeners' ears. The message is then recovered by the listeners' minds.},
	Author = {Dudley, Homer},
	Copyright = {{\copyright} 1940 The Bell System Technical Journal},
	Doi = {10.1002/j.1538-7305.1940.tb00843.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UX5VHRT6/Dudley - The Carrier Nature of Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J8BTZCAA/j.1538-7305.1940.tb00843.html:text/html},
	Issn = {1538-7305},
	Journal = {Bell System Technical Journal},
	Language = {en},
	Number = {4},
	Pages = {495--515},
	Title = {The {Carrier} {Nature} of {Speech}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1940.tb00843.x},
	Urldate = {2018-06-05},
	Volume = {19},
	Year = {1940},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1940.tb00843.x},
	Bdsk-Url-2 = {https://doi.org/10.1002/j.1538-7305.1940.tb00843.x}}

@article{von_kriegstein_how_2010,
	Abstract = {We understand speech from different speakers with ease, whereas artificial speech recognition systems struggle with this task. It is unclear how the human brain solves this problem. The conventional view is that speech message recognition and speaker identification are two separate functions and that message processing takes place predominantly in the left hemisphere, whereas processing of speaker-specific information is located in the right hemisphere. Here, we distinguish the contribution of specific cortical regions, to speech recognition and speaker information processing, by controlled manipulation of task and resynthesized speaker parameters. Two functional magnetic resonance imaging studies provide evidence for a dynamic speech-processing network that questions the conventional view. We found that speech recognition regions in left posterior superior temporal gyrus/superior temporal sulcus (STG/STS) also encode speaker-related vocal tract parameters, which are reflected in the amplitude peaks of the speech spectrum, along with the speech message. Right posterior STG/STS activated specifically more to a speaker-related vocal tract parameter change during a speech recognition task compared with a voice recognition task. Left and right posterior STG/STS were functionally connected. Additionally, we found that speaker-related glottal fold parameters (e.g., pitch), which are not reflected in the amplitude peaks of the speech spectrum, are processed in areas immediately adjacent to primary auditory cortex, i.e., in areas in the auditory hierarchy earlier than STG/STS. Our results point to a network account of speech recognition, in which information about the speech message and the speaker's vocal tract are combined to solve the difficult task of understanding speech from different speakers.},
	Author = {von Kriegstein, Katharina and Smith, David R. R. and Patterson, Roy D. and Kiebel, Stefan J. and Griffiths, Timothy D.},
	Copyright = {Copyright {\copyright} 2010 the authors 0270-6474/10/300629-10\$15.00/0},
	Doi = {10.1523/JNEUROSCI.2742-09.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2GHMGG9Y/Kriegstein et al. - 2010 - How the Human Brain Recognizes Speech in the Conte.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ESNZIBX7/629.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = jan,
	Number = {2},
	Pages = {629--638},
	Pmid = {20071527},
	Title = {How the {Human} {Brain} {Recognizes} {Speech} in the {Context} of {Changing} {Speakers}},
	Url = {http://www.jneurosci.org/content/30/2/629},
	Urldate = {2018-05-12},
	Volume = {30},
	Year = {2010},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/30/2/629},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2742-09.2010}}

@article{rendall_pitch_2005,
	Abstract = {Key voice features--fundamental frequency (F0) and formant frequencies--can vary extensively between individuals. Much of the variation can be traced to differences in the size of the larynx and vocal-tract cavities, but whether these differences in turn simply reflect differences in speaker body size (i.e., neutral vocal allometry) remains unclear. Quantitative analyses were therefore undertaken to test the relationship between speaker body size and voice F0 and formant frequencies for human vowels. To test the taxonomic generality of the relationships, the same analyses were conducted on the vowel-like grunts of baboons, whose phylogenetic proximity to humans and similar vocal production biology and voice acoustic patterns recommend them for such comparative research. For adults of both species, males were larger than females and had lower mean voice F0 and formant frequencies. However, beyond this, F0 variation did not track body-size variation between the sexes in either species, nor within sexes in humans. In humans, formant variation correlated significantly with speaker height but only in males and not in females. Implications for general vocal allometry are discussed as are implications for speech origins theories, and challenges to them, related to laryngeal position and vocal tract length.},
	Author = {Rendall, Drew and Kollias, Sophie and Ney, Christina and Lloyd, Peter},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Keywords = {Adolescent, Adult, Animals, Female, Humans, Male, Phonetics, Sound Spectrography, Species Specificity, Speech Acoustics, Vocalization, Animal, Biometry, Body Size, Papio, Phonation, Voice Quality},
	Language = {eng},
	Month = feb,
	Number = {2},
	Pages = {944--955},
	Pmid = {15759713},
	Shorttitle = {Pitch ({F0}) and formant profiles of human vowels and vowel-like baboon grunts},
	Title = {Pitch ({F0}) and formant profiles of human vowels and vowel-like baboon grunts: the role of vocalizer body size and voice-acoustic allometry},
	Volume = {117},
	Year = {2005}}

@article{chandrasekaran_natural_2009,
	Abstract = {Humans, like other animals, are exposed to a continuous stream of signals, which are dynamic, multimodal, extended, and time varying in nature. This complex input space must be transduced and sampled by our sensory systems and transmitted to the brain where it can guide the selection of appropriate actions. To simplify this process, it's been suggested that the brain exploits statistical regularities in the stimulus space. Tests of this idea have largely been confined to unimodal signals and natural scenes. One important class of multisensory signals for which a quantitative input space characterization is unavailable is human speech. We do not understand what signals our brain has to actively piece together from an audiovisual speech stream to arrive at a percept versus what is already embedded in the signal structure of the stream itself. In essence, we do not have a clear understanding of the natural statistics of audiovisual speech. In the present study, we identified the following major statistical features of audiovisual speech. First, we observed robust correlations and close temporal correspondence between the area of the mouth opening and the acoustic envelope. Second, we found the strongest correlation between the area of the mouth opening and vocal tract resonances. Third, we observed that both area of the mouth opening and the voice envelope are temporally modulated in the 2--7 Hz frequency range. Finally, we show that the timing of mouth movements relative to the onset of the voice is consistently between 100 and 300 ms. We interpret these data in the context of recent neural theories of speech which suggest that speech communication is a reciprocally coupled, multisensory event, whereby the outputs of the signaler are matched to the neural processes of the receiver.},
	Author = {Chandrasekaran, Chandramouli and Trubanova, Andrea and Stillittano, S{\'e}bastien and Caplier, Alice and Ghazanfar, Asif A.},
	Doi = {10.1371/journal.pcbi.1000436},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BJ6TKW33/Chandrasekaran et al. - 2009 - The Natural Statistics of Audiovisual Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5VUYW84J/article.html:text/html},
	Issn = {1553-7358},
	Journal = {PLOS Computational Biology},
	Keywords = {Speech, Vision, Audio signal processing, Speech signal processing, Acoustic signals, Lips, Mouth, Visual signals},
	Language = {en},
	Month = jul,
	Number = {7},
	Pages = {e1000436},
	Title = {The {Natural} {Statistics} of {Audiovisual} {Speech}},
	Url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000436},
	Urldate = {2018-05-10},
	Volume = {5},
	Year = {2009},
	Bdsk-Url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000436},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pcbi.1000436}}

@article{lee_speaker_2009,
	Author = {Lee, Tchao-Yang and Tao, Liang and Bond, Z. S.},
	Doi = {10.1016/j.wocn.2008.08.001},
	Journal = {Journal of Phonetics},
	Month = jan,
	Number = {1},
	Title = {Speaker variability and context in the identification of fragmented {Mandarin} tones by native and non-native listeners},
	Url = {https://www.sciencedirect.com/science/article/pii/S0095447008000405},
	Volume = {37},
	Year = {2009},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0095447008000405},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.wocn.2008.08.001}}

@article{varnet_cross-linguistic_2017,
	Author = {Varnet, L{\'e}o and Ortiz-Barajas, Maria Clemencia and Erra, Ram{\'o}n Guevara and Gervain, Judit and Lorenzi, Christian},
	Doi = {10.1121/1.5006179},
	File = {Snapshot:/Users/Cecile/Zotero/storage/QG9M7HUR/1.html:text/html;Varnet et al. - 2017 - A cross-linguistic study of speech modulation spec.pdf:/Users/Cecile/Zotero/storage/I3ZV6LYS/Varnet et al. - 2017 - A cross-linguistic study of speech modulation spec.pdf:application/pdf},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = oct,
	Number = {4},
	Pages = {1976--1989},
	Title = {A cross-linguistic study of speech modulation spectra},
	Url = {https://asa.scitation.org/doi/10.1121/1.5006179},
	Urldate = {2018-05-08},
	Volume = {142},
	Year = {2017},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.5006179},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.5006179}}

@article{xie_development_2018,
	Abstract = {The current study examined the relation between infant sustained attention and infant EEG oscillations. Fifty-nine infants were tested at 6 (N = 15), 8 (N = 17), 10 (N = 14), and 12 (N = 13) months. Three attention phases, stimulus orienting, sustained attention, and attention termination, were defined based on infants' heart rate changes. Frequency analysis using simultaneously recorded EEG focused on infant theta (2-6 Hz), alpha (6-9 Hz), and beta (9-14 Hz) rhythms. Cortical source analysis of EEG oscillations was conducted with realistic infant MRI models. Theta synchronization was found over fontal pole, temporal, and parietal electrodes during infant sustained attention for 10 and 12 months. Alpha desynchronization was found over frontal, central and parietal electrodes during sustained attention. This alpha effect started to emerge at 10 months and became well established by 12 months. No difference was found for the beta rhythm between different attention phases. The theta synchronization effect was localized to the orbital frontal, temporal pole, and ventral temporal areas. The alpha desynchronization effect was localized to the brain regions composing the default mode network including the posterior cingulate cortex and precuneus, medial prefrontal cortex, and inferior parietal gyrus. The alpha desynchronization effect was also localized to the pre- and post-central gyri. The present study demonstrates a connection between infant sustained attention and EEG oscillatory activities.},
	Author = {Xie, Wanze and Mallin, Brittany M. and Richards, John E.},
	Doi = {10.1111/desc.12562},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {eng},
	Month = may,
	Number = {3},
	Pages = {e12562},
	Pmcid = {PMC5628078},
	Pmid = {28382759},
	Shorttitle = {Development of infant sustained attention and its relation to {EEG} oscillations},
	Title = {Development of infant sustained attention and its relation to {EEG} oscillations: an {EEG} and cortical source analysis study},
	Volume = {21},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1111/desc.12562}}

@article{kreitewolf_neural_2014,
	Abstract = {Understanding speech from different speakers is a sophisticated process, particularly because the same acoustic parameters convey important information about both the speech message and the person speaking. How the human brain accomplishes speech recognition under such conditions is unknown.
One view is that speaker information is discarded at early processing stages and not used for understanding the speech message. An alternative view is that speaker information is exploited to improve speech recognition. Consistent with the latter view, previous research identified functional interactions between the left- and the right-hemispheric superior temporal sulcus/gyrus, which process speech- and speaker-specific vocal tract parameters, respectively. Vocal tract parameters are one of the two major acoustic features that determine both speaker identity and speech message (phonemes). Here, using functional magnetic resonance imaging (fMRI), we show that a similar interaction exists for glottal fold parameters between the left and right Heschl's gyri. Glottal fold parameters are the other main acoustic feature that determines speaker identity and speech message (linguistic prosody).
The findings suggest that interactions between left- and right-hemispheric areas are specific to the processing of different acoustic features of speech and speaker, and that they represent a general neural mechanism when understanding speech from different speakers.},
	Author = {Kreitewolf, Jens and Gaudrain, Etienne and von Kriegstein, Katharina},
	Doi = {10.1016/j.neuroimage.2014.01.005},
	Journal = {NeuroImage},
	Language = {English},
	Month = may,
	Pages = {375--385},
	Title = {A neural mechanism for recognizing speech spoken by different speakers},
	Url = {https://www.sciencedirect.com/science/article/pii/S1053811914000160?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_recommender_email},
	Volume = {91},
	Year = {2014},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811914000160?_rdoc=1&_fmt=high&_origin=gateway&_docanchor=&md5=b8429449ccfc9c30159a5f9aeaa92ffb&dgcid=raven_sd_recommender_email},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.01.005}}

@article{vaissiere_language-independent_1983-1,
	Abstract = {The purpose of this paper is to investigate the similarities in form and function of prosody among diverse languages: - the pause - Fo declinaison tendency and its control - natural Fo range and its control - Resetting of the baseline - the alternance between Fo rise and fall - Fo continuation rise and final fall - intensity fall - final lengthening the differences between the languages seem to be due to - a different timing of the same gestures - a different order of priorities - a different relationship betwen Fo, duration and intensity},
	Author = {Vaissi{\`e}re, Jacqueline},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/C96H2ZMP/Vaissi{\`e}re - 1983 - Language-independent prosodic features.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YBXHYQNK/halshs-00703571.html:text/html},
	Language = {en},
	Pages = {53--65},
	Title = {Language-independent prosodic features},
	Url = {https://halshs.archives-ouvertes.fr/halshs-00703571/document},
	Urldate = {2018-06-07},
	Year = {1983},
	Bdsk-Url-1 = {https://halshs.archives-ouvertes.fr/halshs-00703571/document}}

@article{nourski_temporal_2009,
	Abstract = {Speech comprehension relies on temporal cues contained in the speech envelope, and the auditory cortex has been implicated as playing a critical role in encoding this temporal information. We investigated auditory cortical responses to speech stimuli in subjects undergoing invasive electrophysiological monitoring for pharmacologically refractory epilepsy. Recordings were made from multi-contact electrodes implanted in Heschl's gyrus (HG). Speech sentences, time-compressed from 0.75 to 0.20 of natural speaking rate, elicited average evoked potentials (AEPs) and increases in event-related band power (ERBP) of cortical high frequency (70--250 Hz) activity. Cortex of posteromedial HG, the presumed core of human auditory cortex, represented the envelope of speech stimuli in the AEP and ERBP. Envelope-following in ERBP, but not in AEP, was evident in both language dominant and non-dominant hemispheres for relatively high degrees of compression where speech was not comprehensible. Compared to posteromedial HG, responses from anterolateral HG --- an auditory belt field --- exhibited longer latencies, lower amplitudes and little or no time locking to the speech envelope. The ability of the core auditory cortex to follow the temporal speech envelope over a wide range of speaking rates leads us to conclude that such capacity in itself is not a limiting factor for speech comprehension.},
	Author = {Nourski, Kirill V. and Reale, Richard A. and Oya, Hiroyuki and Kawasaki, Hiroto and Kovach, Christopher K. and Chen, Haiming and Howard, Matthew A. and Brugge, John F.},
	Doi = {10.1523/JNEUROSCI.3065-09.2009},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/P2858G3T/Nourski et al. - 2009 - Temporal envelope of time-compressed speech repres.pdf:application/pdf},
	Issn = {0270-6474},
	Journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	Month = dec,
	Number = {49},
	Pages = {15564--15574},
	Pmcid = {PMC2851231},
	Pmid = {20007480},
	Title = {Temporal envelope of time-compressed speech represented in the human auditory cortex},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2851231/},
	Urldate = {2018-06-14},
	Volume = {29},
	Year = {2009},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2851231/},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.3065-09.2009}}

@article{moore_role_2008,
	Abstract = {Complex broadband sounds are decomposed by the auditory filters into a series of relatively narrowband signals, each of which can be considered as a slowly varying envelope (E) superimposed on a more rapid temporal fine structure (TFS). Both E and TFS information are represented in the timing of neural discharges, although TFS information as defined here depends on phase locking to individual cycles of the stimulus waveform. This paper reviews the role played by TFS in masking, pitch perception, and speech perception and concludes that cues derived from TFS play an important role for all three. TFS may be especially important for the ability to ``listen in the dips'' of fluctuating background sounds when detecting nonspeech and speech signals. Evidence is reviewed suggesting that cochlear hearing loss reduces the ability to use TFS cues. The perceptual consequences of this, and reasons why it may happen, are discussed.},
	Author = {Moore, Brian C. J.},
	Doi = {10.1007/s10162-008-0143-x},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/C6DW8V85/Moore - 2008 - The Role of Temporal Fine Structure Processing in .pdf:application/pdf},
	Issn = {1525-3961},
	Journal = {JARO: Journal of the Association for Research in Otolaryngology},
	Month = dec,
	Number = {4},
	Pages = {399--406},
	Pmcid = {PMC2580810},
	Pmid = {18855069},
	Title = {The {Role} of {Temporal} {Fine} {Structure} {Processing} in {Pitch} {Perception}, {Masking}, and {Speech} {Perception} for {Normal}-{Hearing} and {Hearing}-{Impaired} {People}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2580810/},
	Urldate = {2018-05-10},
	Volume = {9},
	Year = {2008},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2580810/},
	Bdsk-Url-2 = {https://doi.org/10.1007/s10162-008-0143-x}}

@article{maki_spatial_1995,
	Abstract = {The effect of motor activity on the left fronto?central region of the human brain was analyzed spatially and temporally by using noninvasive near?infrared light (NIR) topography. The changes in oxygenation states caused by motor activity were measured using intensity?modulated NIR spectroscopy at ten measurement positions on the head surface. The subject randomly performed unilateral finger opposition for 30 s as motor stimulation. When the subject performed contralateral (right) finger movement, significant increases in both oxygenated hemoglobin (oxy?Hb) and total hemoglobin (total?Hb) and decreases in deoxygenated hemoglobin (deoxy?Hb) were observed in a particular area. By mapping the static topograms of the changes of each Hb and comparing them with an anatomical image of MRI, it was found that the particular area was located on the motor cortex along the central sulcus. By mapping the dynamic topograms of the changes of total?Hb, which reflect the cerebral blood volume, and analyzing the spatiotemporal hemodynamic changes associated with the brain activity, it was found that the regional change in cerebral blood volume in the primary motor area overlaps the global change around the motor cortex. These results demonstrate that NIR topography can be used to effectively observe the human brain activity.},
	Author = {Maki, Atsushi and Yamashita, Yuichi and Ito, Yoshitoshi and Watanabe, Eiju and Mayanagi, Yoshiaki and Koizumi, Hideaki},
	Doi = {10.1118/1.597496},
	File = {Makietal95.pdf:/Users/Cecile/Zotero/storage/KDH8RRTQ/Makietal95.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S667WT8Y/1.html:text/html},
	Issn = {0094-2405},
	Journal = {Medical Physics},
	Keywords = {Hemodynamics, 87.56.09, 87.59.05, Brain, CENTRAL NERVOUS SYSTEM, Global change, HEMOGLOBIN, HUMAN POPULATIONS, Haemodynamics, MRI anatomic imaging, Magnetic resonance imaging, Medical imaging, NEAR INFRARED RADIATION, OPTICAL SPECTROMETERS, Pneumodyamics, respiration, SPATIAL RESOLUTION, Spatial analysis, Surface spectroscopy, Surface states, TOPOGRAPHY, Thermography, Topography},
	Month = dec,
	Number = {12},
	Pages = {1997--2005},
	Title = {Spatial and temporal analysis of human motor activity using noninvasive {NIR} topography},
	Url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.597496},
	Urldate = {2018-05-07},
	Volume = {22},
	Year = {1995},
	Bdsk-Url-1 = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.597496},
	Bdsk-Url-2 = {https://doi.org/10.1118/1.597496}}

@article{andermann_neuromagnetic_2017,
	Abstract = {Vowel recognition is largely immune to differences in speaker size despite the waveform differences associated with variation in speaker size. This has led to the suggestion that voice pitch and mean formant frequency (MFF) are extracted early in the hierarchy of hearing/speech processing and used to normalize the internal representation of vowel sounds. This paper presents a magnetoencephalographic (MEG) experiment designed to locate and compare neuromagnetic activity associated with voice pitch, MFF and vowel type in human auditory cortex. Sequences of six sustained vowels were used to contrast changes in the three components of vowel perception, and MEG responses to the changes were recorded from 25 participants. A staged procedure was employed to fit the MEG data with a source model having one bilateral pair of dipoles for each component of vowel perception. This dipole model showed that the activity associated with the three perceptual changes was functionally separable; the pitch source was located in Heschl's gyrus (bilaterally), while the vowel-type and formant-frequency sources were located (bilaterally) just behind Heschl's gyrus in planum temporale. The results confirm that vowel normalization begins in auditory cortex at an early point in the hierarchy of speech processing.},
	Author = {Andermann, Martin and Patterson, Roy D. and Vogt, Caroline and Winterstetter, Lisa and Rupp, Andr{\'e}},
	Doi = {10.1016/j.neuroimage.2017.06.065},
	Journal = {NeuroImage},
	Month = sep,
	Pages = {79--89},
	Title = {Neuromagnetic correlates of voice pitch, vowel type, and speaker size in auditory cortex},
	Url = {https://www.sciencedirect.com/science/article/pii/S1053811917305360},
	Volume = {158},
	Year = {2017},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1053811917305360},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2017.06.065}}

@article{obleser_pre-lexical_2009,
	Author = {Obleser, Jonas and Eisner, Franck},
	Doi = {10.1016/j.tics.2008.09.005},
	Journal = {Trends in Cognitive Sciences},
	Month = jan,
	Number = {1},
	Pages = {14--19},
	Title = {Pre-lexical abstraction of speech in the auditory cortex},
	Url = {https://www.sciencedirect.com/science/article/pii/S1364661308002477},
	Volume = {13},
	Year = {2009},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1364661308002477},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tics.2008.09.005}}

@article{doelling_acoustic_2014,
	Abstract = {A growing body of research suggests that intrinsic neuronal slow ({\textless}10 Hz) oscillations in auditory cortex appear to track incoming speech and other spectro-temporally complex auditory signals. Within this framework, several recent studies have identified critical-band temporal envelopes as the specific acoustic feature being reflected by the phase of these oscillations. However, how this alignment between speech acoustics and neural oscillations might underpin intelligibility is unclear. Here we test the hypothesis that the 'sharpness' of temporal fluctuations in the critical band envelope acts as a temporal cue to speech syllabic rate, driving delta-theta rhythms to track the stimulus and facilitate intelligibility. We interpret our findings as evidence that sharp events in the stimulus cause cortical rhythms to re-align and parse the stimulus into syllable-sized chunks for further decoding. Using magnetoencephalographic recordings, we show that by removing temporal fluctuations that occur at the syllabic rate, envelope-tracking activity is reduced. By artificially reinstating these temporal fluctuations, envelope-tracking activity is regained. These changes in tracking correlate with intelligibility of the stimulus. Together, the results suggest that the sharpness of fluctuations in the stimulus, as reflected in the cochlear output, drive oscillatory activity to track and entrain to the stimulus, at its syllabic rate. This process likely facilitates parsing of the stimulus into meaningful chunks appropriate for subsequent decoding, enhancing perception and intelligibility.},
	Author = {Doelling, Keith B. and Arnal, Luc H. and Ghitza, Oded and Poeppel, David},
	Doi = {10.1016/j.neuroimage.2013.06.035},
	Issn = {1095-9572},
	Journal = {NeuroImage},
	Keywords = {Acoustic Stimulation, Adolescent, Adult, Comprehension, Cues, Female, Humans, MEG, Male, Speech, Young Adult, Acoustic edge, Auditory cortex, CACoh, CALM, Delta Rhythm, Neural oscillation, Perceptual parsing, Speech Perception, Theta Rhythm, categorization and learning module, cerebro-acoustic coherence, magnetoencephalography},
	Language = {eng},
	Month = jan,
	Pages = {761--768},
	Pmcid = {PMC3839250},
	Pmid = {23791839},
	Title = {Acoustic landmarks drive delta-theta oscillations to enable speech comprehension by facilitating perceptual parsing},
	Volume = {85 Pt 2},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.neuroimage.2013.06.035}}

@article{rohrmeier_principles_2015,
	Abstract = {Human language, music and a variety of animal vocalizations constitute ways of sonic communication that exhibit remarkable structural complexity. While the complexities of language and possible parallels in animal communication have been discussed intensively, reflections on the complexity of music and animal song, and their comparisons, are underrepresented. In some ways, music and animal songs are more comparable to each other than to language as propositional semantics cannot be used as indicator of communicative success or wellformedness, and notions of grammaticality are less easily defined. This review brings together accounts of the principles of structure building in music and animal song. It relates them to corresponding models in formal language theory, the extended Chomsky hierarchy (CH), and their probabilistic counterparts. We further discuss common misunderstandings and shortcomings concerning the CH and suggest ways to move beyond. We discuss language, music and animal song in the context of their function and motivation and further integrate problems and issues that are less commonly addressed in the context of language, including continuous event spaces, features of sound and timbre, representation of temporality and interactions of multiple parallel feature streams. We discuss these aspects in the light of recent theoretical, cognitive, neuroscientific and modelling research in the domains of music, language and animal song.},
	Author = {Rohrmeier, Martin and Zuidema, Willem and Wiggins, Geraint A. and Scharff, Constance},
	Doi = {10.1098/rstb.2014.0097},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/D9XCQPWR/Rohrmeier et al. - 2015 - Principles of structure building in music, languag.pdf:application/pdf},
	Issn = {0962-8436},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Month = mar,
	Number = {1664},
	Pmcid = {PMC4321138},
	Pmid = {25646520},
	Title = {Principles of structure building in music, language and animal song},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321138/},
	Urldate = {2018-05-10},
	Volume = {370},
	Year = {2015},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4321138/},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2014.0097}}

@article{schweinberger_neural_2011,
	Abstract = {Apart from speech content, the human voice also carries paralinguistic information about speaker identity. Voice identification and its neural correlates have received little scientific attention up to now. Here we use event-related potentials (ERPs) in an adaptation paradigm, in order to investigate the neural representation and the time course of vocal identity processing. Participants adapted to repeated utterances of vowel--consonant--vowel (VCV) of one personally familiar speaker (either A or B), before classifying a subsequent test voice varying on an identity continuum between these two speakers. Following adaptation to speaker A, test voices were more likely perceived as speaker B and vice versa, and these contrastive voice identity aftereffects (VIAEs) were much more pronounced when the same syllable, rather than a different syllable, was used as adaptor. Adaptation induced amplitude reductions of the frontocentral N1--P2 complex and a prominent reduction of the parietal P3 component, for test voices preceded by identity-corresponding adaptors. Importantly, only the P3 modulation remained clear for across-syllable combinations of adaptor and test stimuli. Our results suggest that voice identity is contrastively processed by specialized neurons in auditory cortex within â¼250 ms after stimulus onset, with identity processing becoming less dependent on speech content after â¼300 ms.},
	Author = {Schweinberger, Stefan R. and Walther, Christian and Z{\"a}ske, Romi and Kov{\'a}cs, Gyula},
	Copyright = {{\copyright} 2011 The British Psychological Society},
	Doi = {10.1111/j.2044-8295.2011.02048.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/E2UBXNKG/Schweinberger et al. - 2011 - Neural correlates of adaptation to voice identity.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BRP9JDFM/j.2044-8295.2011.02048.html:text/html},
	Issn = {2044-8295},
	Journal = {British Journal of Psychology},
	Language = {en},
	Month = nov,
	Number = {4},
	Pages = {748--764},
	Title = {Neural correlates of adaptation to voice identity},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.2011.02048.x},
	Urldate = {2018-05-12},
	Volume = {102},
	Year = {2011},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.2011.02048.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.2044-8295.2011.02048.x}}

@article{fant_note_1966,
	Author = {Fant, G},
	File = {Fant - A note on vocal tract size factors and non-uniform.pdf:/Users/Cecile/Zotero/storage/IVZ79ETH/Fant - A note on vocal tract size factors and non-uniform.pdf:application/pdf},
	Journal = {Speech Transmission Laboratory - Quarterly Progress and Status Report},
	Language = {en},
	Number = {4},
	Pages = {13},
	Title = {A note on vocal tract size factors and non-uniform {F}-pattern scalings},
	Volume = {7},
	Year = {1966}}

@article{mullennix_stimulus_1990,
	Abstract = {Processing dependencies in speech perception between voice and phoneme were investigated using the Garner (1974) speeded classification procedure. Variability in the voice of the talker and in the cues to word-initial consonants were manipulated. The results showed that the processing of a talker's voice and the perception of voicing are asymmetrically dependent. In addition, when stimulus variability was increased in each dimension, the amount of orthogonal interference obtained for each dimension became significantly larger. The processing asymmetry between voice and phoneme was interpreted in terms of a parallel-contingent relationship of talker normalization processes to auditory-to-phonetic coding processes. The processing of voice information appears to be qualitatively different from the encoding of segmental phonetic information, although they are not independent. Implications of these results for current theories of speech perception are discussed.},
	Author = {Mullennix, John W. and Pisoni, David B.},
	Doi = {10.3758/BF03210878},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/TJY4ZCXX/Mullennix et Pisoni - 1990 - Stimulus variability and processing dependencies i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9BT9PDEK/BF03210878.html:text/html},
	Issn = {0031-5117, 1532-5962},
	Journal = {Perception \& Psychophysics},
	Language = {en},
	Month = jul,
	Number = {4},
	Pages = {379--390},
	Title = {Stimulus variability and processing dependencies in speech perception},
	Url = {https://link.springer.com/article/10.3758/BF03210878},
	Urldate = {2018-05-14},
	Volume = {47},
	Year = {1990},
	Bdsk-Url-1 = {https://link.springer.com/article/10.3758/BF03210878},
	Bdsk-Url-2 = {https://doi.org/10.3758/BF03210878}}

@article{schwartz_identification_1968,
	Author = {Schwartz, Martin F.},
	Doi = {10.1121/1.1910954},
	File = {Snapshot:/Users/Cecile/Zotero/storage/EPT8YEXU/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = may,
	Number = {5},
	Pages = {1178--1179},
	Title = {Identification of {Speaker} {Sex} from {Isolated}, {Voiceless} {Fricatives}},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.1910954},
	Urldate = {2018-05-14},
	Volume = {43},
	Year = {1968},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1910954},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1910954}}

@article{bladon_towards_1984,
	Author = {Bladon, R.A.W. and Henton, C.G. and Pickering, J.B.},
	Doi = {10.1016/0271-5309(84)90019-3},
	File = {Bladon et al. - 1984 - Towards an auditory theory of speaker normalizatio.pdf:/Users/Cecile/Zotero/storage/JXE8F26R/Bladon et al. - 1984 - Towards an auditory theory of speaker normalizatio.pdf:application/pdf},
	Issn = {02715309},
	Journal = {Language \& Communication},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {59--69},
	Title = {Towards an auditory theory of speaker normalization},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/0271530984900193},
	Urldate = {2018-05-14},
	Volume = {4},
	Year = {1984},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/0271530984900193},
	Bdsk-Url-2 = {https://doi.org/10.1016/0271-5309(84)90019-3}}

@article{giordano_contributions_2017,
	Abstract = {Seeing a speaker's face enhances speech intelligibility in adverse environments. We investigated the underlying network mechanisms by quantifying local speech representations and directed connectivity in MEG data obtained while human participants listened to speech of varying acoustic SNR and visual context. During high acoustic SNR speech encoding by temporally entrained brain activity was strong in temporal and inferior frontal cortex, while during low SNR strong entrainment emerged in premotor and superior frontal cortex. These changes in local encoding were accompanied by changes in directed connectivity along the ventral stream and the auditory-premotor axis. Importantly, the behavioral benefit arising from seeing the speaker's face was not predicted by changes in local encoding but rather by enhanced functional connectivity between temporal and inferior frontal cortex. Our results demonstrate a role of auditory-frontal interactions in visual speech representations and suggest that functional connectivity along the ventral pathway facilitates speech comprehension in multisensory environments., DOI:
http://dx.doi.org/10.7554/eLife.24763.001, When listening to someone in a noisy environment, such as a cocktail party, we can understand the speaker more easily if we can also see his or her face. Movements of the lips and tongue convey additional information that helps the listener's brain separate out syllables, words and sentences. However, exactly where in the brain this effect occurs and how it works remain unclear., To find out, Giordano et al. scanned the brains of healthy volunteers as they watched clips of people speaking. The clarity of the speech varied between clips. Furthermore, in some of the clips the lip movements of the speaker corresponded to the speech in question, whereas in others the lip movements were nonsense babble. As expected, the volunteers performed better on a word recognition task when the speech was clear and when the lips movements agreed with the spoken dialogue., Watching the video clips stimulated rhythmic activity in multiple regions of the volunteers' brains, including areas that process sound and areas that plan movements. Speech is itself rhythmic, and the volunteers' brain activity synchronized with the rhythms of the speech they were listening to. Seeing the speaker's face increased this degree of synchrony. However, it also made it easier for sound-processing regions within the listeners' brains to transfer information to one other. Notably, only the latter effect predicted improved performance on the word recognition task. This suggests that seeing a person's face makes it easier to understand his or her speech by boosting communication between brain regions, rather than through effects on individual areas., Further work is required to determine where and how the brain encodes lip movements and speech sounds. The next challenge will be to identify where these two sets of information interact, and how the brain merges them together to generate the impression of specific words., DOI:
http://dx.doi.org/10.7554/eLife.24763.002},
	Author = {Giordano, Bruno L and Ince, Robin A A and Gross, Joachim and Schyns, Philippe G and Panzeri, Stefano and Kayser, Christoph},
	Doi = {10.7554/eLife.24763},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/PBYLRZN5/Giordano et al. - Contributions of local speech encoding and functio.pdf:application/pdf},
	Issn = {2050-084X},
	Journal = {eLife},
	Pmcid = {PMC5462535},
	Pmid = {28590903},
	Title = {Contributions of local speech encoding and functional connectivity to audio-visual speech perception},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5462535/},
	Urldate = {2018-05-08},
	Volume = {6},
	Year = {2017},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5462535/},
	Bdsk-Url-2 = {https://doi.org/10.7554/eLife.24763}}

@phdthesis{guiraud_symphonie_2017,
	Author = {Guiraud, H{\'e}l{\`e}ne},
	File = {Guiraud - Symphonie des oscillations c{\'e}r{\'e}brales lors de la p.pdf:/Users/Cecile/Zotero/storage/ZCIK775B/Guiraud - Symphonie des oscillations c{\'e}r{\'e}brales lors de la p.pdf:application/pdf},
	Language = {fr},
	Month = nov,
	School = {Universit{\'e} lumi{\`e}re Lyon 2},
	Title = {Symphonie des oscillations c{\'e}r{\'e}brales lors de la perception de parole: {\'E}tudes comportementale et en magn{\'e}toenc{\'e}phalographie chez les enfants neurotypiques et dysphasiques.},
	Year = {2017}}

@article{zhang_functionally_2016,
	Abstract = {Speech signals contain information of both linguistic content and a talker's voice. Conventionally, linguistic and talker processing are thought to be mediated by distinct neural systems in the left and right hemispheres respectively, but there is growing evidence that linguistic and talker processing interact in many ways. Previous studies suggest that talker-related vocal tract changes are processed integrally with phonetic changes in the bilateral posterior superior temporal gyrus/superior temporal sulcus (STG/STS), because the vocal tract parameter influences the perception of phonetic information. It is yet unclear whether the bilateral STG is also activated by the integral processing of another parameter --- pitch, which influences the perception of lexical tone information and is related to talker differences in tone languages. In this study, we conducted separate functional magnetic resonance imaging (fMRI) and event-related potential (ERP) experiments to examine the spatial and temporal loci of interactions of lexical tone and talker-related pitch processing in Cantonese. We found that the STG was activated bilaterally during the processing of talker changes when listeners attended to lexical tone changes in the stimuli and during the processing of lexical tone changes when listeners attended to talker changes, suggesting that lexical tone and talker processing are functionally integrated in the bilateral STG. It extends the previous study, providing evidence for a general neural mechanism of integral phonetic and talker processing in the bilateral STG. The ERP results show interactions of lexical tone and talker processing 500--800 ms after auditory word onset (a simultaneous posterior P3b and a frontal negativity). Moreover, there is some asymmetry in the interaction, such that unattended talker changes affect linguistic processing more than vice versa, which may be related to the ambiguity that talker changes cause in speech perception and/or attention bias to talker changes. Our findings have implications for understanding the neural encoding of linguistic and talker information.},
	Author = {Zhang, Caicai and Pugh, Kenneth R. and Mencl, W. Einar and Molfese, Peter J. and Frost, Stephen J. and Magnuson, James S. and Peng, Gang and Wang, William S-Y.},
	Doi = {10.1016/j.neuroimage.2015.08.064},
	File = {Zhang et al. - 2016 - Functionally integrated neural processing of lingu.pdf:/Users/Cecile/Zotero/storage/J3RNTSF6/Zhang et al. - 2016 - Functionally integrated neural processing of lingu.pdf:application/pdf},
	Issn = {10538119},
	Journal = {NeuroImage},
	Language = {en},
	Month = jan,
	Pages = {536--549},
	Shorttitle = {Functionally integrated neural processing of linguistic and talker information},
	Title = {Functionally integrated neural processing of linguistic and talker information: {An} event-related {fMRI} and {ERP} study},
	Url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811915007855},
	Urldate = {2018-05-14},
	Volume = {124},
	Year = {2016},
	Bdsk-Url-1 = {http://linkinghub.elsevier.com/retrieve/pii/S1053811915007855},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2015.08.064}}

@article{chandrasekaran_neural_2011,
	Abstract = {Human speech is composed of two types of information, related to content (lexical information, i.e., ``what'' is being said [e.g., words]) and to the speaker (indexical information, i.e., ``who'' is talking [e.g., voices]). The extent to which lexical versus indexical information is represented separately or integrally in the brain is unresolved. In the current experiment, we use short-term fMRI adaptation to address this issue. Participants performed a loudness judgment task during which single or multiple sets of words/pseudowords were repeated with single (repeat) or multiple talkers (speaker-change) conditions while BOLD responses were collected. As reflected by adaptation fMRI, the left posterior middle temporal gyrus, a crucial component of the ventral auditory stream performing sound-to-meaning computations (``what'' pathway), showed sensitivity to lexical as well as indexical information. Previous studies have suggested that speaker information is abstracted during this stage of auditory word processing. Here, we demonstrate that indexical information is strongly coupled with word information. These findings are consistent with a plethora of behavioral results that have demonstrated that changes to speaker-related information can influence lexical processing.},
	Author = {Chandrasekaran, Bharath and Chan, Alice H. D. and Wong, Patrick C. M.},
	Doi = {10.1162/jocn.2011.21631},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LSU3B6W9/Chandrasekaran et al. - 2011 - Neural Processing of What and Who Information in S.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6CKKH647/jocn.2011.html:text/html},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = jan,
	Number = {10},
	Pages = {2690--2700},
	Title = {Neural {Processing} of {What} and {Who} {Information} in {Speech}},
	Url = {https://doi.org/10.1162/jocn.2011.21631},
	Urldate = {2018-05-12},
	Volume = {23},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1162/jocn.2011.21631}}

@article{picheny_speaking_1986,
	Author = {Picheny, M. A. and Durlach, N. I. and Braida, L. D.},
	Doi = {10.1044/jshr.2904.434},
	File = {Snapshot:/Users/Cecile/Zotero/storage/32SGME5G/article.html:text/html},
	Issn = {1092-4388},
	Journal = {Journal of Speech, Language, and Hearing Research},
	Language = {en},
	Month = dec,
	Number = {4},
	Pages = {434--446},
	Shorttitle = {Speaking {Clearly} for the {Hard} of {Hearing} {II}},
	Title = {Speaking {Clearly} for the {Hard} of {Hearing} {II}: {Acoustic} {Characteristics} of {Clear} and {Conversational} {Speech}},
	Url = {https://jslhr.pubs.asha.org/article.aspx?articleid=1778250},
	Urldate = {2018-05-10},
	Volume = {29},
	Year = {1986},
	Bdsk-Url-1 = {https://jslhr.pubs.asha.org/article.aspx?articleid=1778250},
	Bdsk-Url-2 = {https://doi.org/10.1044/jshr.2904.434}}

@article{fant_non-uniform_1975,
	Abstract = {A study of f e m a l e - m a l e differences i n F F2: and F 3 of v a r i o u s vowels within eight different languages reveals univer sal tendencies of d e p a r t u r e f r o m a simple uniform scaling. T h e s e have been quantified and adopted a s a basis for a vowel-category-specific normalization procedure which, on the average, reduces the female-male v a r i a n c e to one-half of that r e m a i n i n g a f t e r a s i m p l e uniform scaling of the type suggested by N o r d s t r o m and Lindblom (paper 212 p r e s e n t e d a t the 8th International C o n g r e s s of Phonetic Sciences, L e e d s 1975). Dialectal v a r i a t i o n s within a speaker group a r e thus of the s a m e o r d e r of magnitude a s a u n i v e r s a l p a t t e r n of deviations f r o m a simple s c a l e f a c t o r . P a r t s of this p a t t e r n can be a s c r i b e d to non-uniform scaling of vocal- t r a c t dimensions. Other p a r t s r e q u i r e the assumption of sex- specific articulation which may have developed to satisfy per ceptual c r i t e r i a . I t i s interesting to note that the scaling of tenor formants versus bass singers' formants a r e similar to the female-male scaling ( d e m o n s t r a t e d by Tom Cleveland i n a forthcoming paper).},
	Author = {Fant, G},
	File = {Fant - Non-uniform vowel normalization.pdf:/Users/Cecile/Zotero/storage/L92Z4LYI/Fant - Non-uniform vowel normalization.pdf:application/pdf},
	Journal = {Speech Transmission Laboratory - Quarterly Progress and Status Report},
	Language = {en},
	Number = {2-3},
	Pages = {1--19},
	Title = {Non-uniform vowel normalization},
	Volume = {16},
	Year = {1975}}

@article{kaganovich_electrophysiological_2006,
	Author = {Kaganovich, Natalya and Francis, Alexander L. and Melara, Robert D.},
	Doi = {10.1016/j.brainres.2006.07.049},
	Journal = {Brain Research},
	Number = {1},
	Pages = {161--172},
	Title = {Electrophysiological evidence for early interaction between talker and linguistic information during speech perception},
	Url = {https://www.sciencedirect.com/science/article/pii/S0006899306021974},
	Volume = {1114},
	Year = {2006},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0006899306021974},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.brainres.2006.07.049}}

@article{krause_acoustic_2003,
	Author = {Krause, Jean C. and Braida, Louis D.},
	Doi = {10.1121/1.1635842},
	File = {Snapshot:/Users/Cecile/Zotero/storage/PW4LVCXW/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = dec,
	Number = {1},
	Pages = {362--378},
	Title = {Acoustic properties of naturally produced clear speech at normal speaking rates},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.1635842},
	Urldate = {2018-05-10},
	Volume = {115},
	Year = {2003},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1635842},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1635842}}

@article{von_kriegstein_modulation_2003,
	Author = {von Kriegstein, Katharina and Eger, Evelyn and Kleinschmidt, Andreas and Giraud, Anne-Lise},
	Doi = {10.1016/S0926-6410(03)00079-X},
	Journal = {Cognitive Brain Research},
	Month = jun,
	Number = {1},
	Pages = {48--55},
	Title = {Modulation of neural responses to speech by directing attention to voices or verbal content},
	Url = {https://www.sciencedirect.com/science/article/pii/S092664100300079X},
	Volume = {17},
	Year = {2003},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S092664100300079X},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0926-6410(03)00079-X}}

@article{peterson_control_1952,
	Author = {Peterson, Gordon E. and Barney, Harold L.},
	Doi = {10.1121/1.1906875},
	File = {Peterson et Barney - 1952 - Control Methods Used in a Study of the Vowels.pdf:/Users/Cecile/Zotero/storage/PSGZ4PI4/Peterson et Barney - 1952 - Control Methods Used in a Study of the Vowels.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/A85WRRNJ/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = mar,
	Number = {2},
	Pages = {175--184},
	Title = {Control {Methods} {Used} in a {Study} of the {Vowels}},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.1906875},
	Urldate = {2018-05-12},
	Volume = {24},
	Year = {1952},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1906875},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1906875}}

@article{atkinson_correlation_1978,
	Author = {Atkinson, James E.},
	Doi = {10.1121/1.381716},
	File = {Snapshot:/Users/Cecile/Zotero/storage/NN7H8DPS/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = jan,
	Number = {1},
	Pages = {211--222},
	Title = {Correlation analysis of the physiological factors controlling fundamental voice frequency},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.381716},
	Volume = {63},
	Year = {1978},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.381716},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.381716}}

@article{csibra_gamma_2000,
	Abstract = {An enduring controversy in neuroscience concerns how the brain ``binds'' together separately coded stimulus features to form unitary representations of objects. Recent evidence has indicated a close link between this binding process and 40-hertz (gamma-band) oscillations generated by localized neural circuits. In a separate line of research, the ability of young infants to perceive objects as unitary and bounded has become a central focus for debates about the mechanisms of perceptual development. Here we demonstrate that binding-related 40-hertz oscillations are evident in the infant brain around 8 months of age, which is the same age at which behavioral and event-related potential evidence indicates the onset of perceptual binding of spatially separated static visual features.},
	Author = {Csibra, G. and Davis, G. and Spratling, M. W. and Johnson, M. H.},
	Doi = {10.1126/science.290.5496.1582},
	File = {Csibra et al. - 2000 - Gamma Oscillations and Object Processing in the In.pdf:/Users/Cecile/Zotero/storage/NWNE8GZI/Csibra et al. - 2000 - Gamma Oscillations and Object Processing in the In.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ILSPKTBD/1582.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = nov,
	Number = {5496},
	Pages = {1582--1585},
	Pmid = {11090357},
	Title = {Gamma {Oscillations} and {Object} {Processing} in the {Infant} {Brain}},
	Url = {http://science.sciencemag.org/content/290/5496/1582},
	Urldate = {2018-06-18},
	Volume = {290},
	Year = {2000},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/290/5496/1582},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.290.5496.1582}}

@article{marshall_development_2002,
	Abstract = {OBJECTIVES: This report provides a systematic longitudinal analysis of the EEG from infancy into early childhood. Particular emphasis is placed on the empirical confirmation of a 6-9 Hz alpha-range frequency band that has previously been used in the infant EEG literature.
METHODS: EEG data in 1-Hz bins from 3 to 12 Hz were analyzed from a longitudinal sample of 29 participants at 5, 10, 14, 24, and 51 months of age.
RESULTS: Inspection of power spectra averaged across the whole sample indicated the emergence of a peak in the 6-9 Hz range across multiple scalp regions. Coding of peaks in the power spectra of individual infants showed a clear developmental increase in the frequency of this peak. A rhythm in the 6-9 Hz emerged at central sites that was independent of the classical alpha rhythm at posterior sites. The relative amplitude of this central rhythm peaked in the second year of life, when major changes are occurring in locomotor behavior.
CONCLUSIONS: The 6-9 Hz band is a useful alpha-range band from the end of the first year of life into early childhood. The findings also complement other research relating the infant central rhythm with the adult sensorimotor mu rhythm.},
	Author = {Marshall, Peter J. and Bar-Haim, Yair and Fox, Nathan A.},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	Keywords = {Aging, Child, Preschool, Electrodes, Electroencephalography, Female, Frontal Lobe, Humans, Infant, Male, Occipital Lobe, Parietal Lobe, Brain, Alpha Rhythm, Longitudinal Studies, Motor Activity},
	Language = {eng},
	Month = aug,
	Number = {8},
	Pages = {1199--1208},
	Pmid = {12139998},
	Title = {Development of the {EEG} from 5 months to 4 years of age},
	Volume = {113},
	Year = {2002}}

@article{stroganova_eeg_1999,
	Abstract = {The 'functional topography' approach has been applied to study alpha rhythms in infant twins during the second half-year of life. The experimental sample included 154 normal infants born at 32-41 weeks of gestational age. Their chronological age varied from 7.4 to 12.4 months. EEG was registered during wakefulness under two experimental conditions: sustained visual attention and dark homogenous visual field. During darkness as compared with visual attention the sharp increase of spectral amplitudes within 5.2-9.6 Hz band was observed over the occipital-parietal cortex. The properties of the 5.2-9.6 Hz occipital rhythmic activity comply with the classical properties of alpha rhythm. The distinct spectral peak in 6.0-8.8 Hz band at precentral recording sites was observed during sustained visual attention. This rhythmic component was suppressed under the condition of total darkness. Arguments in favour of homology between the infant central rhythm and adult sensorimotor mu rhythm are advanced. The group mean of alpha peak frequency increased from 6.24 +/- 0.45 Hz at 8 months to 6.78 +/- 0.38 Hz at 11 months of chronological age. The frequency of infant alpha rhythm depended only on the period of extrauterine experience, regardless of gestational age at birth. This result points to the critical role of early visual experience in alpha rhythm development. The group mean of the peak frequency of mu rhythm also increased during the second half-year of life, from 7.03 +/- 0.47 Hz at 8 months to 7.42 +/- 0.46 Hz at 11 months. Unlike alpha rhythm, the peak frequency of mu rhythm depended on duration of both intra- and extrauterine development. We speculate that the development of sensorimotor mu rhythm is influenced by somatosensory stimulation, which, in sharp contrast to the visual input, is present in the uterus.},
	Author = {Stroganova, T. A. and Orekhova, E. V. and Posikera, I. N.},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology: Official Journal of the International Federation of Clinical Neurophysiology},
	Keywords = {Electroencephalography, Female, Humans, Infant, Newborn, Male, Brain, Age Distribution, Analysis of Variance},
	Language = {eng},
	Month = jun,
	Number = {6},
	Pages = {997--1012},
	Pmid = {10402087},
	Title = {{EEG} alpha rhythm in infants},
	Volume = {110},
	Year = {1999}}

@article{marshall_neural_2011,
	Abstract = {How do human children come to understand the actions of other people? What neural systems are associated with the processing of others' actions and how do these systems develop, starting in infancy? These questions span cognitive psychology and developmental cognitive neuroscience, and addressing them has important implications for the study of social cognition. A large amount of research has used behavioral measures to investigate infants' imitation of the actions of other people; a related but smaller literature has begun to use neurobiological measures to study of infants' action representation. Here we focus on experiments employing electroencephalographic (EEG) techniques for assessing mu rhythm desynchronization in infancy, and analyze how this work illuminates the links between action perception and production prior to the onset of language.},
	Author = {Marshall, Peter J. and Meltzoff, Andrew N.},
	Doi = {10.1016/j.dcn.2010.09.001},
	Issn = {1878-9307},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Brain Waves, Electroencephalography, Humans, Infant, Infant Behavior, Photic Stimulation, Psychomotor Performance, Reaction Time, Imitative Behavior, Mirror Neurons},
	Language = {eng},
	Month = apr,
	Number = {2},
	Pages = {110--123},
	Pmcid = {PMC3081582},
	Pmid = {21528008},
	Shorttitle = {Neural mirroring systems},
	Title = {Neural mirroring systems: exploring the {EEG} Î¼ rhythm in human infancy},
	Volume = {1},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.dcn.2010.09.001}}

@article{sowell_mapping_2003,
	Abstract = {We used magnetic resonance imaging and cortical matching algorithms to map gray matter density (GMD) in 176 normal individuals ranging in age from 7 to 87 years. We found a significant, nonlinear decline in GMD with age, which was most rapid between 7 and about 60 years, over dorsal frontal and parietal association cortices on both the lateral and interhemispheric surfaces. Age effects were inverted in the left posterior temporal region, where GMD gain continued up to age 30 and then rapidly declined. The trajectory of maturational and aging effects varied considerably over the cortex. Visual, auditory and limbic cortices, which are known to myelinate early, showed a more linear pattern of aging than the frontal and parietal neocortices, which continue myelination into adulthood. Our findings also indicate that the posterior temporal cortices, primarily in the left hemisphere, which typically support language functions, have a more protracted course of maturation than any other cortical region.},
	Author = {Sowell, Elizabeth R. and Peterson, Bradley S. and Thompson, Paul M. and Welcome, Suzanne E. and Henkenius, Amy L. and Toga, Arthur W.},
	Copyright = {2003 Nature Publishing Group},
	Doi = {10.1038/nn1008},
	File = {Snapshot:/Users/Cecile/Zotero/storage/UUXA77JF/nn1008.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {309--315},
	Title = {Mapping cortical change across the human life span},
	Url = {https://www.nature.com/articles/nn1008},
	Urldate = {2018-06-18},
	Volume = {6},
	Year = {2003},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn1008},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn1008}}

@article{maguire_what_2013,
	Abstract = {EEG is a primary method for studying temporally precise neuronal processes across the lifespan. Most of this work focuses on Event Related Potentials (ERPs); however, using time-locked time frequency analysis to decompose the EEG signal can identify and distinguish multiple changes in brain oscillations underlying cognition (). Further this measure is thought to reflect changes in inter-neuronal communication more directly than ERPs (). Although time frequency has elucidated cognitive processes in adults, applying it to cognitive development is still rare. Here, we review the basics of neuronal oscillations, some of what they reveal about adult cognitive function, and what little is known relating to children. We focus on language because it develops early and engages complex cortical networks. Additionally, because time frequency analysis of the EEG related to adult language comprehension has been incredibly informative, using similar methods with children will shed new light on current theories of language development and increase our understanding of how neural processes change over the lifespan. Our goal is to emphasize the power of this methodology and encourage its use throughout developmental cognitive neuroscience.},
	Author = {Maguire, Mandy J. and Abel, Alyson D.},
	Doi = {10.1016/j.dcn.2013.08.002},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/VR3VR9V5/Maguire et Abel - 2013 - What changes in neural oscillations can reveal abo.pdf:application/pdf},
	Issn = {1878-9293},
	Journal = {Developmental cognitive neuroscience},
	Month = oct,
	Pmcid = {PMC3875138},
	Pmid = {24060670},
	Shorttitle = {What changes in neural oscillations can reveal about developmental cognitive neuroscience},
	Title = {What changes in neural oscillations can reveal about developmental cognitive neuroscience: {Language} development as a case in point},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875138/},
	Urldate = {2018-06-18},
	Volume = {6},
	Year = {2013},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3875138/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2013.08.002}}

@article{heinz_properties_1961,
	Author = {Heinz, John M. and Stevens, Kenneth N.},
	Doi = {10.1121/1.1908734},
	File = {Snapshot:/Users/Cecile/Zotero/storage/7747QMR4/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = may,
	Number = {5},
	Pages = {589--596},
	Title = {On the {Properties} of {Voiceless} {Fricative} {Consonants}},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.1908734},
	Urldate = {2018-06-16},
	Volume = {33},
	Year = {1961},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.1908734},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1908734}}

@article{nacar_garcia_evoked_2018,
	Abstract = {Language discrimination is one of the core differences between bilingual and monolingual language acquisition. Here, we investigate the earliest brain specialization induced by it. Following previous research, we hypothesize that bilingual native language discrimination is a complex process involving specific processing of the prosodic properties of the speech signal. We recorded the brain activity of monolingual and bilingual 4.5-month-old infants using EEG, while listening to their native/dominant language and two foreign languages. We defined two different windows of analysis to separate discrimination and identification effects. In the early window of analysis (150-280âms) we measured the P200 component, and in the later window of analysis we measured Theta (400-1800âms) and Gamma (300-2800âms) oscillations. The results point in the direction of different language discrimination strategies for bilingual and monolingual infants. While only monolingual infants show early discrimination of their native language based on familiarity, bilinguals perform a later processing which is compatible with an increase in attention to the speech signal. This is the earliest evidence found for brain specialization induced by bilingualism.},
	Author = {Nacar Garcia, Loreto and Guerrero-Mosquera, Carlos and Colomer, Marc and Sebastian-Galles, Nuria},
	Doi = {10.1038/s41598-018-20824-0},
	Issn = {2045-2322},
	Journal = {Scientific Reports},
	Language = {eng},
	Month = feb,
	Number = {1},
	Pages = {2770},
	Pmcid = {PMC5807452},
	Pmid = {29426859},
	Title = {Evoked and oscillatory {EEG} activity differentiates language discrimination in young monolingual and bilingual infants},
	Volume = {8},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1038/s41598-018-20824-0}}

@article{cheour_maturation_1998,
	Abstract = {The mismatch negativity (MMN) is a pre-attentive change-specific component of the event-related brain potentials (ERPs). During the last decade this response has been intensively studied in adults, but investigations in children and especially in infants are still rare. Recent studies, however, have shown that MMN is also elicited in infants in response to changes in pure tones as well as in phonemes. The present study compared MMN in pre-term infants (conceptional age at the time of recording, 30--35 weeks), full-term newborns and full-term 3-month-old infants. Stimuli were Klatt-synthesized Finnish vowels /y/ and /i/. Previous studies have reported larger MMN amplitudes in school-age children compared with those obtained in adults. According to the results, however, the infant MMN amplitude seems to resemble that of adults. No significant differences in MMN amplitudes were found between the three age groups either. The mean MMN latency, however, decreased significantly with age, although in 3-month-old infants it was not much longer than in a previous study conducted in adults with the same stimuli.},
	Author = {Cheour, M. and Alho, K. and {\v C}eponien{\'e}, R. and Reinikainen, K. and Sainio, K. and Pohjavuori, M. and Aaltonen, O. and N{\"a}{\"a}t{\"a}nen, R.},
	Doi = {10.1016/S0167-8760(98)00017-8},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4UUW8QPB/Cheour et al. - 1998 - Maturation of mismatch negativity in infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XINF3C22/S0167876098000178.html:text/html},
	Issn = {0167-8760},
	Journal = {International Journal of Psychophysiology},
	Keywords = {Event-related brain potential, Mismatch negativity, Pre-term infants},
	Month = jul,
	Number = {2},
	Pages = {217--226},
	Title = {Maturation of mismatch negativity in infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S0167876098000178},
	Volume = {29},
	Year = {1998},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0167876098000178},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0167-8760(98)00017-8}}

@article{mcclelland_trace_1986,
	Abstract = {We describe a model called the TRACE model of speech perception. The model is based on the principles of interactive activation. Information processing takes place through the excitatory and inhibitory interactions of a large number of simple processing units, each working continuously to update its own activation on the basis of the activations of other units to which it is connected. The model is called the TRACE model because the network of units forms a dynamic processing structure called ``the Trace,'' which serves at once as the perceptual processing mechanism and as the system's working memory. The model is instantiated in two simulation programs. TRACE I, described in detail elsewhere, deals with short segments of real speech, and suggests a mechanism for coping with the fact that the cues to the identity of phonemes vary as a function of context. TRACE II, the focus of this article, simulates a large number of empirical findings on the perception of phonemes and words and on the interactions of phoneme and word perception. At the phoneme level, TRACE II simulates the influence of lexical information on the identification of phonemes and accounts for the fact that lexical effects are found under certain conditions but not others. The model also shows how knowledge of phonological constraints can be embodied in particular lexical items but can still be used to influence processing of novel, nonword utterances. The model also exhibits categorical perception and the ability to trade cues off against each other in phoneme identification. At the word level, the model captures the major positive feature of Marslen-Wilson's COHORT model of speech perception, in that it shows immediate sensitivity to information favoring one word or set of words over others. At the same time, it overcomes a difficulty with the COHORT model: it can recover from underspecification or mispronunciation of a word's beginning. TRACE II also uses lexical information to segment a stream of speech into a sequence of words and to find word beginnings and endings, and it simulates a number of recent findings related to these points. The TRACE model has some limitations, but we believe it is a step toward a psychologically and computationally adequate model of the process of speech perception.},
	Author = {McClelland, James L and Elman, Jeffrey L},
	Doi = {10.1016/0010-0285(86)90015-0},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/38RIP3KL/McClelland et Elman - 1986 - The TRACE model of speech perception.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/EA42JI78/0010028586900150.html:text/html},
	Issn = {0010-0285},
	Journal = {Cognitive Psychology},
	Month = jan,
	Number = {1},
	Pages = {1--86},
	Title = {The {TRACE} model of speech perception},
	Url = {http://www.sciencedirect.com/science/article/pii/0010028586900150},
	Urldate = {2018-06-21},
	Volume = {18},
	Year = {1986},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0010028586900150},
	Bdsk-Url-2 = {https://doi.org/10.1016/0010-0285(86)90015-0}}

@article{rao_predictive_1999,
	Abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
	Author = {Rao, R. P. and Ballard, D. H.},
	Doi = {10.1038/4580},
	Issn = {1097-6256},
	Journal = {Nature Neuroscience},
	Keywords = {Models, Neurological, Neural Networks (Computer), Visual Cortex, Feedback, Forecasting, Visual Pathways},
	Language = {eng},
	Month = jan,
	Number = {1},
	Pages = {79--87},
	Pmid = {10195184},
	Shorttitle = {Predictive coding in the visual cortex},
	Title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
	Volume = {2},
	Year = {1999},
	Bdsk-Url-1 = {https://doi.org/10.1038/4580}}

@article{friston_theory_2005,
	Abstract = {{\textless}p{\textgreater}This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts.{\textless}/p{\textgreater}{\textless}p{\textgreater}It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain9s free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain's attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on \textit{empirical Bayes} and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective.{\textless}/p{\textgreater}{\textless}p{\textgreater}In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.{\textless}/p{\textgreater}},
	Author = {Friston, Karl},
	Copyright = {{\copyright} 2005 The Royal Society},
	Doi = {10.1098/rstb.2005.1622},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/P2LW3GDL/Friston - 2005 - A theory of cortical responses.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XGNFW3Q5/815.html:text/html},
	Issn = {0962-8436, 1471-2970},
	Journal = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
	Language = {en},
	Month = apr,
	Number = {1456},
	Pages = {815--836},
	Pmid = {15937014},
	Title = {A theory of cortical responses},
	Url = {http://rstb.royalsocietypublishing.org/content/360/1456/815},
	Urldate = {2018-06-21},
	Volume = {360},
	Year = {2005},
	Bdsk-Url-1 = {http://rstb.royalsocietypublishing.org/content/360/1456/815},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2005.1622}}

@article{murakami_contributions_2006,
	Abstract = {A realistically shaped three-dimensional single-neuron model was constructed for each of four principal cell types in the neocortex in order to infer their contributions to magnetoencephalography (MEG) and electroencephalography (EEG) signals. For each cell, the soma was stimulated and the resulting intracellular current was used to compute the current dipole Q for the whole cell or separately for the apical and basal dendrites. The magnitude of Q is proportional to the magnetic field and electrical potential far from the neuron. A train of spikes and depolarization shift in an intracellular burst discharge were seen as spikes and an envelope in Q for the layer V and layer II/III pyramidal cells. The stellate cells lacked the envelope. As expected, the pyramidal cells produced a stronger Q than the stellate cells. The spikes produced by the layer V pyramidal cells (n = 4) varied between â0.78 and 2.97 pA m with the majority of the cells showing a current toward the pia (defined as positive). The basal dendrites, however, produced considerable spike currents. The magnitude and direction of dipole moment are in agreement with the distribution of the dendrites. The spikes in Q for the layer V pyramidal cells were produced by the transient sodium conductance and potassium conductance of delayed rectifier type; the conductances distributed along the dendrites were capable of generating spike propagation, which was seen in Q as the tail of a triphasic wave lasting several milliseconds. The envelope was similar in magnitude (â0.41 to â0.90 pA m) across the four layer V pyramidal cells. The spike and envelope for the layer II/III pyramidal cell were 0.47 and â0.29 pA m, respectively; these values agreed well with empirical and theoretical estimates for guinea pig CA3 pyramidal cells. Spikes were stronger for the layer IV spiny stellate (0.27 pA m) than the layer III aspiny stellate cell (0.06 pA m) along their best orientations. The spikes may thus be stronger than has been previously thought. The Q for a population of stellate cells may be weaker than a linear sum of their individual Q values due to their variable dendritic geometry. The burst discharge by pyramidal cells may be detectable with MEG and EEG when 10 000--50 000 cells are synchronously active.},
	Author = {Murakami, Shingo and Okada, Yoshio},
	Doi = {10.1113/jphysiol.2006.105379},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/A6TDK7JL/Murakami et Okada - 2006 - Contributions of principal neocortical neurons to .pdf:application/pdf},
	Issn = {0022-3751},
	Journal = {The Journal of Physiology},
	Month = sep,
	Number = {Pt 3},
	Pages = {925--936},
	Pmcid = {PMC1995687},
	Pmid = {16613883},
	Title = {Contributions of principal neocortical neurons to magnetoencephalography and electroencephalography signals},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1995687/},
	Urldate = {2018-06-22},
	Volume = {575},
	Year = {2006},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1995687/},
	Bdsk-Url-2 = {https://doi.org/10.1113/jphysiol.2006.105379}}

@article{singh_which_2012,
	Abstract = {Over the last 20years, BOLD-FMRI has proved itself to be a powerful and versatile tool for the study of the neural substrate underpinning many of our cognitive and perceptual functions. However, exactly how it is coupled to the underlying neurophysiology, and how this coupling varies across the brain, across tasks and across individuals is still unclear. The story is further complicated by the fact that within the same cortical region, multiple evoked and induced oscillatory effects may be modulated during task execution, supporting different cognitive roles, and any or all of these may have metabolic demands that then drive the BOLD response. In this paper I shall concentrate on one experimental approach to shedding light on this problem i.e. the execution of the same experimental tasks using MEG and fMRI in order to reveal which electrophysiological responses best match the BOLD response spatially, temporally and functionally. The results demonstrate a rich and complex story that does not fit with a simplistic view of BOLD reflecting ``neural activity'' and suggests that we could consider the coupling between BOLD and the various parameters of neural function as an ill-posed inverse problem. Finally, I describe recent work linking individual variability in both cortical oscillations and the BOLD-fMRI response to variability in endogenous GABA concentration.},
	Author = {Singh, Krish D.},
	Doi = {10.1016/j.neuroimage.2012.01.028},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/TE97SHVH/Singh - 2012 - Which ``neural activity'' do you mean fMRI, MEG, os.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VPQBNUMF/S1053811912000456.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {MEG, Oscillations, BOLD, Vision, fMRI, Behaviour, GABA, Variability},
	Month = aug,
	Number = {2},
	Pages = {1121--1130},
	Series = {20 {YEARS} {OF} {fMRI}},
	Shorttitle = {Which ``neural activity'' do you mean?},
	Title = {Which ``neural activity'' do you mean? {fMRI}, {MEG}, oscillations and neurotransmitters},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811912000456},
	Urldate = {2018-06-22},
	Volume = {62},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912000456},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.01.028}}

@article{deco_dynamic_2008,
	Abstract = {The cortex is a complex system, characterized by its dynamics and architecture, which underlie many functions such as action, perception, learning, language, and cognition. Its structural architecture has been studied for more than a hundred years; however, its dynamics have been addressed much less thoroughly. In this paper, we review and integrate, in a unifying framework, a variety of computational approaches that have been used to characterize the dynamics of the cortex, as evidenced at different levels of measurement. Computational models at different space--time scales help us understand the fundamental mechanisms that underpin neural processes and relate these processes to neuroscience data. Modeling at the single neuron level is necessary because this is the level at which information is exchanged between the computing elements of the brain; the neurons. Mesoscopic models tell us how neural elements interact to yield emergent behavior at the level of microcolumns and cortical columns. Macroscopic models can inform us about whole brain dynamics and interactions between large-scale neural systems such as cortical regions, the thalamus, and brain stem. Each level of description relates uniquely to neuroscience data, from single-unit recordings, through local field potentials to functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), and magnetoencephalogram (MEG). Models of the cortex can establish which types of large-scale neuronal networks can perform computations and characterize their emergent properties. Mean-field and related formulations of dynamics also play an essential and complementary role as forward models that can be inverted given empirical data. This makes dynamic models critical in integrating theory and experiments. We argue that elaborating principled and informed models is a prerequisite for grounding empirical neuroscience in a cogent theoretical framework, commensurate with the achievements in the physical sciences.},
	Author = {Deco, Gustavo and Jirsa, Viktor K. and Robinson, Peter A. and Breakspear, Michael and Friston, Karl},
	Doi = {10.1371/journal.pcbi.1000092},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FT5K8EVT/Deco et al. - 2008 - The Dynamic Brain From Spiking Neurons to Neural .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CVTY7BYE/article.html:text/html},
	Issn = {1553-7358},
	Journal = {PLOS Computational Biology},
	Keywords = {Neurons, Action potentials, Membrane potential, Mesoscopic physics, Neural networks, Nonlinear dynamics, Population density, Single neuron function},
	Language = {en},
	Month = aug,
	Number = {8},
	Pages = {e1000092},
	Shorttitle = {The {Dynamic} {Brain}},
	Title = {The {Dynamic} {Brain}: {From} {Spiking} {Neurons} to {Neural} {Masses} and {Cortical} {Fields}},
	Url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092},
	Urldate = {2018-06-22},
	Volume = {4},
	Year = {2008},
	Bdsk-Url-1 = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000092},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pcbi.1000092}}

@article{coombes_large-scale_2010,
	Abstract = {We review the use of neural field models for modelling the brain at the large scales necessary for interpreting EEG, fMRI, MEG and optical imaging data. Albeit a framework that is limited to coarse-grained or mean-field activity, neural field models provide a framework for unifying data from different imaging modalities. Starting with a description of neural mass models, we build to spatially extend cortical models of layered two-dimensional sheets with long range axonal connections mediating synaptic interactions. Reformulations of the fundamental non-local mathematical model in terms of more familiar local differential (brain wave) equations are described. Techniques for the analysis of such models, including how to determine the onset of spatio-temporal pattern forming instabilities, are reviewed. Extensions of the basic formalism to treat refractoriness, adaptive feedback and inhomogeneous connectivity are described along with open challenges for the development of multi-scale models that can integrate macroscopic models at large spatial scales with models at the microscopic scale.},
	Author = {Coombes, S.},
	Doi = {10.1016/j.neuroimage.2010.01.045},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SKJLXYDZ/Coombes - 2010 - Large-scale neural dynamics Simple and complex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/5MH4KHWD/S1053811910000674.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {EEG, fMRI, Brain wave equation, Neural field theory},
	Month = sep,
	Number = {3},
	Pages = {731--739},
	Series = {Computational {Models} of the {Brain}},
	Shorttitle = {Large-scale neural dynamics},
	Title = {Large-scale neural dynamics: {Simple} and complex},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811910000674},
	Urldate = {2018-06-22},
	Volume = {52},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811910000674},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2010.01.045}}

@article{alexandrou_cortical_nodate,
	Author = {Alexandrou, Anna Maria and Saarinen, Timo and Kujala, Jan and Salmelin, Riitta},
	Doi = {https://doi.org/10.1162/jocn_a_01295},
	Journal = {Journal of Cognitive Neuroscience},
	Title = {Cortical tracking of global and local variation of speech rhythm during connected natural speech perception},
	Bdsk-Url-1 = {https://doi.org/10.1162/jocn_a_01295}}

@article{wong_neural_2004,
	Abstract = {To recognize phonemes across variation in talkers, listeners can use information about vocal characteristics, a process referred to as ``talker normalization.'' The present study investigates the cortical mechanisms underlying talker normalization using fMRI. Listeners recognized target words presented in either a spoken list produced by a single talker or a mix of different talkers. It was found that both conditions activate an extensive cortical network. However, recognizing words in the mixed-talker condition, relative to the blocked-talker condition, activated middle/superior temporal and superior parietal regions to a greater degree. This temporal-- parietal network is possibly associated with selectively attending and processing spectral and spatial acoustic cues required in recognizing speech in a mixed-talker condition.},
	Author = {Wong, Patrick C. M. and Nusbaum, Howard C. and Small, Steven L.},
	Doi = {10.1162/0898929041920522},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LF7K6EHX/Wong et al. - 2004 - Neural Bases of Talker Normalization.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EDW6XH78/0898929041920522.html:text/html},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = sep,
	Number = {7},
	Pages = {1173--1184},
	Title = {Neural {Bases} of {Talker} {Normalization}},
	Url = {https://doi.org/10.1162/0898929041920522},
	Urldate = {2018-08-06},
	Volume = {16},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1162/0898929041920522}}

@article{banse_acoustic_1996,
	Author = {Banse, Rainer and Scherer, Klaus R.},
	Journal = {Journal of Personality and Social Psychology},
	Month = mar,
	Number = {3},
	Pages = {614--636},
	Title = {Acoustic profiles in vocal emotion expression},
	Volume = {70},
	Year = {1996}}

@article{scherer_vocal_1991,
	Abstract = {This research examines the correspondence between theoretical predictions on vocal expression patterns in naturally occurring emotions (as based on the component process theory of emotion; Scherer, 1986) and empirical data on the acoustic characteristics of actors' portrayals. Two male and two female professional radio actors portrayed anger, sadness, joy, fear, and disgust based on realistic scenarios of emotion-eliciting events. A series of judgment studies was conducted to assess the degree to which judges are able to recognize the intended emotion expressions. Disgust was relatively poorly recognized; average recognition accuracy for the other emotions attained 62.8\% across studies. A set of portrayals reaching a satisfactory level of recognition accuracy underwent digital acoustic analysis. The results for the acoustic parameters extracted from the speech signal show a number of significant differences between emotions, generally confirming the theoretical predictions.},
	Author = {Scherer, Klaus R. and Banse, Rainer and Wallbott, Harald G. and Goldbeck, Thomas},
	Doi = {10.1007/BF00995674},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T2PF7EK5/Scherer et al. - 1991 - Vocal cues in emotion encoding and decoding.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BLVD5RCY/BF00995674.html:text/html},
	Issn = {0146-7239, 1573-6644},
	Journal = {Motivation and Emotion},
	Language = {en},
	Month = jun,
	Number = {2},
	Pages = {123--148},
	Title = {Vocal cues in emotion encoding and decoding},
	Url = {https://link.springer.com/article/10.1007/BF00995674},
	Urldate = {2018-08-05},
	Volume = {15},
	Year = {1991},
	Bdsk-Url-1 = {https://link.springer.com/article/10.1007/BF00995674},
	Bdsk-Url-2 = {https://doi.org/10.1007/BF00995674}}

@article{sheft_effects_2012,
	Abstract = {Objective
The frequency modulation (FM) of speech can convey linguistic information and also enhance speech-stream coherence and segmentation. Using a clinically oriented approach, the purpose of the present study was to examine the effects of age and hearing loss on the ability to discriminate between stochastic patterns of low-rate FM and determine whether difficulties in speech perception experienced by older listeners relate to a deficit in this ability.

Design
Data were collected from 18 normal-hearing young adults, and 18 participants who were at least 60 years old, nine normal-hearing and nine with a mild-to-moderate sensorineural hearing loss. Using stochastic frequency modulators derived from 5-Hz lowpass noise applied to a 1-kHz carrier, discrimination thresholds were measured in terms of frequency excursion (ÎF) both in quiet and with a speech-babble masker present, stimulus duration, and signal-to-noise ratio (SNRFM) in the presence of a speech-babble masker. Speech perception ability was evaluated using Quick Speech-in-Noise (QuickSIN) sentences in four-talker babble.

Results
Results showed a significant effect of age, but not of hearing loss among the older listeners, for FM discrimination conditions with masking present (ÎF and SNRFM). The effect of age was not significant for the FM measures based on stimulus duration. ÎF and SNRFM were also the two conditions for which performance was significantly correlated with listener age when controlling for effect of hearing loss as measured by pure-tone average. With respect to speech-in-noise ability, results from the SNRFM condition were significantly correlated with QuickSIN performance.

Conclusions
Results indicate that aging is associated with reduced ability to discriminate moderate-duration patterns of low-rate stochastic FM. Furthermore, the relationship between QuickSIN performance and the SNRFM thresholds suggests that the difficulty experienced by older listeners with speech-in-noise processing may in part relate to diminished ability to process slower fine-structure modulation at low sensation levels. Results thus suggest that clinical consideration of stochastic FM discrimination measures may offer a fuller picture of auditory processing abilities.},
	Author = {Sheft, Stanley and Shafiro, Valeriy and Lorenzi, Christian and McMullen, Rachel and Farrell, Caitlin},
	Doi = {10.1097/AUD.0b013e31825aab15},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/MDWECQIH/Sheft et al. - 2012 - Effects of Age and Hearing Loss on the Relationshi.pdf:application/pdf},
	Issn = {0196-0202},
	Journal = {Ear and hearing},
	Month = nov,
	Number = {6},
	Pages = {709--720},
	Pmcid = {PMC3480978},
	Pmid = {22790319},
	Title = {Effects of {Age} and {Hearing} {Loss} on the {Relationship} between {Discrimination} of {Stochastic} {Frequency} {Modulation} and {Speech} {Perception}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480978/},
	Urldate = {2018-08-04},
	Volume = {33},
	Year = {2012},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3480978/},
	Bdsk-Url-2 = {https://doi.org/10.1097/AUD.0b013e31825aab15}}

@article{osman_hierarchy_2018,
	Abstract = {Auditory cortex is essential for mammals, including rodents, to detect temporal ``shape'' cues in the sound envelope but it remains unclear how different cortical fields may contribute to this ability (Threlkeld et al, 2008; Malhotra, 2008). Previously, we found precise spiking patterns provide a potential neural code for temporal shape cues in the sound envelope in primary (A1) and ventral (VAF) and caudal suprarhinal (cSRAF) auditory fields of the rat (Lee et al., 2016). Here, we extend these findings and characterize the time course of the temporally precise output of auditory cortical neurons in male rats. A pairwise sound discrimination index and a Na{\"\i}ve Bayesian classifier are used to determine how these spiking patterns could provide brain signals for behavioral discrimination and classification of sounds. We find response durations and optimal time constants for discriminating sound envelope shape increase in rank order with: A1 {\textless} VAF {\textless}cSRAF. Accordingly, sustained spiking is more prominent and results in more robust sound discrimination in non-primary cortex versus A1. Spike timing patterns classify 10 different sound envelope shape sequences and there is a 2-fold increase in maximal performance when pooling output across the neuron population indicating a robust distributed neural code in all three cortical fields. Together, these results support the idea that temporally precise spiking patterns from primary and non-primary auditory cortical fields provide the necessary signals for animals to discriminate and classify a large range of temporal shapes in the sound envelope.
SIGNIFICANCE STATEMENT
Functional hierarchies in the visual cortices support the concept that classification of visual objects requires successive cortical stages of processing including a progressive increase in classical receptive field size. The present study is significant as it supports the idea that a similar progression exists in auditory cortices in the time domain. We demonstrate for the first time that three cortices provide temporal spiking patterns for robust temporal envelope shape discrimination but only the ventral non-primary cortices do so on long time scales. This study raises the possibility that primary and non-primary cortices provide unique temporal spiking patterns and time scales for perception of sound envelope shape.},
	Author = {Osman, Ahmad F. and Lee, Christopher M. and Escab{\'\i}, Monty A. and Read, Heather L.},
	Copyright = {Copyright {\copyright} 2018 the authors},
	Doi = {10.1523/JNEUROSCI.2871-17.2018},
	File = {Osman et al. - 2018 - A hierarchy of time scales for discriminating and .pdf:/Users/Cecile/Zotero/storage/IPGSDEH9/Osman et al. - 2018 - A hierarchy of time scales for discriminating and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YY5AR4NU/JNEUROSCI.2871-17.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = jun,
	Pages = {2871--17},
	Pmid = {29954851},
	Title = {A hierarchy of time scales for discriminating and classifying the temporal shape of sound in three auditory cortical fields},
	Url = {http://www.jneurosci.org/content/early/2018/06/28/JNEUROSCI.2871-17.2018},
	Urldate = {2018-08-04},
	Year = {2018},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/early/2018/06/28/JNEUROSCI.2871-17.2018},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2871-17.2018}}

@article{traub_computer_1992,
	Abstract = {1. We used simulations of the in vitro CA3 region of the hippocampus to analyse the 5 Hz population oscillations recorded experimentally in carbachol. 2. A simulation model of the in vitro CA3 region was constructed with 1000 pyramidal neurones and 200 inhibitory neurones (100 producing fast inhibitory postsynaptic potentials (IPSPs) and 100 producing slow IPSPs of delayed onset). Each neurone contained nineteen soma-dendritic compartments. Pyramidal neurones contained six voltage- and/or calcium-dependent ionic currents, whose kinetics were consistent with voltage-clamp data. The connectivity and waveform of unitary synaptic events for excitatory and fast inhibitory synapses were consistent with dual intracellular recordings. This network was shown to generate previously described network oscillations, including synchronized bursts recorded in the presence of GABAA blockers, and synchronized synaptic potentials observed during partial blockade of GABAA inhibition. 3. The model generated 5 Hz oscillations as recorded in carbachol under the following conditions: (a) excitatory synaptic conductance was within a limited range; (b) there was blockade of fast and slow IPSPs (consistent with the experimental lack of effect of bicuculline and phaclofen on carbachol oscillations and the known depression of IPSPs by acetylcholine); (c) the after hyperpolarization (AHP) conductance was reduced (consistent with the known pharmacology of carbachol); (d) the apical dendrites of the pyramidal cells were depolarized, as suggested by the carbachol-induced depolarization of pyramidal neurones. Each oscillation was associated in pyramidal cells with a burst of action potentials riding on a depolarizing wave. The N-methyl-D-aspartate (NMDA) type of excitatory synapse was not necessary for the oscillations to occur. 4. Progressive reduction of excitatory synaptic strength led to an oscillation of the same frequency, with bursts riding on smaller EPSPs (consistent with the experiment). Further reduction of excitatory synaptic strength abolished the population oscillation by uncoupling the neurones. When excitatory synaptic conductance was too large, population oscillations were attenuated as the cells switched from a bursting mode to a repetitively firing mode. 5. Increasing the AHP conductance prolonged the interburst interval as expected. Inclusion of slow IPSPs exerted a similar effect. 6. When fast IPSPs were included, an oscillation with different characteristics emerged: a 10 Hz oscillation that was gated by compound GABAA IPSPs. On any oscillatory wave, few pyramidal neurones fired, and the firing of individual neurones was irregular.(ABSTRACT TRUNCATED AT 400 WORDS)},
	Author = {Traub, R D and Miles, R and Buzs{\'a}ki, G},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/DC2BALAM/Traub et al. - 1992 - Computer simulation of carbachol-driven rhythmic p.pdf:application/pdf},
	Issn = {0022-3751},
	Journal = {The Journal of Physiology},
	Pages = {653--672},
	Pmcid = {PMC1176181},
	Pmid = {1403830},
	Title = {Computer simulation of carbachol-driven rhythmic population oscillations in the {CA3} region of the in vitro rat hippocampus.},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1176181/},
	Urldate = {2018-08-03},
	Volume = {451},
	Year = {1992},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1176181/}}

@article{silva_intrinsic_1991,
	Abstract = {Rhythmic activity in the neocortex varies with different behavioral and pathological states and in some cases may encode sensory information. However, the neural mechanisms of these oscillations are largely unknown. Many pyramidal neurons in layer 5 of the neocortex showed prolonged, 5- to 12-hertz rhythmic firing patterns at threshold. Rhythmic firing was due to intrinsic membrane properties, sodium conductances were essential for rhythmicity, and calcium-dependent conductances strongly modified rhythmicity. Isolated slices of neocortex generated epochs of 4- to 10-hertz synchronized activity when N-methyl-D-aspartate receptor-mediated channels were facilitated. Layer 5 was both necessary and sufficient to produce these synchronized oscillations. Thus, synaptic networks of intrinsically rhythmic neurons in layer 5 may generate or promote certain synchronized oscillations of the neocortex.},
	Author = {Silva, L. R. and Amitai, Y. and Connors, B. W.},
	Copyright = {{\copyright} 1991},
	Doi = {10.1126/science.1824881},
	File = {Snapshot:/Users/Cecile/Zotero/storage/WTNU8YV6/432.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jan,
	Number = {4992},
	Pages = {432--435},
	Pmid = {1824881},
	Title = {Intrinsic oscillations of neocortex generated by layer 5 pyramidal neurons},
	Url = {http://science.sciencemag.org/content/251/4992/432},
	Urldate = {2018-08-03},
	Volume = {251},
	Year = {1991},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/251/4992/432},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1824881}}

@article{wang_ionic_1993,
	Abstract = {Abstract: We present a biophysical model of a slowly inactivating potassium ion current IKS, based on recent voltage-clamp data from layer V pyramidal...},
	Author = {Wang, X. J.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/T7WK2NYQ/8298079.html:text/html},
	Issn = {0959-4965},
	Journal = {Neuroreport},
	Language = {eng},
	Month = dec,
	Number = {3},
	Pages = {221--224},
	Pmid = {8298079},
	Title = {Ionic basis for intrinsic 40 {Hz} neuronal oscillations.},
	Url = {http://europepmc.org/abstract/med/8298079},
	Urldate = {2018-08-03},
	Volume = {5},
	Year = {1993},
	Bdsk-Url-1 = {http://europepmc.org/abstract/med/8298079}}

@article{wallois_usefulness_2012,
	Abstract = {One of the most challenging tasks in neuroscience in language studies, is investigation of the brain's ability to integrate and process information. This task can only be successfully addressed by applying various assessment techniques integrated into a multimodal approach. Each of these techniques has its advantages and disadvantages, but help to elucidate certain aspects of the capacity of neural networks to process information. These methods provide information about changes in electrical, hemodynamic and metabolic activities. Ideally, they should be noninvasive in order to facilitate their use particularly in children. In the present review, we describe the advantages of simultaneous electroencephalographic (EEG) acquisition with near infrared spectroscopy (NIRS) to provide a better understanding of the mechanisms involved in cerebral activation. This coregistration is also useful to avoid misleading interpretation of NIRS, notably during the various phases of sleep. Development and implementation of the various tools required and assessment strategies are also discussed.},
	Author = {Wallois, F. and Mahmoudzadeh, M. and Patil, A. and Grebe, R.},
	Doi = {10.1016/j.bandl.2011.03.010},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/CA8PX3BQ/Wallois et al. - 2012 - Usefulness of simultaneous EEG--NIRS recording in l.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/AXQEDKGE/S0093934X11000599.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Keywords = {EEG, NIRS, EEG--NIRS, Electroptodes, Electroptods, Language, Near infrared spectroscopy, Optical imaging, Optodes},
	Month = may,
	Number = {2},
	Pages = {110--123},
	Series = {Functional {Near}-{Infra} {Red} {Spectroscopy} ({fNIRS}): {A} {Promising} {Functional} {Imaging} {Technique} for the {Study} of {Brain} and {Language}},
	Title = {Usefulness of simultaneous {EEG}--{NIRS} recording in language studies},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X11000599},
	Urldate = {2018-08-01},
	Volume = {121},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X11000599},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2011.03.010}}

@article{odabaee_neonatal_2014,
	Abstract = {The potential improvements in spatial resolution of neonatal EEG used in source localization have been challenged by the insufficiencies in realistic neonatal head models. Our present study aimed at using empirical methods to indirectly estimate skull conductivity; the model parameter that is known to significantly affect the behavior of newborn scalp EEG and cause it to be markedly different from that of an adult. To this end, we used 64 channel EEG recordings to study the spatial specificity of scalp EEG by assessing the spatial decays in focal transients using both amplitudes and between-c'hannels linear correlations. The findings showed that these amplitudes and correlations decay within few centimeters from the reference channel/electrode, and that the nature of the decay is independent of the scalp area. This decay in newborn infants was found to be approximately three times faster than the corresponding decay in adult EEG analyzed from a set of 256 channel recordings. We then generated realistic head models using both finite and boundary element methods along with a manually segmented magnetic resonance images to study the spatial decays of scalp potentials produced by single dipole in the cortex. By comparing the spatial decays due to real and simulated EEG for different skull conductivities (from 0.003 to 0.3S/m), we showed that a close match between the empirical and simulated decays was obtained when the selected skull conductivity for newborn was around 0.06--0.2S/m. This is over an order of magnitude higher than the currently used values in adult head modeling. The results also showed that the neonatal scalp EEG is less smeared than that of an adult and this characteristic is the same across the entire scalp, including the fontanel region. These results indicate that a focal cortical activity is generally only registered by electrodes within few centimeters from the source. Hence, the conventional 10 to 20 channel neonatal EEG acquisition systems give a significantly spatially under sampled scalp EEG and may, consequently, give distorted pictures of focal brain activities. Such spatial specificity can only be reconciled by appreciating the anatomy of the neonatal head, especially the still unossified skull structure that needs to be modeled with higher conductivities than conventionally used in the adults.},
	Author = {Odabaee, Maryam and Tokariev, Anton and Layeghy, Siamak and Mesbah, Mostefa and Colditz, Paul B. and Ramon, Ceon and Vanhatalo, Sampsa},
	Doi = {10.1016/j.neuroimage.2014.04.007},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/L7LM6BE4/Odabaee et al. - 2014 - Neonatal EEG at scalp is focal and implies high sk.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/524UIQZX/S1053811914002626.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Head model, High density EEG, Neonatal EEG, Source localization},
	Month = aug,
	Pages = {73--80},
	Title = {Neonatal {EEG} at scalp is focal and implies high skull conductivity in realistic neonatal head models},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811914002626},
	Urldate = {2018-08-01},
	Volume = {96},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811914002626},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2014.04.007}}

@article{hassanpour_statistical_2014,
	Abstract = {High density diffuse optical tomography (HD-DOT) is a noninvasive neuroimaging modality with moderate spatial resolution and localization accuracy. Due to portability and wear-ability advantages, HD-DOT has the potential to be used in populations that are not amenable to functional magnetic resonance imaging (fMRI), such as hospitalized patients and young children. However, whereas the use of event-related stimuli designs, general linear model (GLM) analysis, and imaging statistics are standardized and routine with fMRI, such tools are not yet common practice in HD-DOT. In this paper we adapt and optimize fundamental elements of fMRI analysis for application to HD-DOT. We show the use of event-related protocols and GLM de-convolution analysis in un-mixing multi-stimuli event-related HD-DOT data. Statistical parametric mapping (SPM) in the framework of a general linear model is developed considering the temporal and spatial characteristics of HD-DOT data. The statistical analysis utilizes a random field noise model that incorporates estimates of the local temporal and spatial correlations of the GLM residuals. The multiple-comparison problem is addressed using a cluster analysis based on non-stationary Gaussian random field theory. These analysis tools provide access to a wide range of experimental designs necessary for the study of the complex brain functions. In addition, they provide a foundation for understanding and interpreting HD-DOT results with quantitative estimates for the statistical significance of detected activation foci.},
	Author = {Hassanpour, Mahlega S. and White, Brian R. and Eggebrecht, Adam T. and Ferradal, Silvina L. and Snyder, Abraham Z. and Culver, Joseph P.},
	Doi = {10.1016/j.neuroimage.2013.05.105},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IF6LX82J/Hassanpour et al. - 2014 - Statistical analysis of high density diffuse optic.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/LFMRM78R/S1053811913006083.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Diffuse optical tomography, General linear model, Non-stationary cluster analysis, Statistical parametric mapping},
	Month = jan,
	Pages = {104--116},
	Series = {Celebrating 20 {Years} of {Functional} {Near} {Infrared} {Spectroscopy} ({fNIRS})},
	Title = {Statistical analysis of high density diffuse optical tomography},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811913006083},
	Urldate = {2018-07-26},
	Volume = {85},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811913006083},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2013.05.105}}

@article{gilbert_developmental_2017,
	Abstract = {Developmental biology (including embryology) is proposed as "the stem cell of biological disciplines.'' Genetics, cell biology, oncology, immunology, evolutionary mechanisms, neurobiology, and systems biology each has its ancestry in developmental biology. Moreover, developmental biology continues to roll on, budding off more disciplines, while retaining its own identity. While its descendant disciplines differentiate into sciences with a restricted set of paradigms, examples, and techniques, developmental biology remains vigorous, pluripotent, and relatively undifferentiated. In many disciplines, especially in evolutionary biology and oncology, the developmental perspective is being reasserted as an important research program.},
	Author = {Gilbert, Scott F.},
	Doi = {10.1371/journal.pbio.2003691},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4GPK5CIN/Gilbert - 2017 - Developmental biology, the stem cell of biological.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Y8UH9EZW/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Cell biology, Developmental biology, Embryology, Evolutionary biology, Evolutionary developmental biology, Evolutionary genetics, Genetics, Oncology},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e2003691},
	Title = {Developmental biology, the stem cell of biological disciplines},
	Url = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2003691},
	Urldate = {2018-07-19},
	Volume = {15},
	Year = {2017},
	Bdsk-Url-1 = {http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2003691},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.2003691}}

@article{luo_concurrent_2006,
	Abstract = {A natural sound can be described by dynamic changes in envelope (amplitude) and carrier (frequency), corresponding to amplitude modulation (AM) and frequency modulation (FM), respectively. Although the neural responses to both AM and FM sounds are extensively studied in both animals and humans, it is uncertain how they are corepresented when changed simultaneously but independently, as is typical for ecologically natural signals. This study elucidates the neural coding of such sounds in human auditory cortex using magnetoencephalography (MEG). Using stimuli with both sinusoidal modulated envelope (ÆAM, 37 Hz) and carrier frequency (ÆFM, 0.3--8 Hz), it is demonstrated that AM and FM stimulus dynamics are corepresented in the neural code of human auditory cortex. The stimulus AM dynamics are represented neurally with AM encoding, by the auditory steady-state response (aSSR) at ÆAM. For sounds with slowly changing carrier frequency (ÆFM {\textless}5 Hz), it is shown that the stimulus FM dynamics are tracked by the phase of the aSSR, demonstrating neural phase modulation (PM) encoding of the stimulus carrier frequency. For sounds with faster carrier frequency change (ÆFM â¥ 5 Hz), it is shown that modulation encoding of stimulus FM dynamics persists, but the neural encoding is no longer purely PM. This result is consistent with the recruitment of additional neural AM encoding over and above the original neural PM encoding, indicating that both the amplitude and phase of the aSSR at ÆAM track the stimulus FM dynamics. A neural model is suggested to account for these observations.},
	Author = {Luo, Huan and Wang, Yadong and Poeppel, David and Simon, Jonathan Z.},
	Doi = {10.1152/jn.01256.2005},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LJZ88J9D/Luo et al. - 2006 - Concurrent Encoding of Frequency and Amplitude Mod.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8XZFNT38/jn.01256.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = nov,
	Number = {5},
	Pages = {2712--2723},
	Shorttitle = {Concurrent {Encoding} of {Frequency} and {Amplitude} {Modulation} in {Human} {Auditory} {Cortex}},
	Title = {Concurrent {Encoding} of {Frequency} and {Amplitude} {Modulation} in {Human} {Auditory} {Cortex}: {MEG} {Evidence}},
	Url = {https://www.physiology.org/doi/abs/10.1152/jn.01256.2005},
	Urldate = {2018-07-17},
	Volume = {96},
	Year = {2006},
	Bdsk-Url-1 = {https://www.physiology.org/doi/abs/10.1152/jn.01256.2005},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.01256.2005}}

@article{obleser_bilateral_2008,
	Abstract = {{\textless}p{\textgreater}Speech comprehension has been shown to be a strikingly bilateral process, but the differential contributions of the subfields of left and right auditory cortices have remained elusive. The hypothesis that left auditory areas engage predominantly in decoding fast temporal perturbations of a signal whereas the right areas are relatively more driven by changes of the frequency spectrum has not been directly tested in speech or music. This brain-imaging study independently manipulated the speech signal itself along the spectral and the temporal domain using noise-band vocoding. In a parametric design with five temporal and five spectral degradation levels in word comprehension, a functional distinction of the left and right auditory association cortices emerged: increases in the temporal detail of the signal were most effective in driving brain activation of the left anterolateral superior temporal sulcus (STS), whereas the right homolog areas exhibited stronger sensitivity to the variations in spectral detail. In accordance with behavioral measures of speech comprehension acquired in parallel, change of spectral detail exhibited a stronger coupling with the STS BOLD signal. The relative pattern of lateralization (quantified using lateralization quotients) proved reliable in a jack-knifed iterative reanalysis of the group functional magnetic resonance imaging model. This study supplies direct evidence to the often implied functional distinction of the two cerebral hemispheres in speech processing. Applying direct manipulations to the speech signal rather than to low-level surrogates, the results lend plausibility to the notion of complementary roles for the left and right superior temporal sulci in comprehending the speech signal.{\textless}/p{\textgreater}},
	Author = {Obleser, Jonas and Eisner, Frank and Kotz, Sonja A.},
	Copyright = {Copyright {\copyright} 2008 Society for Neuroscience 0270-6474/08/288116-08\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1290-08.2008},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/J5MD42MX/Obleser et al. - 2008 - Bilateral Speech Comprehension Reflects Differenti.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/C3I47BS2/tab-article-info.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = aug,
	Number = {32},
	Pages = {8116--8123},
	Pmid = {18685036},
	Title = {Bilateral {Speech} {Comprehension} {Reflects} {Differential} {Sensitivity} to {Spectral} and {Temporal} {Features}},
	Url = {http://www.jneurosci.org/content/28/32/8116},
	Urldate = {2018-07-17},
	Volume = {28},
	Year = {2008},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/28/32/8116},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1290-08.2008}}

@inproceedings{kawahara_tandem-straight:_2008,
	Abstract = {A simple new method for estimating temporally stable power spectra is introduced to provide a unified basis for computing an interference-free spectrum, the fundamental frequency (F0), as well as aperiodicity estimation. F0 adaptive spectral smoothing and cepstral liftering based on consistent sampling theory are employed for interference-free spectral estimation. A perturbation spectrum, calculated from temporally stable power and interference-free spectra, provides the basis for both F0 and aperiodicity estimation. The proposed approach eliminates ad-hoc parameter tuning and the heavy demand on computational power, from which STRAIGHT has suffered in the past.},
	Author = {Kawahara, H. and Morise, M. and Takahashi, T. and Nisimura, R. and Irino, T. and Banno, H.},
	Booktitle = {2008 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	Doi = {10.1109/ICASSP.2008.4518514},
	File = {IEEE Xplore Abstract Record:/Users/Cecile/Zotero/storage/97ZI4NMJ/4518514.html:text/html},
	Keywords = {Speech analysis, adaptive estimation, adaptive signal processing, adaptive spectral smoothing, aperiodicity estimation, cepstral analysis, cepstral liftering, consistent sampling, consistent sampling theory, Filters, Fourier transforms, Frequency estimation, Interference, interference (signal), interference-free spectral estimation, periodic signal, periodic signal power spectral representation, periodicity, perturbation spectrum, power spectrum, Sampling methods, signal sampling, Signal sampling, smoothing methods, speech processing, speech synthesis, Speech synthesis, TANDEM-STRAIGHT, Testing, Transfer functions},
	Month = mar,
	Pages = {3933--3936},
	Shorttitle = {Tandem-{STRAIGHT}},
	Title = {Tandem-{STRAIGHT}: {A} temporally stable power spectral representation for periodic signals and applications to interference-free spectrum, {F0}, and aperiodicity estimation},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICASSP.2008.4518514}}

@article{manju_association_2014,
	Abstract = {Amplitude modulations in the speech convey important acoustic information for speech perception. Auditory steady state response (ASSR) is thought to be physiological correlate of amplitude modulation perception. Limited research is available exploring association between ASSR and modulation detection ability as well as speech perception. Correlation of modulation detection thresholds (MDT) and speech perception in noise with ASSR was investigated in twofold experiments. 30 normal hearing individuals and 11 normal hearing individuals within age range of 18-24 years participated in experiments 1 and 2, respectively. MDTs were measured using ASSR and behavioral method at 60âHz, 80âHz, and 120âHz modulation frequencies in the first experiment. ASSR threshold was obtained by estimating the minimum modulation depth required to elicit ASSR (ASSR-MDT). There was a positive correlation between behavioral MDT and ASSR-MDT at all modulation frequencies. In the second experiment, ASSR for amplitude modulation (AM) sweeps at four different frequency ranges (30-40âHz, 40-50âHz, 50-60âHz, and 60-70âHz) was recorded. Speech recognition threshold in noise (SRTn) was estimated using staircase procedure. There was a positive correlation between amplitude of ASSR for AM sweep with frequency range of 30-40âHz and SRTn. Results of the current study suggest that ASSR provides substantial information about temporal modulation and speech perception.},
	Author = {Manju, Venugopal and Gopika, Kizhakke Kodiyath and Arivudai Nambi, Pitchai Muthu},
	Doi = {10.1155/2014/374035},
	Issn = {2090-5742},
	Journal = {ISRN otolaryngology},
	Language = {eng},
	Pages = {374035},
	Pmcid = {PMC4009337},
	Pmid = {25006511},
	Title = {Association of auditory steady state responses with perception of temporal modulations and speech in noise},
	Volume = {2014},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1155/2014/374035}}

@article{millman_spatiotemporal_2010,
	Abstract = {The aim of this study was to investigate the mechanisms involved in the perception of perceptually salient frequency modulation (FM) using auditory steady-state responses (ASSRs) measured with magnetoencephalography (MEG). Previous MEG studies using frequency-modulated amplitude modulation as stimuli (Luo et al., 2006, 2007) suggested that a phase modulation encoding mechanism exists for low ({\textless}5 Hz) FM modulation frequencies but additional amplitude modulation encoding is required for faster FM modulation frequencies. In this study single-cycle sinusoidal FM stimuli were used to generate the ASSR. The stimulus was either an unmodulated 1-kHz sinusoid or a 1-kHz sinusoid that was frequency-modulated with a repetition rate of 4, 8, or 12 Hz. The fast Fourier transform (FFT) of each MEG channel was calculated to obtain the phase and magnitude of the ASSR in sensor-space and multivariate Hotelling's T2 statistics were used to determine the statistical significance of ASSRs. MEG beamformer analyses were used to localise the ASSR sources. Virtual electrode analyses were used to reconstruct the time series at each source. FFTs of the virtual electrode time series were calculated to obtain the amplitude and phase characteristics of each source identified in the beamforming analyses. Multivariate Hotelling's T2 statistics were used to determine the statistical significance of these reconstructed ASSRs. The results suggest that the ability of auditory cortex to phase-lock to FM is dependent on the FM pulse rate and that the ASSR to FM is lateralised to the right hemisphere.},
	Author = {Millman, Rebecca E. and Prendergast, Garreth and Kitterick, P{\'a}draig T. and Woods, Will P. and Green, Gary G. R.},
	Doi = {10.1016/j.neuroimage.2009.08.029},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ATLYEQEL/Millman et al. - 2010 - Spatiotemporal reconstruction of the auditory stea.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KTMBGAYJ/S1053811909009410.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Auditory steady-state response, Beamforming, Frequency modulation, Magnetoencephalography, Phase-locking, Virtual electrodes},
	Month = jan,
	Number = {1},
	Pages = {745--758},
	Title = {Spatiotemporal reconstruction of the auditory steady-state response to frequency modulation using magnetoencephalography},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811909009410},
	Urldate = {2018-09-05},
	Volume = {49},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811909009410},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2009.08.029}}

@article{lewicki_efficient_2002,
	Abstract = {The auditory system encodes sound by decomposing the amplitude signal arriving at the ear into multiple frequency bands whose center frequencies and bandwidths are approximately exponential functions of the distance from the stapes. This organization is thought to result from the adaptation of cochlear mechanisms to the animal's auditory environment. Here we report that several basic auditory nerve fiber tuning properties can be accounted for by adapting a population of filter shapes to encode natural sounds efficiently. The form of the code depends on sound class, resembling a Fourier transformation when optimized for animal vocalizations and a wavelet transformation when optimized for non-biological environmental sounds. Only for the combined set does the optimal code follow scaling characteristics of physiological data. These results suggest that auditory nerve fibers encode a broad set of natural sounds in a manner consistent with information theoretic principles.},
	Author = {Lewicki, Michael S.},
	Copyright = {2002 Nature Publishing Group},
	Doi = {10.1038/nn831},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8P4PM49B/Lewicki - 2002 - Efficient coding of natural sounds.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZRKRECDG/nn831.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = apr,
	Number = {4},
	Pages = {356--363},
	Title = {Efficient coding of natural sounds},
	Url = {https://www.nature.com/articles/nn831},
	Urldate = {2018-09-02},
	Volume = {5},
	Year = {2002},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn831},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn831}}

@article{stilp_statistical_2013,
	Author = {Stilp, Christian E. and Lewicki, Michael S.},
	Doi = {10.1121/1.4865250},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6MLHRRM9/Stilp et Lewicki - 2013 - Statistical structure of speech sound classes is c.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NGJRX7SV/1.html:text/html},
	Journal = {Proceedings of Meetings on Acoustics},
	Month = dec,
	Number = {1},
	Pages = {050001},
	Title = {Statistical structure of speech sound classes is congruent with cochlear nucleus response properties},
	Url = {https://asa.scitation.org/doi/abs/10.1121/1.4865250},
	Urldate = {2018-09-02},
	Volume = {20},
	Year = {2013},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/abs/10.1121/1.4865250},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.4865250}}

@article{nelken_processing_2008,
	Abstract = {The coding of complex sounds in the early auditory system has a `standard model' based on the known physiology of the cochlea and main brainstem pathways. This model accounts for a wide range of perceptual capabilities. It is generally accepted that high cortical areas encode abstract qualities such as spatial location or speech sound identity. Between the early and late auditory system, the role of primary auditory cortex (A1) is still debated. A1 is clearly much more than a `whiteboard' of acoustic information---neurons in A1 have complex response properties, showing sensitivity to both low-level and high-level features of sounds.},
	Author = {Nelken, Israel},
	Doi = {10.1016/j.conb.2008.08.014},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QTB396WK/Nelken - 2008 - Processing of complex sounds in the auditory syste.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/WJYFQZ35/S0959438808000895.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = aug,
	Number = {4},
	Pages = {413--417},
	Series = {Sensory systems},
	Title = {Processing of complex sounds in the auditory system},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438808000895},
	Urldate = {2018-09-02},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438808000895},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2008.08.014}}

@article{nelken_processing_2004,
	Abstract = {Neuronal responses in auditory cortex show a fascinating mixture of characteristics that span the range from almost perfect copies of physical aspects of the stimuli to extremely complex context-dependent responses. Fast, highly stimulus-specific adaptation and slower plastic mechanisms work together to constantly adjust neuronal response properties to the statistics of the auditory scene. Evidence with converging implications suggests that the neuronal activity in primary auditory cortex represents sounds in terms of auditory objects rather than in terms of invariant acoustic features.},
	Author = {Nelken, Israel},
	Doi = {10.1016/j.conb.2004.06.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YFUGFF23/Nelken - 2004 - Processing of complex stimuli and natural scenes i.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JGPY5RRQ/S0959438804000947.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = aug,
	Number = {4},
	Pages = {474--480},
	Title = {Processing of complex stimuli and natural scenes in the auditory cortex},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438804000947},
	Urldate = {2018-09-02},
	Volume = {14},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438804000947},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2004.06.005}}

@article{walker_multiplexed_2011,
	Abstract = {We can recognize the melody of a familiar song when it is played on different musical instruments. Similarly, an animal must be able to recognize a warning call whether the caller has a high-pitched female or a lower-pitched male voice, and whether they are sitting in a tree to the left or right. This type of perceptual invariance to ``nuisance'' parameters comes easily to listeners, but it is unknown whether or how such robust representations of sounds are formed at the level of sensory cortex. In this study, we investigate whether neurons in both core and belt areas of ferret auditory cortex can robustly represent the pitch, formant frequencies, or azimuthal location of artificial vowel sounds while the other two attributes vary. We found that the spike rates of the majority of cortical neurons that are driven by artificial vowels carry robust representations of these features, but the most informative temporal response windows differ from neuron to neuron and across five auditory cortical fields. Furthermore, individual neurons can represent multiple features of sounds unambiguously by independently modulating their spike rates within distinct time windows. Such multiplexing may be critical to identifying sounds that vary along more than one perceptual dimension. Finally, we observed that formant information is encoded in cortex earlier than pitch information, and we show that this time course matches ferrets' behavioral reaction time differences on a change detection task.},
	Author = {Walker, Kerry M. M. and Bizley, Jennifer K. and King, Andrew J. and Schnupp, Jan W. H.},
	Copyright = {Copyright {\copyright} 2011 the authors 0270-6474/11/3114565-12\$15.00/0},
	Doi = {10.1523/JNEUROSCI.2074-11.2011},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UYK6ZZTY/Walker et al. - 2011 - Multiplexed and Robust Representations of Sound Fe.pdf:application/pdf},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = oct,
	Number = {41},
	Pages = {14565--14576},
	Pmid = {21994373},
	Title = {Multiplexed and {Robust} {Representations} of {Sound} {Features} in {Auditory} {Cortex}},
	Url = {http://www.jneurosci.org/content/31/41/14565},
	Urldate = {2018-09-02},
	Volume = {31},
	Year = {2011},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/31/41/14565},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2074-11.2011}}

@article{delorme_eeglab:_2004,
	Abstract = {We have developed a toolbox and graphic user interface, EEGLAB, running under the crossplatform MATLAB environment (The Mathworks, Inc.) for processing collections of single-trial and/or averaged EEG data of any number of channels. Available functions include EEG data, channel and event information importing, data visualization (scrolling, scalp map and dipole model plotting, plus multi-trial ERP-image plots), preprocessing (including artifact rejection, filtering, epoch selection, and averaging), independent component analysis (ICA) and time/frequency decompositions including channel and component cross-coherence supported by bootstrap statistical methods based on data resampling. EEGLAB functions are organized into three layers. Top-layer functions allow users to interact with the data through the graphic interface without needing to use MATLAB syntax. Menu options allow users to tune the behavior of EEGLAB to available memory. Middle-layer functions allow users to customize data processing using command history and interactive `pop' functions. Experienced MATLAB users can use EEGLAB data structures and stand-alone signal processing functions to write custom and/or batch analysis scripts. Extensive function help and tutorial information are included. A `plug-in' facility allows easy incorporation of new EEG modules into the main menu. EEGLAB is freely available (http://www.sccn.ucsd.edu/eeglab/) under the GNU public license for noncommercial use and open source development, together with sample data, user tutorial and extensive documentation.},
	Author = {Delorme, Arnaud and Makeig, Scott},
	Doi = {10.1016/j.jneumeth.2003.10.009},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/78SGQRG6/Delorme et Makeig - 2004 - EEGLAB an open source toolbox for analysis of sin.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9GSLXCTP/S0165027003003479.html:text/html},
	Issn = {0165-0270},
	Journal = {Journal of Neuroscience Methods},
	Keywords = {EEG, Software, ERP, ICA, Matlab, Single-trial, Spectral decomposition},
	Month = mar,
	Number = {1},
	Pages = {9--21},
	Shorttitle = {{EEGLAB}},
	Title = {{EEGLAB}: an open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
	Url = {http://www.sciencedirect.com/science/article/pii/S0165027003003479},
	Urldate = {2018-08-29},
	Volume = {134},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0165027003003479},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jneumeth.2003.10.009}}

@article{cohen_where_2017,
	Abstract = {Electroencephalography (EEG) has been instrumental in making discoveries about cognition, brain function, and dysfunction. However, where do EEG signals come from and what do they mean? The purpose of this paper is to argue that we know shockingly little about the answer to this question, to highlight what we do know, how important the answers are, and how modern neuroscience technologies that allow us to measure and manipulate neural circuits with high spatiotemporal accuracy might finally bring us some answers. Neural oscillations are perhaps the best feature of EEG to use as anchors because oscillations are observed and are studied at multiple spatiotemporal scales of the brain, in multiple species, and are widely implicated in cognition and in neural computations.},
	Author = {Cohen, Michael X},
	Doi = {10.1016/j.tins.2017.02.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/VRCVKT2Y/Cohen - 2017 - Where Does EEG Come From and What Does It Mean.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ILF44DKQ/S0166223617300243.html:text/html},
	Issn = {0166-2236},
	Journal = {Trends in Neurosciences},
	Keywords = {EEG, computation, electrophysiology, neural microcircuit, oscillations},
	Month = apr,
	Number = {4},
	Pages = {208--218},
	Title = {Where {Does} {EEG} {Come} {From} and {What} {Does} {It} {Mean}?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0166223617300243},
	Urldate = {2018-08-28},
	Volume = {40},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223617300243},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2017.02.004}}

@article{cohen_its_2011,
	Author = {Cohen, Michael X},
	Doi = {10.3389/fnhum.2011.00002},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/IDACVXDE/Cohen - 2011 - It's about Time.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = jan,
	Pmcid = {PMC3025647},
	Pmid = {21267395},
	Title = {It's about {Time}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025647/},
	Urldate = {2018-08-28},
	Volume = {5},
	Year = {2011},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025647/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2011.00002}}

@article{grossmann_detection_2010,
	Abstract = {A precondition for successful communication between people is the detection of signals indicating the intention to communicate, such as eye contact or calling a person's name. In adults, establishing communication by eye contact or calling a person's name results in overlapping activity in right prefrontal cortex, suggesting that, regardless of modality, the intention to communicate is detected by the same brain region. We measured prefrontal cortex responses in 5-month-olds using near-infrared spectroscopy (NIRS) to examine the neural basis of detecting communicative signals across modalities in early development. Infants watched human faces that either signaled eye contact or directed their gaze away from the infant, and they also listened to voices that addressed them with their own name or another name. The results revealed that infants recruit adjacent but non-overlapping regions in the left dorsal prefrontal cortex when they process eye contact and own name. Moreover, infants that responded sensitively to eye contact in the one prefrontal region were also more likely to respond sensitively to their own name in the adjacent prefrontal region as revealed in a correlation analysis, suggesting that responding to communicative signals in these two regions might be functionally related. These NIRS results suggest that infants selectively process and attend to communicative signals directed at them. However, unlike adults, infants do not seem to recruit a common prefrontal region when processing communicative signals of different modalities. The implications of these findings for our understanding of infants' developing communicative abilities are discussed.},
	Author = {Grossmann, Tobias and Parise, Eugenio and Friederici, Angela D.},
	Doi = {10.3389/fnhum.2010.00201},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/64VG8I67/Grossmann et al. - 2010 - The Detection of Communicative Signals Directed at.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Month = oct,
	Pmcid = {PMC2981376},
	Pmid = {21088694},
	Title = {The {Detection} of {Communicative} {Signals} {Directed} at the {Self} in {Infant} {Prefrontal} {Cortex}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2981376/},
	Urldate = {2017-12-14},
	Volume = {4},
	Year = {2010},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2981376/},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2010.00201}}

@article{taga_spatiotemporal_2011,
	Abstract = {Multi-channel near-infrared spectroscopy (NIRS) has been used as a neuroimaging tool to study functional activation of the developing brain in infants. In this paper, we focus on spatiotemporal dynamics of cortical oxygenation changes during sensory processing in young infants. We use a 94-channel NIRS system to assess the activity of wide regions of the cortex in quietly sleeping three-month-old infants. Auditory stimuli composed of a random sequence of pure tones induced haemodynamic changes not only in the temporal auditory regions, but also in the occipital and frontal regions. Analyses of phase synchronization showed that mutual synchronizations of signal changes among the cortical regions were much stronger than the stimulus-induced synchronizations of signal changes. Furthermore, analyses of phase differences among cortical regions revealed phase advancement of the bilateral temporal auditory regions, and phase gradient in a posterior direction from the temporal auditory regions to the occipital regions and in an anterior direction within the frontal regions. We argue that multi-channel NIRS is capable of detecting the precise timing of cortical activation and its flow in the global network of the developing brain.},
	Author = {Taga, Gentaro and Watanabe, Hama and Homae, Fumitaka},
	Copyright = {This journal is {\copyright} 2011 The Royal Society},
	Doi = {10.1098/rsta.2011.0238},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/XDK3GG9E/Taga et al. - 2011 - Spatiotemporal properties of cortical haemodynamic.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3NG7QYSH/4495.html:text/html},
	Issn = {1364-503X, 1471-2962},
	Journal = {Phil. Trans. R. Soc. A},
	Language = {en},
	Month = nov,
	Number = {1955},
	Pages = {4495--4511},
	Pmid = {22006903},
	Title = {Spatiotemporal properties of cortical haemodynamic response to auditory stimuli in sleeping infants revealed by multi-channel near-infrared spectroscopy},
	Url = {http://rsta.royalsocietypublishing.org/content/369/1955/4495},
	Urldate = {2017-08-15},
	Volume = {369},
	Year = {2011},
	Bdsk-Url-1 = {http://rsta.royalsocietypublishing.org/content/369/1955/4495},
	Bdsk-Url-2 = {https://doi.org/10.1098/rsta.2011.0238}}

@book{pike_intonation_1945,
	Author = {Pike, Kenneth Lee},
	Language = {en},
	Note = {Google-Books-ID: Jz3iAAAAMAAJ},
	Publisher = {University of Michigan Press},
	Title = {The {Intonation} of {American} {English}},
	Year = {1945}}

@article{anders_standardized_1971,
	Author = {Anders, T.F. and {Emde, R.} and {Parmelee, A. A.}},
	Journal = {UCLA Brain Information Service},
	Title = {A standardized terminology, techniques and criteria for scoring states of sleep and wakefulness},
	Year = {1971}}

@article{martynova_mismatch_2003,
	Abstract = {Event-related potentials were recorded from sleeping newborns to compare amplitudes and latencies of mismatch negativity (MMN) and late discriminative negativity (LDN) in active and quiet sleep stages. MMN and LDN were obtained in response to changes in semi-synthesized vowels from 20 healthy newborn infants. MMN and LDN responses were significant for both active and quiet sleep. The amplitude and latency of MMN or LDN did not differ between the sleep stages. Thus, in contrast to adult studies that show a significant drop in the MMN amplitude and an increase in the MMN latency as the sleep gets deeper, arousal stages do not seem to effect either MMN or LDN characteristics in newborns. These results suggest functional differences between infant and adult sleep.},
	Author = {Martynova, Olga and Kirjavainen, Jarkko and Cheour, Marie},
	Doi = {10.1016/S0304-3940(02)01401-5},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/SQX549J4/Martynova et al. - 2003 - Mismatch negativity and late discriminative negati.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZA6MH2I7/S0304394002014015.html:text/html},
	Issn = {0304-3940},
	Journal = {Neuroscience Letters},
	Keywords = {Sleep, Mismatch negativity, Event-related potential, Late discriminative negativity, Newborns},
	Month = apr,
	Number = {2},
	Pages = {75--78},
	Title = {Mismatch negativity and late discriminative negativity in sleeping human newborns},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304394002014015},
	Urldate = {2018-08-25},
	Volume = {340},
	Year = {2003},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394002014015},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0304-3940(02)01401-5}}

@article{plonsey_considerations_1967,
	Abstract = {Conditions under which a time varying electromagnetic field problem (such as arises in electrophysiology, electrocardiography, etc.) can be reduced to the conventional quasistatic problem are summarized. These conditions are discussed for typical physiological parameters.},
	Author = {Plonsey, Robert and Heppner, Dennis B.},
	Doi = {10.1007/BF02476917},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/Y9XDD3LV/Plonsey et Heppner - 1967 - Considerations of quasi-stationarity in electrophy.pdf:application/pdf},
	Issn = {1522-9602},
	Journal = {The bulletin of mathematical biophysics},
	Keywords = {Effect Neglect, Electrophysiological System, Normal Electric Field, Scalar Helmholtz Equation, Secondary Field},
	Language = {en},
	Month = dec,
	Number = {4},
	Pages = {657--664},
	Title = {Considerations of quasi-stationarity in electrophysiological systems},
	Url = {https://doi.org/10.1007/BF02476917},
	Urldate = {2018-08-25},
	Volume = {29},
	Year = {1967},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF02476917}}

@book{nunez_electric_2006,
	Abstract = {Electroencephalography (EEG) is practiced by neurologists, cognitive neuroscientists, and others interested in functional brain imaging. Whether for clinical or experimental purposes, all studies share a common purpose-to relate scalp potentials to the underlying neurophysiology. Electrical potentials on the scalp exhibit spatial and temporal patterns that depend on the nature and location of the sources and the way that currents and fields spread through tissue. Because these dynamic patterns are correlated with behavior and cognition, EEG provides a "window on the mind," correlating physiology and psychology. This classic and widely acclaimed text, originally published in 1981, filled the large gap between EEG and the physical sciences. It has now been brought completely up to date and will again serve as an invaluable resource for understanding the principles of electric fields in living tissue and for using hard science to study human consciousness and cognition. No comparable volume exists for it is no easy task to explain the problems of EEG in clear language, with mathematics presented mainly in appendices. Among the many topics covered by the Second Edition are micro and meso (intermediate scale) synaptic sources, electrode placement, choice of reference, volume conduction, power and coherence measures, projection of scalp potentials to dura surface, dynamic signatures of conscious experience, neural networks immersed in global fields of synaptic action, and physiological bases for brain source dynamics. The Second Edition is an invaluable resource for neurologists, neuroscientists (especially cognitive neuroscientists), biomedical engineers, and their students and trainees. It will also appeal to physicists, mathematicians, computer scientists, psychiatrists, and industrial engineers interested in EEG.},
	Author = {Nunez, Paul L. and Nunez, Emeritus Professor of Biomedical Engineering Paul L. and Srinivasan, Ramesh and Srinivasan, Assistant Professor of Cognitive Science Ramesh},
	Isbn = {978-0-19-505038-7},
	Keywords = {Medical / Neurology, Medical / Neuroscience},
	Language = {en},
	Note = {Google-Books-ID: fUv54as56\_8C},
	Publisher = {Oxford University Press},
	Shorttitle = {Electric {Fields} of the {Brain}},
	Title = {Electric {Fields} of the {Brain}: {The} {Neurophysics} of {EEG}},
	Year = {2006}}

@article{munck_how_2010,
	Author = {Munck, Jan C. de and Bijma, Fetsje},
	Doi = {10.1016/j.clinph.2009.10.002},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/H6SDK7T4/Munck et Bijma - 2010 - How are evoked responses generated The need for a.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XQNLHMRL/S1388245709005811.html:text/html},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology},
	Month = feb,
	Number = {2},
	Pages = {127--129},
	Shorttitle = {How are evoked responses generated?},
	Title = {How are evoked responses generated? {The} need for a unified mathematical framework},
	Url = {http://www.sciencedirect.com/science/article/pii/S1388245709005811},
	Urldate = {2018-08-25},
	Volume = {121},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245709005811},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2009.10.002}}

@book{cohen_analyzing_2014,
	Abstract = {A comprehensive guide to the conceptual, mathematical, and implementational aspects of analyzing electrical brain signals, including data from MEG, EEG, and LFP recordings.
                This book offers a comprehensive guide to the theory and practice of analyzing electrical brain signals. It explains the conceptual, mathematical, and implementational (via Matlab programming) aspects of time-, time-frequency- and synchronization-based analyses of magnetoencephalography (MEG), electroencephalography (EEG), and local field potential (LFP) recordings from humans and nonhuman animals. It is the only book on the topic that covers both the theoretical background and the implementation in language that can be understood by readers without extensive formal training in mathematics, including cognitive scientists, neuroscientists, and psychologists.Readers who go through the book chapter by chapter and implement the examples in Matlab will develop an understanding of why and how analyses are performed, how to interpret results, what the methodological issues are, and how to perform single-subject-level and group-level analyses. Researchers who are familiar with using automated programs to perform advanced analyses will learn what happens when they click the ``analyze now'' button.The book provides sample data and downloadable Matlab code. Each of the 38 chapters covers one analysis topic, and these topics progress from simple to advanced. Most chapters conclude with exercises that further develop the material covered in the chapter. Many of the methods presented (including convolution, the Fourier transform, and Euler's formula) are fundamental and form the groundwork for other advanced data analysis methods. Readers who master the methods in the book will be well prepared to learn other approaches.},
	Address = {Cambridge, Mass.},
	Author = {Cohen, Mike X},
	File = {Snapshot:/Users/Cecile/Zotero/storage/BWT4W7V4/analyzing-neural-time-series-data.html:text/html},
	Isbn = {978-0-262-01987-3},
	Language = {en},
	Month = jan,
	Publisher = {MIT Press},
	Series = {Issues in {Clinical} and {Cognitive} {Neuropsychology}},
	Shorttitle = {Analyzing {Neural} {Time} {Series} {Data}},
	Title = {Analyzing {Neural} {Time} {Series} {Data}: {Theory} and {Practice}},
	Url = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data},
	Urldate = {2018-08-25},
	Year = {2014},
	Bdsk-Url-1 = {https://mitpress.mit.edu/books/analyzing-neural-time-series-data}}

@book{luck_introduction_2014,
	Abstract = {An essential guide to designing, conducting, and analyzing event-related potential (ERP) experiments, completely updated for this edition.
                The event-related potential (ERP) technique, in which neural responses to specific events are extracted from the EEG, provides a powerful noninvasive tool for exploring the human brain. This volume describes practical methods for ERP research along with the underlying theoretical rationale. It offers researchers and students an essential guide to designing, conducting, and analyzing ERP experiments. This second edition has been completely updated, with additional material, new chapters, and more accessible explanations. Freely available supplementary material, including several online-only chapters, offer expanded or advanced treatment of selected topics.The first half of the book presents essential background information, describing the origins of ERPs, the nature of ERP components, and the design of ERP experiments. The second half of the book offers a detailed treatment of the main steps involved in conducting ERP experiments, covering such topics as recording the EEG, filtering the EEG and ERP waveforms, and quantifying amplitudes and latencies. Throughout, the emphasis is on rigorous experimental design and relatively simple analyses. New material in the second edition includes entire chapters devoted to components, artifacts, measuring amplitudes and latencies, and statistical analysis; updated coverage of recording technologies; concrete examples of experimental design; and many more figures. Online chapters cover such topics as overlap, localization, writing and reviewing ERP papers, and setting up and running an ERP lab.},
	Address = {Cambridge, Mass.},
	Author = {Luck, Steven J.},
	Edition = {2nd edition},
	File = {Snapshot:/Users/Cecile/Zotero/storage/6K96Z5CT/introduction-event-related-potential-technique-second-edition.html:text/html},
	Isbn = {978-0-262-52585-5},
	Language = {en},
	Publisher = {MIT press},
	Title = {An {Introduction} to the {Event}-{Related} {Potential} {Technique}, {Second} {Edition}},
	Url = {https://mitpress.mit.edu/books/introduction-event-related-potential-technique-second-edition},
	Urldate = {2018-08-25},
	Year = {2014},
	Bdsk-Url-1 = {https://mitpress.mit.edu/books/introduction-event-related-potential-technique-second-edition}}

@article{buzsaki_nucleus_1988,
	Abstract = {EEG and single-unit techniques have been used to study the EEG correlates of cellular firing in the neocortex, n. reticularis (RT) and ``specific'' thalamic nuclei, and the cholinergic forebrain area (nucleus basalis, NB). Neuronal firing was related to the ongoing behavior of the rat. In addition, using a 16-channel neocortical recording/mapping system, we studied the effects of ibotenic acid lesion of NB, RT, and other thalamic nuclei on the patterns and spatial distribution of neocortical electrical activity. The majority of neurons in neocortex, NB, and RT increased their firing rates during walking, as compared to during immobility, with concurrent decrease of delta power in the neocortical EEG. During immobility, high-voltage spindles (HVS; greater than 1 mV) were occasionally recorded from the neocortex. Depth profiles of HVS and slow delta waves were different in the neocortex. Neocortical cells decreased their discharge frequency during the positive portion of delta waves recorded in layers V and VI. All cells in the neocortex and specific thalamic nuclei fired rhythmically and phase-locked to the spike component of HVS. RT neurons showed an opposite phase relationship and fired mainly during the wave component of HVS. Half of the NB neurons also showed phasic modulation with HVS. Circumscribed lesion of RT and extensive damage of other thalamic regions, including the intralaminar nuclei, suppressed HVS but had no effect on the neocortical EEG correlates of behavior. In sharp contrast, damage to the NB resulted in a dramatic increase of slow delta waves on the side of the lesion, mimicking the effect of scopolamine administration. We suggest that the NB plays a key role in neocortical arousal by directly activating the neocortex and by suppressing the rhythm generation in the RT-thalamocortical circuitry. We further suggest that the NB system may serve as a structural basis for the concept of the generalized ascending activation of Moruzzi and Magoun (1949).},
	Author = {Buzsaki, G. and Bickford, R. G. and Ponomareff, G. and Thal, L. J. and Mandel, R. and Gage, F. H.},
	Copyright = {{\copyright} 1988 by Society for Neuroscience},
	Doi = {10.1523/JNEUROSCI.08-11-04007.1988},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UYCRPH99/Buzsaki et al. - 1988 - Nucleus basalis and thalamic control of neocortica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K7MGNEL6/4007.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = nov,
	Number = {11},
	Pages = {4007--4026},
	Pmid = {3183710},
	Title = {Nucleus basalis and thalamic control of neocortical activity in the freely moving rat},
	Url = {http://www.jneurosci.org/content/8/11/4007},
	Urldate = {2018-08-25},
	Volume = {8},
	Year = {1988},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/8/11/4007},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.08-11-04007.1988}}

@article{gervain_speech_2010,
	Abstract = {During the first year of life, infants pass important milestones in language development. We review some of the experimental evidence concerning these milestones in the domains of speech perception, phonological development, word learning, morphosyntactic acquisition, and bilingualism, emphasizing their interactions. We discuss them in the context of their biological underpinnings, introducing the most recent advances not only in language development, but also in neighboring areas such as genetics and the comparative research on animal communication systems. We argue for a theory of language acquisition that integrates behavioral, cognitive, neural, and evolutionary considerations and proposes to unify previously opposing theoretical stances, such as statistical learning, rule-based nativist accounts, and perceptual learning theories.},
	Author = {Gervain, Judit and Mehler, Jacques},
	Doi = {10.1146/annurev.psych.093008.100408},
	Journal = {Annual Review of Psychology},
	Number = {1},
	Pages = {191--218},
	Pmid = {19575623},
	Title = {Speech {Perception} and {Language} {Acquisition} in the {First} {Year} of {Life}},
	Url = {https://doi.org/10.1146/annurev.psych.093008.100408},
	Urldate = {2018-08-25},
	Volume = {61},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev.psych.093008.100408}}

@article{davidesco_electrocorticographic_2018,
	Abstract = {Human listeners understand spoken language across a variety of rates, but when speech is presented three times or more faster than its usual rate, it becomes unintelligible. How the brain achieves such tolerance and why speech becomes unintelligible above certain rates is still unclear. We addressed these questions using electrocorticography (ECoG) recordings in 7 epileptic patients (two female). Patients rated the intelligibility of sentences presented at the original rate (100\%), speeded rates (33\% or 66\% of the original sentence duration) and a slowed rate (150\%). We then examined which parameters of the neural response covary with the transition from intelligible to unintelligible speech. Specifically, we asked whether neural responses: 1) track the acoustic envelope of the incoming speech; 2) scale with speech rate, i.e. whether neural responses elicited by slowed and speeded sentences can be linearly scaled to match the responses to the original sentence. Behaviorally, intelligibility was at ceiling for speech rates of 66\% and above, but dropped significantly for the 33\% rate. At the neural level, Superior Temporal Gyrus regions (STG) in close proximity to A1 (low-level) tracked the acoustic envelope and linearly scaled with the input across all speech rates, irrespective of intelligibility. In contrast, secondary auditory areas in the STG as well as the inferior frontal gyrus and angular gyrus (high-level) tracked the acoustic envelope and linearly scaled with input only for intelligible speech. These results help reconcile seemingly contradictory previous findings and provide better understanding of how information processing unfolds along the cortical auditory hierarchy.},
	Author = {Davidesco, Ido and Thesen, Thomas and Honey, Christopher J. and Melloni, Lucia and Doyle, Werner and Devinsky, Orrin and Ghitza, Oded and Schroeder, Charles and Poeppel, David and Hasson, Uri},
	Copyright = {{\copyright} 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	Doi = {10.1101/354464},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/V56YX6D5/Davidesco et al. - 2018 - Electrocorticographic responses to time-compressed.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/JXW2P7HC/354464.html:text/html},
	Issn = {10.1101/354464},
	Journal = {bioRxiv},
	Language = {en},
	Month = jun,
	Pages = {354464},
	Title = {Electrocorticographic responses to time-compressed speech vary across the cortical auditory hierarchy},
	Url = {https://www.biorxiv.org/content/early/2018/06/22/354464},
	Urldate = {2018-08-25},
	Year = {2018},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2018/06/22/354464},
	Bdsk-Url-2 = {https://doi.org/10.1101/354464}}

@article{zhang_achieving_2013,
	Abstract = {This event-related potential (ERP) study examines the time course of context-dependent talker normalization in spoken word identification. We found three ERP components, the N1 (100--220ms), the N400 (250--500ms) and the Late Positive Component (500--800ms), which are conjectured to involve (a) auditory processing, (b) talker normalization and lexical retrieval, and (c) decisional process/lexical selection respectively. Talker normalization likely occurs in the time window of the N400 and overlaps with the lexical retrieval process. Compared with the nonspeech context, the speech contexts, no matter whether they have semantic content or not, enable listeners to tune to a talker's pitch range. In this way, speech contexts induce more efficient talker normalization during the activation of potential lexical candidates and lead to more accurate selection of the intended word in spoken word identification.},
	Author = {Zhang, Caicai and Peng, Gang and Wang, William S. -Y.},
	Doi = {10.1016/j.bandl.2013.05.010},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/FNQGL3CJ/Zhang et al. - 2013 - Achieving constancy in spoken word identification.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MSX3DM6B/S0093934X13001089.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Keywords = {Event-related potential, Cantonese, Context, Late Positive Component, Level tones, N1, N400, Talker normalization, Tone perception},
	Month = aug,
	Number = {2},
	Pages = {193--202},
	Shorttitle = {Achieving constancy in spoken word identification},
	Title = {Achieving constancy in spoken word identification: {Time} course of talker normalization},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X13001089},
	Urldate = {2018-08-25},
	Volume = {126},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X13001089},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2013.05.010}}

@article{joos_acoustic_1948,
	Author = {Joos, Martin A.},
	Journal = {Language},
	Number = {2},
	Pages = {1--136},
	Title = {Acoustic phonetics.},
	Volume = {24},
	Year = {1948}}

@article{diliberto_low-frequency_2015,
	Abstract = {Summary
The human ability to understand speech is underpinned by a hierarchical auditory system whose successive stages process increasingly complex attributes of the acoustic input. It has been suggested that to produce categorical speech perception, this system must elicit consistent neural responses to speech tokens (e.g., phonemes) despite variations in their acoustics. Here, using electroencephalography (EEG), we provide evidence for this categorical phoneme-level speech processing by showing that the relationship between continuous speech and neural activity is best described when that speech is represented using both low-level spectrotemporal information and categorical labeling of phonetic features. Furthermore, the mapping between phonemes and EEG becomes more discriminative for phonetic features at longer latencies, in line with what one might expect from a hierarchical system. Importantly, these effects are not seen for time-reversed speech. These findings may form the basis for future research on natural language processing in specific cohorts of interest and for broader insights into how brains transform acoustic input into meaning.},
	Author = {Di Liberto, Giovanni M. and O'Sullivan, James A. and Lalor, Edmund C.},
	Doi = {10.1016/j.cub.2015.08.030},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4P5T6T39/Di Liberto et al. - 2015 - Low-Frequency Cortical Entrainment to Speech Refle.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/I8TIBFS5/S0960982215010015.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Month = oct,
	Number = {19},
	Pages = {2457--2465},
	Title = {Low-{Frequency} {Cortical} {Entrainment} to {Speech} {Reflects} {Phoneme}-{Level} {Processing}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982215010015},
	Urldate = {2018-08-25},
	Volume = {25},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982215010015},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2015.08.030}}

@article{potter_toward_1950,
	Author = {Potter, R. K. and Steinberg, J. C.},
	Doi = {10.1121/1.1906694},
	File = {Potter et Steinberg - 1950 - Toward the Specification of Speech.pdf:/Users/Cecile/Zotero/storage/MHJ7B29F/Potter et Steinberg - 1950 - Toward the Specification of Speech.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MZZPQVRJ/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = nov,
	Number = {6},
	Pages = {807--820},
	Title = {Toward the {Specification} of {Speech}},
	Url = {https://asa.scitation.org/doi/10.1121/1.1906694},
	Urldate = {2018-08-25},
	Volume = {22},
	Year = {1950},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.1906694},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.1906694}}

@article{goswami_speech_2013,
	Author = {Goswami, Usha and Leong, Victoria},
	Doi = {10.1515/lp-2013-0004},
	File = {Goswami et Leong - 2013 - Speech rhythm and temporal structure Converging p.pdf:/Users/Cecile/Zotero/storage/22GSBEMY/Goswami et Leong - 2013 - Speech rhythm and temporal structure Converging p.pdf:application/pdf},
	Issn = {1868-6354, 1868-6346},
	Journal = {Laboratory Phonology},
	Language = {en},
	Month = jan,
	Number = {1},
	Shorttitle = {Speech rhythm and temporal structure},
	Title = {Speech rhythm and temporal structure: {Converging} perspectives?},
	Url = {https://www.degruyter.com/view/j/lp.2013.4.issue-1/lp-2013-0004/lp-2013-0004.xml},
	Urldate = {2018-08-25},
	Volume = {4},
	Year = {2013},
	Bdsk-Url-1 = {https://www.degruyter.com/view/j/lp.2013.4.issue-1/lp-2013-0004/lp-2013-0004.xml},
	Bdsk-Url-2 = {https://doi.org/10.1515/lp-2013-0004}}

@article{ding_temporal_2017,
	Abstract = {Speech and music have structured rhythms. Here we discuss a major acoustic correlate of spoken and musical rhythms, the slow (0.25--32Hz) temporal modulations in sound intensity and compare the modulation properties of speech and music. We analyze these modulations using over 25h of speech and over 39h of recordings of Western music. We show that the speech modulation spectrum is highly consistent across 9 languages (including languages with typologically different rhythmic characteristics). A different, but similarly consistent modulation spectrum is observed for music, including classical music played by single instruments of different types, symphonic, jazz, and rock. The temporal modulations of speech and music show broad but well-separated peaks around 5 and 2Hz, respectively. These acoustically dominant time scales may be intrinsic features of speech and music, a possibility which should be investigated using more culturally diverse samples in each domain. Distinct modulation timescales for speech and music could facilitate their perceptual analysis and its neural processing.},
	Author = {Ding, Nai and Patel, Aniruddh D. and Chen, Lin and Butler, Henry and Luo, Cheng and Poeppel, David},
	Doi = {10.1016/j.neubiorev.2017.02.011},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/4YQCEE88/Ding et al. - 2017 - Temporal modulations in speech and music.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4ZD2FV9A/S0149763416305668.html:text/html},
	Issn = {0149-7634},
	Journal = {Neuroscience \& Biobehavioral Reviews},
	Keywords = {Music, Rhythm, Speech, Modulation spectrum, Temporal modulations},
	Month = oct,
	Pages = {181--187},
	Series = {The {Biology} of {Language}},
	Title = {Temporal modulations in speech and music},
	Url = {http://www.sciencedirect.com/science/article/pii/S0149763416305668},
	Urldate = {2018-08-25},
	Volume = {81},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0149763416305668},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neubiorev.2017.02.011}}

@book{chiba_vowel:_1941,
	Author = {Chiba, Tsutomu and Kajiyama, Masato},
	Language = {en},
	Note = {Google-Books-ID: tpkKAAAAMAAJ},
	Publisher = {Tokyo-Kaiseikan},
	Shorttitle = {The vowel},
	Title = {The vowel: its nature and structure},
	Year = {1941}}

@book{moore_introduction_2012,
	Abstract = {Now available in a sixth edition, An Introduction to the Psychology of Hearing is the leading textbook in the field of auditory perception, also known as psychoacoustics.The textbooks longevity and loyal readership can be attributed to the accessible manner in which it describes the relationships between the characteristics of the sounds that enter the ear and the sensations that they produce. Wherever possible, the author has specified these relationships in terms of the underlying mechanisms. The intention is to impart an understanding of what the auditory system does and how it works: research results are not just described, but are interpreted and evaluated; knowledge is not assumed, but deduced from basic principles. Topics covered include the physics of sound, the physiology of the auditory system, frequency selectivity and masking, loudness perception, temporal analysis, pitch perception, sound localization, timbre perception, the perceptual organization of complex auditory scenes, speech perception, and practical applications such as hearing aids, cochlear implants, and high-fidelity sound reproduction. The book also includes extensive references to recent research so that those interested in a specific area can readily obtain more detailed information.},
	Author = {Moore, Brian C. J.},
	Isbn = {978-1-78052-038-4},
	Keywords = {Science / Life Sciences / Neuroscience, Psychology / Cognitive Psychology \& Cognition, Science / Acoustics \& Sound},
	Language = {en},
	Note = {Google-Books-ID: LM9U8e28pLMC},
	Publisher = {BRILL},
	Title = {An {Introduction} to the {Psychology} of {Hearing}},
	Year = {2012}}

@article{benavides-varela_learning_2017,
	Abstract = {In language, the relative order of words in sentences carries important grammatical functions. However, the developmental origins and the neural correlates of the ability to track word order are to date poorly understood. The current study therefore investigates the origins of infants' ability to learn about the sequential order of words, using near-infrared spectroscopy (NIRS) with newborn infants. We have conducted two experiments: one in which a word order change was implemented in 4-word sequences recorded with a list intonation (as if each word was a separate item in a list; list prosody condition, Experiment 1) and one in which the same 4-word sequences were recorded with a well-formed utterance-level prosodic contour (utterance prosody condition, Experiment 2). We found that newborns could detect the violation of the word order in the list prosody condition, but not in the utterance prosody condition. These results suggest that while newborns are already sensitive to word order in linguistic sequences, prosody appears to be a stronger cue than word order for the identification of linguistic units at birth.},
	Author = {Benavides-Varela, Silvia and Gervain, Judit},
	Doi = {10.1016/j.dcn.2017.03.003},
	Issn = {1878-9307},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Newborn infants, Female, Humans, Infant, Newborn, Male, Spectroscopy, Near-Infrared, Verbal Learning, Prosody, Near-infrared spectroscopy, Language, Word order},
	Language = {eng},
	Pages = {198--208},
	Pmid = {28351534},
	Shorttitle = {Learning word order at birth},
	Title = {Learning word order at birth: {A} {NIRS} study},
	Volume = {25},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.dcn.2017.03.003}}

@article{holmes_nonparametric_1996,
	Abstract = {The analysis of functional mapping experiments in positron emission tomography involves the formation of images displaying the values of a suitable statistic, summarising the evidence in the data for a particular effect at each voxel. These statistic images must then be scrutinised to locate regions showing statistically significant effects. The methods most commonly used are parametric, assuming a particular form of probability distribution for the voxel values in the statistic image. Scientific hypotheses, formulated in terms of parameters describing these distributions, are then tested on the basis of the assumptions. Images of statistics are usually considered as lattice representations of continuous random fields. These are more amenable to statistical analysis. There are various shortcomings associated with these methods of analysis. The many assumptions and approximations involved may not be true. The low numbers of subjects and scans, in typical experiments, lead to noisy statistic images with low degrees of freedom, which are not well approximated by continuous random fields. Thus, the methods are only approximately valid at best and are most suspect in single-subject studies. In contrast to the existing methods, we present a nonparametric approach to significance testing for statistic images from activation studies. Formal assumptions are replaced by a computationally expensive approach. In a simple rest-activation study, if there is really no activation effect, the labelling of the scans as ``active'' or ``rest'' is artificial, and a statistic image formed with some other labelling is as likely as the observed one. Thus, considering all possible relabellings, a p value can be computed for any suitable statistic describing the statistic image. Consideration of the maximal statistic leads to a simple nonparametric single-threshold test. This randomisation test relies only on minimal assumptions about the design of the experiment, is (almost) exact, with Type I error (almost) exactly that specified, and hence is always valid. The absence of distributional assumptions permits the consideration of a wide range of test statistics, for instance, ``pseudo'' t statistic images formed with smoothed variance images. The approach presented extends easily to other paradigms, permitting nonparametric analysis of most functional mapping experiments. When the assumptions of the parametric methods are true, these new nonparametric methods, at worst, provide for their validation. When the assumptions of the parametric methods are dubious, the nonparametric methods provide the only analysis that can be guaranteed valid and exact.},
	Author = {Holmes, A. P. and Blair, R. C. and Watson, J. D. G. and Ford, I.},
	Doi = {10.1097/00004647-199601000-00002},
	File = {SAGE PDF Full Text:/Users/Cecile/Zotero/storage/RTHM5VIR/Holmes et al. - 1996 - Nonparametric Analysis of Statistic Images from Fu.pdf:application/pdf},
	Issn = {0271-678X},
	Journal = {Journal of Cerebral Blood Flow \& Metabolism},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {7--22},
	Title = {Nonparametric {Analysis} of {Statistic} {Images} from {Functional} {Mapping} {Experiments}},
	Url = {https://doi.org/10.1097/00004647-199601000-00002},
	Urldate = {2018-08-22},
	Volume = {16},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1097/00004647-199601000-00002}}

@article{ramus_language_1999,
	Author = {Ramus, Franck and Mehler, Jacques},
	Doi = {10.1121/1.424522},
	File = {Ramus et Mehler - 1999 - Language identification with suprasegmental cues .pdf:/Users/Cecile/Zotero/storage/9EPZARCC/Ramus et Mehler - 1999 - Language identification with suprasegmental cues .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/SX7EYB7K/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = jan,
	Number = {1},
	Pages = {512--521},
	Shorttitle = {Language identification with suprasegmental cues},
	Title = {Language identification with suprasegmental cues: {A} study based on speech resynthesis},
	Url = {https://asa.scitation.org/doi/10.1121/1.424522},
	Urldate = {2018-08-22},
	Volume = {105},
	Year = {1999},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.424522},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.424522}}

@article{nichols_nonparametric_2002,
	Abstract = {Requiring only minimal assumptions for validity, nonparametric permutation testing provides a flexible and intuitive methodology for the statistical analysis of data from functional neuroimaging experiments, at some computational expense. Introduced into the functional neuroimaging literature by Holmes et al. ([1996]: J Cereb Blood Flow Metab 16:7--22), the permutation approach readily accounts for the multiple comparisons problem implicit in the standard voxel-by-voxel hypothesis testing framework. When the appropriate assumptions hold, the nonparametric permutation approach gives results similar to those obtained from a comparable Statistical Parametric Mapping approach using a general linear model with multiple comparisons corrections derived from random field theory. For analyses with low degrees of freedom, such as single subject PET/SPECT experiments or multi-subject PET/SPECT or fMRI designs assessed for population effects, the nonparametric approach employing a locally pooled (smoothed) variance estimate can outperform the comparable Statistical Parametric Mapping approach. Thus, these nonparametric techniques can be used to verify the validity of less computationally expensive parametric approaches. Although the theory and relative advantages of permutation approaches have been discussed by various authors, there has been no accessible explication of the method, and no freely distributed software implementing it. Consequently, there have been few practical applications of the technique. This article, and the accompanying MATLAB software, attempts to address these issues. The standard nonparametric randomization and permutation testing ideas are developed at an accessible level, using practical examples from functional neuroimaging, and the extensions for multiple comparisons described. Three worked examples from PET and fMRI are presented, with discussion, and comparisons with standard parametric approaches made where appropriate. Practical considerations are given throughout, and relevant statistical concepts are expounded in appendices. Hum. Brain Mapping 15:1--25, 2001. {\copyright} 2001 Wiley-Liss, Inc.},
	Author = {Nichols, Thomas E. and Holmes, Andrew P.},
	Copyright = {Copyright {\copyright} 2001 WileyâLiss, Inc.},
	Doi = {10.1002/hbm.1058},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PPSRGNR4/Nichols et Holmes - 2002 - Nonparametric permutation tests for functional neu.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZV2WKCWF/hbm.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {nonparametric, general linear model, hypothesis test, multiple comparisons, permutation test, randomization test, SPM, statistic image},
	Language = {fr},
	Month = jan,
	Number = {1},
	Pages = {1--25},
	Shorttitle = {Nonparametric permutation tests for functional neuroimaging},
	Title = {Nonparametric permutation tests for functional neuroimaging: {A} primer with examples},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.1058},
	Urldate = {2018-08-22},
	Volume = {15},
	Year = {2002},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.1058},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.1058}}

@article{maris_nonparametric_2007,
	Abstract = {In this paper, we show how ElectroEncephaloGraphic (EEG) and MagnetoEncephaloGraphic (MEG) data can be analyzed statistically using nonparametric techniques. Nonparametric statistical tests offer complete freedom to the user with respect to the test statistic by means of which the experimental conditions are compared. This freedom provides a straightforward way to solve the multiple comparisons problem (MCP) and it allows to incorporate biophysically motivated constraints in the test statistic, which may drastically increase the sensitivity of the statistical test. The paper is written for two audiences: (1) empirical neuroscientists looking for the most appropriate data analysis method, and (2) methodologists interested in the theoretical concepts behind nonparametric statistical tests. For the empirical neuroscientist, a large part of the paper is written in a tutorial-like fashion, enabling neuroscientists to construct their own statistical test, maximizing the sensitivity to the expected effect. And for the methodologist, it is explained why the nonparametric test is formally correct. This means that we formulate a null hypothesis (identical probability distribution in the different experimental conditions) and show that the nonparametric test controls the false alarm rate under this null hypothesis.},
	Author = {Maris, Eric and Oostenveld, Robert},
	Doi = {10.1016/j.jneumeth.2007.03.024},
	Issn = {0165-0270},
	Journal = {Journal of Neuroscience Methods},
	Keywords = {Brain Mapping, Evoked Potentials, Data Interpretation, Statistical, Electroencephalography, Humans, Signal Processing, Computer-Assisted, Brain, Magnetoencephalography, Statistics, Nonparametric},
	Language = {eng},
	Month = aug,
	Number = {1},
	Pages = {177--190},
	Pmid = {17517438},
	Title = {Nonparametric statistical testing of {EEG}- and {MEG}-data},
	Volume = {164},
	Year = {2007},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.jneumeth.2007.03.024}}

@article{meng_discovering_2018,
	Abstract = {The folding of the human cerebral cortex is highly complex and variable across individuals, but certain common major patterns of cortical folding do exist. Mining such common patterns of cortical folding is of great importance in understanding the inter-individual variability of cortical folding and their relationship with cognitive functions and brain disorders. As primary cortical folds are mainly genetically influenced and are well established at term birth, neonates with minimal exposure to the complicated postnatal environmental influences are ideal candidates for mining the major patterns of cortical folding. In this paper, we propose a sulcal-pit-based method to discover the major sulcal patterns of cortical folding. In our method, first, the sulcal pattern is characterized by the spatial distribution of sulcal pits, which are the locally deepest points in cortical sulci. Since deep sulcal pits are genetically related, relatively consistent across individuals, and also stable during brain development, they are well suited for representing and characterizing the sulcal patterns. Then, the similarity between the distributions of sulcal pits is measured from the spatial, geometrical, and topological points of view. Next, a comprehensive similarity matrix is constructed for the whole dataset by adaptively fusing these measurements together, thus capturing both their common and complementary information. Finally, leveraging the similarity matrix, a hierarchical affinity propagation algorithm is used to group similar sulcal folding patterns together. The proposed method has been applied to 677 neonatal brains, and revealed multiple distinct and meaningful sulcal patterns in the central sulcus, superior temporal sulcus, and cingulate sulcus.},
	Author = {Meng, Yu and Li, Gang and Wang, Li and Lin, Weili and Gilmore, John H. and Shen, Dinggang},
	Copyright = {{\copyright} 2018 Wiley Periodicals, Inc.},
	Doi = {10.1002/hbm.24199},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/AL8LWGM5/Meng et al. - 2018 - Discovering cortical sulcal folding patterns in ne.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HRP5SIXF/hbm.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {cortical surface, neonatal brain, sulcal folding pattern, sulcal pit},
	Language = {en},
	Month = sep,
	Number = {9},
	Pages = {3625--3635},
	Title = {Discovering cortical sulcal folding patterns in neonates using large-scale dataset},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24199},
	Urldate = {2018-08-21},
	Volume = {39},
	Year = {2018},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24199},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.24199}}

@article{isler_toward_2012,
	Abstract = {The event-related potential (ERP) effect of mismatch negativity (MMN) was the first electrophysiological probe to evaluate cognitive processing (change detection) in newborn infants. Initial studies of MMN predicted clinical utility for this measure in identification of infants at risk for developmental cognitive deficits. These predictions have not been realized. We hypothesized that in sleeping newborn infants, measures derived from wavelet assessment of power in the MMN paradigm would be more robust markers of the brain's response to stimulus change than the ERP-derived MMN. Consistent with this premise, we found increased power in response to unpredictable and infrequent tones compared to frequent tones. These increases were present at multiple locations on the scalp over a range of latencies and frequencies and occurred even in the absence of an ERP-derived MMN. There were two predominant effects. First, theta band power was elevated at middle and late latencies (200 to 600 ms), suggesting that neocortical theta rhythms that subserve working memory in adults are present at birth. Second, late latency (500 ms) increased power to the unpredictable and infrequent tones was observed in the beta and gamma bands, suggesting that oscillations involved in adult cognition are also present in the neonate. These findings support the expectation that frequency dependent measures, such as wavelet power, will improve the prospects for a clinically useful test of cortical function early in the postnatal period.},
	Author = {Isler, Joseph R. and Tarullo, Amanda R. and Grieve, Philip G. and Housman, Elizabeth and Kaku, Michelle and Stark, Raymond I. and Fifer, William P.},
	Copyright = {{\copyright} 2011 Blackwell Publishing Ltd},
	Doi = {10.1111/j.1467-7687.2011.01122.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9HLEBCSJ/Isler et al. - 2012 - Toward an electrocortical biomarker of cognition f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H7I8VPW4/j.1467-7687.2011.01122.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Month = mar,
	Number = {2},
	Pages = {260--271},
	Title = {Toward an electrocortical biomarker of cognition for newborn infants},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2011.01122.x},
	Urldate = {2018-08-07},
	Volume = {15},
	Year = {2012},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2011.01122.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2011.01122.x}}

@article{stefanics_auditory_2007,
	Abstract = {Adults normally perceive auditory scenes in terms of sound patterns emitted by concurrently active sources. Thus pattern formation is an important process of auditory object perception. The aim of the present study was to determine whether neonates group sounds by repeating pitch patterns. Standard (``S''; p=80\%) and deviant tones (``D'', p=20\%) differing only in pitch were delivered either in a randomized order (random condition) or in a repeating SSSSD pattern (grouped condition). Both event-related brain potentials and gamma-band activity differed between the S and D tones in the random condition but not in the grouped condition. These results suggest that in the grouped condition, the S and D tones were processed as part of the same higher order regularity by the neonate auditory system. Also, for the first time, we observed oscillatory gamma-band activity in neonates, which was sensitive to infrequent pitch changes.},
	Author = {Stefanics, G{\'a}bor and H{\'a}den, G{\'a}bor and Huotilainen, Minna and Bal{\'a}zs, L{\'a}szl{\'o} and Sziller, Istv{\'a}n and Beke, Anna and Fellman, Vineta and Winkler, Istv{\'a}n},
	Doi = {10.1111/j.1469-8986.2007.00540.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/YFQ3HR6S/Stefanics et al. - 2007 - Auditory temporal grouping in newborn infants.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T5AWPQ5B/j.1469-8986.2007.00540.html:text/html},
	Issn = {1469-8986},
	Journal = {Psychophysiology},
	Keywords = {Neonate, Auditory event-related potential, Gamma synchronization, Mismatch negativity (MMN), Perceptual development},
	Language = {en},
	Month = sep,
	Number = {5},
	Pages = {697--702},
	Title = {Auditory temporal grouping in newborn infants},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2007.00540.x},
	Urldate = {2018-08-07},
	Volume = {44},
	Year = {2007},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2007.00540.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1469-8986.2007.00540.x}}

@article{haden_timbre-independent_2009,
	Abstract = {The ability to separate pitch from other spectral sound features, such as timbre, is an important prerequisite of veridical auditory perception underlying speech acquisition and music cognition. The current study investigated whether or not newborn infants generalize pitch across different timbres. Perceived resonator size is an aspect of timbre that informs the listener about the size of the sound source, a cue that may be important already at birth. Therefore, detection of infrequent pitch changes was tested by recording event-related brain potentials in healthy newborn infants to frequent standard and infrequent pitch-deviant sounds while the perceived resonator size of all sounds was randomly varied. The elicitation of an early negative and a later positive discriminative response by deviant sounds demonstrated that the neonate auditory system represents pitch separately from timbre, thus showing advanced pitch processing capabilities.},
	Author = {H{\'a}den, G{\'a}bor P. and Stefanics, G{\'a}bor and Vestergaard, Martin D. and Denham, Susan L. and Sziller, Istv{\'a}n and Winkler, Istv{\'a}n},
	Copyright = {Copyright {\copyright} 2008 Society for Psychophysiological Research},
	Doi = {10.1111/j.1469-8986.2008.00749.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/AESNATB8/H{\'a}den et al. - 2009 - Timbre-independent extraction of pitch in newborn .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6QM98PNU/j.1469-8986.2008.00749.html:text/html},
	Issn = {1469-8986},
	Journal = {Psychophysiology},
	Keywords = {Development, Event-related brain potentials (ERP), mismatch negativity (MMN), Neonates, Perceived resonator size, Pitch processing, Timbre},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {69--74},
	Title = {Timbre-independent extraction of pitch in newborn infants},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2008.00749.x},
	Urldate = {2018-08-07},
	Volume = {46},
	Year = {2009},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8986.2008.00749.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1469-8986.2008.00749.x}}

@article{makeig_dynamic_2002,
	Abstract = {It has been long debated whether averaged electrical responses recorded from the scalp result from stimulus-evoked brain events or stimulus-induced changes in ongoing brain dynamics. In a human visual selective attention task, we show that nontarget event-related potentials were mainly generated by partial stimulus-induced phase resetting of multiple electroencephalographic processes. Independent component analysis applied to the single-trial data identified at least eight classes of contributing components, including those producing central and lateral posterior alpha, left and right mu, and frontal midline theta rhythms. Scalp topographies of these components were consistent with their generation in compact cortical domains.},
	Author = {Makeig, S. and Westerfield, M. and Jung, T.-P. and Enghoff, S. and Townsend, J. and Courchesne, E. and Sejnowski, T. J.},
	Doi = {10.1126/science.1066168},
	File = {Snapshot:/Users/Cecile/Zotero/storage/4XUXUR8S/690.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jan,
	Number = {5555},
	Pages = {690--694},
	Pmid = {11809976},
	Title = {Dynamic {Brain} {Sources} of {Visual} {Evoked} {Responses}},
	Url = {http://science.sciencemag.org/content/295/5555/690},
	Urldate = {2018-08-07},
	Volume = {295},
	Year = {2002},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/295/5555/690},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1066168}}

@article{davis_effects_1939,
	Author = {Davis, P. A.},
	Doi = {10.1152/jn.1939.2.6.494},
	File = {Snapshot:/Users/Cecile/Zotero/storage/LG7YQBSK/jn.1939.2.6.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = nov,
	Number = {6},
	Pages = {494--499},
	Title = {Effects of acoustic stimuli on the waking human brain},
	Url = {https://www.physiology.org/doi/citedby/10.1152/jn.1939.2.6.494},
	Urldate = {2018-08-07},
	Volume = {2},
	Year = {1939},
	Bdsk-Url-1 = {https://www.physiology.org/doi/citedby/10.1152/jn.1939.2.6.494},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.1939.2.6.494}}

@article{chapman_evoked_1964,
	Abstract = {Evoked Responses to Numerical and Non-Numerical Visual Stimuli while Problem Solving},
	Author = {Chapman, Robert M. and Bragdon, Henry R.},
	Copyright = {1964 Nature Publishing Group},
	Doi = {10.1038/2031155a0},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/B3Q6LZ68/Chapman et Bragdon - 1964 - Evoked Responses to Numerical and Non-Numerical Vi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NWFPP6M5/2031155a0.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = sep,
	Number = {4950},
	Pages = {1155--1157},
	Title = {Evoked {Responses} to {Numerical} and {Non}-{Numerical} {Visual} {Stimuli} while {Problem} {Solving}},
	Url = {https://www.nature.com/articles/2031155a0},
	Urldate = {2018-08-07},
	Volume = {203},
	Year = {1964},
	Bdsk-Url-1 = {https://www.nature.com/articles/2031155a0},
	Bdsk-Url-2 = {https://doi.org/10.1038/2031155a0}}

@article{kutas_reading_1980,
	Abstract = {In a sentence reading task, words that occurred out of context were associated with specific types of event-related brain potentials. Words that were physically aberrant (larger than normal) elecited a late positive series of potentials, whereas semantically inappropriate words elicited a late negative wave (N400). The N400 wave may be an electrophysiological sign of the "reprocessing" of semantically anomalous information.},
	Author = {Kutas, M. and Hillyard, S. A.},
	Copyright = {{\copyright} 1980},
	Doi = {10.1126/science.7350657},
	File = {Snapshot:/Users/Cecile/Zotero/storage/XG5UPF5W/203.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jan,
	Number = {4427},
	Pages = {203--205},
	Pmid = {7350657},
	Shorttitle = {Reading senseless sentences},
	Title = {Reading senseless sentences: brain potentials reflect semantic incongruity},
	Url = {http://science.sciencemag.org/content/207/4427/203},
	Urldate = {2018-08-07},
	Volume = {207},
	Year = {1980},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/207/4427/203},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.7350657}}

@article{jenni_development_2004,
	Abstract = {The development of nocturnal sleep and the sleep electroencephalogram (EEG) was investigated in a longitudinal study during infancy. All-night polysomnographic recordings were obtained at home at 2 wk and at 2, 4, 6, and 9 mo after birth (analysis of 7 infants). Total sleep time and the percentage of quiet sleep or non-rapid eye movement sleep (QS/NREMS) increased with age, whereas the percentage of active sleep or rapid eye movement sleep (AS/REMS) decreased. Spectral power of the sleep EEG was higher in QS/NREMS than in AS/REMS over a large part of the 0.75- to 25-Hz frequency range. In both QS/NREMS and AS/REMS, EEG power increased with age in the frequency range {\textless}10 Hz and {\textgreater}17 Hz. The largest rise occurred between 2 and 6 mo. A salient feature of the QS/NREMS spectrum was the emergence of a peak in the sigma band (12-14 Hz) at 2 mo that corresponded to the appearance of sleep spindles. Between 2 and 9 mo, low-frequency delta activity (0.75-1.75 Hz) showed an alternating pattern with a high level occurring in every other QS/NREMS episode. At 6 mo, sigma activity showed a similar pattern. In contrast, theta activity (6.5-9 Hz) exhibited a monotonic decline over consecutive QS/NREMS episodes, a trend that at 9 mo could be closely approximated by an exponential function. The results suggest that 1) EEG markers of sleep homeostasis appear in the first postnatal months, and 2) sleep homeostasis goes through a period of maturation. Theta activity and not delta activity seems to reflect the dissipation of sleep propensity during infancy.},
	Author = {Jenni, Oskar G. and Borb{\'e}ly, Alexander A. and Achermann, Peter},
	Doi = {10.1152/ajpregu.00503.2003},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Q69RMALR/Jenni et al. - 2004 - Development of the nocturnal sleep electroencephal.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZRT9379V/ajpregu.00503.html:text/html},
	Issn = {0363-6119},
	Journal = {American Journal of Physiology-Regulatory, Integrative and Comparative Physiology},
	Month = mar,
	Number = {3},
	Pages = {R528--R538},
	Title = {Development of the nocturnal sleep electroencephalogram in human infants},
	Url = {https://www.physiology.org/doi/abs/10.1152/ajpregu.00503.2003},
	Urldate = {2018-08-07},
	Volume = {286},
	Year = {2004},
	Bdsk-Url-1 = {https://www.physiology.org/doi/abs/10.1152/ajpregu.00503.2003},
	Bdsk-Url-2 = {https://doi.org/10.1152/ajpregu.00503.2003}}

@article{friederici_neural_2002,
	Abstract = {We recorded event-related potentials (ERPs) in 2-month-old infants in two different states of alertness: awake and asleep. Syllables varying in vowel duration (long vs short) were presented in an oddball paradigm, known to elicit a mismatch brain response. ERPs of both groups showed a mismatch response reflected in a positivity followed by a frontal negativity. While the positivity was present as a function of the stimulus type (present for long deviants only), the negativity varied as a function of the state of alertness (present for awake infants only). These data indicate a functional separation between precognitive and cognitive aspects of duration mismatch essential for the distinction between long and short vowels during early infancy.},
	Author = {Friederici, Angela D. and Friedrich, Manuela and Weber, Christiane},
	File = {Snapshot:/Users/Cecile/Zotero/storage/8I9ELU99/Neural_manifestation_of_cognitive_and_precognitive.6.html:text/html},
	Issn = {0959-4965},
	Journal = {NeuroReport},
	Language = {en-US},
	Month = jul,
	Number = {10},
	Pages = {1251},
	Title = {Neural manifestation of cognitive and precognitive mismatch detection in early infancy},
	Url = {https://journals.lww.com/neuroreport/Fulltext/2002/07190/Neural_manifestation_of_cognitive_and_precognitive.6.aspx},
	Urldate = {2018-08-07},
	Volume = {13},
	Year = {2002},
	Bdsk-Url-1 = {https://journals.lww.com/neuroreport/Fulltext/2002/07190/Neural_manifestation_of_cognitive_and_precognitive.6.aspx}}

@article{myers_developmental_2012,
	Abstract = {Objective
To quantify spectral power in frequency specific bands and commonly observed types of bursting activities in the EEG during early human development.
Methods
An extensive archive of EEG data from human infants from 35 to 52weeks postmenstrual age obtained in a prior multi-center study was analyzed using power spectrum analyses and a high frequency burst detection algorithm.
Results
Low frequency power increased with age; however, high frequency power decreased from 35 to 45weeks. This unexpected decrease was largely attributable to a rapid decline in the number of high frequency bursts.
Conclusions
The decline in high frequency bursting activity overlaps with a developmental shift in GABA's actions on neurons from depolarizing to hyperpolarizing and the dissolution of the gap junction circuitry of the cortical subplate.
Significance
We postulate that quantitative characterization of features of the EEG unique to early development provide indices for tracking changes in specific neurophysiologic mechanisms that are critical for normal development of brain function.},
	Author = {Myers, M. M. and Grieve, P. G. and Izraelit, A. and Fifer, W. P. and Isler, J. R. and Darnall, R. A. and Stark, R. I.},
	Doi = {10.1016/j.clinph.2011.11.264},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/I65L3J52/Myers et al. - 2012 - Developmental profiles of infant EEG Overlap with.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YP66JMJ3/S1388245712000399.html:text/html},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology},
	Keywords = {EEG, Infant, Development, GABA, Bursts, Subplate},
	Month = aug,
	Number = {8},
	Pages = {1502--1511},
	Shorttitle = {Developmental profiles of infant {EEG}},
	Title = {Developmental profiles of infant {EEG}: {Overlap} with transient cortical circuits},
	Url = {http://www.sciencedirect.com/science/article/pii/S1388245712000399},
	Urldate = {2018-08-07},
	Volume = {123},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245712000399},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2011.11.264}}

@article{ellingson_development_1980,
	Abstract = {EEG polygraph recordings of 1 to over 4 h duration were obtained during daytime sleeps weekly from birth to 11--13 weeks of age in 17 normal full-term newborns. Analysis of the recordings permitted more precise specification of the time courses of early developmental changes in EEG patterns related to the sleep cycle. The trac{\'e} alternant pattern of quiet sleep was seen up to 2 weeks post term in all subjects, but in none beyond 6 weeks. Active sleep onset occurred in 80\% of daytime sleeps at 1--3 weeks and decreased rapidly over the next 5 weeks, but at 8--13 weeks was still seen in 5--10\% of the recordings. Rolandic sleep spindle bursts appeared in some subjects as early as 4 weeks post term and were present in all beyond 8 weeks. Based upon these 3 criterion variables, the transition from `perinatal' to `infantile' EEG sleep patterns started at a mean age of 30.3 days and was completed at a mean age of 46.6 days. The earliest and latest completions of the transition were at 27 and 66 days, respectively. On the average the transition took just over 2 weeks. Frontal sleep transients were seen until 3 weeks post term in all subjects, but in none beyond 7 weeks. Active sleep decreased from just over 50\% of total sleep time at birth to about 20\% beyond 8 weeks. Percent-time quiet sleep increased proportionately. Indeterminate sleep remained relatively constant at 5--10 percent-time. A tendency for percent-time indeterminate sleep to be elevated in the presences of minor illnesses was observed. The usefulness of these, and other, EEG data in defining mature and immature EEGs in the neonatal period and the clinical significance of EEG immaturity are discussed.
R{\'e}sum{\'e}
Des enregistrements EEG et polygraphiques d'une dur{\'e}e de 1--4 h ont {\'e}t{\'e} obtenus au cours de p{\'e}riodes de sommeil diurne toutes les semaines entre la naissance et 11--13 semaines chez 17 nouveau-n{\'e}s {\`a} terme. L'analyse de ces enregistrements permet de d{\'e}finir de fa{\c c}on plus pr{\'e}cise l'{\'e}volution des modifications pr{\'e}coces du d{\'e}veloppement des patterns EEG des cycles de sommeil. Le pattern `trace' alternant' du sommeil calme s'observe jusqu'{\`a} 2 semaines apr{\`e}s la naissance chez tous les sujets, mais ne s'observe plus chez aucun d'entre eux au-del{\`a} de 6 semaines. L'endormissement en sommeil actif s'observe dans 80\% des sommeils de jour entre 1 et 3 semaines, diminue rapidement au cours des 5 semaines suivantes, mais entre 8 et 13 semaines on l'observe encore dans 5--10\% des enregistrements. Les bouff{\'e}es de spindles rolandiques de sommeil apparaissent chez certains sujets d{\`e}s la 4{\`e}me semaine apr{\`e}s la naissance et s'observent chez tous apr{\`e}s la 8{\`e}me semaine. En se basant sur ces 3 crit{\`e}res, la transition des patterns EEG de sommeil de la p{\'e}riode p{\'e}ri-natale {\`a} la p{\'e}riode infantile d{\'e}bute {\`a} un {\^a}ge moyen de 30,3 jours et se parach{\`e}ve {\`a} un {\^a}ge moyen de 46,6 jours. La r{\'e}alisation compl{\`e}te la plus pr{\'e}coce et la plus tardive de cette transition survient {\`a} 27 et 66 jours respectivement. En moyenne cette transition prend juste un peu plus de 2 semaines. Les transitoires frontales du sommeil s'observent jusqu'{\`a} la 3{\`e}me semaine apr{\`e}s la naissance chez tous les sujets mais chez aucun d'entre eux au-del{\`a} de 7 semaines. Le sommeil actif diminue d'une valeur juste sup{\'e}rieure {\`a} 50\% du sommeil total {\`a} la naissance {\`a} environ 20\% apr{\`e}s 8 semaines. Le pourcentage de temps occup{\'e} par le sommeil calme augmente en proportion. Le sommeil ind{\'e}termin{\'e} reste relativement constant, {\`a} une valeur d'environ 5--10\% du temps de sommeil. On observe une tendance {\`a} ce que le pourcentage de sommeil ind{\'e}termin{\'e} soit {\'e}lev{\'e} en cas de maladies b{\'e}nignes. L'utilit{\'e} de ces donn{\'e}es EEG, et d'autres, pour d{\'e}finir les EEGs matures et immatures {\`a} la p{\'e}riode n{\'e}o-natale et la signification clinique de l'immaturit{\'e} EEG sont discut{\'e}es.},
	Author = {Ellingson, Robert J and Peters, Jon F},
	Doi = {10.1016/0013-4694(80)90357-0},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/J3DTA4WE/Ellingson et Peters - 1980 - Development of EEG and daytime sleep patterns in n.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MIKP5A38/0013469480903570.html:text/html},
	Issn = {0013-4694},
	Journal = {Electroencephalography and Clinical Neurophysiology},
	Month = jul,
	Number = {1},
	Pages = {112--124},
	Shorttitle = {Development of {EEG} and daytime sleep patterns in normal full-term infants during the first 3 months of life},
	Title = {Development of {EEG} and daytime sleep patterns in normal full-term infants during the first 3 months of life: {Longitudinal} observations},
	Url = {http://www.sciencedirect.com/science/article/pii/0013469480903570},
	Urldate = {2018-08-07},
	Volume = {49},
	Year = {1980},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0013469480903570},
	Bdsk-Url-2 = {https://doi.org/10.1016/0013-4694(80)90357-0}}

@article{haden_context_2013,
	Abstract = {Detecting and orienting towards sounds carrying new information is a crucial feature of the human brain that supports adaptation to the environment. Rare, acoustically widely deviant sounds presented amongst frequent tones elicit large event related brain potentials (ERPs) in neonates. Here we tested whether these discriminative ERP responses reflect only the activation of fresh afferent neuronal populations (i.e., neuronal circuits not affected by the tones) or they also index the processing of contextual mismatch between the rare and the frequent sounds. In two separate experiments, we presented sleeping newborns with 150 different environmental sounds and the same number of white noise bursts. Both sounds served either as deviants in an oddball paradigm with the frequent standard stimulus a tone (Novel/Noise deviant), or as the standard stimulus with the tone as deviant (Novel/Noise standard), or they were delivered alone with the same timing as the deviants in the oddball condition (Novel/Noise alone). Whereas the ERP responses to noise--deviants elicited similar responses as the same sound presented alone, the responses elicited by environmental sounds in the corresponding conditions morphologically differed from each other. Thus whereas the ERP response to the noise sounds can be explained by the different refractory state of stimulus specific neuronal populations, the ERP response to environmental sounds indicated context sensitive processing. These results provide evidence for an innate tendency of context dependent auditory processing as well as a basis for the different developmental trajectories of processing acoustical deviance and contextual novelty.},
	Author = {H{\'a}den, G{\'a}bor P{\'e}ter and N{\'e}meth, Ren{\'a}ta and T{\"o}r{\"o}k, Mikl{\'o}s and Dr{\'a}vucz, S{\'a}ndor and Winkler, Istv{\'a}n},
	Doi = {10.3389/fpsyg.2013.00674},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UZVGA7CE/H{\'a}den et al. - 2013 - Context effects on processing widely deviant sound.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {Auditory Perception, novelty detection, context effects, ERPs (Event-Related Potentials), human newborn},
	Language = {English},
	Title = {Context effects on processing widely deviant sounds in newborn infants},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00674/full#h3},
	Urldate = {2018-08-07},
	Volume = {4},
	Year = {2013},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00674/full#h3},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2013.00674}}

@article{nemeth_processing_2015,
	Abstract = {Objectives: By measuring event-related brain potentials (ERPs), the authors tested the sensitivity of the newborn auditory cortex to sound lateralization and to the most common cues of horizontal sound localization.
        Design: Sixty-eight healthy full-term newborn infants were presented with auditory oddball sequences composed of frequent and rare noise segments in four experimental conditions. The authors tested in them the detection of deviations in the primary cues of sound lateralization (interaural time and level difference) and in actual sound source location (free-field and monaural sound presentation). ERP correlates of deviance detection were measured in two time windows.
        Results: Deviations in both primary sound localization cues and the ear of stimulation elicited a significant ERP difference in the early (90 to 140 msec) time window. Deviance in actual sound source location (the free-field condition) elicited a significant response in the late (290 to 340 msec) time window.
        Conclusions: The early differential response may indicate the detection of a change in the respective auditory features. The authors suggest that the late differential response, which was only elicited by actual sound source location deviation, reflects the detection of location deviance integrating the various cues of sound source location. Although the results suggest that all of the tested binaural cues are processed by the neonatal auditory cortex, utilizing the cues for locating sound sources of these cues may require maturation and learning.},
	Author = {N{\'e}meth, Ren{\'a}ta and H{\'a}den, G{\'a}bor P. and T{\"o}r{\"o}k, Mikl{\'o}s and Winkler, Istv{\'a}n},
	Doi = {10.1097/AUD.0000000000000160},
	File = {Snapshot:/Users/Cecile/Zotero/storage/CU2Z76T8/Processing_of_Horizontal_Sound_Localization_Cues.6.html:text/html},
	Issn = {0196-0202},
	Journal = {Ear and Hearing},
	Language = {en-US},
	Month = oct,
	Number = {5},
	Pages = {550},
	Title = {Processing of {Horizontal} {Sound} {Localization} {Cues} in {Newborn} {Infants}},
	Url = {https://journals.lww.com/ear-hearing/fulltext/2015/09000/Processing_of_Horizontal_Sound_Localization_Cues.6.aspx},
	Urldate = {2018-08-07},
	Volume = {36},
	Year = {2015},
	Bdsk-Url-1 = {https://journals.lww.com/ear-hearing/fulltext/2015/09000/Processing_of_Horizontal_Sound_Localization_Cues.6.aspx},
	Bdsk-Url-2 = {https://doi.org/10.1097/AUD.0000000000000160}}

@article{toth_large-scale_2017,
	Abstract = {The organization of functional brain networks changes across human lifespan. The present study analyzed functional brain networks in healthy full-term infants (N = 139) within 1--6 days from birth by measuring neural synchrony in EEG recordings during quiet sleep. Large-scale phase synchronization was measured in six frequency bands with the Phase Lag Index. Macroscopic network organization characteristics were quantified by constructing unweighted minimum spanning tree graphs. The cortical networks in early infancy were found to be significantly more hierarchical and had a more cost-efficient organization compared with MST of random control networks, more so in the theta and alpha than in other frequency bands. Frontal and parietal sites acted as the main hubs of these networks, the topological characteristics of which were associated with gestation age (GA). This suggests that individual differences in network topology are related to cortical maturation during the prenatal period, when functional networks shift from strictly centralized toward segregated configurations. Hum Brain Mapp 38:4019--4033, 2017. {\copyright} 2017 Wiley Periodicals, Inc.},
	Author = {T{\'o}th, Brigitta and Urb{\'a}n, G{\'a}bor and H{\'a}den, G{\'a}bor P. and M{\'a}rk, Moln{\'a}r and T{\"o}r{\"o}k, Mikl{\'o}s and Stam, Cornelis Jan and Winkler, Istv{\'a}n},
	Copyright = {{\copyright} 2017 Wiley Periodicals, Inc.},
	Doi = {10.1002/hbm.23645},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9KZRZHBP/T{\'o}th et al. - 2017 - Large-scale network organization of EEG functional.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IF9K3AEG/hbm.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {electroencephalography, functional connectivity, graph theory, minimum spanning tree, neonate, network analysis},
	Language = {en},
	Month = aug,
	Number = {8},
	Pages = {4019--4033},
	Title = {Large-scale network organization of {EEG} functional connectivity in newborn infants},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23645},
	Urldate = {2018-08-07},
	Volume = {38},
	Year = {2017},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23645},
	Bdsk-Url-2 = {https://doi.org/10.1002/hbm.23645}}

@article{von_holzen_bilinguals_2014,
	Abstract = {Upon being presented with a familiar name-known image, monolingual infants and adults implicitly generate the image's label (Mani \& Plunkett, 2010; 2011; Meyer, Belke, Telling, \& Humphreys, 2007). Although the cross-linguistic influences on overt bilingual production are well studied (for a summary see Colom{\'e} \& Miozzo, 2010), evidence that bilinguals implicitly generate the label for familiar objects in both languages remains mixed. For example, bilinguals implicitly generate picture labels in both of their languages, but only when tested in L2 and not L1 (Wu \& Thierry, 2011b) or when immersed in their L2 (Marian \& Spivey, 2003a, 2003b; Spivey \& Marian, 1999) but not when immersed in their L1 (Weber \& Cutler, 2004). The current study tests whether bilinguals implicitly generate picture labels in both of their languages when tested in their L1 with a cross-modal ERP priming paradigm. The results extend previous findings by showing that not just do bilinguals implicitly generate the labels for visually fixated images in both of their languages when immersed in their L1, but also that these implicitly generated labels in one language can prime recognition of subsequently presented auditory targets across languages (i.e. L2 -- L1). The current study provides support for cascaded models of lexical access during speech production, as well as a new priming paradigm for the study of bilingual language processing.},
	Author = {Von Holzen, Katie and Mani, Nivedita},
	Doi = {10.3389/fpsyg.2014.01415},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PSQHMD6J/Von Holzen et Mani - 2014 - Bilinguals implicitly name objects in both their l.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {bilingualism, ERP, implicit naming, lexical access, phonological priming},
	Language = {English},
	Shorttitle = {Bilinguals implicitly name objects in both their languages},
	Title = {Bilinguals implicitly name objects in both their languages: an {ERP} study},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.01415/full},
	Urldate = {2018-08-07},
	Volume = {5},
	Year = {2014},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.01415/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2014.01415}}

@article{von_holzen_consonant_2018,
	Abstract = {Segmentation skill and the preferential processing of consonants (C-bias) develop during the second half of the first year of life and it has been proposed that these facilitate language acquisition. We used Event-related brain potentials (ERPs) to investigate the neural bases of early word form segmentation, and of the early processing of onset consonants, medial vowels, and coda consonants, exploring how differences in these early skills might be related to later language outcomes. Our results with French-learning eight-month-old infants primarily support previous studies that found that the word familiarity effect in segmentation is developing from a positive to a negative polarity at this age. Although as a group infants exhibited an anterior-localized negative effect, inspection of individual results revealed that a majority of infants showed a negative-going response (Negative Responders), while a minority showed a positive-going response (Positive Responders). Furthermore, all infants demonstrated sensitivity to onset consonant mispronunciations, while Negative Responders demonstrated a lack of sensitivity to vowel mispronunciations, a developmental pattern similar to previous literature. Responses to coda consonant mispronunciations revealed neither sensitivity nor lack of sensitivity. We found that infants showing a more mature, negative response to newly segmented words compared to control words (evaluating segmentation skill) and mispronunciations (evaluating phonological processing) at test also had greater growth in word production over the second year of life than infants showing a more positive response. These results establish a relationship between early segmentation skills and phonological processing (not modulated by the type of mispronunciation) and later lexical skills.},
	Author = {Von Holzen, Katie and Nishibayashi, Leo-Lyuki and Nazzi, Thierry},
	Copyright = {http://creativecommons.org/licenses/by/3.0/},
	Doi = {10.3390/brainsci8020024},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/V9FHVEUX/Von Holzen et al. - 2018 - Consonant and Vowel Processing in Word Form Segmen.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XFPAD93X/24.html:text/html},
	Journal = {Brain Sciences},
	Keywords = {consonant bias, Event-related brain potentials (ERPs), French-learning infants, individual variability, lexical processing, word form segmentation},
	Language = {en},
	Month = jan,
	Number = {2},
	Pages = {24},
	Shorttitle = {Consonant and {Vowel} {Processing} in {Word} {Form} {Segmentation}},
	Title = {Consonant and {Vowel} {Processing} in {Word} {Form} {Segmentation}: {An} {Infant} {ERP} {Study}},
	Url = {http://www.mdpi.com/2076-3425/8/2/24},
	Urldate = {2018-08-07},
	Volume = {8},
	Year = {2018},
	Bdsk-Url-1 = {http://www.mdpi.com/2076-3425/8/2/24},
	Bdsk-Url-2 = {https://doi.org/10.3390/brainsci8020024}}

@book{noauthor_doi:_nodate,
	Abstract = {This copy is for your personal, non-commercial use only. clicking here.colleagues, clients, or customers by, you can order high-quality copies for yourIf you wish to distribute this article to others here.following the guidelines can be obtained byPermission to republish or repurpose articles or portions of articles): April 28, 2013 www.sciencemag.org (this information is current as of The following resources related to this article are available online at},
	File = {Citeseer - Full Text PDF:/Users/Cecile/Zotero/storage/YMYZWMTT/DOI 10.1126science.1232509, 376 (2013)\;340 Scien.pdf:application/pdf;Citeseer - Snapshot:/Users/Cecile/Zotero/storage/HC22WWAB/summary.html:text/html},
	Shorttitle = {{DOI}},
	Title = {{DOI}: 10.1126/science.1232509, 376 (2013);340 {Science} et al.{Sid} {Kouider} {A} {Neural} {Marker} of {Perceptual} {Consciousness} in {Infants}}}

@misc{noauthor_oms_nodate,
	Abstract = {FR CGS - chts\_hcfa\_filles\_z},
	File = {Snapshot:/Users/Cecile/Zotero/storage/ZLVWGNSH/fr.html:text/html},
	Journal = {WHO},
	Title = {{OMS} {\textbar} {P{\'e}rim{\`e}tre} cr{\^a}nien-pour-l'{\^a}ge},
	Url = {http://www.who.int/childgrowth/standards/second_set/chts_hcfa_filles_z/fr/},
	Urldate = {2018-08-07},
	Bdsk-Url-1 = {http://www.who.int/childgrowth/standards/second_set/chts_hcfa_filles_z/fr/}}

@article{laing_tuned_2012,
	Abstract = {Voices have unique acoustic signatures, contributing to the acoustic variability listeners must contend with in perceiving speech, and it has long been proposed that listeners normalize speech perception to information extracted from a talker's speech. Initial attempts to explain talker normalization relied on extraction of articulatory referents, but recent studies of context-dependent auditory perception suggest that general auditory referents such as the long-term average spectrum (LTAS) of a talker's speech similarly affect speech perception. The present study aimed to differentiate the contributions of articulatory/linguistic versus auditory referents for context-driven talker normalization effects and, more specifically, to identify the specific constraints under which such contexts impact speech perception. Synthesized sentences manipulated to sound like different talkers influenced categorization of a subsequent speech target only when differences in the sentences' LTAS were in the frequency range of the acoustic cues relevant for the target phonemic contrast. This effect was true both for speech targets preceded by spoken sentence contexts and for targets preceded by nonspeech tone sequences that were LTAS-matched to the spoken sentence contexts. Specific LTAS characteristics, rather than perceived talker, predicted the results suggesting that general auditory mechanisms play an important role in effects considered to be instances of perceptual talker normalization.},
	Author = {Laing, Erika J. C. and Liu, Ran and Lotto, Andrew J. and Holt, Lori L.},
	Doi = {10.3389/fpsyg.2012.00203},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/D2EVFNKA/Laing et al. - 2012 - Tuned with a Tune Talker Normalization via Genera.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {Speech Perception, Auditory cognition, Talker Normalization},
	Language = {English},
	Shorttitle = {Tuned with a {Tune}},
	Title = {Tuned with a {Tune}: {Talker} {Normalization} via {General} {Auditory} {Processes}},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00203/full},
	Urldate = {2018-08-06},
	Volume = {3},
	Year = {2012},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00203/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2012.00203}}

@article{lachaux_measuring_1999,
	Abstract = {This article presents, for the first time, a practical method for the direct quantification of frequency-specific synchronization (i.e., transient phase-locking) between two neuroelectric signals. The motivation for its development is to be able to examine the role of neural synchronies as a putative mechanism for long-range neural integration during cognitive tasks. The method, called phase-locking statistics (PLS), measures the significance of the phase covariance between two signals with a reasonable time-resolution ({\textless}100 ms). Unlike the more traditional method of spectral coherence, PLS separates the phase and amplitude components and can be directly interpreted in the framework of neural integration. To validate synchrony values against background fluctuations, PLS uses surrogate data and thus makes no a priori assumptions on the nature of the experimental data. We also apply PLS to investigate intracortical recordings from an epileptic patient performing a visual discrimination task. We find large-scale synchronies in the gamma band (45 Hz), e.g., between hippocampus and frontal gyrus, and local synchronies, within a limbic region, a few cm apart. We argue that whereas long-scale effects do reflect cognitive processing, short-scale synchronies are likely to be due to volume conduction. We discuss ways to separate such conduction effects from true signal synchrony. Hum Brain Mapping 8:194--208, 1999. {\copyright} 1999 Wiley-Liss, Inc.},
	Author = {Lachaux, Jean-Philippe and Rodriguez, Eugenio and Martinerie, Jacques and Varela, Francisco J.},
	Copyright = {Copyright {\copyright} 1999 WileyâLiss, Inc.},
	Doi = {10.1002/(SICI)1097-0193(1999)8:4<194::AID-HBM4>3.0.CO;2-C},
	File = {Snapshot:/Users/Cecile/Zotero/storage/UDYWHEGI/(SICI)1097-0193(1999)84194AID-HBM43.0.html:text/html},
	Issn = {1097-0193},
	Journal = {Human Brain Mapping},
	Keywords = {EEG, coherence, deblurring, EcoG, epilepsy, gamma-band, neural synchrony, phase-locking},
	Language = {en},
	Month = jan,
	Number = {4},
	Pages = {194--208},
	Title = {Measuring phase synchrony in brain signals},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0193%281999%298%3A4%3C194%3A%3AAID-HBM4%3E3.0.CO%3B2-C},
	Urldate = {2018-09-09},
	Volume = {8},
	Year = {1999},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291097-0193%281999%298%3A4%3C194%3A%3AAID-HBM4%3E3.0.CO%3B2-C},
	Bdsk-Url-2 = {https://doi.org/10.1002/(SICI)1097-0193(1999)8:4%3C194::AID-HBM4%3E3.0.CO;2-C}}

@article{picton_human_2003,
	Abstract = {Steady-state evoked potentials can be recorded from the human scalp in response to auditory stimuli presented at rates between 1 and 200 Hz or by periodic modulations of the amplitude and/or frequency of a continuous tone. Responses can be objectively detected using frequency-based analyses. In waking subjects, the responses are particularly prominent at rates near 40 Hz. Responses evoked by more rapidly presented stimuli are less affected by changes in arousal and can be evoked by multiple simultaneous stimuli without significant loss of amplitude. Response amplitude increases as the depth of modulation or the intensity increases. The phase delay of the response increases as the intensity or the carrier frequency decreases. Auditory steady-state responses are generated throughout the auditory nervous system, with cortical regions contributing more than brainstem generators to responses at lower modulation frequencies. These responses are useful for objectively evaluating auditory thresholds, assessing suprathreshold hearing, and monitoring the state of arousal during anesthesia.Los potenciales evocados de estado estable pueden registrarse del cr{\'a}neo humano en respuesta a est{\'\i}mulos auditivos presentados a tasas de 1 y 200 Hz o por modulaciones peri{\'o}dicas de la amplitud y/o de la frecuencia de un tono continue Las respuestas pueden ser detectadas objetivamente por medio de un an{\'a}lisis frecuencial En sujetos en estado de alerta las respuestas son particularmente prominentes con tasas de estimulaci{\'o}n cercanas a 40 Hz. Las respuestas evocadas por est{\'\i}mulos presentados a tasa m{\'a}s r{\'a}pida resultan menos afectadas por cambios del estado de conciencia y pueden ser evocados por est{\'\i}mulos m{\'u}ltiples simult{\'a}neos sin una p{\'e}rdida significativa de la amplitud. La amplitud de la respuesta aumenta conforme la profundidad de la modulaci{\'o}n o de la intensidad aumenta. El retraso de fase de la respuesta aumenta conforme la intensidad de la frecuencia portadora aumenta. Las respuestas auditivas de estado estable se generan a todo lo largo del sistema nervioso auditivo; las regiones corticales contribuyen m{\'a}s que los generadores del tallo cerebral en las respuestas de frecuencias m{\'a}s bajas. Estas respuestas son {\'u}tiles para evaluar objetivamente los umbrales de audici{\'o}n y permiten tambi{\'e}n evaluar la audici{\'o}n supraliminar y monitorizar el estado de conciencia durante la anestesia.},
	Author = {Picton, Terence W. and John, M. Sasha and Dimitrijevic, Andrew and Purcell, David},
	Doi = {10.3109/14992020309101316},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KF87FIPT/Picton et al. - 2003 - Human auditory steady-state responses Respuestas .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TL4VJUQU/14992020309101316.html:text/html},
	Issn = {1499-2027},
	Journal = {International Journal of Audiology},
	Keywords = {Audiometry, Hearing, Anesthesia, Fourier analysis, Steady-state response},
	Month = jan,
	Number = {4},
	Pages = {177--219},
	Shorttitle = {Human auditory steady-state responses},
	Title = {Human auditory steady-state responses: {Respuestas} auditivas de estado estable en humanos},
	Url = {https://doi.org/10.3109/14992020309101316},
	Urldate = {2018-09-09},
	Volume = {42},
	Year = {2003},
	Bdsk-Url-1 = {https://doi.org/10.3109/14992020309101316}}

@article{woolley_tuning_2005,
	Abstract = {Vocal communicators discriminate conspecific vocalizations from other sounds and recognize the vocalizations of individuals. To identify neural mechanisms for the discrimination of such natural sounds, we compared the linear spectro-temporal tuning properties of auditory midbrain and forebrain neurons in zebra finches with the statistics of natural sounds, including song. Here, we demonstrate that ensembles of auditory neurons are tuned to auditory features that enhance the acoustic differences between classes of natural sounds, and among the songs of individual birds. Tuning specifically avoids the spectro-temporal modulations that are redundant across natural sounds and therefore provide little information; rather, it overlaps with the temporal modulations that differ most across sounds. By comparing the real tuning and a less selective model of spectro-temporal tuning, we found that the real modulation tuning increases the neural discrimination of different sounds. Additionally, auditory neurons discriminate among zebra finch song segments better than among synthetic sound segments.},
	Author = {Woolley, Sarah M. N. and Fremouw, Thane E. and Hsu, Anne and Theunissen, Fr{\'e}d{\'e}ric E.},
	Copyright = {2005 Nature Publishing Group},
	Doi = {10.1038/nn1536},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/5J6JHXRA/Woolley et al. - 2005 - Tuning for spectro-temporal modulations as a mecha.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9U7JDMZD/nn1536.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = oct,
	Number = {10},
	Pages = {1371--1379},
	Title = {Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds},
	Url = {https://www.nature.com/articles/nn1536},
	Urldate = {2018-09-14},
	Volume = {8},
	Year = {2005},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn1536},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn1536}}

@article{smith_efficient_2005,
	Abstract = {Nonstationary acoustic features provide essential cues for many auditory tasks, including sound localization, auditory stream analysis, and speech recognition. These features can best be characterized relative to a precise point in time, such as the onset of a sound or the beginning of a harmonic periodicity. Extracting these types of features is a difficult problem. Part of the difficulty is that with standard block-based signal analysis methods, the representation is sensitive to the arbitrary alignment of the blocks with respect to the signal. Convolutional techniques such as shift-invariant transformations can reduce this sensitivity, but these do not yield a code that is efficient, that is, one that forms a nonredundant representation of the underlying structure. Here, we develop a non-block-based method for signal representation that is both time relative and efficient. Signals are represented using a linear superposition of time-shiftable kernel functions, each with an associated magnitude and temporal position. Signal decomposition in this method is a non-linear process that consists of optimizing the kernel function scaling coefficients and temporal positions to form an efficient, shift-invariant representation. We demonstrate the properties of this representation for the purpose of characterizing structure in various types of nonstationary acoustic signals. The computational problem investigated here has direct relevance to the neural coding at the auditory nerve and the more general issue of how to encode complex, time-varying signals with a population of spiking neurons.},
	Author = {Smith, Evan and Lewicki, Michael S.},
	Doi = {10.1162/0899766052530839},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7Z3T3Z3I/Smith et Lewicki - 2005 - Efficient Coding of Time-Relative Structure Using .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/R9DZT53C/0899766052530839.html:text/html},
	Issn = {0899-7667},
	Journal = {Neural Computation},
	Month = jan,
	Number = {1},
	Pages = {19--45},
	Title = {Efficient {Coding} of {Time}-{Relative} {Structure} {Using} {Spikes}},
	Url = {https://doi.org/10.1162/0899766052530839},
	Urldate = {2018-09-14},
	Volume = {17},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1162/0899766052530839}}

@misc{usakli_improvement_2010,
	Abstract = {The aim of this study is to present some practical state-of-the-art considerations in acquiring satisfactory signals for electroencephalographic signal acquisition. These considerations are important for users and system designers. Especially choosing correct electrode and design strategy of the initial electronic circuitry front end plays an important role in improving the system's measurement performance. Considering the pitfalls in the design of biopotential measurement system and recording session conditions creates better accuracy. In electroencephalogram (EEG) recording electrodes, system electronics including filtering, amplifying, signal conversion, data storing, and environmental conditions affect the recording performance. In this paper, EEG electrode principles and main points of electronic noise reduction methods in EEG signal acquisition front end are discussed, and some suggestions for improving signal acquisition are presented.},
	Author = {Usakli, Ali Bulent},
	Doi = {10.1155/2010/630649},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/H72LNRXA/Usakli - 2010 - Improvement of EEG Signal Acquisition An Electric.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UVRGU6LQ/630649.html:application/xhtml+xml},
	Journal = {Computational Intelligence and Neuroscience},
	Language = {en},
	Pmid = {20148074},
	Shorttitle = {Improvement of {EEG} {Signal} {Acquisition}},
	Title = {Improvement of {EEG} {Signal} {Acquisition}: {An} {Electrical} {Aspect} for {State} of the {Art} of {Front} {End}},
	Type = {Research article},
	Url = {https://www.hindawi.com/journals/cin/2010/630649/},
	Urldate = {2018-09-12},
	Year = {2010},
	Bdsk-Url-1 = {https://www.hindawi.com/journals/cin/2010/630649/},
	Bdsk-Url-2 = {https://doi.org/10.1155/2010/630649}}

@article{smith_efficient_2006,
	Abstract = {The auditory neural code must serve a wide range of auditory tasks that require great sensitivity in time and frequency and be effective over the diverse array of sounds present in natural acoustic environments. It has been suggested1,2,3,4,5 that sensory systems might have evolved highly efficient coding strategies to maximize the information conveyed to the brain while minimizing the required energy and neural resources. Here we show that, for natural sounds, the complete acoustic waveform can be represented efficiently with a nonlinear model based on a population spike code. In this model, idealized spikes encode the precise temporal positions and magnitudes of underlying acoustic features. We find that when the features are optimized for coding either natural sounds or speech, they show striking similarities to time-domain cochlear filter estimates, have a frequency-bandwidth dependence similar to that of auditory nerve fibres, and yield significantly greater coding efficiency than conventional signal representations. These results indicate that the auditory code might approach an information theoretic optimum and that the acoustic structure of speech might be adapted to the coding capacity of the mammalian auditory system.},
	Author = {Smith, Evan C. and Lewicki, Michael S.},
	Copyright = {2006 Nature Publishing Group},
	Doi = {10.1038/nature04485},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/P38YJ77Q/Smith et Lewicki - 2006 - Efficient auditory coding.pdf:application/pdf},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = feb,
	Number = {7079},
	Pages = {978--982},
	Title = {Efficient auditory coding},
	Url = {https://www.nature.com/articles/nature04485},
	Urldate = {2018-09-11},
	Volume = {439},
	Year = {2006},
	Bdsk-Url-1 = {https://www.nature.com/articles/nature04485},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature04485}}

@article{weisz_tonotopic_2004,
	Abstract = {Using neuromagnetic source imaging, we investigated tonotopic representation and direction sensitivity in the auditory cortex of humans (N=15). For this purpose, source analysis was undertaken at every single sampling point during the presentation of a frequency-modulated tone (FM) sweeping slowly downward or upward across periods of 3 s duration. Stimuli were selected to target response properties of the central part of the primary auditory cortical field, which has been shown to exhibit sensitivity to distinct FM-sound features as compared to the ventral and dorsal part. Linear mixed-effects model statistics confirm tonotopic gradients in medial--lateral and anterior--posterior directions. The high resolution provided by this method revealed that the relationship between frequency and spatial location of the responding neural tissue is nonlinear. The idea that neurons specifically sensitive to the employed sound characteristics (slow, downward modulation) were activated is supported by the fact that the upward sweep of identical duration produced a different pattern of functional organisation.},
	Author = {Weisz, Nathan and Wienbruch, Christian and Hoffmeister, Sandra and Elbert, Thomas},
	Doi = {10.1016/j.heares.2004.01.012},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/QU674YNU/Weisz et al. - 2004 - Tonotopic organization of the human auditory corte.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/SLYV8RLS/S037859550400036X.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Keywords = {MEG, High-resolution, LME, Tonotopy},
	Month = may,
	Number = {1},
	Pages = {49--58},
	Title = {Tonotopic organization of the human auditory cortex probed with frequency-modulated tones},
	Url = {http://www.sciencedirect.com/science/article/pii/S037859550400036X},
	Urldate = {2018-09-09},
	Volume = {191},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S037859550400036X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2004.01.012}}

@article{romani_tonotopic_1982,
	Abstract = {Neuromagnetic measurements of responses to auditory stimuli consisting of pure tones amplitude-modulated at a low frequency have been used to deduce the location of cortical activity. The evoked field source systematically increased in depth beneath the scalp with increasing frequency of the tone. The tonotopic progression can be described as a logarithmic mapping.},
	Author = {Romani, G. L. and Williamson, S. J. and Kaufman, L.},
	Copyright = {{\copyright} 1982},
	Doi = {10.1126/science.7079770},
	File = {Snapshot:/Users/Cecile/Zotero/storage/432RJ7T6/1339.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = jun,
	Number = {4552},
	Pages = {1339--1340},
	Pmid = {7079770},
	Title = {Tonotopic organization of the human auditory cortex},
	Url = {http://science.sciencemag.org/content/216/4552/1339},
	Urldate = {2018-09-09},
	Volume = {216},
	Year = {1982},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/216/4552/1339},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.7079770}}

@article{brenner_adaptive_2000,
	Abstract = {Adaptation is a widespread phenomenon in nervous systems, providing flexibility to function under varying external conditions. Here, we relate an adaptive property of a sensory system directly to its function as a carrier of information about input signals. We show that the input/output relation of a sensory system in a dynamic environment changes with the statistical properties of the environment. Specifically, when the dynamic range of inputs changes, the input/output relation rescales so as to match the dynamic range of responses to that of the inputs. We give direct evidence that the scaling of the input/output relation is set to maximize information transmission for each distribution of signals. This adaptive behavior should be particularly useful in dealing with the intermittent statistics of natural signals.},
	Author = {Brenner, Naama and Bialek, William and de Ruyter van Steveninck, Rob},
	Doi = {10.1016/S0896-6273(00)81205-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YGHLYDHI/Brenner et al. - 2000 - Adaptive Rescaling Maximizes Information Transmiss.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/QZRLRQHW/S0896627300812052.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = jun,
	Number = {3},
	Pages = {695--702},
	Title = {Adaptive {Rescaling} {Maximizes} {Information} {Transmission}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627300812052},
	Urldate = {2018-09-15},
	Volume = {26},
	Year = {2000},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627300812052},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0896-6273(00)81205-2}}

@article{howard_discrimination_2010,
	Abstract = {Speech stimuli give rise to neural activity in the listener that can be observed as waveforms using magnetoencephalography. Although waveforms vary greatly from trial to trial due to activity unrelated to the stimulus, it has been demonstrated that spoken sentences can be discriminated based on theta-band (3--7 Hz) phase patterns in single-trial response waveforms. Furthermore, manipulations of the speech signal envelope and fine structure that reduced intelligibility were found to produce correlated reductions in discrimination performance, suggesting a relationship between theta-band phase patterns and speech comprehension. This study investigates the nature of this relationship, hypothesizing that theta-band phase patterns primarily reflect cortical processing of low-frequency ({\textless}40 Hz) modulations present in the acoustic signal and required for intelligibility, rather than processing exclusively related to comprehension (e.g., lexical, syntactic, semantic). Using stimuli that are quite similar to normal spoken sentences in terms of low-frequency modulation characteristics but are unintelligible (i.e., their time-inverted counterparts), we find that discrimination performance based on theta-band phase patterns is equal for both types of stimuli. Consistent with earlier findings, we also observe that whereas theta-band phase patterns differ across stimuli, power patterns do not. We use a simulation model of the single-trial response to spoken sentence stimuli to demonstrate that phase-locked responses to low-frequency modulations of the acoustic signal can account not only for the phase but also for the power results. The simulation offers insight into the interpretation of the empirical results with respect to phase-resetting and power-enhancement models of the evoked response.},
	Author = {Howard, Mary F. and Poeppel, David},
	Doi = {10.1152/jn.00251.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9BNJGF2H/Howard et Poeppel - 2010 - Discrimination of Speech Stimuli Based on Neuronal.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/64F9F4AM/jn.00251.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = may,
	Number = {5},
	Pages = {2500--2511},
	Title = {Discrimination of {Speech} {Stimuli} {Based} on {Neuronal} {Response} {Phase} {Patterns} {Depends} on {Acoustics} {But} {Not} {Comprehension}},
	Url = {https://www.physiology.org/doi/abs/10.1152/jn.00251.2010},
	Urldate = {2018-09-18},
	Volume = {104},
	Year = {2010},
	Bdsk-Url-1 = {https://www.physiology.org/doi/abs/10.1152/jn.00251.2010},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00251.2010}}

@article{formisano_who_2008,
	Abstract = {Can we decipher speech content (``what'' is being said) and speaker identity (``who'' is saying it) from observations of brain activity of a listener? Here, we combine functional magnetic resonance imaging with a data-mining algorithm and retrieve what and whom a person is listening to from the neural fingerprints that speech and voice signals elicit in the listener's auditory cortex. These cortical fingerprints are spatially distributed and insensitive to acoustic variations of the input so as to permit the brain-based recognition of learned speech from unknown speakers and of learned voices from previously unheard utterances. Our findings unravel the detailed cortical layout and computational properties of the neural populations at the basis of human speech recognition and speaker identification.
Distinct patterns of activity elicited in auditory cortex by different vowels and different speakers allows independent identification of who is speaking and what they are saying.
Distinct patterns of activity elicited in auditory cortex by different vowels and different speakers allows independent identification of who is speaking and what they are saying.},
	Author = {Formisano, Elia and Martino, Federico De and Bonte, Milene and Goebel, Rainer},
	Copyright = {American Association for the Advancement of Science},
	Doi = {10.1126/science.1164318},
	File = {Snapshot:/Users/Cecile/Zotero/storage/7BM9E9TE/970.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = nov,
	Number = {5903},
	Pages = {970--973},
	Pmid = {18988858},
	Shorttitle = {"{Who}" {Is} {Saying} "{What}"?},
	Title = {"{Who}" {Is} {Saying} "{What}"? {Brain}-{Based} {Decoding} of {Human} {Voice} and {Speech}},
	Url = {http://science.sciencemag.org/content/322/5903/970},
	Urldate = {2018-09-14},
	Volume = {322},
	Year = {2008},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/322/5903/970},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1164318}}

@article{fernald_cross-language_1989,
	Abstract = {This study compares the prosodie modifications in mothers' and fathers' speech to preverbal infants in French, Italian, German, Japanese, British English, and American English. At every stage of data collection and analysis, standardized procedures were used to enhance the comparability across data sets that is essential for valid cross-language comparison of the prosodie features of parental speech. In each of the six language groups, five mothers and five fathers were recorded in semi-structured home observations while speaking to their infant aged 0; 10--1;2 and to an adult. Speech samples were instrumentally analysed to measure seven prosodic parameters: mean fundamental frequency (f0), f0-minimum, f0-maximum, f0-range, f0-variability, utterance duration, and pause duration. Results showed cross-language consistency in the patterns of prosodic modification used in parental speech to infants. Across languages, both mothers and fathers used higher mean-f0, f0-minimum, and f0-maximum, greater f0-variability, shorter utterances, and longer pauses in infant-directed speech than in adult-directed speech. Mothers, but not fathers, used a wider f0-range in speech to infants. American English parents showed the most extreme prosodic modifications, differing from the other language groups in the extent of intonational exaggeration in Speech to infants. These results reveal common patterns in caretaker's use of intonation across languages, which may function developmentally to regulate infant arousal and attention, to communicate affect, and to facilitate speech perception and language comprehension. In addition to providing evidence for possibly universal prosodic features of speech to infants, these results suggest that language-specific variations are also important, and that the findings of the numerous studies of early language input based on American English are not necessarily generalisable to other cultures.},
	Author = {Fernald, Anne and Taeschner, Traute and Dunn, Judy and Papousek, Mechthild and Boysson-Bardies, B{\'e}n{\'e}dicte de and Fukui, Ikuko},
	Doi = {10.1017/S0305000900010679},
	File = {Snapshot:/Users/Cecile/Zotero/storage/8AY3IBL5/09F89ED04E6663BBA843BE25FB8E9588.html:text/html},
	Issn = {1469-7602, 0305-0009},
	Journal = {Journal of Child Language},
	Language = {en},
	Month = oct,
	Number = {3},
	Pages = {477--501},
	Title = {A cross-language study of prosodic modifications in mothers' and fathers' speech to preverbal infants*},
	Url = {https://www.cambridge.org/core/journals/journal-of-child-language/article/crosslanguage-study-of-prosodic-modifications-in-mothers-and-fathers-speech-to-preverbal-infants/09F89ED04E6663BBA843BE25FB8E9588},
	Urldate = {2018-09-23},
	Volume = {16},
	Year = {1989},
	Bdsk-Url-1 = {https://www.cambridge.org/core/journals/journal-of-child-language/article/crosslanguage-study-of-prosodic-modifications-in-mothers-and-fathers-speech-to-preverbal-infants/09F89ED04E6663BBA843BE25FB8E9588},
	Bdsk-Url-2 = {https://doi.org/10.1017/S0305000900010679}}

@article{soderstrom_beyond_2007,
	Abstract = {Infant-directed maternal speech is an important component of infants' linguistic input. However, speech from other speakers and speech directed to others constitute a large amount of the linguistic environment. What are the properties of infant-directed speech that differentiate it from other components of infants' speech environment? To what extent should these other aspects be considered as part of the linguistic input? This review examines the characteristics of the speech input to preverbal infants, including phonological, morphological, and syntactic characteristics, specifically how these properties might support language development. While maternal, infant-directed speech is privileged in the input, other aspects of the environment, such as adult-directed speech, may also play a role. Furthermore, the input is variable in nature, dependent on the age and linguistic development of the infant, the social context, and the interaction between the infant and speakers in the environment.},
	Author = {Soderstrom, Melanie},
	Doi = {10.1016/j.dr.2007.06.002},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/DDY4RY7L/Soderstrom - 2007 - Beyond babytalk Re-evaluating the nature and cont.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NAY2MCF5/S0273229707000202.html:text/html},
	Issn = {0273-2297},
	Journal = {Developmental Review},
	Keywords = {Infant-directed speech, Babytalk, Language development, Maternal speech, Prelinguistic infants, Preverbal infants, Speech input},
	Month = dec,
	Number = {4},
	Pages = {501--532},
	Shorttitle = {Beyond babytalk},
	Title = {Beyond babytalk: {Re}-evaluating the nature and content of speech input to preverbal infants},
	Url = {http://www.sciencedirect.com/science/article/pii/S0273229707000202},
	Urldate = {2018-09-23},
	Volume = {27},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0273229707000202},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dr.2007.06.002}}

@article{leong_role_2014,
	Author = {Leong, Victoria and Stone, Michael A. and Turner, Richard E. and Goswami, Usha},
	Doi = {10.1121/1.4883366},
	File = {Leong et al. - 2014 - A role for amplitude modulation phase relationship.pdf:/Users/Cecile/Zotero/storage/HFA794YR/Leong et al. - 2014 - A role for amplitude modulation phase relationship.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U5B4YIJY/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = jul,
	Number = {1},
	Pages = {366--381},
	Title = {A role for amplitude modulation phase relationships in speech rhythm perception},
	Url = {https://asa.scitation.org/doi/10.1121/1.4883366},
	Urldate = {2018-09-23},
	Volume = {136},
	Year = {2014},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.4883366},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.4883366}}

@article{lieberman_intonation_1967,
	Abstract = {ATTEMPTED TO DETERMINE HOW PEOPLE ACTUALLY PRODUCE AND PERCEIVE INTONATION AND TO DIFFERENTIATE CLEARLY BETWEEN THE LINGUISTIC AND EMOTIONAL ASPECTS OF INTONATION AND STRESS. EVIDENCE, CONTRARY TO GENERAL ASSUMPTIONS, IS PRESENTED THAT INTONATION IS A CENTRAL RATHER THAT PERIPHERAL LINGUISTIC FEATURE, I.E., AN INNATE RATHER THAN ACQUIRED CHARACTERISTIC; AND THAT IT IS BASED ON UNIVERSAL CONSTANTS OF HUMAN PSYCHOLOGY, AND CONSEQUENTLY IS AN INVARIANT AMONG SPECIFIC LANGUAGE GROUPS. DATA ARE EXAMINED REGARDING THE ARTICULATORY, ACOUSTIC, PERCEPTUAL, PHONETIC, AND SYNTACTIC DIMENSIONS OF INTONATION FOR AMERICAN ENGLISH AND AVAILABLE DATA FOR BOTH RELATED AND UNRELATED LANGUAGES INCLUDING RUSSIAN, FINNISH, JAPANESE, AND SWEDISH. (10 P. REF.) (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
	Author = {Lieberman, Philip},
	File = {Snapshot:/Users/Cecile/Zotero/storage/FZUDI39N/1967-16665-001.html:text/html},
	Journal = {M.I.T. Research Monograph},
	Keywords = {Perception, Psycholinguistics, Language, Stress},
	Pages = {xiii, 210--xiii, 210},
	Title = {Intonation, perception, and language},
	Volume = {38},
	Year = {1967}}

@article{mampe_newborns_2009,
	Abstract = {Summary
Human fetuses are able to memorize auditory stimuli from the external world by the last trimester of pregnancy, with a particular sensitivity to melody contour in both music and language 1, 2, 3. Newborns prefer their mother's voice over other voices 4, 5, 6, 7, 8 and perceive the emotional content of messages conveyed via intonation contours in maternal speech (``motherese'') [9]. Their perceptual preference for the surrounding language 10, 11, 12 and their ability to distinguish between prosodically different languages 13, 14, 15 and pitch changes [16] are based on prosodic information, primarily melody. Adult-like processing of pitch intervals allows newborns to appreciate musical melodies and emotional and linguistic prosody [17]. Although prenatal exposure to native-language prosody influences newborns' perception, the surrounding language affects sound production apparently much later [18]. Here, we analyzed the crying patterns of 30 French and 30 German newborns with respect to their melody and intensity contours. The French group preferentially produced cries with a rising melody contour, whereas the German group preferentially produced falling contours. The data show an influence of the surrounding speech prosody on newborns' cry melody, possibly via vocal learning based on biological predispositions.},
	Author = {Mampe, Birgit and Friederici, Angela D. and Christophe, Anne and Wermke, Kathleen},
	Doi = {10.1016/j.cub.2009.09.064},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/YVDNX7DN/Mampe et al. - 2009 - Newborns' Cry Melody Is Shaped by Their Native Lan.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KQVQU8FF/S0960982209018247.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Keywords = {SYSNEURO},
	Month = dec,
	Number = {23},
	Pages = {1994--1997},
	Title = {Newborns' {Cry} {Melody} {Is} {Shaped} by {Their} {Native} {Language}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982209018247},
	Urldate = {2018-09-24},
	Volume = {19},
	Year = {2009},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982209018247},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2009.09.064}}

@article{moon_language_2013,
	Abstract = {Aims To test the hypothesis that exposure to ambient language in the womb alters phonetic perception shortly after birth. This two-country study aimed to see whether neonates demonstrated prenatal learning by how they responded to vowels in a category from their native language and another non-native language, regardless of how much postnatal experience the infants had. Method A counterbalanced experiment was conducted in Sweden (n = 40) and the USA (n = 40) using Swedish and English vowel sounds. The neonates (mean postnatal age = 33 h) controlled audio presentation of either native or non-native vowels by sucking on a pacifier, with the number of times they sucked their pacifier being used to demonstrate what vowel sounds attracted their attention. The vowels were either the English/i/or Swedish/y/in the form of a prototype plus 16 variants of the prototype. Results The infants in the native and non-native groups responded differently. As predicted, the infants responded to the unfamiliar non-native language with higher mean sucks. They also sucked more to the non-native prototype. Time since birth (range: 7--75 h) did not affect the outcome. Conclusion The ambient language to which foetuses are exposed in the womb starts to affect their perception of their native language at a phonetic level. This can be measured shortly after birth by differences in responding to familiar vs. unfamiliar vowels.},
	Author = {Moon, Christine and Lagercrantz, Hugo and Kuhl, Patricia K.},
	Copyright = {{\copyright}2012 The Author(s)/Acta P{\ae}diatrica {\copyright}2012 Foundation Acta P{\ae}diatrica},
	Doi = {10.1111/apa.12098},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/6YICQ4N2/Moon et al. - 2013 - Language experienced in utero affects vowel percep.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5KZ36KE4/apa.html:text/html},
	Issn = {1651-2227},
	Journal = {Acta Paediatrica},
	Keywords = {Learning, Vowels, Language, Foetal, Neonatal},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {156--160},
	Shorttitle = {Language experienced in utero affects vowel perception after birth},
	Title = {Language experienced in utero affects vowel perception after birth: a two-country study},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/apa.12098},
	Urldate = {2018-09-24},
	Volume = {102},
	Year = {2013},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/apa.12098},
	Bdsk-Url-2 = {https://doi.org/10.1111/apa.12098}}

@incollection{lecanuet_speech_1993,
	Abstract = {Data from three experimental sources are reviewed in this chapter. They indicate: (a) that maternal and external voices travel to fetal head level, (b) the near term fetus perceives and discriminates speech signals, and (c) that he/she may learn some features of speech sounds to which he/she was exposed during the last trimester of the gestation and remember them post-natally.},
	Address = {Dordrecht},
	Author = {Lecanuet, J-P. and Granier-Deferre, C.},
	Booktitle = {Developmental {Neurocognition}: {Speech} and {Face} {Processing} in the {First} {Year} of {Life}},
	Doi = {10.1007/978-94-015-8234-6_20},
	Editor = {de Boysson-Bardies, B{\'e}n{\'e}dicte and de Schonen, Scania and Jusczyk, Peter and McNeilage, Peter and Morton, John},
	Isbn = {978-94-015-8234-6},
	Keywords = {Female Voice, Fetal Heart Rate, Sound Environment, Sound Pressure Level, Speech Sound},
	Language = {en},
	Pages = {237--248},
	Publisher = {Springer Netherlands},
	Series = {{NATO} {ASI} {Series}},
	Title = {Speech {Stimuli} in the {Fetal} {Environment}},
	Url = {https://doi.org/10.1007/978-94-015-8234-6_20},
	Urldate = {2018-09-24},
	Year = {1993},
	Bdsk-Url-1 = {https://doi.org/10.1007/978-94-015-8234-6_20}}

@article{partanen_learning-induced_2013-1,
	Abstract = {Learning, the foundation of adaptive and intelligent behavior, is based on plastic changes in neural assemblies, reflected by the modulation of electric brain responses. In infancy, auditory learning implicates the formation and strengthening of neural long-term memory traces, improving discrimination skills, in particular those forming the prerequisites for speech perception and understanding. Although previous behavioral observations show that newborns react differentially to unfamiliar sounds vs. familiar sound material that they were exposed to as fetuses, the neural basis of fetal learning has not thus far been investigated. Here we demonstrate direct neural correlates of human fetal learning of speech-like auditory stimuli. We presented variants of words to fetuses; unlike infants with no exposure to these stimuli, the exposed fetuses showed enhanced brain activity (mismatch responses) in response to pitch changes for the trained variants after birth. Furthermore, a significant correlation existed between the amount of prenatal exposure and brain activity, with greater activity being associated with a higher amount of prenatal speech exposure. Moreover, the learning effect was generalized to other types of similar speech sounds not included in the training material. Consequently, our results indicate neural commitment specifically tuned to the speech features heard before birth and their memory representations.},
	Author = {Partanen, Eino and Kujala, Teija and N{\"a}{\"a}t{\"a}nen, Risto and Liitola, Auli and Sambeth, Anke and Huotilainen, Minna},
	Doi = {10.1073/pnas.1302159110},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Q8EB2FMA/Partanen et al. - 2013 - Learning-induced neural plasticity of speech proce.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/333E9JB9/15145.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {event-related potentials, mismatch negativity},
	Language = {en},
	Month = sep,
	Number = {37},
	Pages = {15145--15150},
	Pmid = {23980148},
	Title = {Learning-induced neural plasticity of speech processing before birth},
	Url = {http://www.pnas.org/content/110/37/15145},
	Urldate = {2018-09-24},
	Volume = {110},
	Year = {2013},
	Bdsk-Url-1 = {http://www.pnas.org/content/110/37/15145},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1302159110}}

@article{abrams_acoustic_2000,
	Abstract = {The acoustic environment of the fetus is composed of continuous cardiovascular, respiratory, and intestinal sounds that are punctuated by isolated, shorter bursts during maternal body movements and vocalizations. The distribution of sounds is confined to frequencies below 300 Hz. Additionally, vibrations on the external surface of the maternal abdomen can induce sounds inside the uterus. The half-round sound pressure contours in the abdomen during vibroacoustic stimulation differ from the circular distribution of contours resulting from airborne sound pressure exposure. The static and dynamic forces of the vibrator and the vibrator distance from the target are also factors in sound transmission. Responses to sound are best described in animals and include changes in behavioral state, brain bloodflow, auditory brainstem response, and local cerebral glucose utilization along the central auditory pathway.},
	Author = {Abrams, Robert M. and Gerhardt, Kenneth J.},
	Copyright = {2000 Nature Publishing Group},
	Doi = {10.1038/sj.jp.7200445},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8PHVZPD3/Abrams et Gerhardt - 2000 - The Acoustic Environment and Physiological Respons.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AVXID8JG/7200445.html:text/html},
	Issn = {1476-5543},
	Journal = {Journal of Perinatology},
	Language = {en},
	Month = dec,
	Number = {S1},
	Pages = {S31--S36},
	Title = {The {Acoustic} {Environment} and {Physiological} {Responses} of the {Fetus}},
	Url = {https://www.nature.com/articles/7200445},
	Urldate = {2018-09-24},
	Volume = {20},
	Year = {2000},
	Bdsk-Url-1 = {https://www.nature.com/articles/7200445},
	Bdsk-Url-2 = {https://doi.org/10.1038/sj.jp.7200445}}

@article{mizrahi_single_2014,
	Abstract = {The auditory system drives behavior using information extracted from sounds. Early in the auditory hierarchy, circuits are highly specialized for detecting basic sound features. However, already at the level of the auditory cortex the functional organization of the circuits and the underlying coding principles become different. Here, we review some recent progress in our understanding of single neuron and population coding in primary auditory cortex, focusing on natural sounds. We discuss possible mechanisms explaining why single neuron responses to simple sounds cannot predict responses to natural stimuli. We describe recent work suggesting that structural features like local subnetworks rather than smoothly mapped tonotopy are essential components of population coding. Finally, we suggest a synthesis of how single neurons and subnetworks may be involved in coding natural sounds.},
	Author = {Mizrahi, Adi and Shalev, Amos and Nelken, Israel},
	Doi = {10.1016/j.conb.2013.09.007},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/LMEQT2W7/S0959438813001864.html:text/html},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = feb,
	Pages = {103--110},
	Series = {Neural maps},
	Title = {Single neuron and population coding of natural sounds in auditory cortex},
	Url = {http://www.sciencedirect.com/science/article/pii/S0959438813001864},
	Urldate = {2018-09-26},
	Volume = {24},
	Year = {2014},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0959438813001864},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2013.09.007}}

@article{laudanski_differences_2012,
	Abstract = {Spectro-temporal properties of auditory cortex neurons have been extensively studied with artificial sounds but it is still unclear whether they help in understanding neuronal responses to communication sounds. Here, we directly compared spectro-temporal receptive fields (STRFs) obtained from the same neurons using both artificial stimuli (dynamic moving ripples, DMRs) and natural stimuli (conspecific vocalizations) that were matched in terms of spectral content, average power and modulation spectrum. On a population of auditory cortex neurons exhibiting reliable tuning curves when tested with pure tones, significant STRFs were obtained for 62\% of the cells with vocalizations and 68\% with DMR. However, for many cells with significant vocalization-derived STRFs (STRFvoc) and DMR-derived STRFs (STRFdmr), the BF, latency, bandwidth and global STRFs shape differed more than what would be predicted by spiking responses simulated by a linear model based on a non-homogenous Poisson process. Moreover STRFvoc predicted neural responses to vocalizations more accurately than STRFdmr predicted neural response to DMRs, despite similar spike-timing reliability for both sets of stimuli. Cortical bursts, which potentially introduce nonlinearities in evoked responses, did not explain the differences between STRFvoc and STRFdmr. Altogether, these results suggest that the nonlinearity of auditory cortical responses makes it difficult to predict responses to communication sounds from STRFs computed from artificial stimuli.},
	Author = {Laudanski, Jonathan and Edeline, Jean-Marc and Huetz, Chlo{\'e}},
	Doi = {10.1371/journal.pone.0050539},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CV3VVMZ6/Laudanski et al. - 2012 - Differences between Spectro-Temporal Receptive Fie.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P56CIJVW/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Acoustics, Neuronal tuning, Neurons, Auditory cortex, Action potentials, Bandwidth (signal processing), Guinea pigs, Vocalization},
	Language = {en},
	Month = nov,
	Number = {11},
	Pages = {e50539},
	Title = {Differences between {Spectro}-{Temporal} {Receptive} {Fields} {Derived} from {Artificial} and {Natural} {Stimuli} in the {Auditory} {Cortex}},
	Url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0050539},
	Urldate = {2018-09-26},
	Volume = {7},
	Year = {2012},
	Bdsk-Url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0050539},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0050539}}

@article{amin_selective_2013,
	Abstract = {Previous research has shown that postnatal exposure to simple, synthetic sounds can affect the sound representation in the auditory cortex as reflected by changes in the tonotopic map or other relatively simple tuning properties, such as AM tuning. However, their functional implications for neural processing in the generation of ethologically-based perception remain unexplored. Here we examined the effects of noise-rearing and social isolation on the neural processing of communication sounds such as species-specific song, in the primary auditory cortex analog of adult zebra finches. Our electrophysiological recordings reveal that neural tuning to simple frequency-based synthetic sounds is initially established in all the laminae independent of patterned acoustic experience; however, we provide the first evidence that early exposure to patterned sound statistics, such as those found in native sounds, is required for the subsequent emergence of neural selectivity for complex vocalizations and for shaping neural spiking precision in superficial and deep cortical laminae, and for creating efficient neural representations of song and a less redundant ensemble code in all the laminae. Our study also provides the first causal evidence for `sparse coding', such that when the statistics of the stimuli were changed during rearing, as in noise-rearing, that the sparse or optimal representation for species-specific vocalizations disappeared. Taken together, these results imply that a layer-specific differential development of the auditory cortex requires patterned acoustic input, and a specialized and robust sensory representation of complex communication sounds in the auditory cortex requires a rich acoustic and social environment.},
	Author = {Amin, Noopur and Gastpar, Michael and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1371/journal.pone.0061417},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UQ8B28WP/Amin et al. - 2013 - Selective and Efficient Neural Coding of Communica.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/LZXBESKV/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Acoustics, Neuronal tuning, Neurons, Single neuron function, Bird song, Birds, White noise, Zebra finch},
	Language = {en},
	Month = apr,
	Number = {4},
	Pages = {e61417},
	Title = {Selective and {Efficient} {Neural} {Coding} of {Communication} {Signals} {Depends} on {Early} {Acoustic} and {Social} {Environment}},
	Url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061417},
	Urldate = {2018-09-26},
	Volume = {8},
	Year = {2013},
	Bdsk-Url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0061417},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0061417}}

@article{chechik_auditory_2012,
	Abstract = {The auditory system extracts behaviorally relevant information from acoustic stimuli. The average activity in auditory cortex is known to be sensitive to spectro-temporal patterns in sounds. However, it is not known whether the auditory cortex also processes more abstract features of sounds, which may be more behaviorally relevant than spectro-temporal patterns. Using recordings from three stations of the auditory pathway, the inferior colliculus (IC), the ventral division of the medial geniculate body (MGB) of the thalamus, and the primary auditory cortex (A1) of the cat in response to natural sounds, we compared the amount of information that spikes contained about two aspects of the stimuli: spectro-temporal patterns, and abstract entities present in the same stimuli such as a bird chirp, its echoes, and the ambient noise. IC spikes conveyed on average approximately the same amount of information about spectro-temporal patterns as they conveyed about abstract auditory entities, but A1 and the MGB neurons conveyed on average three times more information about abstract auditory entities than about spectro-temporal patterns. Thus, the majority of neurons in auditory thalamus and cortex coded well the presence of abstract entities in the sounds without containing much information about their spectro-temporal structure, suggesting that they are sensitive to abstract features in these sounds.},
	Author = {Chechik, Gal and Nelken, Israel},
	Doi = {10.1073/pnas.1111242109},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/SH8J9DZP/Chechik et Nelken - 2012 - Auditory abstraction from spectro-temporal feature.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/453JJ53N/18968.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Language = {en},
	Month = nov,
	Number = {46},
	Pages = {18968--18973},
	Pmid = {23112145},
	Title = {Auditory abstraction from spectro-temporal features to coding auditory entities},
	Url = {http://www.pnas.org/content/109/46/18968},
	Urldate = {2018-09-26},
	Volume = {109},
	Year = {2012},
	Bdsk-Url-1 = {http://www.pnas.org/content/109/46/18968},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1111242109}}

@article{garcia-lazaro_tuning_2006,
	Abstract = {Summary
The amplitude and pitch fluctuations of natural soundscapes often exhibit ``1/f spectra'' 1, 2, which means that large, abrupt changes in pitch or loudness occur proportionally less frequently in nature than gentle, gradual fluctuations. Furthermore, human listeners reportedly prefer 1/f distributed random melodies to melodies with faster (1/f0) or slower (1/f2) dynamics [3]. One might therefore suspect that neurons in the central auditory system may be tuned to 1/f dynamics, particularly given that recent reports provide evidence for tuning to 1/f dynamics in primary visual cortex [4]. To test whether neurons in primary auditory cortex (A1) are tuned to 1/f dynamics, we recorded responses to random tone complexes in which the fundamental frequency and the envelope were determined by statistically independent ``1/fÎ³ random walks,'' with Î³ set to values between 0.5 and 4. Many A1 neurons showed clear evidence of tuning and responded with higher firing rates to stimuli with Î³ between 1 and 1.5. Response patterns elicited by 1/fÎ³ stimuli were more reproducible for values of Î³ close to 1. These findings indicate that auditory cortex is indeed tuned to the 1/f dynamics commonly found in the statistical distributions of natural soundscapes.},
	Author = {Garcia-Lazaro, J. A. and Ahmed, Bashir and Schnupp, J. W. H.},
	Doi = {10.1016/j.cub.2005.12.013},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/YJG4J3S5/S0960982205015678.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Keywords = {SYSNEURO},
	Month = feb,
	Number = {3},
	Pages = {264--271},
	Title = {Tuning to {Natural} {Stimulus} {Dynamics} in {Primary} {Auditory} {Cortex}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982205015678},
	Urldate = {2018-09-26},
	Volume = {16},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982205015678},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2005.12.013}}

@article{ulanovsky_multiple_2004,
	Abstract = {Neurons in primary auditory cortex (A1) of cats show strong stimulus-specific adaptation (SSA). In probabilistic settings, in which one stimulus is common and another is rare, responses to common sounds adapt more strongly than responses to rare sounds. This SSA could be a correlate of auditory sensory memory at the level of single A1 neurons. Here we studied adaptation in A1 neurons, using three different probabilistic designs. We showed that SSA has several time scales concurrently, spanning many orders of magnitude, from hundreds of milliseconds to tens of seconds. Similar time scales are known for the auditory memory span of humans, as measured both psychophysically and using evoked potentials. A simple model, with linear dependence on both short-term and long-term stimulus history, provided a good fit to A1 responses. Auditory thalamus neurons did not show SSA, and their responses were poorly fitted by the same model. In addition, SSA increased the proportion of failures in the responses of A1 neurons to the adapting stimulus. Finally, SSA caused a bias in the neuronal responses to unbiased stimuli, enhancing the responses to eccentric stimuli. Therefore, we propose that a major function of SSA in A1 neurons is to encode auditory sensory memory on multiple time scales. This SSA might play a role in stream segregation and in binding of auditory objects over many time scales, a property that is crucial for processing of natural auditory scenes in cats and of speech and music in humans.},
	Author = {Ulanovsky, Nachum and Las, Liora and Farkas, Dina and Nelken, Israel},
	Copyright = {Copyright {\copyright} 2004 Society for Neuroscience 0270-6474/04/2410440-14.00/0},
	Doi = {10.1523/JNEUROSCI.1905-04.2004},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/EUEBNU87/Ulanovsky et al. - 2004 - Multiple Time Scales of Adaptation in Auditory Cor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/29RZRARS/10440.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {auditory thalamus, adaptation, auditory cortex, cat, physiology, sensory memory},
	Language = {en},
	Month = nov,
	Number = {46},
	Pages = {10440--10453},
	Pmid = {15548659},
	Title = {Multiple {Time} {Scales} of {Adaptation} in {Auditory} {Cortex} {Neurons}},
	Url = {http://www.jneurosci.org/content/24/46/10440},
	Urldate = {2018-09-26},
	Volume = {24},
	Year = {2004},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/24/46/10440},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1905-04.2004}}

@article{werker_cross-language_1984,
	Abstract = {Previous work in which we compared English infants, English adults, and Hindi adults on their ability to discriminate two pairs of Hindi (non-English) speech contrasts has indicated that infants discriminate speech sounds according to phonetic category without prior specific language experience (Werker, Gilbert, Humphrey, \& Tees, 1981), whereas adults and children as young as age 4 (Werker \& Tees, in press), may lose this ability as a function of age and or linguistic experience. The present work was designed to (a) determine the generalizability of such a decline by comparing adult English, adult Salish, and English infant subjects on their perception of a new non-English (Salish) speech contrast, and (b) delineate the time course of the developmental decline in this ability. The results of these experiments replicate our original findings by showing that infants can discriminate nonnative speech contrasts without relevant experience, and that there is a decline in this ability during ontogeny. Furthermore, data from both cross-sectional and longitudinal studies shows that this decline occurs within the first year of life, and that it is a function of specific language experience.},
	Author = {Werker, Janet F. and Tees, Richard C.},
	Doi = {10.1016/S0163-6383(84)80022-3},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NZ92AZ6W/S0163638384800223.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Keywords = {speech perception, cross-language, decline, infants},
	Month = jan,
	Number = {1},
	Pages = {49--63},
	Shorttitle = {Cross-language speech perception},
	Title = {Cross-language speech perception: {Evidence} for perceptual reorganization during the first year of life},
	Url = {http://www.sciencedirect.com/science/article/pii/S0163638384800223},
	Urldate = {2018-09-27},
	Volume = {7},
	Year = {1984},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638384800223},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0163-6383(84)80022-3}}

@article{rabinowitz_contrast_2011,
	Abstract = {Summary
The auditory system must represent sounds with a wide range of statistical properties. One important property is the spectrotemporal contrast in the acoustic environment: the variation in sound pressure in each frequency band, relative to the mean pressure. We show that neurons in ferret auditory cortex rescale their gain to partially compensate for the spectrotemporal contrast of recent stimulation. When contrast is low, neurons increase their gain, becoming more sensitive to small changes in the stimulus, although the effectiveness of contrast gain control is reduced at low mean levels. Gain is primarily determined by contrast near each neuron's preferred frequency, but there is also a contribution from contrast in more distant frequency bands. Neural responses are modulated by contrast over timescales of â¼100 ms. By using contrast gain control to expand or compress the representation of its inputs, the auditory system may be seeking an efficient coding of natural sounds.},
	Author = {Rabinowitz, Neil C. and Willmore, Ben D. B. and Schnupp, Jan W. H. and King, Andrew J.},
	Doi = {10.1016/j.neuron.2011.04.030},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IA3D5VB9/Rabinowitz et al. - 2011 - Contrast Gain Control in Auditory Cortex.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZSUK6CJ8/S0896627311004351.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = jun,
	Number = {6},
	Pages = {1178--1191},
	Title = {Contrast {Gain} {Control} in {Auditory} {Cortex}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627311004351},
	Urldate = {2018-09-29},
	Volume = {70},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627311004351},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2011.04.030}}

@article{zhang_persistent_2001,
	Abstract = {This study demonstrates that the adult form of 'tonotopic maps' of sound frequency in the rat primary auditory cortex (A1) arises from parallel developmental processes involving two cortical zones: the progressive differentiation and refinement of selectively tone-responsive receptive fields within an initially broadly-tuned posterior zone, and the progressive loss of tone-evoked, short-latency response over an initially large, very broadly tuned anterior zone. The formation of tonotopic maps in A1 was specifically influenced by a rat pup's early acoustic environments. Exposure to pulsed tones resulted in accelerated emergence and an expansion of A1 representations of those specific tone frequencies, as well as a deteriorated tonotopicity and broader-than-normal receptive fields. Thus, auditory experiences during early postnatal development are important in shaping the functional development of auditory cortical representations of specific acoustic environments.},
	Author = {Zhang, Li I. and Bao, Shaowen and Merzenich, Michael M.},
	Copyright = {2001 Nature Publishing Group},
	Doi = {10.1038/nn745},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/QYPIT6Y2/Zhang et al. - 2001 - Persistent and specific influences of early acoust.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KKXYY84P/nn745.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = nov,
	Number = {11},
	Pages = {1123--1130},
	Title = {Persistent and specific influences of early acoustic environments on primary auditory cortex},
	Url = {https://www.nature.com/articles/nn745},
	Urldate = {2018-09-27},
	Volume = {4},
	Year = {2001},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn745},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn745}}

@article{chang_environmental_2003,
	Abstract = {The mammalian auditory cortex normally undergoes rapid and progressive functional maturation. Here we show that rearing infant rat pups in continuous, moderate-level noise delayed the emergence of adultlike topographic representational order and the refinement of response selectivity in the primary auditory cortex (A1) long beyond normal developmental benchmarks. When those noise-reared adult rats were subsequently exposed to a pulsed pure-tone stimulus, A1 rapidly reorganized, demonstrating that exposure-driven plasticity characteristic of the critical period was still ongoing. These results demonstrate that A1 organization is shaped by a young animal's exposure to salient, structured acoustic inputs---and implicate noise as a risk factor for abnormal child development.},
	Author = {Chang, Edward F. and Merzenich, Michael M.},
	Copyright = {American Association for the Advancement of Science},
	Doi = {10.1126/science.1082163},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/XD3VR42E/Chang et Merzenich - 2003 - Environmental Noise Retards Auditory Cortical Deve.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/54UNZTCI/498.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = apr,
	Number = {5618},
	Pages = {498--502},
	Pmid = {12702879},
	Title = {Environmental {Noise} {Retards} {Auditory} {Cortical} {Development}},
	Url = {http://science.sciencemag.org/content/300/5618/498},
	Urldate = {2018-09-27},
	Volume = {300},
	Year = {2003},
	Bdsk-Url-1 = {http://science.sciencemag.org/content/300/5618/498},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1082163}}

@article{webb_mothers_2015,
	Abstract = {Brain development is largely shaped by early sensory experience. However, it is currently unknown whether, how early, and to what extent the newborn's brain is shaped by exposure to maternal sounds when the brain is most sensitive to early life programming. The present study examined this question in 40 infants born extremely prematurely (between 25- and 32-wk gestation) in the first month of life. Newborns were randomized to receive auditory enrichment in the form of audio recordings of maternal sounds (including their mother's voice and heartbeat) or routine exposure to hospital environmental noise. The groups were otherwise medically and demographically comparable. Cranial ultrasonography measurements were obtained at 30 $\pm$ 3 d of life. Results show that newborns exposed to maternal sounds had a significantly larger auditory cortex (AC) bilaterally compared with control newborns receiving standard care. The magnitude of the right and left AC thickness was significantly correlated with gestational age but not with the duration of sound exposure. Measurements of head circumference and the widths of the frontal horn (FH) and the corpus callosum (CC) were not significantly different between the two groups. This study provides evidence for experience-dependent plasticity in the primary AC before the brain has reached full-term maturation. Our results demonstrate that despite the immaturity of the auditory pathways, the AC is more adaptive to maternal sounds than environmental noise. Further studies are needed to better understand the neural processes underlying this early brain plasticity and its functional implications for future hearing and language development.},
	Author = {Webb, Alexandra R. and Heller, Howard T. and Benson, Carol B. and Lahav, Amir},
	Doi = {10.1073/pnas.1414924112},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/D48KFQJS/Webb et al. - 2015 - Mother's voice and heartbeat sounds elicit auditor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2VRTALLV/3152.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {auditory, brain, heartbeat, mother's voice, preterm newborns},
	Language = {en},
	Month = mar,
	Number = {10},
	Pages = {3152--3157},
	Pmid = {25713382},
	Title = {Mother's voice and heartbeat sounds elicit auditory plasticity in the human brain before full gestation},
	Url = {http://www.pnas.org/content/112/10/3152},
	Urldate = {2018-09-27},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {http://www.pnas.org/content/112/10/3152},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1414924112}}

@article{eisermann_normal_2013,
	Abstract = {Summary
The important EEG changes that occur throughout childhood are a major challenge for the neurophysiologist. These reflect brain maturation, which is especially fast during the first year of life. This article describes normal EEG features and variants, characteristic patterns of development, as well as some patterns that are unusual for age, from the neonatal period to adolescence. We also describe how to adapt techniques and prepare patients in order to get interpretable records of appropriate duration, in neonates, infants, and young children.
R{\'e}sum{\'e}
L'organisation spatio-temporelle et les grapho-{\'e}l{\'e}ments physiologiques de l'EEG {\'e}voluent parall{\`e}lement {\`a} la maturation c{\'e}r{\'e}brale, particuli{\`e}rement rapide dans la premi{\`e}re ann{\'e}e de vie. Cet article d{\'e}crit l'EEG normal avec ses variantes et aspects maturatifs caract{\'e}ristiques en fonction de l'{\^a}ge et de l'EEG, qui doivent {\^e}tre connus pour interpr{\'e}ter l'EEG de l'enfant. Nous d{\'e}crivons {\'e}galement les techniques d'enregistrement adapt{\'e}es au nouveau-n{\'e}, au nourrisson et {\`a} l'enfant, indispensables pour obtenir des trac{\'e}s de bonne qualit{\'e}.},
	Author = {Eisermann, M. and Kaminska, A. and Moutard, M. -L. and Soufflet, C. and Plouin, P.},
	Doi = {10.1016/j.neucli.2012.09.091},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/NRZSWVDE/S0987705312003735.html:text/html},
	Issn = {0987-7053},
	Journal = {Neurophysiologie Clinique/Clinical Neurophysiology},
	Keywords = {EEG, Maturation, Electroencephalogram, {\'E}lectroenc{\'e}phalogramme, N{\'e}onatologie, Neonatology, Normal variants, Variantes normales},
	Month = jan,
	Number = {1},
	Pages = {35--65},
	Shorttitle = {Normal {EEG} in childhood},
	Title = {Normal {EEG} in childhood: {From} neonates to adolescents},
	Url = {http://www.sciencedirect.com/science/article/pii/S0987705312003735},
	Urldate = {2018-09-29},
	Volume = {43},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0987705312003735},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neucli.2012.09.091}}

@book{selkirk_phonology_1986,
	Address = {Cambridge, MA, USA},
	Author = {Selkirk, E O},
	Isbn = {0-262-69098-5},
	Publisher = {MIT Press},
	Shorttitle = {Phonology and {Syntax}},
	Title = {Phonology and {Syntax}: {The} {Relationship} {Between} {Sound} and {Structure}},
	Year = {1986}}

@article{von_kriegstein_neural_2007,
	Abstract = {Summary
The size of a resonant source can be estimated by the acoustic-scale information in the sound 1, 2, 3. Previous studies revealed that posterior superior temporal gyrus (STG) responds to acoustic scale in human speech when it is controlled for spectral-envelope change (unpublished data). Here we investigate whether the STG activity is specific to the processing of acoustic scale in human voice or whether it reflects a generic mechanism for the analysis of acoustic scale in resonant sources. In two functional magnetic resonance imaging (fMRI) experiments, we measured brain activity in response to changes in acoustic scale in different categories of resonant sound (human voice, animal call, and musical instrument). We show that STG is activated bilaterally for spectral-envelope changes in general; it responds to changes in category as well as acoustic scale. Activity in left posterior STG is specific to acoustic scale in human voices and not responsive to acoustic scale in other resonant sources. In contrast, the anterior temporal lobe and intraparietal sulcus are activated by changes in acoustic scale across categories. The results imply that the human voice requires special processing of acoustic scale, whereas the anterior temporal lobe and intraparietal sulcus process auditory size information independent of source category.},
	Author = {von Kriegstein, Katharina and Smith, David R. R. and Patterson, Roy D. and Ives, D. Timothy and Griffiths, Timothy D.},
	Doi = {10.1016/j.cub.2007.05.061},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/LRIDUXDP/von Kriegstein et al. - 2007 - Neural Representation of Auditory Size in the Huma.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TQG2DEHZ/S0960982207014856.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Keywords = {SYSNEURO},
	Month = jul,
	Number = {13},
	Pages = {1123--1128},
	Title = {Neural {Representation} of {Auditory} {Size} in the {Human} {Voice} and in {Sounds} from {Other} {Resonant} {Sources}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982207014856},
	Urldate = {2018-09-30},
	Volume = {17},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982207014856},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2007.05.061}}

@article{overath_information_2007,
	Abstract = {The entropy metric derived from information theory provides a means to quantify the amount of information transmitted in acoustic streams like speech or music. By systematically varying the entropy of pitch sequences, we sought brain areas where neural activity and energetic demands increase as a function of entropy. Such a relationship is predicted to occur in an efficient encoding mechanism that uses less computational resource when less information is present in the signal: we specifically tested the hypothesis that such a relationship is present in the planum temporale (PT). In two convergent functional MRI studies, we demonstrated this relationship in PT for encoding, while furthermore showing that a distributed fronto-parietal network for retrieval of acoustic information is independent of entropy. The results establish PT as an efficient neural engine that demands less computational resource to encode redundant signals than those with high information content.},
	Author = {Overath, Tobias and Cusack, Rhodri and Kumar, Sukhbinder and Kriegstein, Katharina von and Warren, Jason D. and Grube, Manon and Carlyon, Robert P. and Griffiths, Timothy D.},
	Doi = {10.1371/journal.pbio.0050288},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/Y4EZTGA9/Overath et al. - 2007 - An Information Theoretic Characterisation of Audit.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/W6RCAN2X/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Acoustics, Fractals, Speech signal processing, Acoustic signals, Entropy, Functional magnetic resonance imaging, Information entropy, Pitch perception},
	Language = {en},
	Month = oct,
	Number = {11},
	Pages = {e288},
	Title = {An {Information} {Theoretic} {Characterisation} of {Auditory} {Encoding}},
	Url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0050288},
	Urldate = {2018-09-30},
	Volume = {5},
	Year = {2007},
	Bdsk-Url-1 = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0050288},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.0050288}}

@book{nespor_prosodic_2007,
	Abstract = {Prosodic Phonology by Marina Nespor and Irene Vogel is now available again. "Nespor \& Vogel 1986" is a citation classic - even after twenty years, it is still recognized as the standard resource on Prosodic Phonology. This groundbreaking work introduces all of the prosodic constituents (syllable, foot, word, clitic group, phonological phrase, intonational phrase and utterance) and provides evidence for each one from numerous languages. Prosodic Phonology also includes a chapter in which experimental psycholinguistic data support the proposed hierarchy.A perceptual study provides evidence that prosodic constituent structure - not syntactic constituent structure - predicts whether listeners are able to disambiguate different types of ambiguous sentences. A chapter on the phonology of poetic meter examines portions of Dante's Divine Comedy.It is demonstrated that the constituents proposed for spoken language also make interesting predictions about literary metrical patterns. Prosodic Phonology is an important reference not only for phonologists, but for all linguists interested in the issue of interfaces among the components of grammar.It is also a basic resource for psycholinguists and cognitive scientists working on linguistic perception and language acquisition.},
	Author = {Nespor, Marina and Vogel, Irene},
	Isbn = {978-3-11-019789-1},
	Keywords = {Language Arts \& Disciplines / Linguistics / General, Language Arts \& Disciplines / Grammar \& Punctuation},
	Language = {en},
	Note = {Google-Books-ID: VQC9jY2qTCkC},
	Publisher = {Walter de Gruyter},
	Shorttitle = {Prosodic {Phonology}},
	Title = {Prosodic {Phonology}: {With} a {New} {Foreword}},
	Year = {2007}}

@article{ding_encoding_2016,
	Abstract = {Neural encoding of sensory stimuli is typically studied by averaging neural signals across repetitions of the same stimulus. However, recent work has suggested that the variance of neural activity across repeated trials can also depend on sensory inputs. Here we characterize how intertrial variance of the local field potential (LFP) in primary auditory cortex of awake ferrets is affected by continuous natural sound stimuli. We find that natural sounds often suppress the intertrial variance of low-frequency LFP ({\textless}16 Hz). However, the amount of the variance reduction is not significantly correlated with the amplitude of the mean response at the same recording site. Moreover, the variance changes occur with longer latency than the mean response. Although the dynamics of the mean response and intertrial variance differ, spectro-temporal receptive field analysis reveals that changes in LFP variance have frequency tuning similar to multiunit activity at the same recording site, suggesting a local origin for changes in LFP variance. In summary, the spectral tuning of LFP intertrial variance and the absence of a correlation with the amplitude of the mean evoked LFP suggest substantial heterogeneity in the interaction between spontaneous and stimulus-driven activity across local neural populations in auditory cortex.},
	Author = {Ding, Nai and Simon, Jonathan Z. and Shamma, Shihab A. and David, Stephen V.},
	Doi = {10.1152/jn.00652.2015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FQ9TIS22/Ding et al. - 2016 - Encoding of natural sounds by variance of the cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8IQGQGSG/jn.00652.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = feb,
	Number = {5},
	Pages = {2389--2398},
	Title = {Encoding of natural sounds by variance of the cortical local field potential},
	Url = {https://www.physiology.org/doi/abs/10.1152/jn.00652.2015},
	Urldate = {2018-10-02},
	Volume = {115},
	Year = {2016},
	Bdsk-Url-1 = {https://www.physiology.org/doi/abs/10.1152/jn.00652.2015},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00652.2015}}

@article{ding_encoding_2016-1,
	Abstract = {Neural encoding of sensory stimuli is typically studied by averaging neural signals across repetitions of the same stimulus. However, recent work has suggested that the variance of neural activity across repeated trials can also depend on sensory inputs. Here we characterize how intertrial variance of the local field potential (LFP) in primary auditory cortex of awake ferrets is affected by continuous natural sound stimuli. We find that natural sounds often suppress the intertrial variance of low-frequency LFP ({\textless}16 Hz). However, the amount of the variance reduction is not significantly correlated with the amplitude of the mean response at the same recording site. Moreover, the variance changes occur with longer latency than the mean response. Although the dynamics of the mean response and intertrial variance differ, spectro-temporal receptive field analysis reveals that changes in LFP variance have frequency tuning similar to multiunit activity at the same recording site, suggesting a local origin for changes in LFP variance. In summary, the spectral tuning of LFP intertrial variance and the absence of a correlation with the amplitude of the mean evoked LFP suggest substantial heterogeneity in the interaction between spontaneous and stimulus-driven activity across local neural populations in auditory cortex.},
	Author = {Ding, Nai and Simon, Jonathan Z. and Shamma, Shihab A. and David, Stephen V.},
	Doi = {10.1152/jn.00652.2015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RAANV79D/Ding et al. - 2016 - Encoding of natural sounds by variance of the cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TZLY7NCA/jn.00652.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = feb,
	Number = {5},
	Pages = {2389--2398},
	Title = {Encoding of natural sounds by variance of the cortical local field potential},
	Url = {https://www.physiology.org/doi/full/10.1152/jn.00652.2015},
	Urldate = {2018-10-03},
	Volume = {115},
	Year = {2016},
	Bdsk-Url-1 = {https://www.physiology.org/doi/full/10.1152/jn.00652.2015},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00652.2015}}

@article{mazzoni_encoding_2008,
	Abstract = {Recordings of local field potentials (LFPs) reveal that the sensory cortex displays rhythmic activity and fluctuations over a wide range of frequencies and amplitudes. Yet, the role of this kind of activity in encoding sensory information remains largely unknown. To understand the rules of translation between the structure of sensory stimuli and the fluctuations of cortical responses, we simulated a sparsely connected network of excitatory and inhibitory neurons modeling a local cortical population, and we determined how the LFPs generated by the network encode information about input stimuli. We first considered simple static and periodic stimuli and then naturalistic input stimuli based on electrophysiological recordings from the thalamus of anesthetized monkeys watching natural movie scenes. We found that the simulated network produced stimulus-related LFP changes that were in striking agreement with the LFPs obtained from the primary visual cortex. Moreover, our results demonstrate that the network encoded static input spike rates into gamma-range oscillations generated by inhibitory--excitatory neural interactions and encoded slow dynamic features of the input into slow LFP fluctuations mediated by stimulus--neural interactions. The model cortical network processed dynamic stimuli with naturalistic temporal structure by using low and high response frequencies as independent communication channels, again in agreement with recent reports from visual cortex responses to naturalistic movies. One potential function of this frequency decomposition into independent information channels operated by the cortical network may be that of enhancing the capacity of the cortical column to encode our complex sensory environment.},
	Author = {Mazzoni, Alberto and Panzeri, Stefano and Logothetis, Nikos K. and Brunel, Nicolas},
	Doi = {10.1371/journal.pcbi.1000239},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8D363ZXP/Mazzoni et al. - 2008 - Encoding of Naturalistic Stimuli by Local Field Po.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AGKH7HGB/article.html:text/html},
	Issn = {1553-7358},
	Journal = {PLOS Computational Biology},
	Keywords = {Neurons, Action potentials, Membrane potential, Neural networks, Coding mechanisms, Gamma-aminobutyric acid, Signaling networks, Visual cortex},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e1000239},
	Title = {Encoding of {Naturalistic} {Stimuli} by {Local} {Field} {Potential} {Spectra} in {Networks} of {Excitatory} and {Inhibitory} {Neurons}},
	Url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000239},
	Urldate = {2018-10-18},
	Volume = {4},
	Year = {2008},
	Bdsk-Url-1 = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000239},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pcbi.1000239}}

@article{steinschneider_spectrotemporal_2008,
	Abstract = {Abstract.  Electroencephalography is increasingly being used to probe the functional organization of auditory cortex. Modulation of the electroencephalographic},
	Author = {Steinschneider, Mitchell and Fishman, Yonatan I. and Arezzo, Joseph C.},
	Doi = {10.1093/cercor/bhm094},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/MUPTXXJL/Steinschneider et al. - 2008 - Spectrotemporal Analysis of Evoked and Induced Ele.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GZPGS3G6/286882.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {610--625},
	Title = {Spectrotemporal {Analysis} of {Evoked} and {Induced} {Electroencephalographic} {Responses} in {Primary} {Auditory} {Cortex} ({A1}) of the {Awake} {Monkey}},
	Url = {https://academic.oup.com/cercor/article/18/3/610/286882},
	Urldate = {2018-10-17},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/18/3/610/286882},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhm094}}

@article{howard_neuromagnetic_2012,
	Abstract = {Speech elicits a phase-locked response in the auditory cortex that is dominated by theta (3--7Hz) frequencies when observed via magnetoencephalography (MEG). This phase-locked response is potentially explained as new phase-locked activity superimposed on the ongoing theta oscillation or, alternatively, as phase-resetting of the ongoing oscillation. The conventional method used to distinguish between the two hypotheses is the comparison of post- to prestimulus amplitude for the phase-locked frequency across a set of trials. In theory, increased amplitude indicates the presence of additive activity, while unchanged amplitude points to phase-resetting. However, this interpretation may not be valid if the amplitude of ongoing background activity also changes following the stimulus. In this study, we employ a new approach that circumvents this problem. Specifically, we utilize a fine-grained time--frequency analysis of MEG channel data to examine the co-modulation of amplitude change and phase coherence in the post-stimulus theta-band response. If the phase-locked response is attributable solely to phase-resetting of the ongoing theta oscillation, then amplitude and phase coherence should be uncorrelated. In contrast, additive activity should produce a positive correlation. We find significant positive correlation not only during the onset response but also throughout the response period. In fact, transient increases in phase coherence are accompanied by transient increases in amplitude in accordance with a ``signal plus background'' model of the evoked response. The results support the hypothesis that the theta-band phase-locked response to attended speech observed using MEG is dominated by additive phase-locked activity.},
	Author = {Howard, Mary F. and Poeppel, David},
	Doi = {10.1016/j.neuroimage.2012.02.028},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/R6VPSGNR/Howard et Poeppel - 2012 - The neuromagnetic response to spoken sentences Co.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/4NGR7GWN/S1053811912002054.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {MEG, Speech, Auditory, Amplitude, Evoked, Phase},
	Month = may,
	Number = {4},
	Pages = {2118--2127},
	Shorttitle = {The neuromagnetic response to spoken sentences},
	Title = {The neuromagnetic response to spoken sentences: {Co}-modulation of theta band amplitude and phase},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811912002054},
	Urldate = {2018-10-17},
	Volume = {60},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811912002054},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2012.02.028}}

@article{churchland_stimulus_2010,
	Abstract = {Neural responses are typically characterized by computing the mean firing rate, but response variability can exist across trials. Many studies have examined the effect of a stimulus on the mean response, but few have examined the effect on response variability. We measured neural variability in 13 extracellularly recorded datasets and one intracellularly recorded dataset from seven areas spanning the four cortical lobes in monkeys and cats. In every case, stimulus onset caused a decline in neural variability. This occurred even when the stimulus produced little change in mean firing rate. The variability decline was observed in membrane potential recordings, in the spiking of individual neurons and in correlated spiking variability measured with implanted 96-electrode arrays. The variability decline was observed for all stimuli tested, regardless of whether the animal was awake, behaving or anaesthetized. This widespread variability decline suggests a rather general property of cortex, that its state is stabilized by an input.},
	Author = {Churchland, Mark M. and Yu, Byron M. and Cunningham, John P. and Sugrue, Leo P. and Cohen, Marlene R. and Corrado, Greg S. and Newsome, William T. and Clark, Andrew M. and Hosseini, Paymon and Scott, Benjamin B. and Bradley, David C. and Smith, Matthew A. and Kohn, Adam and Movshon, J. Anthony and Armstrong, Katherine M. and Moore, Tirin and Chang, Steve W. and Snyder, Lawrence H. and Lisberger, Stephen G. and Priebe, Nicholas J. and Finn, Ian M. and Ferster, David and Ryu, Stephen I. and Santhanam, Gopal and Sahani, Maneesh and Shenoy, Krishna V.},
	Copyright = {2010 Nature Publishing Group},
	Doi = {10.1038/nn.2501},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/QKAEQ8V8/Churchland et al. - 2010 - Stimulus onset quenches neural variability a wide.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ELXRGRCN/nn.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {369--378},
	Shorttitle = {Stimulus onset quenches neural variability},
	Title = {Stimulus onset quenches neural variability: a widespread cortical phenomenon},
	Url = {https://www.nature.com/articles/nn.2501},
	Urldate = {2018-10-17},
	Volume = {13},
	Year = {2010},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn.2501},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.2501}}

@article{ghitza_behavioral_2014,
	Abstract = {Studies on the intelligibility of time-compressed speech have shown flawless performance for moderate compression factors, a sharp deterioration for compression factors above three, and an improved performance as a result of "repackaging" -- a process of dividing the time-compressed waveform into fragments, called packets, and delivering the packets in a prescribed rate. This intricate pattern of performance reflects the reliability of the auditory system in processing speech streams with different information transfer rates; the knee-point of performance defines the auditory channel capacity. This study is concerned with the cortical computation principle that determines channel capacity. Oscillation-based models of speech perception hypothesize that the speech decoding process is guided by a cascade of oscillations with Î¸ as "master," capable of tracking the input rhythm, with the Î¸ cycles aligned with the intervocalic speech fragments termed Î¸-syllables; intelligibility remains high as long as Î¸ is in sync with the input, and it sharply deteriorates once Î¸ is out of sync. In the study described here the hypothesized role of Î¸ was examined by measuring the auditory channel capacity of time-compressed speech undergone repackaging. For all compression factors tested (up to eight), packaging rate at capacity equals 9 packets/sec -- aligned with the upper limit of cortical Î¸, Î¸max (about 9 Hz) -- and the packet duration equals the duration of one uncompressed Î¸-syllable divided by the compression factor. The alignment of both the packaging rate and the packet duration with properties of cortical Î¸ suggests that the auditory channel capacity is determined by Î¸. Irrespective of speech speed, the maximum information transfer rate through the auditory channel is the information in one uncompressed Î¸-syllable long speech fragment per one Î¸max cycle. Equivalently, the auditory channel capacity is 9 Î¸-syllables/sec.},
	Author = {Ghitza, Oded},
	Doi = {10.3389/fpsyg.2014.00652},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/E64G7R4X/Ghitza - 2014 - Behavioral evidence for the role of cortical Î¸ osc.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {Auditory channel capacity, brain rhythms, fast speech, information transfer rate, intelligibility, phonetic variability, theta oscillations},
	Language = {English},
	Title = {Behavioral evidence for the role of cortical Î¸ oscillations in determining auditory channel capacity for speech},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00652/full},
	Urldate = {2018-10-28},
	Volume = {5},
	Year = {2014},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00652/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2014.00652}}

@article{de_roever_investigation_2018,
	Abstract = {It has been 20 years since functional near-infrared spectroscopy (fNIRS) was first used to investigate the evoked haemodynamic response to a stimulus in newborns. The haemodynamic response to functional activation is well-established in adults, with an observed increase in concentration change of oxygenated haemoglobin (â[HbO2]) and decrease in deoxygenated haemoglobin (â[HHb]). However, functional studies in newborns have revealed a mixed response, particularly with â[HHb] where an inconsistent change in direction is observed. The reason for this heterogeneity is unknown, with potential explanations arising from differing physiology in the developing brain, or differences in instrumentation or methodology. The aim of this review is to collate the findings from studies that have employed fNIRS to monitor cerebral haemodynamics in term newborn infants aged 1 day to 1 month. A total of 46 eligible studies were identified; some studies investigated more than one stimulus type, resulting in a total of 51 reported results. The NIRS parameters reported varied across studies with 50/51 cases reporting â[HbO2], 39/51 reporting â[HHb] and 13/51 reporting total haemoglobin concentration â[HbT] (â[HbO2] + â[HHb]). However, of the 39 cases reporting â[HHb] in graphs or tables, only 24 studies explicitly discuss the response (i.e. direction of change) of this variable. In the studies where the fNIRS responses are discussed, 46/51 cases observed an increase in â[HbO2], 7/51 observed an increase or varied â[HHb] and 2/51 reported a varied or negative â[HbT]. An increase in â[HbO2] and decrease or no change in â[HHb] was observed in 15 studies. By reviewing this body of literature, we have identified that the majority of research articles report an increase in â[HbO2] across various functional tasks and did not report the response of â[HHb]. Confirming the normal, healthy haemodynamic response in newborns will allow identification of unhealthy patterns and their association to normal neurodevelopment.},
	Author = {de Roever, Isabel and Bale, Gemma and Mitra, Subhabrata and Meek, Judith and Robertson, Nicola J. and Tachtsidis, Ilias},
	Doi = {10.3389/fnhum.2018.00371},
	File = {de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:/Users/Cecile/Zotero/storage/XYWUFNZN/de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/9YNTN8B9/de Roever et al. - 2018 - Investigation of the Pattern of the Hemodynamic Re.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {newborns, neonates, Brain activity, functional activation, functional near-infrared spectroscopy (fNIRS), haemodynamic response function, Near-infrared spectroscopy (NIRS), neurovascular coupling, term infant},
	Language = {English},
	Shorttitle = {Investigation of the {Pattern} of the {Hemodynamic} {Response} as {Measured} by {Functional} {Near}-{Infrared} {Spectroscopy} ({fNIRS}) {Studies} in {Newborns}, {Less} {Than} a {Month} {Old}},
	Title = {Investigation of the {Pattern} of the {Hemodynamic} {Response} as {Measured} by {Functional} {Near}-{Infrared} {Spectroscopy} ({fNIRS}) {Studies} in {Newborns}, {Less} {Than} a {Month} {Old}: {A} {Systematic} {Review}},
	Url = {https://www.frontiersin.org/articles/10.3389/fnhum.2018.00371/full},
	Urldate = {2018-11-05},
	Volume = {12},
	Year = {2018},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2018.00371/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2018.00371}}

@article{gervain_efficient_2018,
	Abstract = {Speech has long been recognized as `special'. Here, we suggest that one of the reasons for speech being special is that our auditory system has evolved to encode it in an efficient, optimal way. The theory of efficient neural coding argues that our perceptual systems have evolved to encode environmental stimuli in the most efficient way. Mathematically, this can be achieved if the optimally efficient codes match the statistics of the signals they represent. Experimental evidence suggests that the auditory code is optimal in this mathematical sense: statistical properties of speech closely match response properties of the cochlea, the auditory nerve, and the auditory cortex. Even more interestingly, these results may be linked to phenomena in auditory and speech perception.},
	Author = {Gervain, Judit and Geffen, Maria N.},
	Doi = {10.1016/j.tins.2018.09.004},
	File = {Gervain et Geffen - 2018 - Efficient Neural Coding in Auditory and Speech Per.pdf:/Users/Cecile/Zotero/storage/XTZVZQ5C/Gervain et Geffen - 2018 - Efficient Neural Coding in Auditory and Speech Per.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JPQ7V4EJ/S0166223618302467.html:text/html},
	Issn = {0166-2236},
	Journal = {Trends in Neurosciences},
	Keywords = {speech perception, auditory perception, efficient neural coding, information theory},
	Month = oct,
	Title = {Efficient {Neural} {Coding} in {Auditory} and {Speech} {Perception}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0166223618302467},
	Urldate = {2018-11-12},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0166223618302467},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2018.09.004}}

@article{pena_language_2010,
	Abstract = {We tested healthy preterm (born near 28 $\pm$ 2 weeks of gestational age) and full-term infants at various different ages. We compared the two populations on the development of a language acquisition landmark, namely, the ability to distinguish the native language from a rhythmically similar one. This ability is attained 4 months after birth in healthy full-term infants. We measured the induced gamma-band power associated with passive listening to (i) the infants' native language (Spanish), (ii) a rhythmically close language (Italian), and (iii) a rhythmically distant language (Japanese) as a marker of gains in language discrimination. Preterm and full-term infants were matched for neural maturation and duration of exposure to broadcast speech. We found that both full-term and preterm infants only display a response to native speech near 6 months after their term age. Neural maturation seems to constrain advances in speech discrimination at early stages of language acquisition.},
	Author = {Pe{\~n}a, Marcela and Pittaluga, Enrica and Mehler, Jacques},
	Doi = {10.1073/pnas.0914326107},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LYKIGU6V/Pe{\~n}a et al. - 2010 - Language acquisition in premature and full-term in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/D8JFYLBM/0914326107.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {development, gamma-band oscillations, preterm infant, rhythm, speech},
	Language = {en},
	Month = jan,
	Pages = {200914326},
	Pmid = {20133589},
	Title = {Language acquisition in premature and full-term infants},
	Url = {http://www.pnas.org/content/early/2010/01/22/0914326107},
	Urldate = {2018-11-14},
	Year = {2010},
	Bdsk-Url-1 = {http://www.pnas.org/content/early/2010/01/22/0914326107},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0914326107}}

@article{granier-deferre_audition_2011,
	Author = {Granier-Deferre, Carolyn and Busnel, Marie-Claire},
	File = {Granier-Deferre et Busnel - 2011 - L'audition pr{\'e}natale, quoi de neuf .pdf:/Users/Cecile/Zotero/storage/GER9A2LB/Granier-Deferre et Busnel - 2011 - L'audition pr{\'e}natale, quoi de neuf .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YZGZYJFH/revue-spirale-2011-3-page-17.html:text/html},
	Issn = {1278-4699},
	Journal = {Spirale},
	Language = {fr},
	Month = oct,
	Number = {3},
	Pages = {17--32},
	Title = {L'audition pr{\'e}natale, quoi de neuf ?},
	Url = {https://www.cairn.info/revue-spirale-2011-3-page-17.html},
	Urldate = {2018-11-19},
	Volume = {n$\,^{\circ}$ 59},
	Year = {2011},
	Bdsk-Url-1 = {https://www.cairn.info/revue-spirale-2011-3-page-17.html}}

@article{penn_possible_2018,
	Abstract = {The rhythms of speech and the time scales of linguistic units (e.g., syllables) correspond remarkably to cortical oscillations. Previous research has demonstrated that in young adults, the intelligibility of time-compressed speech can be rescued by ``repackaging'' the speech signal through the regular insertion of silent gaps to restore correspondence to the theta oscillator. This experiment tested whether this same phenomenon can be demonstrated in older adults, who show age-related changes in cortical oscillations. The results demonstrated a similar phenomenon for older adults, but that the ``rescue point'' of repackaging is shifted, consistent with a slowing of theta oscillations.},
	Author = {Penn, Lana R. and Ayasse, Nicole D. and Wingfield, Arthur and Ghitza, Oded},
	Doi = {10.1121/1.5054905},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BFXWH7B7/Penn et al. - 2018 - The possible role of brain rhythms in perceiving f.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TMBWZK3V/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = oct,
	Number = {4},
	Pages = {2088--2094},
	Shorttitle = {The possible role of brain rhythms in perceiving fast speech},
	Title = {The possible role of brain rhythms in perceiving fast speech: {Evidence} from adult aging},
	Url = {https://asa.scitation.org/doi/full/10.1121/1.5054905},
	Urldate = {2018-11-19},
	Volume = {144},
	Year = {2018},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/full/10.1121/1.5054905},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.5054905}}

@article{friston_lfp_2015,
	Abstract = {*
              A brief treatment of dynamic coordination in terms of predictive coding.
            
            
              *
              Understanding synchronous message passing in terms of hierarchical predictive coding.
            
            
              *
              Characterising cortical gain control with the dynamic causal modelling of neural fields.
            
            
              *
              Characterising pathophysiological oscillations with dynamic causal modelling of neural masses.
            
          
        , This review surveys recent trends in the use of local field potentials---and their non-invasive counterparts---to address the principles of functional brain architectures. In particular, we treat oscillations as the (observable) signature of context-sensitive changes in synaptic efficacy that underlie coordinated dynamics and message-passing in the brain. This rich source of information is now being exploited by various procedures---like dynamic causal modelling---to test hypotheses about neuronal circuits in health and disease. Furthermore, the roles played by neuromodulatory mechanisms can be addressed directly through their effects on oscillatory phenomena. These neuromodulatory or gain control processes are central to many theories of normal brain function (e.g. attention) and the pathophysiology of several neuropsychiatric conditions (e.g. Parkinson's disease).},
	Author = {Friston, Karl J and Bastos, Andr{\'e} M and Pinotsis, Dimitris and Litvak, Vladimir},
	Doi = {10.1016/j.conb.2014.05.004},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/BEZVT6Z2/Friston et al. - 2015 - LFP and oscillations---what do they tell us.pdf:application/pdf},
	Issn = {0959-4388},
	Journal = {Current Opinion in Neurobiology},
	Month = apr,
	Pages = {1--6},
	Pmcid = {PMC4376394},
	Pmid = {25079053},
	Title = {{LFP} and oscillations---what do they tell us?},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376394/},
	Urldate = {2018-11-20},
	Volume = {31},
	Year = {2015},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4376394/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2014.05.004}}

@article{morillon_asymmetric_2012,
	Abstract = {Low-gamma (25-45 Hz) and theta (4-8 Hz) oscillations are proposed to underpin the integration of phonemic and syllabic information, respectively. How these two scales of analysis split functions across hemispheres is unclear. We analyzed cortical responses from an epileptic patient with a rare bilateral electrode implantation (stereotactic EEG) in primary (A1/BA41 and A2/BA42) and association auditory cortices (BA22). Using time-frequency analyses, we confirmed the dominance of a 5-6 Hz theta activity in right and of a low-gamma (25-45 Hz) activity in left primary auditory cortices (A1/A2), during both resting state and syllable processing. We further detected high-theta (7-8 Hz) resting activity in left primary, but also associative auditory regions. In left BA22, its phase correlated with high-gamma induced power. Such a hierarchical relationship across theta and gamma frequency bands (theta/gamma phase-amplitude coupling) could index the process by which the neural code shifts from stimulus feature- to phonological- encoding, and is associated with the transition from evoked to induced power responses. These data suggest that theta and gamma activity in right and left auditory cortices bear different functions. They support a scheme where slow parsing of the acoustic information dominates in right-hemisphere at a syllabic (5-6 Hz) rate, and left auditory cortex exhibits a more complex cascade of oscillations, reflecting the possible extraction of transient acoustic cues at a fast ({\textasciitilde}25-45 Hz) rate, subsequently integrated at a slower, e.g. syllabic one. Slow oscillations could functionally participate to speech processing by structuring gamma activity in left BA22, where abstract percepts emerge.},
	Author = {Morillon, Benjamin and Liegeois-Chauvel, Catherine and Arnal, Luc Henri and B{\'e}nar, Christian G. and Giraud, Anne-Lise},
	Doi = {10.3389/fpsyg.2012.00248},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RIGNJ5F7/Morillon et al. - 2012 - Asymmetric Function of Theta and Gamma Activity in.pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {auditory, oscillation, asymmetric sampling, gamma, intra-cortical, theta},
	Language = {English},
	Shorttitle = {Asymmetric {Function} of {Theta} and {Gamma} {Activity} in {Syllable} {Processing}},
	Title = {Asymmetric {Function} of {Theta} and {Gamma} {Activity} in {Syllable} {Processing}: {An} {Intra}-{Cortical} {Study}},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00248/full},
	Urldate = {2018-11-22},
	Volume = {3},
	Year = {2012},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00248/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2012.00248}}

@incollection{arnal_temporal_2015,
	Author = {Arnal, Luc H. and Poeppel, David and Giraud, Anne-lise},
	Booktitle = {Handbook of {Clinical} {Neurology}},
	Doi = {10.1016/B978-0-444-62630-1.00005-6},
	File = {Arnal et al. - 2015 - Temporal coding in the auditory cortex.pdf:/Users/Cecile/Zotero/storage/EXRGJIH2/Arnal et al. - 2015 - Temporal coding in the auditory cortex.pdf:application/pdf},
	Isbn = {978-0-444-62630-1},
	Language = {en},
	Pages = {85--98},
	Publisher = {Elsevier},
	Title = {Temporal coding in the auditory cortex},
	Url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444626301000056},
	Urldate = {2018-11-22},
	Volume = {129},
	Year = {2015},
	Bdsk-Url-1 = {https://linkinghub.elsevier.com/retrieve/pii/B9780444626301000056},
	Bdsk-Url-2 = {https://doi.org/10.1016/B978-0-444-62630-1.00005-6}}

@article{garcia-rosales_neuronal_2018,
	Abstract = {Garc{\'\i}a-Rosales et al. identified three distinct neuronal populations within the auditory cortex of awake Carollia perspicillata bats. These neurons responded to different temporal features of communication calls from conspecifics and synchronized to distinct cortical oscillations, suggesting multiscale temporal representation at a cellular level.},
	Author = {Garc{\'\i}a-Rosales, Francisco and Beetz, M. Jerome and Cabral-Calderin, Yuranny and K{\"o}ssl, Manfred and Hechavarria, Julio C.},
	Copyright = {2018 The Author(s)},
	Doi = {10.1038/s42003-018-0205-5},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BL7E9A9S/Garc{\'\i}a-Rosales et al. - 2018 - Neuronal coding of multiscale temporal features in.pdf:application/pdf},
	Issn = {2399-3642},
	Journal = {Communications Biology},
	Language = {en},
	Month = nov,
	Number = {1},
	Pages = {200},
	Title = {Neuronal coding of multiscale temporal features in communication sequences within the bat auditory cortex},
	Url = {https://www.nature.com/articles/s42003-018-0205-5},
	Urldate = {2018-11-26},
	Volume = {1},
	Year = {2018},
	Bdsk-Url-1 = {https://www.nature.com/articles/s42003-018-0205-5},
	Bdsk-Url-2 = {https://doi.org/10.1038/s42003-018-0205-5}}

@article{venezia_hierarchy_2019,
	Abstract = {Existing data indicate that cortical speech processing is hierarchically organized. Numerous studies have shown that early auditory areas encode fine acoustic details while later areas encode abstracted speech patterns. However, it remains unclear precisely what speech information is encoded across these hierarchical levels. Estimation of speech-driven spectrotemporal receptive fields (STRFs) provides a means to explore cortical speech processing in terms of acoustic or linguistic information associated with characteristic spectrotemporal patterns. Here, we estimate STRFs from cortical responses to continuous speech in fMRI. Using a novel approach based on filtering randomly-selected spectrotemporal modulations (STMs) from aurally-presented sentences, STRFs were estimated for a group of listeners and categorized using a data-driven clustering algorithm. `Behavioral STRFs' highlighting STMs crucial for speech recognition were derived from intelligibility judgments. Clustering revealed that STRFs in the supratemporal plane represented a broad range of STMs, while STRFs in the lateral temporal lobe represented circumscribed STM patterns important to intelligibility. Detailed analysis recovered a bilateral organization with posterior-lateral regions preferentially processing STMs associated with phonological information and anterior-lateral regions preferentially processing STMs associated with word- and phrase-level information. Regions in lateral Heschl's gyrus preferentially processed STMs associated with vocalic information (pitch).},
	Author = {Venezia, Jonathan H. and Thurman, Steven M. and Richards, Virginia M. and Hickok, Gregory},
	Doi = {10.1016/j.neuroimage.2018.11.049},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/F47ZRPHM/Venezia et al. - 2019 - Hierarchy of speech-driven spectrotemporal recepti.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/B4PD3A4S/S105381191832130X.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {fMRI, Bubbles, Classification images, Spectrotemporal modulations, Speech perception},
	Month = feb,
	Pages = {647--666},
	Title = {Hierarchy of speech-driven spectrotemporal receptive fields in human auditory cortex},
	Url = {http://www.sciencedirect.com/science/article/pii/S105381191832130X},
	Urldate = {2018-12-03},
	Volume = {186},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S105381191832130X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2018.11.049}}

@article{panzeri_cracking_2017,
	Author = {Panzeri, Stefano and Harvey, Christopher D. and Piasini, Eugenio and Latham, Peter E. and Fellin, Tommaso},
	Doi = {10.1016/j.neuron.2016.12.036},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RWS3USW2/Panzeri et al. - 2017 - Cracking the Neural Code for Sensory Perception by.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/K4N2U4VG/S0896-6273(16)31009-1.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {behavior, information, neural coding, choice, optogenetics, population coding},
	Language = {English},
	Month = feb,
	Number = {3},
	Pages = {491--507},
	Pmid = {28182905},
	Title = {Cracking the {Neural} {Code} for {Sensory} {Perception} by {Combining} {Statistics}, {Intervention}, and {Behavior}},
	Url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31009-1},
	Urldate = {2019-01-04},
	Volume = {93},
	Year = {2017},
	Bdsk-Url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(16)31009-1},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2016.12.036}}

@article{runyan_distinct_2017,
	Abstract = {The cortex represents information across widely varying timescales1,2,3,4,5. For instance, sensory cortex encodes stimuli that fluctuate over few tens of milliseconds6,7, whereas in association cortex behavioural choices can require the maintenance of information over seconds8,9. However, it remains poorly understood whether diverse timescales result mostly from features intrinsic to individual neurons or from neuronal population activity. This question remains unanswered, because the timescales of coding in populations of neurons have not been studied extensively, and population codes have not been compared systematically across cortical regions. Here we show that population codes can be essential to achieve long coding timescales. Furthermore, we find that the properties of population codes differ between sensory and association cortices. We compared coding for sensory stimuli and behavioural choices in auditory cortex and posterior parietal cortex as mice performed a sound localization task. Auditory stimulus information was stronger in auditory cortex than in posterior parietal cortex, and both regions contained choice information. Although auditory cortex and posterior parietal cortex coded information by tiling in time neurons that were transiently informative for approximately 200 milliseconds, the areas had major differences in functional coupling between neurons, measured as activity correlations that could not be explained by task events. Coupling among posterior parietal cortex neurons was strong and extended over long time lags, whereas coupling among auditory cortex neurons was weak and short-lived. Stronger coupling in posterior parietal cortex led to a population code with long timescales and a representation of choice that remained consistent for approximately 1 second. In contrast, auditory cortex had a code with rapid fluctuations in stimulus and choice information over hundreds of milliseconds. Our results reveal that population codes differ across cortex and that coupling is a variable property of cortical populations that affects the timescale of information coding and the accuracy of behaviour.},
	Author = {Runyan, Caroline A. and Piasini, Eugenio and Panzeri, Stefano and Harvey, Christopher D.},
	Copyright = {2017 Nature Publishing Group},
	Doi = {10.1038/nature23020},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CAEV7P2C/Runyan et al. - 2017 - Distinct timescales of population coding across co.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HZVWAW7K/nature23020.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = aug,
	Number = {7665},
	Pages = {92--96},
	Title = {Distinct timescales of population coding across cortex},
	Url = {https://www.nature.com/articles/nature23020},
	Urldate = {2019-01-04},
	Volume = {548},
	Year = {2017},
	Bdsk-Url-1 = {https://www.nature.com/articles/nature23020},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature23020}}

@article{uddin_hearing_2018,
	Abstract = {Environmental sounds (ES) can be understood easily when substituted for words in sentences, suggesting that linguistic context benefits may be mediated by processes more general than some language-specific theories assert. However, the underlying neural processing is not understood. EEG was recorded for spoken sentences ending in either a spoken word or a corresponding ES. Endings were either congruent or incongruent with the sentence frame, and thus were expected to produce N400 activity. However, if ES and word meanings are combined with language context by different mechanisms, different N400 responses would be expected. Incongruent endings (both words and ES) elicited frontocentral negativities corresponding to the N400 typically observed to incongruent spoken words. Moreover, sentential constraint had similar effects on N400 topographies to ES and words. Comparison of speech and ES responses suggests that understanding meaning in speech context may be mediated by similar neural mechanisms for these two types of stimuli.},
	Author = {Uddin, Sophia and Heald, Shannon L. M. and Van Hedger, Stephen C. and Nusbaum, Howard C.},
	Doi = {10.1016/j.bandl.2018.02.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/PR5C2WV5/Uddin et al. - 2018 - Hearing sounds as words Neural responses to envir.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/E6GI62AD/S0093934X17303073.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Keywords = {Event-related potential, Context, N400, Environmental sounds, Language processing, Sentence understanding},
	Month = apr,
	Pages = {51--61},
	Shorttitle = {Hearing sounds as words},
	Title = {Hearing sounds as words: {Neural} responses to environmental sounds in the context of fluent speech},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X17303073},
	Urldate = {2018-12-26},
	Volume = {179},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X17303073},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.bandl.2018.02.004}}

@article{costafreda_pooling_2009,
	Abstract = {The quantitative analysis of pooled data from related fMRI experiments has the potential to significantly accelerate progress in brain mapping. Such data-pooling can be achieved through meta-analysis (the pooled analysis of published results), mega-analysis (the pooled analysis of raw data) or multi-site studies which can be seen as designed mega-analyses. Current limitations in function-location brain mapping and how data-pooling can be used to remediate them are reviewed, with particular attention to power aggregation and mitigation of false positive results. Some recently developed analysis tools for meta- and mega-analysis are also presented, and recommendations for the conduct of valid fMRI data pooling are formulated.},
	Author = {Costafreda, Sergi G.},
	Doi = {10.3389/neuro.11.033.2009},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4T5ZJ7CZ/Costafreda - 2009 - Pooling fMRI data meta-analysis, mega-analysis an.pdf:application/pdf},
	Issn = {1662-5196},
	Journal = {Frontiers in Neuroinformatics},
	Keywords = {fMRI, false positive results, mega-analysis, Meta-analysis, multi-center studies, power, random effects analysis, Study Design},
	Language = {English},
	Shorttitle = {Pooling {fMRI} data},
	Title = {Pooling {fMRI} data: meta-analysis, mega-analysis and multi-center studies},
	Url = {https://www.frontiersin.org/articles/10.3389/neuro.11.033.2009/full},
	Urldate = {2019-01-22},
	Volume = {3},
	Year = {2009},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/neuro.11.033.2009/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/neuro.11.033.2009}}

@article{kruschke_bayesian_2018,
	Abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
	Author = {Kruschke, John K. and Liddell, Torrin M.},
	Doi = {10.3758/s13423-016-1221-4},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/UAQB2KFE/Kruschke et Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf:application/pdf},
	Issn = {1531-5320},
	Journal = {Psychonomic Bulletin \& Review},
	Keywords = {Meta-analysis, Bayes factor, Bayesian inference, Confidence interval, Credible interval, Effect size, Equivalence testing, Highest density interval, Null hypothesis significance testing, Power analysis, Randomized controlled trial, Region of practical equivalence},
	Language = {en},
	Month = feb,
	Number = {1},
	Pages = {178--206},
	Shorttitle = {The {Bayesian} {New} {Statistics}},
	Title = {The {Bayesian} {New} {Statistics}: {Hypothesis} testing, estimation, meta-analysis, and power analysis from a {Bayesian} perspective},
	Url = {https://doi.org/10.3758/s13423-016-1221-4},
	Urldate = {2019-01-29},
	Volume = {25},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.3758/s13423-016-1221-4}}

@article{mai_sounds_2014,
	Abstract = {As one kind of sounds, human voices are important for language acquisition and human-infant relations. Human voices have positive effects on infants, e.g., soothe infants and evoke an infant's smile. Increased left relative to right frontal alpha activity as assessed by the electroencephalogram (EEG) is considered to reflect approach-related emotions. In the present study, we recorded the EEG in thirty-eight 2-month-old infants during a baseline period while listening to sounds, i.e., human voices. Infants displayed increased relative left frontal alpha activity in response to sounds compared to the baseline condition. These results suggest that sounds can elicit relative left frontal activity in young infants, and that this approach-related emotion presents early in life.},
	Author = {Mai, Xiaoqin and Xu, Lin and Li, Mingyan and Shao, Jie and Zhao, Zhengyan and Lamm, Connie and Fox, Nathan A. and Nelson, Charles A. and Lozoff, Betsy},
	Doi = {10.1016/j.ijpsycho.2014.09.008},
	File = {Version accept{\'e}e:/Users/Cecile/Zotero/storage/VX7HKXBQ/Mai et al. - 2014 - Sounds elicit relative left frontal alpha activity.pdf:application/pdf},
	Issn = {1872-7697},
	Journal = {International Journal of Psychophysiology: Official Journal of the International Organization of Psychophysiology},
	Keywords = {Acoustic Stimulation, Emotions, Female, Frontal Lobe, Functional Laterality, Humans, Infant, Male, Alpha Rhythm, Electroencephalogram (EEG), Frontal lobe, Human voice, Mother-Child Relations},
	Language = {eng},
	Month = dec,
	Number = {3},
	Pages = {287--291},
	Pmcid = {PMC4339870},
	Pmid = {25242501},
	Title = {Sounds elicit relative left frontal alpha activity in 2-month-old infants},
	Volume = {94},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1016/j.ijpsycho.2014.09.008}}

@article{cristia_responses_2014,
	Abstract = {In the adult brain, speech can recruit a brain network that is overlapping with, but not identical to, that involved in perceiving non-linguistic vocalizations. Using the same stimuli that had been presented to human 4-month-olds and adults, as well as adult macaques, we sought to shed light on the cortical networks engaged when human newborns process diverse vocalization types. Near infrared spectroscopy was used to register the response of 40 newborns' perisylvian regions when stimulated with speech, human and macaque emotional vocalizations, as well as auditory controls where the formant structure was destroyed but the long-term spectrum was retained. Left fronto-temporal and parietal regions were significantly activated in the comparison of stimulation versus rest, with unclear selectivity in cortical activation. These results for the newborn brain are qualitatively and quantitatively compared with previous work on newborns, older human infants, adult humans, and adult macaques reported in previous work.},
	Author = {Cristia, Alejandrina and Minagawa, Yasuyo and Dupoux, Emmanuel},
	Doi = {10.1371/journal.pone.0115162},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NVS7J9ZU/Cristia et al. - 2014 - Responses to Vocalizations and Auditory Controls i.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IS3FVFYS/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Emotions, Speech, Speech signal processing, Neonates, Vocalization, Adults, Macaque, Monkeys},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e115162},
	Title = {Responses to {Vocalizations} and {Auditory} {Controls} in the {Human} {Newborn} {Brain}},
	Url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115162},
	Urldate = {2019-02-19},
	Volume = {9},
	Year = {2014},
	Bdsk-Url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115162},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0115162}}

@article{vouloumanos_tuned_2004,
	Abstract = {Do young infants treat speech as a special signal, compared with structurally similar non-speech sounds? We presented 2- to 7-month-old infants with nonsense speech sounds and complex non-speech analogues. The non-speech analogues retain many of the spectral and temporal properties of the speech signal, including the pitch contour information which is known to be salient to young listeners, and thus provide a stringent test for a potential listening bias for speech. Our results show that infants as young as 2 months of age listened longer to speech sounds. This listening selectivity indicates that early-functioning biases direct infants' attention to speech, granting speech a special status in relation to other sounds.},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena and Werker, Janet F.},
	Date-Modified = {2020-06-16 13:47:57 +0200},
	Doi = {10.1111/j.1467-7687.2004.00345.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/8L54R3V4/Vouloumanos et Werker - 2004 - Tuned to the signal the privileged status of spee.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6NEE2BYM/j.1467-7687.2004.00345.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Number = {3},
	Pages = {270--276},
	Shorttitle = {Tuned to the signal},
	Title = {Tuned to the signal: the privileged status of speech for young infants},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2004.00345.x},
	Urldate = {2019-02-19},
	Volume = {7},
	Year = {2004},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2004.00345.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-7687.2004.00345.x}}

@article{shultz_three-month-olds_2010,
	Abstract = {Human infants show a preference for listening to speech, but little is known about how infants listen to other naturally occurring sounds. Here, we test infants' listening bias for speech against a range of naturally occurring sounds that share properties of speech to varying extents and we aim to better characterize the speech properties that attract infant attention. We compared 3-month-olds' listening patterns for five types of sounds: nonnative speech, rhesus macaque vocalizations, human noncommunicative vocalizations, human communicative nonspeech vocalizations, and environmental sounds. Across three experiments, 3-month-olds preferred speech to the other four types of sounds. The set of acoustic properties we measured---pitch, peak amplitude, nonzero-root mean square amplitude, frequency difference and amplitude variance---did not predict infant looking time. Our results demonstrate that young infants attend selectively to speech over many other naturally occurring stimuli, an important tool for learning language.},
	Annote = {meta-analysis},
	Author = {Shultz, Sarah and Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:47:50 +0200},
	Doi = {10.1080/15475440903507830},
	File = {Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:/Users/Cecile/Zotero/storage/MF96VJHB/Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VA3LY5F3/15475440903507830.html:text/html;Version soumise:/Users/Cecile/Zotero/storage/J525FMXY/Shultz et Vouloumanos - 2010 - Three-Month-Olds Prefer Speech to Other Naturally .pdf:application/pdf},
	Issn = {1547-5441},
	Journal = {Language Learning and Development},
	Month = sep,
	Number = {4},
	Pages = {241--257},
	Title = {Three-{Month}-{Olds} {Prefer} {Speech} to {Other} {Naturally} {Occurring} {Signals}},
	Url = {https://doi.org/10.1080/15475440903507830},
	Urldate = {2019-03-21},
	Volume = {6},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1080/15475440903507830}}

@article{mcdonald_infant_2019,
	Abstract = {Infants are responsive to and show a preference for human vocalizations from very early in development. While previous studies have provided a strong foundation of understanding regarding areas of the infant brain that respond preferentially to social vs. non-social sounds, how the infant brain responds to sounds of varying social significance over time, and how this relates to behavior, is less well understood. The current study uniquely examined longitudinal brain responses to social sounds of differing social-communicative value in infants at 3 and 6 months of age using functional near-infrared spectroscopy (fNIRS). At 3 months, infants showed similar patterns of widespread activation in bilateral temporal cortices to communicative and non-communicative human non-speech vocalizations, while by 6 months infants showed more similar, and focal, responses to social sounds that carried increased social value (infant-directed speech and human non-speech communicative sounds). In addition, we found that brain activity at 3 months of age related to later brain activity and receptive language abilities as measured at 6 months. These findings suggest areas of consistency and change in auditory social perception between 3 and 6 months of age.},
	Author = {McDonald, Nicole M. and Perdue, Katherine L. and Eilbott, Jeffrey and Loyal, Jaspreet and Shic, Frederick and Pelphrey, Kevin A.},
	Doi = {10.1016/j.dcn.2019.100638},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/83NWVR54/McDonald et al. - 2019 - Infant brain responses to social sounds A longitu.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/IT3ULPGS/S187892931830118X.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Brain development, fNIRS, Auditory stimuli, Infancy, Social perception},
	Month = apr,
	Pages = {100638},
	Shorttitle = {Infant brain responses to social sounds},
	Title = {Infant brain responses to social sounds: {A} longitudinal functional near-infrared spectroscopy study},
	Url = {http://www.sciencedirect.com/science/article/pii/S187892931830118X},
	Urldate = {2019-03-21},
	Volume = {36},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S187892931830118X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2019.100638}}

@article{dehaene-lambertz_neural_2005,
	Abstract = {Many people exposed to sinewave analogues of speech first report hearing them as electronic glissando and, later, when they switch into a `speech mode', hearing them as syllables. This perceptual switch modifies their discrimination abilities, enhancing perception of differences that cross phonemic boundaries while diminishing perception of differences within phonemic categories. Using high-density evoked potentials and fMRI in a discrimination paradigm, we studied the changes in brain activity that are related to this change in perception. With ERPs, we observed that phonemic coding is faster than acoustic coding: The electrophysiological mismatch response (MMR) occurred earlier for a phonemic change than for an equivalent acoustic change. The MMR topography was also more asymmetric for a phonemic change than for an acoustic change. In fMRI, activations were also significantly asymmetric, favoring the left hemisphere in both perception modes. Furthermore, switching to the speech mode significantly enhanced activation in the posterior parts of the left superior gyrus and sulcus relative to the non-speech mode. When responses to a change of stimulus were studied, a cluster of voxels in the supramarginal gyrus was activated significantly more by a phonemic change than by an acoustic change. These results demonstrate that phoneme perception in adults relies on a specific and highly efficient left-hemispheric network, which can be activated in top-down fashion when processing ambiguous speech/non-speech stimuli.},
	Author = {Dehaene-Lambertz, Ghislaine and Pallier, Christophe and Serniclaes, Willy and Sprenger-Charolles, Liliane and Jobert, Antoinette and Dehaene, Stanislas},
	Doi = {10.1016/j.neuroimage.2004.09.039},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JZACHBE6/Dehaene-Lambertz et al. - 2005 - Neural correlates of switching from auditory to sp.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/D39TNUZE/S1053811904005452.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Auditory, ERP, Speech perception, MRI, Non-speech stimuli},
	Month = jan,
	Number = {1},
	Pages = {21--33},
	Title = {Neural correlates of switching from auditory to speech perception},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811904005452},
	Urldate = {2019-03-27},
	Volume = {24},
	Year = {2005},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811904005452},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2004.09.039}}

@article{morton_conspec_1991,
	Author = {Morton, John and Johnson, Mark H},
	File = {Morton et Johnson - CONSPEC and CONLERN A Two-Process Theory of Infan.pdf:/Users/Cecile/Zotero/storage/NQ3VZVDM/Morton et Johnson - CONSPEC and CONLERN A Two-Process Theory of Infan.pdf:application/pdf},
	Journal = {Psychological Review},
	Language = {en},
	Number = {2},
	Pages = {164--181},
	Title = {{CONSPEC} and {CONLERN}: {A} {Two}-{Process} {Theory} of {Infant} {Face} {Recognition}},
	Volume = {98},
	Year = {1991}}

@article{gaucher_cortical_2013,
	Abstract = {In all sensory modalities, intracortical inhibition shapes the functional properties of cortical neurons but also influences the responses to natural stimuli. Studies performed in various species have revealed that auditory cortex neurons respond to conspecific vocalizations by temporal spike patterns displaying a high trial-to-trial reliability, which might result from precise timing between excitation and inhibition. Studying the guinea pig auditory cortex, we show that partial blockage of GABAA receptors by gabazine (GBZ) application (10 Î¼m, a concentration that promotes expansion of cortical receptive fields) increased the evoked firing rate and the spike-timing reliability during presentation of communication sounds (conspecific and heterospecific vocalizations), whereas GABAB receptor antagonists [10 Î¼m saclofen; 10--50 Î¼m CGP55845 (p-3-aminopropyl-p-diethoxymethyl phosphoric acid)] had nonsignificant effects. Computing mutual information (MI) from the responses to vocalizations using either the evoked firing rate or the temporal spike patterns revealed that GBZ application increased the MI derived from the activity of single cortical site but did not change the MI derived from population activity. In addition, quantification of information redundancy showed that GBZ significantly increased redundancy at the population level. This result suggests that a potential role of intracortical inhibition is to reduce information redundancy during the processing of natural stimuli.},
	Author = {Gaucher, Quentin and Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Edeline, Jean-Marc},
	Copyright = {Copyright {\copyright} 2013 the authors 0270-6474/13/3310713-16\$15.00/0},
	Doi = {10.1523/JNEUROSCI.0079-13.2013},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/434SN7UY/Gaucher et al. - 2013 - Cortical Inhibition Reduces Information Redundancy.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NN8JDLAQ/10713.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = jun,
	Number = {26},
	Pages = {10713--10728},
	Pmid = {23804094},
	Title = {Cortical {Inhibition} {Reduces} {Information} {Redundancy} at {Presentation} of {Communication} {Sounds} in the {Primary} {Auditory} {Cortex}},
	Url = {http://www.jneurosci.org/content/33/26/10713},
	Urldate = {2019-04-19},
	Volume = {33},
	Year = {2013},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/33/26/10713},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.0079-13.2013}}

@article{gaucher_how_2013,
	Abstract = {A major goal in auditory neuroscience is to characterize how communication sounds are represented at the cortical level. The present review aims at investigating the role of auditory cortex in the processing of speech, bird songs and other vocalizations, which all are spectrally and temporally highly structured sounds. Whereas earlier studies have simply looked for neurons exhibiting higher firing rates to particular conspecific vocalizations over their modified, artificially synthesized versions, more recent studies determined the coding capacity of temporal spike patterns, which are prominent in primary and non-primary areas (and also in non-auditory cortical areas). In several cases, this information seems to be correlated with the behavioral performance of human or animal subjects, suggesting that spike-timing based coding strategies might set the foundations of our perceptive abilities. Also, it is now clear that the responses of auditory cortex neurons are highly nonlinear and that their responses to natural stimuli cannot be predicted from their responses to artificial stimuli such as moving ripples and broadband noises. Since auditory cortex neurons cannot follow rapid fluctuations of the vocalizations envelope, they only respond at specific time points during communication sounds, which can serve as temporal markers for integrating the temporal and spectral processing taking place at subcortical relays. Thus, the temporal sparse code of auditory cortex neurons can be considered as a first step for generating high level representations of communication sounds independent of the acoustic characteristic of these sounds. This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	Author = {Gaucher, Quentin and Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Laudanski, Jonathan and Occelli, Florian and Edeline, Jean-Marc},
	Doi = {10.1016/j.heares.2013.03.011},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/SPTXZPCV/S0378595513000920.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = nov,
	Pages = {102--112},
	Series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	Title = {How do auditory cortex neurons represent communication sounds?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513000920},
	Urldate = {2019-04-19},
	Volume = {305},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513000920},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.03.011}}

@article{bennur_understanding_2013-1,
	Abstract = {Acoustic communication between animals requires them to detect, discriminate, and categorize conspecific or heterospecific vocalizations in their natural environment. Laboratory studies of the auditory-processing abilities that facilitate these tasks have typically employed a broad range of acoustic stimuli, ranging from natural sounds like vocalizations to ``artificial'' sounds like pure tones and noise bursts. However, even when using vocalizations, laboratory studies often test abilities like categorization in relatively artificial contexts. Consequently, it is not clear whether neural and behavioral correlates of these tasks (1) reflect extensive operant training, which drives plastic changes in auditory pathways, or (2) the innate capacity of the animal and its auditory system. Here, we review a number of recent studies, which suggest that adopting more ethological paradigms utilizing natural communication contexts are scientifically important for elucidating how the auditory system normally processes and learns communication sounds. Additionally, since learning the meaning of communication sounds generally involves social interactions that engage neuromodulatory systems differently than laboratory-based conditioning paradigms, we argue that scientists need to pursue more ethological approaches to more fully inform our understanding of how the auditory system is engaged during acoustic communication. This article is part of a Special Issue entitled ``Communication Sounds and the Brain: New Directions and Perspectives''.},
	Author = {Bennur, Sharath and Tsunada, Joji and Cohen, Yale E. and Liu, Robert C.},
	Doi = {10.1016/j.heares.2013.08.008},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/39C47Z3N/S0378595513001998.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/ZMWBMEIC/Bennur et al. - 2013 - Understanding the neurophysiological basis of audi.pdf:application/pdf},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = nov,
	Pages = {3--9},
	Series = {Communication {Sounds} and the {Brain}: {New} {Directions} and {Perspectives}},
	Shorttitle = {Understanding the neurophysiological basis of auditory abilities for social communication},
	Title = {Understanding the neurophysiological basis of auditory abilities for social communication: {A} perspective on the value of ethological paradigms},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	Urldate = {2019-04-19},
	Volume = {305},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595513001998},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2013.08.008}}

@article{gaucher_how_2012,
	Abstract = {Simultaneous recording of multiple neurons, or neuron groups, offers new promise for investigating fundamental questions about the neural code. We used arrays of 16 electrodes in the tonotopic, primary, auditory cortex of guinea pigs and we extracted LFP- and spike-based spectro-temporal receptive fields (STRFs). We confirm here that LFP signals provide broadly tuned activity which lacks frequency resolution compared to multiunit signals and, therefore, lead to large redundancy in neural responses even between recording sites far apart. Thanks to the use of multi-electrode arrays which allows simultaneous recordings, we also focused on functional relationships between neuronal discharges (through cross-correlations) and between LFPs (through coherence). Since the LFP is composed of distinct brain rhythms, the LFP results were split into three frequency bands from the slowest to the fastest components of LFPs. For driven as well as spontaneous activity, we show that components {\textgreater}70Hz in LFPs are much less coherent between recording sites than slower components. In general, coherence between LFPs from two recordings sites is positively correlated with the degree of frequency overlap between the two corresponding STRFs, similar to cross-correlation between multiunit activities. However, coherence is only weakly correlated with cross-correlation in all frequency ranges. Altogether, these results suggest that LFPs reflect global functional connectivity in the thalamocortical auditory system whereas spiking activities reflect more independent local processing.},
	Author = {Gaucher, Quentin and Edeline, Jean-Marc and Gour{\'e}vitch, Boris},
	Doi = {10.1016/j.jphysparis.2011.09.006},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/QJBACN2K/S0928425711000325.html:text/html},
	Issn = {0928-4257},
	Journal = {Journal of Physiology-Paris},
	Keywords = {Auditory cortex, Coherence, Cross-correlation, LFP, Multi-unit activity, Spectro-temporal receptive field},
	Month = may,
	Number = {3},
	Pages = {93--103},
	Series = {Neuronal {Ensemble} {Recordings} in {Integrative} {Neuroscience}},
	Shorttitle = {How different are the local field potentials and spiking activities?},
	Title = {How different are the local field potentials and spiking activities? {Insights} from multi-electrodes arrays},
	Url = {http://www.sciencedirect.com/science/article/pii/S0928425711000325},
	Urldate = {2019-04-19},
	Volume = {106},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0928425711000325},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jphysparis.2011.09.006}}

@article{huetz_neural_2011,
	Abstract = {Over the last 15years, an increasing number of studies have described the responsiveness of thalamic and cortical neurons to communication sounds. Whereas initial studies have simply looked for neurons exhibiting higher firing rate to conspecific vocalizations over their modified, artificially synthesized versions, more recent studies determine the relative contribution of ``rate coding'' and ``temporal coding'' to the information transmitted by spike trains. In this article, we aim at reviewing the different strategies employed by thalamic and cortical neurons to encode information about acoustic stimuli, from artificial to natural sounds. Considering data obtained with simple stimuli, we first illustrate that different facets of temporal code, ranging from a strict correspondence between spike-timing and stimulus temporal features to more complex coding strategies, do already exist with artificial stimuli. We then review lines of evidence indicating that spike-timing provides an efficient code for discriminating communication sounds from thalamus, primary and non-primary auditory cortex up to frontal areas. As the neural code probably developed, and became specialized, over evolution to allow precise and reliable processing of sounds that are of survival value, we argue that spike-timing based coding strategies might set the foundations of our perceptive abilities.},
	Author = {Huetz, Chlo{\'e} and Gour{\'e}vitch, Boris and Edeline, Jean-Marc},
	Doi = {10.1016/j.heares.2010.01.010},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/8PCXJ7TI/S0378595510000237.html:text/html},
	Issn = {0378-5955},
	Journal = {Hearing Research},
	Month = jan,
	Number = {1},
	Pages = {147--158},
	Series = {Auditory {Cortex}: {Current} {Concepts} in {Human} and {Animal} {Research}},
	Shorttitle = {Neural codes in the thalamocortical auditory system},
	Title = {Neural codes in the thalamocortical auditory system: {From} artificial stimuli to communication sounds},
	Url = {http://www.sciencedirect.com/science/article/pii/S0378595510000237},
	Urldate = {2019-04-19},
	Volume = {271},
	Year = {2011},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0378595510000237},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.heares.2010.01.010}}

@article{ferry_categorization_2010,
	Abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1111/j.1467-8624.2009.01408.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/5LTQDGNY/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/82XHNAUY/j.1467-8624.2009.01408.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {2},
	Pages = {472--479},
	Shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	Title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Urldate = {2019-05-06},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{fulkerson_words_2007,
	Abstract = {Recent studies reveal that naming has powerful conceptual consequences within the first year of life. Naming distinct objects with the same word highlights commonalities among the objects and promotes object categorization. In the present experiment, we pursued the origin of this link by examining the influence of words and tones on object categorization in infants at 6 and 12 months. At both ages, infants hearing a novel word for a set of distinct objects successfully formed object categories; those hearing a sequence of tones for the same objects did not. These results support the view that infants are sensitive to powerful and increasingly nuanced links between linguistic and conceptual units very early in the process of lexical acquisition.},
	Author = {Fulkerson, Anne L. and Waxman, Sandra R.},
	Doi = {10.1016/j.cognition.2006.09.005},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/W4QZEQUC/Fulkerson et Waxman - 2007 - Words (but not Tones) facilitate object categoriza.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/JSVIAAI8/S001002770600196X.html:text/html},
	Issn = {0010-0277},
	Journal = {Cognition},
	Keywords = {Categorization, Infancy, Object naming},
	Month = oct,
	Number = {1},
	Pages = {218--228},
	Shorttitle = {Words (but not {Tones}) facilitate object categorization},
	Title = {Words (but not {Tones}) facilitate object categorization: {Evidence} from 6- and 12-month-olds},
	Url = {http://www.sciencedirect.com/science/article/pii/S001002770600196X},
	Urldate = {2019-05-06},
	Volume = {105},
	Year = {2007},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S001002770600196X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cognition.2006.09.005}}

@article{balaban_words_1997,
	Abstract = {Previous research reveals that novel words highlight object categories for preschoolers and infants as young as 12 months. Three experiments extend these findings to 9-month-olds. Infants were familiarized to slides of animals (e.g., rabbits). Infants in theWordcondition heard infant-directed word phrases (``a rabbit'') and infants in theTonecondition heard tones. During familiarization, infants' visual fixation was enhanced on trials with sounds (either words or tones), relative to silent trials. On test trials, a new exemplar from the familiar category (e.g., rabbit) was paired with a novel animal (e.g., pig). Infants in theWordcondition showed greater attention to novelty than those in theTonecondition. A third group of infants who heard content-filtered words responded similarly to infants in theWordcondition. Implications of the facilitative effects of words and content-filtered words on object categorization are discussed within a framework describing infants' emerging appreciation of language over the first year of life.},
	Author = {Balaban, Marie T. and Waxman, Sandra R.},
	Doi = {10.1006/jecp.1996.2332},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/NJQ9YD4N/Balaban et Waxman - 1997 - Do Words Facilitate Object Categorization in 9-Mon.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/MDJ4HRKS/S0022096596923322.html:text/html},
	Issn = {0022-0965},
	Journal = {Journal of Experimental Child Psychology},
	Month = jan,
	Number = {1},
	Pages = {3--26},
	Title = {Do {Words} {Facilitate} {Object} {Categorization} in 9-{Month}-{Old} {Infants}?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0022096596923322},
	Urldate = {2019-05-06},
	Volume = {64},
	Year = {1997},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0022096596923322},
	Bdsk-Url-2 = {https://doi.org/10.1006/jecp.1996.2332}}

@article{ferry_categorization_2010-1,
	Abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1111/j.1467-8624.2009.01408.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NXRHDH65/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IRBDQHVV/j.1467-8624.2009.01408.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {2},
	Pages = {472--479},
	Shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	Title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Urldate = {2019-05-06},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{ferry_categorization_2010-2,
	Abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1111/j.1467-8624.2009.01408.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/WX23Q27Y/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/66LS2LAW/j.1467-8624.2009.01408.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {2},
	Pages = {472--479},
	Shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	Title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Urldate = {2019-05-06},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{ferry_categorization_2010-3,
	Abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1111/j.1467-8624.2009.01408.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/JH3N4LPT/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/37MPK8US/j.1467-8624.2009.01408.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {2},
	Pages = {472--479},
	Shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	Title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Urldate = {2019-05-06},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{ferry_categorization_2010-4,
	Abstract = {Neonates prefer human speech to other nonlinguistic auditory stimuli. However, it remains an open question whether there are any conceptual consequences of words on object categorization in infants younger than 6 months. The current study examined the influence of words and tones on object categorization in forty-six 3- to 4-month-old infants. Infants were familiarized to different exemplars of a category accompanied by either a labeling phrase or a tone sequence. In test, infants viewed novel category and new within-category exemplars. Infants who heard labeling phrases provided evidence of categorization at test while infants who heard tone sequences did not, suggesting that infants as young as 3 months of age treat words and tones differently vis-{\`a}-vis object categorization.},
	Author = {Ferry, Alissa L. and Hespos, Susan J. and Waxman, Sandra R.},
	Doi = {10.1111/j.1467-8624.2009.01408.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/32QB3579/Ferry et al. - 2010 - Categorization in 3- and 4-Month-Old Infants An A.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/U66JS29L/j.1467-8624.2009.01408.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {2},
	Pages = {472--479},
	Shorttitle = {Categorization in 3- and 4-{Month}-{Old} {Infants}},
	Title = {Categorization in 3- and 4-{Month}-{Old} {Infants}: {An} {Advantage} of {Words} {Over} {Tones}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Urldate = {2019-05-06},
	Volume = {81},
	Year = {2010},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.2009.01408.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1467-8624.2009.01408.x}}

@article{colombo_method_1981,
	Abstract = {In two experiments, infants were-presented with varying auditory stimuli contingent upon their fixation to identical but separate visual targets. Differential responses were found in total fixation time to targets on the basis of the auditory stimulus associated with them. This method for assessment of auditory selectivity can be used with infqnts as young as four months of age.},
	Annote = {meta-analysis},
	Author = {Colombo, John and Bundy, Robert S.},
	Date-Modified = {2020-06-16 13:52:13 +0200},
	Doi = {10.1016/S0163-6383(81)80025-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/JTQFMQ5X/Colombo et Bundy - 1981 - A method for the measurement of infant auditory se.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KAIVD9M2/S0163638381800252.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Month = mar,
	Pages = {219--223},
	Title = {A method for the measurement of infant auditory selectivity},
	Url = {http://www.sciencedirect.com/science/article/pii/S0163638381800252},
	Urldate = {2019-05-02},
	Volume = {4},
	Year = {1981},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638381800252},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0163-6383(81)80025-2}}

@article{park_unifying_2019,
	Abstract = {{\textless}p{\textgreater}Several recent studies implicate parvalbumin- (PV) and somatostatin- (SOM) positive interneurons in processing the temporal context of sounds in the auditory cortex. We built minimal rate and spiking models of AC in order to understand how these interneurons modulate cortical processing. Our models not only replicate findings from recent experiments involving optogenetic manipulation of PV or SOM activity, accounting for the differential effects of PVs and SOMs in stimulus-specific adaptation, forward suppression and tuning-curve adaptation, but also provided for a simple mechanism for changes to PV-modulated functional connectivity. The unifying mechanisms of our model include dynamic synapses from SOMs and PVs to pyramidal neurons, such as depressing and facilitating synapses from PVs and SOMs to pyramidal neurons, respectively. To reproduce experimental studies, we fine-tuned two key parameters: the strength of thalamic inputs and the strength of optogenetic inactivation. Our model will be useful in predicting the function of PVs and SOMs in sensory processing.{\textless}/p{\textgreater}},
	Author = {Park, Youngmin and Geffen, Maria N.},
	Copyright = {{\copyright} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	Doi = {10.1101/626358},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/32R8DJPW/Park et Geffen - 2019 - A Unifying Mechanistic Model of the Auditory Corte.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KCM56SF8/626358v1.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = may,
	Pages = {626358},
	Title = {A {Unifying} {Mechanistic} {Model} of the {Auditory} {Cortex} with {Inhibitory} {Subtypes}},
	Url = {https://www.biorxiv.org/content/10.1101/626358v1},
	Urldate = {2019-05-10},
	Year = {2019},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/10.1101/626358v1},
	Bdsk-Url-2 = {https://doi.org/10.1101/626358}}

@article{yaron_sensitivity_2012,
	Abstract = {Summary
Neurons in auditory cortex are sensitive to the probability of stimuli: responses to rare stimuli tend to be stronger than responses to common ones. Here, intra- and extracellular recordings from the auditory cortex of halothane-anesthetized rats revealed the existence of a finer sensitivity to the structure of sound sequences. Using oddball sequences in which the order of stimulus presentations is periodic, we found that tones in periodic sequences evoked smaller responses than the same tones in random sequences. Significant reduction in the responses to the common tones in periodic relative to random sequences occurred even when these tones consisted of 95\% of the stimuli in the sequence. The reduction in responses paralleled the complexity of the sound sequences and could not be explained by short-term effects of clusters of deviants on succeeding standards. We conclude that neurons in auditory cortex are sensitive to the detailed structure of sound sequences over timescales of minutes.},
	Author = {Yaron, Amit and Hershenhoren, Itai and Nelken, Israel},
	Doi = {10.1016/j.neuron.2012.08.025},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KG8KRK6H/Yaron et al. - 2012 - Sensitivity to Complex Statistical Regularities in.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/UIRGQLBI/S0896627312007623.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = nov,
	Number = {3},
	Pages = {603--615},
	Title = {Sensitivity to {Complex} {Statistical} {Regularities} in {Rat} {Auditory} {Cortex}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627312007623},
	Urldate = {2019-05-12},
	Volume = {76},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627312007623},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2012.08.025}}

@article{malmierca_pattern-sensitive_2019,
	Abstract = {A `pattern alternation paradigm' has been previously used in human ERP recordings to investigate the brain encoding of complex auditory regularities, but prior studies on regularity encoding in animal models to examine mechanisms of adaptation of auditory neuronal responses have used primarily oddball stimulus sequences to study stimulus-specific adaptation alone. In order to examine the sensitivity of neuronal adaptation to expected and unexpected events embedded in a complex sound sequence, we used a similar patterned sequence of sounds. We recorded single unit activity and compared neuronal responses in the rat inferior colliculus (IC) to sound stimuli conforming to pattern alternation regularity with those to stimuli in which occasional sound repetitions violated that alternation. Results show that some neurons in the rat inferior colliculus are sensitive to the history of patterned stimulation and to violations of patterned regularity, demonstrating that there is a population of subcortical neurons, located as early as the level of the midbrain, that can detect more complex stimulus regularities than previously supposed and that are as sensitive to complex statistics as some neurons in primary auditory cortex. Our findings indicate that these pattern-sensitive neurons can extract temporal and spectral regularities between successive acoustic stimuli. This is important because the extraction of regularities from the sound sequences will result in the development of expectancies for future sounds and hence, the present results are compatible with predictive coding models. Our results demonstrate that some collicular neurons, located as early as in the midbrain level, are involved in the generation and shaping of prediction errors in ways not previously considered and thus, the present findings challenge the prevailing view that perceptual organization of sound only emerges at the auditory cortex level.},
	Author = {Malmierca, Manuel S. and Ni{\~n}o-Aguill{\'o}n, Blanca E. and Nieto-Diego, Javier and Porteros, {\'A}ngel and P{\'e}rez-Gonz{\'a}lez, David and Escera, Carles},
	Doi = {10.1016/j.neuroimage.2018.10.012},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/24ZLSHHX/Malmierca et al. - 2019 - Pattern-sensitive neurons reveal encoding of compl.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/ZNIRCGAK/S1053811918319712.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {MMN, Auditory midbrain, Pattern alternation paradigm, Predictive coding, Single unit recordings, SSA},
	Month = jan,
	Pages = {889--900},
	Title = {Pattern-sensitive neurons reveal encoding of complex auditory regularities in the rat inferior colliculus},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811918319712},
	Urldate = {2019-05-12},
	Volume = {184},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811918319712},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2018.10.012}}

@article{boubenec_detecting_2017,
	Author = {Boubenec, Yves and Lawlor, Jennifer and G{\'o}rska, Urszula and Shamma, Shihab and Englitz, Bernhard},
	Doi = {10.7554/eLife.24910},
	Issn = {2050-084X},
	Journal = {eLife},
	Language = {en},
	Month = mar,
	Title = {Detecting changes in dynamic and complex acoustic environments},
	Url = {https://elifesciences.org/articles/24910},
	Urldate = {2019-05-16},
	Volume = {6},
	Year = {2017},
	Bdsk-Url-1 = {https://elifesciences.org/articles/24910},
	Bdsk-Url-2 = {https://doi.org/10.7554/eLife.24910}}

@article{maor_neural_2019,
	Abstract = {{\textless}p{\textgreater}Auditory perceptual learning of pure tones causes tonotopic map expansion in the primary auditory cortex (A1), but the function this plasticity sub-serves is unclear. We developed an automated training platform called the "Educage", which was used to train mice on a go/no-go auditory discrimination task to their perceptual limits, for difficult discriminations among pure tones or natural sounds. Spiking responses of excitatory and inhibitory L2/3 neurons in mouse A1 revealed learning-induced overrepresentation of the learned frequencies, in accordance with previous literature. Using a novel computational model to study auditory tuning curves we show that overrepresentation does not necessarily improve discrimination performance of the network to the learned tones. In contrast, perceptual learning of natural sounds induced "sparsening" and decorrelation of the neural response, and consequently improving discrimination of these complex sounds. The signature of plasticity in A1 highlights its central role in coding natural sounds as compared to pure tones.{\textless}/p{\textgreater}},
	Author = {Maor, Ido and Shwartz-Ziv, Ravid and Feigin, Libi and Elyada, Yishai and Sompolinsky, Haim and Mizrahi, Adi},
	Copyright = {{\copyright} 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	Doi = {10.1101/273342},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/GGTFP4RC/Maor et al. - 2019 - Neural correlates of learning pure tones versus na.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P4LEIBBP/273342v3.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = jan,
	Pages = {273342},
	Title = {Neural correlates of learning pure tones versus natural sounds in the auditory cortex},
	Url = {https://www.biorxiv.org/content/10.1101/273342v3},
	Urldate = {2019-05-13},
	Year = {2019},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/10.1101/273342v3},
	Bdsk-Url-2 = {https://doi.org/10.1101/273342}}

@article{yaron_sensitivity_2012-1,
	Abstract = {Neurons in auditory cortex are sensitive to the probability of stimuli: responses to rare stimuli tend to be stronger than responses to common ones. Here, intra- and extracellular recordings from the auditory cortex of halothane-anesthetized rats revealed the existence of a finer sensitivity to the structure of sound sequences. Using oddball sequences in which the order of stimulus presentations is periodic, we found that tones in periodic sequences evoked smaller responses than the same tones in random sequences. Significant reduction in the responses to the common tones in periodic relative to random sequences occurred even when these tones consisted of 95\% of the stimuli in the sequence. The reduction in responses paralleled the complexity of the sound sequences and could not be explained by short-term effects of clusters of deviants on succeeding standards. We conclude that neurons in auditory cortex are sensitive to the detailed structure of sound sequences over timescales of minutes.},
	Author = {Yaron, Amit and Hershenhoren, Itai and Nelken, Israel},
	Doi = {10.1016/j.neuron.2012.08.025},
	File = {Yaron et al. - 2012 - Sensitivity to Complex Statistical Regularities in.pdf:/Users/Cecile/Zotero/storage/32ELYPHG/Yaron et al. - 2012 - Sensitivity to Complex Statistical Regularities in.pdf:application/pdf},
	Issn = {08966273},
	Journal = {Neuron},
	Language = {en},
	Month = nov,
	Number = {3},
	Pages = {603--615},
	Title = {Sensitivity to {Complex} {Statistical} {Regularities} in {Rat} {Auditory} {Cortex}},
	Url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312007623},
	Urldate = {2019-05-13},
	Volume = {76},
	Year = {2012},
	Bdsk-Url-1 = {https://linkinghub.elsevier.com/retrieve/pii/S0896627312007623},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2012.08.025}}

@article{nelken_responses_1999,
	Abstract = {Sound-processing strategies that use the highly non-random structure of natural sounds may confer evolutionary advantage to many species. Auditory processing of natural sounds has been studied almost exclusively in the context of species-specific vocalizations1,2,3,4, although these form only a small part of the acoustic biotope5. To study the relationships between properties of natural soundscapes and neuronal processing mechanisms in the auditory system, we analysed sound from a range of different environments. Here we show that for many non-animal sounds and background mixtures of animal sounds, energy in different frequency bands is coherently modulated. Co-modulation of different frequency bands in background noise facilitates the detection of tones in noise by humans, a phenomenon known as co-modulation masking release (CMR)6,7. We show that co-modulation also improves the ability of auditory-cortex neurons to detect tones in noise, and we propose that this property of auditory neurons may underlie behavioural CMR. This correspondence may represent an adaptation of the auditory system for the use of an attribute of natural sounds to facilitate real-world processing tasks.},
	Author = {Nelken, Israel and Rotman, Yaron and Yosef, Omer Bar},
	Copyright = {1999 Macmillan Magazines Ltd.},
	Doi = {10.1038/16456},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LKNM4ADN/Nelken et al. - 1999 - Responses of auditory-cortex neurons to structural.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DRLAN7W7/16456.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {En},
	Month = jan,
	Number = {6715},
	Pages = {154},
	Title = {Responses of auditory-cortex neurons to structural features of natural sounds},
	Url = {https://www.nature.com/articles/16456},
	Urldate = {2019-05-07},
	Volume = {397},
	Year = {1999},
	Bdsk-Url-1 = {https://www.nature.com/articles/16456},
	Bdsk-Url-2 = {https://doi.org/10.1038/16456}}

@article{nelken_encoding_2005,
	Abstract = {Neurons can transmit information about sensory stimuli via their firing rate, spike latency, or by the occurrence of complex spike patterns. Identifying which aspects of the neural responses actually encode sensory information remains a fundamental question in neuroscience. Here we compared various approaches for estimating the information transmitted by neurons in auditory cortex in two very different experimental paradigms, one measuring spatial tuning and the other responses to complex natural stimuli. We demonstrate that, in both cases, spike counts and mean response times jointly carry essentially all the available information about the stimuli. Thus, in auditory cortex, whereas spike counts carry only partial information about stimulus identity or location, the additional availability of relatively coarse temporal information is sufficient in order to extract essentially all the sensory information available in the spike discharge pattern, at least for the relatively short stimuli ({\textless} â¼ 100 ms) commonly used in auditory research.},
	Author = {Nelken, Israel and Chechik, Gal and Mrsic-Flogel, Thomas D. and King, Andrew J. and Schnupp, Jan W. H.},
	Doi = {10.1007/s10827-005-1739-3},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/WRLN849U/Nelken et al. - 2005 - Encoding Stimulus Information by Spike Numbers and.pdf:application/pdf},
	Issn = {1573-6873},
	Journal = {Journal of Computational Neuroscience},
	Keywords = {electrophysiology, auditory cortex, complex sounds, mutual information},
	Language = {en},
	Month = oct,
	Number = {2},
	Pages = {199--221},
	Title = {Encoding {Stimulus} {Information} by {Spike} {Numbers} and {Mean} {Response} {Time} in {Primary} {Auditory} {Cortex}},
	Url = {https://doi.org/10.1007/s10827-005-1739-3},
	Urldate = {2019-05-07},
	Volume = {19},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10827-005-1739-3}}

@article{ulanovsky_multiple_2004-1,
	Abstract = {Neurons in primary auditory cortex (A1) of cats show strong stimulus-specific adaptation (SSA). In probabilistic settings, in which one stimulus is common and another is rare, responses to common sounds adapt more strongly than responses to rare sounds. This SSA could be a correlate of auditory sensory memory at the level of single A1 neurons. Here we studied adaptation in A1 neurons, using three different probabilistic designs. We showed that SSA has several time scales concurrently, spanning many orders of magnitude, from hundreds of milliseconds to tens of seconds. Similar time scales are known for the auditory memory span of humans, as measured both psychophysically and using evoked potentials. A simple model, with linear dependence on both short-term and long-term stimulus history, provided a good fit to A1 responses. Auditory thalamus neurons did not show SSA, and their responses were poorly fitted by the same model. In addition, SSA increased the proportion of failures in the responses of A1 neurons to the adapting stimulus. Finally, SSA caused a bias in the neuronal responses to unbiased stimuli, enhancing the responses to eccentric stimuli. Therefore, we propose that a major function of SSA in A1 neurons is to encode auditory sensory memory on multiple time scales. This SSA might play a role in stream segregation and in binding of auditory objects over many time scales, a property that is crucial for processing of natural auditory scenes in cats and of speech and music in humans.},
	Author = {Ulanovsky, Nachum and Las, Liora and Farkas, Dina and Nelken, Israel},
	Copyright = {Copyright {\copyright} 2004 Society for Neuroscience 0270-6474/04/2410440-14.00/0},
	Doi = {10.1523/JNEUROSCI.1905-04.2004},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DEFT5IJJ/Ulanovsky et al. - 2004 - Multiple Time Scales of Adaptation in Auditory Cor.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BGK82V62/10440.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {auditory thalamus, adaptation, auditory cortex, cat, physiology, sensory memory},
	Language = {en},
	Month = nov,
	Number = {46},
	Pages = {10440--10453},
	Pmid = {15548659},
	Title = {Multiple {Time} {Scales} of {Adaptation} in {Auditory} {Cortex} {Neurons}},
	Url = {http://www.jneurosci.org/content/24/46/10440},
	Urldate = {2019-05-07},
	Volume = {24},
	Year = {2004},
	Bdsk-Url-1 = {http://www.jneurosci.org/content/24/46/10440},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1905-04.2004}}

@misc{noauthor_responses_nodate,
	File = {Responses of auditory-cortex neurons to structural features of natural sounds | Nature:/Users/Cecile/Zotero/storage/GT2FJ6LT/16456.html:text/html},
	Title = {Responses of auditory-cortex neurons to structural features of natural sounds {\textbar} {Nature}},
	Url = {https://www.nature.com/articles/16456},
	Urldate = {2019-05-07},
	Bdsk-Url-1 = {https://www.nature.com/articles/16456}}

@article{polterovich_deviance_2018,
	Abstract = {Deviance sensitivity is the specific response to a surprising stimulus, one that violates expectations set by the past stimulation stream. In audition, deviance sensitivity is often conflated with stimulus-specific adaptation (SSA), the decrease in responses to a common stimulus that only partially generalizes to other, rare stimuli. SSA is usually measured using oddball sequences, where a common (standard) tone and a rare (deviant) tone are randomly intermixed. However, the larger responses to a tone when deviant does not necessarily represent deviance sensitivity. Deviance sensitivity is commonly tested using a control sequence in which many different tones serve as the standard, eliminating the expectations set by the standard ('deviant among many standards'). When the response to a tone when deviant (against a single standard) is larger than the responses to the same tone in the control sequence, it is concluded that true deviance sensitivity occurs. In primary auditory cortex of anesthetized rats, responses to deviants and to the same tones in the control condition are comparable in size. We recorded local field potentials and multiunit activity from the auditory cortex of awake, freely moving rats, implanted with 32-channel drivable microelectrode arrays and using telemetry. We observed highly significant SSA in the awake state. Moreover, the responses to a tone when deviant were significantly larger than the responses to the same tone in the control condition. These results establish the presence of true deviance sensitivity in primary auditory cortex in awake rats.},
	Author = {Polterovich, Ana and Jankowski, Maciej M. and Nelken, Israel},
	Doi = {10.1371/journal.pone.0197678},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/FKB8RTSW/Polterovich et al. - 2018 - Deviance sensitivity in the auditory cortex of fre.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VQJS87U5/article.html:text/html},
	Issn = {1932-6203},
	Journal = {PLOS ONE},
	Keywords = {Signal filtering, Auditory cortex, Anesthesia, Control sequences, Electrode recording, Histology, Microphones, Tetrodes},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {e0197678},
	Title = {Deviance sensitivity in the auditory cortex of freely moving rats},
	Url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0197678},
	Urldate = {2019-05-07},
	Volume = {13},
	Year = {2018},
	Bdsk-Url-1 = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0197678},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pone.0197678}}

@article{pick_reproducible_2019,
	Abstract = {Research synthesis, such as comparative and meta-analyses, requires the extraction of effect sizes from primary literature, which are commonly calculated from descriptive statistics. However, the exact values of such statistics are commonly hidden in figures. Extracting descriptive statistics from figures can be a slow process that is not easily reproducible. Additionally, current software lacks an ability to incorporate important metadata (e.g. sample sizes, treatment/variable names) about experiments and is not integrated with other software to streamline analysis pipelines. Here we present the r package metaDigitise which extracts descriptive statistics such as means, standard deviations and correlations from four plot types: (a) mean/error plots (e.g. bar graphs with standard errors), (b) box plots, (c) scatter plots and (d) histograms. metaDigitise is user-friendly and easy to learn as it interactively guides the user through the data extraction process. Notably, it enables large-scale extraction by automatically loading image files, letting the user stop processing, edit and add to the resulting data-frame at any point. Digitised data can be easily re-plotted and checked, facilitating reproducible data extraction from plots with little inter-observer bias. We hope that by making the process of figure extraction more flexible and easy to conduct, it will improve the transparency and quality of meta-analyses in the future.},
	Author = {Pick, Joel L. and Nakagawa, Shinichi and Noble, Daniel W. A.},
	Copyright = {{\copyright} 2018 The Authors. Methods in Ecology and Evolution {\copyright} 2018 British Ecological Society},
	Doi = {10.1111/2041-210X.13118},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/AGSJPTMB/Pick et al. - 2019 - Reproducible, flexible and high-throughput data ex.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/A6LE77F8/2041-210X.html:text/html},
	Issn = {2041-210X},
	Journal = {Methods in Ecology and Evolution},
	Keywords = {comparative analysis, data extraction, descriptive statistics, figures, images, meta-analysis, r, reproducibility},
	Language = {en},
	Number = {3},
	Pages = {426--431},
	Shorttitle = {Reproducible, flexible and high-throughput data extraction from primary literature},
	Title = {Reproducible, flexible and high-throughput data extraction from primary literature: {The} {metaDigitise} r package},
	Url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13118},
	Urldate = {2019-05-23},
	Volume = {10},
	Year = {2019},
	Bdsk-Url-1 = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13118},
	Bdsk-Url-2 = {https://doi.org/10.1111/2041-210X.13118}}

@article{ramaswamy_algorithmic_2019,
	Abstract = {{\textless}p{\textgreater}Neuroscience is witnessing extraordinary progress in experimental techniques, especially at the neural circuit level. These advances are largely aimed at enabling us to understand how neural circuit computations mechanistically \textit{cause} behavior. Here, using techniques from Theoretical Computer Science, we examine how many experiments are needed to obtain such an empirical understanding. It is proved, mathematically, that establishing the most extensive notions of understanding \textit{need} exponentially-many experiments in the number of neurons, in general, unless a widely-posited hypothesis about computation is false. Worse still, the feasible experimental regime is one where the number of experiments scales \textit{sub-linearly} in the number of neurons, suggesting a fundamental impediment to such an understanding. Determining which notions of understanding are algorithmically tractable, thus, becomes an important new endeavor in Neuroscience.{\textless}/p{\textgreater}},
	Author = {Ramaswamy, Venkatakrishnan},
	Copyright = {{\copyright} 2019, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	Doi = {10.1101/639724},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/3EHBP3BR/Ramaswamy - 2019 - An Algorithmic Barrier to Neural Circuit Understan.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H3HMX75X/639724v1.html:text/html},
	Journal = {bioRxiv},
	Language = {en},
	Month = may,
	Pages = {639724},
	Title = {An {Algorithmic} {Barrier} to {Neural} {Circuit} {Understanding}},
	Url = {https://www.biorxiv.org/content/10.1101/639724v1},
	Urldate = {2019-05-28},
	Year = {2019},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/10.1101/639724v1},
	Bdsk-Url-2 = {https://doi.org/10.1101/639724}}

@article{moher_preferred_2009,
	Author = {Moher, David and Liberati, Alessandro and Tetzlaff, Jennifer and Altman, Douglas G. and Group, The PRISMA},
	Doi = {10.1371/journal.pmed.1000097},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/HFCYZPFE/Moher et al. - 2009 - Preferred Reporting Items for Systematic Reviews a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YWHNN3VJ/article.html:text/html},
	Issn = {1549-1676},
	Journal = {PLOS Medicine},
	Keywords = {Systematic reviews, Meta-analysis, Clinical research design, Database searching, Medical journals, Publication ethics, Research quality assessment, Research reporting guidelines},
	Language = {en},
	Month = jul,
	Number = {7},
	Pages = {e1000097},
	Shorttitle = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}},
	Title = {Preferred {Reporting} {Items} for {Systematic} {Reviews} and {Meta}-{Analyses}: {The} {PRISMA} {Statement}},
	Url = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000097},
	Urldate = {2019-06-19},
	Volume = {6},
	Year = {2009},
	Bdsk-Url-1 = {https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000097},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pmed.1000097}}

@article{stuart_protocol_2017,
	Abstract = {Introduction People who use methamphetamine (MA) regularly, often experience symptoms of mental ill health associated with the use of the drug. These include symptoms of psychosis, depression, anxiety and also cognitive deficits. Accordingly, psychological treatments aim to reduce MA use and related problems, including symptoms of mental ill health. Although there has been a substantial body of research reporting on the evidence of effectiveness of psychological treatments for MA use, there is a paucity of research addressing the effectiveness of these treatments for coexisting symptoms of mental ill health. We aim to address this gap by providing a comprehensive overview of the evidence for psychological treatments for MA use and associated symptoms of mental ill health in experimental/controlled clinical studies. In addition, a critical evaluation of study methods and the outcomes of psychological interventions on MA use and symptoms of mental ill health will be conducted.
Methods and analysis The Cochrane Handbook for Systematic Reviews of Interventions and the Preferred Reporting Items for Systematic Reviews and Meta-Analysis statement will be used to inform the methods of this review. Eight electronic peer-reviewed databases will be searched. Pilot searches have been conducted for MA literature considering controlled clinical trials only. Eligible articles will be independently assessed against inclusion criteria. Before final analyses are completed, searches will be rerun and if eligible, additional studies will be retrieved for inclusion. A quantitative synthesis of the findings will be reported where possible, and `summary of findings' tables will be generated for each comparison. Risk ratios and 95\% CI (dichotomous outcomes) will be calculated and/or effect size according to Cohen's formula (continuous outcomes) for the primary outcome of each trial.
Ethics and dissemination No ethical issues are foreseen. Findings will be disseminated widely to clinicians and researchers via journal publication and conference presentation(s).
Trial registration number CRD42016043657.},
	Author = {Stuart, Alexandra and Baker, Amanda L. and Bowman, Jenny and McCarter, Kristen and Denham, Alexandra Mary Janice and Lee, Nicole and Colyvas, Kim and Dunlop, Adrian},
	Copyright = {{\copyright} Article author(s) (or their employer(s) unless otherwise stated in the text of the article) 2017. All rights reserved. No commercial use is permitted unless otherwise expressly granted.. This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/},
	Doi = {10.1136/bmjopen-2016-015383},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7CPXYWPE/Stuart et al. - 2017 - Protocol for a systematic review of psychological .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UARD7FCL/e015383.html:text/html},
	Issn = {2044-6055, 2044-6055},
	Journal = {BMJ Open},
	Keywords = {mental health, quality in health care, substance misuse},
	Language = {en},
	Month = sep,
	Number = {9},
	Pages = {e015383},
	Pmid = {28882907},
	Shorttitle = {Protocol for a systematic review of psychological treatment for methamphetamine use},
	Title = {Protocol for a systematic review of psychological treatment for methamphetamine use: an analysis of methamphetamine use and mental health symptom outcomes},
	Url = {https://bmjopen.bmj.com/content/7/9/e015383},
	Urldate = {2019-07-01},
	Volume = {7},
	Year = {2017},
	Bdsk-Url-1 = {https://bmjopen.bmj.com/content/7/9/e015383},
	Bdsk-Url-2 = {https://doi.org/10.1136/bmjopen-2016-015383}}

@article{clemens_connecting_2015,
	Abstract = {Summary
Brains are optimized for processing ethologically relevant sensory signals. However, few studies have characterized the neural coding mechanisms that underlie the transformation from natural sensory information to behavior. Here, we focus on acoustic communication in Drosophila melanogaster and use computational modeling to link natural courtship song, neuronal codes, and female behavioral responses to song. We show that melanogaster females are sensitive to long timescale song structure (on the order of tens of seconds). From intracellular recordings, we generate models that recapitulate neural responses to acoustic stimuli. We link these neural codes with female behavior by generating model neural responses to natural courtship song. Using a simple decoder, we predict female behavioral responses to the same song stimuli with high accuracy. Our modeling approach reveals how long timescale song features are represented by the Drosophila brain and how neural representations can be decoded to generate behavioral selectivity for acoustic communication signals.},
	Author = {Clemens, Jan and Girardin, Cyrille C. and Coen, Philip and Guan, Xiao-Juan and Dickson, Barry J. and Murthy, Mala},
	Doi = {10.1016/j.neuron.2015.08.014},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KWXYQIQ7/Clemens et al. - 2015 - Connecting Neural Codes with Behavior in the Audit.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/7CVJW8VH/S0896627315007084.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = sep,
	Number = {6},
	Pages = {1332--1343},
	Title = {Connecting {Neural} {Codes} with {Behavior} in the {Auditory} {System} of {Drosophila}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627315007084},
	Urldate = {2019-07-05},
	Volume = {87},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627315007084},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2015.08.014}}

@phdthesis{vouloumanos_is_2004,
	Abstract = {Language is a uniquely human adaptation that is hypothesised to require specialised anatomical substrates and dedicated processing mechanisms. Speech, the primary medium for language, is argued to rely on specialised substrates and processing as well. Yet, to date, evidence for the speech specialisation hypothesis has been equivocal. The four experiments in this thesis aim to advance the discussion in two ways. The differential processing of speech by humans was investigated through the use of functional neuroimaging tools (Experiment One), and through developmental studies of young infants' listening biases (Experiments Two-Four). In Experiment One, functional neuroimaging tools are used to investigate the specificity of neural substrates recruited in detecting speech compared with closely matched non-speech controls. This study takes advantage of an event-related imaging design that provides a narrow window of observation for neural recruitment during individual stimulus events. The results of the first study demonstrate that adults activate specific neural substrates when detecting speech sounds, indicating that specialised substrates are involved from the early processing stages. Experiments Two through Four take an ethological approach to speech specialisation and investigate whether young infants show a bias for listening to speech as compared to matched non-speech sounds. In Experiment Two, behavioural methods probe whether young infants of 2 to 7 months show listening preferences for speech compared with non-speech. Experiment Three seeks to establish the roots of a speech bias in the neonatal period. Finally, Experiment Four investigates the origin of the bias, to determine whether the speech bias originates from prenatal experience, or is independent of specific experience. The results of these studies show that differential processing has its roots in early infancy, with infants demonstrating a preference for listening to speech from birth. The speech bias shown by neonates appears not to be based on specific experience with speech sounds, but instead is rooted in human biology. Human infants are prewired to preferentially attend to speech, granting speech a special status in relation to other sounds.},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:46:52 +0200},
	Doi = {10.14288/1.0091926},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/J92J6MZ4/Vouloumanos - 2004 - Is speech special insights from neonates and ne.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2G6B4RNS/1.html:text/html},
	Language = {eng},
	School = {University of British Columbia},
	Shorttitle = {Is speech special?},
	Title = {Is speech special? : insights from neonates and neuroimaging},
	Url = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/831/items/1.0091926},
	Urldate = {2019-07-05},
	Year = {2004},
	Bdsk-Url-1 = {https://open.library.ubc.ca/cIRcle/collections/ubctheses/831/items/1.0091926},
	Bdsk-Url-2 = {https://doi.org/10.14288/1.0091926}}

@inproceedings{black_quantifying_2017,
	Abstract = {Author: Black, Alexis et al.; Genre: Conference Paper; Published in Print: 2017; Open Access; Title: Quantifying infants\&apos; statistical word segmentation: A meta-analysis},
	Author = {Black, Alexis and Bergmann, Christina},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KAIAH7W7/Black et Bergmann - 2017 - Quantifying infants' statistical word segmentation.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/5R7Z6Q9K/ViewItemOverviewPage.html:text/html},
	Language = {eng},
	Pages = {124--129},
	Publisher = {Cognitive Science Society},
	Shorttitle = {Quantifying infants' statistical word segmentation},
	Title = {Quantifying infants' statistical word segmentation: {A} meta-analysis},
	Url = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2475527},
	Urldate = {2019-07-05},
	Year = {2017},
	Bdsk-Url-1 = {https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_2475527}}

@article{bergmann_promoting_2018,
	Abstract = {Previous work suggests that key factors for replicability, a necessary feature for theory building, include statistical power and appropriate research planning. These factors are examined by analyzing a collection of 12 standardized meta-analyses on language development between birth and 5 years. With a median effect size of Cohen's d = .45 and typical sample size of 18 participants, most research is underpowered (range = 6\%--99\%; median = 44\%); and calculating power based on seminal publications is not a suitable strategy. Method choice can be improved, as shown in analyses on exclusion rates and effect size as a function of method. The article ends with a discussion on how to increase replicability in both language acquisition studies specifically and developmental research more generally.},
	Author = {Bergmann, Christina and Tsuji, Sho and Piccinini, Page E. and Lewis, Molly L. and Braginsky, Mika and Frank, Michael C. and Cristia, Alejandrina},
	Copyright = {{\copyright} 2018 The Authors. Child Development published by Wiley Periodicals, Inc. on behalf of Society for Research in Child Development},
	Doi = {10.1111/cdev.13079},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4MFMRSHS/Bergmann et al. - 2018 - Promoting Replicability in Developmental Research .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/PRNFGCN8/cdev.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {6},
	Pages = {1996--2009},
	Shorttitle = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses},
	Title = {Promoting {Replicability} in {Developmental} {Research} {Through} {Meta}-analyses: {Insights} {From} {Language} {Acquisition} {Research}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13079},
	Urldate = {2019-07-05},
	Volume = {89},
	Year = {2018},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cdev.13079},
	Bdsk-Url-2 = {https://doi.org/10.1111/cdev.13079}}

@article{oakes_sample_2017,
	Abstract = {Infant research is hard. It is difficult, expensive, and time-consuming to identify, recruit, and test infants. As a result, ours is a field of small sample sizes. Many studies using infant looking time as a measure have samples of 8--12 infants per cell, and studies with more than 24 infants per cell are uncommon. This paper examines the effect of such sample sizes on statistical power and the conclusions drawn from infant looking-time research. An examination of the state of the current literature suggests that most published looking-time studies have low power, which leads in the long run to an increase in both false positive and false negative results. Three data sets with relatively large samples ({\textgreater}30 infants) were used to simulate experiments with smaller sample sizes; 1,000 random subsamples of 8, 12, 16, 20, and 24 infants from the overall samples were selected, making it possible to examine the systematic effect of sample size on the results. This approach revealed that despite clear results with the original large samples, the results with smaller subsamples were highly variable, yielding both false positive and false negative outcomes. Finally, a number of emerging possible solutions are discussed.},
	Author = {Oakes, Lisa M.},
	Copyright = {Copyright {\copyright} International Congress of Infant Studies (ICIS)},
	Doi = {10.1111/infa.12186},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BTRW72W4/Oakes - 2017 - Sample Size, Statistical Power, and False Conclusi.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/8I3TME8W/infa.html:text/html},
	Issn = {1532-7078},
	Journal = {Infancy},
	Language = {en},
	Number = {4},
	Pages = {436--469},
	Title = {Sample {Size}, {Statistical} {Power}, and {False} {Conclusions} in {Infant} {Looking}-{Time} {Research}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12186},
	Urldate = {2019-07-05},
	Volume = {22},
	Year = {2017},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12186},
	Bdsk-Url-2 = {https://doi.org/10.1111/infa.12186}}

@article{van_den_heuvel_differences_2015,
	Abstract = {Infant auditory event-related potentials (AERPs) show a series of marked changes during the first year of life. These AERP changes indicate important advances in early development. The current study examined AERP differences between 2- and 4-month-old infants. An auditory oddball paradigm was delivered to infants with a frequent repetitive tone and three rare auditory events. The three rare events included a shorter than the regular inter-stimulus interval (ISI-deviant), white noise segments, and environmental sounds. The results suggest that the N250 infantile AERP component emerges during this period in response to white noise but not to environmental sounds, possibly indicating a developmental step towards separating acoustic deviance from contextual novelty. The scalp distribution of the AERP response to both the white noise and the environmental sounds shifted towards frontal areas and AERP peak latencies were overall lower in infants at 4 than at 2months of age. These observations indicate improvements in the speed of sound processing and maturation of the frontal attentional network in infants during this period.},
	Author = {van den Heuvel, Marion I. and Otte, Ren{\'e}e A. and Braeken, Marijke A. K. A. and Winkler, Istv{\'a}n and Kushnerenko, Elena and Van den Bergh, Bea R. H.},
	Doi = {10.1016/j.ijpsycho.2015.04.003},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/RJMJCT93/S0167876015001518.html:text/html},
	Issn = {0167-8760},
	Journal = {International Journal of Psychophysiology},
	Keywords = {Auditory event-related potential, Infancy, Auditory attention, Cognitive development, Oddball paradigm},
	Month = jul,
	Number = {1},
	Pages = {75--83},
	Title = {Differences between human auditory event-related potentials ({AERPs}) measured at 2 and 4months after birth},
	Url = {http://www.sciencedirect.com/science/article/pii/S0167876015001518},
	Urldate = {2019-07-09},
	Volume = {97},
	Year = {2015},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0167876015001518},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.ijpsycho.2015.04.003}}

@article{vinje_sparse_2000,
	Abstract = {Theoretical studies suggest that primary visual cortex (area V1) uses a sparse code to efficiently represent natural scenes. This issue was investigated by recording from V1 neurons in awake behaving macaques during both free viewing of natural scenes and conditions simulating natural vision. Stimulation of the nonclassical receptive field increases the selectivity and sparseness of individual V1 neurons, increases the sparseness of the population response distribution, and strongly decorrelates the responses of neuron pairs. These effects are due to both excitatory and suppressive modulation of the classical receptive field by the nonclassical receptive field and do not depend critically on the spatiotemporal structure of the stimuli. During natural vision, the classical and nonclassical receptive fields function together to form a sparse representation of the visual world. This sparse code may be computationally efficient for both early vision and higher visual processing.},
	Author = {Vinje, William E. and Gallant, Jack L.},
	Doi = {10.1126/science.287.5456.1273},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/YFR9EVXG/Vinje et Gallant - 2000 - Sparse Coding and Decorrelation in Primary Visual .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VQ6HL6FF/1273.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = feb,
	Number = {5456},
	Pages = {1273--1276},
	Pmid = {10678835},
	Title = {Sparse {Coding} and {Decorrelation} in {Primary} {Visual} {Cortex} {During} {Natural} {Vision}},
	Url = {https://science.sciencemag.org/content/287/5456/1273},
	Urldate = {2019-07-12},
	Volume = {287},
	Year = {2000},
	Bdsk-Url-1 = {https://science.sciencemag.org/content/287/5456/1273},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.287.5456.1273}}

@article{tasaka_genetic_2018,
	Abstract = {Fos-CreER knock-in mice enable tagging of neurons that are activated within a distinct\&nbsp;time window. Here, the authors develop a Cre reporter mouse with low baseline activation and use it to reveal the specific coding properties of auditory cortex neurons that are activated by pup calls in both naive mice and mothers.},
	Author = {Tasaka, Gen-ichi and Guenthner, Casey J. and Shalev, Amos and Gilday, Omri and Luo, Liqun and Mizrahi, Adi},
	Copyright = {2018 The Author(s)},
	Doi = {10.1038/s41467-018-03183-2},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RSAWR6US/Tasaka et al. - 2018 - Genetic tagging of active neurons in auditory cort.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/P2NNXMU3/s41467-018-03183-2.html:text/html},
	Issn = {2041-1723},
	Journal = {Nature Communications},
	Language = {En},
	Month = feb,
	Number = {1},
	Pages = {871},
	Title = {Genetic tagging of active neurons in auditory cortex reveals maternal plasticity of coding ultrasonic vocalizations},
	Url = {https://www.nature.com/articles/s41467-018-03183-2},
	Urldate = {2019-07-13},
	Volume = {9},
	Year = {2018},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41467-018-03183-2},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41467-018-03183-2}}

@article{cohen_plasticity_2015,
	Abstract = {Maternal behavior can be triggered by auditory and olfactory cues originating from the newborn. Here we report how the transition to motherhood affects excitatory and inhibitory neurons in layer 2/3 (L2/3) of the mouse primary auditory cortex. We used in vivo two-photon targeted cell-attached recording to compare the response properties of parvalbumin-expressing neurons (PVNs) and pyramidal glutamatergic neurons (PyrNs). The transition to motherhood shifts the average best frequency of PVNs to higher frequency by a full octave, with no significant effect on average best frequency of PyrNs. The presence of pup odors significantly reduced the spontaneous and evoked activity of PVN. This reduction of feedforward inhibition coincides with a complimentary increase in spontaneous and evoked activity of PyrNs. The selective shift of PVN frequency tuning should render pup odor-induced disinhibition more effective for high-frequency stimuli, such as ultrasonic vocalizations. Indeed, pup odors increased neuronal responses of PyrNs to pup ultrasonic vocalizations. We conclude that plasticity in the mothers is mediated, at least in part, via modulation of the feedforward inhibition circuitry in the auditory cortex.},
	Author = {Cohen, Lior and Mizrahi, Adi},
	Copyright = {Copyright {\copyright} 2015 the authors 0270-6474/15/351806-10\$15.00/0},
	Doi = {10.1523/JNEUROSCI.1786-14.2015},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CUGZF64N/Cohen et Mizrahi - 2015 - Plasticity during Motherhood Changes in Excitator.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RXWR6MJG/1806.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {feed-forward inhibition, motherhood, pup odors, ultrasonic vocalizations},
	Language = {en},
	Month = jan,
	Number = {4},
	Pages = {1806--1815},
	Pmid = {25632153},
	Shorttitle = {Plasticity during {Motherhood}},
	Title = {Plasticity during {Motherhood}: {Changes} in {Excitatory} and {Inhibitory} {Layer} 2/3 {Neurons} in {Auditory} {Cortex}},
	Url = {https://www.jneurosci.org/content/35/4/1806},
	Urldate = {2019-07-13},
	Volume = {35},
	Year = {2015},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/35/4/1806},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1786-14.2015}}

@incollection{ehret_chapter_2018,
	Abstract = {Adult house mice emit an ultrasonic call series in response to perceived changes of stimulus contexts referring to olfactory stimuli from objects such as urine from another animal and/or olfactory and other stimuli when interacting with conspecifics. The perception of stimulus changes induces arousal and the rate of emitted USVs seems to correlate with the intensity of induced arousal. Series of ultrasonic calls are composed of call types varying in spectrotemporal properties from simple frequency-modulated tones to tones with one or several frequency jumps and/or harmonics. Complex call types seem to characterize animals in positive emotional states while a series of simple calls characterizes states of low arousal and seem also to express the emotional state of fear or anxiety. Thus, mouse USVs have a high potential to characterize the excitability and emotionality of mice of different genetic backgrounds and physiological states, especially when mice are used as animal models in studies of human behavioral, developmental, neural, and psychiatric diseases.},
	Author = {Ehret, G{\"u}nter},
	Booktitle = {Handbook of {Behavioral} {Neuroscience}},
	Doi = {10.1016/B978-0-12-809600-0.00018-4},
	Editor = {Brudzynski, Stefan M.},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TB8GZ5SE/B9780128096000000184.html:text/html},
	Keywords = {Arousal, Acoustic communication, Auditory perception, Emotional expression, Fear expression, Female choice, Innate vocal expression, Mouse strains, Olfactory stimuli, Positive emotion, Sexual interaction, Social interaction, USVs},
	Month = jan,
	Pages = {187--195},
	Publisher = {Elsevier},
	Series = {Handbook of {Ultrasonic} {Vocalization}},
	Title = {Chapter 18 - {Characteristics} of {Vocalization} in {Adult} {Mice}},
	Url = {http://www.sciencedirect.com/science/article/pii/B9780128096000000184},
	Urldate = {2019-07-18},
	Volume = {25},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/B9780128096000000184},
	Bdsk-Url-2 = {https://doi.org/10.1016/B978-0-12-809600-0.00018-4}}

@article{de_cheveigne_filters:_2019,
	Abstract = {Filters are commonly used to reduce noise and improve data quality. Filter theory is part of a scientist's training, yet the impact of filters on interpreting data is not always fully appreciated. This paper reviews the issue and explains what a filter is, what problems are to be expected when using them, how to choose the right filter, and how to avoid filtering by using alternative tools. Time-frequency analysis shares some of the same problems that filters have, particularly in the case of wavelet transforms. We recommend reporting filter characteristics with sufficient details, including a plot of the impulse or step response as an inset.},
	Author = {de Cheveign{\'e}, Alain and Nelken, Israel},
	Doi = {10.1016/j.neuron.2019.02.039},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/IRDHRTHG/de Cheveign{\'e} et Nelken - 2019 - Filters When, Why, and How (Not) to Use Them.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/C3TUFTB6/S0896627319301746.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {oscillations, Fourier analysis, causality, distortions, filter, impulse response, ringing, time-frequency representation},
	Month = apr,
	Number = {2},
	Pages = {280--293},
	Shorttitle = {Filters},
	Title = {Filters: {When}, {Why}, and {How} ({Not}) to {Use} {Them}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627319301746},
	Urldate = {2019-07-23},
	Volume = {102},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627319301746},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2019.02.039}}

@article{yuval-greenberg_transient_2008,
	Author = {Yuval-Greenberg, Shlomit and Tomer, Orr and Keren, Alon S. and Nelken, Israel and Deouell, Leon Y.},
	Doi = {10.1016/j.neuron.2008.03.027},
	File = {Snapshot:/Users/Cecile/Zotero/storage/DLYM7XCQ/S0896-6273(08)00301-2.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {SYSNEURO, SYSBIO},
	Language = {English},
	Month = may,
	Number = {3},
	Pages = {429--441},
	Pmid = {18466752},
	Title = {Transient {Induced} {Gamma}-{Band} {Response} in {EEG} as a {Manifestation} of {Miniature} {Saccades}},
	Url = {https://www.cell.com/neuron/abstract/S0896-6273(08)00301-2},
	Urldate = {2019-07-23},
	Volume = {58},
	Year = {2008},
	Bdsk-Url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(08)00301-2},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2008.03.027}}

@article{viechtbauer_conducting_2010,
	Author = {Viechtbauer, Wolfgang},
	Copyright = {Copyright (c) 2009 Wolfgang Viechtbauer},
	Doi = {10.18637/jss.v036.i03},
	File = {Snapshot:/Users/Cecile/Zotero/storage/VPZQ95KL/v036i03.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/7PPLFC92/Viechtbauer - 2010 - Conducting Meta-Analyses in R with the metafor Pac.pdf:application/pdf},
	Issn = {1548-7660},
	Journal = {Journal of Statistical Software},
	Language = {en},
	Month = aug,
	Number = {1},
	Pages = {1--48},
	Title = {Conducting {Meta}-{Analyses} in {R} with the metafor {Package}},
	Url = {https://www.jstatsoft.org/index.php/jss/article/view/v036i03},
	Urldate = {2019-07-24},
	Volume = {36},
	Year = {2010},
	Bdsk-Url-1 = {https://www.jstatsoft.org/index.php/jss/article/view/v036i03},
	Bdsk-Url-2 = {https://doi.org/10.18637/jss.v036.i03}}

@article{duval_trim_2000,
	Abstract = {Summary. We study recently developed nonparametric methods for estimating the number of missing studies that might exist in a meta-analysis and the effect that these studies might have had on its outcome. These are simple rank-based data augmentation techniques, which formalize the use of funnel plots. We show that they provide effective and relatively powerful tests for evaluating the existence of such publication bias. After adjusting for missing studies, we find that the point estimate of the overall effect size is approximately correct and coverage of the effect size confidence intervals is substantially improved, in many cases recovering the nominal confidence levels entirely. We illustrate the trim and fill method on existing meta-analyses of studies in clinical trials and psychometrics.},
	Author = {Duval, Sue and Tweedie, Richard},
	Doi = {10.1111/j.0006-341X.2000.00455.x},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BHXY9THQ/Duval et Tweedie - 2000 - Trim and Fill A Simple Funnel-Plot--Based Method o.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WZ52ULAI/j.0006-341X.2000.00455.html:text/html},
	Issn = {1541-0420},
	Journal = {Biometrics},
	Keywords = {Meta-analysis, Data augmentation, File drawer problem, Funnel plots, IQ, Malaria, Missing studies, Publication bias},
	Language = {en},
	Number = {2},
	Pages = {455--463},
	Shorttitle = {Trim and {Fill}},
	Title = {Trim and {Fill}: {A} {Simple} {Funnel}-{Plot}--{Based} {Method} of {Testing} and {Adjusting} for {Publication} {Bias} in {Meta}-{Analysis}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00455.x},
	Urldate = {2019-07-24},
	Volume = {56},
	Year = {2000},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00455.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.0006-341X.2000.00455.x}}

@article{anonymous_infant_2019,
	Author = {Anonymous},
	File = {DEV-2019-2627_R1_reviewer.pdf:/Users/Cecile/Zotero/storage/GSI6HXZP/DEV-2019-2627_R1_reviewer.pdf:application/pdf},
	Journal = {Personal communication},
	Month = apr,
	Title = {Infant biases for detecting speech in complex scenes},
	Year = {2019}}

@article{sorcinelli_preference_2019,
	Abstract = {Early emerging biases for conspecific vocalizations are a hallmark of early development. Typically developing neonates listen to speech more than many other sounds, including non-biological non-speech sounds, but listen equally to speech and monkey calls. By 3â¯months of age, however, infants prefer speech over both non-biological non-speech sounds and monkey calls. We examined whether different listening preferences continue to develop along different developmental trajectories and whether listening preferences are related to developmental outcomes. Given the static preference for speech over non-biological non-speech sounds and the dynamic preference for speech over monkey calls between birth and 3â¯months, we examined whether 9-month-olds prefer speech over non-biological non-speech sounds (Experiment 1) and prefer speech over monkey calls (Experiment 2). We compared preferences for sounds in infants at low risk (SIBS-TD) and infants at high risk (SIBS-A) of autism spectrum disorder (ASD), a heterogeneous population who differ from typically developing infants in their preferences for speech, and examined whether listening preferences predict vocabulary and autism-like behaviors at 12â¯months for both groups. At 9â¯months, SIBS-TD listened longer to speech than to non-speech sounds and listened longer to monkey calls than to speech, whereas SIBS-A listened longer to speech than to non-speech sounds but listened equally to speech and monkey calls. SIBS-TD's preferences did not predict immediate developmental outcomes. In contrast, SIBS-A who preferred speech over non-speech or monkey calls had larger vocabularies and fewer markers of autism-like behaviors at 12â¯months, which could have positive developmental implications.},
	Annote = {meta-analysis},
	Author = {Sorcinelli, Andrea and Ference, Jennifer and Curtin, Suzanne and Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:47:25 +0200},
	Doi = {10.1016/j.jecp.2018.09.011},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H92S6GRK/S0022096518302285.html:text/html;Sorcinelli et al. - 2019 - Preference for speech in infancy differentially pr.pdf:/Users/Cecile/Zotero/storage/IHYYMDBJ/Sorcinelli et al. - 2019 - Preference for speech in infancy differentially pr.pdf:application/pdf},
	Issn = {0022-0965},
	Journal = {Journal of Experimental Child Psychology},
	Keywords = {Autism spectrum disorder, Language development, Conspecifics, High-risk infant siblings, Social development, Speech perception and bias},
	Month = feb,
	Pages = {295--316},
	Title = {Preference for speech in infancy differentially predicts language skills and autism-like behaviors},
	Url = {http://www.sciencedirect.com/science/article/pii/S0022096518302285},
	Urldate = {2019-07-25},
	Volume = {178},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0022096518302285},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.jecp.2018.09.011}}

@article{lieder_perceptual_2019,
	Abstract = {Lieder et al show that individuals with dyslexia and individuals with ASD rely mostly on recent and earlier perceptual information, respectively, during perceptual tasks. This may explain the unique difficulties associated with the two conditions.},
	Author = {Lieder, Itay and Adam, Vincent and Frenkel, Or and Jaffe-Dax, Sagi and Sahani, Maneesh and Ahissar, Merav},
	Copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	Doi = {10.1038/s41593-018-0308-9},
	File = {Snapshot:/Users/Cecile/Zotero/storage/LGS3XISI/s41593-018-0308-9.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {256--264},
	Title = {Perceptual bias reveals slow-updating in autism and fast-forgetting in dyslexia},
	Url = {https://www.nature.com/articles/s41593-018-0308-9},
	Urldate = {2019-07-31},
	Volume = {22},
	Year = {2019},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41593-018-0308-9},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41593-018-0308-9}}

@misc{jaffe-dax_shorter_2018,
	Abstract = {BOLD activity throughout the cortex, including auditory cortex and associative regions, reveals that adaptation is shorter in dyslexia.},
	Author = {Jaffe-Dax, Sagi and Kimel, Eva and Ahissar, Merav},
	Copyright = {{\copyright} 2018 Jaffe-Dax et al.. This article is distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use and redistribution provided that the original author and source are credited.},
	Doi = {10.7554/eLife.30018},
	File = {Snapshot:/Users/Cecile/Zotero/storage/S3TCBQAQ/30018.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/LG593S7V/Jaffe-Dax et al. - 2018 - Shorter cortical adaptation in dyslexia is broadly.pdf:application/pdf},
	Journal = {eLife},
	Language = {en},
	Month = feb,
	Title = {Shorter cortical adaptation in dyslexia is broadly distributed in the superior temporal lobe and includes the primary auditory cortex},
	Url = {https://elifesciences.org/articles/30018},
	Urldate = {2019-07-31},
	Year = {2018},
	Bdsk-Url-1 = {https://elifesciences.org/articles/30018},
	Bdsk-Url-2 = {https://doi.org/10.7554/eLife.30018}}

@article{jaffe-dax_shorter_2018-1,
	Author = {Jaffe-Dax, Sagi and Kimel, Eva and Ahissar, Merav},
	Doi = {10.7554/eLife.30018},
	File = {Jaffe-Dax et al. - 2018 - Shorter cortical adaptation in dyslexia is broadly.pdf:/Users/Cecile/Zotero/storage/LNAS2C3H/Jaffe-Dax et al. - 2018 - Shorter cortical adaptation in dyslexia is broadly.pdf:application/pdf},
	Issn = {2050-084X},
	Journal = {eLife},
	Language = {en},
	Month = feb,
	Title = {Shorter cortical adaptation in dyslexia is broadly distributed in the superior temporal lobe and includes the primary auditory cortex},
	Url = {https://elifesciences.org/articles/30018},
	Urldate = {2019-08-01},
	Volume = {7},
	Year = {2018},
	Bdsk-Url-1 = {https://elifesciences.org/articles/30018},
	Bdsk-Url-2 = {https://doi.org/10.7554/eLife.30018}}

@article{bartha-doering_absence_2019,
	Abstract = {Children born preterm are at higher risk to develop language deficits. Auditory speech discrimination deficits may be early signs for language developmental problems. The present study used functional near-infrared spectroscopy to investigate neural speech discrimination in 15 preterm infants at term-equivalent age compared to 15 full term neonates. The full term group revealed a significantly greater hemodynamic response to forward compared to backward speech within the left hemisphere extending from superior temporal to inferior parietal and middle and inferior frontal areas. In contrast, the preterm group did not show differences in their hemodynamic responses during forward versus backward speech, thus, they did not discriminate speech from non-speech. Groups differed significantly in their response to forward speech, whereas they did not differ in their responses to backward speech. The significant differences between groups point to an altered development of the functional network underlying language acquisition in preterm infants as early as in term-equivalent age.},
	Author = {Bartha-Doering, Lisa and Alexopoulos, Johanna and Giordano, Vito and Stelzer, Lisa and Kainz, Theresa and Benavides-Varela, Silvia and Wartenburger, Isabell and Klebermass-Schrehof, Katrin and Olischar, Monika and Seidl, Rainer and Berger, Angelika},
	Doi = {10.1016/j.dcn.2019.100679},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/V4AWY4S3/Bartha-Doering et al. - 2019 - Absence of Neural Speech Discrimination in Preterm.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/3VUS7R28/S1878929319300301.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {Newborn infants, Near-infrared spectroscopy, Language development, Preterm birth, Speech discrimination},
	Month = jul,
	Pages = {100679},
	Title = {Absence of {Neural} {Speech} {Discrimination} in {Preterm} {Infants} at {Term}-{Equivalent} {Age}},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929319300301},
	Urldate = {2019-08-07},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929319300301},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2019.100679}}

@article{picton_human_1978,
	Abstract = {In response to a sustained toneburst a negative baseline shift can be recorded from the human fronto-central scalp regions with an onset latency of approximately 150 msec. This auditory sustained potential is distinct both in its scalp distribution and in its stimulus relationships from the transient response occurring at the onset or offset of the toneburst. It differs from the contingent negative variation in that it can occur in the absence of attention or during sleep. Attention to the auditory stimulus can increase the amplitude of the sustained potential, possibly through the addition of an extra negative potential related to auditory expectancy or uncertainty.
R{\'e}sum{\'e}
En r{\'e}ponse {\`a} une bouff{\'e}e de sons prolong{\'e}e, une d{\'e}flection n{\'e}gative de la ligne de base peut {\^e}tre enregistr{\'e}e sur les r{\'e}gions fronto-centrales du scalp chez l'homme avec une latence de d{\'e}but d'environ 150 msec. Ce potentiel auditif prolong{\'e} est diff{\'e}rent dans sa distribution sur le scalp et dans ses relations au stimulus, des r{\'e}ponses transitoires survenat au d{\'e}but et {\`a} la fin de la bouff{\'e}e de sons. Il diff{\`e}re de la variation contigente n{\'e}gative en ce qu'il peut survenir en l'absence d'attention ou au cours du sommeil. L'attention au stimulus auditif peut augmenter l'amplitude de ce potentiel de longue dur{\'e}e peut-{\^e}tre du fait de l'addition d'un potentiel n{\'e}gatif suppl{\'e}mentaire li{\'e} {\`a} l'attente auditive ou {\`a} l'incertitude.},
	Author = {Picton, T. W and Woods, D. L and Proulx, G. B},
	Doi = {10.1016/0013-4694(78)90003-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/CTEB4TVM/Picton et al. - 1978 - Human auditory sustained potentials. I. The nature.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XEV7QC74/0013469478900032.html:text/html},
	Issn = {0013-4694},
	Journal = {Electroencephalography and Clinical Neurophysiology},
	Month = aug,
	Number = {2},
	Pages = {186--197},
	Title = {Human auditory sustained potentials. {I}. {The} nature of the response},
	Url = {http://www.sciencedirect.com/science/article/pii/0013469478900032},
	Urldate = {2019-08-06},
	Volume = {45},
	Year = {1978},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0013469478900032},
	Bdsk-Url-2 = {https://doi.org/10.1016/0013-4694(78)90003-2}}

@article{lopesdasilva_eeg_2013,
	Abstract = {To understand dynamic cognitive processes, the high time resolution of EEG/MEG is invaluable. EEG/MEG signals can play an important role in providing measures of functional and effective connectivity in the brain. After a brief description of the foundations and basic methodological aspects of EEG/MEG signals, the relevance of the signals to obtain novel insights into the neuronal mechanisms underlying cognitive processes is surveyed, with emphasis on neuronal oscillations (ultra-slow, theta, alpha, beta, gamma, and HFOs) and combinations of oscillations. Three main functional roles of brain oscillations are put in evidence: (1) coding specific information, (2) setting and modulating brain attentional states, and (3) assuring the communication between neuronal populations such that specific dynamic workspaces may be created. The latter form the material core of cognitive functions.},
	Author = {Lopes da Silva, Fernando},
	Doi = {10.1016/j.neuron.2013.10.017},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/42U6LPAH/Lopes da Silva - 2013 - EEG and MEG Relevance to Neuroscience.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/J6I5AIB3/S0896627313009203.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Month = dec,
	Number = {5},
	Pages = {1112--1128},
	Shorttitle = {{EEG} and {MEG}},
	Title = {{EEG} and {MEG}: {Relevance} to {Neuroscience}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627313009203},
	Urldate = {2019-08-06},
	Volume = {80},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313009203},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2013.10.017}}

@article{moore_emergent_2019,
	Abstract = {Like humans, songbirds learn to communicate vocally early in life. Moore and Woolley taught birds the songs of a different species to identify how vocal experience and auditory tuning mechanisms create neural representations of communication sounds.},
	Author = {Moore, Jordan M. and Woolley, Sarah M. N.},
	Copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	Doi = {10.1038/s41593-019-0458-4},
	File = {Moore et Woolley - 2019 - Emergent tuning for learned vocalizations in audit.pdf:/Users/Cecile/Zotero/storage/JPBXHA2E/Moore et Woolley - 2019 - Emergent tuning for learned vocalizations in audit.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Z2DALUF7/s41593-019-0458-4.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = aug,
	Pages = {1--8},
	Title = {Emergent tuning for learned vocalizations in auditory cortex},
	Url = {https://www.nature.com/articles/s41593-019-0458-4},
	Urldate = {2019-08-17},
	Year = {2019},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41593-019-0458-4},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41593-019-0458-4}}

@article{legendre_sleepers_2019,
	Abstract = {Why do we continue processing external events during sleep, yet remain unresponsive? Legendre et al. use electroencephalography to show that sleepers enter a `standby mode', continuing to track relevant signals but doing so transiently.},
	Author = {Legendre, Guillaume and Andrillon, Thomas and Koroma, Matthieu and Kouider, Sid},
	Copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	Doi = {10.1038/s41562-018-0502-5},
	File = {Snapshot:/Users/Cecile/Zotero/storage/UZIQJZC6/s41562-018-0502-5.html:text/html},
	Issn = {2397-3374},
	Journal = {Nature Human Behaviour},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {274--283},
	Title = {Sleepers track informative speech in a multitalker environment},
	Url = {https://www.nature.com/articles/s41562-018-0502-5},
	Urldate = {2019-08-23},
	Volume = {3},
	Year = {2019},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41562-018-0502-5},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41562-018-0502-5}}

@article{mcnamara_spontaneous_2002,
	Abstract = {The infant arousal response involves subcortical and cortical responses occurring as a sequence of stereotyped behaviour regardless of the eliciting stimulus. The spontaneous activity of these responses during sleep, however, is uncertain. We examined the spontaneous arousal pattern in normal infants to determine the sequence of responses, and to examine their periodicity and the effects of sleep state. We performed a nap polysomnographic study on 10 normal infants between 2 and 10 weeks of age. Electroencephalographic and electro-oculographic activity, and respiratory airflow and movements were measured, and video recordings were made throughout each study. Different levels of arousal behaviour were examined. We found that spontaneous arousal activity occurred frequently and the majority of responses occurred as a sequence involving an augmented breath followed by a startle and then cortical arousal. Subcortical arousals as reflected by augmented breaths and startles were more common than cortical arousals. Additionally, augmented breaths followed by apnoea were recorded and were not usually associated with other arousal responses. All of the responses occurred periodically either as bursts of activity or as isolated responses. Each of the responses occurred more frequently during rapid eye movement (REM) sleep than during non-rapid eye movement (NREM) sleep. We conclude that there is an endogenous rhythm of spontaneous activity in infants involving excitatory processes from the brainstem, which may or may not be closely followed by cortical excitation. The spontaneous arousal responses occur periodically but with a high level of irregularity and the level of activity is affected by sleep state.},
	Author = {McNamara, Frances and Lijowska, Anna S. and Thach, Bradley T.},
	Copyright = {{\copyright} 2002 The Journal of Physiology {\copyright} 2002 The Physiological Society},
	Doi = {10.1113/jphysiol.2001.012507},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/422ZVER8/McNamara et al. - 2002 - Spontaneous arousal activity in infants during NRE.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/6PTJSJ2W/jphysiol.2001.html:text/html},
	Issn = {1469-7793},
	Journal = {The Journal of Physiology},
	Language = {en},
	Number = {1},
	Pages = {263--269},
	Title = {Spontaneous arousal activity in infants during {NREM} and {REM} sleep},
	Url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2001.012507},
	Urldate = {2019-08-23},
	Volume = {538},
	Year = {2002},
	Bdsk-Url-1 = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2001.012507},
	Bdsk-Url-2 = {https://doi.org/10.1113/jphysiol.2001.012507}}

@article{kouider_neural_2013,
	Abstract = {{\textless}p{\textgreater}Infants have a sophisticated behavioral and cognitive repertoire suggestive of a capacity for conscious reflection. Yet, demonstrating conscious access in infants remains challenging, mainly because they cannot report their thoughts. Here, to circumvent this problem, we studied whether an electrophysiological signature of consciousness found in adults, corresponding to a late nonlinear cortical response [{\textasciitilde}300 milliseconds (ms)] to brief pictures, already exists in infants. We recorded event-related potentials while 5-, 12-, and 15-month-old infants (\textit{N} = 80) viewed masked faces at various levels of visibility. In all age groups, we found a late slow wave showing a nonlinear profile at the expected perceptual thresholds. However, this late component shifted from a weak and delayed response in 5-month-olds (starting around 900 ms) to a more sustained and faster response in older infants (around 750 ms). These results reveal that the brain mechanisms underlying the threshold for conscious perception are already present in infancy but undergo a slow acceleration during development.{\textless}/p{\textgreater}},
	Author = {Kouider, Sid and Stahlhut, Carsten and Gelskov, Sofie V. and Barbosa, Leonardo S. and Dutat, Michel and Gardelle, Vincent de and Christophe, Anne and Dehaene, Stanislas and Dehaene-Lambertz, Ghislaine},
	Copyright = {Copyright {\copyright} 2013, American Association for the Advancement of Science},
	Doi = {10.1126/science.1232509},
	File = {1232509-Kouider.SM.pdf:/Users/Cecile/Zotero/storage/8L2UAY8M/1232509-Kouider.SM.pdf:application/pdf;Full Text PDF:/Users/Cecile/Zotero/storage/2A67JLIX/Kouider et al. - 2013 - A Neural Marker of Perceptual Consciousness in Inf.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UIVDHI7U/376.html:text/html},
	Issn = {0036-8075, 1095-9203},
	Journal = {Science},
	Language = {en},
	Month = apr,
	Number = {6130},
	Pages = {376--380},
	Pmid = {23599498},
	Title = {A {Neural} {Marker} of {Perceptual} {Consciousness} in {Infants}},
	Url = {https://science.sciencemag.org/content/340/6130/376},
	Urldate = {2019-08-30},
	Volume = {340},
	Year = {2013},
	Bdsk-Url-1 = {https://science.sciencemag.org/content/340/6130/376},
	Bdsk-Url-2 = {https://doi.org/10.1126/science.1232509}}

@article{tarullo_sleep_2011,
	Abstract = {Human neonates spend the majority of their time sleeping. Despite the limited waking hours available for environmental exploration, the first few months of life are a time of rapid learning about the environment. The organization of neonate sleep differs qualitatively from adult sleep, and the unique characteristics of neonatal sleep may promote learning. Sleep contributes to infant learning in multiple ways. First, sleep facilitates neural maturation, thereby preparing infants to process and explore the environment in increasingly sophisticated ways. Second, sleep plays a role in memory consolidation of material presented while the infant was awake. Finally, emerging evidence indicates that infants process sensory stimuli and learn about contingencies in their environment even while asleep. As infants make the transition from reflexive to cortically mediated control, learned responses to physiological challenges during sleep may be critical adaptations to promote infant survival.},
	Author = {Tarullo, Amanda R. and Balsam, Peter D. and Fifer, William P.},
	Doi = {10.1002/icd.685},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/JE9U2FA8/Tarullo et al. - 2011 - Sleep and Infant Learning.pdf:application/pdf},
	Issn = {1522-7227},
	Journal = {Infant and child development},
	Month = jan,
	Number = {1},
	Pages = {35--46},
	Pmcid = {PMC3034475},
	Pmid = {21311602},
	Title = {Sleep and {Infant} {Learning}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3034475/},
	Urldate = {2019-08-30},
	Volume = {20},
	Year = {2011},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3034475/},
	Bdsk-Url-2 = {https://doi.org/10.1002/icd.685}}

@article{norman-haignere_neural_2018,
	Abstract = {A central goal of sensory neuroscience is to construct models that can explain neural responses to natural stimuli. As a consequence, sensory models are often tested by comparing neural responses to natural stimuli with model responses to those stimuli. One challenge is that distinct model features are often correlated across natural stimuli, and thus model features can predict neural responses even if they do not in fact drive them. Here, we propose a simple alternative for testing a sensory model: we synthesize a stimulus that yields the same model response as each of a set of natural stimuli, and test whether the natural and ``model-matched'' stimuli elicit the same neural responses. We used this approach to test whether a common model of auditory cortex---in which spectrogram-like peripheral input is processed by linear spectrotemporal filters---can explain fMRI responses in humans to natural sounds. Prior studies have that shown that this model has good predictive power throughout auditory cortex, but this finding could reflect feature correlations in natural stimuli. We observed that fMRI responses to natural and model-matched stimuli were nearly equivalent in primary auditory cortex (PAC) but that nonprimary regions, including those selective for music or speech, showed highly divergent responses to the two sound sets. This dissociation between primary and nonprimary regions was less clear from model predictions due to the influence of feature correlations across natural stimuli. Our results provide a signature of hierarchical organization in human auditory cortex, and suggest that nonprimary regions compute higher-order stimulus properties that are not well captured by traditional models. Our methodology enables stronger tests of sensory models and could be broadly applied in other domains.},
	Author = {Norman-Haignere, Sam V. and McDermott, Josh H.},
	Doi = {10.1371/journal.pbio.2005127},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CZLBK25Y/Norman-Haignere et McDermott - 2018 - Neural responses to natural and model-matched stim.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YMN4RI4N/article.html:text/html},
	Issn = {1545-7885},
	Journal = {PLOS Biology},
	Keywords = {Neurons, Auditory cortex, Forecasting, Functional magnetic resonance imaging, Bioacoustics, Matched filters, Research validity, Statistical noise},
	Language = {en},
	Month = dec,
	Number = {12},
	Pages = {e2005127},
	Title = {Neural responses to natural and model-matched stimuli reveal distinct computations in primary and nonprimary auditory cortex},
	Url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005127},
	Urldate = {2019-09-13},
	Volume = {16},
	Year = {2018},
	Bdsk-Url-1 = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2005127},
	Bdsk-Url-2 = {https://doi.org/10.1371/journal.pbio.2005127}}

@article{curtin_speech_2013,
	Abstract = {We examined whether infants' preference for speech at 12 months is associated with autistic-like behaviors at 18 months in infants who are at increased risk for autism spectrum disorder (ASD) because they have an older sibling diagnosed with ASD and in low-risk infants. Only low-risk infants listened significantly longer to speech than to nonspeech at 12 months. In both groups, relative preference for speech correlated positively with general cognitive ability at 12 months. However, in high-risk infants only, preference for speech was associated with autistic-like behavior at 18 months, while in low-risk infants, preference for speech correlated with language abilities. This suggests that in children at risk for ASD an atypical species-specific bias for speech may underlie atypical social development.},
	Annote = {meta-analysis},
	Author = {Curtin, Suzanne and Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:47:37 +0200},
	Doi = {10.1007/s10803-013-1759-1},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/72BYLTIJ/Curtin et Vouloumanos - 2013 - Speech Preference is Associated with Autistic-Like.pdf:application/pdf},
	Issn = {1573-3432},
	Journal = {Journal of Autism and Developmental Disorders},
	Keywords = {Language development, High-risk infant siblings, Autism spectrum disorders, Speech preference},
	Language = {en},
	Month = sep,
	Number = {9},
	Pages = {2114--2120},
	Title = {Speech {Preference} is {Associated} with {Autistic}-{Like} {Behavior} in 18-{Months}-{Olds} at {Risk} for {Autism} {Spectrum} {Disorder}},
	Url = {https://doi.org/10.1007/s10803-013-1759-1},
	Urldate = {2019-09-17},
	Volume = {43},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10803-013-1759-1}}

@article{vouloumanos_foundational_2014,
	Abstract = {Orienting biases for speech may provide a foundation for language development. Although human infants show a bias for listening to speech from birth, the relation of a speech bias to later language development has not been established. Here, we examine whether infants' attention to speech directly predicts expressive vocabulary. Infants listened to speech or non-speech in a preferential listening procedure. Results show that infants' attention to speech at 12 months significantly predicted expressive vocabulary at 18 months, while indices of general development did not. No predictive relationships were found for infants' attention to non-speech, or overall attention to sounds, suggesting that the relationship between speech and expressive vocabulary was not a function of infants' general attentiveness. Potentially ancient evolutionary perceptual capacities such as biases for conspecific vocalizations may provide a foundation for proficiency in formal systems such language, much like the approximate number sense may provide a foundation for formal mathematics.},
	Annote = {meta-analysis},
	Author = {Vouloumanos, Athena and Curtin, Suzanne},
	Copyright = {Copyright {\copyright} 2014 Cognitive Science Society, Inc.},
	Date-Modified = {2020-06-16 13:45:31 +0200},
	Doi = {10.1111/cogs.12128},
	File = {Snapshot:/Users/Cecile/Zotero/storage/USBB2NWZ/cogs.html:text/html},
	Issn = {1551-6709},
	Journal = {Cognitive Science},
	Keywords = {Speech perception, Cognitive development, Language acquisition, Longitudinal, Predictor},
	Language = {en},
	Number = {8},
	Pages = {1675--1686},
	Shorttitle = {Foundational {Tuning}},
	Title = {Foundational {Tuning}: {How} {Infants}' {Attention} to {Speech} {Predicts} {Language} {Development}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12128},
	Urldate = {2019-09-17},
	Volume = {38},
	Year = {2014},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12128},
	Bdsk-Url-2 = {https://doi.org/10.1111/cogs.12128}}

@article{hedges_robust_2010,
	Author = {Hedges, Larry V. and Tipton, Elizabeth and Johnson, Matthew C.},
	Doi = {10.1002/jrsm.5},
	File = {Hedges et al. - 2010 - Robust variance estimation in meta-regression with.pdf:/Users/Cecile/Zotero/storage/MGENK2VD/Hedges et al. - 2010 - Robust variance estimation in meta-regression with.pdf:application/pdf},
	Issn = {17592879, 17592887},
	Journal = {Research Synthesis Methods},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {39--65},
	Title = {Robust variance estimation in meta-regression with dependent effect size estimates},
	Url = {http://doi.wiley.com/10.1002/jrsm.5},
	Urldate = {2019-09-19},
	Volume = {1},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1002/jrsm.5},
	Bdsk-Url-2 = {https://doi.org/10.1002/jrsm.5}}

@article{jones-molfese_preferences_1977,
	Abstract = {The schema hypothesis proposed by Kagan (Science, 1970, 170, 826--832) andLewis (Developmental Psychology, 1969, 1, 75--86) was used to make predictions concerning the preferences of infants 3 to 14 months old for speech stimuli. An operant response method was used in determining the infants' preferences for inflected, monotone, and scrambled natural speech stimuli. Although the infants' preferences did not change with age as predicted, the infants produced clear preference orderings for the three stimuli. The speech preferences were interpreted as being based on stimulus variables (e.g., word order, inflection, and speech rate) in addition to the realism variables assumed by the schema hypothesis.},
	Author = {Jones-Molfese, Victoria},
	Doi = {10.1016/0022-0965(77)90083-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/7FGR4JM6/Jones-Molfese - 1977 - Preferences of infants for regular and distorted n.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/DNBVDM8A/0022096577900832.html:text/html},
	Issn = {0022-0965},
	Journal = {Journal of Experimental Child Psychology},
	Month = feb,
	Number = {1},
	Pages = {172--179},
	Title = {Preferences of infants for regular and distorted natural speech stimuli},
	Url = {http://www.sciencedirect.com/science/article/pii/0022096577900832},
	Urldate = {2019-09-24},
	Volume = {23},
	Year = {1977},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0022096577900832},
	Bdsk-Url-2 = {https://doi.org/10.1016/0022-0965(77)90083-2}}

@article{ference_role_2018,
	Abstract = {A bias for speech over non-speech emerges at birth in typically developing (TD) infants and a preference for vocalizations generated from one's own species (conspecific) emerges by 3 months. These biases and preferences may direct infants to relevant communicative information in their language learning environments, possibly predicting positive linguistic and social development. The first series of studies explored whether a bias for speech (over non-speech) at 6 and 9 months was predictive of language and social behaviors at 12 months. Whether a preference for conspecific vocalizations (over monkey calls) at 9 months was predictive of these same outcomes was also examined. Infants were biased toward speech over non-speech at 6 and 9 months, but preferred monkey calls over speech at 9 months. However, these listening patterns did not predict language or social developmental outcomes. Understanding these patterns of attention and how experimental procedures may influence preferences is important for advancing our understanding of the relationship between attention to speech and early development. The second series of studies reports findings from high-risk (HR) infant siblings of children diagnosed with Autism Spectrum Disorder (ASD), who participated in these same experiments. HR infants are known to have heterogeneous outcomes by age 3, with about half developing typically, while others present with atypical outcomes, including ASD. Given the hypothesized importance of attention to speech on later development, we explored whether HR infants as a group selectively attended to speech and whether such attention was predictive of early language and social behaviors. HR infants were biased toward speech at 6 months; however, by 9 months, they did not differentially attend to speech over non-speech or monkey calls overall. Despite this, increased attention to speech at 9 months predicted better language and fewer autism-like behaviors at 12 months. Therefore, increased attention to conspecifics may indicate typical outcomes for HR infants. Future directions include following both groups of infants to 3 years of age to explore whether selective attention to speech during the first year is predictive of much later developmental outcomes and/or diagnostic status.},
	Annote = {meta-analysis},
	Author = {Ference, Jennifer Diana},
	Copyright = {University of Calgary graduate students retain copyright ownership and moral rights for their thesis. You may use this material in any way that is permitted by the Copyright Act or through licensing that has been assigned to the document. For uses that are not allowable under copyright legislation or licensing, you are required to seek permission.},
	Date-Modified = {2020-06-16 13:50:16 +0200},
	Doi = {http://dx.doi.org/10.11575/PRISM/31878},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/EPVQ5BTK/Ference - 2018 - The Role of Attentional Biases for Conspecific Voc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9CZEDUCY/106592.html:text/html},
	Language = {eng},
	Month = apr,
	Title = {The {Role} of {Attentional} {Biases} for {Conspecific} {Vocalizations}},
	Url = {https://prism.ucalgary.ca/handle/1880/106592},
	Urldate = {2019-09-24},
	Year = {2018},
	Bdsk-Url-1 = {https://prism.ucalgary.ca/handle/1880/106592},
	Bdsk-Url-2 = {http://dx.doi.org/10.11575/PRISM/31878}}

@phdthesis{prescott_differential_1985,
	Author = {Prescott, Phyllis A.},
	File = {Prescott_uncg_8709241.PDF:/Users/Cecile/Zotero/storage/YJCLNYIL/Prescott_uncg_8709241.PDF:application/pdf},
	School = {The University of North Carolina at Greensboro},
	Title = {Differential reinforcing value of speech and heartbeats: a measure of functional lateralization in the neonate.},
	Url = {http://libres.uncg.edu/ir/listing.aspx?styp=ti&id=25823},
	Year = {1985},
	Bdsk-Url-1 = {http://libres.uncg.edu/ir/listing.aspx?styp=ti&id=25823}}

@book{borenstein_introduction_2011,
	Abstract = {This book provides a clear and thorough introduction to meta-analysis, the process of synthesizing data from a series of separate studies. Meta-analysis has become a critically important tool in fields as diverse as medicine, pharmacology, epidemiology, education, psychology, business, and ecology. Introduction to Meta-Analysis:  Outlines the role of meta-analysis in the research process Shows how to compute effects sizes and treatment effects Explains the fixed-effect and random-effects models for synthesizing data Demonstrates how to assess and interpret variation in effect size across studies Clarifies concepts using text and figures, followed by formulas and examples Explains how to avoid common mistakes in meta-analysis Discusses controversies in meta-analysis Features a web site with additional material and exercises  A superb combination of lucid prose and informative graphics, written by four of the world's leading experts on all aspects of meta-analysis. Borenstein, Hedges, Higgins, and Rothstein provide a refreshing departure from cookbook approaches with their clear explanations of the what and why of meta-analysis. The book is ideal as a course textbook or for self-study. My students, who used pre-publication versions of some of the chapters, raved about the clarity of the explanations and examples. David Rindskopf, Distinguished Professor of Educational Psychology, City University of New York, Graduate School and University Center, \& Editor of the Journal of Educational and Behavioral Statistics. The approach taken by Introduction to Meta-analysis is intended to be primarily conceptual, and it is amazingly successful at achieving that goal. The reader can comfortably skip the formulas and still understand their application and underlying motivation. For the more statistically sophisticated reader, the relevant formulas and worked examples provide a superb practical guide to performing a meta-analysis. The book provides an eclectic mix of examples from education, social science, biomedical studies, and even ecology. For anyone considering leading a course in meta-analysis, or pursuing self-directed study, Introduction to Meta-analysis would be a clear first choice. Jesse A. Berlin, ScD  Introduction to Meta-Analysis is an excellent resource for novices and experts alike. The book provides a clear and comprehensive presentation of all basic and most advanced approaches to meta-analysis. This book will be referenced for decades. Michael A. McDaniel, Professor of Human Resources and Organizational Behavior, Virginia Commonwealth University},
	Author = {Borenstein, Michael and Hedges, Larry V. and Higgins, Julian P. T. and Rothstein, Hannah R.},
	Isbn = {978-1-119-96437-7},
	Keywords = {Mathematics / Probability \& Statistics / Stochastic Processes, Medical / Biostatistics},
	Language = {en},
	Month = aug,
	Note = {Google-Books-ID: JQg9jdrq26wC},
	Publisher = {John Wiley \& Sons},
	Title = {Introduction to {Meta}-{Analysis}},
	Year = {2011}}

@article{feldon_postdocs_2019,
	Abstract = {The doctoral advisor---typically the principal investigator (PI)---is often characterized as a singular or primary mentor who guides students using a cognitive apprenticeship model. Alternatively, the ``cascading mentorship'' model describes the members of laboratories or research groups receiving mentorship from more senior laboratory members and providing it to more junior members (i.e., PIs mentor postdocs, postdocs mentor senior graduate students, senior students mentor junior students, etc.). Here we show that PIs' laboratory and mentoring activities do not significantly predict students' skill development trajectories, but the engagement of postdocs and senior graduate students in laboratory interactions do. We found that the cascading mentorship model accounts best for doctoral student skill development in a longitudinal study of 336 PhD students in the United States. Specifically, when postdocs and senior doctoral students actively participate in laboratory discussions, junior PhD students are over 4 times as likely to have positive skill development trajectories. Thus, postdocs disproportionately enhance the doctoral training enterprise, despite typically having no formal mentorship role. These findings also illustrate both the importance and the feasibility of identifying evidence-based practices in graduate education.},
	Author = {Feldon, David F. and Litson, Kaylee and Jeong, Soojeong and Blaney, Jennifer M. and Kang, Jina and Miller, Candace and Griffin, Kimberly and Roksa, Josipa},
	Copyright = {{\copyright} 2019 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	Doi = {10.1073/pnas.1912488116},
	File = {Feldon et al. - 2019 - Postdocs' lab engagement predicts trajectories of .pdf:/Users/Cecile/Zotero/storage/5HGT7MNH/Feldon et al. - 2019 - Postdocs' lab engagement predicts trajectories of .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/XGPWC9BX/20910.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {doctoral education, graduate training, mentorship, postdocs, research skills},
	Language = {en},
	Month = oct,
	Number = {42},
	Pages = {20910--20916},
	Pmid = {31570599},
	Title = {Postdocs' lab engagement predicts trajectories of {PhD} students' skill development},
	Url = {https://www.pnas.org/content/116/42/20910},
	Urldate = {2019-10-17},
	Volume = {116},
	Year = {2019},
	Bdsk-Url-1 = {https://www.pnas.org/content/116/42/20910},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1912488116}}

@article{doelling_oscillator_2019,
	Abstract = {A body of research demonstrates convincingly a role for synchronization of auditory cortex to rhythmic structure in sounds including speech and music. Some studies hypothesize that an oscillator in auditory cortex could underlie important temporal processes such as segmentation and prediction. An important critique of these findings raises the plausible concern that what is measured is perhaps not an oscillator but is instead a sequence of evoked responses. The two distinct mechanisms could look very similar in the case of rhythmic input, but an oscillator might better provide the computational roles mentioned above (i.e., segmentation and prediction). We advance an approach to adjudicate between the two models: analyzing the phase lag between stimulus and neural signal across different stimulation rates. We ran numerical simulations of evoked and oscillatory computational models, showing that in the evoked case,phase lag is heavily rate-dependent, while the oscillatory model displays marked phase concentration across stimulation rates. Next, we compared these model predictions with magnetoencephalography data recorded while participants listened to music of varying note rates. Our results show that the phase concentration of the experimental data is more in line with the oscillatory model than with the evoked model. This finding supports an auditory cortical signal that (i) contains components of both bottom-up evoked responses and internal oscillatory synchronization whose strengths are weighted by their appropriateness for particular stimulus types and (ii) cannot be explained by evoked responses alone.},
	Author = {Doelling, Keith B. and Assaneo, M. Florencia and Bevilacqua, Dana and Pesaran, Bijan and Poeppel, David},
	Copyright = {Copyright {\copyright} 2019 the Author(s). Published by PNAS.. This open access article is distributed under Creative Commons Attribution-NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).},
	Doi = {10.1073/pnas.1816414116},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/RPJ62RWQ/Doelling et al. - 2019 - An oscillator model better predicts cortical entra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/C29IQUNP/10113.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {MEG, computational models, evoked response, music, oscillator},
	Language = {en},
	Month = may,
	Number = {20},
	Pages = {10113--10121},
	Pmid = {31019082},
	Title = {An oscillator model better predicts cortical entrainment to music},
	Url = {https://www.pnas.org/content/116/20/10113},
	Urldate = {2019-10-30},
	Volume = {116},
	Year = {2019},
	Bdsk-Url-1 = {https://www.pnas.org/content/116/20/10113},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1816414116}}

@article{doelling_cortical_2015,
	Abstract = {Recent studies establish that cortical oscillations track naturalistic speech in a remarkably faithful way. Here, we test whether such neural activity, particularly low-frequency ({\textless}8 Hz; delta--theta) oscillations, similarly entrain to music and whether experience modifies such a cortical phenomenon. Music of varying tempi was used to test entrainment at different rates. In three magnetoencephalography experiments, we recorded from nonmusicians, as well as musicians with varying years of experience. Recordings from nonmusicians demonstrate cortical entrainment that tracks musical stimuli over a typical range of tempi, but not at tempi below 1 note per second. Importantly, the observed entrainment correlates with performance on a concurrent pitch-related behavioral task. In contrast, the data from musicians show that entrainment is enhanced by years of musical training, at all presented tempi. This suggests a bidirectional relationship between behavior and cortical entrainment, a phenomenon that has not previously been reported. Additional analyses focus on responses in the beta range (â¼15--30 Hz)---often linked to delta activity in the context of temporal predictions. Our findings provide evidence that the role of beta in temporal predictions scales to the complex hierarchical rhythms in natural music and enhances processing of musical content. This study builds on important findings on brainstem plasticity and represents a compelling demonstration that cortical neural entrainment is tightly coupled to both musical training and task performance, further supporting a role for cortical oscillatory activity in music perception and cognition.},
	Author = {Doelling, Keith B. and Poeppel, David},
	Doi = {10.1073/pnas.1508431112},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7T5EJS3E/Doelling et Poeppel - 2015 - Cortical entrainment to music and its modulation b.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/94FZVI98/E6233.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {MEG, theta, beta, entrainment, musical expertise},
	Language = {en},
	Month = nov,
	Number = {45},
	Pages = {E6233--E6242},
	Pmid = {26504238},
	Title = {Cortical entrainment to music and its modulation by expertise},
	Url = {https://www.pnas.org/content/112/45/E6233},
	Urldate = {2019-10-30},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {https://www.pnas.org/content/112/45/E6233},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1508431112}}

@article{schulze_transparent_2018,
	Abstract = {The combination of transparency, small brain size and genetic access positions Danionella translucida as a promising model organism for functional imaging of neuronal circuits, especially during complex behaviors in adults.},
	Author = {Schulze, Lisanne and Henninger, J{\"o}rg and Kadobianskyi, Mykola and Chaigne, Thomas and Faustino, Ana Isabel and Hakiy, Nahid and Albadri, Shahad and Schuelke, Markus and Maler, Leonard and Bene, Filippo Del and Judkewitz, Benjamin},
	Copyright = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	Doi = {10.1038/s41592-018-0144-6},
	File = {Snapshot:/Users/Cecile/Zotero/storage/L4UPEXS9/s41592-018-0144-6.html:text/html},
	Issn = {1548-7105},
	Journal = {Nature Methods},
	Language = {en},
	Month = nov,
	Number = {11},
	Pages = {977--983},
	Title = {Transparent {Danionella} translucida as a genetically tractable vertebrate brain model},
	Url = {https://www.nature.com/articles/s41592-018-0144-6},
	Urldate = {2019-11-06},
	Volume = {15},
	Year = {2018},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41592-018-0144-6},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41592-018-0144-6}}

@article{muir_ontogenesis_1979,
	Abstract = {Research on the early development of auditory localization responses is reviewed, and the existence of a U-shaped developmental function is described. It has been reported that many newborns turn toward off-centered sound sources reliably at birth and will perform well for approximately the 1st mo of life, poorly during the 2nd and 3rd mo, and well again during the 4th mo. This trend was confirmed in 3 of 4 infants who were tested extensively throughout their early months. The 4th S failed to show reliable orientation toward sounds until the 4th mo of life. During the period of temporary performance decrement, attempts to reinstate reliable responding by either introducing meaningful acoustic stimuli or eliminating possible auditory-visual conflicts were not successful. (French abstract) (48 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Author = {Muir, Darwin and Abraham, Wayne and Forbes, Brian and Harris, Leonard},
	Doi = {10.1037/h0081729},
	File = {EBSCO Full Text:/Users/Cecile/Zotero/storage/8BP7ZA6C/Muir et al. - 1979 - The ontogenesis of an auditory localization respon.pdf:application/pdf},
	Issn = {0008-4255},
	Journal = {Canadian Journal of Psychology/Revue canadienne de psychologie},
	Keywords = {Auditory Perception, Child Development, Discrimination Learning, Female, Humans, Infant, Infant, Newborn, Male, Auditory Localization, auditory localization response, birth to 4 mo of age, Perceptual Development, Sound Localization},
	Month = dec,
	Number = {4},
	Pages = {320--333},
	Series = {Infant {Perceptual} {Development}},
	Title = {The ontogenesis of an auditory localization response from birth to four months of age},
	Url = {http://sirius.parisdescartes.fr/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=psyh&AN=1981-12511-001&lang=fr&site=eds-live&scope=site},
	Urldate = {2019-11-12},
	Volume = {33},
	Year = {1979},
	Bdsk-Url-1 = {http://sirius.parisdescartes.fr/login?url=https://search.ebscohost.com/login.aspx?direct=true&db=psyh&AN=1981-12511-001&lang=fr&site=eds-live&scope=site},
	Bdsk-Url-2 = {https://doi.org/10.1037/h0081729}}

@article{jusczyk_viewing_1988,
	Abstract = {The present paper examines the issue of how speech sounds may be treated by infants as special signals relative to other kinds of acoustic stimuli. Consideration is given to the view that the mechanisms underlying the infant's perception of speech are specialized for this purpose. Some of the difficulties of providing definitive evidence for or against this position are noted. Then the thesis is advanced that special processing of speech may lie in the inherent salience which such sounds have for infants. in particular, it is suggested that the development of speech perception follows the course of an innately guided learning process. One key assumption of this view is that speech sounds may be more apt to attract attention or have a higher priority for further processing than other types of acoustic signals. Recent evidence from a number of new paradigms for studying infant speech perception is reviewed in light of this position. The paper concludes with a discussion of how findings concerning the development of speech perception during the first year of life fit with the innately guided learning view.},
	Author = {Jusczyk, Peter W. and Bertoncini, Josiane},
	Doi = {10.1177/002383098803100301},
	File = {SAGE PDF Full Text:/Users/Cecile/Zotero/storage/RF9ATN86/Jusczyk et Bertoncini - 1988 - Viewing The Development of Speech Perception As An.pdf:application/pdf},
	Issn = {0023-8309},
	Journal = {Language and Speech},
	Language = {en},
	Month = jul,
	Number = {3},
	Pages = {217--238},
	Title = {Viewing {The} {Development} of {Speech} {Perception} {As} {An} {Innately} {Guided} {Learning} {Process}},
	Url = {https://doi.org/10.1177/002383098803100301},
	Urldate = {2019-11-12},
	Volume = {31},
	Year = {1988},
	Bdsk-Url-1 = {https://doi.org/10.1177/002383098803100301}}

@article{gilley_spectral-temporal_2017,
	Abstract = {Oddball paradigms are frequently used to study auditory discrimination by comparing event-related potential (ERP) responses from a standard, high probability sound and to a deviant, low probability sound. Previous research has established that such paradigms, such as the mismatch response or mismatch negativity, are useful for examining auditory processes in young children and infants across various sleep and attention states. The extent to which oddball ERP responses may reflect subtle discrimination effects, such as speech discrimination, is largely unknown, especially in infants that have not yet acquired speech and language.},
	Author = {Gilley, Phillip M. and Uhler, Kristin and Watson, Kaylee and Yoshinaga-Itano, Christine},
	Doi = {10.1186/s12868-017-0353-4},
	File = {Snapshot:/Users/Cecile/Zotero/storage/EF8N68BJ/s12868-017-0353-4.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/APH5G9C2/Gilley et al. - 2017 - Spectral-temporal EEG dynamics of speech discrimin.pdf:application/pdf},
	Issn = {1471-2202},
	Journal = {BMC Neuroscience},
	Month = mar,
	Number = {1},
	Pages = {34},
	Title = {Spectral-temporal {EEG} dynamics of speech discrimination processing in infants during sleep},
	Url = {https://doi.org/10.1186/s12868-017-0353-4},
	Urldate = {2019-11-12},
	Volume = {18},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1186/s12868-017-0353-4}}

@article{fulkerson_influence_2003,
	Abstract = {This experiment examines the joint influence of auditory and social cues on infants' basic-level and global categorization. Nine- and fifteen-month-olds were familiarized to a series of category exemplars in an object-examining task. Objects were introduced with a labeling phrase, a non-labeling sound, or no sound, and auditory input was presented orally by the experimenter or played on a hidden voice recorder. Novel objects from the familiarized category and a contrasting category were then presented. Results of analyses performed on novelty preference scores indicated that infants demonstrated basic-level categorization in all conditions. However, infants at both age levels only demonstrated global categorization when labeling phrases were introduced. In addition, labels led to global categorization in 9-month-olds regardless of the source of those labels; however, labels only led to global categorization in 15-month-olds when the labels were presented orally by the experimenter.},
	Author = {Fulkerson, Anne L. and Haaf, Robert A.},
	Doi = {10.1207/S15327078IN0403_03},
	File = {Fulkerson et Haaf - 2003 - The Influence of Labels, Non-Labeling Sounds, and .pdf:/Users/Cecile/Zotero/storage/3VI9DWQA/Fulkerson et Haaf - 2003 - The Influence of Labels, Non-Labeling Sounds, and .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/NG8GSVYG/S15327078IN0403_03.html:text/html},
	Issn = {1525-0008},
	Journal = {Infancy},
	Month = aug,
	Number = {3},
	Pages = {349--369},
	Title = {The {Influence} of {Labels}, {Non}-{Labeling} {Sounds}, and {Source} of {Auditory} {Input} on 9- and 15-{Month}-{Olds}' {Object} {Categorization}},
	Url = {https://www.tandfonline.com/doi/abs/10.1207/S15327078IN0403_03},
	Urldate = {2019-11-14},
	Volume = {4},
	Year = {2003},
	Bdsk-Url-1 = {https://www.tandfonline.com/doi/abs/10.1207/S15327078IN0403_03},
	Bdsk-Url-2 = {https://doi.org/10.1207/S15327078IN0403_03}}

@article{woodward_infants_1999,
	Abstract = {In acquiring language, babies learn not only that people can communicate about objects and events, but also that they typically use a particular kind of act as the communicative signal. The current studies asked whether 1-year-olds' learning of names during joint attention is guided by the expectation that names will be in the form of spoken words. In the first study, 13-month-olds were introduced to either a novel word or a novel sound-producing action (using a small noisemaker). Both the word and the sound were produced by a researcher as she showed the baby a new toy during a joint attention episode. The baby's memory for the link between the word or sound and the object was tested in a multiple choice procedure. Thirteen-month-olds learned both the word--object and sound--object correspondences, as evidenced by their choosing the target reliably in response to hearing the word or sound on test trials, but not on control trials when no word or sound was present. In the second study, 13-month-olds, but not 20-month-olds, learned a new sound--object correspondence. These results indicate that infants initially accept a broad range of signals in communicative contexts and narrow the range with development.},
	Author = {Woodward, Amanda and Hoyne, Karen},
	Doi = {10.1111/1467-8624.00006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/79ENZB3U/Woodward et Hoyne - 1999 - Infants' Learning about Words and Sounds in Relati.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TTXN5HC4/1467-8624.html:text/html},
	Issn = {1467-8624},
	Journal = {Child Development},
	Language = {en},
	Number = {1},
	Pages = {65--77},
	Title = {Infants' {Learning} about {Words} and {Sounds} in {Relation} to {Objects}},
	Url = {https://srcd.onlinelibrary.wiley.com/doi/abs/10.1111/1467-8624.00006},
	Urldate = {2019-11-14},
	Volume = {70},
	Year = {1999},
	Bdsk-Url-1 = {https://srcd.onlinelibrary.wiley.com/doi/abs/10.1111/1467-8624.00006},
	Bdsk-Url-2 = {https://doi.org/10.1111/1467-8624.00006}}

@article{molfese_ontogeny_1975,
	Abstract = {Auditory evoked responses (AER) were recorded from the temporal region of both cerebral hemispheres of human infants, children, and adults in response to four speech and two nonspeech acoustic stimuli. Left hemisphere AERs were larger in amplitude than right hemisphere AERs to speech stimuli for all groups. Nonspeech stimuli produced larger amplitude AERs in the right hemisphere. Lateral differences to both types of stimuli were found to decrease with age.},
	Author = {Molfese, Dennis L. and Freeman, Robert B. and Palermo, David S.},
	Doi = {10.1016/S0093-934X(75)80076-9},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/8TGVZT65/Molfese et al. - 1975 - The ontogeny of brain lateralization for speech an.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/H98M354F/S0093934X75800769.html:text/html},
	Issn = {0093-934X},
	Journal = {Brain and Language},
	Language = {en},
	Month = jan,
	Pages = {356--368},
	Title = {The ontogeny of brain lateralization for speech and nonspeech stimuli},
	Url = {http://www.sciencedirect.com/science/article/pii/S0093934X75800769},
	Urldate = {2019-11-14},
	Volume = {2},
	Year = {1975},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0093934X75800769},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0093-934X(75)80076-9}}

@article{gelman_difference_2006,
	Abstract = {It is common to summarize statistical comparisons by declarations of statistical significance or nonsignificance. Here we discuss one problem with such declarations, namely that changes in statistical significance are often not themselves statistically significant. By this, we are not merely making the commonplace observation that any particular threshold is arbitrary---for example, only a small change is required to move an estimate from a 5.1\% significance level to 4.9\%, thus moving it into statistical significance. Rather, we are pointing out that even large changes in significance levels can correspond to small, nonsignificant changes in the underlying quantities.The error we describe is conceptually different from other oft-cited problems---that statistical significance is not the same as practical importance, that dichotomization into significant and nonsignificant results encourages the dismissal of observed differences in favor of the usually less interesting null hypothesis of no difference, and that any particular threshold for declaring significance is arbitrary. We are troubled by all of these concerns and do not intend to minimize their importance. Rather, our goal is to bring attention to this additional error of interpretation. We illustrate with a theoretical example and two applied examples. The ubiquity of this statistical error leads us to suggest that students and practitioners be made more aware that the difference between ``significant'' and ``not significant'' is not itself statistically significant.},
	Author = {Gelman, Andrew and Stern, Hal},
	Doi = {10.1198/000313006X152649},
	File = {Snapshot:/Users/Cecile/Zotero/storage/JEK3MW34/000313006X152649.html:text/html;Version soumise:/Users/Cecile/Zotero/storage/4HE94A7W/Gelman et Stern - 2006 - The Difference Between ``Significant'' and ``Not Sign.pdf:application/pdf},
	Issn = {0003-1305},
	Journal = {The American Statistician},
	Month = nov,
	Number = {4},
	Pages = {328--331},
	Title = {The {Difference} {Between} ``{Significant}'' and ``{Not} {Significant}'' is not {Itself} {Statistically} {Significant}},
	Url = {https://amstat.tandfonline.com/doi/abs/10.1198/000313006X152649},
	Urldate = {2019-11-15},
	Volume = {60},
	Year = {2006},
	Bdsk-Url-1 = {https://amstat.tandfonline.com/doi/abs/10.1198/000313006X152649},
	Bdsk-Url-2 = {https://doi.org/10.1198/000313006X152649}}

@article{kiyonaga_practical_2019,
	Author = {Kiyonaga, Anastasia and Scimeca, Jason M.},
	Doi = {10.1016/j.tins.2019.07.003},
	File = {Snapshot:/Users/Cecile/Zotero/storage/DW55E9MK/S0166-2236(19)30124-9.html:text/html},
	Issn = {0166-2236, 1878-108X},
	Journal = {Trends in Neurosciences},
	Keywords = {open science, preregistration, research practices},
	Language = {English},
	Month = sep,
	Number = {9},
	Pages = {568--572},
	Pmid = {31470913},
	Title = {Practical {Considerations} for {Navigating} {Registered} {Reports}},
	Url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(19)30124-9},
	Urldate = {2019-11-18},
	Volume = {42},
	Year = {2019},
	Bdsk-Url-1 = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(19)30124-9},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.tins.2019.07.003}}

@article{bergmann_development_2016,
	Abstract = {Infants start learning words, the building blocks of language, at least by 6 months. To do so, they must be able to extract the phonological form of words from running speech. A rich literature has investigated this process, termed word segmentation. We addressed the fundamental question of how infants of different ages segment words from their native language using a meta-analytic approach. Based on previous popular theoretical and experimental work, we expected infants to display familiarity preferences early on, with a switch to novelty preferences as infants become more proficient at processing and segmenting native speech. We also considered the possibility that this switch may occur at different points in time as a function of infants' native language and took into account the impact of various task- and stimulus-related factors that might affect difficulty. The combined results from 168 experiments reporting on data gathered from 3774 infants revealed a persistent familiarity preference across all ages. There was no significant effect of additional factors, including native language and experiment design. Further analyses revealed no sign of selective data collection or reporting. We conclude that models of infant information processing that are frequently cited in this domain may not, in fact, apply in the case of segmenting words from native speech.},
	Author = {Bergmann, Christina and Cristia, Alejandrina},
	Copyright = {{\copyright} 2015 John Wiley \& Sons Ltd},
	Doi = {10.1111/desc.12341},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/AA7NRQSI/Bergmann et Cristia - 2016 - Development of infants' segmentation of words from.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HHJXEKH9/desc.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Number = {6},
	Pages = {901--917},
	Shorttitle = {Development of infants' segmentation of words from native speech},
	Title = {Development of infants' segmentation of words from native speech: a meta-analytic approach},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12341},
	Urldate = {2019-11-19},
	Volume = {19},
	Year = {2016},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12341},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12341}}

@book{lipsey_practical_2001,
	Abstract = {Meta-analysis can be understood as a form of survey research in which research reports, rather than people, are surveyed. But how does a researcher select relevant research studies, code their various characteristics and quantitative findings, and analyze and describe their collective results in a valid and useful manner? Through an emphasis on practical procedures and a consideration of choices for implementing them, the authors provide readers with an answer to this question in a user-friendly, state-of-the-art presentation of meta-analysis. The authors lay out each step of meta-analysis from problem formulation through statistical analysis and the interpretation of results. In addition, they offer (1) detailed advice about formatting coding forms, estimating effect sizes, and conducting statistical analysis; (2) coverage of meta-analysis with all the effect size statistics commonly used in different fields, plus some specialized ones; (3) macros that can be used with popular statistical programs to perform meta-analysis calculations; and (4) frequent examples to illustrate important points and procedures. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Address = {Thousand Oaks, CA, US},
	Author = {Lipsey, Mark W. and Wilson, David B.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/PGK9ZFUW/2000-16602-000.html:text/html},
	Isbn = {978-0-7619-2167-7 978-0-7619-2168-4},
	Keywords = {Experimental Methods, Meta Analysis},
	Publisher = {Sage Publications, Inc},
	Series = {Practical meta-analysis},
	Title = {Practical meta-analysis},
	Year = {2001}}

@article{dunlap_meta-analysis_1996,
	Abstract = {Tests for experiments with matched groups or repeated measures designs use error terms that involve the correlation between the measures as well as the variance of the data. The larger the correlation between the measures, the smaller the error and the larger the test statistic. If an effect size is computed from the test statistic without taking the correlation between the measures into account, effect size will be overestimated. Procedures for computing effect size appropriately from matched groups or repeated measures designs are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Author = {Dunlap, William P. and Cortina, Jose M. and Vaslow, Joel B. and Burke, Michael J.},
	Doi = {10.1037/1082-989X.1.2.170},
	File = {Snapshot:/Users/Cecile/Zotero/storage/WR282X2W/1996-04469-005.html:text/html},
	Issn = {1939-1463(Electronic),1082-989X(Print)},
	Journal = {Psychological Methods},
	Keywords = {Meta Analysis, Effect Size (Statistical), Experimental Design, Repeated Measures},
	Number = {2},
	Pages = {170--177},
	Title = {Meta-analysis of experiments with matched groups or repeated measures designs},
	Volume = {1},
	Year = {1996},
	Bdsk-Url-1 = {https://doi.org/10.1037/1082-989X.1.2.170}}

@article{cooper_developmental_1994,
	Abstract = {Across several independent studies, infants from a few days to 9 months of age have shown preferences for infant-directed (ID) over adult-directed (AD) speech. Moreover, 4-month-olds have been shown to prefer sine-wave analogs of the fundamental frequency of ID speech, suggesting that exaggerated pitch contours are prepotent stimuli for infants. The possibility of similar preferences by 1-month-olds was examined in a series of experiments, using a fixation-based preference procedure. Results from the first 2 experiments showed that 1-month-olds did not prefer the lower-frequency pitch characteristics of ID speech, even though 1-month-olds were able to discriminate low-pass filtered ID and AD speech. Since low-pass filtering may have distorted the fundamental frequency characteristics of ID speech, 1-month-olds were also tested with sine-wave analogs of the fundamental frequencies of the ID utterances. Infants in this third experiment also showed no preference for ID pitch contours. In the fourth experiment, 1-month-olds preferred a natural recording of ID speech over a version which preserved only its lower frequency prosodic features. From these results, it is argued that, although young infants are similar to older infants in their attraction to ID speech, their preferences depend on a wider range of acoustic features (e. g., spectral structure). It is suggested that exaggerated pitch contours which characterize ID speech may become salient communicative signals for infants through language-rich, interactive experiences with caretakers and increased perceptual acuity over the first months after birth.},
	Annote = {meta-analysis},
	Author = {Cooper, Robin Panneton and Aslin, Richard N.},
	Date-Modified = {2020-06-16 13:51:55 +0200},
	Doi = {10.2307/1131286},
	Issn = {0009-3920},
	Journal = {Child Development},
	Number = {6},
	Pages = {1663--1677},
	Title = {Developmental {Differences} in {Infant} {Attention} to the {Spectral} {Properties} of {Infant}-{Directed} {Speech}},
	Url = {www.jstor.org/stable/1131286},
	Urldate = {2019-11-19},
	Volume = {65},
	Year = {1994},
	Bdsk-Url-1 = {www.jstor.org/stable/1131286},
	Bdsk-Url-2 = {https://doi.org/10.2307/1131286}}

@article{yamashiro_does_2019,
	Abstract = {Human infants show a robust preference for speech over many other sounds, helping them learn language and interact with others. Lacking a preference for speech may underlie some language and social-pragmatic difficulties in children with ASD. But, it's unclear how an early speech preference supports later language and social-pragmatic abilities. We show that across infants displaying and not displaying later ASD symptoms, a greater speech preference at 9 months is related to increased attention to a person when they speak at 12 months, and better expressive language at 24 months, but is not related to later social-pragmatic attention or outcomes. Understanding how an early speech preference supports language outcomes could inform targeted and individualized interventions for children with ASD.},
	Annote = {meta-analysis},
	Author = {Yamashiro, Amy and Curtin, Suzanne and Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:45:00 +0200},
	Doi = {10.1007/s10803-019-03924-2},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/R2N4F5AN/Yamashiro et al. - 2019 - Does an Early Speech Preference Predict Linguistic.pdf:application/pdf},
	Issn = {1573-3432},
	Journal = {Journal of Autism and Developmental Disorders},
	Keywords = {Autism spectrum disorder, Speech preference, Language outcomes, Linguistic attention, Social-pragmatic attention},
	Language = {en},
	Month = feb,
	Title = {Does an {Early} {Speech} {Preference} {Predict} {Linguistic} and {Social}-{Pragmatic} {Attention} in {Infants} {Displaying} and {Not} {Displaying} {Later} {ASD} {Symptoms}?},
	Url = {https://doi.org/10.1007/s10803-019-03924-2},
	Urldate = {2019-11-19},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1007/s10803-019-03924-2}}

@article{segal_listening_2011,
	Annote = {meta-analysis},
	Author = {Segal, Osnat and Kishon-Rabin, Liat},
	Date-Modified = {2020-06-16 13:52:28 +0200},
	Doi = {10.1097/AUD.0b013e3182008afc},
	File = {Listening Preference for Child-Directed Speech Versus Nonspeech Stimuli in Normal-Hearing and Hearing-Impaired Infants After Cochlear Implantation | Ovid:/Users/Cecile/Zotero/storage/SCH8D7LH/HTML.html:text/html;Segal et Kishon-Rabin - 2011 - Listening Preference for Child-Directed Speech Ver.pdf:/Users/Cecile/Zotero/storage/56VGVDVI/Segal et Kishon-Rabin - 2011 - Listening Preference for Child-Directed Speech Ver.pdf:application/pdf},
	Issn = {0196-0202},
	Journal = {Ear and Hearing},
	Language = {English},
	Month = jun,
	Number = {3},
	Pages = {358--372},
	Title = {Listening {Preference} for {Child}-{Directed} {Speech} {Versus} {Nonspeech} {Stimuli} in {Normal}-{Hearing} and {Hearing}-{Impaired} {Infants} {After} {Cochlear} {Implantation} {\textbar} {Ovid}},
	Url = {https://oce.ovid.com/article/00003446-201105000-00009/HTML},
	Urldate = {2019-11-19},
	Volume = {32},
	Year = {2011},
	Bdsk-Url-1 = {https://oce.ovid.com/article/00003446-201105000-00009/HTML},
	Bdsk-Url-2 = {https://doi.org/10.1097/AUD.0b013e3182008afc}}

@article{ference_role_2018-1,
	Abstract = {A bias for speech over non-speech emerges at birth in typically developing (TD) infants and a preference for vocalizations generated from one's own species (conspecific) emerges by 3 months. These biases and preferences may direct infants to relevant communicative information in their language learning environments, possibly predicting positive linguistic and social development. The first series of studies explored whether a bias for speech (over non-speech) at 6 and 9 months was predictive of language and social behaviors at 12 months. Whether a preference for conspecific vocalizations (over monkey calls) at 9 months was predictive of these same outcomes was also examined. Infants were biased toward speech over non-speech at 6 and 9 months, but preferred monkey calls over speech at 9 months. However, these listening patterns did not predict language or social developmental outcomes. Understanding these patterns of attention and how experimental procedures may influence preferences is important for advancing our understanding of the relationship between attention to speech and early development. The second series of studies reports findings from high-risk (HR) infant siblings of children diagnosed with Autism Spectrum Disorder (ASD), who participated in these same experiments. HR infants are known to have heterogeneous outcomes by age 3, with about half developing typically, while others present with atypical outcomes, including ASD. Given the hypothesized importance of attention to speech on later development, we explored whether HR infants as a group selectively attended to speech and whether such attention was predictive of early language and social behaviors. HR infants were biased toward speech at 6 months; however, by 9 months, they did not differentially attend to speech over non-speech or monkey calls overall. Despite this, increased attention to speech at 9 months predicted better language and fewer autism-like behaviors at 12 months. Therefore, increased attention to conspecifics may indicate typical outcomes for HR infants. Future directions include following both groups of infants to 3 years of age to explore whether selective attention to speech during the first year is predictive of much later developmental outcomes and/or diagnostic status.},
	Author = {Ference, Jennifer Diana},
	Copyright = {University of Calgary graduate students retain copyright ownership and moral rights for their thesis. You may use this material in any way that is permitted by the Copyright Act or through licensing that has been assigned to the document. For uses that are not allowable under copyright legislation or licensing, you are required to seek permission.},
	Doi = {http://dx.doi.org/10.11575/PRISM/31878},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/763GHHVU/Ference - 2018 - The Role of Attentional Biases for Conspecific Voc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/2E4FCYZW/106592.html:text/html},
	Language = {eng},
	Month = apr,
	Title = {The {Role} of {Attentional} {Biases} for {Conspecific} {Vocalizations}},
	Url = {https://prism.ucalgary.ca/handle/1880/106592},
	Urldate = {2019-11-19},
	Year = {2018},
	Bdsk-Url-1 = {https://prism.ucalgary.ca/handle/1880/106592},
	Bdsk-Url-2 = {http://dx.doi.org/10.11575/PRISM/31878}}

@article{tsuji_perceptual_2014,
	Abstract = {Although the majority of evidence on perceptual narrowing in speech sounds is based on consonants, most models of infant speech perception generalize these findings to vowels, assuming that vowel perception improves for vowel sounds that are present in the infant's native language within the first year of life, and deteriorates for non-native vowel sounds over the same period of time. The present meta-analysis contributes to assessing to what extent these descriptions are accurate in the first comprehensive quantitative meta-analysis of perceptual narrowing in infant vowel discrimination, including results from behavioral, electrophysiological, and neuroimaging methods applied to infants 0--14 months of age. An analysis of effect sizes for native and non-native vowel discrimination over the first year of life revealed that they changed with age in opposite directions, being significant by about 6 months of age. {\copyright} 2013 Wiley Periodicals, Inc. Dev Psychobiol 56: 179--191, 2014.},
	Author = {Tsuji, Sho and Cristia, Alejandrina},
	Copyright = {{\copyright} 2013 Wiley Periodicals, Inc.},
	Doi = {10.1002/dev.21179},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KCS3XND5/Tsuji et Cristia - 2014 - Perceptual attunement in vowels A meta-analysis.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7CF5HIPN/dev.html:text/html},
	Issn = {1098-2302},
	Journal = {Developmental Psychobiology},
	Keywords = {development, infancy, language, speech, meta-analysis, humans, vowels},
	Language = {en},
	Number = {2},
	Pages = {179--191},
	Shorttitle = {Perceptual attunement in vowels},
	Title = {Perceptual attunement in vowels: {A} meta-analysis},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dev.21179},
	Urldate = {2019-11-19},
	Volume = {56},
	Year = {2014},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/dev.21179},
	Bdsk-Url-2 = {https://doi.org/10.1002/dev.21179}}

@article{oller_precursors_1999,
	Abstract = {During the canonical stage of infant babbling, infants produce well-formed syllables, often in reduplicated sequences such as ``bababa.'' Although nearly all infants with normal hearing begin the canonical stage by 10 months of age, a few are delayed, and these infants may be of special interest. Recent studies indicate that late onset of canonical babbling may be a predictor of disorders. A simple screening procedure that focuses on canonical babbling was used to evaluate over 3400 infants at risk who were about 10 months of age. Among infants who showed late onset of canonical babbling, fewer than half had been previously diagnosed as having a significant medical problem that might have accounted for the delay. A follow-up study indicated that infants with delayed canonical babbling had smaller production vocabularies at 18, 24, and 30 months than did infants in the control group. The results suggest that late onset of canonical babbling, a factor that can be monitored effectively through an interview with a parent, can predict delay in the onset of speech production.},
	Author = {Oller, D. Kimbrough and Eilers, Rebecca E and Neal, A. Rebecca and Schwartz, Heidi K},
	Doi = {10.1016/S0021-9924(99)00013-1},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GGVBGMXX/Oller et al. - 1999 - Precursors to speech in infancy The prediction of.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/G83RSMDZ/S0021992499000131.html:text/html},
	Issn = {0021-9924},
	Journal = {Journal of Communication Disorders},
	Keywords = {Phonology, Babbling, Infant vocalization, Screening},
	Language = {en},
	Month = jul,
	Number = {4},
	Pages = {223--245},
	Shorttitle = {Precursors to speech in infancy},
	Title = {Precursors to speech in infancy: {The} prediction of speech and language disorders},
	Url = {http://www.sciencedirect.com/science/article/pii/S0021992499000131},
	Urldate = {2019-11-19},
	Volume = {32},
	Year = {1999},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0021992499000131},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0021-9924(99)00013-1}}

@article{simmons_false-positive_2011,
	Abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings (â¤ .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
	Author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
	Doi = {10.1177/0956797611417632},
	File = {SAGE PDF Full Text:/Users/Cecile/Zotero/storage/778WMGIQ/Simmons et al. - 2011 - False-Positive Psychology Undisclosed Flexibility.pdf:application/pdf},
	Issn = {0956-7976},
	Journal = {Psychological Science},
	Language = {en},
	Month = nov,
	Number = {11},
	Pages = {1359--1366},
	Shorttitle = {False-{Positive} {Psychology}},
	Title = {False-{Positive} {Psychology}: {Undisclosed} {Flexibility} in {Data} {Collection} and {Analysis} {Allows} {Presenting} {Anything} as {Significant}},
	Url = {https://doi.org/10.1177/0956797611417632},
	Urldate = {2019-11-19},
	Volume = {22},
	Year = {2011},
	Bdsk-Url-1 = {https://doi.org/10.1177/0956797611417632}}

@article{foster_open_2017,
	Author = {Foster, Erin D. and Deardorff, Ariel},
	Doi = {10.5195/jmla.2017.88},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/DCILBVEV/Foster et Deardorff - 2017 - Open Science Framework (OSF).pdf:application/pdf},
	Issn = {1536-5050},
	Journal = {Journal of the Medical Library Association : JMLA},
	Month = apr,
	Number = {2},
	Pages = {203--206},
	Pmcid = {PMC5370619},
	Pmid = {null},
	Title = {Open {Science} {Framework} ({OSF})},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	Urldate = {2019-11-19},
	Volume = {105},
	Year = {2017},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5370619/},
	Bdsk-Url-2 = {https://doi.org/10.5195/jmla.2017.88}}

@misc{r_core_team_r:_2018,
	Address = {Vienna, Austria},
	Author = {{R Core Team}},
	Publisher = {R Foundation for Statistical Computing},
	Title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	Url = {https://www.R-project.org},
	Year = {2018},
	Bdsk-Url-1 = {https://www.R-project.org}}

@article{eimas_contextual_1980,
	Abstract = {Infants, aged 2 to 4 months, discriminated synthetic speech patterns that varied in duration of the formant transitions; this variation provides information sufficient to signal the phonetic distinction between a stop consonant and a semivowel in adult listeners. In addition, the discriminability of a given difference in transition duration was a function of both the particular stimulus values and the total duration of the syllable. This contextual effect occurred even though the information for syllable duration came after the transition information. The obtained pattern of discontinuous discriminability was in accord with perception that is relational and categorical.},
	Author = {Eimas, Peter D. and Miller, Joanne L.},
	File = {JSTOR Full Text PDF:/Users/Cecile/Zotero/storage/SWJLJLYV/Eimas et Miller - 1980 - Contextual Effects in Infant Speech Perception.pdf:application/pdf},
	Issn = {0036-8075},
	Journal = {Science},
	Number = {4461},
	Pages = {1140--1141},
	Title = {Contextual {Effects} in {Infant} {Speech} {Perception}},
	Url = {www.jstor.org/stable/1684418},
	Urldate = {2019-11-28},
	Volume = {209},
	Year = {1980},
	Bdsk-Url-1 = {www.jstor.org/stable/1684418}}

@article{wisdom_pre-verbal_1971,
	Abstract = {Sixteen 9-18 month normal/superior infants "played" in their home cribs with a two-channel operant "toy" which allowed free choice between alternate audio feedbacks. With more than 300,000 seconds of listening time in the response record, 12 babies successfully discriminated gross differences in auditory complexity, while 10 discriminated fine differences in linguistic redundancy. (Author)},
	Author = {Wisdom, Sara S. and Friedlander, Bernard Z.},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/XWKPFEDP/Wisdom et Friedlander - 1971 - Pre-verbal Infants' Selective Operant Responses fo.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/396897ZF/eric.ed.gov.html:text/html},
	Keywords = {Discrimination Learning, Infants, Audiolingual Methods, Auditory Stimuli, Cognitive Development, Language Acquisition, Listening Skills, Responses},
	Language = {en},
	Title = {Pre-verbal {Infants}' {Selective} {Operant} {Responses} for {Different} {Levels} of {Auditory} {Complexity} and {Language} {Redundancy}. {Summary}},
	Url = {https://eric.ed.gov/?id=ED058940},
	Urldate = {2019-11-28},
	Year = {1971},
	Bdsk-Url-1 = {https://eric.ed.gov/?id=ED058940}}

@article{calabrese_coding_2015,
	Author = {Calabrese, Ana and Woolley, Sarah M. N.},
	Doi = {10.1073/pnas.1408545112},
	File = {Calabrese et Woolley - 2015 - Coding principles of the canonical cortical microc.pdf:/Users/Cecile/Zotero/storage/TS4DMR7G/Calabrese et Woolley - 2015 - Coding principles of the canonical cortical microc.pdf:application/pdf},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Language = {en},
	Month = mar,
	Number = {11},
	Pages = {3517--3522},
	Title = {Coding principles of the canonical cortical microcircuit in the avian brain},
	Url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408545112},
	Urldate = {2019-12-03},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {http://www.pnas.org/lookup/doi/10.1073/pnas.1408545112},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1408545112}}

@article{fruhholz_neural_2019,
	Abstract = {Previous work pointed to the neural and functional significance of infraslow neural oscillations below 1 âHz that can be detected and precisely located with fast functional magnetic resonance imaging (fMRI). While previous work demonstrated this significance for brain dynamics during very low-level sensory stimulation, we here provide the first evidence for the detectability and functional significance of infraslow oscillatory blood oxygenation level-dependent (BOLD) responses to auditory stimulation by the sociobiological relevant and more complex category of voices. Previous work pointed to a specific area of the mammalian auditory cortex (AC) that is sensitive to vocal signals as quantified by activation levels. Here we show, by using fast fMRI, that the human voice-sensitive AC prioritizes vocal signals not only in terms of activity level but also in terms of specific infraslow BOLD oscillations. We found unique sustained and transient oscillatory BOLD patterns in the AC for vocal signals. For transient oscillatory patterns, vocal signals showed faster peak oscillatory responses across all AC regions. Furthermore, we identified an exclusive sustained oscillatory component for vocal signals in the primary AC. Fast fMRI thus demonstrates the significance and richness of infraslow BOLD oscillations for neurocognitive mechanisms in social cognition as demonstrated here for the sociobiological relevance of voice processing.},
	Author = {Fr{\"u}hholz, Sascha and Trost, Wiebke and Grandjean, Didier and Belin, Pascal},
	Doi = {10.1016/j.neuroimage.2019.116401},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/GTQEKNDK/Fr{\"u}hholz et al. - 2019 - Neural oscillations in human auditory cortex revea.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/KKDJAL5F/S1053811919309929.html:text/html},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Keywords = {Oscillations, Voice, fMRI, Auditory cortex, Social signals},
	Language = {en},
	Month = nov,
	Pages = {116401},
	Title = {Neural oscillations in human auditory cortex revealed by fast {fMRI} during auditory perception},
	Url = {http://www.sciencedirect.com/science/article/pii/S1053811919309929},
	Urldate = {2019-12-05},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1053811919309929},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2019.116401}}

@article{issard_variability_2018-1,
	Abstract = {Measuring brain activity in developmental populations remains a major challenge despite great technological advances. Among the numerous available methods, functional near-infrared spectroscopy (fNIRS), an imaging modality that probes the hemodynamic response, is a powerful tool for recording brain activity in a great variety of situations and populations. Neurocognitive studies with infants have often reported inverted hemodynamic responses, i.e. a decrease instead of an increase in regional blood oxygenation, but the exact physiological explanation and cognitive interpretation of this response remain unclear. Here, we first provide an overview of the basic principles of NIRS and its use in cognitive developmental neuroscience. We then review the infant fNIRS literature to show that the hemodynamic response is modulated by experimental design and stimulus complexity, sometimes leading to hemodynamic responses with non-canonical shapes. We also argue that this effect is further modulated by the age of participants, the cortical regions involved, and the developmental stage of the tested cognitive process. We argue that this variability needs to be taken into account when designing and interpreting developmental studies measuring the hemodynamic response.},
	Author = {Issard, C{\'e}cile and Gervain, Judit},
	Copyright = {All rights reserved},
	Doi = {10.1016/j.dcn.2018.01.009},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/URT4QVTJ/Issard et Gervain - 2018 - Variability of the hemodynamic response in infants.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/R4K2R9EV/S187892931730049X.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {fNIRS, Infants, Development, Experimental complexity, Inverted Hemodynamic Response},
	Language = {en},
	Month = oct,
	Pages = {182--193},
	Series = {Methodological {Challenges} in {Developmental} {Neuroimaging}: {Contemporary} {Approaches} and {Solutions}},
	Shorttitle = {Variability of the hemodynamic response in infants},
	Title = {Variability of the hemodynamic response in infants: {Influence} of experimental design and stimulus complexity},
	Url = {http://www.sciencedirect.com/science/article/pii/S187892931730049X},
	Urldate = {2019-12-05},
	Volume = {33},
	Year = {2018},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S187892931730049X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2018.01.009}}

@article{donhauser_two_2019,
	Abstract = {During speech listening, the brain could use contextual predictions to optimize sensory sampling and processing. We asked if such predictive processing is organized dynamically into separate oscillatory timescales. We trained a neural network that uses context to predict speech at the phoneme level. Using this model, we estimated contextual uncertainty and surprise of natural speech as factors to explain neurophysiological activity in human listeners. We show, first, that speech-related activity is hierarchically organized into two timescales: fast responses (theta: 4--10 Hz), restricted to early auditory regions, and slow responses (delta: 0.5--4 Hz), dominating in downstream auditory regions. Neural activity in these bands is selectively modulated by predictions: the gain of early theta responses varies according to the contextual uncertainty of speech, while later delta responses are selective to surprising speech inputs. We conclude that theta sensory sampling is tuned to maximize expected information gain, while delta encodes only non-redundant information.},
	Author = {Donhauser, Peter W. and Baillet, Sylvain},
	Doi = {10.1016/j.neuron.2019.10.019},
	File = {Donhauser et Baillet - 2019 - Two Distinct Neural Timescales for Predictive Spee.pdf:/Users/Cecile/Zotero/storage/PRPGCS47/Donhauser et Baillet - 2019 - Two Distinct Neural Timescales for Predictive Spee.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/VVTSSWZF/S0896627319308931.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {MEG, auditory processing, speech processing, theta oscillations, delta oscillations, neural networks, predictive coding, surprise, temporal response functions, uncertainty},
	Language = {en},
	Month = dec,
	Title = {Two {Distinct} {Neural} {Timescales} for {Predictive} {Speech} {Processing}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627319308931},
	Urldate = {2019-12-09},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627319308931},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2019.10.019}}

@article{puschmann_musicians_2019,
	Abstract = {Abstract.  Musical training has been demonstrated to benefit speech-in-noise perception. It is however unknown whether this effect translates to selective liste},
	Author = {Puschmann, Sebastian and Baillet, Sylvain and Zatorre, Robert J.},
	Doi = {10.1093/cercor/bhy193},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/UPJYBYYL/Puschmann et al. - 2019 - Musicians at the Cocktail Party Neural Substrates.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/AKL6TRBY/5078215.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Language = {en},
	Month = jul,
	Number = {8},
	Pages = {3253--3265},
	Shorttitle = {Musicians at the {Cocktail} {Party}},
	Title = {Musicians at the {Cocktail} {Party}: {Neural} {Substrates} of {Musical} {Training} {During} {Selective} {Listening} in {Multispeaker} {Situations}},
	Url = {https://academic.oup.com/cercor/article/29/8/3253/5078215},
	Urldate = {2019-12-09},
	Volume = {29},
	Year = {2019},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/29/8/3253/5078215},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhy193}}

@article{disbergen_assessing_2018,
	Abstract = {Polyphonic music listening well exemplifies processes typically involved in daily auditory scene analysis situations, relying on an interactive interplay between bottom-up and top-down processes. Most studies investigating scene analysis have used elementary auditory scenes, however real-world scene analysis is far more complex. In particular, music, contrary to most other natural auditory scenes, can be perceived by either integrating or, under attentive control, segregating sound streams, often carried by different instruments. One of the prominent bottom-up cues contributing to multi-instrument music perception is their timbre difference. In this work, we introduce and validate a novel paradigm designed to investigate, within naturalistic musical auditory scenes, attentive modulation as well as its interaction with bottom-up processes. Two psychophysical experiments are described, employing custom-composed two-voice polyphonic music pieces within a framework implementing a behavioral performance metric to validate listener instructions requiring either integration or segregation of scene elements. In experiment 1, the listeners' locus of attention was switched between individual instruments or the aggregate (i.e. both instruments together), via a task requiring the detection of temporal modulations (i.e. triplets) incorporated within or across instruments. Subjects responded post-stimulus whether triplets were present in the to-be-attended instrument(s). Experiment 2 introduced the bottom-up manipulation by adding a three-level morphing of instrument timbre distance to the attentional framework. The task was designed to be used within neuroimaging paradigms; experiment 2 was additionally validated behaviorally in the functional Magnetic Resonance Imaging (fMRI) environment. Experiment 1 subjects (N=29, non-musicians) completed the task at high levels of accuracy, showing no group differences between any experimental conditions. Nineteen listeners also participated in experiment 2, showing a main effect of instrument timbre distance, even though within attention-condition timbre-distance contrasts did not demonstrate any timbre effect. Correlation of overall scores with morph-distance effects, computed by subtracting the largest from the smallest timbre distance scores, showed an influence of general task difficulty on the timbre distance effect. Comparison of laboratory and fMRI data showed scanner noise had no adverse effect on task performance. These experimental paradigms enable to study both bottom-up and top-down contributions to auditory stream segregation and integration within psychophysical and neuroimaging experiments.},
	Author = {Disbergen, Niels R. and Valente, Giancarlo and Formisano, Elia and Zatorre, Robert J.},
	Doi = {10.3389/fnins.2018.00121},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PHLQJQ7I/Disbergen et al. - 2018 - Assessing Top-Down and Bottom-Up Contributions to .pdf:application/pdf},
	Issn = {1662-453X},
	Journal = {Frontiers in Neuroscience},
	Keywords = {Attention, auditory scene analysis, Auditory Stream Integration, auditory stream segregation, Polyphonic music, timbre},
	Language = {English},
	Title = {Assessing {Top}-{Down} and {Bottom}-{Up} {Contributions} to {Auditory} {Stream} {Segregation} and {Integration} {With} {Polyphonic} {Music}},
	Url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00121/full},
	Urldate = {2019-12-09},
	Volume = {12},
	Year = {2018},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00121/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2018.00121}}

@article{osullivan_hierarchical_2019,
	Author = {O'Sullivan, James and Herrero, Jose and Smith, Elliot and Schevon, Catherine and McKhann, Guy M. and Sheth, Sameer A. and Mehta, Ashesh D. and Mesgarani, Nima},
	Doi = {10.1016/j.neuron.2019.09.007},
	File = {Snapshot:/Users/Cecile/Zotero/storage/FDY6QMBU/S0896-6273(19)30780-9.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Keywords = {cocktail party, speech perception, auditory object, encoding, Heschl's gyrus, hierarchical, human auditory cortex, multi-talker, superior temporal gyrus},
	Language = {English},
	Month = oct,
	Number = {0},
	Pmid = {31648900},
	Title = {Hierarchical {Encoding} of {Attended} {Auditory} {Objects} in {Multi}-talker {Speech} {Perception}},
	Url = {https://www.cell.com/neuron/abstract/S0896-6273(19)30780-9},
	Urldate = {2019-12-10},
	Volume = {0},
	Year = {2019},
	Bdsk-Url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(19)30780-9},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2019.09.007}}

@article{herholz_musical_2012,
	Author = {Herholz, Sibylle C. and Zatorre, Robert J.},
	Doi = {10.1016/j.neuron.2012.10.011},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZNPNT7Q2/Herholz et Zatorre - 2012 - Musical Training as a Framework for Brain Plastici.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QVDYM6X4/S0896-6273(12)00931-2.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Language = {English},
	Month = nov,
	Number = {3},
	Pages = {486--502},
	Pmid = {23141061},
	Shorttitle = {Musical {Training} as a {Framework} for {Brain} {Plasticity}},
	Title = {Musical {Training} as a {Framework} for {Brain} {Plasticity}: {Behavior}, {Function}, and {Structure}},
	Url = {https://www.cell.com/neuron/abstract/S0896-6273(12)00931-2},
	Urldate = {2019-12-15},
	Volume = {76},
	Year = {2012},
	Bdsk-Url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(12)00931-2},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2012.10.011}}

@article{buonomano_cortical_1998,
	Abstract = {It has been clear for almost two decades that cortical representations in adult animals are not fixed entities, but rather, are dynamic and are continuously modified by experience. The cortex can preferentially allocate area to represent the particular peripheral input sources that are proportionally most used. Alterations in cortical representations appear to underlie learning tasks dependent on the use of the behaviorally important peripheral inputs that they represent. The rules governing this cortical representational plasticity following manipulations of inputs, including learning, are increasingly well understood. In parallel with developments in the field of cortical map plasticity, studies of synaptic plasticity have characterized specific elementary forms of plasticity, including associative long-term potentiation and long-term depression of excitatory postsynaptic potentials. Investigators have made many important strides toward understanding the molecular underpinnings of these fundamental plasticity processes and toward defining the learning rules that govern their induction. The fields of cortical synaptic plasticity and cortical map plasticity have been implicitly linked by the hypothesis that synaptic plasticity underlies cortical map reorganization. Recent experimental and theoretical work has provided increasingly stronger support for this hypothesis. The goal of the current paper is to review the fields of both synaptic and cortical map plasticity with an emphasis on the work that attempts to unite both fields. A second objective is to highlight the gaps in our understanding of synaptic and cellular mechanisms underlying cortical representational plasticity.},
	Author = {Buonomano, Dean V. and Merzenich, Michael M.},
	Doi = {10.1146/annurev.neuro.21.1.149},
	File = {Buonomano et Merzenich - 1998 - CORTICAL PLASTICITY From Synapses to Maps.pdf:/Users/Cecile/Zotero/storage/6L2RPX3U/Buonomano et Merzenich - 1998 - CORTICAL PLASTICITY From Synapses to Maps.pdf:application/pdf},
	Journal = {Annual Review of Neuroscience},
	Number = {1},
	Pages = {149--186},
	Pmid = {9530495},
	Shorttitle = {{CORTICAL} {PLASTICITY}},
	Title = {{CORTICAL} {PLASTICITY}: {From} {Synapses} to {Maps}},
	Url = {https://doi.org/10.1146/annurev.neuro.21.1.149},
	Urldate = {2019-12-15},
	Volume = {21},
	Year = {1998},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev.neuro.21.1.149}}

@article{elhilali_cocktail_2008,
	Abstract = {Sound systems and speech technologies can benefit greatly from a deeper understanding of how the auditory system, and particularly the auditory cortex, is able to parse complex acoustic scenes into meaningful auditory objects and streams under adverse conditions. In the current work, a biologically plausible model of this process is presented, where the role of cortical mechanisms in organizing complex auditory scenes is explored. The model consists of two stages: (i) a feature analysis stage that maps the acoustic input into a multidimensional cortical representation and (ii) an integrative stage that recursively builds up expectations of how streams evolve over time and reconciles its predictions with the incoming sensory input by sorting it into different clusters. This approach yields a robust computational scheme for speaker separation under conditions of speech or music interference. The model can also emulate the archetypal streaming percepts of tonal stimuli that have long been tested in human subjects. The implications of this model are discussed with respect to the physiological correlates of streaming in the cortex as well as the role of attention and other top-down influences in guiding sound organization.},
	Author = {Elhilali, Mounya and Shamma, Shihab A.},
	Doi = {10.1121/1.3001672},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/KGC2V2LM/Elhilali et Shamma - 2008 - A cocktail party with a cortical twist How cortic.pdf:application/pdf},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = dec,
	Number = {6},
	Pages = {3751--3771},
	Pmcid = {PMC2676630},
	Pmid = {19206802},
	Shorttitle = {A cocktail party with a cortical twist},
	Title = {A cocktail party with a cortical twist: {How} cortical mechanisms contribute to sound segregation},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2676630/},
	Urldate = {2019-12-17},
	Volume = {124},
	Year = {2008},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2676630/},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.3001672}}

@article{kell_invariance_2019,
	Abstract = {The authors show that areas of the auditory cortex differ in the extent to which their responses to sounds are altered by\&nbsp;the presence of background noise. Cortical responses to sounds in primary areas are more affected by background noise than are those in non-primary areas.},
	Author = {Kell, Alexander J. E. and McDermott, Josh H.},
	Copyright = {2019 The Author(s)},
	Doi = {10.1038/s41467-019-11710-y},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/YT4BNHLG/Kell et McDermott - 2019 - Invariance to background noise as a signature of n.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QJUT9KJ3/s41467-019-11710-y.html:text/html},
	Issn = {2041-1723},
	Journal = {Nature Communications},
	Language = {en},
	Month = sep,
	Number = {1},
	Pages = {1--11},
	Title = {Invariance to background noise as a signature of non-primary auditory cortex},
	Url = {https://www.nature.com/articles/s41467-019-11710-y},
	Urldate = {2019-12-18},
	Volume = {10},
	Year = {2019},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41467-019-11710-y},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41467-019-11710-y}}

@article{abraham_metaplasticity:_2008,
	Abstract = {Synaptic plasticity is central to learning mechanisms, but what keeps the plasticity in check? Abraham reviews our current understanding of the mechanisms of metaplasticity --- the plasticity of synaptic plasticity --- and considers its importance for nervous system function and disease.},
	Author = {Abraham, Wickliffe C.},
	Copyright = {2008 Nature Publishing Group},
	Doi = {10.1038/nrn2356},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DHZQYXHG/Abraham - 2008 - Metaplasticity tuning synapses and networks for p.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MJYZ9UFI/nrn2356.html:text/html},
	Issn = {1471-0048},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = may,
	Number = {5},
	Pages = {387--387},
	Shorttitle = {Metaplasticity},
	Title = {Metaplasticity: tuning synapses and networks for plasticity},
	Url = {https://www.nature.com/articles/nrn2356},
	Urldate = {2019-12-23},
	Volume = {9},
	Year = {2008},
	Bdsk-Url-1 = {https://www.nature.com/articles/nrn2356},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn2356}}

@article{sambeth_sleeping_2008,
	Abstract = {Objective
Behavioral experiments show that infants use both prosodic and statistical cues in acquiring language. However, it is not yet clear whether these prosodic and statistical tools are already present at birth.
Methods
We recorded brain responses of sleeping newborns to natural sounds rich in prosody, namely singing and continuous speech, and to two impoverished manipulations of speech. A total of 11 newborns were presented with continuous speech, singing, and degraded speech, while MEG was recorded.
Results
We found that a brain response elicited to the prosodically rich singing and continuous natural speech conditions decreased dramatically when the prosody in the speech was impoverished.
Conclusions
We claim that this response is the indicator of the infants' sensitivity to prosodic cues in language, which is already present at birth during natural sleep.
Significance
The indicators of detection of prosody may be crucial in assessing the normal and abnormal cortical function in newborns, especially of those infants at-risk for language problems.},
	Author = {Sambeth, Anke and Ruohio, Katja and Alku, Paavo and Fellman, Vineta and Huotilainen, Minna},
	Doi = {10.1016/j.clinph.2007.09.144},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/BL8EIXX2/S1388245707006451.html:text/html},
	Issn = {1388-2457},
	Journal = {Clinical Neurophysiology},
	Keywords = {Prosody, Newborn, Magnetoencephalography, Continuous speech, Degraded speech},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {332--341},
	Title = {Sleeping newborns extract prosody from continuous speech},
	Url = {http://www.sciencedirect.com/science/article/pii/S1388245707006451},
	Urldate = {2019-12-23},
	Volume = {119},
	Year = {2008},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1388245707006451},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.clinph.2007.09.144}}

@article{baillet_magnetoencephalography_2017,
	Abstract = {Magnetoencephalography (MEG) tracks the millisecond electrical activity of the brain noninvasively. This review emphasizes MEG's unique assets, especially in terms of imaging and resolving the mechanisms underlying the apparent complexity of polyrhythmic brain dynamics. It also identifies practical challenges and clarifies misconceptions about the technique.},
	Author = {Baillet, Sylvain},
	Copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Doi = {10.1038/nn.4504},
	File = {Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf:/Users/Cecile/Zotero/storage/LTJ8DINJ/Baillet - 2017 - Magnetoencephalography for brain electrophysiology.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/BXNDQWYT/nn.html:text/html},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = mar,
	Number = {3},
	Pages = {327--339},
	Title = {Magnetoencephalography for brain electrophysiology and imaging},
	Url = {https://www.nature.com/articles/nn.4504},
	Urldate = {2019-12-24},
	Volume = {20},
	Year = {2017},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn.4504},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.4504}}

@misc{noauthor_behavioral_nodate,
	File = {Snapshot:/Users/Cecile/Zotero/storage/Q4KP47E5/1.html:text/html},
	Language = {fr},
	Title = {Behavioral and {Neural} {Selectivity} for {Acoustic} {Signatures} of {Vocalizations} - {ProQuest}},
	Url = {https://search.proquest.com/openview/bce79931d61e1421610c72c4ac01d9aa/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y},
	Urldate = {2019-12-24},
	Bdsk-Url-1 = {https://search.proquest.com/openview/bce79931d61e1421610c72c4ac01d9aa/1.pdf?pq-origsite=gscholar&cbl=18750&diss=y}}

@article{cichy_resolving_2014,
	Abstract = {A comprehensive picture of object processing in the human brain requires combining both spatial and temporal information about brain activity. Here we acquired human magnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI) responses to 92 object images. Multivariate pattern classification applied to MEG revealed the time course of object processing: whereas individual images were discriminated by visual representations early, ordinate and superordinate category levels emerged relatively late. Using representational similarity analysis, we combined human fMRI and MEG to show content-specific correspondence between early MEG responses and primary visual cortex (V1), and later MEG responses and inferior temporal (IT) cortex. We identified transient and persistent neural activities during object processing with sources in V1 and IT. Finally, we correlated human MEG signals to single-unit responses in monkey IT. Together, our findings provide an integrated space- and time-resolved view of human object categorization during the first few hundred milliseconds of vision.},
	Author = {Cichy, Radoslaw Martin and Pantazis, Dimitrios and Oliva, Aude},
	Doi = {10.1038/nn.3635},
	File = {Version accept{\'e}e:/Users/Cecile/Zotero/storage/CZGQGVEV/Cichy et al. - 2014 - Resolving human object recognition in space and ti.pdf:application/pdf},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Keywords = {Adult, Animals, Cerebral Cortex, Female, Functional Neuroimaging, Humans, Macaca mulatta, Male, Pattern Recognition, Visual, Temporal Lobe, Time Factors, Visual Cortex, Young Adult, Magnetoencephalography, Electrodes, Implanted, Electrophysiological Phenomena},
	Language = {eng},
	Month = mar,
	Number = {3},
	Pages = {455--462},
	Pmcid = {PMC4261693},
	Pmid = {24464044},
	Title = {Resolving human object recognition in space and time},
	Volume = {17},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1038/nn.3635}}

@article{buzsaki_scaling_2013,
	Abstract = {Despite the several-thousand-fold increase of brain volume during the course of mammalian evolution, the hierarchy of brain oscillations remains remarkably preserved, allowing for multiple-time-scale communication within and across neuronal networks at approximately the same speed, irrespective of brain size. Deployment of large-diameter axons of long-range neurons could be a key factor in the preserved time management in growing brains. We discuss the consequences of such preserved network constellation in mental disease, drug discovery, and interventional therapies.},
	Author = {Buzs{\'a}ki, Gy{\"o}rgy and Logothetis, Nikos and Singer, Wolf},
	Doi = {10.1016/j.neuron.2013.10.002},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/2GXZY6MI/Buzs{\'a}ki et al. - 2013 - Scaling Brain Size, Keeping Timing Evolutionary P.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/TKIQ6QCB/S0896627313009045.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Language = {en},
	Month = oct,
	Number = {3},
	Pages = {751--764},
	Shorttitle = {Scaling {Brain} {Size}, {Keeping} {Timing}},
	Title = {Scaling {Brain} {Size}, {Keeping} {Timing}: {Evolutionary} {Preservation} of {Brain} {Rhythms}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0896627313009045},
	Urldate = {2019-12-27},
	Volume = {80},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0896627313009045},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2013.10.002}}

@article{du_musical_2017,
	Abstract = {The idea that musical training improves speech perception in challenging listening environments is appealing and of clinical importance, yet the mechanisms of any such musician advantage are not well specified. Here, using functional magnetic resonance imaging (fMRI), we found that musicians outperformed nonmusicians in identifying syllables at varying signal-to-noise ratios (SNRs), which was associated with stronger activation of the left inferior frontal and right auditory regions in musicians compared with nonmusicians. Moreover, musicians showed greater specificity of phoneme representations in bilateral auditory and speech motor regions (e.g., premotor cortex) at higher SNRs and in the left speech motor regions at lower SNRs, as determined by multivoxel pattern analysis. Musical training also enhanced the intrahemispheric and interhemispheric functional connectivity between auditory and speech motor regions. Our findings suggest that improved speech in noise perception in musicians relies on stronger recruitment of, finer phonological representations in, and stronger functional connectivity between auditory and frontal speech motor cortices in both hemispheres, regions involved in bottom-up spectrotemporal analyses and top-down articulatory prediction and sensorimotor integration, respectively.},
	Author = {Du, Yi and Zatorre, Robert J.},
	Copyright = {{\copyright} 2017 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	Doi = {10.1073/pnas.1712223114},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/GR849SKL/Du et Zatorre - 2017 - Musical training sharpens and bonds ears and tongu.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/9J9G8F6X/13579.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {functional connectivity, auditory--motor integration, multivoxel pattern classification, musical training, speech in noise perception},
	Language = {en},
	Month = dec,
	Number = {51},
	Pages = {13579--13584},
	Pmid = {29203648},
	Title = {Musical training sharpens and bonds ears and tongue to hear speech better},
	Url = {https://www.pnas.org/content/114/51/13579},
	Urldate = {2019-12-30},
	Volume = {114},
	Year = {2017},
	Bdsk-Url-1 = {https://www.pnas.org/content/114/51/13579},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1712223114}}

@article{halwani_effects_2011,
	Abstract = {Structure and function of the human brain are affected by training in both linguistic and musical domains. Individuals with intensive vocal musical training provide a useful model for investigating neural adaptations of learning in the vocal-motor domain and can be compared with learning in a more general musical domain. Here we confirm general differences in macrostructure (tract volume) and microstructure (fractional anisotropy (FA)) of the arcuate fasciculus (AF), a prominent white-matter tract connecting temporal and frontal brain regions, between singers, instrumentalists, and non-musicians. Both groups of musicians differed from non-musicians in having larger tract volume and higher FA values of the right and left AF. The AF was then subdivided in a dorsal (superior) branch connecting the superior temporal gyrus and the inferior frontal gyrus (STG\&lt;--\&gt;IFG), and ventral (inferior) branch connecting the middle temporal gyrus and the inferior frontal gyrus (MTG\&lt;--\&gt;IFG). Relative to instrumental musicians, singers had a larger tract volume but lower FA values in the left dorsal AF (STG\&lt;--\&gt;IFG), and a similar trend in the left ventral AF (MTG\&lt;--\&gt;IFG). This between-group comparison controls for the general effects of musical training, although FA was still higher in singers compared to non-musicians. Both musician groups had higher tract volumes in the right dorsal and ventral tracts compared to non-musicians, but did not show a significant difference between each other. Furthermore, in the singers' group, FA in the left dorsal branch of the AF was inversely correlated with the number of years of participants' vocal training. Our findings suggest that long-term vocal-motor training might lead to an increase in volume and microstructural complexity of specific white matter tracts connecting regions that are fundamental to sound perception, production, and its feedforward and feedback control which can be differentiated from a more general musician effect.},
	Author = {Halwani, Gus F. and Loui, Psyche and Rueber, Theo and Schlaug, Gottfried},
	Doi = {10.3389/fpsyg.2011.00156},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7CLR7RPZ/Halwani et al. - 2011 - Effects of Practice and Experience on the Arcuate .pdf:application/pdf},
	Issn = {1664-1078},
	Journal = {Frontiers in Psychology},
	Keywords = {Frontal Lobe, Temporal Lobe, Arcuate Fasciculus, Diffusion Tensor Imaging, musicians, plasticity, Singers, white matter},
	Language = {English},
	Shorttitle = {Effects of {Practice} and {Experience} on the {Arcuate} {Fasciculus}},
	Title = {Effects of {Practice} and {Experience} on the {Arcuate} {Fasciculus}: {Comparing} {Singers}, {Instrumentalists}, and {Non}-{Musicians}},
	Url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00156/full},
	Urldate = {2019-12-30},
	Volume = {2},
	Year = {2011},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fpsyg.2011.00156/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fpsyg.2011.00156}}

@article{bertolero_modular_2015,
	Abstract = {Network-based analyses of brain imaging data consistently reveal distinct modules and connector nodes with diverse global connectivity across the modules. How discrete the functions of modules are, how dependent the computational load of each module is to the other modules' processing, and what the precise role of connector nodes is for between-module communication remains underspecified. Here, we use a network model of the brain derived from resting-state functional MRI (rs-fMRI) data and investigate the modular functional architecture of the human brain by analyzing activity at different types of nodes in the network across 9,208 experiments of 77 cognitive tasks in the BrainMap database. Using an author--topic model of cognitive functions, we find a strong spatial correspondence between the cognitive functions and the network's modules, suggesting that each module performs a discrete cognitive function. Crucially, activity at local nodes within the modules does not increase in tasks that require more cognitive functions, demonstrating the autonomy of modules' functions. However, connector nodes do exhibit increased activity when more cognitive functions are engaged in a task. Moreover, connector nodes are located where brain activity is associated with many different cognitive functions. Connector nodes potentially play a role in between-module communication that maintains the modular function of the brain. Together, these findings provide a network account of the brain's modular yet integrated implementation of cognitive functions.},
	Author = {Bertolero, Maxwell A. and Yeo, B. T. Thomas and D'Esposito, Mark},
	Doi = {10.1073/pnas.1510619112},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/U9HY462I/Bertolero et al. - 2015 - The modular and integrative functional architectur.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/S9559MML/E6798.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {graph theory, cognition, hubs, modularity, network},
	Language = {en},
	Month = dec,
	Number = {49},
	Pages = {E6798--E6807},
	Pmid = {26598686},
	Title = {The modular and integrative functional architecture of the human brain},
	Url = {https://www.pnas.org/content/112/49/E6798},
	Urldate = {2020-01-07},
	Volume = {112},
	Year = {2015},
	Bdsk-Url-1 = {https://www.pnas.org/content/112/49/E6798},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1510619112}}

@article{amin_development_2007,
	Abstract = {In adult songbirds, auditory neurons in the primary auditory forebrain region of field L and a secondary auditory forebrain region of caudal mesopallium (CM) are highly responsive to natural sounds, such as conspecific song. Because these nuclei are involved in sensory representations of songs, we investigated how their function changes during development. We recorded neural responses to conspecific and tutor song and acoustically matched synthetic sounds in field L and lateral CM (CLM) of urethane-anesthetized juvenile male zebra finches of approximately 35 days of age. At this age, juvenile songbirds are memorizing the songs of their adult tutors but do not yet sing mature song. They are also starting to recognize songs of individual conspecifics. Compared with adult auditory forebrain neurons, juvenile neurons in field L were on average less responsive to auditory stimuli and exhibited less selectivity for natural sounds compared with the synthetic sounds. This developmental effect was more pronounced in the secondary subregions of L1 and L3 than in the primary thalamo-recipient subregion L2 of field L. CLM showed adultlike selectivity for natural sounds. Also, we did not find any evidence of memory for the tutor song in either field L or CLM. We note that the neural development of selective responses to conspecific song in the secondary subregions of field L is correlated with the emergence of individual song preference around 35 days of age. Therefore we suggest that the emergence of natural sound selectivity in field L could be important for the behavioral development of song recognition.},
	Author = {Amin, Noopur and Doupe, Allison and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1152/jn.01066.2006},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/XECJCAWN/Amin et al. - 2007 - Development of Selectivity for Natural Sounds in t.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UHK2MH37/jn.01066.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = may,
	Number = {5},
	Pages = {3517--3531},
	Title = {Development of {Selectivity} for {Natural} {Sounds} in the {Songbird} {Auditory} {Forebrain}},
	Url = {https://www.physiology.org/doi/full/10.1152/jn.01066.2006},
	Urldate = {2020-01-13},
	Volume = {97},
	Year = {2007},
	Bdsk-Url-1 = {https://www.physiology.org/doi/full/10.1152/jn.01066.2006},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.01066.2006}}

@incollection{cramer_early_2017,
	Abstract = {Vocal communication is critical for life in a wide range of vertebrate species. Mammals, birds, frogs, and fishes rely on auditory processing to perceive the vocal signals of others in the environment and gain social information such as the presence of potential mates or predators. Conspecific vocalizations convey information on sex, age, individual identity, and behavioral state. The importance of vocal communication for social behavior places auditory processing at the forefront of brain functions that directly impact fitness. Young humans and songbirds require experience of adult vocal communication to develop their own perceptual and vocal skills. Studies on songbird vocal development and auditory processing are revealing how early experience and developmental plasticity interact to specialize central auditory function for vocal communication. This chapter reviews research findings that shed light on the role of early song experience in shaping adult song perception and the auditory coding of songs.},
	Address = {Cham},
	Author = {Woolley, Sarah M. N.},
	Booktitle = {Auditory {Development} and {Plasticity}},
	Doi = {10.1007/978-3-319-21530-3_8},
	Editor = {Cramer, Karina S. and Coffin, Allison B. and Fay, Richard R. and Popper, Arthur N.},
	File = {Woolley - 2017 - Early Experience and Auditory Development in Songb.pdf:/Users/Cecile/Zotero/storage/5LT33744/Woolley - 2017 - Early Experience and Auditory Development in Songb.pdf:application/pdf},
	Isbn = {978-3-319-21529-7 978-3-319-21530-3},
	Language = {en},
	Pages = {193--217},
	Publisher = {Springer International Publishing},
	Title = {Early {Experience} and {Auditory} {Development} in {Songbirds}},
	Url = {http://link.springer.com/10.1007/978-3-319-21530-3_8},
	Urldate = {2020-01-17},
	Volume = {64},
	Year = {2017},
	Bdsk-Url-1 = {http://link.springer.com/10.1007/978-3-319-21530-3_8},
	Bdsk-Url-2 = {https://doi.org/10.1007/978-3-319-21530-3_8}}

@article{sanes_behavioral_2011,
	Author = {Sanes, Dan H. and Woolley, Sarah M. N.},
	Doi = {10.1016/j.neuron.2011.12.005},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/KR43VE8W/Sanes et Woolley - 2011 - A Behavioral Framework to Guide Research on Centra.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/KNM8K459/S0896-6273(11)01047-6.html:text/html},
	Issn = {0896-6273},
	Journal = {Neuron},
	Language = {English},
	Month = dec,
	Number = {6},
	Pages = {912--929},
	Pmid = {22196328},
	Title = {A {Behavioral} {Framework} to {Guide} {Research} on {Central} {Auditory} {Development} and {Plasticity}},
	Url = {https://www.cell.com/neuron/abstract/S0896-6273(11)01047-6},
	Urldate = {2020-01-17},
	Volume = {72},
	Year = {2011},
	Bdsk-Url-1 = {https://www.cell.com/neuron/abstract/S0896-6273(11)01047-6},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuron.2011.12.005}}

@book{bregman_auditory_1990,
	Abstract = {Auditory Scene Analysis addresses the problem of hearing complex auditory environments, using a series of creative analogies to describe the process required of the human auditory system as it analyzes mixtures of sounds to recover descriptions of individual sounds. In a unified and comprehensive way, Bregman establishes a theoretical framework that integrates his findings with an unusually wide range of previous research in psychoacoustics, speech perception, music theory and composition, and computer modeling.},
	Author = {Bregman, Albert S.},
	File = {Snapshot:/Users/Cecile/Zotero/storage/HV3VVEAT/auditory-scene-analysis.html:text/html},
	Language = {en},
	Publisher = {MIT Press},
	Title = {Auditory {Scene} {Analysis}},
	Url = {https://mitpress.mit.edu/books/auditory-scene-analysis},
	Urldate = {2020-01-20},
	Year = {1990},
	Bdsk-Url-1 = {https://mitpress.mit.edu/books/auditory-scene-analysis}}

@article{andoh_insights_2018,
	Abstract = {Non-invasive brain stimulation (NIBS) has been widely used as a research tool to modulate cortical excitability of motor as well as non-motor areas, including auditory or language-related areas. NIBS, especially transcranial magnetic stimulation (TMS) and transcranial direct current stimulation (tDCS), have also been used in clinical settings, with however variable therapeutic outcome, highlighting the need to better understand the mechanisms underlying NIBS techniques. TMS was initially used to address causality between specific brain areas and related behaviour, such as language production, providing non-invasive alternatives to lesion studies. Recent literature however suggests that the relationship is not as straightforward as originally thought, and that TMS can show both linear and non-linear modulation of brain responses, highlighting complex network dynamics. In particular, in the last decade, NIBS studies have enabled further advances in our understanding of auditory processing and its underlying functional organization. For instance, NIBS studies showed that even when only one auditory cortex is stimulated unilaterally, bilateral modulation may result, highlighting the influence of functional connectivity between auditory cortices. Additional neuromodulation techniques such as transcranial alternating current stimulation or transcranial random noise stimulation have been used to target frequency-specific neural oscillations of the auditory cortex, providing further insight into modulation of auditory functions. All these NIBS techniques offer different perspectives into the function and organization of auditory cortex. However, further research should be carried out to assess the mode of action and long-term effects of NIBS to optimize their use in clinical settings.},
	Author = {Andoh, Jamila and Matsushita, Reiko and Zatorre, Robert J.},
	Doi = {10.3389/fnins.2018.00469},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7VB2CMV4/Andoh et al. - 2018 - Insights Into Auditory Cortex Dynamics From Non-in.pdf:application/pdf},
	Issn = {1662-453X},
	Journal = {Frontiers in Neuroscience},
	Keywords = {asymmetry, Auditory Cortex, Interhemispheric interactions, network dynamics, Non-invasive brain stimulation (NIBS)},
	Language = {English},
	Title = {Insights {Into} {Auditory} {Cortex} {Dynamics} {From} {Non}-invasive {Brain} {Stimulation}},
	Url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00469/full},
	Urldate = {2020-01-20},
	Volume = {12},
	Year = {2018},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00469/full},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnins.2018.00469}}

@article{pearce_auditory_2012,
	Abstract = {Following in a psychological and musicological tradition beginning with Leonard Meyer, and continuing through David Huron, we present a functional, cognitive account of the phenomenon of expectation in music, grounded in computational, probabilistic modeling. We summarize a range of evidence for this approach, from psychology, neuroscience, musicology, linguistics, and creativity studies, and argue that simulating expectation is an important part of understanding a broad range of human faculties, in music and beyond.},
	Author = {Pearce, Marcus T. and Wiggins, Geraint A.},
	Doi = {10.1111/j.1756-8765.2012.01214.x},
	File = {Pearce et Wiggins - 2012 - Auditory Expectation The Information Dynamics of .pdf:/Users/Cecile/Zotero/storage/RCMWRIY5/Pearce et Wiggins - 2012 - Auditory Expectation The Information Dynamics of .pdf:application/pdf},
	Issn = {17568757},
	Journal = {Topics in Cognitive Science},
	Language = {en},
	Month = oct,
	Number = {4},
	Pages = {625--652},
	Shorttitle = {Auditory {Expectation}},
	Title = {Auditory {Expectation}: {The} {Information} {Dynamics} of {Music} {Perception} and {Cognition}},
	Url = {http://doi.wiley.com/10.1111/j.1756-8765.2012.01214.x},
	Urldate = {2020-01-20},
	Volume = {4},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.wiley.com/10.1111/j.1756-8765.2012.01214.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1756-8765.2012.01214.x}}

@article{pressnitzer_auditory_2011,
	Abstract = {In this review paper aimed at the non-specialist, we explore the use that neuroscientists and musicians have made of perceptual illusions based on ambiguity. The pivotal issue is auditory scene analysis, or what enables us to make sense of complex acoustic mixtures in order to follow, for instance, a single melody in the midst of an orchestra. In general, auditory scene analysis uncovers the most likely physical causes that account for the waveform collected at the ears. However, the acoustical problem is ill-posed and it must be solved from noisy sensory input. Recently, the neural mechanisms implicated in the transformation of ambiguous sensory information into coherent auditory scenes have been investigated using so-called bistability illusions (where an unchanging ambiguous stimulus evokes a succession of distinct percepts in the mind of the listener). After reviewing some of those studies, we turn to music, which arguably provides some of the most complex acoustic scenes that a human listener will ever encounter. Interestingly, musicians will not always aim at making each physical source intelligible, but rather to express one or more melodic lines with a small or large number of instruments. By means of a few musical illustrations and by using a computational model inspired by neuro-physiological principles, we suggest that this relies on a detailed (if perhaps implicit) knowledge of the rules of auditory scene analysis and of its inherent ambiguity. We then put forward the opinion that some degree perceptual ambiguity may participate in our appreciation of music.},
	Author = {Pressnitzer, Daniel and Suied, Clara and Shamma, Shihab},
	Doi = {10.3389/fnhum.2011.00158},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/BUJ8D6SL/Pressnitzer et al. - 2011 - Auditory scene analysis The sweet music of ambigu.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {Auditory Perception, Music, Auditory illusions, bistability, perceptual organization},
	Language = {English},
	Shorttitle = {Auditory scene analysis},
	Title = {Auditory scene analysis: {The} sweet music of ambiguity},
	Url = {https://www.frontiersin.org/articles/10.3389/fnhum.2011.00158/full#h6},
	Urldate = {2020-01-25},
	Volume = {5},
	Year = {2011},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/fnhum.2011.00158/full#h6},
	Bdsk-Url-2 = {https://doi.org/10.3389/fnhum.2011.00158}}

@article{shamma_behind_2010,
	Abstract = {``Auditory scenes'' often contain contributions from multiple acoustic sources. These are usually heard as separate auditory ``streams'', which can be selectively followed over time. How and where these auditory streams are formed in the auditory system is one of the most fascinating questions facing auditory scientists today. Findings published within the last two years indicate that both cortical and sub-cortical processes contribute to the formation of auditory streams, and they raise important questions concerning the roles of primary and secondary areas of auditory cortex in this phenomenon. In addition, these findings underline the importance of taking into account the relative timing of neural responses, and the influence of selective attention, in the search for neural correlates of the perception of auditory streams.},
	Author = {Shamma, Shihab A and Micheyl, Christophe},
	Doi = {10.1016/j.conb.2010.03.009},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/NMUNIPNM/Shamma et Micheyl - 2010 - Behind the Scenes of Auditory Perception.pdf:application/pdf},
	Issn = {0959-4388},
	Journal = {Current opinion in neurobiology},
	Month = jun,
	Number = {3},
	Pages = {361--366},
	Pmcid = {PMC2901988},
	Pmid = {20456940},
	Title = {Behind the {Scenes} of {Auditory} {Perception}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901988/},
	Urldate = {2020-01-25},
	Volume = {20},
	Year = {2010},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901988/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2010.03.009}}

@article{bregman_progress_2015,
	Abstract = {Skip to Next Section
In this paper, I make the following claims: (1) Subjective experience is tremendously useful in guiding productive research. (2) Studies of auditory scene analysis (ASA) in adults, newborn infants, and non-human animals (e.g., in goldfish or pigeons) establish the generality of ASA and suggest that it has an innate foundation. (3) ASA theory does not favor one musical style over another. (4) The principles used in the composition of polyphony (slightly modified) apply not only to one particular musical style or culture but to any form of layered music. (5) Neural explanations of ASA do not supersede explanations in terms of capacities; the two are complementary. (6) In computational auditory scene analysis (CASA) -- ASA by computer systems -- or any adequate theory of ASA, the most difficult challenge will be to discover how the contributions of a very large number of types of acoustical evidence and top-down schemas (acquired knowledge about the sound sources in our environments), can be coordinated without producing conflict that disables the system. (7) Finally I argue that the movement of a listener within the auditory scene provides him/her/it with rich information that should not be ignored by ASA theorists and researchers.},
	Author = {Bregman, Albert S.},
	Copyright = {{\copyright} 2015 by The Regents of the University of California},
	Doi = {10.1525/mp.2015.33.1.12},
	File = {Snapshot:/Users/Cecile/Zotero/storage/NIKMS3K9/12.html:text/html},
	Issn = {0730-7829, 1533-8312},
	Journal = {Music Perception: An Interdisciplinary Journal},
	Keywords = {infants, auditory perception, music, auditory scene analysis, animal perception, ASA, auditory brain, auditory streaming, CASA},
	Language = {en},
	Month = sep,
	Number = {1},
	Pages = {12--19},
	Title = {Progress in {Understanding} {Auditory} {Scene} {Analysis}},
	Url = {https://mp.ucpress.edu/content/33/1/12},
	Urldate = {2020-01-27},
	Volume = {33},
	Year = {2015},
	Bdsk-Url-1 = {https://mp.ucpress.edu/content/33/1/12},
	Bdsk-Url-2 = {https://doi.org/10.1525/mp.2015.33.1.12}}

@article{winkler_newborn_2003,
	Abstract = {The perceptual world of neonates is usually regarded as not yet being fully organized in terms of objects in the same way as it is for adults. Using a recently developed method based on electric brain responses, we found that, similarly to adults, newborn infants segregate concurrent streams of sound, allowing them to organize the auditory input according to the existing sound source. The segregation of concurrent sound streams is a crucial step in the path leading to the identification of objects in the environment. Its presence in newborn infants shows that the basic abilities required for the development of conceptual objects are available already at the time of birth.},
	Author = {Winkler, Istv{\'a}n and Kushnerenko, Elena and Horv{\'a}th, J{\'a}nos and {\v C}eponien{\.e}, Rita and Fellman, Vineta and Huotilainen, Minna and N{\"a}{\"a}t{\"a}nen, Risto and Sussman, Elyse},
	Copyright = {Copyright {\copyright} 2003, The National Academy of Sciences},
	Doi = {10.1073/pnas.2031891100},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/9VIFJ7IE/Winkler et al. - 2003 - Newborn infants can organize the auditory world.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/296SJZ4F/11812.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Language = {en},
	Month = sep,
	Number = {20},
	Pages = {11812--11815},
	Pmid = {14500903},
	Title = {Newborn infants can organize the auditory world},
	Url = {https://www.pnas.org/content/100/20/11812},
	Urldate = {2020-01-27},
	Volume = {100},
	Year = {2003},
	Bdsk-Url-1 = {https://www.pnas.org/content/100/20/11812},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.2031891100}}

@article{demany_auditory_1982,
	Abstract = {In a rapid and repeating melodic sequence, S = {\ldots} abcdabcd {\ldots}, adults may perceive, instead of one coherent string of tones, several co-occurring segregated streams (e.g., {\ldots} a-c-a-c- {\ldots} and {\ldots} b-d-b-d- {\ldots}); melodic stream segregation obeys the Gestalt principle of pitch similarity. Can evidence for stream segregation processes be found in young infants? We reasoned that S should be discriminable from its retrogradation, Sr = {\ldots} adcbadcb {\ldots}, if adjacent tones are grouped in the same stream, but not if adjacent tones are systematically assigned to separate streams. Same / different judgments were obtained from adults on various S-Sr pairs. The same pairs of sequences were then presented to 7--15-week-old infants in a habituation / dishabituation paradigm. The discriminative abilities of the adults and infants varied in parallel as a function of changes in the melodic structure of S and Sr. Our results suggest that stream segregation processes governed by Gestalt factors are operative very early in life.},
	Author = {Demany, Laurent},
	Doi = {10.1016/S0163-6383(82)80036-2},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/ZHWYJ9X6/Demany - 1982 - Auditory stream segregation in infancy.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/9AMBGECC/S0163638382800362.html:text/html},
	Issn = {0163-6383},
	Journal = {Infant Behavior and Development},
	Language = {en},
	Month = jan,
	Number = {2},
	Pages = {261--276},
	Title = {Auditory stream segregation in infancy},
	Url = {http://www.sciencedirect.com/science/article/pii/S0163638382800362},
	Urldate = {2020-01-27},
	Volume = {5},
	Year = {1982},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0163638382800362},
	Bdsk-Url-2 = {https://doi.org/10.1016/S0163-6383(82)80036-2}}

@article{rauschecker_maps_2009,
	Abstract = {As language is unique to humans, it is usually thought that work in other animals has made limited contributions to understanding it. Authors here review work on species-specific vocalizations in nonhuman primates to arrive at a new model for how human speech is processed.},
	Author = {Rauschecker, Josef P. and Scott, Sophie K.},
	Copyright = {2009 Nature Publishing Group},
	Doi = {10.1038/nn.2331},
	File = {Snapshot:/Users/Cecile/Zotero/storage/6RUPJUKB/nn.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/PWPEZ94R/Rauschecker et Scott - 2009 - Maps and streams in the auditory cortex nonhuman .pdf:application/pdf},
	Issn = {1546-1726},
	Journal = {Nature Neuroscience},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {718--724},
	Shorttitle = {Maps and streams in the auditory cortex},
	Title = {Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing},
	Url = {https://www.nature.com/articles/nn.2331},
	Urldate = {2020-01-27},
	Volume = {12},
	Year = {2009},
	Bdsk-Url-1 = {https://www.nature.com/articles/nn.2331},
	Bdsk-Url-2 = {https://doi.org/10.1038/nn.2331}}

@article{tervaniemi_pitch_2005,
	Abstract = {Previously, professional violin players were found to automatically discriminate tiny pitch changes, not discriminable by nonmusicians. The present study addressed the pitch processing accuracy in musicians with expertise in playing a wide selection of instruments (e.g., piano; wind and string instruments). Of specific interest was whether also musicians with such divergent backgrounds have facilitated accuracy in automatic and/or attentive levels of auditory processing. Thirteen professional musicians and 13 nonmusicians were presented with frequent standard sounds and rare deviant sounds (0.8, 2, or 4\% higher in frequency). Auditory event-related potentials evoked by these sounds were recorded while first the subjects read a self-chosen book and second they indicated behaviorally the detection of sounds with deviant frequency. Musicians detected the pitch changes faster and more accurately than nonmusicians. The N2b and P3 responses recorded during attentive listening had larger amplitude in musicians than in nonmusicians. Interestingly, the superiority in pitch discrimination accuracy in musicians over nonmusicians was observed not only with the 0.8\% but also with the 2\% frequency changes. Moreover, also nonmusicians detected quite reliably the smallest pitch changes of 0.8\%. However, the mismatch negativity (MMN) and P3a recorded during a reading condition did not differentiate musicians and nonmusicians. These results suggest that musical expertise may exert its effects merely at attentive levels of processing and not necessarily already at the preattentive levels.},
	Author = {Tervaniemi, Mari and Just, Viola and Koelsch, Stefan and Widmann, Andreas and Schr{\"o}ger, Erich},
	Doi = {10.1007/s00221-004-2044-5},
	File = {Springer Full Text PDF:/Users/Cecile/Zotero/storage/YQLW2RX3/Tervaniemi et al. - 2005 - Pitch discrimination accuracy in musicians vs nonm.pdf:application/pdf},
	Issn = {1432-1106},
	Journal = {Experimental Brain Research},
	Keywords = {Mismatch negativity (MMN), Auditory event-related potentials, Complex sounds, Musical expertise, N2b, P3, P3a, Pitch discrimination},
	Language = {en},
	Month = feb,
	Number = {1},
	Pages = {1--10},
	Shorttitle = {Pitch discrimination accuracy in musicians vs nonmusicians},
	Title = {Pitch discrimination accuracy in musicians vs nonmusicians: an event-related potential and behavioral study},
	Url = {https://doi.org/10.1007/s00221-004-2044-5},
	Urldate = {2020-01-27},
	Volume = {161},
	Year = {2005},
	Bdsk-Url-1 = {https://doi.org/10.1007/s00221-004-2044-5}}

@article{mishra_enhanced_2014,
	Abstract = {Many features of auditory perception are positively altered in musicians. Traditionally auditory mechanisms in musicians are investigated using the Western-classical musician model. The objective of the present study was to adopt an alternative model---Indian-classical music---to further investigate auditory temporal processing in musicians. This study presents that musicians have significantly lower across-channel gap detection thresholds compared to nonmusicians. Use of the South Indian musician model provides an increased external validity for the prediction, from studies on Western-classical musicians, that auditory temporal coding is enhanced in musicians.},
	Author = {Mishra, Srikanta K. and Panda, Manas R. and Herbert, Carolyn},
	Doi = {10.1121/1.4890207},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/HBDVIEJW/Mishra et al. - 2014 - Enhanced auditory temporal gap detection in listen.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/H6U6RMVP/1.html:text/html},
	Issn = {0001-4966},
	Journal = {The Journal of the Acoustical Society of America},
	Month = jul,
	Number = {2},
	Pages = {EL173--EL178},
	Title = {Enhanced auditory temporal gap detection in listeners with musical training},
	Url = {https://asa.scitation.org/doi/10.1121/1.4890207},
	Urldate = {2020-01-27},
	Volume = {136},
	Year = {2014},
	Bdsk-Url-1 = {https://asa.scitation.org/doi/10.1121/1.4890207},
	Bdsk-Url-2 = {https://doi.org/10.1121/1.4890207}}

@article{nieder_neurobiology_2020,
	Abstract = {Vocalization is an ancient vertebrate trait essential to many forms of communication, ranging from courtship calls to free verse. Vocalizations may be entirely innate and evoked by sexual cues or emotional state, as with many types of calls made in primates, rodents and birds; volitional, as with innate calls that, following extensive training, can be evoked by arbitrary sensory cues in non-human primates and corvid songbirds; or learned, acoustically flexible and complex, as with human speech and the courtship songs of oscine songbirds. This review compares and contrasts the neural mechanisms underlying innate, volitional and learned vocalizations, with an emphasis on functional studies in primates, rodents and songbirds. This comparison reveals both highly conserved and convergent mechanisms of vocal production in these different groups, despite their often vast phylogenetic separation. This similarity of central mechanisms for different forms of vocal production presents experimentalists with useful avenues for gaining detailed mechanistic insight into how vocalizations are employed for social and sexual signalling, and how they can be modified through experience to yield new vocal repertoires customized to the individual's social group.This article is part of the theme issue `What can animal communication teach us about human language?'},
	Author = {Nieder, Andreas and Mooney, Richard},
	Doi = {10.1098/rstb.2019.0054},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/4MM4D3AD/Nieder et Mooney - 2020 - The neurobiology of innate, volitional and learned.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/HK9ETB9L/rstb.2019.html:text/html},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Month = jan,
	Number = {1789},
	Pages = {20190054},
	Title = {The neurobiology of innate, volitional and learned vocalizations in mammals and birds},
	Url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0054},
	Urldate = {2020-01-28},
	Volume = {375},
	Year = {2020},
	Bdsk-Url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0054},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2019.0054}}

@article{tyack_taxonomy_2020,
	Abstract = {Humans and songbirds learn to sing or speak by listening to acoustic models, forming auditory templates, and then learning to produce vocalizations that match the templates. These taxa have evolved specialized telencephalic pathways to accomplish this complex form of vocal learning, which has been reported for very few other taxa. By contrast, the acoustic structure of most animal vocalizations is produced by species-specific vocal motor programmes in the brainstem that do not require auditory feedback. However, many mammals and birds can learn to fine-tune the acoustic features of inherited vocal motor patterns based upon listening to conspecifics or noise. These limited forms of vocal learning range from rapid alteration based on real-time auditory feedback to long-term changes of vocal repertoire and they may involve different mechanisms than complex vocal learning. Limited vocal learning can involve the brainstem, mid-brain and/or telencephalic networks. Understanding complex vocal learning, which underpins human speech, requires careful analysis of which species are capable of which forms of vocal learning. Selecting multiple animal models for comparing the neural pathways that generate these different forms of learning will provide a richer view of the evolution of complex vocal learning and the neural mechanisms that make it possible.This article is part of the theme issue `What can animal communication teach us about human language?'},
	Author = {Tyack, Peter L.},
	Doi = {10.1098/rstb.2018.0406},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/5MFGAYZV/Tyack - 2020 - A taxonomy for vocal learning.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MUIQJMZC/rstb.2018.html:text/html},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Month = jan,
	Number = {1789},
	Pages = {20180406},
	Title = {A taxonomy for vocal learning},
	Url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2018.0406},
	Urldate = {2020-01-30},
	Volume = {375},
	Year = {2020},
	Bdsk-Url-1 = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2018.0406},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2018.0406}}

@article{fishbein_sound_2020,
	Abstract = {The complex and melodic nature of many birds' songs has raised interest in potential parallels between avian vocal sequences and human speech. The similarities between birdsong and speech in production and learning are well established, but surprisingly little is known about how birds perceive song sequences. One popular laboratory songbird, the zebra finch (Taeniopygia guttata), has recently attracted attention as an avian model for human speech, in part because the male learns to produce the individual elements in its song motif in a fixed sequence. But psychoacoustic evidence shows that adult zebra finches are relatively insensitive to the sequential features of song syllables. Instead, zebra finches and other birds seem to be exquisitely sensitive to the acoustic details of individual syllables to a degree that is beyond human hearing capacity. Based on these findings, we present a finite-state model of zebra finch perception of song syllable sequences and discuss the rich informational capacity of their vocal system. Furthermore, we highlight the abilities of budgerigars (Melopsittacus undulatus), a parrot species, to hear sequential features better than zebra finches and suggest that neurophysiological investigations comparing these species could prove fruitful for uncovering neural mechanisms for auditory sequence perception in human speech.This article is part of the theme issue `What can animal communication teach us about human language?'},
	Author = {Fishbein, Adam R. and Idsardi, William J. and Ball, Gregory F. and Dooling, Robert J.},
	Doi = {10.1098/rstb.2019.0044},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/TBH52ZBA/Fishbein et al. - 2020 - Sound sequences in birdsong how much do birds rea.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/DEUK9FUX/rstb.2019.html:text/html},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Month = jan,
	Number = {1789},
	Pages = {20190044},
	Shorttitle = {Sound sequences in birdsong},
	Title = {Sound sequences in birdsong: how much do birds really care?},
	Url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	Urldate = {2020-02-07},
	Volume = {375},
	Year = {2020},
	Bdsk-Url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2019.0044}}

@article{doupe_birdsong_1999,
	Abstract = {Human speech and birdsong have numerous parallels. Both humans and songbirds learn their complex vocalizations early in life, exhibiting a strong dependence on hearing the adults they will imitate, as well as themselves as they practice, and a waning of this dependence as they mature. Innate predispositions for perceiving and learning the correct sounds exist in both groups, although more evidence of innate descriptions of species-specific signals exists in songbirds, where numerous species of vocal learners have been compared. Humans also share with songbirds an early phase of learning that is primarily perceptual, which then serves to guide later vocal production. Both humans and songbirds have evolved a complex hierarchy of specialized forebrain areas in which motor and auditory centers interact closely, and which control the lower vocal motor areas also found in nonlearners. In both these vocal learners, however, how auditory feedback of self is processed in these brain areas is surprisingly unclear. Finally, humans and songbirds have similar critical periods for vocal learning, with a much greater ability to learn early in life. In both groups, the capacity for late vocal learning may be decreased by the act of learning itself, as well as by biological factors such as the hormones of puberty. Although some features of birdsong and speech are clearly not analogous, such as the capacity of language for meaning, abstraction, and flexible associations, there are striking similarities in how sensory experience is internalized and used to shape vocal outputs, and how learning is enhanced during a critical period of development. Similar neural mechanisms may therefore be involved.},
	Author = {Doupe, Allison J. and Kuhl, Patricia K.},
	Doi = {10.1146/annurev.neuro.22.1.567},
	File = {Doupe et Kuhl - 1999 - BIRDSONG AND HUMAN SPEECH Common Themes and Mecha.pdf:/Users/Cecile/Zotero/storage/WHLPTCMW/Doupe et Kuhl - 1999 - BIRDSONG AND HUMAN SPEECH Common Themes and Mecha.pdf:application/pdf},
	Journal = {Annual Review of Neuroscience},
	Number = {1},
	Pages = {567--631},
	Pmid = {10202549},
	Shorttitle = {{BIRDSONG} {AND} {HUMAN} {SPEECH}},
	Title = {{BIRDSONG} {AND} {HUMAN} {SPEECH}: {Common} {Themes} and {Mechanisms}},
	Url = {https://doi.org/10.1146/annurev.neuro.22.1.567},
	Urldate = {2020-02-07},
	Volume = {22},
	Year = {1999},
	Bdsk-Url-1 = {https://doi.org/10.1146/annurev.neuro.22.1.567}}

@article{schumacher_vocal_nodate,
	Author = {Schumacher, Joseph W and Woolley, Sarah M N},
	File = {Schumacher et Woolley - Vocal tutoring drives rapid tuning of neurons in t.pdf:/Users/Cecile/Zotero/storage/C4PK8HAM/Schumacher et Woolley - Vocal tutoring drives rapid tuning of neurons in t.pdf:application/pdf},
	Language = {en},
	Pages = {41},
	Title = {Vocal tutoring drives rapid tuning of neurons in the auditory cortex}}

@article{keller_neural_2009,
	Abstract = {Living in noisy colonies, songbird vocal learning requires individuals to differentiate self-generated vocalizations from other sound sources to accurately match the learned song template. However, neurons responding to vocal output have not been identified. This study identifies neurons in the auditory forebrain of zebra finch that specifically responded to either song or playback perturbations, suggesting the existence of a computational error-checking function in the forebrain auditory areas.},
	Author = {Keller, Georg B. and Hahnloser, Richard H. R.},
	Copyright = {2008 Macmillan Publishers Limited. All rights reserved},
	Doi = {10.1038/nature07467},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DEXLEPNH/Keller et Hahnloser - 2009 - Neural processing of auditory feedback during voca.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CPETINXZ/nature07467.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = jan,
	Number = {7226},
	Pages = {187--190},
	Title = {Neural processing of auditory feedback during vocal practice in a songbird},
	Url = {https://www.nature.com/articles/nature07467},
	Urldate = {2020-02-08},
	Volume = {457},
	Year = {2009},
	Bdsk-Url-1 = {https://www.nature.com/articles/nature07467},
	Bdsk-Url-2 = {https://doi.org/10.1038/nature07467}}

@article{hough_short-term_2002,
	Abstract = {Adult zebra finch song is irreversibly altered when birds are deprived of correct feedback by deafening or denervation of the syrinx. To clarify the role of feedback in song maintenance, we developed a reversible technique to distort vocal output without damaging the auditory or vocal systems. We implanted flexible beads adjacent to the syrinx to alter its biomechanics. Immediate song aberrations included low volume, frequency shifts, missing harmonics, and production of click-like syllables. After a few weeks, seven of nine birds stopped producing some syllables. In six of these birds, the gaps left by the silenced syllables gradually shortened, and the lost syllables did not return when beads were removed 16 weeks after treatment began. The nondeleted syllables of all birds regained their preimplant morphology, insofar as could be detected, within 9 d after bead removal. In four other birds, we removed the beads as soon as syllables were deleted, when the silent intervals were still full length. In these birds, all deleted syllables returned within 1 week. Our results indicate that both silenced syllables and syllable morphology can recover as long as the song's temporal structure is maintained, but once altered, changes in the song sequence can be permanent. A hierarchical organization of the song production system has recently been described (). Reversible disruption of song production by our method appears to permanently alter the higher levels of the system that encode song sequence, but not the lower levels that encode individual syllable structure.},
	Author = {Hough, Gerald E. and Volman, Susan F.},
	Doi = {10.1523/JNEUROSCI.22-03-01177.2002},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Y27T7RPW/Hough et Volman - 2002 - Short-Term and Long-Term Effects of Vocal Distorti.pdf:application/pdf},
	Issn = {0270-6474},
	Journal = {The Journal of Neuroscience},
	Month = feb,
	Number = {3},
	Pages = {1177--1186},
	Pmcid = {PMC6758533},
	Pmid = {11826147},
	Title = {Short-{Term} and {Long}-{Term} {Effects} of {Vocal} {Distortion} on {Song} {Maintenance} in {Zebra} {Finches}},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6758533/},
	Urldate = {2020-02-08},
	Volume = {22},
	Year = {2002},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6758533/},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.22-03-01177.2002}}

@techreport{yamahachi_welfare_2017,
	Abstract = {Over the past 50 years, songbirds have become a valuable model organism for scientists studying vocal communication from its behavioral, hormonal, neuronal, and genetic perspectives. Many advances in our understanding of vocal learning result from research using the zebra finch, a close-ended vocal learner. We review some of the manipulations used in zebra finch research, such as isolate housing, transient/irreversible impairment of hearing/vocal organs, implantation of small devices for chronic electrophysiology, head fixation for imaging, aversive song conditioning using sound playback, and mounting of miniature backpacks for behavioral monitoring. We highlight the use of these manipulations in scientific research, and estimate their impact on animal welfare, based on the literature and on data from our past and ongoing work. The assessment of harm-benefits tradeoffs is a legal prerequisite for animal research in Switzerland. We conclude that a diverse set of known stressors reliably lead to suppressed singing rate, and that by contraposition, increased singing rate may be a useful indicator of welfare. We hope that our study can contribute to answering some of the most burning questions about zebra finch welfare in research on vocal behaviors.},
	Author = {Yamahachi, Homare and Zai, Anja T. and Tachibana, Ryosuke O. and Stepien, Anna E. and Rodrigues, Diana I. and Cav{\'e}-Lopez, Sophie and Narula, Gagan and Lee, Juneseung and Huang, Ziqiang and H{\"o}rster, Heiko and D{\"u}ring, Daniel and Hahnloser, Richard H. R.},
	Doi = {10.1101/154567},
	File = {Yamahachi et al. - 2017 - Welfare of zebra finches used in research.pdf:/Users/Cecile/Zotero/storage/FGFLRTKY/Yamahachi et al. - 2017 - Welfare of zebra finches used in research.pdf:application/pdf},
	Institution = {Animal Behavior and Cognition},
	Language = {en},
	Month = jun,
	Title = {Welfare of zebra finches used in research},
	Type = {preprint},
	Url = {http://biorxiv.org/lookup/doi/10.1101/154567},
	Urldate = {2020-02-08},
	Year = {2017},
	Bdsk-Url-1 = {http://biorxiv.org/lookup/doi/10.1101/154567},
	Bdsk-Url-2 = {https://doi.org/10.1101/154567}}

@article{brown_air_2006,
	Abstract = {Air sac cannulas are indicated in birds with upper respiratory obstruction or for ventilation during surgical procedures involving the head and neck. Proper technique, knowledge of potential complications, and an understanding of the indications for air sac tube placement are important for scientists, veterinarians, and technicians who work with birds.},
	Author = {Brown, Cyndi and Pilny, Anthony A.},
	Copyright = {2006 Nature Publishing Group},
	Doi = {10.1038/laban0706-23},
	File = {Snapshot:/Users/Cecile/Zotero/storage/TTL7PNFM/laban0706-23.html:text/html},
	Issn = {1548-4475},
	Journal = {Lab Animal},
	Language = {en},
	Month = jul,
	Number = {7},
	Pages = {23--24},
	Title = {Air sac cannula placement in birds},
	Url = {https://www.nature.com/articles/laban0706-23},
	Urldate = {2020-02-08},
	Volume = {35},
	Year = {2006},
	Bdsk-Url-1 = {https://www.nature.com/articles/laban0706-23},
	Bdsk-Url-2 = {https://doi.org/10.1038/laban0706-23}}

@article{phan_early_2006,
	Abstract = {In both humans and songbirds, infants learn vocalizations by imitating the sounds of adult tutors with whom they interact during an early sensitive period. Vocal learning occurs in few animal taxa; similarities in the imitation process between humans and songbirds make the songbird a unique system in which vocal learning mechanisms can be studied at the neurobiological level. One theory of vocal learning proposes that early auditory experience generates auditory memories that subsequently guide vocal imitation. We now present a combination of behavioral and neurophysiological results, obtained in a songbird, that support this theory. We show that neurons in a forebrain auditory area of adult male zebra finches are selectively tuned to the song of a tutor heard early in development. Furthermore, the strength of this selectivity shows a striking correlation with the fidelity of vocal imitation, suggesting that this auditory memory may have served as the model for song learning.},
	Author = {Phan, Mimi L. and Pytte, Carolyn L. and Vicario, David S.},
	Copyright = {Copyright {\copyright} 2006, The National Academy of Sciences. Freely available online through the PNAS open access option.},
	Doi = {10.1073/pnas.0510136103},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/T4YJT4SA/Phan et al. - 2006 - Early auditory experience generates long-lasting m.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/J2JE9CBZ/1088.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {development, electrophysiology, caudal medial nidopallium, memory, zebra finch},
	Language = {en},
	Month = jan,
	Number = {4},
	Pages = {1088--1093},
	Pmid = {16418265},
	Title = {Early auditory experience generates long-lasting memories that may subserve vocal learning in songbirds},
	Url = {https://www.pnas.org/content/103/4/1088},
	Urldate = {2020-02-11},
	Volume = {103},
	Year = {2006},
	Bdsk-Url-1 = {https://www.pnas.org/content/103/4/1088},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0510136103}}

@article{kelley_generation_2020,
	Abstract = {In many species, vocal communication is essential for coordinating social behaviors including courtship, mating, parenting, rivalry, and alarm signaling. Effective communication requires accurate production, detection, and classification of signals, as well as selection of socially appropriate responses. Understanding how signals are generated and how acoustic signals are perceived is key to understanding the neurobiology of social behaviors. Here we review our long-standing research program focused on Xenopus, a frog genus which has provided valuable insights into the mechanisms and evolution of vertebrate social behaviors. In Xenopus laevis, vocal signals differ between the sexes, through development, and across the genus, reflecting evolutionary divergence in sensory and motor circuits that can be interrogated mechanistically. Using two ex vivo preparations, the isolated brain and vocal organ, we have identified essential components of the vocal production system: the sexually differentiated larynx at the periphery, and the hindbrain vocal central pattern generator (CPG) centrally, that produce sex- and species-characteristic sound pulse frequencies and temporal patterns, respectively. Within the hindbrain, we have described how intrinsic membrane properties of neurons in the vocal CPG generate species-specific vocal patterns, how vocal nuclei are connected to generate vocal patterns, as well as the roles of neurotransmitters and neuromodulators in activating the circuit. For sensorimotor integration, we identified a key forebrain node that links auditory and vocal production circuits to match socially appropriate vocal responses to acoustic features of male and female calls. The availability of a well supported phylogeny as well as reference genomes from several species now support analysis of the genetic architecture and the evolutionary divergence of neural circuits for vocal communication. Xenopus thus provides a vertebrate model in which to study vocal communication at many levels, from physiology, to behavior, and from development to evolution. As one of the most comprehensively studied phylogenetic groups within vertebrate vocal communication systems, Xenopus provides insights that can inform social communication across phyla.},
	Author = {Kelley, Darcy B. and Ballagh, Irene H. and Barkan, Charlotte L. and Bendesky, Andres and Elliott, Taffeta M. and Evans, Ben J. and Hall, Ian C. and Kwon, Young Mi and Kwong-Brown, Ursula and Leininger, Elizabeth C. and Perez, Emilie C. and Rhodes, Heather J. and Villain, Avelyne and Yamaguchi, Ayako and Zornik, Erik},
	Copyright = {Copyright {\copyright} 2020 the authors},
	Doi = {10.1523/JNEUROSCI.0736-19.2019},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/H7ZGWF64/Kelley et al. - 2020 - Generation, Coordination, and Evolution of Neural .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/GEBBY4MU/22.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {CPG, duets, hindbrain, neuroendocrine, parabrachial, song},
	Language = {en},
	Month = jan,
	Number = {1},
	Pages = {22--36},
	Pmid = {31896561},
	Title = {Generation, {Coordination}, and {Evolution} of {Neural} {Circuits} for {Vocal} {Communication}},
	Url = {https://www.jneurosci.org/content/40/1/22},
	Urldate = {2020-02-11},
	Volume = {40},
	Year = {2020},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/40/1/22},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.0736-19.2019}}

@article{santolin_role_2019,
	Abstract = {Speech preferences emerge very early in infancy, pointing to a special status for speech in auditory processing and a crucial role of prosody in driving infant preferences. Recent theoretical models suggest that infant auditory perception may initially encompass a broad range of human and nonhuman vocalizations, then tune in to relevant sounds for the acquisition of species-specific communication sounds. However, little is known about sound properties eliciting infants' tuning-in to speech. To address this issue, we presented a group of 4-month-olds with segments of non-native speech (Mandarin Chinese) and birdsong, a nonhuman vocalization that shares some prosodic components with speech. A second group of infants was presented with the same segment of birdsong paired with Mandarin played in reverse. Infants showed an overall preference for birdsong over non-native speech. Moreover, infants in the Backward condition preferred birdsong over backward speech whereas infants in the Forward condition did not show clear preference. These results confirm the prominent role of prosody in early auditory processing and suggest that infants' preferences may privilege communicative vocalizations featured by certain prosodic dimensions regardless of the biological source of the sound, human or nonhuman.},
	Annote = {meta-analysis},
	Author = {Santolin, Chiara and Russo, Sofia and Calignano, Giulia and Saffran, Jenny R. and Valenza, Eloisa},
	Copyright = {{\copyright} International Congress of Infant Studies (ICIS)},
	Date-Modified = {2020-06-16 13:49:43 +0200},
	Doi = {10.1111/infa.12295},
	File = {Snapshot:/Users/Cecile/Zotero/storage/7GZ3I4XP/infa.html:text/html},
	Issn = {1532-7078},
	Journal = {Infancy},
	Language = {en},
	Number = {5},
	Pages = {827--833},
	Shorttitle = {The role of prosody in infants' preference for speech},
	Title = {The role of prosody in infants' preference for speech: {A} comparison between speech and birdsong},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12295},
	Urldate = {2020-02-13},
	Volume = {24},
	Year = {2019},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/infa.12295},
	Bdsk-Url-2 = {https://doi.org/10.1111/infa.12295}}

@article{brainard_contributions_2004,
	Abstract = {The anterior forebrain pathway (AFP) is a basal ganglia-dorsal forebrain circuit that is prominent specifically in birds that learn to sing. This circuit is interconnected with the song motor pathway, is active during song production, and contains neurons that are selective for the sound of the bird's own song, suggesting an important role for the AFP in vocal behavior. However, interruption of the AFP by lesions in adult birds has little overt effect on the production of learned song. In contrast, lesions in juvenile birds prevent the normal progression of song learning. Moreover, lesions in adults, while not disrupting production, can prevent experience-dependent plasticity of song. Such data implicate the AFP specifically in song learning and vocal plasticity. This chapter reviews some of the experimental evidence supporting a role for the AFP in these processes and discusses potential instructive and permissive functions of the AFP in vocal plasticity.},
	Author = {Brainard, Michael S.},
	Doi = {10.1196/annals.1298.042},
	Issn = {0077-8923},
	Journal = {Annals of the New York Academy of Sciences},
	Keywords = {Animals, Attention, Learning, Models, Biological, Psychomotor Performance, Vocalization, Animal, Feedback, Motivation, Prosencephalon, Songbirds},
	Language = {eng},
	Month = jun,
	Pages = {377--394},
	Pmid = {15313786},
	Title = {Contributions of the anterior forebrain pathway to vocal plasticity},
	Volume = {1016},
	Year = {2004},
	Bdsk-Url-1 = {https://doi.org/10.1196/annals.1298.042}}

@article{perkel_origin_2004,
	Abstract = {Abstract: The brain nuclei and pathways comprising the song system of oscine songbirds bear many similarities with circuits in other bird species and in mammals. This suggests that the song system evolved as a specialization of pre-existing circuits and may retain fundamental properties in common with those of other taxa. Here we review evidence for these similarities, including electrophysiological, morphological, and neurochemical data for identifying specific cell types. In addition, we discuss connectional data, addressing similarities in axonal projections among nuclei across taxa. We focus primarily on the anterior forebrain pathway, a circuit essential for song learning and vocal plasticity, because the evidence is strongest that this circuit is homologous to mammalian circuits. These fundamental similarities highlight the importance of comparative approaches; for example, understanding the role the anterior forebrain pathway plays in song plasticity may shed light on general principles of basal ganglia function. In addition, understanding specializations of such circuits in songbirds may illuminate specific innovations critical for vocal learning.},
	Author = {Perkel, David J.},
	Doi = {10.1196/annals.1298.039},
	File = {Snapshot:/Users/Cecile/Zotero/storage/76N2YE5Y/annals.1298.html:text/html},
	Issn = {0077-8923},
	Journal = {Annals of the New York Academy of Sciences},
	Keywords = {basal ganglia, comparative neurobiology, evolution, striatum},
	Month = jun,
	Number = {1},
	Pages = {736--748},
	Title = {Origin of the {Anterior} {Forebrain} {Pathway}},
	Url = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.039},
	Urldate = {2020-02-13},
	Volume = {1016},
	Year = {2004},
	Bdsk-Url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.039},
	Bdsk-Url-2 = {https://doi.org/10.1196/annals.1298.039}}

@article{brainard_auditory_2000,
	Abstract = {Songbirds are one of the best-studied examples of vocal learners. Learning of both human speech and birdsong depends on hearing. Once learned, adult song in many species remains unchanging, suggesting a reduced influence of sensory experience. Recent studies have revealed, however, that adult song is not always stable, extending our understanding of the mechanisms involved in song maintenance, and their similarity to those active during song learning. Here we review some of the processes that contribute to song learning and production, with an emphasis on the role of auditory feedback. We then consider some of the possible neural substrates involved in these processes, particularly basal ganglia circuitry. Although a thorough treatment of human speech is beyond the scope of this article, we point out similarities between speech and song learning, and ways in which studies of these disparate behaviours complement each other in developing an understanding of general principles that contribute to learning and maintenance of vocal behaviour.},
	Author = {Brainard, Michael S. and Doupe, Allison J.},
	Copyright = {2000 Macmillan Magazines Ltd.},
	Doi = {10.1038/35036205},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CBGZX6Q4/Brainard et Doupe - 2000 - Auditory feedback in learning and maintenance of v.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/CYI4J24U/35036205.html:text/html},
	Issn = {1471-0048},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = oct,
	Number = {1},
	Pages = {31--40},
	Title = {Auditory feedback in learning and maintenance of vocal behaviour},
	Url = {https://www.nature.com/articles/35036205},
	Urldate = {2020-02-14},
	Volume = {1},
	Year = {2000},
	Bdsk-Url-1 = {https://www.nature.com/articles/35036205},
	Bdsk-Url-2 = {https://doi.org/10.1038/35036205}}

@article{theunissen_song_2004,
	Abstract = {Abstract: The sensorimotor neurons found in the song-system nuclei are responsive to the sounds of the bird's own song. This selectivity emerges during vocal learning and appears to follow the development of the bird's song vocalization in two ways: at each stage, the neurons are most selective for the bird's current vocalizations and this selectivity increases as the bird learns to produce a stable adult song. Also, because of their location in the sensori-vocal pathway and because their physiological properties are correlated with the motor program, it is postulated that these neurons play a crucial role in interpreting the auditory feedback during song to preserve a desirable vocal output. The neurons found in presynaptic auditory areas lack this selectivity for the bird's own song. Auditory neurons in the secondary auditory areas caudal nidopallium and caudal mesopallium show specific responses to familiar songs or behaviorally relevant songs. These auditory areas might therefore be involved in perceptual tasks. Neurons in the primary forebrain auditory area are selective for the spectrotemporal modulations that are common in song, yielding an efficient neural representation of those sounds. Neurons that are particularly selective for the tutor song at the end of the sensory period have not yet been described in any areas. Although these three levels of selectivity found in the primary auditory forebrain areas, the secondary auditory forebrain areas, and the song system suggest a form of hierarchical sensory processing, the functional connectivity between these areas and the mechanisms generating the specific selectivity for songs that are behaviorally relevant or crucial in song learning and production have yet to be revealed.},
	Author = {Theunissen, Fr{\'e}d{\'e}ric E. and Amin, Noopur and Shaevitz, Sarita S. and Woolley, Sarah M. N. and Fremouw, Thane and Hauber, Mark E.},
	Doi = {10.1196/annals.1298.023},
	File = {Snapshot:/Users/Cecile/Zotero/storage/VZ72LJ83/annals.1298.html:text/html},
	Issn = {0077-8923},
	Journal = {Annals of the New York Academy of Sciences},
	Keywords = {auditory cortex, natural sounds, vocalizations},
	Month = jun,
	Number = {1},
	Pages = {222--245},
	Title = {Song {Selectivity} in the {Song} {System} and in the {Auditory} {Forebrain}},
	Url = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.023},
	Urldate = {2020-02-14},
	Volume = {1016},
	Year = {2004},
	Bdsk-Url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/full/10.1196/annals.1298.023},
	Bdsk-Url-2 = {https://doi.org/10.1196/annals.1298.023}}

@article{morillon_motor_2017,
	Abstract = {In behavior, action and perception are inherently interdependent. However, the actual mechanistic contributions of the motor system to sensory processing are unknown. We present neurophysiological evidence that the motor system is involved in predictive timing, a brain function that aligns temporal fluctuations of attention with the timing of events in a task-relevant stream, thus facilitating sensory selection and optimizing behavior. In a magnetoencephalography experiment involving auditory temporal attention, participants had to disentangle two streams of sound on the unique basis of endogenous temporal cues. We show that temporal predictions are encoded by interdependent delta and beta neural oscillations originating from the left sensorimotor cortex, and directed toward auditory regions. We also found that overt rhythmic movements improved the quality of temporal predictions and sharpened the temporal selection of relevant auditory information. This latter behavioral and functional benefit was associated with increased signaling of temporal predictions in right-lateralized frontoparietal associative regions. In sum, this study points at a covert form of auditory active sensing. Our results emphasize the key role of motor brain areas in providing contextual temporal information to sensory regions, driving perceptual and behavioral selection.},
	Author = {Morillon, Benjamin and Baillet, Sylvain},
	Copyright = {{\copyright} . http://www.pnas.org/site/misc/userlicense.xhtml},
	Doi = {10.1073/pnas.1705373114},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2E3VDNEI/Morillon et Baillet - 2017 - Motor origin of temporal predictions in auditory a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/YDBHTITD/E8913.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {magnetoencephalography, auditory perception, rhythm, psychophysics, sensorimotor},
	Language = {en},
	Month = oct,
	Number = {42},
	Pages = {E8913--E8921},
	Pmid = {28973923},
	Title = {Motor origin of temporal predictions in auditory attention},
	Url = {https://www.pnas.org/content/114/42/E8913},
	Urldate = {2020-02-24},
	Volume = {114},
	Year = {2017},
	Bdsk-Url-1 = {https://www.pnas.org/content/114/42/E8913},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.1705373114}}

@article{foster_role_2010,
	Abstract = {Abstract.  The present functional magnetic resonance imaging study investigates the neural substrates of relative pitch. Musicians and nonmusicians performed 2},
	Author = {Foster, Nicholas E. V. and Zatorre, Robert J.},
	Doi = {10.1093/cercor/bhp199},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/CIEJ72WL/Foster et Zatorre - 2010 - A Role for the Intraparietal Sulcus in Transformin.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/EJGBHKSK/316634.html:text/html},
	Issn = {1047-3211},
	Journal = {Cerebral Cortex},
	Language = {en},
	Month = jun,
	Number = {6},
	Pages = {1350--1359},
	Title = {A {Role} for the {Intraparietal} {Sulcus} in {Transforming} {Musical} {Pitch} {Information}},
	Url = {https://academic.oup.com/cercor/article/20/6/1350/316634},
	Urldate = {2020-02-24},
	Volume = {20},
	Year = {2010},
	Bdsk-Url-1 = {https://academic.oup.com/cercor/article/20/6/1350/316634},
	Bdsk-Url-2 = {https://doi.org/10.1093/cercor/bhp199}}

@article{mizuhara_songbirds_2020,
	Abstract = {Songbirds as vocal learners have been one of the most popular model species to investigate the biological prerequisite to human language. Their songs consist of syllables, which appear as pulse trains in sound spectrograms. When describing the song sequence, researchers consider the syllable to be the unit of the song. Moreover, artificial grammar learning studies asking whether songbirds recognize structural regularities observed in human language often design stimuli using song syllables as components. However, whether syllables are perceptual units is yet to be determined. We found that Bengalese finches, a species of songbird, responded significantly less to one specific syllable when it was temporally placed close to the preceding syllable. The proximity, or silent interval was within the range of what is produced in the natural songs of both Bengalese and zebra finches, and what has been used in other artificial grammar learning studies using zebra finches. Our results suggest the need for a reinterpretation of the description of birdsong structure and of previous artificial grammar learning studies.},
	Author = {Mizuhara, Tomoko and Okanoya, Kazuo},
	Doi = {10.1016/j.beproc.2020.104089},
	File = {Mizuhara et Okanoya - 2020 - Do songbirds hear songs syllable by syllable.pdf:/Users/Cecile/Zotero/storage/RGDKU5B7/Mizuhara et Okanoya - 2020 - Do songbirds hear songs syllable by syllable.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/37K4BVJT/S0376635719302669.html:text/html},
	Issn = {0376-6357},
	Journal = {Behavioural Processes},
	Keywords = {Songbirds, Artificial grammar learning, Operant conditioning, Syllable perception},
	Language = {en},
	Month = may,
	Pages = {104089},
	Title = {Do songbirds hear songs syllable by syllable?},
	Url = {http://www.sciencedirect.com/science/article/pii/S0376635719302669},
	Urldate = {2020-02-28},
	Volume = {174},
	Year = {2020},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0376635719302669},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.beproc.2020.104089}}

@techreport{bergelson_quantifying_2017,
	Abstract = {The field of psychology has become increasingly concerned with issues related to methodology and replicability. Infancy researchers face specific challenges related to replicability: high-powered studies are difficult to conduct, testing conditions vary across labs, and different labs have access to different infant populations, amongst other factors. Addressing these concerns, we report on a large-scale, multi-site study aimed at 1) assessing the overall replicability of a single theoretically-important phenomenon and 2) examining methodological, situational, cultural, and developmental moderators. We focus on infants' preference for infant-directed speech (IDS) over adult-directed speech (ADS). Stimuli of mothers speaking to their infants and to an adult were created using semi-naturalistic laboratory-based audio recordings in North American English. Infants' relative preference for IDS and ADS was assessed across 67 laboratories in North America, Europe, Australia, and Asia using the three commonly-used infant discrimination methods (head-turn preference, central fixation, and eye tracking). The overall meta-analytic effect size (Cohen's *d*) was 0.35 [0.29 - 0.42], which was reliably above zero but smaller than the meta-analytic mean computed from previous literature (0.67). The IDS preference was significantly stronger in older children, in those children for whom the stimuli matched their native language and dialect, and in data from labs using the head-turn preference procedure. Together these findings replicate the infant-directed speech preference but suggest that its magnitude is modulated by development, native language experience, and testing procedure.},
	Author = {Bergelson, Elika and Bergmann, Christina and Byers-Heinlein, Krista and Cristia, Alejandrina and Cusack, Rhodri and Dyck, Kelsey and floccia, caroline and Frank, Michael C. and Gervain, Judit and Gonzalez, Nayeli and Hamlin, Kiley and Hannon, Erin and Kellier, Danielle and Kline, Melissa and Lew-Williams, Casey and Nazzi, Thierry and Panneton, Robin and Rabagliati, Hugh and Rennels, Jennifer and Seidl, Amanda and Soderstrom, Melanie and Yurovsky, Daniel},
	Doi = {10.31234/osf.io/s98ab},
	File = {Bergelson et al. - 2017 - Quantifying sources of variability in infancy rese.pdf:/Users/Cecile/Zotero/storage/HBBFIJ4F/Bergelson et al. - 2017 - Quantifying sources of variability in infancy rese.pdf:application/pdf},
	Institution = {PsyArXiv},
	Language = {en},
	Month = apr,
	Title = {Quantifying sources of variability in infancy research using the infant-directed speech preference},
	Type = {preprint},
	Url = {https://osf.io/s98ab},
	Urldate = {2020-03-04},
	Year = {2017},
	Bdsk-Url-1 = {https://osf.io/s98ab},
	Bdsk-Url-2 = {https://doi.org/10.31234/osf.io/s98ab}}

@article{karen_cerebral_2019,
	Author = {Karen, Tanja and Kleiser, Stefan and Ostojic, Daniel and Isler, Helene and Guglielmini, Sabino and Bassler, Dirk and Wolf, Martin and Scholkmann, Felix},
	Doi = {10.1117/1.NPh.6.4.045005},
	File = {Karen et al. - 2019 - Cerebral hemodynamic responses in preterm-born neo.pdf:/Users/Cecile/Zotero/storage/LKGCU6SP/Karen et al. - 2019 - Cerebral hemodynamic responses in preterm-born neo.pdf:application/pdf},
	Issn = {2329-423X},
	Journal = {Neurophotonics},
	Language = {en},
	Month = nov,
	Number = {04},
	Pages = {1},
	Shorttitle = {Cerebral hemodynamic responses in preterm-born neonates to visual stimulation},
	Title = {Cerebral hemodynamic responses in preterm-born neonates to visual stimulation: classification according to subgroups and analysis of frontotemporal--occipital functional connectivity},
	Url = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-6/issue-04/045005/Cerebral-hemodynamic-responses-in-preterm-born-neonates-to-visual-stimulation/10.1117/1.NPh.6.4.045005.full},
	Urldate = {2020-03-05},
	Volume = {6},
	Year = {2019},
	Bdsk-Url-1 = {https://www.spiedigitallibrary.org/journals/neurophotonics/volume-6/issue-04/045005/Cerebral-hemodynamic-responses-in-preterm-born-neonates-to-visual-stimulation/10.1117/1.NPh.6.4.045005.full},
	Bdsk-Url-2 = {https://doi.org/10.1117/1.NPh.6.4.045005}}

@article{fishbein_sound_2020-1,
	Abstract = {The complex and melodic nature of many birds' songs has raised interest in potential parallels between avian vocal sequences and human speech. The similarities between birdsong and speech in production and learning are well established, but surprisingly little is known about how birds perceive song sequences. One popular laboratory songbird, the zebra finch (Taeniopygia guttata), has recently attracted attention as an avian model for human speech, in part because the male learns to produce the individual elements in its song motif in a fixed sequence. But psychoacoustic evidence shows that adult zebra finches are relatively insensitive to the sequential features of song syllables. Instead, zebra finches and other birds seem to be exquisitely sensitive to the acoustic details of individual syllables to a degree that is beyond human hearing capacity. Based on these findings, we present a finite-state model of zebra finch perception of song syllable sequences and discuss the rich informational capacity of their vocal system. Furthermore, we highlight the abilities of budgerigars (Melopsittacus undulatus), a parrot species, to hear sequential features better than zebra finches and suggest that neurophysiological investigations comparing these species could prove fruitful for uncovering neural mechanisms for auditory sequence perception in human speech.This article is part of the theme issue `What can animal communication teach us about human language?'},
	Author = {Fishbein, Adam R. and Idsardi, William J. and Ball, Gregory F. and Dooling, Robert J.},
	Doi = {10.1098/rstb.2019.0044},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZHDBJUFQ/Fishbein et al. - 2020 - Sound sequences in birdsong how much do birds rea.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7QNKT7HU/rstb.2019.html:text/html},
	Journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	Month = jan,
	Note = {Publisher: Royal Society},
	Number = {1789},
	Pages = {20190044},
	Shorttitle = {Sound sequences in birdsong},
	Title = {Sound sequences in birdsong: how much do birds really care?},
	Url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	Urldate = {2020-03-10},
	Volume = {375},
	Year = {2020},
	Bdsk-Url-1 = {https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0044},
	Bdsk-Url-2 = {https://doi.org/10.1098/rstb.2019.0044}}

@article{vates_auditory_1996,
	Abstract = {Auditory information is critical for vocal imitation and other elements of social life in songbirds. In zebra finches, neural centers that are necessary for the acquisition and production of learned vocalizations are known, and they all respond to acoustic stimulation. However, the circuits by which conspecific auditory signals are perceived, processed, and stored in long-term memory have not been well documented. In particular, no evidence exists of direct connections between auditory and vocal motor pathways, and two newly identified centers for auditory processing, caudomedial neostriatum (Ncm) and caudomedial hyperstriatum ventrale (cmHV), have no documented place among known auditory circuits. Our goal was to describe anatomically the auditory pathways in adult zebra finch males and, specifically, to show the projections by which Ncm and vocal motor centers may receive auditory input. By using injections of different kinds of neuroanatomical tracers (biotinylated dextran amines, rhodamine-linked dextran amines, biocytin, fluorogold, and rhodamine-linked latex beads), we have shown that, as in other avian groups, the neostriatal field L complex in caudal telencephalon is the primary forebrain relay for pathways originating in the auditory thalamus, i.e., the nucleus ovoidalis complex (Ov). In addition, Ncm and cmHV also receive input from the Ov complex. Ov has been broken down into two parts, the Ov ``core'' and ``shell,'' which project in parallel to different targets in the caudal telencephalon. Parts of the field L complex are connected among themselves and to Ncm, cmHV, and caudolateral HV (cIHV) through a complex web of largely reciprocal pathways. In addition, cIHV and parts of the field L complex project strongly to the ``shelf'' of neostriatum underneath the song control nucleus high vocal center (HVC) and to the ``cup'' of archistriatum rostrodorsal to another song-control nucleus, the robust nucleus of the archistriatum (RA). We have documented two points at which the vocal motor pathway may pick up auditory signals: the HVC-shelf interface and a projection from cIHV to the nucleus interfacialis (NIf), which projects to HVC. These data represent the most complete survey to date of auditory pathways in the adult male zebra finch brain, and of their projections to motor stations of the song system. {\copyright} 1996 Wiley-Liss, Inc.},
	Author = {Vates, G. Edward and Broome, Bede M. and Mello, Claudio V. and Nottebohm, Fernando},
	Copyright = {Copyright {\copyright} 1996 WileyâLiss, Inc.},
	Doi = {10.1002/(SICI)1096-9861(19960318)366:4<613::AID-CNE5>3.0.CO;2-7},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/25USM6WF/Vates et al. - 1996 - Auditory pathways of caudal telencephalon and thei.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/IWJ7IX8R/(SICI)1096-9861(19960318)3664613AID-CNE53.0.html:text/html},
	Issn = {1096-9861},
	Journal = {Journal of Comparative Neurology},
	Keywords = {birdsong, field L complex, HVC, Ncm, shelf},
	Language = {en},
	Note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/\%28SICI\%291096-9861\%2819960318\%29366\%3A4\%3C613\%3A\%3AAID-CNE5\%3E3.0.CO\%3B2-7},
	Number = {4},
	Pages = {613--642},
	Title = {Auditory pathways of caudal telencephalon and their relation to the song system of adult male zebra finches ({Taenopygia} guttata)},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9861%2819960318%29366%3A4%3C613%3A%3AAID-CNE5%3E3.0.CO%3B2-7},
	Urldate = {2020-03-11},
	Volume = {366},
	Year = {1996},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1002/%28SICI%291096-9861%2819960318%29366%3A4%3C613%3A%3AAID-CNE5%3E3.0.CO%3B2-7},
	Bdsk-Url-2 = {https://doi.org/10.1002/(SICI)1096-9861(19960318)366:4%3C613::AID-CNE5%3E3.0.CO;2-7}}

@article{rioslopez_development_nodate,
	Abstract = {Recent neurophysiological theories propose that the cerebral hemispheres collaborate to resolve the complex temporal nature of speech, such that left-hemisphere (or bilateral) gamma-band oscillatory activity would specialize in coding information at fast rates (phonemic information), whereas right-hemisphere delta- and theta-band activity would code for speech's slow temporal components (syllabic and prosodic information). Despite the relevance that neural entrainment to speech might have for reading acquisition and for core speech perception operations such as the perception of intelligible speech, no study had yet explored its development in young children. In the current study, speech-brain entrainment was recorded via EEG in a cohort of children at three different time points since they were 4--5 to 6--7 years of age. Our results showed that speech-brain entrainment occurred only at delta frequencies (0.5 Hz) at all testing times. The fact that, from the longitudinal perspective, coherence increased in bilateral temporal electrodes suggests that, contrary to previous hypotheses claiming for an innate right-hemispheric bias for processing prosodic information, at 7 years of age the low-frequency components of speech are processed in a bilateral manner. Lastly, delta speech-brain entrainment in the right hemisphere was related to an indirect measure of intelligibility, providing preliminary evidence that the entrainment phenomenon might support core linguistic operations since early childhood.},
	Author = {R{\'\i}osâL{\'o}pez, Paula and Molinaro, Nicola and Bourguignon, Mathieu and Lallier, Marie},
	Copyright = {{\copyright} 2020 The Authors. Developmental Science published by John Wiley \& Sons Ltd},
	Doi = {10.1111/desc.12947},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/2BPBX7PP/R{\'\i}osâL{\'o}pez et al. - Development of neural oscillatory activity in resp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VXM37RF8/desc.html:text/html},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Keywords = {coherence, speech perception, language development, language lateralization, neural entrainment, reading acquisition},
	Language = {en},
	Note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12947},
	Number = {n/a},
	Pages = {e12947},
	Title = {Development of neural oscillatory activity in response to speech in children from 4 to 6 years old},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12947},
	Urldate = {2020-03-17},
	Volume = {n/a},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12947},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12947}}

@article{kalashnikova_infant-directed_2018,
	Abstract = {This study assessed cortical tracking of temporal information in incoming natural speech in seven-month-old infants. Cortical tracking refers to the process by which neural activity follows the dynamic patterns of the speech input. In adults, it has been shown to involve attentional mechanisms and to facilitate effective speech encoding. However, in infants, cortical tracking or its effects on speech processing have not been investigated. This study measured cortical tracking of speech in infants and, given the involvement of attentional mechanisms in this process, cortical tracking of both infant-directed speech (IDS), which is highly attractive to infants, and the less captivating adult-directed speech (ADS), were compared. IDS is the speech register parents use when addressing young infants. In comparison to ADS, it is characterised by several acoustic qualities that capture infants' attention to linguistic input and assist language learning. Seven-month-old infants' cortical responses were recorded via electroencephalography as they listened to IDS or ADS recordings. Results showed stronger low-frequency cortical tracking of the speech envelope in IDS than in ADS. This suggests that IDS has a privileged status in facilitating successful cortical tracking of incoming speech which may, in turn, augment infants' early speech processing and even later language development.},
	Author = {Kalashnikova, Marina and Peter, Varghese and Liberto, Giovanni M. Di and Lalor, Edmund C. and Burnham, Denis},
	Copyright = {2018 The Author(s)},
	Doi = {10.1038/s41598-018-32150-6},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/PH5TQ53A/Kalashnikova et al. - 2018 - Infant-directed speech facilitates seven-month-old.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/7CTKDTBI/s41598-018-32150-6.html:text/html},
	Issn = {2045-2322},
	Journal = {Scientific Reports},
	Language = {en},
	Month = sep,
	Note = {Number: 1 Publisher: Nature Publishing Group},
	Number = {1},
	Pages = {1--8},
	Title = {Infant-directed speech facilitates seven-month-old infants' cortical tracking of speech},
	Url = {https://www.nature.com/articles/s41598-018-32150-6},
	Urldate = {2020-03-17},
	Volume = {8},
	Year = {2018},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41598-018-32150-6},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41598-018-32150-6}}

@article{peter_mature_2016,
	Abstract = {Infant directed speech (IDS), the speech register adults use when talking to infants, has been shown to have positive effects on attracting infants' attention, language learning, and emotional communication. Here event related potentials (ERPs) are used to investigate the neural coding of IDS and ADS (adult directed speech) as well as their discrimination by both infants and adults. Two instances of the vowel /i/, one extracted from ADS and one from IDS, were presented to 9-month-old infants and adults in two oddball conditions: ADS standard/IDS deviant and IDS standard/ADS deviant. In Experiment 1 with adults, the obligatory ERPs that code acoustic information were different for ADS and IDS; and discrimination, indexed by mismatch negativity (MMN) responses, showed that IDS and ADS deviants were discriminated equally well; although, the P3a response was larger for IDS suggesting it captured adults' attention more than did ADS. In infants the obligatory responses did not differ for IDS and ADS, but for discrimination, while IDS deviants generated both a slow-positive mismatch response (MMR) as well as an adult-like MMN, the ADS deviants generated only an MMR. The presence of a mature adult-like MMN suggests that the IDS stimulus is easier to discriminate for infants.},
	Author = {Peter, Varghese and Kalashnikova, Marina and Santos, Aimee and Burnham, Denis},
	Copyright = {2016 The Author(s)},
	Doi = {10.1038/srep34273},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NFNV3X2Z/Peter et al. - 2016 - Mature neural responses to Infant-Directed Speech .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/3MS65ZU9/srep34273.html:text/html},
	Issn = {2045-2322},
	Journal = {Scientific Reports},
	Language = {en},
	Month = sep,
	Note = {Number: 1 Publisher: Nature Publishing Group},
	Number = {1},
	Pages = {1--14},
	Title = {Mature neural responses to {Infant}-{Directed} {Speech} but not {Adult}-{Directed} {Speech} in {Pre}-{Verbal} {Infants}},
	Url = {https://www.nature.com/articles/srep34273},
	Urldate = {2020-03-17},
	Volume = {6},
	Year = {2016},
	Bdsk-Url-1 = {https://www.nature.com/articles/srep34273},
	Bdsk-Url-2 = {https://doi.org/10.1038/srep34273}}

@article{ceponiene_childrens_2001,
	Abstract = {Children's long-latency auditory event-related potential (LLAEP) structure differs from that of adults. Functional significance of childhood ERP components is largely unknown. In order to look for the functional correlates in adult and children's LLAEPs, stimulus-complexity effects were investigated in 8--10-year old children. To this end, auditory ERPs to vowels, acoustically matched complex tones, and sinusoidal tones were recorded. All types of stimuli elicited P100-N250-N450 ERP complex. Differences between the sinusoidal and complex tones were confined to the P100 and N250 peaks, complex tones eliciting larger responses. Vowels elicited smaller-amplitude N250 but larger-amplitude N450 than the complex tones. Some stimulus-complexity effects observed for N250 in children corresponded to those observed for the Nl in adults, whereas the N450 peak exhibited behaviour resembling that of the adult ERP components subsequent to the Nl wave.},
	Author = {{\v C}eponien{\'e}, Rita and Shestakova, Anna and Balan, Polina and Alku, Paavo and Yiaguchi, Kiyoshi and Naatanen, Risto},
	Doi = {10.3109/00207450108986536},
	File = {Snapshot:/Users/Cecile/Zotero/storage/T44L3WVS/00207450108986536.html:text/html},
	Issn = {0020-7454},
	Journal = {International Journal of Neuroscience},
	Keywords = {Children, Event-related potentials (ERP), Long-latency auditory evoked potentials (LLAEP), N250, N450, Nl, Obligatory components, Stimulus complexity},
	Month = jan,
	Note = {Publisher: Taylor \& Francis \_eprint: https://doi.org/10.3109/00207450108986536},
	Number = {3-4},
	Pages = {245--260},
	Title = {Children's {Auditory} {Event}-{Related} {Potentials} {Index} {Sound} {Complexity} and ``{Speechness}''},
	Url = {https://doi.org/10.3109/00207450108986536},
	Urldate = {2020-03-18},
	Volume = {109},
	Year = {2001},
	Bdsk-Url-1 = {https://doi.org/10.3109/00207450108986536}}

@article{kushnerenko_maturation_2002,
	Abstract = {This study examined the maturation of cortical auditory event-related potentials (ERPs) from birth until 12 months of age. In the 15 infants studied, all ERP peaks observable at 12 months of age, the P150, N250, P350, and N450 were identifiable already at birth. As in previous studies, the amplitudes of the ERP peaks increased and latencies shortened with increasing age. In addition, the time courses of the amplitude growth of these peaks differed from each other. It was concluded, that the generators of all the infantile ERP peaks are functional already at birth, and that the maturational changes in the waveform morphology can mostly be accounted for by the changing relative strengths of the different generators.},
	Author = {Kushnerenko, Elena and Ceponiene, Rita and Balan, Polina and Fellman, Vineta and Huotilainen, Minna and N{\"a}{\"a}t{\"a}nen, Risto},
	File = {Snapshot:/Users/Cecile/Zotero/storage/7V8LF64H/Maturation_of_the_auditory_event_related.14.html:text/html},
	Issn = {0959-4965},
	Journal = {NeuroReport},
	Language = {en-US},
	Month = jan,
	Number = {1},
	Pages = {47--51},
	Title = {Maturation of the auditory event-related potentials during the first year of life},
	Url = {https://journals.lww.com/neuroreport/Abstract/2002/01210/Maturation_of_the_auditory_event_related.14.aspx},
	Urldate = {2020-03-18},
	Volume = {13},
	Year = {2002},
	Bdsk-Url-1 = {https://journals.lww.com/neuroreport/Abstract/2002/01210/Maturation_of_the_auditory_event_related.14.aspx}}

@article{konishi_role_1965,
	Author = {Konishi, Masakazu},
	Copyright = {1965 Blackwell Verlag GmbH},
	Doi = {10.1111/j.1439-0310.1965.tb01688.x},
	File = {Snapshot:/Users/Cecile/Zotero/storage/SP9GF7A7/j.1439-0310.1965.tb01688.html:text/html},
	Issn = {1439-0310},
	Journal = {Zeitschrift f{\"u}r Tierpsychologie},
	Language = {en},
	Note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1439-0310.1965.tb01688.x},
	Number = {7},
	Pages = {770--783},
	Title = {The {Role} of {Auditory} {Feedback} in the {Control} of {Vocalization} in the {White}-{Crowned} {Sparrow1}},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1965.tb01688.x},
	Urldate = {2020-03-19},
	Volume = {22},
	Year = {1965},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1965.tb01688.x},
	Bdsk-Url-2 = {https://doi.org/10.1111/j.1439-0310.1965.tb01688.x}}

@article{konishi_role_2004,
	Abstract = {Abstract: Young songbirds memorize a tutor song and use the memory trace as a template to shape their own song by auditory feedback. Major issues in birdsong research include the neural sites and mechanisms for song memory and auditory feedback. The brain song control system contains neurons with both premotor and auditory function. Yet no evidence so far shows that they respond to the bird's own song during singing. Also, no neurons have been found to respond to perturbation of auditory feedback in the brain area that is thought to be involved in the feedback control of song. The phenomenon of gating in which neurons respond to playback of the bird's own song only during sleep or under anesthesia is the sole known evidence for control of auditory input to the song system. It is, however, not known whether the gating is involved in switching between the premotor and auditory function of neurons in the song control system.},
	Author = {Konishi, Masakazu},
	Doi = {10.1196/annals.1298.010},
	File = {Snapshot:/Users/Cecile/Zotero/storage/6I7YGE7C/annals.1298.html:text/html},
	Issn = {1749-6632},
	Journal = {Annals of the New York Academy of Sciences},
	Keywords = {auditory feedback, gating, song learning, songbirds, vocal control system},
	Language = {en},
	Note = {\_eprint: https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1196/annals.1298.010},
	Number = {1},
	Pages = {463--475},
	Title = {The {Role} of {Auditory} {Feedback} in {Birdsong}},
	Url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1196/annals.1298.010},
	Urldate = {2020-03-19},
	Volume = {1016},
	Year = {2004},
	Bdsk-Url-1 = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1196/annals.1298.010},
	Bdsk-Url-2 = {https://doi.org/10.1196/annals.1298.010}}

@article{bouton_perception_2012,
	Abstract = {Purpose
      The present study investigates the perception of phonological features in French-speaking
         children with cochlear implants (CIs) compared with normal-hearing (NH) children matched
         for listening age.
      
      
      Method
      Scores for discrimination and identification of minimal pairs for all features defining
         consonants (e.g., place, voicing, manner, nasality) and vowels (e.g., frontness, nasality,
         aperture) were measured in each listener.
      
      
      Results
      The results indicated no differences in ``categorical perception,'' specified as a similar
         difference between discrimination and identification between CI children and controls.
         However, CI children demonstrated a lower level of ``categorical precision,'' that is,
         lesser accuracy in both feature identification and discrimination, than NH children,
         with the magnitude of the deficit depending on the feature.
      
      
      Conclusions
      If sensitive periods of language development extend well beyond the moment of implantation,
         the consequences of hearing deprivation for the acquisition of categorical perception
         should be fairly important in comparison to categorical precision because categorical
         precision develops more slowly than categorical perception in NH children. These results
         do not support the idea that the sensitive period for development of categorical perception
         is restricted to the first 1--2 years of life. The sensitive period may be significantly
         longer. Differences in precision may reflect the acoustic limitations of the cochlear
         implant, such as coding for temporal fine structure and frequency resolution.},
	Author = {Bouton, Sophie and Serniclaes, Willy and Bertoncini, Josiane and Col{\'e}, Pascale},
	Doi = {10.1044/1092-4388(2011/10-0330)},
	File = {Snapshot:/Users/Cecile/Zotero/storage/6RGELNW3/10-0330).html:text/html;Version soumise:/Users/Cecile/Zotero/storage/2ZVH8ZMU/Bouton Sophie et al. - 2012 - Perception of Speech Features by French-Speaking C.pdf:application/pdf},
	Journal = {Journal of Speech, Language, and Hearing Research},
	Month = feb,
	Note = {Publisher: American Speech-Language-Hearing Association},
	Number = {1},
	Pages = {139--153},
	Title = {Perception of {Speech} {Features} by {French}-{Speaking} {Children} {With} {Cochlear} {Implants}},
	Url = {https://pubs.asha.org/doi/abs/10.1044/1092-4388%282011/10-0330%29},
	Urldate = {2020-03-19},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {https://pubs.asha.org/doi/abs/10.1044/1092-4388%282011/10-0330%29},
	Bdsk-Url-2 = {https://doi.org/10.1044/1092-4388(2011/10-0330)}}

@article{lazard_understanding_2012,
	Abstract = {The cochlear implant (CI), by enabling oral communication in severely to profoundly deaf subjects, is one of the major medical advances over the last fifty years. Despite the globally very satisfactory results, individual outcomes vary considerably. The objective of this review is to describe the various factors influencing the results of CI rehabilitation with particular emphasis on the better understanding of neurocognitive mechanisms provided by functional brain imaging. The following aspects will be discussed: 1. Peripheral predictors such as the degree of preservation of nerve structures and the positioning of the electrode array. 2. The duration of auditory deprivation whose influence on brain reorganization is now becoming more clearly understood. 3. The age of initiation of hearing rehabilitation in subjects with pre-lingual deafness influencing the possibility of physiological maturation of nerve structures. 4. The concepts of sensitive period, decoupling and cross-modality. 5. In post-lingually deaf adults, brain plasticity can allow adaptation to the disability induced by deafness, subsequently potentiating CI rehabilitation, particularly as a result of audiovisual interactions. 6. Several studies provide concordant evidence that implanted patients present different phonological analysis and primary linguistic capacities. The results of CI rehabilitation are dependent on factors situated between the cochlea and cortical associative areas. The importance of higher cognitive influences on the functional results of cochlear implantation justify adaptation of coding strategies, as well as global cognitive management of deaf patients by utilising brain plasticity capacities.},
	Author = {Lazard, D. S. and Giraud, A. -L. and Gnansia, D. and Meyer, B. and Sterkers, O.},
	Doi = {10.1016/j.anorl.2011.06.001},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KDJ5ZZ2X/Lazard et al. - 2012 - Understanding the deafened brain Implications for.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/55UXGB3M/S1879729611001001.html:text/html},
	Issn = {1879-7296},
	Journal = {European Annals of Otorhinolaryngology, Head and Neck Diseases},
	Keywords = {Plasticity, Functional MRI, Maturation, Phonology, Predictor, Cross-modality, Performance, PET, Pre/post-lingual, Rehabilitation},
	Language = {en},
	Month = apr,
	Number = {2},
	Pages = {98--103},
	Shorttitle = {Understanding the deafened brain},
	Title = {Understanding the deafened brain: {Implications} for cochlear implant rehabilitation},
	Url = {http://www.sciencedirect.com/science/article/pii/S1879729611001001},
	Urldate = {2020-03-19},
	Volume = {129},
	Year = {2012},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1879729611001001},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.anorl.2011.06.001}}

@article{geary_contiguity_1954,
	Author = {Geary, R. C.},
	Doi = {10.2307/2986645},
	Issn = {1466-9404},
	Journal = {The Incorporated Statistician},
	Note = {Publisher: [Royal Statistical Society, Wiley]},
	Number = {3},
	Pages = {115--146},
	Title = {The {Contiguity} {Ratio} and {Statistical} {Mapping}},
	Url = {https://www.jstor.org/stable/2986645},
	Urldate = {2020-03-19},
	Volume = {5},
	Year = {1954},
	Bdsk-Url-1 = {https://www.jstor.org/stable/2986645},
	Bdsk-Url-2 = {https://doi.org/10.2307/2986645}}

@article{schumacher_anesthetic_2011,
	Abstract = {The majority of sensory physiology experiments have used anesthesia to facilitate the recording of neural activity. Current techniques allow researchers to study sensory function in the context of varying behavioral states. To reconcile results across multiple behavioral and anesthetic states, it is important to consider how and to what extent anesthesia plays a role in shaping neural response properties. The role of anesthesia has been the subject of much debate, but the extent to which sensory coding properties are altered by anesthesia has yet to be fully defined. In this study we asked how urethane, an anesthetic commonly used for avian and mammalian sensory physiology, affects the coding of complex communication vocalizations (songs) and simple artificial stimuli in the songbird auditory midbrain. We measured spontaneous and song-driven spike rates, spectrotemporal receptive fields, and neural discriminability from responses to songs in single auditory midbrain neurons. In the same neurons, we recorded responses to pure tone stimuli ranging in frequency and intensity. Finally, we assessed the effect of urethane on population-level representations of birdsong. Results showed that intrinsic neural excitability is significantly depressed by urethane but that spectral tuning, single neuron discriminability, and population representations of song do not differ significantly between unanesthetized and anesthetized animals.},
	Author = {Schumacher, Joseph W. and Schneider, David M. and Woolley, Sarah M. N.},
	Doi = {10.1152/jn.01072.2010},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NBYYEM6F/Schumacher et al. - 2011 - Anesthetic state modulates excitability but not sp.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/QBF3BSJ7/jn.01072.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = may,
	Note = {Publisher: American Physiological Society},
	Number = {2},
	Pages = {500--514},
	Title = {Anesthetic state modulates excitability but not spectral tuning or neural discrimination in single auditory midbrain neurons},
	Url = {https://journals.physiology.org/doi/full/10.1152/jn.01072.2010},
	Urldate = {2020-03-19},
	Volume = {106},
	Year = {2011},
	Bdsk-Url-1 = {https://journals.physiology.org/doi/full/10.1152/jn.01072.2010},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.01072.2010}}

@article{issard_infants_nodate,
	Abstract = {The human auditory system is amazingly e cient at processing speech, with a preference for this type of sound reported by full term birth. Numerous studies have investigated this preference at a variety of ages, and with a large variety of sounds contrasted to speech, from monkey calls to white noise. Many of these contrasts confound familiar, natural, and/or vocal sounds, inviting a meta-analytic investigation in which these three conceptually distinct explanations (preference for familiar, natural, or vocal sounds) are statistically tested. Moreover, when reviewed qualitatively, previous experimental work suggested that infants' preference for speech would initially encompass a broad range of natural or vocal sounds, and then tune in to species-specific vocalizations, namely speech. A meta-analytic framework allows us to check whether this explanation holds for the entire body of literature. We therefore synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a medium e ect size, with infants preferring speech over other sounds. This preference was not significantly moderated by familiarity with the language of the speech sound, vocal quality, or naturalness of the competitor. We found no e ect of age: infants showed the same strength of preference throughout the first year of life. Speech therefore appears to be preferred from birth, even to other natural or vocal sounds. These results contradict current views of the literature, and call for further investigation of the phenomenon, especially in older infants.},
	Author = {Issard, C{\'e}cile and Tsuji, Sho and Cristia, Alejandrina},
	Copyright = {Licence Creative Commons Attribution - Pas d'utilisation commerciale - Pas de modification 4.0 International (CC-BY-NC-ND)},
	File = {Issard et al. - Infants' preference for speech decomposed Meta-an.pdf:/Users/Cecile/Zotero/storage/N6BWNWKD/Issard et al. - Infants' preference for speech decomposed Meta-an.pdf:application/pdf},
	Language = {en},
	Pages = {35},
	Title = {Infants' preference for speech decomposed: {Meta}-analytic evidence}}

@article{taylor_faces_2004,
	Author = {Taylor, M. J. and Batty, M. and Itier, R. J.},
	Doi = {10.1162/0898929042304732},
	File = {Taylor et al. - 2004 - The Faces of Development A Review of Early Face P.pdf:/Users/Cecile/Zotero/storage/C3P32JEJ/Taylor et al. - 2004 - The Faces of Development A Review of Early Face P.pdf:application/pdf},
	Issn = {0898-929X, 1530-8898},
	Journal = {Journal of Cognitive Neuroscience},
	Keywords = {face perception, meta-analysis, Children},
	Language = {en},
	Month = oct,
	Number = {8},
	Pages = {1426--1442},
	Shorttitle = {The {Faces} of {Development}},
	Title = {The {Faces} of {Development}: {A} {Review} of {Early} {Face} {Processing} over {Childhood}},
	Url = {http://www.mitpressjournals.org/doi/10.1162/0898929042304732},
	Urldate = {2020-03-24},
	Volume = {16},
	Year = {2004},
	Bdsk-Url-1 = {http://www.mitpressjournals.org/doi/10.1162/0898929042304732},
	Bdsk-Url-2 = {https://doi.org/10.1162/0898929042304732}}

@article{lakatos_new_2019,
	Abstract = {Rhythms are a fundamental and defining feature of neuronal activity in animals including humans. This rhythmic brain activity interacts in complex ways with rhythms in the internal and external environment through the phenomenon of `neuronal entrainment', which is attracting increasing attention due to its suggested role in a multitude of sensory and cognitive processes. Some senses, such as touch and vision, sample the environment rhythmically, while others, like audition, are faced with mostly rhythmic inputs. Entrainment couples rhythmic brain activity to external and internal rhythmic events, serving fine-grained routing and modulation of external and internal signals across multiple spatial and temporal hierarchies. This interaction between a brain and its environment can be experimentally investigated and even modified by rhythmic sensory stimuli or invasive and non-invasive neuromodulation techniques. We provide a comprehensive overview of the topic and propose a theoretical framework of how neuronal entrainment dynamically structures information from incoming neuronal, bodily and environmental sources. We discuss the different types of neuronal entrainment, the conceptual advances in the field, and converging evidence for general principles.},
	Author = {Lakatos, Peter and Gross, Joachim and Thut, Gregor},
	Doi = {10.1016/j.cub.2019.07.075},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/MHZ3ENTU/Lakatos et al. - 2019 - A New Unifying Account of the Roles of Neuronal En.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/F5MUI46K/S0960982219309558.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Language = {en},
	Month = sep,
	Number = {18},
	Pages = {R890--R905},
	Title = {A {New} {Unifying} {Account} of the {Roles} of {Neuronal} {Entrainment}},
	Url = {http://www.sciencedirect.com/science/article/pii/S0960982219309558},
	Urldate = {2020-03-26},
	Volume = {29},
	Year = {2019},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0960982219309558},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2019.07.075}}

@article{kuefner_early_2010,
	Abstract = {Whether the development of face recognition abilities truly reflects changes in how faces, specifically, are perceived, or rather can be attributed to more general perceptual or cognitive development is debated. Event-related potential (ERP) recordings on the scalp offer promise for this issue because they allow brain responses to complex visual stimuli to be relatively well isolated from other sensory, cognitive and motor processes. ERP studies in 5-16 year-old children report large age-related changes in amplitude, latency (decreases) and topographical distribution of the early visual components, the P1 and the occipito-temporal N170. To test the face specificity of these effects, we recorded high-density ERPs to pictures of faces, cars, and their phase-scrambled versions from 72 children between the ages of 4 and 17, and a group of adults. We found that none of the previously reported age-dependent changes in amplitude, latency or topography of the P1 or N170 were specific to faces. Most importantly, when we controlled for age-related variations of the P1, the N170 appeared remarkably similar in amplitude and topography across development, with much smaller age-related decreases in latencies than previously reported. At all ages the N170 showed equivalent face-sensitivity: it had the same topography and right hemisphere dominance, it was absent for meaningless (scrambled) stimuli, and larger and earlier for faces than cars. The data also illustrate the large amount of inter-individual and inter-trial variance in young children\&rsquo;s data, which causes the N170 to merge with a later component, the N250 in grand-averaged data. Based on our observations, we suggest that the previously reported \&ldquo;bi-fid\&rdquo; N170 of young children is in fact the N250. Overall, our data indicate that the electrophysiological markers of face-sensitive perceptual processes are present from 4 years of age and do not appear to change throughout development.},
	Author = {Kuefner, Dana and De Heering, Adelaide and Jacques, Corentin and Palmero-Soler, Ernesto and Rossion, Bruno},
	Doi = {10.3389/neuro.09.067.2009},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/DEF9MI2Z/Kuefner et al. - 2010 - Early visually evoked electrophysiological respons.pdf:application/pdf},
	Issn = {1662-5161},
	Journal = {Frontiers in Human Neuroscience},
	Keywords = {development, N170, face recognition, ERP},
	Language = {English},
	Note = {Publisher: Frontiers},
	Title = {Early visually evoked electrophysiological responses over the human brain ({P1}, {N170}) show stable patterns of face-sensitivity from 4 years to adulthood},
	Url = {https://www.frontiersin.org/articles/10.3389/neuro.09.067.2009/full#h2},
	Urldate = {2020-03-26},
	Volume = {3},
	Year = {2010},
	Bdsk-Url-1 = {https://www.frontiersin.org/articles/10.3389/neuro.09.067.2009/full#h2},
	Bdsk-Url-2 = {https://doi.org/10.3389/neuro.09.067.2009}}

@article{so_auditory_2020,
	Abstract = {Vocal communication relies on the ability of listeners to identify, process, and respond to vocal sounds produced by others in complex environments. To accurately recognize these signals, animals' auditory systems must robustly represent acoustic features that distinguish vocal sounds from other environmental sounds. Vocalizations typically have spectral structure; power regularly fluctuates along the frequency axis, creating spectral contrast. Spectral contrast is closely related to harmonicity, which refers to spectral power peaks occurring at integer multiples of a fundamental frequency. Although both spectral contrast and harmonicity typify natural sounds, they may differ in salience for communication behavior and engage distinct neural mechanisms. Therefore, it is important to understand which of these properties of vocal sounds underlie the neural processing and perception of vocalizations.
Here, we test the importance of vocalization-typical spectral features in behavioral recognition and neural processing of vocal sounds, using male zebra finches. We show that behavioral responses to natural and synthesized vocalizations rely on the presence of discrete frequency components, but not on harmonic ratios between frequencies. We identify a specific population of neurons in primary auditory cortex that are sensitive to the spectral resolution of vocal sounds. We find that behavioral and neural response selectivity is explained by sensitivity to spectral contrast rather than harmonicity. This selectivity emerges within the cortex; it is absent in the thalamorecipient region and present in the deep output region. Further, deep-region neurons that are contrast-sensitive show distinct temporal responses and selectivity for modulation density compared with unselective neurons.
SIGNIFICANCE STATEMENT Auditory coding and perception are critical for vocal communication. Auditory neurons must encode acoustic features that distinguish vocalizations from other sounds in the environment and generate percepts that direct behavior. The acoustic features that drive neural and behavioral selectivity for vocal sounds are unknown, however. Here, we show that vocal response behavior scales with stimulus spectral contrast but not with harmonicity, in songbirds. We identify a distinct population of auditory cortex neurons in which response selectivity parallels behavioral selectivity. This neural response selectivity is explained by sensitivity to spectral contrast rather than to harmonicity. Our findings inform the understanding of how the auditory system encodes socially-relevant signals via detection of an acoustic feature that is ubiquitous in vocalizations.},
	Author = {So, Nina L. T. and Edwards, Jacob A. and Woolley, Sarah M. N.},
	Copyright = {Copyright {\copyright} 2020 the authors},
	Doi = {10.1523/JNEUROSCI.1200-19.2019},
	File = {Snapshot:/Users/Cecile/Zotero/storage/JRMTVXJV/1015.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {auditory cortex, vocalizations, songbirds, harmonic sounds, perception, social communication},
	Language = {en},
	Month = jan,
	Note = {Publisher: Society for Neuroscience Section: Research Articles},
	Number = {5},
	Pages = {1015--1027},
	Pmid = {31826944},
	Title = {Auditory {Selectivity} for {Spectral} {Contrast} in {Cortical} {Neurons} and {Behavior}},
	Url = {https://www.jneurosci.org/content/40/5/1015},
	Urldate = {2020-03-31},
	Volume = {40},
	Year = {2020},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/40/5/1015},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.1200-19.2019}}

@article{bauer_synaptic_2008,
	Abstract = {Songbirds learn to sing by memorizing a tutor song that they then vocally mimic using auditory feedback. This developmental sequence suggests that brain areas that encode auditory memories communicate with brain areas for learned vocal control. In the songbird, the secondary auditory telencephalic region caudal mesopallium (CM) contains neurons that encode aspects of auditory experience. We investigated whether CM is an important source of auditory input to two sensorimotor structures implicated in singing, the telencephalic song nucleus interface (NIf) and HVC. We used reversible inactivation methods to show that activity in CM is necessary for much of the auditory-evoked activity that can be detected in NIf and HVC of anesthetized adult male zebra finches. Furthermore, extracellular and intracellular recordings along with spike-triggered averaging methods indicate that auditory selectivity for the bird's own song is enhanced between CM and NIf. We used lentiviral-mediated tracing methods to confirm that CM neurons directly innervate NIf. To our surprise, these tracing studies also revealed a direct projection from CM to HVC. We combined irreversible lesions of NIf with reversible inactivation of CM to establish that CM supplies a direct source of auditory drive to HVC. Finally, using chronic recording methods, we found that CM neurons are active in response to song playback and during singing, indicating their potential importance to song perception and processing of auditory feedback. These results establish the functional synaptic linkage between sites of auditory and vocal learning and may identify an important substrate for learned vocal communication.},
	Author = {Bauer, Eric E. and Coleman, Melissa J. and Roberts, Todd F. and Roy, Arani and Prather, Jonathan F. and Mooney, Richard},
	Copyright = {Copyright {\copyright} 2008 Society for Neuroscience 0270-6474/08/281509-14\$15.00/0},
	Doi = {10.1523/JNEUROSCI.3838-07.2008},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/WRYXYPE3/Bauer et al. - 2008 - A Synaptic Basis for Auditory--Vocal Integration in.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZV6VZCEN/1509.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Keywords = {auditory, zebra finch, song, HVC, CM, learning, vocal},
	Language = {en},
	Month = feb,
	Note = {Publisher: Society for Neuroscience Section: Articles},
	Number = {6},
	Pages = {1509--1522},
	Pmid = {18256272},
	Title = {A {Synaptic} {Basis} for {Auditory}--{Vocal} {Integration} in the {Songbird}},
	Url = {https://www.jneurosci.org/content/28/6/1509},
	Urldate = {2020-03-31},
	Volume = {28},
	Year = {2008},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/28/6/1509},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.3838-07.2008}}

@article{shaevitz_functional_2007,
	Abstract = {A key discovery that has emerged from studies of the vocal system in songbirds is that neurons in these regions respond preferentially to playback of the bird's own song (BOS). This BOS selectivity is not a general property of neurons in primary and secondary auditory forebrain regions, field L and caudolateral mesopallium (CLM). Moreover, anatomical studies have been unable to conclusively define a direct projection from field L and/or CLM to HVC, a central structure for integrating sensory and motor information in the vocal system. To examine the communication between these regions, we used simultaneous dual-electrode recording in anesthetized male zebra finches and cross-correlation analysis to estimate the functional connectivity between auditory areas, field L and CLM, and HVC. We found that â¥18\% of neurons in field L and 33\% of neurons in CLM are functionally connected to HVC, most with auditory forebrain leading-HVC latencies ranging from 0.5 to 15 ms. These results indicate that field L and CLM communicate extensively with HVC through both direct and indirect anatomical connections. To further explore the role of the auditory forebrain cells that are functionally connected with HVC, we assessed their responsiveness and selectivity for a variety of natural and synthetic auditory stimuli. We found that field L and CLM neurons that are functionally connected to HVC exhibit generic auditory forebrain properties including the lack of BOS selectivity. This finding puts further constraints on the neural architecture and the nature of the nonlinearity that leads to BOS-selective auditory responses in the vocal control nuclei.},
	Author = {Shaevitz, Sarita S. and Theunissen, Fr{\'e}d{\'e}ric E.},
	Doi = {10.1152/jn.00294.2007},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/LG8DYC9K/Shaevitz et Theunissen - 2007 - Functional Connectivity Between Auditory Areas Fie.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Q24335CE/jn.00294.html:text/html},
	Issn = {0022-3077},
	Journal = {Journal of Neurophysiology},
	Month = nov,
	Note = {Publisher: American Physiological Society},
	Number = {5},
	Pages = {2747--2764},
	Title = {Functional {Connectivity} {Between} {Auditory} {Areas} {Field} {L} and {CLM} and {Song} {System} {Nucleus} {HVC} in {Anesthetized} {Zebra} {Finches}},
	Url = {https://journals.physiology.org/doi/full/10.1152/jn.00294.2007},
	Urldate = {2020-03-31},
	Volume = {98},
	Year = {2007},
	Bdsk-Url-1 = {https://journals.physiology.org/doi/full/10.1152/jn.00294.2007},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00294.2007}}

@article{bolhuis_neural_2006,
	Abstract = {Birdsong learning in avian species has strong similarities with speech acquisition in human infants. Recent research on the song system has shed fresh light on the neural substrate of song memory and sensorimotor learning in both male and female songbirds.},
	Author = {Bolhuis, Johan J. and Gahr, Manfred},
	Copyright = {2006 Nature Publishing Group},
	Doi = {10.1038/nrn1904},
	File = {Snapshot:/Users/Cecile/Zotero/storage/XYK6XVWA/nrn1904.html:text/html},
	Issn = {1471-0048},
	Journal = {Nature Reviews Neuroscience},
	Language = {en},
	Month = may,
	Note = {Number: 5 Publisher: Nature Publishing Group},
	Number = {5},
	Pages = {347--357},
	Title = {Neural mechanisms of birdsong memory},
	Url = {https://www.nature.com/articles/nrn1904},
	Urldate = {2020-04-01},
	Volume = {7},
	Year = {2006},
	Bdsk-Url-1 = {https://www.nature.com/articles/nrn1904},
	Bdsk-Url-2 = {https://doi.org/10.1038/nrn1904}}

@article{deshpande_rapid_2014,
	Abstract = {As in human infant speech development, vocal imitation in songbirds involves sensory acquisition and memorization of adult-produced vocal signals, followed by a protracted phase of vocal motor practice. The internal model of adult tutor song in the juvenile male brain, termed `the template', is central to the vocal imitation process. However, even the most fundamental aspects of the template, such as when, where and how it is encoded in the brain, remain poorly understood. A major impediment to progress is that current studies of songbird vocal learning use protracted tutoring over days, weeks or months, complicating dissection of the template encoding process. Here, we take the key step of tightly constraining the timing of template acquisition. We show that, in the zebra finch, template encoding can be time locked to, on average, a 2 h period of juvenile life and based on just 75 s of cumulative tutor song exposure. Crucially, we find that vocal changes occurring on the day of training correlate with eventual imitative success. This paradigm will lead to insights on how the template is instantiated in the songbird brain, with general implications for deciphering how internal models are formed to guide learning of complex social behaviours.},
	Author = {Deshpande, Mugdha and Pirlepesov, Fakhriddin and Lints, Thierry},
	Doi = {10.1098/rspb.2013.2630},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/L2ZBBN2P/Deshpande et al. - 2014 - Rapid encoding of an internal model for imitative .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/WZIYCFKT/rspb.2013.html:text/html},
	Journal = {Proceedings of the Royal Society B: Biological Sciences},
	Month = apr,
	Note = {Publisher: Royal Society},
	Number = {1781},
	Pages = {20132630},
	Title = {Rapid encoding of an internal model for imitative learning},
	Url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2013.2630},
	Urldate = {2020-04-01},
	Volume = {281},
	Year = {2014},
	Bdsk-Url-1 = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2013.2630},
	Bdsk-Url-2 = {https://doi.org/10.1098/rspb.2013.2630}}

@article{jing_brain_2006,
	Abstract = {Maturation of auditory perceptual and discrimination process within the first two years of life is investigated in healthy infants by examining event-related potentials (ERPs). High-density EEG signals were recorded from the scalp monthly between 3 and 24 months of age. Two types of stimuli (100 vs. 100Hz for standard stimuli; 100 vs. 300Hz for deviant stimuli; occurrence rate: 85:15\%) were presented using an oddball paradigm. Latencies and amplitudes were compared across development. The results showed that latencies of P150, N250, P350, and N450 components gradually decreased with increasing age. Amplitudes of the N250 and P350 components gradually increased and reached the maximum at 9 months, and then gradually decreased with the increase of age. Mismatch negativity was not obvious at 3 months of age, but was seen at 4--5 months and became robust after 6 months. Robust late positivity was recorded at all ages. These mismatch responses were noticeable in the frontal, central, and parietal areas, and the maximal MMN amplitude distribution gradually moved from the parietal area to the frontal area across the age range. Two important periods---one around 6 months and the other around 9 months are suggested in the maturation of auditory central system. Dynamical changes in the underlying source strengths and orientations may be principal contributors to ERP morphological changes in infants within the first 24 months.},
	Author = {Jing, Hongkui and Benasich, April A.},
	Doi = {10.1016/j.braindev.2005.09.002},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/A2XPPCVP/S0387760405001932.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/XHKH3ZLZ/Jing et Benasich - 2006 - Brain responses to tonal changes in the first two .pdf:application/pdf},
	Issn = {0387-7604},
	Journal = {Brain and Development},
	Keywords = {Child, EEG, Development, Mismatch negativity, Auditory event-related potentials},
	Language = {en},
	Month = may,
	Number = {4},
	Pages = {247--256},
	Title = {Brain responses to tonal changes in the first two years of life},
	Url = {http://www.sciencedirect.com/science/article/pii/S0387760405001932},
	Urldate = {2020-04-06},
	Volume = {28},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0387760405001932},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.braindev.2005.09.002}}

@book{gunnar_developmental_1992,
	Abstract = {This volume provides an introduction to current research on the relation between brain development and the development of cognitive, linguistic, motor, and emotional behavior. At least two audiences will benefit from this book: psychologists interested in brain development, and neuroscientists interested in behavioral development. Although each chapter is content-oriented, the volume as a whole provides a well integrated summary of the latest findings from developmental behavioral neuroscience.},
	Author = {Gunnar, Megan R. and Nelson, Charles A.},
	Isbn = {978-0-8058-0977-0},
	Keywords = {Psychology / Neuropsychology},
	Language = {en},
	Note = {Google-Books-ID: 1ZBRxYtpZ\_cC},
	Publisher = {Psychology Press},
	Title = {Developmental {Behavioral} {Neuroscience}},
	Year = {1992}}

@article{xie_development_2018-1,
	Abstract = {The current study examined the relation between infant sustained attention and infant EEG oscillations. Fifty-nine infants were tested at 6 (N = 15), 8 (N = 17), 10 (N = 14), and 12 (N = 13) months. Three attention phases, stimulus orienting, sustained attention, and attention termination, were defined based on infants' heart rate changes. Frequency analysis using simultaneously recorded EEG focused on infant theta (2--6 Hz), alpha (6--9 Hz), and beta (9--14 Hz) rhythms. Cortical source analysis of EEG oscillations was conducted with realistic infant MRI models. Theta synchronization was found over fontal pole, temporal, and parietal electrodes during infant sustained attention for 10 and 12 months. Alpha desynchronization was found over frontal, central and parietal electrodes during sustained attention. This alpha effect started to emerge at 10 months and became well established by 12 months. No difference was found for the beta rhythm between different attention phases. The theta synchronization effect was localized to the orbital frontal, temporal pole, and ventral temporal areas. The alpha desynchronization effect was localized to the brain regions composing the default mode network including the posterior cingulate cortex and precuneus, medial prefrontal cortex, and inferior parietal gyrus. The alpha desynchronization effect was also localized to the pre- and post-central gyri. The present study demonstrates a connection between infant sustained attention and EEG oscillatory activities.},
	Author = {Xie, Wanze and Mallin, Brittany M. and Richards, John E.},
	Copyright = {{\copyright} 2017 John Wiley \& Sons Ltd},
	Doi = {10.1111/desc.12562},
	File = {Snapshot:/Users/Cecile/Zotero/storage/YNXJB9B4/desc.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/SQ9ZZUJG/Xie et al. - 2018 - Development of infant sustained attention and its .pdf:application/pdf},
	Issn = {1467-7687},
	Journal = {Developmental Science},
	Language = {en},
	Note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12562},
	Number = {3},
	Pages = {e12562},
	Shorttitle = {Development of infant sustained attention and its relation to {EEG} oscillations},
	Title = {Development of infant sustained attention and its relation to {EEG} oscillations: an {EEG} and cortical source analysis study},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12562},
	Urldate = {2020-04-07},
	Volume = {21},
	Year = {2018},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.12562},
	Bdsk-Url-2 = {https://doi.org/10.1111/desc.12562}}

@article{musacchia_infant_2015,
	Abstract = {Rapid auditory processing and acoustic change detection abilities play a critical role in allowing human infants to efficiently process the fine spectral and temporal changes that are characteristic of human language. These abilities lay the foundation for effective language acquisition; allowing infants to hone in on the sounds of their native language. Invasive procedures in animals and scalp-recorded potentials from human adults suggest that simultaneous, rhythmic activity (oscillations) between and within brain regions are fundamental to sensory development; determining the resolution with which incoming stimuli are parsed. At this time, little is known about oscillatory dynamics in human infant development. However, animal neurophysiology and adult EEG data provide the basis for a strong hypothesis that rapid auditory processing in infants is mediated by oscillatory synchrony in discrete frequency bands. In order to investigate this, 128-channel, high-density EEG responses of 4-month old infants to frequency change in tone pairs, presented in two rate conditions (Rapid: 70 msec ISI and Control: 300 msec ISI) were examined. To determine the frequency band and magnitude of activity, auditory evoked response averages were first co-registered with age-appropriate brain templates. Next, the principal components of the response were identified and localized using a two-dipole model of brain activity. Single-trial analysis of oscillatory power showed a robust index of frequency change processing in bursts of Theta band (3 - 8 Hz) activity in both right and left auditory cortices, with left activation more prominent in the Rapid condition. These methods have produced data that are not only some of the first reported evoked oscillations analyses in infants, but are also, importantly, the product of a well-established method of recording and analyzing clean, meticulously collected, infant EEG and ERPs. In this article, we describe our method for infant EEG net application, recording, dynamic brain response analysis, and representative results.},
	Author = {Musacchia, Gabriella and Ortiz-Mantilla, Silvia and Realpe-Bonilla, Teresa and Roesler, Cynthia P. and Benasich, April A.},
	Doi = {10.3791/52420},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/X4TCMEKR/Musacchia et al. - 2015 - Infant Auditory Processing and Event-related Brain.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/Z72HTKU2/infant-auditory-processing-and-event-related-brain-oscillations.html:text/html},
	Issn = {1940-087X},
	Journal = {JoVE (Journal of Visualized Experiments)},
	Month = jul,
	Number = {101},
	Pages = {e52420},
	Title = {Infant {Auditory} {Processing} and {Event}-related {Brain} {Oscillations}},
	Url = {https://www.jove.com/video/52420/infant-auditory-processing-and-event-related-brain-oscillations},
	Urldate = {2020-04-07},
	Year = {2015},
	Bdsk-Url-1 = {https://www.jove.com/video/52420/infant-auditory-processing-and-event-related-brain-oscillations},
	Bdsk-Url-2 = {https://doi.org/10.3791/52420}}

@article{grossmann_social_2007,
	Abstract = {Abstract.  Gamma band oscillatory brain activity was measured to examine the neural basis of 4-month-old infants' perception of eye gaze direction. Infants were},
	Author = {Grossmann, Tobias and Johnson, Mark H. and Farroni, Teresa and Csibra, Gergely},
	Doi = {10.1093/scan/nsm025},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/MAERJL4S/Grossmann et al. - 2007 - Social perception in the infant brain gamma oscil.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/RJRZDPMA/1675437.html:text/html},
	Issn = {1749-5016},
	Journal = {Social Cognitive and Affective Neuroscience},
	Language = {en},
	Month = dec,
	Note = {Publisher: Oxford Academic},
	Number = {4},
	Pages = {284--291},
	Shorttitle = {Social perception in the infant brain},
	Title = {Social perception in the infant brain: gamma oscillatory activity in response to eye gaze},
	Url = {https://academic.oup.com/scan/article/2/4/284/1675437},
	Urldate = {2020-04-07},
	Volume = {2},
	Year = {2007},
	Bdsk-Url-1 = {https://academic.oup.com/scan/article/2/4/284/1675437},
	Bdsk-Url-2 = {https://doi.org/10.1093/scan/nsm025}}

@article{kaufman_oscillatory_2005,
	Abstract = {The apparent failure of infants to understand ``object permanence'' by reaching for hidden objects is perhaps the most striking and debated phenomenon in cognitive development. Of particular interest is the extent to which infants perceive and remember objects in a similar way to that of adults. Here we report two findings that clarify infant object processing. The first is that 6-mo-old infants are sensitive to visual cues to occlusion, particularly gradual deletion. The second finding is that oscillatory electroencephalogram activity recorded over right temporal channels is involved in object maintenance. This effect occurs only after disappearance in a manner consistent with occlusion and the object's continued existence.},
	Author = {Kaufman, Jordy and Csibra, Gergely and Johnson, Mark H.},
	Copyright = {Copyright {\copyright} 2005, The National Academy of Sciences},
	Doi = {10.1073/pnas.0507626102},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7EIR6KLA/Kaufman et al. - 2005 - Oscillatory activity in the infant brain reflects .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/MGZIN6Y3/15271.html:text/html},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Keywords = {infancy, electroencephalogram, gamma oscillations, object permanence},
	Language = {en},
	Month = oct,
	Note = {Publisher: National Academy of Sciences Section: Social Sciences},
	Number = {42},
	Pages = {15271--15274},
	Pmid = {16230640},
	Title = {Oscillatory activity in the infant brain reflects object maintenance},
	Url = {https://www.pnas.org/content/102/42/15271},
	Urldate = {2020-04-07},
	Volume = {102},
	Year = {2005},
	Bdsk-Url-1 = {https://www.pnas.org/content/102/42/15271},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0507626102}}

@article{libertus_induced_2008,
	Abstract = {Behavioral studies show that infants are capable of discriminating the number of objects or events in their environment, while also suggesting that number discrimination in infancy may be ratio-dependent. However, due to limitations of the dependent measures used with infant behavioral studies, the evidence for ratio dependence falls short of the vast psychophysical datasets that have established ratio dependence, and thus, adherence to Weber's Law in adults and nonhuman animals. We addressed this issue in two experiments that presented 7-month-old infants with familiar and novel numerosities while electroencephalogram measures of their brain activity were recorded. These data provide convergent evidence that the brains of 7-month-old infants detected numerical novelty. Alpha-band and theta-band oscillations both differed for novel and familiar numerical values. Most importantly, spectral power in the alpha band over midline and right posterior scalp sites was modulated by the ratio between the familiar and novel numerosities. Our findings provide neural evidence that numerical discrimination in infancy is ratio dependent and follows Weber's Law, thus indicating continuity of these cognitive processes over development. Results are also consistent with the idea that networks in the frontal and parietal cortices support ratio-dependent number discrimination in the first year of human life, consistent with what has been reported in neuroimaging studies in adults and older children.},
	Author = {Libertus, Melissa E. and Pruitt, Laura B. and Woldorff, Marty G. and Brannon, Elizabeth M.},
	Doi = {10.1162/jocn.2008.21162},
	File = {Snapshot:/Users/Cecile/Zotero/storage/8CI7WPYH/jocn.2008.html:text/html},
	Issn = {0898-929X},
	Journal = {Journal of Cognitive Neuroscience},
	Month = nov,
	Note = {Publisher: MIT Press},
	Number = {12},
	Pages = {2398--2406},
	Title = {Induced {Alpha}-band {Oscillations} {Reflect} {Ratio}-dependent {Number} {Discrimination} in the {Infant} {Brain}},
	Url = {https://doi.org/10.1162/jocn.2008.21162},
	Urldate = {2020-04-07},
	Volume = {21},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1162/jocn.2008.21162}}

@article{fabrizi_encoding_2016,
	Abstract = {Newborn human infants display robust pain behaviour and specific cortical activity following noxious skin stimulation, but it is not known whether brain processing of nociceptive information differs in infants and adults. Imaging studies have emphasised the overlap between infant and adult brain connectome architecture, but electrophysiological analysis of infant brain nociceptive networks can provide further understanding of the functional postnatal development of pain perception. Here we hypothesise that the human infant brain encodes noxious information with different neuronal patterns compared to adults. To test this we compared EEG responses to the same time-locked noxious skin lance in infants aged 0--19 days (nâ=â18, clinically required) and adults aged 23--48 years (nâ=â21). Time-frequency analysis revealed that while some features of adult nociceptive network activity are present in infants at longer latencies, including beta-gamma oscillations, infants display a distinct, long latency, noxious evoked 18-fold energy increase in the fast delta band (2--4âHz) that is absent in adults. The differences in activity between infants and adults have a widespread topographic distribution across the brain. These data support our hypothesis and indicate important postnatal changes in the encoding of mechanical pain in the human brain.},
	Author = {Fabrizi, Lorenzo and Verriotis, Madeleine and Williams, Gemma and Lee, Amy and Meek, Judith and Olhede, Sofia and Fitzgerald, Maria},
	Copyright = {2016 The Author(s)},
	Doi = {10.1038/srep28642},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/7CAYQNMX/Fabrizi et al. - 2016 - Encoding of mechanical nociception differs in the .pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/TZT7UJZ7/srep28642.html:text/html},
	Issn = {2045-2322},
	Journal = {Scientific Reports},
	Language = {en},
	Month = jun,
	Note = {Number: 1 Publisher: Nature Publishing Group},
	Number = {1},
	Pages = {1--9},
	Title = {Encoding of mechanical nociception differs in the adult and infant brain},
	Url = {https://www.nature.com/articles/srep28642},
	Urldate = {2020-04-07},
	Volume = {6},
	Year = {2016},
	Bdsk-Url-1 = {https://www.nature.com/articles/srep28642},
	Bdsk-Url-2 = {https://doi.org/10.1038/srep28642}}

@article{saby_neural_2012,
	Abstract = {A foundational aspect of early social--emotional development is the ability to detect and respond to the actions of others who are coordinating their behavior with that of the self. Behavioral work in this area has found that infants show particular preferences for adults who are imitating them rather than adults who are carrying out noncontingent or mismatching actions. Here, we explore the neural processes related to this tendency of infants to prefer others who act like the self. Electroencephalographic (EEG) signals were recorded from 14-month-old infants while they were observing actions that either matched or mismatched the action the infant had just executed. Desynchronization of the EEG mu rhythm was greater when infants observed an action that matched their own most recently executed action. This effect was strongest immediately prior to the culmination of the goal of the observed action, which is consistent with recent ideas about the predictive nature of brain responses during action observation.},
	Author = {Saby, Joni N. and Marshall, Peter J. and Meltzoff, Andrew N.},
	Doi = {10.1080/17470919.2012.691429},
	File = {Snapshot:/Users/Cecile/Zotero/storage/RJKY4UAD/17470919.2012.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/NXTFFWKZ/Saby et al. - 2012 - Neural correlates of being imitated An EEG study .pdf:application/pdf},
	Issn = {1747-0919},
	Journal = {Social Neuroscience},
	Keywords = {EEG, Infant, Imitation, Mu rhythm, Perception--action},
	Month = nov,
	Note = {Publisher: Routledge \_eprint: https://doi.org/10.1080/17470919.2012.691429},
	Number = {6},
	Pages = {650--661},
	Pmid = {22646701},
	Shorttitle = {Neural correlates of being imitated},
	Title = {Neural correlates of being imitated: {An} {EEG} study in preverbal infants},
	Url = {https://doi.org/10.1080/17470919.2012.691429},
	Urldate = {2020-04-07},
	Volume = {7},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.1080/17470919.2012.691429}}

@article{james_learning_2017,
	Abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}Biological predispositions in vocal learning have been proposed to underlie commonalities in vocal sequences, including for speech and birdsong, but cultural propagation could also account for such commonalities [1--4]. Songbirds such as the zebra finch learn the sequencing of their acoustic elements ("syllables") during development [5--8]. Zebra finches are not constrained to learn a specific sequence of syllables, but significant consistencies in the positioning and sequencing of syllables have been observed between individuals within populations and between populations [8--10]. To reveal biological predispositions in vocal sequence learning, we individually tutored juvenile zebra finches with randomized and unbiased sequences of syllables and analyzed the extent to which birds produced common sequences. In support of biological predispositions, birds tutored with randomized sequences produced songs with striking similarities. Birds preferentially started and ended their song sequence with particular syllables, consistently positioned shorter and higher frequency syllables in the middle of their song, and sequenced their syllables such that pitch alternated across adjacent syllables. These patterns are reminiscent of those observed in normally tutored birds, suggesting that birds "creolize" aberrant sequence inputs to produce normal sequence outputs. Similar patterns were also observed for syllables that were not used for tutoring (i.e., unlearned syllables), suggesting that motor biases could contribute to sequence learning biases. Furthermore, zebra finches spontaneously produced acoustic patterns that are commonly observed in speech and music, suggesting that sensorimotor processes that are shared across a wide range of vertebrates could underlie these patterns in humans.{\textless}/p{\textgreater}},
	Author = {James, Logan S. and Sakata, Jon T.},
	Doi = {10.1016/j.cub.2017.10.019},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/53RRIG4P/James et Sakata - 2017 - Learning Biases Underlie ``Universals'' in Avian Voc.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/UP985HPU/S0960-9822(17)31322-2.html:text/html},
	Issn = {0960-9822},
	Journal = {Current Biology},
	Language = {English},
	Month = dec,
	Note = {Publisher: Elsevier},
	Number = {23},
	Pages = {3676--3682.e4},
	Pmid = {29174890},
	Title = {Learning {Biases} {Underlie} ``{Universals}'' in {Avian} {Vocal} {Sequencing}},
	Url = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31322-2},
	Urldate = {2020-04-20},
	Volume = {27},
	Year = {2017},
	Bdsk-Url-1 = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31322-2},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cub.2017.10.019}}

@article{musacchia_active_2017,
	Abstract = {Language acquisition in infants is driven by on-going neural plasticity that is acutely sensitive to environmental acoustic cues. Recent studies showed that attention-based experience with non-linguistic, temporally-modulated auditory stimuli sharpens cortical responses. A previous ERP study from this laboratory showed that interactive auditory experience via behavior-based feedback (AEx), over a 6-week period from 4- to 7-months-of-age, confers a processing advantage, compared to passive auditory exposure (PEx) or maturation alone (Na{\"\i}ve Control, NC). Here, we provide a follow-up investigation of the underlying neural oscillatory patterns in these three groups. In AEx infants, Standard stimuli with invariant frequency (STD) elicited greater Theta-band (4--6â¯Hz) activity in Right Auditory Cortex (RAC), as compared to NC infants, and Deviant stimuli with rapid frequency change (DEV) elicited larger responses in Left Auditory Cortex (LAC). PEx and NC counterparts showed less-mature bilateral patterns. AEx infants also displayed stronger Gamma (33--37â¯Hz) activity in the LAC during DEV discrimination, compared to NCs, while NC and PEx groups demonstrated bilateral activity in this band, if at all. This suggests that interactive acoustic experience with non-linguistic stimuli can promote a distinct, robust and precise cortical pattern during rapid auditory processing, perhaps reflecting mechanisms that support fine-tuning of early acoustic mapping.},
	Author = {Musacchia, Gabriella and Ortiz-Mantilla, Silvia and Choudhury, Naseem and Realpe-Bonilla, Teresa and Roesler, Cynthia and Benasich, April A.},
	Doi = {10.1016/j.dcn.2017.04.004},
	File = {ScienceDirect Full Text PDF:/Users/Cecile/Zotero/storage/KS5VMYNR/Musacchia et al. - 2017 - Active auditory experience in infancy promotes bra.pdf:application/pdf;ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XQHV2LXD/S1878929316301542.html:text/html},
	Issn = {1878-9293},
	Journal = {Developmental Cognitive Neuroscience},
	Keywords = {EEG, Plasticity, Infant, Auditory, Development, Brain oscillations},
	Language = {en},
	Month = aug,
	Pages = {9--19},
	Title = {Active auditory experience in infancy promotes brain plasticity in {Theta} and {Gamma} oscillations},
	Url = {http://www.sciencedirect.com/science/article/pii/S1878929316301542},
	Urldate = {2020-04-29},
	Volume = {26},
	Year = {2017},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1878929316301542},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.dcn.2017.04.004}}

@article{isola_manipulations_2020,
	Author = {Isola, Gaurav R. and Vochin, Anca and Sakata, Jon T.},
	Doi = {10.1152/jn.00142.2019},
	File = {Isola et al. - 2020 - Manipulations of inhibition in cortical circuitry .pdf:/Users/Cecile/Zotero/storage/3Y7QNUIV/Isola et al. - 2020 - Manipulations of inhibition in cortical circuitry .pdf:application/pdf},
	Issn = {0022-3077, 1522-1598},
	Journal = {Journal of Neurophysiology},
	Language = {en},
	Month = feb,
	Number = {2},
	Pages = {815--830},
	Title = {Manipulations of inhibition in cortical circuitry differentially affect spectral and temporal features of {Bengalese} finch song},
	Url = {https://www.physiology.org/doi/10.1152/jn.00142.2019},
	Urldate = {2020-05-05},
	Volume = {123},
	Year = {2020},
	Bdsk-Url-1 = {https://www.physiology.org/doi/10.1152/jn.00142.2019},
	Bdsk-Url-2 = {https://doi.org/10.1152/jn.00142.2019}}

@article{deoni_mapping_2011,
	Abstract = {Myelination, the elaboration of myelin surrounding neuronal axons, is essential for normal brain function. The development of the myelin sheath enables rapid synchronized communication across the neural systems responsible for higher order cognitive functioning. Despite this critical role, quantitative visualization of myelination in vivo is not possible with current neuroimaging techniques including diffusion tensor and structural magnetic resonance imaging (MRI). Although these techniques offer insight into structural maturation, they reflect several different facets of development, e.g., changes in axonal size, density, coherence, and membrane structure; lipid, protein, and macromolecule content; and water compartmentalization. Consequently, observed signal changes are ambiguous, hindering meaningful inferences between imaging findings and metrics of learning, behavior or cognition. Here we present the first quantitative study of myelination in healthy human infants, from 3 to 11 months of age. Using a new myelin-specific MRI technique, we report a spatiotemporal pattern beginning in the cerebellum, pons, and internal capsule; proceeding caudocranially from the splenium of the corpus callosum and optic radiations (at 3--4 months); to the occipital and parietal lobes (at 4--6 months); and then to the genu of the corpus callosum and frontal and temporal lobes (at 6--8 months). Our results also offer preliminary evidence of hemispheric myelination rate differences. This work represents a significant step forward in our ability to appreciate the fundamental process of myelination, and provides the first ever in vivo visualization of myelin maturation in healthy human infancy.},
	Author = {Deoni, Sean C. L. and Mercure, Evelyne and Blasi, Anna and Gasston, David and Thomson, Alex and Johnson, Mark and Williams, Steven C. R. and Murphy, Declan G. M.},
	Copyright = {Copyright {\copyright} 2011 the authors 0270-6474/11/310784-08\$15.00/0},
	Doi = {10.1523/JNEUROSCI.2106-10.2011},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/ZLTX5NE2/Deoni et al. - 2011 - Mapping Infant Brain Myelination with Magnetic Res.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/LM8C25LV/784.html:text/html},
	Issn = {0270-6474, 1529-2401},
	Journal = {Journal of Neuroscience},
	Language = {en},
	Month = jan,
	Note = {Publisher: Society for Neuroscience Section: Articles},
	Number = {2},
	Pages = {784--791},
	Pmid = {21228187},
	Title = {Mapping {Infant} {Brain} {Myelination} with {Magnetic} {Resonance} {Imaging}},
	Url = {https://www.jneurosci.org/content/31/2/784},
	Urldate = {2020-05-05},
	Volume = {31},
	Year = {2011},
	Bdsk-Url-1 = {https://www.jneurosci.org/content/31/2/784},
	Bdsk-Url-2 = {https://doi.org/10.1523/JNEUROSCI.2106-10.2011}}

@article{cheour_speech_2002,
	Abstract = {It is not yet clear whether humans are able to learn while they are sleeping1,2. Here we show that full-term human newborns can be taught to discriminate between similar vowel sounds when they are fast asleep. It is possible that such sleep training soon after birth could find application in clinical or educational situations3,4.},
	Author = {Cheour, M. and Martynova, O. and N{\"a}{\"a}t{\"a}nen, R. and Erkkola, R. and Sillanp{\"a}{\"a}, M. and Kero, P. and Raz, A. and Kaipio, M.-L. and Hiltunen, J. and Aaltonen, O. and Savela, J. and H{\"a}m{\"a}l{\"a}inen, H.},
	Copyright = {2002 Nature Publishing Group},
	Doi = {10.1038/415599b},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/34662XQ8/Cheour et al. - 2002 - Speech sounds learned by sleeping newborns.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/VQFRDIWZ/415599b.html:text/html},
	Issn = {1476-4687},
	Journal = {Nature},
	Language = {en},
	Month = feb,
	Note = {Number: 6872 Publisher: Nature Publishing Group},
	Number = {6872},
	Pages = {599--600},
	Title = {Speech sounds learned by sleeping newborns},
	Url = {https://www.nature.com/articles/415599b},
	Urldate = {2020-05-14},
	Volume = {415},
	Year = {2002},
	Bdsk-Url-1 = {https://www.nature.com/articles/415599b},
	Bdsk-Url-2 = {https://doi.org/10.1038/415599b}}

@article{chen_origins_2020,
	Abstract = {Acoustic communication is crucial to humans and many other tetrapods, including birds, frogs, crocodilians, and mammals. However, large-scale patterns in its evolution are largely unstudied. Here, we address several fundamental questions about the origins of acoustic communication in terrestrial vertebrates (tetrapods), using phylogenetic methods. We show that origins of acoustic communication are significantly associated with nocturnal activity. We find that acoustic communication does not increase diversification rates, a surprising result given the many speciation-focused studies of frog calls and bird songs. We also demonstrate that the presence of acoustic communication is strongly conserved over time. Finally, we find that acoustic communication evolved independently in most major tetrapod groups, often with remarkably ancient origins ({\textasciitilde}100--200 million years ago). Overall, we show that the role of ecology in shaping signal evolution applies to surprisingly deep timescales, whereas the role of signal evolution in diversification may not.},
	Author = {Chen, Zhuo and Wiens, John J.},
	Copyright = {2020 The Author(s)},
	Doi = {10.1038/s41467-020-14356-3},
	File = {Full Text PDF:/Users/Cecile/Zotero/storage/NEYXDBYL/Chen et Wiens - 2020 - The origins of acoustic communication in vertebrat.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/ZFTU847L/s41467-020-14356-3.html:text/html},
	Issn = {2041-1723},
	Journal = {Nature Communications},
	Language = {en},
	Month = jan,
	Note = {Number: 1 Publisher: Nature Publishing Group},
	Number = {1},
	Pages = {369},
	Title = {The origins of acoustic communication in vertebrates},
	Url = {https://www.nature.com/articles/s41467-020-14356-3},
	Urldate = {2020-05-15},
	Volume = {11},
	Year = {2020},
	Bdsk-Url-1 = {https://www.nature.com/articles/s41467-020-14356-3},
	Bdsk-Url-2 = {https://doi.org/10.1038/s41467-020-14356-3}}

@article{imada_infant_2006,
	Abstract = {Discriminative responses to tones, harmonics, and syllables in the left hemisphere were measured with magnetoencephalography in neonates, 6-month-old infants, and 12-month-old infants using the oddball paradigm. Real-time head position tracking, signal space separation, and head position standardization were applied to secure quality data for source localization. Minimum current estimates were calculated to characterize infants' cortical activities for detecting sound changes. The activation patterns observed in the superior temporal and inferior frontal regions provide initial evidence for the developmental emergence early in life of a perceptual--motor link for speech perception that may depend on experience.},
	Author = {Imada, Toshiaki and Zhang, Yang and Cheour, Marie and Taulu, Samu and Ahonen, Antti and Kuhl, Patricia K.},
	Doi = {10.1097/01.wnr.0000223387.51704.89},
	File = {Imada et al. - 2006 - Infant speech perception activates Broca's area a.pdf:/Users/Cecile/Zotero/storage/YMCTE9LG/Imada et al. - 2006 - Infant speech perception activates Broca's area a.pdf:application/pdf;Snapshot:/Users/Cecile/Zotero/storage/T5Q9U8QJ/Infant_speech_perception_activates_Broca_s_area__a.3.html:text/html},
	Issn = {0959-4965},
	Journal = {NeuroReport},
	Language = {en-US},
	Month = jul,
	Number = {10},
	Pages = {957--962},
	Shorttitle = {Infant speech perception activates {Broca}'s area},
	Title = {Infant speech perception activates {Broca}'s area: a developmental magnetoencephalography study},
	Url = {https://journals.lww.com/neuroreport/Abstract/2006/07170/Infant_speech_perception_activates_Broca_s_area__a.3.aspx},
	Urldate = {2020-05-19},
	Volume = {17},
	Year = {2006},
	Bdsk-Url-1 = {https://journals.lww.com/neuroreport/Abstract/2006/07170/Infant_speech_perception_activates_Broca_s_area__a.3.aspx},
	Bdsk-Url-2 = {https://doi.org/10.1097/01.wnr.0000223387.51704.89}}

@article{chen_magnetoencephalography_2019,
	Abstract = {Magnetoencephalography (MEG) is a non-invasive neuroimaging technique that provides whole-head measures of neural activity with millisecond temporal resolution. Over the last three decades, MEG has been used for assessing brain activity, most commonly in adults. MEG has been used less often to examine neural function during early development, in large part due to the fact that infant whole-head MEG systems have only recently been developed. In this review, an overview of infant MEG studies is provided, focusing on the period from birth to three years. The advantages of MEG for measuring neural activity in infants are highlighted (See ), including the ability to assess activity in brain (source) space rather than sensor space, thus allowing direct assessment of neural generator activity. Recent advances in MEG hardware and source analysis are also discussed. As the review indicates, efforts in this area demonstrate that MEG is a promising technology for studying the infant brain. As a noninvasive technology, with emerging hardware providing the necessary sensitivity, an expected deliverable is the capability for longitudinal infant MEG studies evaluating the developmental trajectory (maturation) of neural activity. It is expected that departures from neuro-typical trajectories will offer early detection and prognosis insights in infants and toddlers at-risk for neurodevelopmental disorders, thus paving the way for early targeted interventions.},
	Author = {Chen, Yu-Han and Saby, Joni and Kuschner, Emily and Gaetz, William and Edgar, J. Christopher and Roberts, Timothy P.L.},
	Doi = {10.1016/j.neuroimage.2019.01.059},
	File = {PubMed Central Full Text PDF:/Users/Cecile/Zotero/storage/Z28W6BRY/Chen et al. - 2019 - Magnetoencephalography and the infant brain.pdf:application/pdf},
	Issn = {1053-8119},
	Journal = {NeuroImage},
	Month = apr,
	Pages = {445--458},
	Pmcid = {PMC6662211},
	Pmid = {30685329},
	Title = {Magnetoencephalography and the infant brain},
	Url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662211/},
	Urldate = {2020-05-25},
	Volume = {189},
	Year = {2019},
	Bdsk-Url-1 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6662211/},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neuroimage.2019.01.059}}

@article{wakai_slow_2016,
	Abstract = {Objective
To investigate the slow rhythm and its relationship to spindling in early infancy. Methods
We analyzed sleep MEG recordings containing sleep spindles, taken from 7 normal, healthy subjects at conceptional age 46--63 weeks in 21 sessions.
Results
We show that the sleep MEG in early infancy contains a slow rhythm, centered at approximately 0.2Hz, which showed a striking association with spindling. The slow rhythm grouped sleep spindles, which were clock-like with a recurrence rate of approximately 0.1Hz.
Conclusions
The association of the 0.2Hz oscillation and low delta rhythms with spindling was so strong as to suggest that they may play a critical role during brain development in the genesis of sleep spindles.
Significance
Infant brain rhythms exhibit relatively simple, regular behavior, allowing the relationships between them to be more easily discerned.},
	Author = {Wakai, R. T. and Lutter, W. J.},
	Doi = {10.1016/j.neulet.2016.07.051},
	File = {ScienceDirect Snapshot:/Users/Cecile/Zotero/storage/XN3AHWE4/S0304394016305456.html:text/html;Version accept{\'e}e:/Users/Cecile/Zotero/storage/7AVN5UCN/Wakai et Lutter - 2016 - Slow rhythms and sleep spindles in early infancy.pdf:application/pdf},
	Issn = {0304-3940},
	Journal = {Neuroscience Letters},
	Keywords = {Magnetoencephalography, Sleep spindles, Slow rhythm},
	Language = {en},
	Month = sep,
	Pages = {164--168},
	Title = {Slow rhythms and sleep spindles in early infancy},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304394016305456},
	Urldate = {2020-05-27},
	Volume = {630},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304394016305456},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.neulet.2016.07.051}}

@techreport{santolin_experience_2020,
	Abstract = {Interpreting and predicting direction of preference in infant behavioral research has been a thorny issue for decades. Several factors have been proposed to account for familiarity and novelty preferences in habituation and familiarization studies, including infant age, length of exposure and task complexity. The current study explores an additional dimension that may affect direction of preference: amount of experience with the experimental task. To test this hypothesis, we re-analyzed the data from 4 experiments on artificial grammar learning in 12-month-old infants run using the Head- turn Preference Procedure (HPP). The participants in these studies varied substantially in their number of laboratory visits. Linear mixed-effects results show that the number of HPP studies in which infants had previously participated is related to infants' direction of preference: infants who had no (or limited) experience with the HPP setting were more likely to show familiarity preferences than infants who had amassed more experience with this task in prior study visits. Interestingly, the effect is driven by a significant decrease in looking time for familiar trials. These results have important implications for the interpretation of experimental results: infants' experience with a given paradigm or, more broadly, with the lab environment, may affect their patterns of preferences.},
	Author = {Santolin, Chiara and Garc{\'\i}a-Castro, Gonzalo and Zettersten, Martin and Sebastian-Galles, Nuria and Saffran, Jenny},
	Doi = {10.31234/osf.io/xgvbh},
	File = {Santolin et al. - 2020 - Experience with research paradigms relates to infa.pdf:/Users/Cecile/Zotero/storage/434G6AG7/Santolin et al. - 2020 - Experience with research paradigms relates to infa.pdf:application/pdf},
	Institution = {PsyArXiv},
	Language = {en},
	Month = mar,
	Title = {Experience with research paradigms relates to infants' direction of preference},
	Type = {preprint},
	Url = {https://osf.io/xgvbh},
	Urldate = {2020-05-29},
	Year = {2020},
	Bdsk-Url-1 = {https://osf.io/xgvbh},
	Bdsk-Url-2 = {https://doi.org/10.31234/osf.io/xgvbh}}

@article{vanden_bosch_der_nederlanden_infant_2020,
	Annote = {meta-analysis},
	Author = {Vanden Bosch der Nederlanden, Christina M. and Vouloumanos, Athena},
	Date-Modified = {2020-06-16 13:45:36 +0200},
	File = {VandenBosch.pdf:/Users/Cecile/Zotero/storage/QFYRKEES/VandenBosch.pdf:application/pdf},
	Journal = {under review},
	Title = {Infant biases for detecting speech in complex scenes},
	Year = {2020}}

@article{lewkowicz_decline_2006,
	Author = {Lewkowicz, D. J. and Ghazanfar, A. A.},
	Doi = {10.1073/pnas.0602027103},
	File = {Lewkowicz et Ghazanfar - 2006 - The decline of cross-species intersensory percepti.pdf:/Users/Cecile/Zotero/storage/L42B2CFX/Lewkowicz et Ghazanfar - 2006 - The decline of cross-species intersensory percepti.pdf:application/pdf},
	Issn = {0027-8424, 1091-6490},
	Journal = {Proceedings of the National Academy of Sciences},
	Language = {en},
	Month = apr,
	Number = {17},
	Pages = {6771--6774},
	Title = {The decline of cross-species intersensory perception in human infants},
	Url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0602027103},
	Urldate = {2020-06-11},
	Volume = {103},
	Year = {2006},
	Bdsk-Url-1 = {http://www.pnas.org/cgi/doi/10.1073/pnas.0602027103},
	Bdsk-Url-2 = {https://doi.org/10.1073/pnas.0602027103}}

@article{gottlieb_experiential_1991,
	Abstract = {C. H. Waddington's (1942) notion of canalization has been widely invoked in developmental psychology to conceptualize species-typical regularities in behavioral development as genetically determined. In contrast, a developmental systems view, such as the one described in the present article, sees the genes as only one component in a hierarchy of influences, all of which contribute to canalize behavioral development. A key issue is that genetic activity does not by itself produce finished traits; differentiation occurs as a consequence of events above as well as below the cellular level, necessarily involving factors in addition to genetic influences to canalize behavioral development. In exploring the possible experiential canalization of development, it was found that the mallard duck embryo's contact call plays a canalizing role in species-specific perceptual development (G. Gottlieb; see record 1991-11868-001). Thus, normally occurring experience, in concert with genetic and other activities, can canalize behavioral development. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	Author = {Gottlieb, Gilbert},
	Doi = {10.1037/0012-1649.27.1.4},
	File = {Snapshot:/Users/Cecile/Zotero/storage/DRNE52I5/1991-11900-001.html:text/html;Texte int{\'e}gral:/Users/Cecile/Zotero/storage/6WVU495N/Gottlieb - 1991 - Experiential canalization of behavioral developmen.pdf:application/pdf},
	Issn = {1939-0599(Electronic),0012-1649(Print)},
	Journal = {Developmental Psychology},
	Keywords = {Animal Development, Behavior, Ducks, Genetics, Species Differences, Systems Theory, Theories},
	Note = {Place: US Publisher: American Psychological Association},
	Number = {1},
	Pages = {4--13},
	Shorttitle = {Experiential canalization of behavioral development},
	Title = {Experiential canalization of behavioral development: {Theory}},
	Volume = {27},
	Year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.1037/0012-1649.27.1.4}}
