---
title: "Infants prefer to listen to speech: A meta-analysis."
author: "Cécile Issard, Sho Tsuji and Alejandrina Cristia"
date: "`r format(Sys.time(), '%d %m, %Y')`"
output: pdf_document
#bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = FALSE, echo = FALSE) #options for all the code chunks of the document.

source("compute_es.R", chdir = TRUE)  #chdir stands for "change directory"

library(metafor)
library(robumeta)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(grid)
library(gridExtra)
library(RCurl)
library(papaja)

sessionInfo()


read.csv('speech_pref_full_DB.csv')->DB

#unique studies
papers <- levels(factor(DB$short_cite))

#number of unique infants
DB$n<-rowSums( cbind (DB$n_1,DB$n_2), na.rm=TRUE)
temp<-aggregate(n~same_infant,DB,mean)

summary(DB$mean_age_1)
```
- Target journal: Developmental science
- Article type: short report
- 4000 words
- 6 keywords
- Running title: 40 characters
- Submit one normal and one blinded version
- Separate files for title page, main text, and figures
- No identifiying info in the main text.
- up to 4 research highlights; each 25 words
- Abstract: 250 words

Main text file:

1. Title 
2. Research highlights
3. Abstract and key words
4. Main 
5. References
6. Figures and tables (each clearly identified, labelled and on a separate page)
7. Appendices (if relevant).

# Abstract

The human auditory system is amazingly efficient at processing speech. This capacity would be present from birth, infants preferring to listen to natural speech than to other types of sounds, enabling them to select the signals that are relevant for communication with homospecifics. However, a large variety of sounds have been contrasted to speech, with infants of very different ages. Drawing a global picture of how this capacity emerges is therefore difficult. We synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a strong effect size, infants prefering speech over any other type of sound. However, contrary to the results of individual studies, we found no effect of age: infants showed the same amount of preference from birth to one year of age. Preference was stronger when speech was contrasted to artificial sounds, and when the speech stimuli were in the infants' native language. This suggests that the representation of speech as a distinct auditory object emerges from a broader category of natural sounds, modulated by the degree of familiarity with the sound.

# Introduction

Speech is probably the most important sound class for humans. It is the main signal for vocal communication, and as such it is crucial that individuals detect this sound in the environment to spot a homospecific and build social interactions. Readily from birth, humans would be equipped with a capacity to recognize speech sounds, to process them with dedicated auditory and cognitive mechanisms. At birth, infants discriminate speech from complex tones (Dehaene-Lambertz, 2000), and sine-wave speech (SWS) (Vouloumanos & Werker, 2007). Extending to language acquisition, the naturalness of sound stimuli (i.e. using synthetic vs. natural speech) is a key factor for infants to segment words (Black & Bergman, 2016). This highlights the importance of recognizing natural speech sounds in the auditory environment to trigger the relevant cognitive processes for this stimulus, including for language acquisition. Discriminating speech from other sounds, and preferring it over other types of sound, may be a necessary condition to learn language. Here we synthesize empirical data on infants’ preferences for speech over artificial sounds, natural sounds, as well as human and social non-speech sounds.

A key question is whether speech is preferred per se, or because it belongs to a broader category of natural or own-species sounds. 
Studies from the auditory neuroscience literature have provided evidence that natural sounds are processed preferentially by the auditory system, from the cochlea (Lewicki, 2006) to the auditory cortex (e.g. Gehr et al., 2000) (see Mizrahi et al., 2014 for a review). Consistently, infants have been shown to discriminate between speech and various types of artificial sounds from birth, from white-noise (Colombo, 1981) to sine-wave speech (Vouloumanos et al., 2007), low-pass filtered speech (Cooper, 1994), and backward speech (Peña, 2003; May et al, 2011, 2018). This preference is maintained to the end of the first year of life (Curtin, 2013; Vouloumanos, 2014). The infant auditory system would thus detect general acoustical properties that differentiate artificial from natural sounds, among them speech. 
However, studies contrasting speech to other natural sounds have nuanced this view. Newborns made more head-turns to speech than to heartbeat (Ecklund-Flores & Turkewitz, 1996), but listened equivalently to speech and monkey calls (Vouloumanos & Werker, 2010). Infants younger than 3 months have been shown to not discriminate between speech and monkey calls, whereas infants from 3 months of age do (Vouloumanos et al., 2004). It is thus possible that infants rely on a more specific category for vocal sounds, that includes our closest genealogical cousins (i.e. primates), whose vocalizations may share some important acoustical properties with speech. 
In an fMRI study, the activity of the temporal cortex in response to biological non-speech sounds (such as human non-speech vocalizations or rhesus calls) decreased with age between 1 and 4 months-old. The response to speech didn't increase during the same developmental window (Shultz et al. 2014), suggesting that the capacity to discriminate speech from other sounds comes from a narrowing of the perceptual category to speech rather than a more in-depth processing.
Infants therefore appear to discriminate vocal from other natural sounds from the beginning of their life, and later to discriminate and preferentially process speech specifically as they get older.

But is it really an effect of age, or does preference come from familiarity with specific sounds that infants frequently encounter in their environment? Larger hemodynamic responses were observed in the newborn brain for forward as compared to backward speech when the native language was used for the speech stimuli, but not when a foreign language was used (Sato et al., 2012; May et al., 2018). In 4 month-old infants, speech produced similar activation patterns for speech and non-speech vocal sounds, with a larger difference when the speech stimuli were in the native language of the participants (as compared to when speech was in a foreign language) (Minagawa-Kawai et al., 2011). This suggests that infants use their knowledge of the language they are familiar to to discriminate speech from other sounds.
Furthermore, 9 month-old infants listen longer to monkey calls than their native language (Sorcinelli, 2019), possibly because at this age they are already attuned to the sounds of their native language and transfer their attention to the more demanding sound in the paradigm.

Finally, it is possible that the infants’ auditory system preferentially process vocal sounds, and later speech, because they share a complex acoustical structure. Indeed, studies comparing speech to music often found a lack of preferential processing. At two months, the temporal cortex showed the same amount of repetition suppression for speech and music (Dehaene-Lambertz et al., 2010). Interestingly, this lack of discrimination persists even after infants discriminate speech from other complex vocal sounds: at five months, infants detected speech or music equivalently well in an auditory scene (anonymous, 2019). It is therefore possible that the developing auditory system is attuned to complex specific parameters shared by music and speech, but not in other animal vocalizations. 

The complex developmental pattern that we describe above is even more difficult to understand that controversies exist in the literature.
When speech was compared to other human sounds, two different laboratories found different patterns: In the first case, speech triggered larger BOLD responses and looking times than other human sounds, both communicative (e.g. laugh or agreement) and non-communicative (e.g. yawns or coughs) in 1 to 4 month-old infants (Shultz et al., 2014, Shultz & Vouloumanos, 2010). In the second case, the opposite pattern was observed: human communicative and non-communicative sounds evoked larger responses than speech in a similar region at 3 months. No difference between the three types of sounds was observed in the same infants at 6 months (MacDonald et al., 2019). 
Moreover, even studies that found consistent results contrasted speech to a large variety of sounds, from white noise to filtered speech, and at different ages. Getting a precise overview of this capacity is therefore difficult. 
This points to the importance of synthesizing the available data is a systematic way.

All of these results have been observed on small groups of infants, with a large variety of age and stimuli across groups. Individual studies can only test a few infants on very specific stimuli due to experimental constraints (Oakes, 2017; Bergmann et al., 2017; Sugden & Moulson, 2015). On the opposite, meta-analysis are a way of achieving power without running new studies. They gather data from significantly more infants than individual studies, which significantly increases statistical power. By merging a lot of different studies, they allow researcher to state support (or not) for some results with controversy, and provide statistical evidence of how much we can trust the results. If an effect emerges, it’s more likely to be a reproducible one that different labs can find.
Finally, meta-analysis offer tools to detect publication bias in the literature, providing even more evidence to support or not the results (i.e. significant effects being less trustworthy if they emerge from a biased literature). 
However, meta-analysis have the disadvantage of mixing studies with different experimental designs together, therefore having less control on the effect measured. They merge results focusing on common factors between studies, potentially missing subtle effects. But moderators analyses allow to explain the heterogeneity between study. In individual studies, addressing questions such as differences across stimuli and age groups types would require large power. Meta-analysis allow to draw a developmental timeline across the age range covered by the literature, and test how the different factors discussed by different individual studies interact. 
For all of these reasons, we conducted a meta-analysis to test if infants’ reliably have a preference for speech sounds over other types of sounds, and if yes, if different types of sound modulated this preference, and how it developed over the first year of life. 


# Methods
## Literature search
We followed PRISMA (Moher et al., 2009).
The information sources used to compose the initial list included suggestions by experts (authors of this work); two google scholar searches (“ ("speech preference" OR "own-species vocalization" ) AND infant”, and “("speech preference" OR "own-species vocalization" ) AND infant”) complemented with the same searches in PubMed and PsycInfo; and a google alert, as well as reference lists of the full papers inspected.
After a first screening based on titles and abstracts, we ran a second round of screening based on full paper reading. 

## Inclusion criteria
We included studies that tested human infants from birth to 1 year (0-365 days) of age, and contrasted speech sounds with any other type of sound, measuring either behavioral (e.g. looking times) or neurophysiological responses to the sounds. We excluded studies that contrasted foreign to native language, didn’t present natural speech sounds, presented speech recorded with the mother’s voice, or intentionally mixed speech with other vocal sounds within the same sound condition. We included published (e.i. journal articles) as well as unpublished works (e.i. doctoral dissertations). A PRISMA flow chart summarizes the literature review and selection process (Figure 1). We documented all the studies that we inspected in a decision spreadsheet (supplementary materials).

[Insert Figure 1 here]

Data were coded by the first author. 20% of the papers were selected to be coded by the second author independently, with disagreements resolved by discussion. There were **XX** disagreements out of a total of **YY** fields filled in, so that the total agreement rate was **ZZ**%. For effect sizes, we coded the mean score and the standard deviation for each sound condition. When individual data was provided, we recomputed the respective mean scores and standard deviations based on the reported individual scores. When they were reported, we coded the t-statistic between the two sound conditions or the F-statistic. If a Cohen’s d oran Hedge’s g effect size was directly reported we also coded this. The full list of the variables coded is available in the supplementary material.

**Risk assessment at the level of papers was done by ... Risk assessment for the whole body of literature ...**

## Statistical analysis

### Individual effect sizes

Once the data were coded, we computed individual effect sizes that were not directly reported in the papers, along with their respective variance. We adjusted the formula according to the experimental design of the respective paper (Lipsey \& Wilson, 2001). When the coded study used a within-participant design with two measurements (e.g. looking time during speech and during monkey calls), we computed effect size using t-statistic (Dunlap et al., 1996). If this statistic was not reported, we computed effect size based on the respective means and SDs.
We then corrected the computed effect size with the correlation between the two measurements. We computed this correlation based on the t-statistic, the respective means and SDs (Lipsey \& Wilson, 2001). If not all of these informations were reported, we randomly imputed a correlation with equal probability between 0.01 and 0.99. 

Effect sizes were first computed as Cohen's d, and then transformed to Hedge's g. 

### Meta-analytic models

Once the data was completed, we estimated the true effect size fitting mixed-effects meta-analytic regressions. We used the R package metafor **(CITE)**. We specified a hierarchical model with random effects of paper, and random effects for independent infants within paper (same_infant). We specified the following moderators as fixed effects:
- mean age of children;
- experimental method (Central fixation/Head-turn Preference Procedure/High Amplitude Sucking/Passive Listening);
- familiarity with the language used (native/foreign);
- naturalness of the contrastive sound (natural/artificial, coded as yes/no).
If the sound contrasted to speech was natural, we also coded whether it was vocal or not, and from human or another species (homospecific/heterospecific, coded as yes/no).

We first estimated the global effect size by fitting a random-effects meta-analytic regression without any hierarchical structure or moderator. 
We then added the hierarchical structure with papers and infant groups within papers. 
We assessed whether the experimental method influenced the magnitude of the effect size apart from target moderators by fitting a mixed-effects meta-analytic regression with the above described hierarchical structure and the method as a moderator.

We investigated the effect of familiarity with the sound by running a mixed-effects meta-analytic model with nativeness of the language used for the speech stimuli as a moderator.

We then investigated whether speech preference was embedded in a preference for natural sounds, and whether this potential effect evolved over the course of the first year of life, by fitting a mixed-effects meta-analytic model with naturalness and age as moderators. To facilitate result interpretation, we centered age.

Finally, we subsetted the dataset to contrasts between speech and natural sounds, and fitted a meta-analytic regression on this subset with vocalness (vocal/non-vocal), and species (homospecific/heterospecific) as moderators.

```{r moderators, include=FALSE}
#distribution of moderators
g_age <- tapply(DB$g_calc, DB$mean_age_1, mean)#ES by age
table(DB$natural)#no. of natural and non-natural data points
table(DB$vocal)#no. of vocal and non-vocal data points
table(DB$homospecific)#no. of homo- and heterospecific data points
table(DB$homospecific,DB$vocal)
table(DB$natural,DB$vocal)

#setting up of predictors 
#http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/

 #check that the experimental method doesn't make a difference
DB$method_m <- group.mean(DB$method, DB$study_ID) #ac this line didn't work - perhaps it relies on langcog? this is easy to do with aggregate
#dummy coding: each level is compared to a reference level of the dependent variable, intercept corresponds to the reference level.
contrasts(DB$method) = contr.treatment(length(levels(DB$method)))
 #check that the language doesn't make a difference (true speech preference and not pref for native language, hence familiarity)
contrasts(DB$test_lang) <- contr.treatment(length(levels(DB$test_lang)),base=1)

 #moderators of interest
contrasts(DB$natural) <- contr.treatment(length(levels(DB$natural)),base=2)

DB$homospecific<-factor(DB$homospecific)
contrasts(DB$homospecific) <- contr.treatment(length(levels(DB$homospecific)))

DB$vocal<-factor(DB$vocal)
contrasts(DB$vocal) <- contr.treatment(length(levels(DB$vocal)),base=2)

```



```{r models, include = TRUE}
#ac changed include so that we can print out the model results to check for stability

#fit models
DB2 = DB[!is.na(DB$g_calc)&DB$outlier==F,]

simple_model <- rma(g_calc, g_var_calc, data=DB, weighted = TRUE, method = "REML", subset=!DB$outlier, slab =DB$short_cite) 

base_model <- robu(g_calc ~ 1, data=DB[!DB$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_calc) 

method_model <- rma.mv(g_calc, g_var_calc, mods = ~method, random = ~ 1 | study_ID/same_infant, data=DB, method = "REML", subset=!DB$outlier & !is.na(DB$method))

#full model (with moderators of interest). 
full_model <-rma.mv(g_calc, g_var_calc, mods= ~ test_lang + vocal*agec, random = ~ 1 | study_ID/same_infant, data=DB, method = "REML", subset=!DB$outlier, slab =DB$short_cite)

full_model2 <-rma.mv(g_calc, g_var_calc, mods= ~ test_lang + natural*agec, random = ~ 1 | study_ID/same_infant, data=DB, method = "REML", subset=!DB$outlier, slab =DB$short_cite)

table(DB2$test_lang,DB2$natural)

summary(full_model)

#ac suspicious of the test_lang being opposite sign to vocal1, check that this beta doesn't change much when no other n/s predictors

lang_model <-rma.mv(g_calc, g_var_calc, mods= ~ test_lang , random = ~ 1 | study_ID/same_infant, data=DB, method = "REML", subset=!DB$outlier, slab =DB$short_cite)

summary(lang_model)

#ac confirmed, now checking beta for vocal

voc_model <-rma.mv(g_calc, g_var_calc, mods= ~ vocal , random = ~ 1 | study_ID/same_infant, data=DB, method = "REML", subset=!DB$outlier, slab =DB$short_cite)

summary(voc_model)
#ac confirmed

#ac base_model required below to be an rma object, but now it's a robu object; here I fake attribute simple model to base model
#base_model<-simple_model
```


### Publication bias

We assessed the presence of a potential publication bias in the literature by plotting N funnel plots. The first one was based on the simple model without hierarchical structure nor moderators. We symmetrized this funnel plot using the “trim and fill” method (ADD REF). The second funnel plot was based on the mixed model with hierarchical random structure and moderators. We tested the asymmetry of the funnel plots by regressing effect size as a function of effect size standard error and running a Kendall's tau rank test. 

# Results

## Database description
We found a total of `r length(papers)` papers reporting `r length(DB$g_calc)` (not mutually independent) effect sizes, see Table 1. All of them have been submitted to or published in peer-reviewed journals. 
Studies tended to have small sample sizes, with a median N of `r median(DB$n)` children (Range = `r max(DB$n)-min(DB$n)`, M = `r mean(DB$n)`, Total: `r round(sum(temp$n))`).
Infants ranged from `r round(min(DB$mean_age_1)/30.44)` to `r round(max(DB$mean_age_1)/30.44)` months (`r min(DB$mean_age_1)` to `r max(DB$mean_age_1)` days). Individual samples comprised `r round(min(DB$gender_1, na.rm=TRUE)*100)` % of female participants on average. Infants were native of 7 different languages across the whole database (English, French, Japanese, Italian, Russian, Yiddish, Hebrew). 
Studies were performed in 13 different laboratories from 6 different countries (United States, Canada, Israel, France, Japan, Italy). `r length(unique(DB$method))` experimental methods were used: XX studies used Near-Infrared Spectroscopy (NIRS), 1 study used fMRI, 12 studies used Central Fixation (CF), 3 used High-Amplitude Sucking (HAS), 1 used Head-turn Preference Procedure (HPP), and 9 used Passive Listening (PL). 

## Summary effect size

We found a mean weighted effect size g =`r base_model$beta` (SE = `r base_model$se` CI[`r base_model$ci.lb`,`r base_model$ci.ub`]).

```{r forest plot}
pdf("forest_plot_noMod.pdf")
for_plot = forest.rma(simple_model, order = 'obs', annotate = FALSE, xlim = c(-4.5,3), alim = c(-3,3), top=0, main = 'Forest plot of effect sizes', xlab = 'Effect size (Hedges\' g)', mlab = "", steps = 7, fonts = 'mono', cex = 0.4, cex.axis = 0.6, cex.lab = 0.7) 
dev.off()
```

## Publication bias
Evidence of bias at level of papers
Evidence of bias at level of literature
```{r publication bias}

#add symmetrize
tf <- trimfill(simple_model) 
fun.fig <- funnel(tf, cex=1.5, xlab='Hedges\' g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference", legend=TRUE)


#Figure
pdf("Funnel.pdf")

funnel(base_model,cex=1.5,xlab='Hedge\'s g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference", legend=TRUE)
dev.off()

# testing for asymetry (indicates a publication bias) #ac this is highly significant
regtest(DB$g_calc,DB$g_var_calc)
ranktest(DB$g_calc,DB$g_var_calc)

```

## Main effects

```{r plots} 
DB$age_months = DB$mean_age_1/30.44

#Effect of naturalness
vio_nat <- ggplot(data=DB[!is.na(DB$natural),], aes(x=natural, y=g_calc))+
  geom_violin(aes(fill=natural), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=natural, y=g_calc, size=1/DB[!is.na(DB$natural),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", labels=c("artificial","natural"), na.translate = FALSE)+
  scale_fill_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 20))

ggsave("violin_natural.pdf")

ggplot(data=DB[!is.na(DB$natural),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB[!is.na(DB$natural),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_colour_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20), legend.position = c(.9, .9))

ggsave("natural-age.pdf")

# Effect of vocalness
vio_voc <- ggplot(data=DB[!is.na(DB$vocal),],aes(x=vocal, y=g_calc))+
  geom_violin(aes(fill=vocal), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=vocal, y=g_calc, size=1/DB[!is.na(DB$vocal),]$g_var_calc), position=position_jitter(w=0.1, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", na.translate = FALSE, labels = c("non-vocal", "vocal"))+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("turquoise2","tomato"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20))

ggsave("scatter_vocal.pdf")

ggplot(data=DB[!is.na(DB$vocal),],aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB[!is.na(DB$vocal),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_colour_manual(values = c("turquoise2","tomato"), labels = c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20), legend.position = c(.9, .9))

ggsave("vocal-age.pdf")

#method varies with age
#plot g as a function of method
mycols=c("black","blue","red","green")
names(mycols) <- levels(DB$method)
mycols
plot(DB$g_calc~DB$mean_age_1,col = mycols[DB$method],pch=20,cex=.7)

ggplot(data=DB[!is.na(DB$test_lang),], aes(x=age_months, y=g_calc))+
  geom_point(aes(size=1/DB[!is.na(DB$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(method = "glm", na.rm = TRUE, color='gray40')+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 20))

ggsave("age.pdf")

#Effect of familiarity with the speech sounds? Nativeness (test_lang) and age.

vio_lang <- ggplot(data=DB[!is.na(DB$test_lang),],aes(x=test_lang, y=g_calc))+
  geom_violin(aes(fill=test_lang), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=test_lang, y=g_calc, size=1/DB[!is.na(DB$test_lang),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "speech sound", labels=c("foreign","native"), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedge's g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20))

ggsave("violin_lang.pdf")

```

Heterogeneity
Moderators
age, type & interaction


# Discussion

- Age
- Type of sounds contrasted
- Interactions
- power
- heterogeneity

Naturalness alone doesn't significantly moderate infants' preference for speech sounds: they still prefer speech, and the amount of preference doesn't change, whether the sound is natural or artificial. This means that infants prefer natural speech in itself. 
This preference might explain why naturalness makes a difference for higher-level linguistic, a priori abstract tasks such as word segmentation (Black & Bergmann, 2016): speech triggers different cognitive mechanisms than other sounds. Not incompatible as in this meta-analysis natural speech stimuli when contrasted to only synthetic speech. We don't know if infants would have been able to find "words" with natural sounds other than syllables (i.e. frequent sequences of several natural sounds).

Experimental method significantly modulates speech preference: some methods are more appropriate than others to test infants on this type of task. This phenomenon has been repeatedly observed in developmental meta-analysis (see Bergmann et al., 2018, for a synthesis across meta-analysis in developmental psychology).