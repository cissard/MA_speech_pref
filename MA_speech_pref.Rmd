---
title: "How does the human auditory system become expert in speech processing? Insights from development."
author: "Cécile Issard and Alejandrina Cristia"
date: "`r format(Sys.time(), '%d %m, %Y')`"
output: pdf_document
#bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE) #option for all the code chunks of the document.
ggplot2::theme_set(langcog::theme_mikabr(base_family = "Ubuntu"))

source("compute_es.R", chdir = TRUE)  #chdir stands for "change directory"

library(metafor)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(langcog)
library(grid)
library(gridExtra)
library(RCurl)

sessionInfo()
```
- Target journal: Developmental science
- Article type: short report
- 4000 words
- 6 keywords
- Running title: 40 characters
- Submit one normal and one blinded version
- Separate files for title page, main text, and figures
- No identifiying info in the main text.
- up to 4 research highlights; each 25 words
- Abstract: 250 words

Main text file:

1. Title 
2. Research highlights
3. Abstract and key words
4. Main 
5. References
6. Figures and tables (each clearly identified, labelled and on a separate page)
7. Appendices (if relevant).

# Abstract

The human auditory system is amazingly efficient at processing speech. This capacity would be present from birth, infants preferring to listen to natural speech than to other types of sounds, enabling them to select the signals that are relevant for communication with conspecifics. However, a large variety of sounds have been contrasted to speech, with infants of very different ages. Drawing a global picture of how this capacity emerges is therefore difficult. We synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a strong effect size, infants prefering speech over any other type of sound. However, contrary to the results of individual studies, we found no effect of age: infants showed the same amount of preference from birth to one year of age. Preference was stronger when speech was contrasted to artificial sounds, and when the speech stimuli were in the infants' native language. This suggests that the representation of speech as a distinct auditory object emerges from a broader category of natural sounds, modulated by the degree of familiarity with the sound.

```{r db general}

# Comment out next set of lines for RECALCULATION
 require(RCurl)
 u <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRzzqtgNdfoKTMqb4bWyy5LyH5XdrOEy4sl3VNDCnGIyvdrny4wwUBeKPvy8tXczN0ri0yp94Kxgun_/pub?gid=0&single=true&output=csv"
 tc <- getURL(u, ssl.verifypeer=FALSE)
 DB <- read.csv(textConnection(tc))
 write.csv(DB,"MA_speech_pref_data.csv")
# Uncomment next line for OFFLINE MODE
#DB <- read.csv("MA_speech_pref_data.csv", header = T, sep = ",", na.strings = "")

## of datapoints and variables coded
dim(DB)

## FIX, remove empty columns
rmcol=NULL
for(mycol in 1:dim(DB)[2]) if(sum(is.na(DB[,mycol]))==length(DB[,mycol])) rmcol=c(rmcol,colnames(DB)[mycol])
rmcol[!(rmcol %in% "corr")]->rmcol
DB[,!(colnames(DB) %in% rmcol)]->DB
dim(DB)

## FIX, DOUBLE CHECK ALEX & CECILE !! REPLACE ALL EMPTY WITH NA
for(mycol in colnames(DB)) DB[DB[,mycol]=="" & !is.na(DB[,mycol]),mycol]<-NA
for(mycol in c("natural","vocal","conspecific","test_lang")) DB[,mycol]<-factor(DB[,mycol]) 
summary(DB)

#unique studies
papers <- levels(factor(DB$short_cite))

#number of unique infants
DB$n<-rowSums( cbind (DB$n_1,DB$n_2), na.rm=TRUE)
temp<-aggregate(n~same_infant,DB,mean)

summary(DB$mean_age_1)

```

# Introduction

1. Para/subsection 1: general para about preferences being useful for info filtering in all species; 
previous work shows these are partially innate, partially based on experience (in chicks: what can be used for imprinting or not; in humans: faces, voices, etc); 
A long line of research shows that infants process speech preferentially over other types of sounds. As the main signal for vocal communication, speech must be special for humans. Readily from birth, humans would be equipped with an auditory module dedicated to speech sounds, to process them with dedicated auditory and cognitive mechanisms. This preference has been investigated by numerous studies, contrasting speech to a variety of sounds, from white noise to backward speech, and at different ages. Getting a precise overview of this capacity is therefore difficult. 
“broader template that initially encompasses vocalizations of human and nonhuman primates and is rapidly tuned specifically to human vocalizations.” “Is this link sufficiently broad to include naturalistic vocalizations beyond those of our closest genealogical cousins, or is it restricted to primates, whose vocalizations may be perceptually just close enough to our own to serve as early candidates for the platform on which human language is launched?” (Ferry et al., 2013) 
The auditory literature suggests that natural sounds are processed differently by the auditory system (e.g. Mezhrahi & Nelken, 2014). Extending to language acquisition, naturalness is a key factor for word segmentation (Black and Bergman, 2016). Speech might therefore not be prefered per se, but because it belongs to a broader category of natural, own-species, or communicative sounds.
End saying “here we synthesize empirical data on infants’ preferences for natural sounds, human sounds, social sounds, and/or speech”

2. Para/subsection 2: (age)
This general capacity is thought to be modulated by age. Infants younger than 3 months have been shown to discriminate speech and sine-wave speech, but not speech and monkey calls, whereas infants from 3 months of age do (Vouloumanos et al., 2004). Similarly, the activity of the temporal cortex in response to biological non-speech sounds increased with age between 1 and 4 month-old. The response to speech didn't increase during the same developmental window (Shultz et al. 2014), suggesting that the capacity to discriminate speech from other sounds comes from a narrowing of the perceptual category to speech rather than a more in-depth processing.
elaborate on developmental & experiential aspects (explain how they are correlated, and when they are separable)
→  age is a crucial factor; 
mention controversies in additional para if they exist

3. Para/subsection 3: (types)
types of attractors: natural sounds, human sounds, social sounds, and/or speech; 
explain that to a certain extent these are inside a hierarchy (show in a figure?); Natural > human > social > vocal > speech Vent diagram.
also explain similarities and differences; 
explain the relevance of the contrast/control sound; 
if there are controversies, mention them as well (break down into several para if needed)

4. Para/subsection 4: MA
	All of these results have been observed on small groups of infants, with a large variety of age and stimuli across groups. Individual studies can only test a few infants on very specific stimuli due to experimental constraints. On the opposite, meta-analysis are a way of achieving power without running new studies. Meta-analysis have the disadvantage of mixing studies with different experimental designs together, therefore having less control on the effect measured. They merge results from different studies with common factors, so subtle differences in experimental paradigms are overklooked, potentially missing subtle effects. But meta-analysis have important advantages: they gather data from significantly more infants than individual studies, which significantly increases statistical power. They also offer tools to detect publication bias in the literature. Finally they allow to draw a developmental time-line across the age range covered by the literature, and test how the different factors discussed by different individual studies interact. 
	We conducted a meta-analysis to test if infants’ reliably have a preference for speech sounds over other types of sounds, and if yes if different types of sound modulated this preference, and how it developped over the first year of life. 

  - trying to address Qs like differences across types would require large power
  - reproducibility checks are built in (i.e., if we do find an effect, it’s more likely to be an effect different labs can find) MA is based on data from multiple labs.

# Methods
## Literature search
We followed PRISMA (Moher et al., 2009).

The information sources used to compose the initial list included suggestions by experts (authors of this work); two google scholar searches (“ ("speech preference" OR "own-species vocalization" ) AND infant”, and “("speech preference" OR "own-species vocalization" ) AND infant”) complemented with the same searches in PubMed and PsycInfo; and a google alert, as well as reference lists of the full papers inspected.

We included studies that tested human infants for birth to 1 year (0-365 days) of age, and contrasted speech sounds with any other type of sound, measuring either behavioral (e.g. looking times) or neurophysiological responses to the sounds. We excluded studies that contrasted foreign to native language, or didn’t present natural speech sounds. We also excluded studies that used the mother's voice to produce the speech stimuli, as this might raise a confound between speech processing and emotional response to the mother. A PRISMA flowchart summarizes the literature review and selection process (Figure 1). We documented all the studies that we inspected in this decision spreadsheet.

[Insert Figure 1 here]

For fMRI and NIRS studies, the contrast between the response to speech and to the other sound wad coded only if the same voxel, channel, or region of interest was reported for both types of sounds. As different brain regions are sensitive to different stimuli, preferential processing of a specific sound only holds if a larger response is observed for this sound within regions. Therefore, if different voxels, channels, or regions of interest were reported for the two sound conditions, the corresponding contrast was not reported. This ensured comparibility of the two responses. 
Data were coded by the first author. 20% of the papers were selected to be coded by the second author independently, with disagreements resolved by discussion. There were **XX** disagreements out of a total of **YY** fields filled in, so that the total agreement rate was **ZZ**%. The full list of the variables coded is available in the supplementary material.

**Risk assessment at the level of papers was done by ... Risk assessment for the whole body of literature ...** See PRISMA CHECKLIST.

## Statistical analysis

### Individual effect sizes

Once the data were coded, we computed individual effect sizes that were not directly reported in the papers, along with their respective variance. We adjusted the formula according to the experimental design of the respective paper (Lipsey \& Wilson, 2001). When the coded study used a within-participant design with two measurements (e.g. looking time during speech and during monkey calls), we computed effect size using t-statistic (Dunlap et al., 1996). If this statistic was not reported, we computed effect size based on the respective means and SDs.
We then corrected the computed effect size with the correlation between the two measurments. We computed this correlation based on the t-statistic, the respective means and SDs (Lipsey \& Wilson, 2001). If not all of these informations were reported, we randomly imputed a correlation with equal probability between 0.01 and 0.99. 

Effect sizes were first computed as Cohen's d, and then transformed to Hedge's g. 

```{r data_completion, include=FALSE}
#calculate correlations
for (i in 1:nrow(DB)){
    db = DB[i,]
       if (db$participant_design == "within_two") {
        # Use raw means, SD, and t-values to calculate correlations
          if (is.na(db$corr) & complete(db$x_1, db$x_2, db$SD_1, db$SD_2, db$t)) {
        db$corr = (db$SD_1^2 + db$SD_2^2 - (db$n_1 * (db$x_1 - db$x_2)^2 / db$t^2)) / (2 * db$SD_1 * db$SD_2)
          }
        DB[i,] = db
       }
}

#if all of these measures are not reported, use an imputed correlation value
#we also account for the observation that some re-calculated values are impossible and replace those
for (i in 1:nrow(DB)){
    db = DB[i,]
       if (db$participant_design == "within_two") {
         if (is.na(db$corr) | db$corr > .99 | db$corr < .01){
          db$corr = runif(1, min = 0.01, max = 0.99)
         }
       DB[i,] = db
       }
}

#We create variables for effect sizes (ES)
DB$d_calc = NA
DB$d_var_calc = NA
DB$g_calc = NA
DB$g_var_calc = NA
DB$r_calc = NA
DB$r_var_calc = NA
DB$z_calc = NA
DB$z_var_calc = NA
DB$log_odds_calc = NA
DB$log_odds_var_calc = NA
DB$es_method = NA
  
#we introduce variables d_calc and d_var_calc to distiguish them from the fields d and d_var, which are fields where effect sizes were already available from the source of the data
d_calc <- NA
d_var_calc <- NA
es_method <- "missing"
  
#start of decision tree where effect sizes are calculated differently based on participant design depending on which data is available, effect sizes are calculated differently
for (i in 1:nrow(DB)){
    db = DB[i,]
       if (db$participant_design == "between") {
    es_method  <- "between"
    #effect size calculation
    if (complete(db$x_1, db$x_2, db$SD_1, db$SD_2)) {
      pooled_SD <- sqrt(((db$n_1 - 1) * db$SD_1 ^ 2 + (db$n_2 - 1) * db$SD_2 ^ 2) / (db$n_1 + db$n_2 - 2)) # Lipsey & Wilson, 3.14
      d_calc <- (db$x_1 - db$x_2) / pooled_SD # Lipsey & Wilson (2001)
    } else if (complete(db$t)) {
      d_calc <- db$t * sqrt((db$n_1 + db$n_2) / (db$n_1 * db$n_2)) # Lipsey & Wilson, (2001)
    } else if (complete(db$F)) {
      d_calc <- sqrt(db$F * (db$n_1 + db$n_2) / (db$n_1 * db$n_2)) # Lipsey & Wilson, (2001)
    } else {d_calc = NA}
    #now that effect size are calculated, effect size variance is calculated
    if (complete(db$n_1, db$n_2, d_calc)) {
      d_var_calc <- ((db$n_1 + db$n_2) / (db$n_1 * db$n_2)) + (d_calc ^ 2 / (2 * (db$n_1 + db$n_2)))
    } else if (complete(db$d, db$d_var)) {
      #if d and d_var were already reported, use those values
      d_calc <- d
      d_var_calc <- d_var
    } else {d_var_calc = NA}

  } else if (db$participant_design == "within_two") {
      
    #effect size calculation
    if (complete(db$x_1, db$x_2, db$SD_1, db$SD_2)) {
      pooled_SD <- sqrt((db$SD_1 ^ 2 + db$SD_2 ^ 2) / 2) # Lipsey & Wilson (2001)
      d_calc <- (db$x_1 - db$x_2) / pooled_SD # Lipsey & Wilson (2001)
      es_method  <- "group_means_two"
    } else if (complete(db$t)) {
      wc <- sqrt(2 * (1 - db$corr))
      d_calc <- (db$t / sqrt(db$n_1)) * wc #Dunlap et al., 1996, p.171
      es_method  <- "t_two"
    } else if (complete(db$F)) {
      wc <- sqrt(2 * (1 - db$corr))
      d_calc <- sqrt(db$F / db$n_1) * wc
      es_method  <- "f_two"
    } else {d_calc = NA}
    #now that effect size are calculated, effect size variance is calculated
    if (complete(db$n_1, d_calc)) {
      #d_var_calc <- ((1 / n_1) + (d_calc ^ 2 / (2 * n_1))) * 2 * (1 - corr) #we used this until 4/7/17
      d_var_calc <- (2 * (1 - db$corr)/ db$n_1) + (d_calc ^ 2 / (2 * db$n_1)) # Lipsey & Wilson (2001)
    } else if (complete(db$d, db$d_var)) {
      #if d and d_var were already reported, use those values
      d_calc <- db$d
      d_var_calc <- db$d_var
      es_method  <- "d_two"
    } else {d_var_calc = NA}
    
  } else if (db$participant_design == "within_one") {
    if (complete(db$x_1, db$x_2, db$SD_1)) {
      d_calc <- (db$x_1 - db$x_2) / db$SD_1
      es_method  <- "group_means_one"
    } else if (complete(db$t)) {
      d_calc <- db$t / sqrt(db$n_1)
      es_method  <- "t_one"
    } else if (complete(db$F)) {
      d_calc <- sqrt(db$F / db$n_1)
      es_method  <- "f_one"
    } else {d_calc = NA}
  }
  
  df <- if (db$participant_design == "between") {
    sum(db$n_1, db$n_2, na.rm = TRUE) - 2
  } else {
    db$n_1 - 1
  }
  J <- 1 - 3 / (4 * (df - 1))
  g_calc <- d_calc * J
  g_var_calc <- J ^ 2 * d_var_calc

  if (db$participant_design == "between") {
    a <- (sum(db$n_1, db$n_2, na.rm = TRUE) ^ 2) / prod(db$n_1, db$n_2, na.rm = TRUE)
  } else {
    a <- 4
  }
  r_calc <- d_calc / sqrt(d_calc ^ 2 + a)
  r_var_calc <- a ^ 2 * d_var_calc / (d_calc ^ 2 + a) ^ 3

  z_calc <- 0.5 * log((1 + r_calc) / (1 - r_calc))
  z_var_calc = 1 / (db$n_1 - 3)

  log_odds_calc <- d_calc * pi / sqrt(3)
  log_odds_var_calc <- d_var_calc * pi ^ 2 / 3
  
  #add the results to the database
  db$d_calc = d_calc
  db$d_var_calc = d_var_calc
  db$g_calc = g_calc
  db$g_var_calc = g_var_calc
  db$r_calc = r_calc
  db$r_var_calc = r_var_calc
  db$z_calc = z_calc
  db$z_var_calc = z_var_calc
  db$log_odds_calc = log_odds_calc
  db$log_odds_var_calc = log_odds_var_calc
  db$es_method = es_method
  
  DB[i,] = db
}

#Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
DB$outlier <- F #create the variable, and set as no by default (majority of cases hopefully!)
for (i in 1:nrow(DB)){
   db = DB[i,]
   if (!is.na(db$d_calc)){ #select the lines for which there is an ES available (bug next line if d_calc = NA)
     if (db$d_calc > mean(DB$d_calc, na.rm = TRUE) + 3*sd(DB$d_calc, na.rm = TRUE) | db$d_calc < mean(DB$d_calc, na.rm = TRUE) - 3*sd(DB$d_calc, na.rm = TRUE)) {
     db$outlier=T #if more than 3 SDs away from the mean, we consider this ES as an outlier.
     }
   }
   DB[i,] = db
}
#Visualize the outliers
outliers<-subset(DB,outlier==T)
outliers

#Not considered as outliers but still high
highES<-subset(DB,g_calc>(mean(DB$g_calc,na.rm=T)+2*sd(DB$g_calc,na.rm=T)))
highES

#centering of age (although some rows also have mean_age_2, it is always the same as mean_age_1 in this db, hence the latter is used)
DB$agec<-scale(DB$mean_age_1,scale=F)

# save the complete data base
write.csv(DB,'speech_pref_full_DB.csv')

summary(DB)

#info 
paste("We were considering", nrow(DB),"ES candidates")
paste("We could calculate", sum(!is.na(DB$d_calc)),"ES's")
table(DB$response_mode)
#summarize the data
mean(DB$g_calc,na.rm=T)
sd(DB$g_calc,na.rm=T)
stripchart(DB$g_calc, main = 'Distribution of ES')
boxplot(DB$g_calc)
```

### Meta-analytic models

Once the data was completed, we estimated the true effect size fitting mixed-effects meta-analytic regressions. We used the R package metafor **(CITE)**. We included random effects of paper, and random effects for independent infants within paper (same_infant).
We included the following variables in the analysis:
- Number and demographic characteristics of children, including age and gender;
- The experimental method (Central fixation/Head-turn Preference Procedure/High Amplitude Sucking/Passive Listening)
- Familiarity with the language used (native/foreign);
- Naturalness of the contrastive sound (natural/artificial);
If the sound contrasted to speech was natural, we also coded whether it was vocal or not, and from human or another species (homospecific/heterospecific).

We first assessed whether the experimental method influenced the magnitude of the effect size apart from target moderators by fitting a meta-analytic regression with the method as a moderator.

We investigated the effect of familiarity with the sound by running a meta-analytic model with nativeness of the language used for the speech stimuli as a moderator.

We then investigated whether speech preference was embedded in a preference for natural sounds, and whether this potential effect evolved over the course of the first year of life, by fitting a meta-analytic model with naturalness and age as moderators. To facilitate result interpretaion, we centered age.

Sho: We assess significance of predictor variables by model comparison.

Finally, we subsetted the dataset to contrasts between speech and natural sounds, and fitted a meta-analytic regression on this subset with socialness (social/non-social), vocalness (vocal/non-vocal), and species (homospecific/heterospecific) as moderators.

```{r moderators}
#distribution of moderators
g_age <- tapply(DB$g_calc,DB$mean_age_1,mean)#ES by age
table(DB$natural)#no. of natural and non-natural data points
table(DB$vocal)#no. of vocal and non-vocal data points
table(DB$conspecific)#no. of homo- and heterospecific data points
table(DB$conspecific,DB$vocal)
table(DB$natural,DB$vocal)

#plot ES as a function of moderators
#age
plot(unique(DB$mean_age_1),g_age, main = 'ES as a function of age', xlab = 'age centered (days)', ylab = 'g_calc')
#naturalness
boxplot(DB$g_calc~DB$natural, main = 'ES as a function of naturalness')

#vocal
boxplot(DB$g_calc~DB$vocal, main = 'ES as a function of vocalness')

#species
boxplot(DB$g_calc~DB$conspecific, main = 'ES as a function of species')
```


## Including Plots

```{r Figure Template}

apatheme=theme_bw()+
  theme(#panel.grid.major=element_blank(),
        #panel.grid.minor=element_blank(),
        panel.border=element_blank(),
        axis.line=element_line(),
        #text=element_text(family='Times'),
        legend.position='none')
```


```{r models}
#setting up of predictors 
#http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/

 #check that the experimental method doesn't make a difference
#dummy coding: each level is compared to a reference level of the dependent variable, intercept corresponds to the reference level.
contrasts(DB$method) = contr.treatment(length(levels(DB$method)))
 #check that the language doesn't make a difference (true speech preference and not pref for native language, hence familiarity)
contrasts(DB$test_lang) <- contr.treatment(length(levels(DB$test_lang)))

 #moderators of interest
contrasts(DB$natural) <- contr.treatment(length(levels(DB$natural)),base=2)

DB$conspecific<-factor(DB$conspecific)
contrasts(DB$conspecific) <- contr.treatment(length(levels(DB$conspecific)))

DB$vocal<-factor(DB$vocal)
contrasts(DB$vocal) <- contr.treatment(length(levels(DB$vocal)),base=2)

#fit models

base_model <-rma.mv(g_calc, g_var_calc, random = ~ 1 | study_ID/same_infant, data=DB, weighted=TRUE, method = "REML", subset=!DB$outlier)

method_model <-rma.mv(g_calc, g_var_calc, mods = ~method, random = ~ 1 | study_ID/same_infant, data=DB, weighted=TRUE, method = "REML", subset=!DB$outlier & !is.na(DB$method)) 

 #age varies with method
#plot g as a function of method
mycols=c("black","blue","red","green")
names(mycols)<-levels(DB$method)
mycols
plot(DB$g_calc~DB$mean_age_1,col=mycols[DB$method],pch=20,cex=.7)

 #check also for test_lang (nativeness)
 #The language used for the speech trials doesn't make a difference
plot(DB$g_calc~DB$mean_age_1,col=DB$test_lang, main='effect of nativeness')
tapply(DB$g_calc,DB$test_lang, mean,na.rm=T)
tapply(DB$g_calc,DB$test_lang, sd,na.rm=T)

DB2 = DB[!is.na(DB$g_calc)&DB$outlier==F,]
table(DB2$test_lang,DB2$natural)

 #full model (with moderators of interest). 
full_model <-rma.mv(g_calc, g_var_calc, mods= ~ natural*test_lang*agec, random = ~ 1 | study_ID/same_infant, data=DB, weighted=TRUE, method = "REML", subset=!DB$outlier,slab =DB$short_cite)

summary(full_model)

#subset to natural sounds, as naturalness doesn't make a difference. This allows to test species (conspecific) that is not orthogonal to naturalness.
natural_only <-rma.mv(g_calc, g_var_calc, mods=~ conspecific*agec, random = ~ 1 | study_ID/same_infant, data=DB, weighted=TRUE, method = "ML", subset=!DB$outlier & !is.na(DB$natural) & DB$natural=='yes')

summary(natural_only)
```


### Publication bias

We assessed the presence of a potantial publication bias in the literature by plotting funnel plot. We tested the asymmetry of the funnel plot by regressing effect size as a function of effect size standard error and running a Kendall's tau rank test. 

```{r publication bias}
tf <- trimfill(base_model)
fun.fig <- funnel(tf, cex=1.5, xlab='Hedges\' g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference")


#Figure
pdf("Fig1.pdf")
par(mfrow=c(1,2)) #graphical parameters: A vector of the form c(nr, nc). Subsequent figures will be drawn in an nr-by-nc array on the device by rows (mfrow), respectively.

funnel(base_model,cex=1.5,xlab='Hedge\'s g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference")
dev.off()
#add symmetrize

# testing for asymetry (indicates a publication bias)
regtest(DB$g_calc,DB$g_var_calc)
ranktest(DB$g_calc,DB$g_var_calc)

#ALEX commented this out, I don't think this code belongs here
#calculate regression weight of studies that were conducted by supporters of NRV model 
# DB.periph<-DB[DB$periph==T,]
# DB.periph$weight<-1/sqrt(DB.periph$g_var_calc^2)
# DB.periph$forNRV<-0
# DB.periph$forNRV[DB.periph$study_ID=="Polka1996"|DB.periph$study_ID=="Polka2011"]<-1
# forNRV.weight<-sum(DB.periph$weight[DB.periph$forNRV==1])/sum(DB.periph$weight)
# forNRV.weight

```

# Results

## Database description
We found a total of ```{r} length(papers)``` papers reporting ```{r} length(DB$g_calc)``` (not mutually independent) effect sizes, see Table 1. All of them have been submitted to or published in peer-reviewed journals. 
Studies tended to have small sample sizes, with a median N of ```{r} median(DB$n)``` children (Range = ```{r} max(DB$n)-min(DB$n)```, M = ```{r} mean(DB$n)```, Total: ```{r} round(sum(temp$n))```.
Infants ranged from ```{r} round(min(DB$mean_age_1)/30.44)``` to ```{r} round(max(DB$mean_age_1)/30.44)``` (```{r} min(DB$mean_age_1)``` to ```{r} max(DB$mean_age_1)``` days). Individual samples comprised ```{r} round(min(DB$gender_1)*100``` % of female participants on average. Infants were native of XX different languages across the whole database (English, French, Japanese, Italian, Russian, Yiddish, Hebrew). 
Studies were performed in 13 different laboratories from 6 different countries (United States, Canada, Israel, France, Japan, Italy). ```{r} length(unique(DB$method))``` experimental methods were used: 12 studies used Central Fixation (CF), 3 used High-Amplitude Sucking (HAS), 1 used Head-turn Preference Procedure (HPP), and 9 used Passive Listening (PL). 

## Publication bias
Evidence of bias at level of papers
Evidence of bias at level of literature

## Main effects
We found a mean weighted effect size g=0.78 (CI[,])
```{r plots}
forest.rma(full_model, main = 'Forest plot of effect sizes', xlab = 'Hedges\' g') 

```
Heterogeneity
Moderators
age, type & interaction


# Discussion

- Age
- Type of sounds contrasted
- Interactions
- power
- heterogeneity

Naturalness doesn't significantly moderate infants' preference for speech sounds: they still prefer speech, and the amount of preference doesn't change, whether the sound is natural or artificial. This means that infants prefer natural speech in itself. 
This preference might explain why naturalness makes a difference for higher-level linguistic, a priori abstract tasks such as word segmentation (Black & Bergmann, 2016): speech triggers different cognitive mechanisms than other sounds. Not incompatible as in this meta-analysis natural speech stimuli when contrasted to only synthetic speech. We don't know if infants would have been able to find "words" with natural sounds other than syllables (i.e. frequent sequences of several natural sounds).

Experimental method significantly modulates speech preference: some methods are more appropriate than other to test infants on this type of task. This phenomenon has been repeatedly observed in developmental meta-analysis (see Bergmann et al., 2018, for a synthesis across meta-analysis in developmental psychology).