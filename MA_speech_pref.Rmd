---
title             : "Infants’ preference for speech is stable across the first year of life: Meta-analytic evidence"
shorttitle        : "Preference for speech sounds in infancy"

author: 
  - name          : "Cécile Issard"
    affiliation   : "1"
  - name          : "Sho Tsuji"
    affiliation   : "2"
  - name          : "Alejandrina Cristia"
    corresponding : yes    # Define only one corresponding author
    email         : "alecristia@gmail.com"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Laboratoire de Sciences Cognitives et Psycholinguistique, Ecole Normale Supérieure, Département d'Études Cognitives"
  - id            : "2"
    institution   : "International Research Center for Neurointelligence, The University of Tokyo"

authornote: |
  This work was supported by a Fyssen Foundation Post-doctoral Fellowship to CI, Agence Nationale de la Recherche (ANR-17-CE28-0007 LangAge, ANR-16-DATA-0004 ACLEW, ANR-14-CE30-0003 MechELex, ANR-17-EURE-0017); and the J. S. McDonnell Foundation Understanding Human Cognition Scholar Award to AC. The authors declare no conflict of interest. Funding sources did not take part in study design, data collection or analysis.  Our data is fully available in the corresponding OSF repository: http://tidy.ws/bqjc4U
  
abstract: |
 Previous work suggested that humans' sophisticated speech perception abilities stem from an early capacity to pay attention to speech in the auditory environment. What are the roots of this early preference? We assess the extent to which it is due to it being a vocal sound, a natural sound, and a familiar sound, through a meta-analytic approach, classifying experiments as a function of whether they used native or foreign speech, and whether the competitor, against which preference is tested, was vocal or non-vocal, natural or artificial. We also tested for effect of age. Synthesizing data from 775 infants across 38 experiments, we found a medium effect size, confirming at the scale of the literature that infants reliably prefer speech over other sounds. This preference was not significantly moderated by the language used, vocal quality or naturalness of the competitor, nor by infant age. The current body of evidence appears most compatible with the hypothesis that speech is preferred consistently as such, and not just due to its vocal, natural, or familiar nature. We discuss limitations of the extant body of work on speech preference, including evidence consistent with a publication bias and low representation of certain stimuli types and ages.
 

  
keywords          : "Meta-analysis, Infants, Speech preference, Conspecific detection, Developmental tuning"
wordcount         : "6930"

bibliography      : ["bibliography.bib"]
annotate_references: yes

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : yes
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include=F}

knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = FALSE, echo = FALSE, include = F) #options for all the code chunks of the document.

source("data_completion.R", chdir = TRUE)  #chdir stands for "change directory"

library(metafor)
library(robumeta)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(grid)
library(gridExtra)
library(RCurl)
library(papaja)

sessionInfo()


read.csv('speech_pref_full_DB.csv')->DB

DB2 = DB[DB$method!='PL' & !is.na(DB$g_calc),] #keep only the behavioral experiments, remove NAs.

#Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
DB2$outlier[DB2$g_calc > mean(DB2$g_calc, na.rm = TRUE) + 3*sd(DB2$g_calc, na.rm = TRUE) | DB2$g_calc < mean(DB2$g_calc, na.rm = TRUE) - 3*sd(DB2$g_calc, na.rm = TRUE)]<-T 

#unique experiments
papers <- levels(factor(DB2$short_cite))

#number of unique infants
DB2$n<-rowSums( cbind (DB2$n_1,DB2$n_2), na.rm=TRUE)
temp<-aggregate(n~same_infant,DB2,mean)

summary(DB2$mean_age_1)
```
<!-- # Significance -->

<!-- - Infants reliably prefer natural speech over other types of sounds -->
<!-- - Preference is stable from birth to the end of the first year of life -->
<!-- - Speech is preferred over both artificial and other natural sounds -->
<!-- - Speech is preferred over both non-vocal and other vocal sounds -->
<!-- - The language used for the speech sounds made no significant difference -->

# Introduction



Humans acquire their communication skills from early infancy, with specialized speech perception abilities well before they produce their first word. These perceptual capacities manifest in an early preference for speech over other types of sound [@vouloumanos_listening_2007;@vouloumanos_tuning_2010;@ecklund-flores_asymmetric_1996]. Some studies show, at birth, a preference for speech over sine-wave speech [e.g. time-varying sinusoidals tracking the fundamental frequency and the first three formants in @vouloumanos_listening_2007], and heartbeat [@ecklund-flores_asymmetric_1996]. Studies find no preference between speech and monkey calls at birth [@vouloumanos_tuning_2010;@shultz_three-month-olds_2010], but a preference for speech over monkey calls at three month old [@vouloumanos_tuning_2010]. Results like these, where infants show a preference for the target speech over a competitor, have led to the theoretical proposal that speech is a privileged signal for humans, whereby newborns have a preference for the vocalizations of humans and non-human primates, and by three months tune in to human speech specifically [@vouloumanos_listen_2014]. These studies even found that three-month-olds favor human speech over other human vocal sounds, such as coughing [@shultz_three-month-olds_2010]. Because these results have been obtained both with the participants' native language [@vouloumanos_listening_2007;@vouloumanos_tuning_2010], and a foreign language as target speech sounds [@shultz_three-month-olds_2010], it was claimed that infants tune to the speech signal itself, and not simply the familiar sounds of their native language [@vouloumanos_listen_2014]. 

These studies also tested factors other than vocal quality which could modulate the preference. Experiments at three months of age showed a preference for speech as compared to environmental sounds, such as wind or water, but in the same paper, other environmental sounds did not yield the same results [@shultz_three-month-olds_2010]. Regarding developmental tuning, this study did not test this contrast at other ages, making difficult to determine if infants prefer speech to other natural sounds from birth, or if this preference emerges during the first three months of life, as for monkey calls.

<!-- Finally, a line of studies argued that there are dedicated mechanisms for speech from birth that stem from high-level linguistic processing [i.e., recognition of properties like syllabic structure, @bertoncini_morae_1995].  -->
<!-- In this case, infants' preference for speech would be specific to the infant's native language.  -->
Studies opposing speech to monkey calls or environmental sounds found a preference for speech in both the native language [@vouloumanos_listening_2007;@vouloumanos_tuning_2010], and foreign languages as target speech sounds [@shultz_three-month-olds_2010], suggesting that familiarity with the language used as the target speech sounds does not determine the preference. However, newborns were only tested in their native language, so the impact of this factor over development has yet to be determined.



## A meta-analytic approach

Previous work has thus contributed both important hypotheses and tantalizing results, but the specificity of data collected in any one experiment makes it hard to obtain a bird's eye view. Moreover, some claims are based on juxtaposing a significant result in one condition or age against a non-significant one in another, a practice that is now known to be inappropriate since "the difference between 'significant' and 'not significant' is not itself statistically significant" [@gelman_difference_2006]. In this paper, we seek to directly test the theoretical predictions presented in the summarized work, namely that the preference for speech may be attributed to a general preference for vocalizations, to a preference for natural sounds, or to familiar sounds. To do so, we employ a meta-analytic approach, which is recommended over narrative reviews [@cristia_meta-analytic_2021].  A meta-analysis can integrate data from experiments that vary in their methodology, as well as test the effect of factors of theoretical importance, by redescribing the stimuli used as a function of those factors. For instance, a study measuring preference for native speech over white noise provides data on a natural versus artificial contrast, as well as a vocal versus non-vocal contrast, thus accounting for how the same stimuli can be both natural and vocal or artificial and non-vocal. 

Also, we can draw a developmental timeline across the age range covered by the literature, beyond age groups tested within papers. This is particularly useful in developmental psychology, which relies on age-related differences that need to be tested statistically [@gelman_difference_2006]. Meta-analyses offer a powerful statistical approach to directly test for interactions with age across the whole age-range covered by the literature. To give an example from a previous developmental meta-analysis, it had been proposed that infants’ preference for novel or familiar items related to infants' age such that, all things equal, younger infants showed familiarity preferences whereas older infants exhibited novelty preferences [@hunter_multifactor_1988]. However, stable familiarity preferences across the first two years have been found for word segmentation in natural speech [@bergmann_development_2016]; and a stable novelty effect ensues for artificial grammars implemented in synthesized speech, whereas those implemented in natural speech led to stable familiarity preferences [@black_quantifying_2017]. Meta-analyses are therefore important to statistically and systematically test the theoretical predictions proposed in qualitative reviews, and show subtle effects that are difficult to see when reading the literature with a human eye.

Single experiments tell us about what a specific group of participants, presented with a specific set of stimuli, at a specific point in time has done. Meta-analyses are the following step because they provide a principled statistical approach to integrate those individual and specific results into a larger picture. By aggregating the numerous individual studies of a literature, meta-analyses gain statistical power. As a result, meta-analyses can reveal small effects that are difficult to show in individual experiments. By integrating data across different laboratories, they provide evidence for the generalizability of effects, and facilitate comparisons between experimental results. A systematic review also allows us to identify empirical gaps (e.g., age groups that are under-represented but are crucial to tease apart two factors) and conceptual gaps (e.g., use of stimuli that systematically confounds two or more of those explanations). As a result, meta-analyses are a moment of self-reflection for the field [@cox2022bayesian;@nguyen2021systematic].



Finally, meta-analyses offer tools to detect publication bias in the literature. By aggregating all the available evidence for a phenomenon, we can see if the distribution of effect sizes has an unexpected shape, typically with an excess of positive results due to the difficulty to publish null or negative results. We can further integrate this information, and derive a new estimate of the overall effect size. 



## Research question and predictions

Our study tests three potential factors, latent in the literature, that could explain infants' speech preference: the *vocal* quality of the sound, the *natural* quality of the sound, and the *familiarity* of speech sounds for the infant. Vocal sounds are characterized by harmonic structure introduced by the resonance of the vocal tract, whereas natural sounds are characterized by slow temporal modulations. Both could be acoustical signatures detected by infants, and are not mutually exclusive. Vocal and natural quality sometimes overlap, as it is the case for example for monkey calls, but not always, as for example heartbeat that is natural but not vocal, or filtered speech that is vocal but not natural.


When an experiment uses native speech as the target and pure tones as the competitor, the preference emerging could be due to at least four conceptually separable differences across the two stimuli types: the target is speech whereas the competitor isn't, the target is  produced with a mouth (vocal) whereas the competitor isn't, the target is a natural sound whereas the competitor isn't, and the target is potentially more familiar than the competitor. Can preferences observed in the previous body of work be explained by one of these factors? 


If infants' (including newborns') preference is attributable to the fact that speech is a **vocal** sound, then effects when the competitor is another vocal sound will be smaller than when the competitor is not vocal. If it is driven by **naturalness**, then effects when the competitor is natural will be smaller than when it is not natural. Finally, if preferences are at least partly due to **familiarity**, then two predictions follow: effects should be larger when the target is the infant's native speech as opposed to foreign speech, and speech preference should increase with age. We aknowledge that any effect of age could also reveal neural maturation in regions involved in linguistic processing. In this study, we focus on the behavioral outcomes of this phenomenon and will not look at neural studies, which would require a different meta-analytic approach [but see @grossmann_developmental_2010 for an entry point to this literature]. Of course, it is also possible that the preference for speech cannot be reduced to any of the three aforementioned factors (i.e. vocal quality, naturalness, and familiarity), in which case effect sizes will not be modulated by such distinctions.  In addition, given that many previous empirical studies comment on changes with infant age, we pay special attention to the possibility that age modulates effect size in general, or specifically in conjunction with one of the aforementioned factors.


# Methods

This meta-analysis was carried out following PRISMA recommendations [@moher_preferred_2009]. In addition, we provide information on all steps (including PRISMA checklist, data, and code) for full transparency and accountability via online supplementary materials; https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8. 

## Literature search

We composed the initial list of papers with suggestions by experts (authors of this work); one google scholar search (*("speech preference" OR "own-species vocalization") AND infant - "infant-directed"*), the same search in PubMed and PsycInfo (last searched on 2019-09-24); and a google alert. We also inspected the reference lists of all included papers. Finally, we emailed a major mailing list to ask for missing data. We received two replies, one of which revealed a formerly undiscovered published study, and communicated unpublished data [@santolin_infants_2020].

## Inclusion criteria

As standard in systematic reviews, after a first screening based on titles and abstracts, we decided on final inclusion based on full paper reading. We included experiments that tested human infants from birth to one year of age, and contrasted speech sounds with any other type of sound, measuring behavioral preferences to the sounds (e.g., looking times). If a paper reported results from neurotypical and at-risk infants, we included only the data from the neurotypical group.

Given our key interest in the preference for speech over other sounds, we excluded studies that contrasted two different speech sounds (e.g., foreign vs. native language, or adult vs. child-directed speech, or mother vs. stranger's voice); or two different non-speech sounds (e.g., backward speech vs. animal vocalizations). In addition, we excluded experiments where the contrast presented to the infants could not be coded according to our three hypotheses (vocal, natural, familiar). This meant the exclusion of experiments where speech was presented in the mother’s voice (which confounds speech and individual voice recognition for our familiarity factor). Finally, we excluded neuroimaging experiments to avoid mixing results from different brain regions with different response profiles. We included published (i.e., journal articles) as well as unpublished works (i.e., doctoral dissertations) as long as sufficient information was provided. 

A PRISMA flow chart summarizes the literature review and selection process (Figure \@ref(fig:prisma)). The full list of the papers that were inspected together with final inclusion decisions are available in a decision spreadsheet (see the online supplementary materials; https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8).

```{r prisma, include=T, fig.dim=c(15,15), fig.cap = "PRISMA flowchart summarizing the literature review and selection process."}
knitr::include_graphics("figures_intro/PRISMA.png")
```

## Coding

Data were coded by the first author. In addition, 20% of the papers were randomly selected to be coded by the last author independently, with disagreements resolved by discussion. There were 10 disagreements out of a total of 260 fields filled in, and they were indicative of the coders not following the codebook, which led to a revision of all data in four variables. 

The critical variables for our purpose are key stimuli characteristics, infant age, and testing method (central fixation, high amplitude sucking, head-turn preference procedure). As for key stimuli characteristics, we coded vocal quality, naturalness, and familiarity, as follows.

For **vocal quality**, the competitor sound was considered as vocal if it was produced by an animal vocal tract (human or not), either original or modified. Vocal competitors included non-speech vocalizations, animal calls, bird song, and filtered speech. Non-vocal competitors included backward speech (that has abrupt closures that cannot be produced by a vocal tract), white-noise, environmental sounds, instrumental music, heartbeat, and sine-wave speech (that lacks the harmonic structure introduced by the natural resonance of the vocal tract). 

For **naturalness**, the competitor sound was coded as natural if it was produced by a biological organism without any further acoustic manipulation. Natural competitors included animal calls, environmental sounds (e.g. wind or water sounds), heartbeat, bird song, non-speech vocalizations (e.g. laughter or coughs)[^1]. If the authors applied acoustic manipulations, the competitor was coded as artificial. Artificial competitors included sine-wave speech, filtered speech[^2], white noise, instrumental music, and speech with altered rhythmic structure. The only exception was for newborn experiments presenting low-pass filtered speech mimicking the filtering applied by the womb. Given the recency of the intra-uterine environment to newborns (about 2 days), we coded these as natural. 


[^1]: Some stimuli used as competitors in the literature are both vocal and natural, such as bird song. Others don’t overlap, such as heartbeat, that is natural but not vocal.
[^2]: In the case of filtered speech, the modulations introduced by the vocal tract are still present at the retained frequencies, and formant transitions are consistent with vocal production constraints. For this reason, filtered speech can be considered as vocal but not natural. 

For **familiarity**, we considered the language in which the speech sounds were recorded (native or foreign). Because younger infants respond similarly to their native language and foreign languages within the same rhythmic class [@bertoncini_morae_1995; @mehler_precursor_1988; @nazzi_language_1998], infants would be expected to respond to a non-native language from the same rhythm class as their native native language similarly to a native language. We therefore took a careful look at our database to see, in the studies that used a foreign language as target speech sounds, whether the language belonged to the same rhythmic class as the infants’ native language or not. We found that all these studies but one used Japanese with English-learning infants, and the remaining one used Mandarin Chinese. Since Japanese is mora-timed, Mandarin syllable-timed, and English  stress-timed language, it turns out that all of the literature using a non-native language as target speech used samples from a different rhythmic class from the infants' native language. Given that there is no variability in rhythmicity, we did not code for linguistic rhythm. Also, according to standard interpretation, we can assume that even newborns would have distinguished the non-native speech from their own native language [see @gasparini_quantifying_2021 for a meta-analysis of language discrimination].

|         | Competitor sound  |
| ------------- |:-------------:| -----:|
| col 3 is      | right-aligned | $1600 |
| col 2 is      | centered      |   $12 |
| zebra stripes | are neat      |    $1 |

We coded all the statistical information reported in the included papers. If reported, we coded the mean score and the standard deviation for speech, and the other sound separately. When infant-level data was provided, we recomputed the respective mean scores and standard deviations based on the reported individual scores. If reported, we also coded the t-statistic between the two sound conditions, or an F-statistic provided this was a two-way comparison. If effect sizes were directly reported as a Cohen’s d or a Hedges' g, we also coded this. 

## Effect sizes

Once the data were coded, we extracted effect sizes, along with their respective variance. Effect sizes were standardized differences (Cohen’s d) between response to speech vs. the competitor.
If effect sizes were not directly reported in the papers, we computed them using the respective means and SDs [@lipsey_practical_2001], or a t- or F-statistic [@dunlap_meta-analysis_1996]. As our effect sizes came from within-subject comparisons (e.g., looking time of the same infant during speech and monkey calls), we needed to take into account the correlation between the two measurements in effect sizes and effect size variances computations. We computed this correlation based on the t-statistic, the respective means, and SDs [@lipsey_practical_2001] if they were all reported; or imputed this correlation randomly if not [@bergmann_development_2016]. We calculated the variance of each effect size using standard formulae [@lipsey_practical_2001]. Cohen's d were transformed to Hedges' g by multiplying d by a correction factor for small sample sizes based on the degrees of freedom [@borenstein_introduction_2011].

We did not center age because our hypotheses included a developmental progression from birth to the end of the first year of life. We were therefore interested in the intercept at age 0 (i.e., birth).

Analyses use the R [@r_core_team_r:_2018] package Robumeta [@hedges_robust_2010], which allows us to fit meta-analytic regressions that take into account the correlated structure of the data when repeated measures are obtained from the same infant groups within papers [@bergmann_promoting_2018]. 

# Results

## Database description

We found a total of `r length(papers)` publications (labeled with an asterisk in the reference list) reporting `r length(unique(DB2$same_infant))` experiments, for a total of `r sum(temp$n)` infants, and `r length(DB2$g_calc)` (not mutually independent) effect sizes. Regarding publication status, `r length(DB2$g_calc[DB2$peer_reviewed == 'yes'])` effect sizes came from `r length(unique(DB2$study_ID[DB2$peer_reviewed == 'yes']))` papers that have been published in peer-reviewed journals [@cooper_developmental_1994; @vouloumanos_tuned_2004; @vouloumanos_tuning_2010; @shultz_three-month-olds_2010; @colombo_method_1981; @vouloumanos_five-month-old_2009; @sorcinelli_preference_2019; @yamashiro_does_2020; @segal_listening_2011; @curtin_speech_2013; @vouloumanos_foundational_2014; @vouloumanos_listening_2007; @vouloumanos_tuning_2010; @spence_prenatal_1987; @ecklund-flores_asymmetric_1996; @santolin_role_2019; @vanden_bosch_der_nederlanden_infant_2021; @segal_infants_2021]. Additionally, a thesis contributed `r length(DB2$g_calc[DB2$peer_reviewed == 'no' & DB2$study_ID!="santolinUnpub"])` effect sizes  [@ference_role_2018], and `r length(DB2$g_calc[DB2$study_ID=="santolinUnpub"])`  effect sizes were contributed by authors of unpublished work [@santolin_infants_2020].


Experiments tended to have small sample sizes, with a median N of `r median(DB2$n)` children (Range = [`r min(DB2$n)`, `r max(DB2$n)`], M = `r mean(DB2$n)`), which is close to the field standard [@bergmann_promoting_2018], but much lower than current recommendations [@oakes_sample_2017]. Infants ranged from `r round(min(DB2$mean_age_1)/30.44)` to `r round(max(DB2$mean_age_1)/30.44)` months (`r min(DB2$mean_age_1)` to `r max(DB2$mean_age_1)` days), although the majority were under 6 months of age (`r length(unique(DB2$same_infant[DB2$age_months<=6]))/length(unique(DB2$same_infant))*100`% of the experiments). 


There was a fair representation of the factors most relevant to the theoretical hypotheses we aimed to assess. Speech stimuli were recorded in the infant native language in `r length(unique(DB2$same_infant[DB2$test_lang=='native']))/length(unique(DB2$same_infant))*100`% of the experiments. 
The competitor sound was vocal in `r length(unique(DB2$same_infant[DB2$vocal=='yes']))/length(unique(DB2$same_infant))*100`% of the experiments. The competitor sound was natural `r length(unique(DB2$same_infant[DB2$natural=='yes']))/length(unique(DB2$same_infant))*100`% of the experiments.  Although this means there is some data to assess each of the hypotheses, our systematic review also reveals that these factors are not very well separated in previous work (as an example, an experiment with native, and natural and vocal stimuli would be English-learning infants hearing English contrasted to monkey calls). To start with the most obvious case in which two theoretical explanations are hard to tease apart, there was only `r length(unique(DB2$same_infant[DB2$natural=='yes'& DB2$vocal=='no' ]))/length(unique(DB2$same_infant))*100`% of effects emerging from stimuli that were natural but not vocal (e.g. water sounds), `r length(unique(DB2$same_infant[DB2$natural=='no'& DB2$vocal=='yes' ]))/length(unique(DB2$same_infant))*100`% that we classified as vocal but not natural (e.g. filtered speech), `r length(unique(DB2$same_infant[DB2$natural=='no'& DB2$vocal=='no' ]))/length(unique(DB2$same_infant))*100`% that were neither natural nor vocal (e.g. white noise), and the rest that were both natural and vocal (`r length(unique(DB2$same_infant[DB2$natural=='yes'& DB2$vocal=='yes' ]))/length(unique(DB2$same_infant))*100`%, e.g. monkey calls). This means that if we find that both naturalness and vocal quality explain effect sizes, we cannot properly attribute variance to one or the other.

Less obvious is the fact that there are confounds across vocal, natural, and familiarity factors. Figure \@ref(fig:stimuli) shows that there are relatively fewer effect sizes in which foreign speech is contrasted against non-vocal sounds, and against non-natural sounds (e.g. English learning infants hearing Japanese contrasted to sine-wave speech), for which we have fewer than 10 (non-independent) effect sizes. Again, this means that it will be difficult to attribute unique variance to familiarity versus the other factors, if they emerge as significant predictors. In addition, we note that experiments using the infants' native language tested infants from the whole range covered in this meta-analysis (0 to 12 months of age), whereas experiments using a foreign language only tested infants from 3 to 9 months of age, a point to which return.




```{r stimuli, include=T, fig.show='asis', fig.cap = "Histograms of the number of effect sizes for each language and moderator status."}
hist_voc <- ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = vocal, fill = test_lang), position = 'dodge')+
  scale_fill_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  labs(x = "Vocal quality", y = "Number of effect sizes")+
  theme(text = element_text(size = 10))

hist_nat <- ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = natural, fill = test_lang), position = 'dodge')+
  scale_fill_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  labs(x = "Naturalness", y = "Number of effect sizes")+
  theme(text = element_text(size = 10))

grid.arrange(hist_voc, hist_nat, ncol=1, nrow=2)
```




Although not integral to our study, we report characteristics of discovered data along other dimensions, which are relevant when considering the likely generalizability of conclusions based on previous empirical work. Individual samples comprised `r round(mean(DB2$gender_1, na.rm=TRUE)*100)`% of female participants on average. Infants were native of 6 different languages across the whole database (English, French, Russian, Yiddish, Hebrew, Italian). 
Experiments were performed in 10 different laboratories from 4 different countries (United States, Canada, Israel, Italy). `r length(unique(DB2$method))` experimental methods were used: `r length(unique(DB2$same_infant[DB2$method=='CF']))/length(unique(DB2$same_infant))*100`% of the experiments used Central Fixation (CF, also called sequential looking preference procedure); `r length(unique(DB2$same_infant[DB2$method=='HAS']))/length(unique(DB2$same_infant))*100`% used High-Amplitude Sucking (HAS); and `r length(unique(DB2$same_infant[DB2$method=='HPP']))/length(unique(DB2$same_infant))*100`% used Head-turn Preference Procedure (HPP). Trial length was fixed in `r length(unique(DB2$same_infant[DB2$trial_length=='fixed']))/length(unique(DB2$same_infant))*100`% of the experiments, and infant-controlled in `r length(unique(DB2$same_infant[DB2$trial_length=='infant_controlled']))/length(unique(DB2$same_infant))*100`% of the experiments. 

Speech sounds were spoken by a female in `r length(unique(DB2$same_infant[DB2$talker_gender=='female']))/length(unique(DB2$same_infant))*100`% of the experiments, with an infant-directed prosody in `r length(unique(DB2$same_infant[DB2$prosody=='IDS']))/length(unique(DB2$same_infant))*100`% of the experiments. Speech was presented in isolated segments (i.e. words or syllables) in `r length(unique(DB2$same_infant[DB2$utterance_length=='words']))/length(unique(DB2$same_infant))*100`% of the experiments, and full sentences or passages in `r length(unique(DB2$same_infant[DB2$utterance_length=='passages']))/length(unique(DB2$same_infant))*100`% of the experiments (the remaining were unspecified).  The competitors covered a wide range of sounds, as represented in Figure \@ref(fig:competitors).


```{r competitors, include=T, fig.show='asis', fig.cap = "Histogram of the number of effect sizes for each competitor."}
ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = contrast_stim))+
   scale_y_continuous(limits = c(0, 10), breaks = seq(0,10,1))+
  theme_classic()+
  labs(x="Competitor sound", y = "Number of effect sizes")+
  theme(text = element_text(size = 15), legend.position = c(.9, .9),axis.text.x=element_text(angle=45, hjust=1))
```


## Average effect size

```{r forest, include=T, fig.cap = "Forest plot of effect sizes available in the literature, along with their respective moderator status. The average effect size is plotted on the bottom line. ",fig.width=7,fig.height=9.5}
#average variance / infant group to build models with CORR, and allow robumeta to detect correlated effect sizes within papers. 
DB2 = DB2 %>% group_by(same_infant) %>% mutate(g_var_m = mean(g_var_calc))

#AC added outlier removal bc I was getting errors

noutliers=sum(DB2$outlier)

DB2 = DB2[!DB2$outlier,]

# Model without moderators to get the average effect size
base_model <- robu(g_calc ~ 1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T) 

# same model with metafor for a nice forest plot 
simple_model <- rma(g_calc, g_var_calc, data=DB2, weighted = TRUE, method = "REML", subset=!DB2$outlier & !is.na(DB2$g_calc), slab =DB2$study_ID) 

forest.rma(simple_model, annotate = FALSE, xlim = c(-13,3), ylim = c(-1,54), order = 'obs',
       xlab = 'Effect size (Hedges\' g)', mlab = "", alim = c(-1.5,3), steps = 6, cex.axis = 0.6, cex.lab = 0.7, 
       ilab=cbind(round(DB2[!DB2$outlier,]$age_months, digits = 1), as.character(DB2[!DB2$outlier,]$method), as.character(DB2[!DB2$outlier,]$natural), as.character(DB2[!DB2$outlier,]$vocal), as.character(DB2[!DB2$outlier,]$test_lang), DB2[!DB2$outlier,]$n_1),
       ilab.xpos=c(-7.4,-6.2,-5,-3.8, -2.5, -1)) 
op <- par(cex=.5)
text(c(-7.4,-6.2,-5,-3.8, -2.5, -1), 53, c("age", "method", "natural", "vocal", "language", "sample size"))
```



Following standard analytic practice, we removed `r noutliers` outliers that were more than 3 standard deviations away from the mean (See Supplementary Materials S1 for more details on these outliers). We then integrated all effect sizes in a meta-analytic regression without any moderator, and found an average effect size g of `r base_model$reg_table$b.r` (SE = `r base_model$reg_table$SE`, CI = [`r base_model$reg_table$CI.L` , `r base_model$reg_table$CI.U`]) (see Figure \@ref(fig:forest) for the forest plot), corresponding to a medium effect size for the literature as a whole, which was significantly different from zero ($t$ = `r base_model$reg_table[,"t"]`, $p$ < .001).
<!-- `r base_model$reg_table[,"prob"]` -->
Heterogeneity among effect sizes was estimated at $\tau^2$ = `r simple_model$tau2` (I^2^ = `r simple_model$I2`%), which was significant (Q = `r simple_model$QE`, p < 0.01) despite the removal of outliers before running the model. This strongly suggest differences across experiments, and invites analyses using moderators.


## Publication bias

```{r bias, include = T, fig.cap="Funnel plot of effect sizes and their respective standard errors. Black dots: effect sizes observed in the literature. White dots: missing effect sizes, suggestive of a publication bias$^2$. Vertical line: average effect size after filling the missing effect sizes."}

#add symmetrize
tf <- trimfill(simple_model) 
funnel(tf, cex=1.5, xlab='Effect size (Hedges\' g)', ylab="Standard Error of Effect Size g", digits=2, legend=TRUE)

# testing for asymetry (indicates a publication bias)
SEg = regtest(DB2$g_calc,DB2$g_var_calc)
k = ranktest(DB2$g_calc,DB2$g_var_calc)

#Identify the missing ES filled
missing_ES = setdiff(tf$yi[1:63],DB2$g_calc[DB2$outlier==F])

```

Before proceeding with the moderator analysis, we checked for the presence of a potential publication bias in the body of literature by studying the relationship between standard errors of effect sizes as a function of Hedges’ g (see funnel plot in Figure \@ref(fig:bias))[^2]. A regression test on these data was significant (z = `r SEg$zval`, p < 0.01), as  was the Kendall's tau rank correlation test for funnel plot asymmetry (Kendall's tau = `r k$tau`, p < 0.01), consistent with a publication bias in the literature.


[^2]: If the literature is not biased, effect sizes should be evenly distributed around the mean effect size, with increasing standard error as they go away from the mean effect size (both in the positive and negative directions, white triangle in the funnel plot). This is reflected by a symmetrical funnel plot, with no linear relationship between effect sizes and standard errors. 

To check whether this bias fully explains speech preference in the extant body of literature, we  symmetrized the funnel plot with the “trim and fill” method [@duval_trim_2000]. To symmetrize the funnel plot, `r tf$k0` (SE = `r tf$se.k0`) missing experiments were needed on the left side of the plot. The corrected effect size was estimated at `r tf$beta[1,1]` (SE = `r tf$se`) after filling in the `r tf$k0` missing experiments, which is still significantly different from zero. Thus, even correcting for a potential publication bias, we still find statistical evidence for infants' preferring speech over competitors.

## Moderator analyses

We then tested if heterogeneity could be accounted for by the factors proposed in previous work (vocal, natural, familiar). There are two main ways of answering this question, and they  provide converging results. We start with the simplest analysis, in which a single meta-analytic model is fit with the following moderators: 

- mean age of children;
- vocal quality of the competitor sound (coded as yes if it was vocal and no otherwise);
- naturalness of the competitor sound (coded as yes if it was natural and no otherwise);
- familiarity with the language used (native or foreign).

These moderators were specified without interactions with each other both to avoid overfitting and because they were sometimes confounded in previous work, as described previously. None of the moderators was significant in this analysis (see Table \@ref(tab:Table2)).

```{r moderators}
#distribution of moderators
table(DB2$natural)#no. of natural and non-natural data points
table(DB2$vocal)#no. of vocal and non-vocal data points
table(DB2$homospecific)#no. of homo- and heterospecific data points
table(DB2$test_lang)
table(DB2$homospecific,DB2$vocal)
table(DB2$natural,DB2$vocal)
table(DB2$contrast_stim)

#setting up of predictors 
#http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/

#check that the experimental method doesn't make a difference
DB2$method = factor(DB2$method)
relevel(DB2$method,"HAS")->DB2$method #put HAS as the 1st level
#dummy coding: each level is compared to a reference level of the dependent variable, intercept corresponds to the reference level.
contrasts(DB2$method) = contr.treatment(length(levels(DB2$method)),base=1) #baseline method should be HAS because it's the one used with newborns

#moderators of interest
DB2$test_lang = factor(DB2$test_lang)
contrasts(DB2$test_lang) <- contr.treatment(length(levels(DB2$test_lang)),base=1)

DB2$natural = factor(DB2$natural)
contrasts(DB2$natural) <- contr.treatment(length(levels(DB2$natural)),base=2)

DB2$vocal = factor(DB2$vocal)
DB2$vocal <- factor(DB2$vocal)
contrasts(DB2$vocal) <- contr.treatment(length(levels(DB2$vocal)),base=2)
table(DB2$natural,DB2$vocal,DB2$test_lang)
summary(table(DB2$natural,DB2$vocal,DB2$test_lang))#super significant, these are correlated!


# model with moderators of interest. 

full_model <- robu(g_calc ~ mean_age_1 +  vocal + natural + test_lang , data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)


```

 

```{r Table2, results="asis", include=T} 

table2 = rbind(full_model$reg_table[1:5,c(2:4,7:8)])
rownames(table2)=c('intercept','naturalness','vocal quality','language','age')

table2[,4]=paste0(round(table2[,4],2)," - ",round(table2[,5],2))
table2=table2[,-5]

apa_table(table2, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with all moderators. The intercept corresponds to the effect size when the competitor is natural, and vocal, and speech is in a foreign language, at age 0. The moderator estimates correspond to changes in the intercept when the target stimuli are in the native language (familiarity); the competitor is artificial (naturalness); and the competitor is non-vocal (vocal quality).", escape= T)
```




```{r vocal, include=T, fig.show='asis', fig.cap="Effect sizes as a function of age and vocal quality of the competitor. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("red3","skyblue"), labels = c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

# stim = knitr::include_graphics("voc-nonvoc.png")
# 
# grid.arrange(stim, scatter, ncol=2, nrow=1)
```

```{r TableVocal, results="asis", include=T} 

model_vocal <- robu(g_calc ~ vocal*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_voc = rbind(model_vocal$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_voc)=c('intercept','vocal quality','vocal quality*age')

table_voc[,4]=paste0(round(table_voc[,4],2)," - ",round(table_voc[,5],2))
table_voc=table_voc[,-5]

apa_table(table_voc, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with vocal quality and its interaction with age as moderators. The intercept corresponds to the effect size when the competitor is vocal, at age 0. The moderator estimates correspond to changes in the intercept when the competitor is non-vocal (vocal quality).", escape= T)
```



```{r natural, include=T, fig.show='asis', fig.cap="Effect sizes as a function of age and natural quality of the competitor. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$natural),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#stim = knitr::include_graphics("Natural-artificial.png")

#grid.arrange(stim, scatter, ncol=2, nrow=1)
```

```{r TableNatural, results="asis", include=T} 

model_natural <- robu(g_calc ~ natural*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_nat = rbind(model_natural$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_nat)=c('intercept','naturalness','naturalness*age')

table_nat[,4]=paste0(round(table_nat[,4],2)," - ",round(table_nat[,5],2))
table_nat=table_nat[,-5]

apa_table(table_nat, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with naturalness and its interaction with age as moderators. The intercept corresponds to the effect size when the competitor is natural, at age 0. The moderator estimates correspond to changes in the intercept when the competitor is artificial (naturalness).", escape= T)
```


```{r lang, include=T, fig.show='asis', fig.cap="Effect sizes as a function of age and familiarity with the speech sounds. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("#FF8E06","#005C96"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

# stim = knitr::include_graphics("native-foreign.png")
# 
# grid.arrange(stim, scatter, ncol=2, nrow=1)
```

```{r TableLang, results="asis", include=T} 

model_lang <- robu(g_calc ~ test_lang*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_lang = rbind(model_lang$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_lang)=c('intercept','language','language * age')

table_lang[,4]=paste0(round(table_lang[,4],2)," - ",round(table_lang[,5],2))
table_lang=table_lang[,-5]

apa_table(table_lang, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with language of the speech sounds and interaction with age. The intercept corresponds to the effect size when speech is in a foreign language at age 0. The moderator estimate correspond to changes in the intercept when the target stimuli are in the native language.", escape= T)
```

Another way of answering our key research question is by fitting a separate meta-regression model for each moderator and its interaction with age. Once again, we observe no significant main effect (nor interaction with age) for any of our predictors (Tables \@ref(tab:TableVocal), \@ref(tab:TableNatural), \@ref(tab:TableLang)). Even though neither main effects or interactions with age were significant, we thought readers would be interested in assessing the extent to which results visually fit expectations from the literature summarized in the Introduction. To begin with the vocal quality of the competitor, the expectation is that effect sizes will be smaller for a contrast between speech and vocal at birth, than speech and non-vocal at the same age; and as infants age, the contrast between speech and vocal should become larger. Neither expectation fits Figure \@ref(fig:vocal), where, if anything, the contrast between speech and non-vocal competitors is larger at birth than that of speech and vocal competitors. As for naturalness of the competitor, if infants prefer speech because it is natural, then we should see smaller effects for the contrast against natural than that for non-natural. That is again not the case:  Figure \@ref(fig:natural) shows overlap across the effect sizes of these two types of experiment. Finally, if infants' speech preference is driven by familiarity, then effect sizes should be larger when native as opposed to foreign speech is used, and this contrast should be larger as infants age. The trends in Figure \@ref(fig:lang) are visually consistent with these predictions, with a positive slope for the native conditions and negative for the foreign conditions. However, it is clear that there is a great deal of overlap between the two curves, and key data (below three and above nine months, particularly gathered with foreign speech) would complete the picture. 

```{r other plots}
vio_method <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=method, y=g_calc))+
  geom_violin(aes(fill=method), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=method, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.2, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "method", labels=levels(DB2$method), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#Effect of naturalness
vio_nat <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=natural, y=g_calc))+
  geom_violin(aes(fill=natural), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=natural, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", labels=c("artificial","natural"), na.translate = FALSE)+
  scale_fill_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

facet_natural <- ggplot(data=DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("mediumvioletred","green3"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

# Effect of vocalness
vio_voc <- ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=vocal, y=g_calc))+
  geom_violin(aes(fill=vocal), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=vocal, y=g_calc, size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), position=position_jitter(w=0.1, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", na.translate = FALSE, labels = c("non-vocal", "vocal"))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("turquoise2","tomato"), labels=c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15))

facet_vocal<-ggplot(data=DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("turquoise2","tomato"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

#Effect of familiarity with the speech sounds? Nativeness (test_lang) and age.
ggplot(data=DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("red3","skyblue"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

vio_lang <- ggplot(data=DB2[!is.na(DB2$test_lang),],aes(x=test_lang, y=g_calc))+
  geom_violin(aes(fill=test_lang), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=test_lang, y=g_calc, size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "speech sound", labels=c("foreign","native"), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20))

#violin plot / contrasted sound
vio_contrast <- ggplot(data=DB2[!is.na(DB2$contrast_stim),],aes(x=contrast_stim, y=g_calc))+
  geom_violin(aes(fill=contrast_stim), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=contrast_stim, y=g_calc, size=1/DB2[!is.na(DB2$contrast_stim),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "contrast sound", na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  #scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20), axis.text.x = element_text(angle = 45, size = 10))

```


# Discussion

Our meta-analysis synthesizes the available literature on infants’ preference for speech sounds. When all experiments were considered together with no moderators, we found a sizable intercept (g=`r base_model$reg_table$b.r`, g=`r tf$beta[1,1]` when taking the publication bias into account), which was still significant after correcting for the publication bias. Our meta-analysis shows that this preferential processing of speech sounds is observable from birth on. It is important to stress that this conclusion is not trivial because others have said similar things in the past: One key advantage of meta-analysis over conclusions drawn from individual studies or unsystematic narrative reviews is that we can actually measure the likely presence of publication bias (which *is* present in these data, as we discuss below), and furthermore compensate for this bias statistically, to see if an effect remains significant after doing so [@cristia_meta-analytic_2021; see also @ioannidis_why_2005].

The significant heterogeneity we found among the literature suggests that underlying factors modulate this effect. Based on previous theoretical claims, one would have predicted infants' speech preference to be larger when the competitor was non-vocal; when the competitor was an artificial sound than when it was a natural one; and when the speech was in the infants' native language. In fact, we were unable to disprove the null hypothesis of no difference for all three factors. Thus, although these explanations are conceptually appealing, it does not appear to be the case that we can reduce infants' speech preference to a bias for vocal, natural, or familiar sounds.


Also based on theoretical claims in the literature, we had expected age to play a major role. Indeed, experiments comparing the preference for human speech against human non-speech as well as animal vocalizations more generally [@vouloumanos_tuning_2010; @mcdonald_infant_2019] often discuss age-related differences in categorization of these sounds. Surprisingly, age did not significantly moderate the overall preference for speech, as shown by the null estimate of this moderator (Table \@ref(tab:Table2)), nor did it interact with any other moderators (Tables \@ref(tab:TableNatural), \@ref(tab:TableLang), and \@ref(tab:TableVocal), and corresponding figures). This result was replicated in a separate model declaring age as the only moderator, which showed a significant intercept, similar in size to the intercept found in the meta-regression with no moderator (Supplementary results S3). 
Crucially, in this supplementary analysis, age was not centered so that this intercept  provides an estimate of the effect size at age 0, i.e. at birth. 
Moreover, the scatterplot of effect sizes as a function of age reveals clearly no change with age even when plotted without other moderators (Supplementary figure S4). This null effect of age, combined with the sizable intercept, confirms that infants reliably prefer speech over other types of sounds stably across the age range covered by previous literature.

For all of our analyses, concerning vocal quality, naturalness, familiarity, and age, it is important to remember that, by aggregating the numerous individual studies of a literature, meta-analyses gain statistical power as compared to individual experiments. As such, meta-analytic results have more cumulative explanatory value than single studies. 


Our meta-analysis revealed uneven distributions of experiments across age and stimulus dimensions, and that the distribution of effect sizes in the literature is consistent with publication bias. Moreover, distributions of effect sizes for experiments varying along the three dimensions widely overlap. 


This clearly points to the value of meta-analysis: to take stock of a field and inspire follow-up studies. In particular, future experiments should test infants from 1 to 3 months, and older than 9 months. Language production gains in complexity at about 9 months [@oller_precursors_1999], which could affect infants' speech preference. In adults, speech perception is modulated by the participant’s own speech production [e.g. @assaneo_speaking_2020]. During development, auditory feedback, coming from infants hearing their own speech, could refine auditory perception, by comparing the auditory feedback to an internal model of speech sounds, which would in turn generate a prediction error. As a result, infants’ preference for speech could increase, especially when contrasted to other natural or vocal sounds. It is therefore possible that the effect investigated here (namely that the vocal or natural quality of the competitor sound modulates infants preference for speech) would emerge after 9 months. We hope that this meta-analysis will encourage laboratories to test this hypothesis by running the missing studies. Experiments using natural vocal stimuli as competitor, and foreign speech as target, would contribute to filling the gap in the literature that our meta-analysis revealed. In addition, no experiment in the literature tested newborns with human vocal sounds, such as coughing, or animal vocalizations other than monkey calls. It is therefore not possible to know if newborns did not prefer speech from monkey calls because infants have an initial preference for primate vocalizations (as proposed), or for vocal sounds in general (human or not). Our dataset can be community-augmented, and we invite researchers investigating this phenomenon to complement it with any data they would have (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8), whatever the results and publication status, to address the current publication bias currently affecting this body of work, and potentially revisit the research question that motivated the present study.

Another way in which additional studies could help is by boosting power. Infant language development meta-analyses rely on studies with smaller sample sizes than other meta-analyses in psychology, based on a comparison of a meta-meta-analysis of infant studies (Bergmann et al., 2018; median sample size = 18) and one in psychology in general (Cafri et al., 2010; median sample size = 231). Smaller sample sizes result in larger variance for individual studies, and effect sizes that are more heterogeneous (more dispersion at the literature level), and potentially more unexplained variance between studies (i.e. variance that is not explained by moderators).  This predicts that statistical power in infant meta-analyses should be lower than in meta-analyses of adults (Cafri et al., 2010). Consistently with this prediction, we found a significant heterogeneity in our data, and moderators that did not explain a significant amount of variance (i.e. moderators were not significant).  It is therefore crucial to run the missing experiments our meta-analysis revealed, adjusting sample size for 80% power based on the average effect size we found. 

Our results suggest that, from birth on, infants show a preference for speech, which cannot be accounted by the three explanations tested here: vocal quality, naturalness, or familiarity with the native language. It is possible that infants prefer speech because of its complex acoustic structure and fast transitions [@rosen_constructing_2007]. Spectral or temporal modulations taken separately are not sufficient to elicit neural responses similar to the ones elicited by speech [@minagawa-kawai_assessing_2011]. However, speech is characterized by joint spectrotemporal modulations at specific rates [@singh_modulation_2003]. It is possible that infants are sensitive to this specific spectro-temporal structure [though see @norman-haignere_neural_2018 showing that they only explain neural responses in primary auditory cortex, suggesting that other factors contribute to the behavioral response in later processing stages]. Testing this explanation would require to compute the modulation spectra of the actual stimuli used in the experiments. Thus, we recommend interested researchers to deposit their stimuli in a public archive such as the Open Science Framework [@foster_open_2017].

A stable preference for speech in infancy is compatible with the idea that infants are born with the capacity to recognize their conspecifics’ communication signals. This parallels what has been proposed for faces: Infants are born with the capacity to orient their attention toward them, even without any prior exposure to faces [@morton_conspec_1991; @turati_why_2004]. 
This would stem from basic perceptual abilities present at birth, namely that the visual system would be tuned to a spatial structure that correspond to those of faces [@morton_conspec_1991; @turati_why_2004]. As newborns have never been exposed to such visual stimuli before, it would reflect general properties (i.e. filters) of the visual system. Similarly, the auditory system could be tuned to a spectro-temporal structure that speech presents. The combination of this non-specific bias with the systematic variations of the auditory environment (i.e. the fact that an acoustical structure characterizes speech but not other sounds of the environment) would result in preferential responses to speech from birth. However, contrary to faces, fetuses are exposed to speech low-pass filtered by the womb throughout the last trimester of gestation [@querleu_fetal_1988; @lecanuet_speech_1993]. It is therefore possible that prenatal experience with low-pass filtered speech helps infants to form a representation of speech, by tuning the response properties of the auditory system to speech.
The fact that familiarity with the language used in the experiment did not modulate infants’ preference suggests that this effect is not triggered by familiarity with the sounds of the native language. Infants would therefore form a representation that is specific enough to discriminate speech from other natural or vocal sounds, but general enough to be independent of the language spoken.

The human species is a gregarious one. Detecting speech signals allows to integrate it with other sensory percepts, such as faces, to form multisensory representations of conspecifics. Five-months old infants were capable to match human faces to speech, as well as monkey faces to monkey vocalizations [@vouloumanos_five-month-old_2009]. This provides evidence that human infants make correspondences between faces and vocalizations, and that they distinguish their conspecifics from other species. This lays the groundwork for social cognition. Finally, the preference itself may also be a meaningful index of processing that can be used to identify children at risk [@sorcinelli_preference_2019]. Understanding this phenomenon is therefore crucial for both theoretical and clinical advances.

Ultimately, preferential processing of speech may support higher level cognitive tasks. Identifying speech signals and paying attention to them would allow infants to form complex representations of the sensory world, that they can manipulate cognitively. Consistently, infants could categorize visual stimuli (i.e., associate a label to a category of objects) when they were associated to speech, but not pure tones or backward speech [@fulkerson_words_2007; @ferry_categorization_2010; @ferry_nonhuman_2013]. Interestingly, infants categorized visual stimuli when presented with speech, melodies, monkey [@fulkerson_influence_2003], or lemur vocalizations [@ferry_nonhuman_2013]. These results support the idea that infants' cognition is set up to respond to, and manipulate complex sounds (i.e. modulated in time and frequency), especially those of critical ecological importance such as communicative vocalizations. 

With a sample size of `r sum(temp$n)` infants, covering the wide age range of all individual experiments available, our meta-analysis provides evidence for a specialized processing of speech from birth. This parallels infants' attention to faces from birth [@morton_conspec_1991; @turati_why_2004], and suggests that human cognition is set up to pay attention to signals from conspecifics specifically. Such systems may be the precursors of humans' advanced social cognition skills. 


```{r suplementary}
model_age <- robu(g_calc ~ mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(method = "glm", na.rm = TRUE, color='gray40', aes(alpha=0.3))+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = 'none')

model_prosody <- robu(g_calc ~ prosody * mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc, colour=prosody))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("#ff00a0","#820000","#5c6b63"), labels = c("ADS","IDS","NA"), name = "prosody")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))
```



\newpage
# References
<!-- # References -->
<!-- # ```{r create_r-references} -->
<!-- # r_refs(file = "r-references.bib") -->
<!-- # ``` -->

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

References marked with an asterisk indicate studies included in the meta-analysis.

<div id = "refs"></div>
\endgroup
