---
title             : "Infants’ preference for speech decomposed: Meta-analytic evidence"
shorttitle        : "Preference for speech sounds in infancy"

author: 
  - name          : "Cécile Issard"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Laboratoire de Sciences Cognitives et Psycholinguistique, Département d'Études Cognitives, Ecole Normale Supérieure, 29 rue d'Ulm, 75005 Paris, France"
    email         : "cecile.issard@gmail.com"
  - name          : "Sho Tsuji"
    affiliation   : "2"
  - name          : "Alejandrina Cristia"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Laboratoire de Sciences Cognitives et Psycholinguistique, Ecole Normale Supérieure, Département d'Études Cognitives"
  - id            : "2"
    institution   : "International Research Center for Neurointelligence, The University of Tokyo"

authornote: |
  This work was supported by an Agence Nationale de la Recherche grant to A.C. (ANR-17-CE28-0007 LangAge, ANR-16-DATA-0004 ACLEW, ANR-14-CE30-0003 MechELex, ANR-17-EURE-0017); and the J. S. McDonnell Foundation Understanding Human Cognition Scholar Award to A.C.
  
  The authors declare no conflict of interest. Funding sources did not take part in study design, data collection or analysis.
  
  Our data is fully available in the corresponding OSF repository: http://tidy.ws/bqjc4U
  
abstract: |
 Previous experimental work suggested that infants initially prefer a broad range of natural or vocal sounds, and then tune in to speech. To check whether this explanation holds for the entire body of literature, we conducted a meta-analysis of experiments testing speech preference in infants. Infants reliably preferred speech over other sounds, but this preference was not significantly moderated by vocal quality, or naturalness of the competitor. We found no effect of age: infants showed the same strength of preference throughout the first year of life. Speech therefore appears to be preferred from birth, even to other natural or vocal sounds. These results contradict current views of the literature, and call for further investigation of the phenomenon.
  
keywords          : "Meta-analysis, infants, speech preference, auditory development, natural sounds"
wordcount         : ""

bibliography      : ["bibliography.bib"]
csl: https://tinyurl.com/apa6-meta-analysis

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include=F}

knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = FALSE, echo = FALSE, include = F) #options for all the code chunks of the document.

source("data_completion.R", chdir = TRUE)  #chdir stands for "change directory"

library(metafor)
library(robumeta)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(grid)
library(gridExtra)
library(RCurl)
library(papaja)

sessionInfo()


read.csv('speech_pref_full_DB.csv')->DB

DB2 = DB[DB$method!='PL' & !is.na(DB$g_calc),] #keep only the behavioral experiments, remove NAs.

#Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
DB2$outlier[DB2$g_calc > mean(DB2$g_calc, na.rm = TRUE) + 3*sd(DB2$g_calc, na.rm = TRUE) | DB2$g_calc < mean(DB2$g_calc, na.rm = TRUE) - 3*sd(DB2$g_calc, na.rm = TRUE)]<-T 

#unique experiments
papers <- levels(factor(DB2$short_cite))

#number of unique infants
DB2$n<-rowSums( cbind (DB2$n_1,DB2$n_2), na.rm=TRUE)
temp<-aggregate(n~same_infant,DB2,mean)

summary(DB2$mean_age_1)
```
# Highlights

- Infants reliably prefer natural speech over other types of sounds, from birth to the end of the first year of life
- Speech is preferred over both artificial and other natural sounds
- Speech is preferred over both non-vocal and other vocal sounds
- The difference between whether infants are familiar or not with the language used was not significant

# Introduction

Acoustic communication is a crucial behavior in humans that support social interactions. Given its significance, previous work argued for an early precursor of such social communication, manifested as an early preference for speech over other types of sound [@vouloumanos_listening_2007;@vouloumanos_tuning_2010;@ecklund-flores_asymmetric_1996]. This auditory bias would initially encompass a broad range of natural or vocal sounds (Figure \@ref(fig:venn)), and then tune in to species-specific communicative vocalizations, namely speech [e.g. @ferry_nonhuman_2013; @shultz_three-month-olds_2010; @shultz_neural_2014; @vouloumanos_tuning_2010; @vouloumanos_tuned_2004]. However, other factors might also explain it. Here, we synthesize the available empirical data on infants’ preferences for speech over non-speech sounds to assess the explanatory role of several factors cited in the literature. 

```{r venn, include=T, fig.cap="Speech is a natural, vocal sound."}
knitr::include_graphics("/Users/Cecile/Documents/MA_speech_pref/figures_intro/Venn.png")
```

## Potential dimensions underlying preference patterns

Speech is a complex signal that varies on many dimensions from other natural vocal sounds. In order to understand how infants come to prefer speech, researchers have looked at several prominent ways in which speech differs from other sounds, especially the following three: familiarity, naturalness, and vocal quality. We will review the extant literature on these, as well as changes over development.

### Familiarity

A first hypothesis is that infants prefer speech to other sounds since it is a frequent sound in their experience. Newborns prefer their native speech to prosodically distinct foreign speech [e.g., @mehler_precursor_1988; @moon_two-day-olds_1993], which supports a preference for sound patterns heard frequently in the womb. If this was indeed the case, infants would show a stronger preference for speech over other sounds when tested in their native language, and a weaker preference when tested with a foreign language. Two different experiments testing three-month-old infants with the same stimuli found a similar amount of preference as compared to monkey calls whether speech was in the native language [@vouloumanos_tuning_2010] or a foreign language [@shultz_three-month-olds_2010], but results from neuroimaging experiments provide contradictory evidence. Newborns' brain activation was different for forward than backward speech when the native language was used as the speech stimuli, but not when a foreign language was used [@may_specificity_2018]. Qualitative review does therefore not provide clear evidence for familiarity as a driving factor of infants' preference for speech. As these experiments used very different competitors, it is likely that familiarity with the language used interacts with properties of the competitor to drive infants' preference for speech. 

### Naturalness

A second hypothesis postulates a preference for natural over artificial sounds. Natural sounds are those produced by biological systems, such as heart beat, the sound of walking, or animal vocalizations, and environmental/geophysical sounds, such as wind, rain, or the sound of a river. Natural sounds are processed more efficiently by the auditory system, from the cochlea [@smith_efficient_2006] to the auditory cortex [see @mizrahi_single_2014 for a review]. As a result, this should be reflected in infants behavior, with a preference for natural sounds, including speech, over artificial competitors from birth. Consistently, newborns increased their sucking rate more during speech than during an artificial equivalent, sine-wave speech [@vouloumanos_listening_2007], and three-month-olds did not listen significantly longer to speech than to another type of natural sound, environmental sounds [@shultz_three-month-olds_2010]. However, other experiments demonstrate that infants still prefer speech over other natural sounds. Three-month-olds listened longer to speech than to water sounds [@shultz_three-month-olds_2010], and newborns made more head-turns to speech than to heartbeat [@ecklund-flores_asymmetric_1996]. These results suggest that being a natural sound can be a contributing factor, but not the only explanation for infants' speech preference. 

### Vocal quality

Perhaps the most widely cited hypothesis across the literature is that of an initial preference for vocal sounds in general, that later restricts to speech [e.g. @vouloumanos_tuning_2010]. Vocal sounds are characterized by modulations introduced by the vocal tract, with harmonically related energy peaks. In contrast, backward speech has unnatural formant transitions and seemingly abrupt closures that cannot be produced by the vocal tract[^1]. Accordingly, newborns listened equivalently to speech and monkey calls [@vouloumanos_tuning_2010], and neuro-imaging results failed to report differential response to speech, human non-communicative vocalizations, and rhesus calls in 1- to 4-month-old infants [@shultz_neural_2014].

[^1]: In the case of filtered speech, the modulations introduced by the vocal tract are still present at the retained frequencies, and formant transitions are consistent with vocal production constraints. For this reason, filtered speech can be considered as vocal but not natural. Because the womb acts as a low-pass filter, newborn infants are familiar with low-pass filtered speech, but this familiarity fades after birth.

## Changes as a function of development

Development may affect the preference for speech in various ways. Whereas newborns do not prefer speech over monkey calls, there is some evidence that three-month-olds do [@vouloumanos_tuning_2010, but see @shultz_neural_2014]. This suggests that as they age, infants might develop an increasingly narrow definition of the stimulus they prefer. In this case  naturalness, familiarity, and vocal quality effects might differentially change as a function of age:  Very close stimuli (e.g., speech versus another natural sound) initially leads to a weak preference, but, as infants age, this preference may be as strong as that found for very different stimuli (e.g., speech versus an artificial sound).
Many articles discuss potential changes in the pattern of preference as a function of age [e.g. @ferry_nonhuman_2013; @shultz_three-month-olds_2010; @shultz_neural_2014]. However, statements about the factors driving this phenomenon are often done using the demonstrably problematic method of concluding that there is an interaction without actually testing for it statistically [e.g. @gelman_difference_2006]. To our knowledge, only two papers from the same laboratory include multiple age groups tested with the exact same stimulus categories and procedure [@vouloumanos_tuning_2010; @vouloumanos_tuned_2004]. It is therefore important to directly test these statements with larger datasets, ideally across the whole literature.


## A meta-analytic approach

In sum, previous work on infants' preferences is compatible with preference for natural over artificial, vocal over non-vocal, and familiar over unfamiliar sounds, potentially interacting with infants' age. In this paper, we seek to directly test these interpretations of the literature by employing a meta-analytic approach. A meta-analysis allows direct comparison of data otherwise hard to compare, weights the data, and allows to integrate more factors at once than a single study can. 

Meta-analyses are quantitative syntheses of experiments testing a comparable phenomenon with comparable approaches. As such, they can reveal small effects not obvious in individual experiments by combining them to obtain larger samples. By integrating data across different laboratories, they provide evidence for the generalizability of effects across labs, and facilitate comparisons between experimental results.

Meta-analyses can also involve combining experiments that may vary in their methodology. Specifically for the present case, a meta-analysis allows to statistically test different explanations. We can test the effect of factors that are not part of the original design, by redescribing the stimuli used as a function of those factors. For instance, a study measuring preference for native speech over native backward speech provides data on a natural versus artificial, as well as a vocal versus non-vocal contrast. One limitation is that one cannot isolate specific variables as well as in direct experimentation, and meta-analyses may miss subtle effects due to specific stimuli. However, the larger number of infants included in meta-analyses allows to integrate more factors in the same analysis than individual experiments.
We can also draw a developmental timeline across the age range covered by the literature, beyond age groups tested within papers. 

Meta-analyses can even provide theoretical and empirical insights that nuance qualitative reviews. For example, it has been proposed that infants’ preference for novel or familiar items related to infants' age such that, all things equal, younger infants showed familiarity preferences whereas older infants exhibited novelty preferences [@hunter_multifactor_1988]. However, @bergmann_development_2016 found stable familiarity preferences for word segmentation in natural speech across the first two years; and @black_quantifying_2017 found a stable novelty effect for artificial grammars implemented in synthesized speech, whereas those implemented in natural speech led to stable familiarity preferences. Meta-analyses are therefore important to statistically and systematically test the theoretical predictions proposed in qualitative reviews, and refine current readings of a literature.

Finally, meta-analyses offer tools to detect publication bias in the literature. By aggregating all the available evidence for a phenomenon, we can see if the distribution of effect sizes has an unexpected shape, typically with an excess of positive results due to the difficulty to publish null or negative results. 

## The present study

To shed light on the question of infant speech preference, we conducted a meta-analysis to test whether infants' preference for speech over other types of sounds is reliable, whether the factors in the signal cited in the literature (naturalness, vocal quality, and familiarity, as a function of age) drive this prefence, and how it develops over the first year of life. Assuming all three factors are true, and further assuming that the definition of the preferred stimulus narrows with age, we predicted that infants will show (see Figure \@ref(fig:hyp)): 

1. a greater preference for native speech over non-speech as a function of age, but a smaller preference for foreign speech over non-speech with age; 
2. a greater preference for speech over other natural sounds as a function of age, but a preference for speech over artificial sounds that is stable over development;
3. a greater preference for speech over other vocal sounds as a function of age, but a stable preference for speech over non-vocal sounds over development.

```{r hyp, include=T, fig.cap = "Hypothesized pattern of preference: the x axis shows age, the y axis represents the effect size derived from the contrast between a speech condition and a competitor condition (preference for speech over the competitor is plotted up; the lower quadrants are empty because we do not predict a preference for the competitor over speech). A: Speech contrasted to natural (green) or artificial (purple) competitors. B: Speech contrasted to vocal (orange) or non-vocal (cyan) competitors. C: Collapsing across competitors, separating speech in a foreign language (red); speech in the native language (blue)."}
knitr::include_graphics("/Users/Cecile/Documents/MA_speech_pref/figures_intro/hypotheses.png")
```

We also want to give an overview of potential gaps in the literature: It is possible that the literature has gathered more evidence on one than another factor, and in one than another age range. For scientific progress it is crucial to identify such potential gaps, in order to get a better idea of how we need to proceed to find reliable answers.

# Methods

## Literature search

We composed the initial list of papers with suggestions by experts (authors of this work); one google scholar search (*("speech preference" OR "own-species vocalization") AND infant - "infant-directed"*), the same search in PubMed and PsycInfo (last searched on 2019-09-24); and a google alert. We also inspected the reference lists of all included papers. Finally, we emailed a major mailing list to ask for missing data. We received only two replies, one of which revealed a formerly undiscovered published study, but no unpublished data was made available to us.

## Inclusion criteria

After a first screening based on titles and abstracts using more liberal inclusion criteria, we decided on final inclusion based on full paper reading. We included experiments that tested human infants from birth to one year of age, and contrasted speech sounds with any other type of sound, measuring behavioral preferences to the sounds (e.g., looking times). We excluded experiments that did not contrast speech to another sound type, such as experiments contrasting two different speech sounds (e.g. foreign against native language, or adult vs. child-directed speech), or on the opposite did not present natural speech sounds at all (e.g. backward speech vs animal vocalizations). We excluded experiments that presented speech in the mother’s voice to avoid counfounds between speech and individual voice recognition. Experiments that intentionally mixed speech with other vocal sounds within the same sound condition were also excluded. Finally, we excluded neuroimaging experiments to avoid mixing results from different brain regions with different response profiles. The full list of the papers that were inspected but excluded is available in the supplementary materials (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8). We included published (i.e., journal articles) as well as unpublished works (i.e., doctoral dissertations) as long as sufficient information was provided. 

A PRISMA flow chart summarizes the literature review and selection process (Figure \@ref(fig:prisma)). We documented all the papers that we inspected in a decision spreadsheet (available in the online supplementary materials; https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8).

```{r prisma, include=T, fig.cap = "PRISMA flowchart summarizing the literature review and selection process."}
knitr::include_graphics("/Users/Cecile/Documents/MA_speech_pref/figures_intro/PRISMA.jpg")
```

## Coding
The critical variables for our purpose are infant age, methodological variables (testing method: central fixation, high amplitude sucking, head-turn preference procedure), and key stimuli characteristics. Specifically, we coded the language in which the speech sounds were recorded (native or foreign), and  whether the sound opposed to speech was natural or not, as well as vocal or not. 
This competitor was coded as natural if it was produced by a biological organism without any further acoustic manipulation Natural competitors included animal calls, environmental sounds (e.g. wind or water sounds), heartbeat, bird song, non-speech vocalizations (e.g. laughters or coughs). If the authors applied acoustic manipulations it was coded as artificial. Artificial competitors included sine-wave speech, filtered speech, white noise, instrumental music, and speech with altered rhythmic structure. The only exception was for newborn experiments presenting low-pass filtered speech mimicking the filtering applied by the womb. Given the recency of the intra-uterine environement to newborns (about 2 days), we coded these as natural. 
The competitor sound was considered as vocal if it was produced by an animal vocal tract (human or not), either original or modified. Vocal competitors included non-speech vocalizations, animal calls, bird songs, and filtered speech. Non-vocal competitors included backward speech (that has abrupt closures that cannot be produced by the vocal tract), white-noise, environmental sounds, instrumental music, heartbeat, and sine-wave speech (that lacks the harmonic structure introduced by the natural resonance of the vocal tract). 
If a paper reported results from neurotypical and at-risk infants, we coded only the data from the neurotypical group.

Data were coded by the first author. In addition, 20% of the papers were randomly selected to be coded by the last author independently, with disagreements resolved by discussion. There were 10 disagreements out of a total of 260 fields filled in, and they were indicative of the coders not following the codebook, which led to a revision of all data in four variables. 

We coded all the statistical information reported in the included papers. If reported, we coded the mean score and the standard deviation for speech, and the other sound separately. When infant-level data was provided, we recomputed the respective mean scores and standard deviations based on the reported individual scores. If reported, we also coded the t-statistic between the two sound conditions, or an F-statistic provided this was a two-way comparison. If effect sizes were directly reported as a Cohen’s d or a Hedges' g, we also coded this. 

The PRISMA checklist, data, and code can be found on the online supplementary materials (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8).


## Effect sizes

Once the data were coded, we extracted effect sizes, along with their respective variance. Effect sizes were standardized differences (Cohen’s d) between response to speech and to the other sound.
If they were not directly reported in the papers, we computed them using the respective means and SDs [@lipsey_practical_2001], or a t- or F-statistic [@dunlap_meta-analysis_1996]. As our effect sizes came from within-subject comparisons (e.g. looking time of the same infant during speech and during monkey calls), we needed to take into account the correlation between the two measurements in effect sizes and effect size variances computations. We computed this correlation based on the t-statistic, the respective means and SDs [@lipsey_practical_2001] if they were all reported; or imputed this correlation randomly if not. We finally calculated the variance of each effect size [@lipsey_practical_2001]. Cohen's d were transformed to Hedges' g by multiplying d by a correction for small sample sizes based on the degree of freedom [@borenstein_introduction_2011].

We did not center age because our hypotheses included a developmental progression from birth to the end of the first year of life. We were therefore interested in the intercept at age 0 (i.e. birth).

All analyses use the R [@r_core_team_r:_2018] package Robumeta [@hedges_robust_2010], which allows to fit meta-analytic regressions that take into account the correlated structure of the data, when repeated measures are obtained from the same infant groups within papers. 

# Results

## Database description

We found a total of `r length(papers)` publications (labeled with an asterisk in the reference list) reporting `r length(unique(DB2$same_infant))` experiments, and `r length(DB2$g_calc)` (not mutually independent) effect sizes, see Figure \@ref(fig:forest). `r length(unique(DB2$study_ID[DB2$peer_reviewed == 'yes']))` papers have been submitted to or published in peer-reviewed journals [@cooper_developmental_1994; @vouloumanos_tuned_2004; @vouloumanos_tuning_2010; @shultz_three-month-olds_2010; @colombo_method_1981; @vouloumanos_five-month-old_2009; @sorcinelli_preference_2019; @yamashiro_does_2019; @segal_listening_2011; @curtin_speech_2013; @vouloumanos_foundational_2014; @vouloumanos_listening_2007; @vouloumanos_tuning_2010; @spence_prenatal_1987; @ecklund-flores_asymmetric_1996; @santolin_role_2019; @vanden_bosch_der_nederlanden_infant_2020]. The remaining 1 publication contributing `r length(DB2$g_calc[DB2$peer_reviewed == 'no'])` effect size was a thesis  [@ference_role_2018].

Experiments tended to have small sample sizes, with a median N of `r median(DB2$n)` children (Range = [`r max(DB2$n)`, `r min(DB2$n)`], M = `r mean(DB2$n)`, Total: `r round(sum(temp$n))`).
Infants ranged from `r round(min(DB2$mean_age_1)/30.44)` to `r round(max(DB2$mean_age_1)/30.44)` months (`r min(DB2$mean_age_1)` to `r max(DB2$mean_age_1)` days), although the majority were under 6 months of age (`r length(unique(DB2$same_infant[DB2$age_months<=6]))/length(unique(DB2$same_infant))*100`% of the experiments). Individual samples comprised `r round(mean(DB2$gender_1, na.rm=TRUE)*100)`% of female participants on average. Infants were native of 6 different languages across the whole database (English, French, Russian, Yiddish, Hebrew, Italian). 
Experiments were performed in 10 different laboratories from 4 different countries (United States, Canada, Israel, Italy). `r length(unique(DB2$method))` experimental methods were used: `r length(unique(DB2$same_infant[DB2$method=='CF']))` experiments used Central Fixation (CF) (also called sequential looking preference procedure) [@cooper_developmental_1994; @vouloumanos_tuned_2004; @vouloumanos_tuning_2010; @shultz_three-month-olds_2010; @colombo_method_1981; @vouloumanos_five-month-old_2009; @sorcinelli_preference_2019; @yamashiro_does_2019; @segal_listening_2011; @curtin_speech_2013; @vouloumanos_foundational_2014; @ference_role_2018; @santolin_role_2019; @vanden_bosch_der_nederlanden_infant_2020]; `r length(unique(DB2$same_infant[DB2$method=='HAS']))` used High-Amplitude Sucking (HAS) [@vouloumanos_listening_2007; @vouloumanos_tuning_2010; @spence_prenatal_1987]; and `r length(unique(DB2$same_infant[DB2$method=='HPP']))` used Head-turn Preference Procedure (HPP) [@ecklund-flores_asymmetric_1996]. Trial length was fixed in `r length(unique(DB2$same_infant[DB2$trial_length=='fixed']))` experiments, and infant-controlled in `r length(unique(DB2$same_infant[DB2$trial_length=='infant_controlled']))` experiments. 

Speech sounds were spoken by a female in `r length(unique(DB2$same_infant[DB2$talker_gender=='female']))` out of `r length(unique(DB2$same_infant))` experiments, with an infant-directed prosody in `r length(unique(DB2$same_infant[DB2$prosody=='IDS']))` out of the `r length(unique(DB2$same_infant))` experiments. Speech was presented in isolated segments (i.e. words or syllables) in `r length(unique(DB2$same_infant[DB2$utterance_length=='words']))` experiments, and full sentences or passages in `r length(unique(DB2$same_infant[DB2$utterance_length=='passages']))` experiments. Speech stimuli were recorded in the infant native language in `r length(unique(DB2$same_infant[DB2$test_lang=='native']))/length(unique(DB2$same_infant))*100`% of the experiments. Strinkingly, experiments using the infants' native language tested infants from 0 to 12 months of age, whereas experiments using a foreign language only tested infants from 3 to 9 months of age (see Figure \@ref(fig:lang)). 
The competitor sound was vocal in `r length(unique(DB2$same_infant[DB2$vocal=='yes']))/length(unique(DB2$same_infant))*100`% of the experiments. The competitor sound was natural `r length(unique(DB2$same_infant[DB2$natural=='yes']))/length(unique(DB2$same_infant))*100`% of the experiments.
The stimuli characteristics are sumarized on Figures \@ref(fig:stimuli) and \@ref(fig:competitors).

```{r stimuli, include=T, fig.cap = "Histograms of the number of effect sizes for each language and moderator status."}
ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = vocal, fill = test_lang), position = 'dodge')+
  scale_fill_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  labs(title = "A. Vocal quality", y = "Number of effect sizes")+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = natural, fill = test_lang), position = 'dodge')+
  scale_fill_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  labs(title = "B. Naturalness", y = "Number of effect sizes")+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))
```

```{r competitors, include=T, fig.cap = "Histogram of the number of effect sizes for each competitor."}
ggplot(data = DB2)+
  geom_bar(stat = 'count', aes(x = contrast_stim))+
   scale_y_continuous(limits = c(0, 10), breaks = seq(0,10,1))+
  theme_classic()+
  labs(x="Competitor sound", y = "Number of effect sizes")+
  theme(text = element_text(size = 15), legend.position = c(.9, .9),axis.text.x=element_text(angle=45, hjust=1))
```

## Average effect size

```{r forest, include=T, fig.cap = "Forest plot of effect sizes available in the literature, along with their respective moderator status."}
#average variance / infant group to build models with CORR, and allow robumeta to detect correlated effect sizes within papers. 
DB2 = DB2 %>% group_by(same_infant) %>% mutate(g_var_m = mean(g_var_calc))

# Model without moderators to get the average effect size
base_model <- robu(g_calc ~ 1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T) 

# same model with metafor for a nice forest plot 
simple_model <- rma(g_calc, g_var_calc, data=DB2, weighted = TRUE, method = "REML", subset=!DB2$outlier & !is.na(DB2$g_calc), slab =DB2$short_cite) 

forest.rma(simple_model, annotate = FALSE, xlim = c(-13,3), ylim = c(-1,51), order = 'obs',
       xlab = 'Effect size (Hedges\' g)', mlab = "", alim = c(-2,3), steps = 6, cex.axis = 0.6, cex.lab = 0.7, 
       ilab=cbind(round(DB2[!DB2$outlier,]$age_months, digits = 1), DB2[!DB2$outlier,]$method, DB2[!DB2$outlier,]$natural, DB2[!DB2$outlier,]$vocal, DB2[!DB2$outlier,]$test_lang),
       ilab.xpos=c(-7.4,-6.2,-5,-3.8, -2.5)) 
op <- par(cex=.75)
text(c(-7.4,-6.2,-5,-3.8, -2.5), 50, c("age", "method", "natural", "vocal", "language"))
```

Integrating across all experiments in a meta-analytic regression without any moderator, we found an average effect size g of `r base_model$reg_table$b.r` (SE = `r base_model$reg_table$SE`, CI = [`r base_model$reg_table$CI.L` , `r base_model$reg_table$CI.U`]) (Table 1, and Figure \@ref(tab:Table1), diamond), corresponding to a medium effect size.
Heterogeneity among effect sizes was estimated at $\tau^2$ = `r simple_model$tau2` (I^2^ = `r simple_model$I2`%), which was significant (Q = `r simple_model$QE`, p<0.001) despite the removal of outliers before running the model. 

```{r Table1, results="asis", include=T}
table1 = rbind(base_model$reg_table[,c(2:4,7:8)])
rownames(table1)=c('average effect size')

table1[,4]=paste0(round(table1[,4],2)," - ",round(table1[,5],2))
table1=table1[,-5]

apa_table(table1, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression without any moderator.", escape= T)

```

```{r resampling}
# Sanity check: We repeat random imputation of missing correlation between the two measures (done in data_completion.R for the main database), and recompute effect sizes 100 times to check it doesn't change the results.
library(Hmisc)

#set up the dataframe that will contain the results after resampling (one line per resampling)
resamp_stats = base_model$reg_table
resamp_prob = base_model$reg_table$prob

for (s in 1:100){
  
  data = DB2 #make a copy of the database without the imputed correlations
  data$corr_imputed[is.na(data$corr)==T] = NA
  data$corr_imputed[data$participant_design == "within_two"] <- impute(data$corr[data$participant_design == "within_two"],fun='random')
  
  # recompute effect sizes
  # empty the relevant variables
  data$d_calc = NA
  data$d_var_calc = NA
  data$g_calc = NA
  data$g_var_calc = NA
  data$es_method = NA
  
  #effect size calculation
  for (i in 1:nrow(data)){
    db = data[i,]
    if (is.na(db$corr) | db$corr > .99 | db$corr < .01){
      #if correlation between two measures is not reported, use an imputed correlation value
      #we also account for the observation that some re-calculated values are impossible and replace those
      corr <- db$corr_imputed
    }else{corr <- db$corr}
    
    if (complete(db$x_1, db$x_2, db$SD_1, db$SD_2)) {
      pooled_SD <- sqrt((db$SD_1 ^ 2 + db$SD_2 ^ 2) / 2) # Lipsey & Wilson (2001)
      d_calc <- (db$x_1 - db$x_2) / pooled_SD # Lipsey & Wilson (2001)
      es_method  <- "group_means_two"
    } else if (complete(db$t)) {
      wc <- sqrt(2 * (1 - corr))
      d_calc <- (db$t / sqrt(db$n_1)) * wc #Dunlap et al., 1996, p.171
      es_method  <- "t_two"
    } else if (complete(db$F)) {
      wc <- sqrt(2 * (1 - corr))
      d_calc <- sqrt(db$F / db$n_1) * wc
      es_method  <- "f_two"
    } else {d_calc = NA}
    #now that effect sizes are calculated, effect size variance is calculated
    if (complete(db$n_1, d_calc)) {
      d_var_calc <- (2 * (1 - corr)/ db$n_1) + (d_calc ^ 2 / (2 * db$n_1)) # Lipsey & Wilson (2001)
    } else if (complete(db$d, db$d_var)) {
      #if d and d_var were already reported, use those values
      d_calc <- db$d
      d_var_calc <- db$d_var
      es_method  <- "d_two"
    } else {d_var_calc = NA}
    
    df <- db$n_1 - 1
    J <- 1 - 3 / (4 * (df - 1))
    g_calc <- d_calc * J
    g_var_calc <- J ^ 2 * d_var_calc
    
    #add the results to the database
    db$d_calc = d_calc
    db$d_var_calc = d_var_calc
    db$g_calc = g_calc
    db$g_var_calc = g_var_calc
    db$es_method = es_method
    
    data[i,] = db
  }
  
  #Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
  data$outlier <- F #create the variable, and set as no by default (majority of cases hopefully!)
  data$outlier[data$d_calc > mean(data$d_calc, na.rm = TRUE) + 3*sd(data$d_calc, na.rm = TRUE) | data$d_calc < mean(data$d_calc, na.rm = TRUE) - 3*sd(data$d_calc, na.rm = TRUE)]<-T 
  
  # Re-fit the meta-analytic model
  #average variance / infant group to build models with CORR, and allow robumeta to detect correlated effect sizes within papers. 
  data = data %>% group_by(same_infant) %>% mutate(g_var_m = mean(g_var_calc))
  base <- robu(g_calc ~ 1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T) 
  resamp_stats = bind_rows(resamp_stats,base$reg_table)
  
}

# check that the results don't change in 95 % of cases
resamp_alphas <- ifelse(resamp_stats$prob < 0.05, 1, 0)
resamp_alphas <- length(resamp_alphas[resamp_alphas==0])/length(resamp_alphas)
resamp_alphas
```

## Publication bias

```{r bias, include = T, fig.cap="Funnel plot of effect sizes and their respective standard errors. Black dots: effect sizes observed in the literature. White dots: missing effect sizes, suggestive of a publication bias$^2$. Vertical line: average effect size after filling the missing effect sizes."}

#add symmetrize
tf <- trimfill(simple_model) 
funnel(tf, cex=1.5, xlab='Effect size (Hedges\' g)', ylab="Standard Error of Effect Size g", digits=2, legend=TRUE)

# testing for asymetry (indicates a publication bias)
SEg = regtest(DB2$g_calc,DB2$g_var_calc)
k = ranktest(DB2$g_calc,DB2$g_var_calc)

```

We assessed the presence of a potential publication bias in the body of literature by studying the relationship between standard errors of effect sizes as a function of Hedges’ g (see funnel plot in Figure \@ref(fig:bias)).[^2] A regression test on these data was significant (z = `r SEg$zval`, p = `r SEg$pval`), as  was the Kendall's tau rank correlation test for funnel plot asymmetry (Kendall's tau = `r k$tau`, p = `r k$pval`), consistent with a publication bias in the literature.
To further investigate this bias, we  symmetrized the funnel plot with the “trim and fill” method [@duval_trim_2000]. To symmetrize the funnel plot, `r tf$k0` (SE = `r tf$se.k0`) missing experiments were needed on the left side of the plot. The corrected effect size was estimated at `r tf$beta[1,1]` (SE = `r tf$se`) after filling in the `r tf$k0` missing experiments.

[^2]: If the literature is not biased, effect sizes should be evenly distributed around the mean effect size, with increasing standard error as they go away from the mean effect size (both in the positive and negative directions, white triangle in the funnel plot). This is reflected by a symmetrical funnel plot, with no linear relationship between effect sizes and standard errors. 

## Moderator analyses

We then tested if the heterogeneity found above could be explained by the dimensions discussed in the literature. Following our hypotheses, we fit a meta-analytic model with the following moderators: 

- mean age of children;
- familiarity with the language used (native or foreign);
- naturalness of the contrastive sound (coded as yes if it was natural and no otherwise);
- vocal quality of the contrastive sound (coded as yes if it was vocal and no otherwise).

Given the number of effect sizes available in the literature, these moderators were specified without interactions to avoid overfitting.

```{r moderators}
#distribution of moderators
table(DB2$natural)#no. of natural and non-natural data points
table(DB2$vocal)#no. of vocal and non-vocal data points
table(DB2$homospecific)#no. of homo- and heterospecific data points
table(DB2$homospecific,DB2$vocal)
table(DB2$natural,DB2$vocal)
table(DB2$contrast_stim)

#setting up of predictors 
#http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/

#check that the experimental method doesn't make a difference
relevel(DB2$method,"HAS")->DB2$method #put HAS as the 1st level
#dummy coding: each level is compared to a reference level of the dependent variable, intercept corresponds to the reference level.
contrasts(DB2$method) = contr.treatment(length(levels(DB2$method)),base=1) #baseline method should be HAS because it's the one used with newborns

#moderators of interest
contrasts(DB2$test_lang) <- contr.treatment(length(levels(DB2$test_lang)),base=1)

contrasts(DB2$natural) <- contr.treatment(length(levels(DB2$natural)),base=2)

DB2$vocal <- factor(DB2$vocal)
contrasts(DB2$vocal) <- contr.treatment(length(levels(DB2$vocal)),base=2)

# model with moderators of interest. 

full_model <- robu(g_calc ~ test_lang + natural + vocal + mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

```

None of the moderators was significant (see Figures \@ref(fig:natural),  \@ref(fig:vocal), and  \@ref(fig:lang); and Table \@ref(tab:Table2)). 

```{r Table2, results="asis", include=T} 

table2 = rbind(full_model$reg_table[1:5,c(2:4,7:8)])
rownames(table2)=c('intercept','familiarity','naturalness','vocal quality','age')

table2[,4]=paste0(round(table2[,4],2)," - ",round(table2[,5],2))
table2=table2[,-5]

apa_table(table2, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with all moderators. The intercept corresponds to the effect size when speech is in a foreign language, and the competitor is natural, and vocal, at age 0. The moderator estimates correspond to changes in the intercept when the target stimuli are in the native language (familiarity); the competitor is artificial (naturalness); and the competitor is non-vocal (vocal quality).", escape= T)
```


We also tested each of our three hypotheses by three separate models for each moderator and its interaction with age. None of them yield any significant effect or interaction (Table \@ref(tab:TableNatural), \@ref(tab:TableVocal), and \@ref(tab:TableLang)).  

```{r natural, include=T, fig.cap="Effect sizes as a function of age and natural quality of the competitor. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$natural),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

```

```{r TableNatural, results="asis", include=T} 

model_natural <- robu(g_calc ~ natural*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_nat = rbind(model_natural$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_nat)=c('intercept','naturalness','naturalness*age')

table_nat[,4]=paste0(round(table_nat[,4],2)," - ",round(table_nat[,5],2))
table_nat=table_nat[,-5]

apa_table(table_nat, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with naturalness and its interaction with age as moderators. The intercept corresponds to the effect size when the competitor is natural, at age 0. The moderator estimates correspond to changes in the intercept when the competitor is artificial (naturalness).", escape= T)
```

```{r vocal, include=T, fig.cap="Effect sizes as a function of age and vocal quality of the competitor. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("turquoise2","tomato"), labels = c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

```

```{r TableVocal, results="asis", include=T} 

model_vocal <- robu(g_calc ~ vocal*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_voc = rbind(model_vocal$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_voc)=c('intercept','vocal quality','vocal quality*age')

table_voc[,4]=paste0(round(table_voc[,4],2)," - ",round(table_voc[,5],2))
table_voc=table_voc[,-5]

apa_table(table_voc, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with vocal quality and its interaction with age as moderators. The intercept corresponds to the effect size when the competitor is vocal, at age 0. The moderator estimates correspond to changes in the intercept when the competitor is non-vocal (vocal quality).", escape= T)
```

```{r lang, include=T, fig.cap="Effect sizes as a function of age and familiarity with the speech sounds. The size of each dot is inversely proportional to the variance. Positive effect sizes reflect a preference for the speech sound, negative effect sizes reflect a preference for the competitor sound."}
ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

```

```{r TableLang, results="asis", include=T} 

model_lang <- robu(g_calc ~ test_lang*mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

table_lang = rbind(model_lang$reg_table[c(1:2,4),c(2:4,7:8)])
rownames(table_lang)=c('intercept','familiarity','familiarity * age')

table_lang[,4]=paste0(round(table_lang[,4],2)," - ",round(table_lang[,5],2))
table_lang=table_lang[,-5]

apa_table(table_lang, digits=2, align='lcccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with language of the speech sounds and interaction with age. The intercept corresponds to the effect size when speech is in a foreign language at age 0. The moderator estimates correspond to changes in the intercept when the target stimuli are in the native language (familiarity).", escape= T)
```

```{r other plots}
vio_method <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=method, y=g_calc))+
  geom_violin(aes(fill=method), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=method, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.2, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "method", labels=levels(DB2$method), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#Effect of naturalness
vio_nat <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=natural, y=g_calc))+
  geom_violin(aes(fill=natural), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=natural, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", labels=c("artificial","natural"), na.translate = FALSE)+
  scale_fill_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

facet_natural <- ggplot(data=DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$natural)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("mediumvioletred","green3"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

# Effect of vocalness
vio_voc <- ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=vocal, y=g_calc))+
  geom_violin(aes(fill=vocal), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=vocal, y=g_calc, size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), position=position_jitter(w=0.1, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", na.translate = FALSE, labels = c("non-vocal", "vocal"))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("turquoise2","tomato"), labels=c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15))

facet_vocal<-ggplot(data=DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$vocal)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("turquoise2","tomato"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

#Effect of familiarity with the speech sounds? Nativeness (test_lang) and age.
ggplot(data=DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),], aes(x=age_months, y=g_calc, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$test_lang)&!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE, alpha=0.3)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  scale_colour_manual(values = c("red3","skyblue"))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = "none")+
  facet_grid(.~test_lang)

vio_lang <- ggplot(data=DB2[!is.na(DB2$test_lang),],aes(x=test_lang, y=g_calc))+
  geom_violin(aes(fill=test_lang), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=test_lang, y=g_calc, size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "speech sound", labels=c("foreign","native"), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20))

#violin plot / contrasted sound
vio_contrast <- ggplot(data=DB2[!is.na(DB2$contrast_stim),],aes(x=contrast_stim, y=g_calc))+
  geom_violin(aes(fill=contrast_stim), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=contrast_stim, y=g_calc, size=1/DB2[!is.na(DB2$contrast_stim),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "contrast sound", na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  #scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20), axis.text.x = element_text(angle = 45, size = 10))

```


# Discussion

Our meta-analysis synthesizes the available literature on infants’ preference for speech sounds. When all experiments were considered together with no moderators, we found a sizable intercept (g=`r base_model$reg_table$b.r`). For comparison, the average effect for native vowel discrimination using looking time methods is estimated at 0.25 [@tsuji_perceptual_2014, data inspected in http://metalab.stanford.edu on 2019-10-18]. These results are in line with adult neuroimaging data showing distinct responses to speech as compared to other natural or environmental sounds, even in low-level auditory regions [@norman-haignere_distinct_2015;  @norman-haignere_neural_2018]. Our meta-analysis shows that this preferential processing of speech sounds is observable from birth on. We had hypothesized age to play a major role, because it may correlate with a reshaping of the category definition for speech itself. Indeed, experiments comparing processing of human speech against human non-speech as well as animal vocalizations more generally [@vouloumanos_tuning_2010; @mcdonald_infant_2019] often discuss these age-related differences in categorization of these sounds. Surprisingly, age did not significantly moderate the overall preference for speech, as shown by the null estimate of this moderator (Table \@ref(table:Table1)). This result was replicated in a separate model for age only, which showed a significant intercept, similar to the intercept found in the meta-regression with no moderator (Supplementary results S5). Crucially, age was not centered. This intercept therefore provides an estimate of the effect size at age 0, i.e. at birth. Moreover, the scatterplot of effect sizes as a function of age reveals clearly no change with age even when plotted without other moderators (Supplementary figure S6). This null effect of age, combined with the sizeable intercept, confirms that infants reliably prefer speech over other types of sounds from birth.

The significant heterogeneity we found among the literature suggests that underlying factors modulate this effect. We had predicted infants' speech preference to be larger when the competitor was an artificial sound than when it was a natural one; when the competitor was non-vocal; and when the speech was in the infants' native language. In fact, we were unable to disprove the null hypothesis of no difference for all three factors. Distributions of effect sizes for experiments varying along the three dimensions widely overlap, and the confidence intervals of all conditions overlap almost exactly (Figures \@ref(fig:natural),  \@ref(fig:vocal), and  \@ref(fig:lang)). Moreover, Table \@ref(table:Table1) shows that the estimate for all these factors is close to zero (the maximum being `r max(full_model$reg_table$b.r[2:5]) `). Our findings therefore suggest that none of these parameters fully explain infants' preference for speech sounds. 

In other words, from birth on, infants show a preference for speech, which cannot be reduced to the three simpler explanations tested here: naturalness, vocalness, or familiarity (represented here by comparing effects for native versus competitor against those for foreign versus competitor). It is possible that infants prefer speech because of its complex acoustic structure and fast transitions [@rosen_constructing_2007]. Spectral or temporal modulations taken separately are not sufficient to elicit neural responses similar to the ones elicited by speech [@minagawa-kawai_assessing_2011]. However, speech is characterized by joint spectrotemporal modulations at specific rates [@singh_modulation_2003]. It is possible that infants are sensitive to this specific spectro-temporal structure [though see @norman-haignere_neural_2018 showing that they only explain neural responses in primary auditory cortex, suggesting that other factors contribute to the behavioral response in later processing stages]. Testing this explanation would require to compute the modulation spectra of the actual stimuli used in the experiments. Thus, we recommend interested researchers to deposit their stimuli in a public archive such as the Open Science Framework [@foster_open_2017].

A capacity to preferentially listen to speech sounds from birth suggests that infants are born with the capacity to recognize their conspecifics’ communication signals. This parallels what has been proposed for faces: Infants are born with the capacity to orient their attention toward them, even without any prior exposure to faces [@morton_conspec_1991; @turati_faces_2004]. This would stem from basic perceptual abilities present at birth, namely that the visual system would be tuned to a spatial structure that correspond to those of faces [@morton_conspec_1991; @turati_faces_2004]. As newborns have never been exposed to such visual stimuli before, it would reflect general properties (i.e. filters) of the visual system. Similarly, the auditory system could be tuned to a spectro-temporal structure that speech presents. The combination of this non-specific bias with the systematic variations of the auditory environment would result in preferential responses to speech from birth. However, contrary to faces, fetuses are exposed to speech that is low-pass filtered by the womb throughout the last trimester of gestation [@querleu_fetal_1988; @lecanuet_speech_1993]. It is therefore possible that prenatal experience with low-pass filtered speech helps infants to form a representation of speech, by refining the response properties of the auditory system to speech.
The fact that familiarity with the language used in the experiment did not modulate infants’ preference suggests that this effect is not triggered by familiarity with the sounds of the native language. Infants would therefore form a representation that is specific enough to discriminate speech from other natural or vocal sounds, but general enough to be independant of the language spoken.

Ultimately, preferential processing of speech may support higher level cognitive tasks. The human species is a gregarious one. Detecting speech signals would allow to integrate it with other sensory percepts, such as faces, to form multisensory representations of conspecifics [@vouloumanos_five-month-old_2009]. This would lay the track for social cognition. Identifying speech signals and paying attention to them would allow infants to form complex representations of the sensory world, that they can manipulate cognitively. Consistently, infants could categorize visual stimuli (i.e., associate a label to a category of objects) when they were associated to speech, but not pure tones or backward speech [@fulkerson_words_2007; @ferry_categorization_2010; @ferry_nonhuman_2013]. Interestingly, infants categorized visual stimuli when presented with speech, melodies, monkey [@fulkerson_influence_2003], or lemur vocalizations [@ferry_nonhuman_2013]. These results support the idea that infants may preferentially process complex sounds. Finally, the preference itself may also be a meaningful index of processing that can be used to identify children at risk [@sorcinelli_preference_2019]. Understanding this phenomenon is therefore crucial for both theoretical and clinical advances. 

We want to close by drawing the reader's attention to methodological insights the present study provides. 
First, the median sample size at present is `r median(DB2$n)`, which is close to the field standard [@bergmann_promoting_2018], but much lower than current recommendations [@oakes_sample_2017]. Well-chosen sample sizes are crucial for powerful experiments [@simmons_false-positive_2011]. Our meta-analysis provides the average effect size across the literature, which will, in turn, allow researchers to run power analyses to determine the sample size they need in future experiments.
Second, the distribution of effect sizes in the literature is consistent with publication bias, in view of a strong asymmetry of the funnel plot. The trim-and-fill method suggested `r tf$k0` points may be missing. Given that we have `r length(DB2$g_calc)` effect sizes in total, a fifth more would be missing. The missing experiments are in the negative section, i.e., a preference *against* speech, a result that could lead authors to doubt their own data and not submit it to journals, or that would be considered odd by reviewers and editors, who may ask that the data be removed (or who may recommend the paper to be rejected altogether). The literature being biased toward positive effect sizes, the true effect size might be smaller than the one we found (vertical line on Figure \@ref(fig:bias)). To correct this bias, we invite researchers to use registered reports [@kiyonaga_practical_2019]. In this new publication scheme (available for Developmental Science, Infancy, Infant Behavior and Development, and Journal of Child Language at the time of writing, see a full up-to-date list on https://cos.io/rr/), manuscripts are submitted before data are collected. Reviewers and editors make publication decisions based solely on the introduction and methods. The paper is then reviewed once more for readability, but it cannot be rejected if the results are surprising or uncomfortable for the field. This would facilitate the publication of experiments failing to report a speech preference, or actually reporting a preference for the competitor, which would in turn help to draw a more accurate picture of the phenomenon. Our dataset can be community-augmented, and we invite researchers investigating this phenomenon to complement it with any data they would have (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8), whatever the results and publication status. 

Our meta-analysis revealed uneven distributions of experiments across age and stimulus dimensions. One may think that this uneven age distribution could be one potential reason for the lack of an age effect. However, by aggregating the numerous individual studies of a literature, meta-analyses gain statistical power. As such, meta-analytic results have more cumulative explanatory value than any single study. Previous experiments suggested that infants initially perceive speech and other vocal sounds as a common category, and then narrow it to speech around five months of age. With a sample size of `r sum(DB2$n)` infants, covering a much wider age range than individual experiments, our meta-analysis provide evidence for an alternative view of the phenomenon, namely that infant prefer speech from birth onwards, even to other natural or vocal sounds, and that this effect is not driven by familiarity with the sounds of the language used. This clearly points to the value of meta-analysis: to advance a field and inspire follow-up studies. In particular, future experiments should test infants older than 9 months. Language production gains in complexity at about this age [@oller_precursors_1999], which could affect infants' speech preference. Experiments using natural vocal stimuli as competitor, and foreign speech as target, would contribute to fill in the gap in the litterature that our meta-analysis revealed.

```{r suplementary}
model_age <- robu(g_calc ~ mean_age_1, data=DB2[!DB2$outlier,], modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(method = "glm", na.rm = TRUE, color='gray40', aes(alpha=0.3))+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-1, 3), breaks = seq(-1,3,1))+
  geom_hline(yintercept=0, linetype="dashed", color="grey")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = 'none')

```


\newpage
# References
<!-- # References -->
<!-- # ```{r create_r-references} -->
<!-- # r_refs(file = "r-references.bib") -->
<!-- # ``` -->

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
