---
title             : "Infants’ preference for speech decomposed: Meta-analytic evidence"
shorttitle        : "Preference for speech sounds in infancy"

author: 
  - name          : "Cécile Issard"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Laboratoire de Sciences Cognitives et Psycholinguistique, Département d'Études Cognitives, Ecole Normale Supérieure, 29 rue d'Ulm, 75005 Paris, France"
    email         : "cecile.issard@gmail.com"
  - name          : "Sho Tsuji"
    affiliation   : "2"
  - name          : "Alejandrina Cristia"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Laboratoire de Sciences Cognitives et Psycholinguistique, Ecole Normale Supérieure, Département d'Études Cognitives"
  - id            : "2"
    institution   : "International Research Center for Neurointelligence, The University of Tokyo"

authornote: |
  This work was supported by an Agence Nationale de la Recherche grant to A.C. (ANR-17-CE28-0007 LangAge, ANR-16-DATA-0004 ACLEW, ANR-14-CE30-0003 MechELex, ANR-17-EURE-0017); and the J. S. McDonnell Foundation Understanding Human Cognition Scholar Award to A.C.
  
  The authors declare no conflict of interest. Funding sources did not take part in study design, data collection or analysis.
  
  Our data is fully available in the corresponding OSF repository: http://tidy.ws/bqjc4U
  
abstract: |
 The human auditory system is amazingly efficient at processing speech, with a preference for these sounds reported by full term birth. More generally, infants tested at a variety of ages have been presented with contrasts between native or foreign speech and another sound, which may be vocal or not, natural or not. These data constitute a rich pool of evidence that can be sourced from to assess to what extent familiarity, vocal quality, and naturalness affect speech preference across development. We synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a medium effect size, with infants preferring speech over other sounds. This preference was not significantly moderated by familiarity, vocal quality, or naturalness. We found no effect of age: infants showed the same strength of preference throughout the first year of life. Speech therefore appears to be preferred from birth, even to other natural or vocal sounds. These results contradict current views of the literature, and call for further investigation of the phenomenon, especially in older infants.

  
keywords          : "Meta-analysis, infants, speech preference, auditory development, natural sounds"
# wordcount         : "3971"

bibliography      : ["bibliography.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include=F}

knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = FALSE, echo = FALSE, include = F) #options for all the code chunks of the document.

source("compute_es.R", chdir = TRUE)  #chdir stands for "change directory"

library(metafor)
library(robumeta)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(grid)
library(gridExtra)
library(RCurl)
library(papaja)

sessionInfo()


read.csv('speech_pref_full_DB.csv')->DB

DB2 = DB[DB$method!='PL',] #keep only the behavioral studies, remove outliers and NAs.

#Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
DB2$outlier[DB2$g_calc > mean(DB2$g_calc, na.rm = TRUE) + 3*sd(DB2$g_calc, na.rm = TRUE) | DB2$g_calc < mean(DB2$g_calc, na.rm = TRUE) - 3*sd(DB2$g_calc, na.rm = TRUE)]<-T 

#unique studies
papers <- levels(factor(DB2$short_cite))

#number of unique infants
DB2$n<-rowSums( cbind (DB2$n_1,DB2$n_2), na.rm=TRUE)
temp<-aggregate(n~same_infant,DB2,mean)

summary(DB2$mean_age_1)
```
# Highlights

- Infants reliably prefer natural speech over other types of sounds, from birth to the end of the first year of life
- Speech is preferred over both artificial and other natural sounds
- Speech is preferred over both non-vocal and other vocal sounds
- The difference between whether infants are familiar or not with the language used was not significant

# Abstract

  The human auditory system is amazingly efficient at processing speech, with a preference for these sounds reported by full term birth. More generally, infants tested at a variety of ages have been presented with contrasts between native or foreign speech and another sound, which may be vocal or not, natural or not. These data constitute a rich pool of evidence that can be sourced from to assess to what extent familiarity, vocal quality, and naturalness affect speech preference across development. We synthesized the literature by conducting a meta-analysis of studies testing speech preference in infants from birth to one year of age. We found a medium effect size, with infants preferring speech over other sounds. This preference was not significantly moderated by familiarity, vocal quality, or naturalness. We found no effect of age: infants showed the same strength of preference throughout the first year of life. Speech therefore appears to be preferred from birth, even to other natural or vocal sounds. These results contradict current views of the literature, and call for further investigation of the phenomenon, especially in older infants.
  
*Keywords:* meta-analysis, infants, speech preference, auditory development, natural sounds, vocal sounds

# Introduction

Given the importance of speech for human vocal communication, it is conceivable that infants are born equipped with a preference for speech, which becomes stronger with age and exposure. Here, we synthesize empirical data on infants’ preferences for speech over non-speech sounds to assess the explanatory role of three factors: stimulus naturalness, vocal quality, and familiarity.

## Potential dimensions underlying preference patterns
There are three key conceptual explanations for infants preference for speech over competitor sounds: Preference for (a) natural over artificial sounds; (b) familiar over unfamiliar sounds; and (c) vocal over non-vocal sounds (Figure 1). These explanations are mutually compatible, and one or more may be true.

### Naturalness

A first hypothesis postulates a preference for natural over artificial sounds. Natural sounds are those produced by biological systems, including vocal tracts but also the sound of walking and heart rate. In many cases natural and artificial sounds differ in their  acoustic characteristics. For example, backward speech has unnatural formant transitions and seemingly abrupt closures compared to naturally produced sounds. Natural sounds are processed more efficiently by the auditory system, from the cochlea [@smith_efficient_2006] to the auditory cortex [e.g., @mizrahi_single_2014]. This predicts a preference for speech over artificial competitors that is present from birth, consistent with existing literature [e.g., @vouloumanos_listening_2007].  


### Familiarity

Perhaps infants prefer speech to other sounds since it is a frequent sound. Newborns prefer their native speech to prosodically distinct foreign speech [e.g., @mehler_precursor_1988], which supports a preference for sound patterns heard frequently in the womb. There are no behavioral results directly testing the prediction that infants show stronger preferences for speech over a foil when tested with more familiar speech stimuli (for instance, spoken in their native, as compared to a foreign language), but results from neuroimaging studies provide indirect evidence for this view. For instance, newborns' brain activation was different for forward than backward speech when the native language was used as the speech stimuli, but not when a foreign language was used [@may_specificity_2018]. 


### Vocal quality

  Many results summarized above may be accommodated by a third hypothesis, postulating a preference for vocal over non-vocal sounds. Vocal sounds are those made with a mouth, and thus typically a subset of natural sounds[^1]. Newborns made more head-turns to speech than to heartbeat [@ecklund-flores_asymmetric_1996], arguably both equally natural and familiar to them, but they listened equivalently to speech and monkey calls, despite the greater familiarity of the former [@vouloumanos_tuning_2010]. 
  
[^1]: In the case of filtered speech, the modulations introduced by the vocal tract are still present at the retained frequencies. For this reason, filtered speech can be considered as vocal but not natural. 

## Changes as a function of development

Development may affect the preference for speech in various ways. Whereas newborns do not prefer speech over monkey calls, three-month-olds do [@vouloumanos_tuning_2010]. This suggests that as they age, infants might develop an increasingly narrow definition of the stimulus they prefer. In this case  naturalness, familiarity, and vocal quality effects should change as a function of age:  Very close stimuli (e.g., speech versus another natural sound) initially leads to a weak preference, but, as infants age, this preference may be as strong as that found for very different stimuli (e.g., speech versus an artificial sound).
Many articles discuss potential changes in the pattern of preference as a function of age [e.g. @ferry_nonhuman_2013; @shultz_three-month-olds_2010; @shultz_neural_2014]. To our knowledge, only two papers from the same laboratory include multiple age groups tested with the exact same stimulus categories and procedure [@vouloumanos_tuning_2010; @vouloumanos_tuned_2004]. In fact, statements about age-related changes are often done using the demonstrably problematic method of concluding that there is an interaction without actually testing for it statistically  [@gelman_difference_2006]. It is therefore important to directly test these statements.


## A meta-analytic approach

In sum, previous work on infants' preferences is broadly compatible with preference for natural over artificial, vocal over non-vocal, and familiar over unfamiliar sounds, potentially interacting with infants' age. In this paper, we seek to directly test these interpretations of the literature by employing a meta-analytic approach. 
Meta-analyses involve  combining studies that may vary in their methodology. One limitation is therefore that one cannot isolate specific variables as well as in direct experimentation. Therefore, meta-analyses may miss subtle effects. Nonetheless, they  have several useful features. They can reveal small effects not obvious in individual studies by combining them to obtain larger samples. Additionally, by integrating data across different laboratories, they provide evidence for the generalizability of effects across labs. Finally, meta-analyses offer tools to detect publication bias in the literature. 

Specifically for the present case, a meta-analysis allows to statistically test different explanations. We can test the effect of factors that are not part of the original design, by redescribing the stimuli used as a function of those factors. For instance, a study measuring preference for native speech over native backward speech provides data on a natural versus artificial, as well as a vocal versus non-vocal contrast. We can also draw a developmental timeline across the age range covered by the literature. 

Meta-analyses can even provide theoretical and empirical insights that contradict qualitative reviews. For example, it has been proposed that infants’ preference for novel or familiar items related to infants' age such that, all things equal, younger infants showed familiarity preferences whereas older infants exhibited novelty preferences [@hunter_multifactor_1988]. However, @bergmann_development_2016 found stable familiarity preferences for word segmentation in natural speech across the first two years; and @black_quantifying_2017 found a stable novelty effect for artificial grammars implemented in synthesized speech, whereas those implemented in natural speech led to stable familiarity preferences. Meta-analyses are therefore important to statistically and systematically test the theoretical predictions proposed in qualitative reviews.

## The present study

Given the scarcity of direct evidence on the potential explanations laid out above (naturalness, vocal quality, and familiarity, as a function of age), we conducted a meta-analysis to test whether infants' preference for speech sounds over other types of sounds is stable in newborns, and how it develops over the first year of life. Assuming all three factors are true, and further assuming that the definition of the preferred stimulus narrows with age, we predicted that infants will show (see Figure 2): 

1. a greater preference for speech over natural sounds as a function of age, but a stable preference for speech over artificial sounds that is stable over development; 
3. a greater preference for speech over other vocal sounds as a function of age, but a stable preference for speech over non-vocal sounds over development;
4. a greater preference for native speech over non-speech as a function of age, but a smaller preference for foreign speech over non-speech with age.

# Methods

## Literature search

We composed the initial list of studies with suggestions by experts (authors of this work); one google scholar search (*("speech preference" OR "own-species vocalization") AND infant - "infant-directed"*), the same search in PubMed and PsycInfo (last searched on 2019-09-24); and a google alert. We also inspected the reference lists of all included papers.

## Inclusion criteria

After a first screening based on titles and abstracts using more liberal inclusion criteria, we decided on inclusion based on full paper reading. We included studies that tested human infants from birth to one year of age, and contrasted speech sounds with any other type of sound, measuring behavioral responses to the sounds (e.g., looking times). We excluded studies that only contrasted foreign against native language, did not present natural speech sounds at all, presented speech in the mother’s voice, or intentionally mixed speech with other vocal sounds within the same sound condition. We also excluded neuroimaging studies to avoid mixing results from different brain regions with different response profiles. We included published (i.e., journal articles) as well as unpublished works (i.e., doctoral dissertations as long as sufficient information was provided). 

A PRISMA flow chart summarizes the literature review and selection process (Figure 3). We documented all the studies that we inspected in a decision spreadsheet (available in the online supplementary materials; https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8).


## Coding
The critical variables for our purpose are infant age, methodological variables (testing method: central fixation, high amplitude sucking, head-turn preference procedure, high amplitude sucking/passive listening), and key stimuli characteristics. Specifically, we coded the language in which the speech sounds were recorded (native or foreign), and  whether the sound opposed to speech was natural or not, vocal or not. This competitor was coded as natural if it was produced by a biological organism without any further acoustic manipulation. If the authors applied acoustic manipulations it was coded as artificial. This sound was considered as vocal if it was produced by an animal vocal tract, either original or modified.  

Data were coded by the first author. In addition, 20% of the papers were randomly selected to be coded by the last author independently, with disagreements resolved by discussion. There were 10 disagreements out of a total of 260 fields filled in, and they were indicative of the coders not following the codebook, which led to a revision of all data in four variables. 

We coded all the statistical information reported in the included papers. If reported, we coded the mean score and the standard deviation for speech, and the other sound separately. When infant-level data was provided, we recomputed the respective mean scores and standard deviations based on the reported individual scores. If reported, we also coded the t-statistic between the two sound conditions, or an F-statistic provided this was a two-way comparison. If effect sizes  were directly reported as a Cohen’s d or a Hedges' g, we also coded this. 

The PRISMA checklist, data, and code can be found on the online supplementary materials (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8).


## Effect sizes

Once the data were coded, we extracted effect sizes, along with their respective variance. Effect sizes were standardized differences (Cohen’s d) between response to speech and to the other sound.
If they were not directly reported in the papers, we computed them using the respective means and SDs [@lipsey_practical_2001], or a t- or F-statistic [@dunlap_meta-analysis_1996]. As our effect sizes came from within-subject comparisons (e.g. looking time of the same infant during speech and during monkey calls), we needed to take into account the correlation between the two measurements in effect sizes and effect size variances computations. We computed this correlation based on the t-statistic, the respective means and SDs [@lipsey_practical_2001] if they were all reported; or imputed this correlation randomly if not. We finally calculated the variance of each effect size [@lipsey_practical_2001]. Cohen's d were transformed to Hedges' g by multiplying d by a correction for small sample sizes based on the degree of freedom [@borenstein_introduction_2011].

All analyses use the R [@r_core_team_r:_2018] package Robumeta [@hedges_robust_2010], which allows to fit meta-analytic regressions that take into account the correlated structure of the data, when repeated measures are obtained from the same infant groups within papers. 

# Results

## Database description

We found a total of `r length(papers)` papers reporting `r length(DB2$g_calc)` (not mutually independent) effect sizes, see Figure 4. `r length(unique(DB2$study_ID[DB2$peer_reviewed == 'yes']))` papers have been submitted to or published in peer-reviewed journals [@cooper_developmental_1994; @vouloumanos_tuned_2004; @vouloumanos_tuning_2010; @shultz_three-month-olds_2010; @colombo_method_1981; @vouloumanos_five-month-old_2009; @sorcinelli_preference_2019; @yamashiro_does_2019; @segal_listening_2011; @curtin_speech_2013; @vouloumanos_foundational_2014; @vouloumanos_listening_2007; @vouloumanos_tuning_2010; @spence_prenatal_1987; @ecklund-flores_asymmetric_1996]. The remaining 1 paper contributing `r length(DB2$g_calc[DB2$peer_reviewed == 'no'])` effect size was a thesis  [@ference_role_2018].

Studies tended to have small sample sizes, with a median N of `r median(DB2$n)` children (Range = `r max(DB2$n)-min(DB2$n)`, M = `r mean(DB2$n)`, Total: `r round(sum(temp$n))`).
Infants ranged from `r round(min(DB2$mean_age_1)/30.44)` to `r round(max(DB2$mean_age_1)/30.44)` months (`r min(DB2$mean_age_1)` to `r max(DB2$mean_age_1)` days), although the majority were under 9 months of age (`r length(unique(DB2$study_ID[DB2$age_months<=9]))/length(unique(DB2$study_ID))*100`% of the studies). Individual samples comprised `r round(mean(DB2$gender_1, na.rm=TRUE)*100)`% of female participants on average. Infants were native of 6 different languages across the whole database (English, French, Russian, Yiddish, Hebrew, Italian). 
Studies were performed in 10 different laboratories from 4 different countries (United States, Canada, Israel, Italy). As for experimental methods, `r length(unique(DB2$method))`  were used: 12 studies used Central Fixation (CF) [@cooper_developmental_1994; @vouloumanos_tuned_2004; @vouloumanos_tuning_2010; @shultz_three-month-olds_2010; @colombo_method_1981; @vouloumanos_five-month-old_2009; @sorcinelli_preference_2019; @yamashiro_does_2019; @segal_listening_2011; @curtin_speech_2013; @vouloumanos_foundational_2014; @ference_role_2018]; 3 used High-Amplitude Sucking (HAS) [@vouloumanos_listening_2007; @vouloumanos_tuning_2010; @spence_prenatal_1987]; and 1 used Head-turn Preference Procedure (HPP) [@ecklund-flores_asymmetric_1996].

## Summary effect size

```{r forest plot}
#average variance / infant group to build models with CORR, and allow robumeta to detect correlated effect sizes within papers. 
DB2 = DB2 %>% group_by(same_infant) %>% mutate(g_var_m = mean(g_var_calc))

# Model without moderators to get the summary effect size
base_model <- robu(g_calc ~ 1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T) 

# same model with metafor for a nice forest plot 
simple_model <- rma(g_calc, g_var_calc, data=DB2, weighted = TRUE, method = "REML", subset=!DB2$outlier & !is.na(DB2$g_calc), slab =DB2$short_cite) 

for_plot = forest.rma(simple_model, annotate = FALSE, xlim = c(-4.5,3), alim = c(-3,3), top=0, main = 'Forest plot of effect sizes', xlab = 'Effect size (Hedges\' g)', mlab = "", steps = 7, fonts = 'mono', cex = 0.4, cex.axis = 0.6, cex.lab = 0.7) 
#dev.off()
```

Integrating across all studies in a meta-analytic regression without any moderator, we found a summary effect size g of `r base_model$reg_table$b.r` (SE = `r base_model$reg_table$SE`, CI = [`r base_model$reg_table$CI.L` , `r base_model$reg_table$CI.U`]) (Table 1, and Figure 4, diamond), corresponding to a medium effect size. 


```{r resampling}
# Sanity check: We repeat random imputation of missing correlation between the two measures (done in data_completion.R for the main database), and recompute effect sizes 100 times to check it doesn't change the results.
library(Hmisc)

#set up the dataframe that will contain the results after resampling (one line per resampling)
resamp_stats = base_model$reg_table
resamp_prob = base_model$reg_table$prob

for (s in 1:100){
  
  data = DB2 #make a copy of the database without the imputed correlations
  data$corr_imputed[is.na(data$corr)==T] = NA
  data$corr_imputed[data$participant_design == "within_two"] <- impute(data$corr[data$participant_design == "within_two"],fun='random')
  
  # recompute effect sizes
  # empty the relevant variables
  data$d_calc = NA
  data$d_var_calc = NA
  data$g_calc = NA
  data$g_var_calc = NA
  data$es_method = NA
  
  #effect size calculation
  for (i in 1:nrow(data)){
    db = data[i,]
    if (is.na(db$corr) | db$corr > .99 | db$corr < .01){
      #if correlation between two measures is not reported, use an imputed correlation value
      #we also account for the observation that some re-calculated values are impossible and replace those
      corr <- db$corr_imputed
    }else{corr <- db$corr}
    
    if (complete(db$x_1, db$x_2, db$SD_1, db$SD_2)) {
      pooled_SD <- sqrt((db$SD_1 ^ 2 + db$SD_2 ^ 2) / 2) # Lipsey & Wilson (2001)
      d_calc <- (db$x_1 - db$x_2) / pooled_SD # Lipsey & Wilson (2001)
      es_method  <- "group_means_two"
    } else if (complete(db$t)) {
      wc <- sqrt(2 * (1 - corr))
      d_calc <- (db$t / sqrt(db$n_1)) * wc #Dunlap et al., 1996, p.171
      es_method  <- "t_two"
    } else if (complete(db$F)) {
      wc <- sqrt(2 * (1 - corr))
      d_calc <- sqrt(db$F / db$n_1) * wc
      es_method  <- "f_two"
    } else {d_calc = NA}
    #now that effect sizes are calculated, effect size variance is calculated
    if (complete(db$n_1, d_calc)) {
      d_var_calc <- (2 * (1 - corr)/ db$n_1) + (d_calc ^ 2 / (2 * db$n_1)) # Lipsey & Wilson (2001)
    } else if (complete(db$d, db$d_var)) {
      #if d and d_var were already reported, use those values
      d_calc <- db$d
      d_var_calc <- db$d_var
      es_method  <- "d_two"
    } else {d_var_calc = NA}
    
    df <- db$n_1 - 1
    J <- 1 - 3 / (4 * (df - 1))
    g_calc <- d_calc * J
    g_var_calc <- J ^ 2 * d_var_calc
    
    #add the results to the database
    db$d_calc = d_calc
    db$d_var_calc = d_var_calc
    db$g_calc = g_calc
    db$g_var_calc = g_var_calc
    db$es_method = es_method
    
    data[i,] = db
  }
  
  #Mark effect sizes more than 3 SD away from the mean effect (in both positive and negative directions) as outliers
  data$outlier <- F #create the variable, and set as no by default (majority of cases hopefully!)
  data$outlier[data$d_calc > mean(data$d_calc, na.rm = TRUE) + 3*sd(data$d_calc, na.rm = TRUE) | data$d_calc < mean(data$d_calc, na.rm = TRUE) - 3*sd(data$d_calc, na.rm = TRUE)]<-T 
  
  # Re-fit the meta-analytic model
  #average variance / infant group to build models with CORR, and allow robumeta to detect correlated effect sizes within papers. 
  data = data %>% group_by(same_infant) %>% mutate(g_var_m = mean(g_var_calc))
  base <- robu(g_calc ~ 1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T) 
  resamp_stats = bind_rows(resamp_stats,base$reg_table)
  
}

# check that the results don't change in 95 % of cases
resamp_alphas <- ifelse(resamp_stats$prob < 0.05, 1, 0)
resamp_alphas <- length(resamp_alphas[resamp_alphas==0])/length(resamp_alphas)
resamp_alphas
```

## Publication bias

```{r publication bias, fig.align="center", include = F}

#add symmetrize
tf <- trimfill(simple_model) 
fun.fig <- funnel(tf, cex=1.5, xlab='Hedges\' g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference", legend=TRUE)


#Figure
png(filename = "Funnel.png")

#funnel(base_model,cex=1.5,xlab='Hedge\'s g', ylab="Standard Error of Effect Size g", digits=2, main="Funnel plot speech preference", legend=TRUE)
dev.off()

# testing for asymetry (indicates a publication bias) #ac this is highly significant
SEg = regtest(DB2$g_calc,DB2$g_var_calc)
k = ranktest(DB2$g_calc,DB2$g_var_calc)

```

We assessed the presence of a potential publication bias in the body of literature by studying the relationship between standard errors of effect sizes as a function of Hedges’ g (see funnel plot in Figure 5)[^2]. A regression test on these data was significant (z = `r SEg$zval`, p = `r SEg$pval`), as  was the Kendall's tau rank correlation test for funnel plot asymmetry (Kendall's tau = `r k$tau`, p = `r k$pval`), indicating a publication bias in the literature.
To further investigate this bias, we  symmetrized the funnel plot with the “trim and fill” method [@duval_trim_2000]. To symmetrize the funnel plot, `r tf$k0` (SE = `r tf$se.k0`) missing studies were needed on the left side of the plot.

[^2]: If the literature is not biased, effect sizes should be evenly distributed around the mean effect size, with increasing standard error as they go away from the mean effect size (both in the positive and negative directions, white triangle in the funnel plot). This is reflected by a symmetrical funnel plot, with no linear relationship between effect sizes and standard errors. 

## Moderator analyses

We then tested if the preference found above could be explained by the dimensions discussed in the literature. Following our hypothesis, we fit a meta-analytic model with the following moderators: 

- mean age of children;
- familiarity with the language used (native or foreign);
- naturalness of the contrastive sound (coded as yes if it was natural and no otherwise);
- vocal quality of the contrastive sound (coded as yes if it was vocal and no otherwise).

```{r moderators}
#distribution of moderators
g_age <- tapply(DB2$g_calc, DB2$mean_age_1, mean)#ES by age
table(DB2$natural)#no. of natural and non-natural data points
table(DB2$vocal)#no. of vocal and non-vocal data points
table(DB2$homospecific)#no. of homo- and heterospecific data points
table(DB2$homospecific,DB2$vocal)
table(DB2$natural,DB2$vocal)
table(DB2$contrast_stim)

#setting up of predictors 
#http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/

#check that the experimental method doesn't make a difference
relevel(DB2$method,"HAS")->DB2$method #put HAS as the 1st level
#dummy coding: each level is compared to a reference level of the dependent variable, intercept corresponds to the reference level.
contrasts(DB2$method) = contr.treatment(length(levels(DB2$method)),base=1) #baseline method should be HAS because it's the one used with newborns

#moderators of interest
contrasts(DB2$test_lang) <- contr.treatment(length(levels(DB2$test_lang)),base=1)

contrasts(DB2$natural) <- contr.treatment(length(levels(DB2$natural)),base=2)

DB2$vocal <- factor(DB2$vocal)
contrasts(DB2$vocal) <- contr.treatment(length(levels(DB2$vocal)),base=2)

# models with moderators of interest. 

model_vocal <- robu(g_calc ~ test_lang + vocal*mean_age_1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

model_natural <- robu(g_calc ~ test_lang + natural*mean_age_1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

full_model <- robu(g_calc ~ test_lang + natural + vocal + mean_age_1, data=DB2, modelweights = "CORR", studynum = same_infant, var.eff.size = g_var_m, small = T)

```

None of the moderators was significant (see Figure 6 and Table 1).
```{r Table1, results="asis", include=T} 

table1 = rbind(base_model$reg_table[,c(2:4,7:8)],full_model$reg_table[2:5,c(2:4,7:8)])
rownames(table1)=c('summary effect size','familiarity','naturalness','vocal quality','age')

table1[,4]=paste0(round(table1[,4],2)," - ",round(table1[,5],2))
table1=table1[,-5]

apa_table(table1, digits=2, align='lccc', col.names=c("","estimate","SE","t","confidence interval"), caption = "Statistical results of meta-regression with all main effects. The estimates correspond to changes in the intercept when the target stimuli are in the native language (familiarity); the competitor is artificial (naturalness); and the competitor is non-vocal (vocal quality).", escape= T)
```


Due to the relatively low number of effect sizes available in the literature, we did not add interactions with age to the model to avoid overfitting. Inspection of results in Figure 5 show that the confidence intervals of all conditions overlap almost exactly across the tested ages, excluding the possibility of such interactions. 
 
```{r plots}
vio_method <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=method, y=g_calc))+
  geom_violin(aes(fill=method), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=method, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.2, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "method", labels=levels(DB2$method), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#Effect of naturalness
vio_nat <- ggplot(data=DB2[!is.na(DB2$natural),], aes(x=natural, y=g_calc))+
  geom_violin(aes(fill=natural), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=natural, y=g_calc, size=1/DB2[!is.na(DB2$natural),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", labels=c("artificial","natural"), na.translate = FALSE)+
  scale_fill_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

ggplot(data=DB2[!is.na(DB2$natural),], aes(x=age_months, y=g_calc, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_colour_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

# Effect of vocalness
vio_voc <- ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=vocal, y=g_calc))+
  geom_violin(aes(fill=vocal), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=vocal, y=g_calc, size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), position=position_jitter(w=0.1, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "other sound", na.translate = FALSE, labels = c("non-vocal", "vocal"))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("turquoise2","tomato"), labels=c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15))

ggplot(data=DB2[!is.na(DB2$vocal),],aes(x=age_months, y=g_calc, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$vocal),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_colour_manual(values = c("turquoise2","tomato"), labels = c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

age <- ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(method = "glm", na.rm = TRUE, color='gray40')+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  theme_classic()+
  theme(text = element_text(size = 15))

#Effect of familiarity with the speech sounds? Nativeness (test_lang) and age.
ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=g_calc, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  scale_size(range = c(1, 5))+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_colour_manual(values = c("red3","skyblue"), labels = c("foreign","native"), name = "speech sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

vio_lang <- ggplot(data=DB2[!is.na(DB2$test_lang),],aes(x=test_lang, y=g_calc))+
  geom_violin(aes(fill=test_lang), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=test_lang, y=g_calc, size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "speech sound", labels=c("foreign","native"), na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20))

#violin plot / contrasted sound
vio_contrast <- ggplot(data=DB2[!is.na(DB2$contrast_stim),],aes(x=contrast_stim, y=g_calc))+
  geom_violin(aes(fill=contrast_stim), show.legend = F, na.rm = TRUE) +
  geom_jitter(aes(x=contrast_stim, y=g_calc, size=1/DB2[!is.na(DB2$contrast_stim),]$g_var_calc), position=position_jitter(w=0.15, h = 0), show.legend = F, na.rm = TRUE)+
  scale_x_discrete(name = "contrast sound", na.translate = FALSE)+
  scale_y_continuous(name = "Effect size (Hedges' g)", limits = c(-3, 3), breaks = seq(-3,3,1))+
  #scale_fill_manual(values = c("red3","skyblue"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 20), axis.text.x = element_text(angle = 45, size = 10))

```

Readers may wonder to what extent our results are obscured by the influence of experimental method, which is known to be sizable in the cognitive developmental literature [@bergmann_promoting_2018]. Inspection of plots where effect sizes has been residualized from experimental method (Supplementary figure S1) looks virtually identical. 

```{r residuals}

method_reg = lm(DB2$g_calc[!is.na(DB2$g_calc) & !is.na(DB2$method) & !is.na(DB2$natural)] ~ DB2$method[!is.na(DB2$g_calc) & !is.na(DB2$method) & !is.na(DB2$natural)])

DB2$method_res = NA #set-up an empty column
DB2$method_res[!is.na(DB2$g_calc) & !is.na(DB2$method) & !is.na(DB2$natural)] = residuals(method_reg) #fill it with the residuals

#vocal
ggplot(data=DB2[!is.na(DB2$g_calc),], aes(x=age_months, y=method_res, colour=vocal))+
  geom_point(aes(size=1/DB2[!is.na(DB2$g_calc),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2[!is.na(DB2$g_calc),], outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Residuals (Hedges' g)", limits = c(-2, 2), breaks = seq(-2,2,1))+
  scale_colour_manual(values = c("turquoise2","tomato"), labels=c("non-vocal","vocal"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#natural

ggplot(data=DB2[!is.na(DB2$natural),], aes(x=age_months, y=method_res, colour=natural))+
  geom_point(aes(size=1/DB2[!is.na(DB2$natural),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Residuals (Hedges' g)", limits = c(-2, 2), breaks = seq(-2,2,1))+
  scale_colour_manual(values = c("mediumvioletred","green3"), labels=c("artificial","natural"), name = "other sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))

#language
ggplot(data=DB2[!is.na(DB2$test_lang),], aes(x=age_months, y=method_res, colour=test_lang))+
  geom_point(aes(size=1/DB2[!is.na(DB2$test_lang),]$g_var_calc), show.legend = F, na.rm = TRUE)+
  stat_smooth(data=subset(DB2, outlier = F), method = "glm", na.rm = TRUE)+
  scale_x_continuous(name = "Mean age (months)", breaks = seq(0,12,1))+
  scale_y_continuous(name = "Residuals (Hedges' g)", limits = c(-2, 2), breaks = seq(-2,2,1))+
  scale_colour_manual(values = c("red3","skyblue"), labels=c("foreign","native"), name = "speech sound")+
  theme_classic()+
  theme(text = element_text(size = 15), legend.position = c(.9, .9))
```

# Discussion

Our meta-analysis synthesizes the available literature on infants’ preference for speech sounds. Our results confirm that infants reliably prefer speech over other types of sounds from birth. When all studies were considered together with no moderators, we found a sizable intercept (g=`r base_model$reg_table$b.r`). For comparison, the main effect for native vowel discrimination using looking time methods is estimated at 0.25 [@tsuji_perceptual_2014, data inspected in http://metalab.stanford.edu on 2019-10-18]. We had predicted infants' speech preference to be larger when the competitor was an artificial sound than when it was a natural one; when the competitor was non-vocal; and when the speech was in the infants' native language. In fact, we were unable to disprove the null hypothesis of no difference for all three factors, with widely overlapping distributions of effect sizes for studies varying along the three dimensions. 

We had also hypothesized age to play a major role, because it may correlate with a reshaping of the category definition for speech itself. Indeed, studies comparing processing of human speech against human non-speech as well as animal vocalizations more generally [@vouloumanos_tuning_2010; @mcdonald_infant_2019] often discuss these age-related differences in categorization of these sounds. Surprisingly, age did not significantly moderate the overall preference for speech.

From birth and regardless of changes co-occurring with age, infants show a preference for speech, which cannot be reduced to three simpler explanations: naturalness, vocalness, or familiarity (represented here by the native/foreign contrast). This capacity to preferentially listen to speech sounds from birth suggests that infants are born with the capacity to recognize their conspecifics’ communication signals. This parallels what has been proposed by the Conspec model for faces: infants would be born with knowledge about faces, enabling them to orient their attention toward them, even without any prior exposure to faces [@morton_conspec_1991]. The fact that familiarity with the language used in the experiment did not modulate infants’ preference suggests that exposure did not play a crucial role for speech either. However, contrary to faces, fetuses are exposed to speech that is low-pass filtered by the womb throughout the last trimester of gestation [@querleu_fetal_1988; @lecanuet_speech_1993]. It is therefore possible that prenatal experience with low-pass filtered speech helps infants to form a representation of speech, independently of the language spoken. 

 The Conspec model proposes that faces would be detected because of their spatial structure [@morton_conspec_1991]. Similarly, it is possible that infants prefer speech because of its complex acoustic structure and fast transitions [@rosen_constructing_2007]. Speech is characterized by joint spectral and temporal modulations at specific rates [@singh_modulation_2003]. It is possible that infants attune to this specific spectro-temporal structure [though see @minagawa-kawai_assessing_2011, for evidence that these factors taken separately may not be sufficient for neural responses]. Testing this explanation would require to carry out acoustic analyses of the actual stimuli used in the studies. Thus, we recommend interested researchers to gather more data in which the competitor is acoustically simple versus complex; and to deposit the actual stimuli in a public archive such as the Open Science Framework [@foster_open_2017]. 
	
One may wonder whether we fail to find many differences because of a lack of statistical power, particularly in view of between-study variability. We think it is unlikely that all null results reported in this paper are due to this. Inspection of results in Figure 6 show that the confidence intervals of all conditions overlap almost exactly. Moreover, Table 1 shows that the estimate for all these factors is close to zero (the maximum being `r max(full_model$reg_table$b.r[2:5]) `). That said, more data would be welcome to confirm our results with more statistical power. It would also be important to carry out more tests on infants older than 9 months. Language production gains in complexity at about this age [@oller_precursors_1999], which could affect infants' speech preference. We particularly recommend using as competitor natural vocal stimuli, and as target foreign speech, which would help fill in an important gap in our dataset. 

Another finding of our meta-analysis is that the distribution of effect sizes in the literature is consistent with publication bias, in view of a strong asymmetry of the funnel plot. In fact, the trim-and-fill method suggested `r tf$k0` points may be missing, which is a considerable number given that we have `r length(DB2$g_calc)` effect sizes in total (i.e., a quarter more would be missing). Unsurprisingly, the missing studies are in the negative section, i.e., a preference *against* speech, a result that could lead authors to doubt their own data and not submit it to journals, or that would be considered odd by reviewers and editors, who may ask that the data be removed (or who may recommend the paper to be rejected altogether). These missing studies constitute an important limitation of our results. The literature being biased toward positive effect sizes, the true effect size might be smaller than the one we found (vertical line on Figure 5). 

Ultimately, preferential processing of speech may support higher level cognitive tasks. The human species is a highly social one. Detecting speech signals would allow to integrate it with other sensory percepts, such as faces, to form multisensory representations of conspecifics [@vouloumanos_five-month-old_2009]. This would lay the track for social cognition. Identifying speech signals and paying attention to them would allow infants to form complex representations of the sensory world, that they can manipulate cognitively. Infants could categorize visual stimuli (i.e. associate a label to a category of objects) when they were associated to speech, but not pure tones or backward speech [@fulkerson_words_2007; @ferry_categorization_2010; @ferry_nonhuman_2013]. Interestingly, infants categorized visual stimuli when presented with speech, melodies, or monkey vocalizations [@fulkerson_influence_2003; @ferry_nonhuman_2013]. These results support the idea that infants may preferentially process complex sounds. Finally, the preference itself may also be a meaningful index of processing that can be used to identify children at risk [@sorcinelli_preference_2019]. It is therefore important to take stock of what we know today. 

Given the crucial importance of understanding infants' speech preference, we make the following recommendations for further data collection, analysis, and reporting. First, authors should strive to increase their sample sizes. The median sample size at present is 20, which is close to the field standard [@bergmann_promoting_2018] but much lower than current recommendations [@oakes_sample_2017]. Second, authors should consider proposing their studies as registered reports [@kiyonaga_practical_2019]. In this new publication scheme (available for Developmental Science, Infancy, Infant Behavior and Development, and Journal of Child Language at the time of writing, see a full up-to-date list on https://cos.io/rr/), manuscripts are submitted before data are collected. Reviewers and editors make publication decisions based solely on the introduction and methods. Once the paper is accepted, the author collects the data, analyses it according to a pipeline described in the accepted methods, and writes up the rest of the manuscript. The paper is then reviewed once more for readability, but it cannot be rejected if the results are surprising or uncomfortable for the field. Third, for authors who would rather not follow this publication route, we still strongly recommend the use of pre-specified analysis plans. These have the virtue of, when used correctly, allowing both authors and readers to separate confirmation from exploration, reducing the likelihood of inadvertently engaging in questionable research practices [@simmons_false-positive_2011], known to increase false positives. Finally, we strongly recommend reviewers and editors to evaluate submitted manuscripts on the basis of the quality of the methods, and not of the results. If a study fails to report a speech preference, or actually reports a preference for the competitor, this may actually reflect the reality of this phenomenon. For interested readers who intend to collect such data, we recommend caution when designing the study, and transparency when reporting it. Our dataset can be community-augmented, and we invite researchers investigating this phenomenon to complement it with any data they would have (https://osf.io/4stz9/?view_only=d0696591ebf34bfc8430f848cd945ca8), whatever the results and publication status.


\newpage
# References
<!-- # References -->
<!-- # ```{r create_r-references} -->
<!-- # r_refs(file = "r-references.bib") -->
<!-- # ``` -->

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
